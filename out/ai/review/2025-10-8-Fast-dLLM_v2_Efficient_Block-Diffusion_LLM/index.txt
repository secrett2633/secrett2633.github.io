3:I[9275,[],""]
5:I[1343,[],""]
6:I[9157,["231","static/chunks/231-c27e618569e042bc.js","157","static/chunks/157-1a135130af3e1cae.js","185","static/chunks/app/layout-c3e2e457f12fb6f6.js"],"default"]
7:I[231,["231","static/chunks/231-c27e618569e042bc.js","877","static/chunks/app/%5B...slug%5D/page-90448483657abf9e.js"],""]
4:["slug","ai/review/2025-10-8-Fast-dLLM_v2_Efficient_Block-Diffusion_LLM","c"]
0:["8N6icDw00Cy0kKVlExSq2",[[["",{"children":[["slug","ai/review/2025-10-8-Fast-dLLM_v2_Efficient_Block-Diffusion_LLM","c"],{"children":["__PAGE__?{\"slug\":[\"ai\",\"review\",\"2025-10-8-Fast-dLLM_v2_Efficient_Block-Diffusion_LLM\"]}",{}]}]},"$undefined","$undefined",true],["",{"children":[["slug","ai/review/2025-10-8-Fast-dLLM_v2_Efficient_Block-Diffusion_LLM","c"],{"children":["__PAGE__",{},[["$L1","$L2"],null],null]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","$4","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},[["$","html",null,{"lang":"ko","className":"no-js","children":[["$","head",null,{"children":[["$","meta",null,{"name":"msapplication-TileColor","content":"#ffc40d"}],["$","meta",null,{"name":"theme-color","content":"#ffffff"}],["$","script",null,{"async":true,"src":"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY"}],["$","script",null,{"dangerouslySetInnerHTML":{"__html":"\n              window.dataLayer = window.dataLayer || [];\n              function gtag(){dataLayer.push(arguments);}\n              gtag('js', new Date());\n              gtag('config', 'G-NE2W3CFPNY');\n            "}}]]}],["$","body",null,{"className":"__className_f367f3 layout--default","children":["$","div",null,{"className":"min-h-screen bg-gray-50","children":[["$","$L6",null,{}],["$","main",null,{"className":"initial-content","children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","div",null,{"className":"min-h-screen flex items-center justify-center bg-gray-50","children":["$","div",null,{"className":"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center","children":[["$","h1",null,{"className":"text-6xl font-bold text-primary-600 mb-4","children":"404"}],["$","h2",null,{"className":"text-2xl font-semibold text-gray-900 mb-4","children":"페이지를 찾을 수 없습니다"}],["$","p",null,{"className":"text-gray-600 mb-8","children":"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다."}],["$","$L7",null,{"href":"/","className":"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors","children":"홈으로 돌아가기"}]]}]}],"notFoundStyles":[],"styles":null}]}],["$","div",null,{"id":"footer","className":"page__footer","children":["$","footer",null,{"className":"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8","children":["$","div",null,{"className":"text-center text-gray-500 text-sm","children":["$","p",null,{"children":"© 2025 secrett2633. All rights reserved."}]}]}]}]]}]}]]}],null],[["$","div",null,{"className":"flex items-center justify-center min-h-screen","children":["$","div",null,{"className":"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600"}]}],[],[]]],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/e975486d410ad4e9.css","precedence":"next","crossOrigin":"$undefined"}]],[null,"$L8"]]]]]
9:Ta7e,<blockquote>
<p><strong>링크:</strong> <a href="https://arxiv.org/abs/2509.26328">논문 PDF로 바로 열기</a></p>
</blockquote>
<p><strong>저자:</strong> Chengyue Wu, Hao Zhang, Shuchen Xue, Shizhe Diao, Yonggan Fu, Zhijian Liu, Pavlo Molchanov, Ping Luo, Song Han, Enze Xie</p>
<h2>핵심 연구 목표</h2>
<p>본 논문은 **Autoregressive (AR) 대규모 언어 모델(LLMs)**의 본질적인 순차적 디코딩으로 인한 추론 비효율성을 해결하는 것을 목표로 합니다. 사전 훈련된 AR 모델을 효율적인 병렬 텍스트 생성을 위한 블록 확산 언어 모델(dLLM)로 성공적으로 전환하여, AR 모델의 성능을 유지하면서 추론 속도를 크게 향상시키는 것을 목표로 합니다.</p>
<h2>핵심 방법론</h2>
<p>저자들은 사전 훈련된 AR 모델을 dLLM으로 전환하기 위한 혁신적인 훈련 방식을 제안합니다. 이는 <strong>블록 확산 메커니즘</strong>과 <strong>보완적인 어텐션 마스크</strong>를 결합하여 AR 훈련 목표를 유지하면서 블록 단위 양방향 문맥 모델링을 가능하게 합니다. 추론 속도 향상을 위해 <strong>계층적 캐싱 메커니즘</strong> (블록 수준 캐시 및 서브-블록 캐시)과 <strong>병렬 디코딩 파이프라인</strong>을 설계했으며, 특히 <strong>DualCache</strong>와 <strong>신뢰도 기반 병렬 디코딩 전략</strong>을 활용합니다.</p>
<h2>주요 결과</h2>
<p>Fast-dLLM v2는 표준 AR 디코딩 대비 최대 <strong>2.5배</strong> 빠른 속도 향상을 달성하면서도, AR 모델과 동등하거나 더 나은 생성 품질을 유지합니다. **Fast-dLLM v2 (7B)**는 평균 점수 <strong>60.3</strong>으로 <strong>Qwen2.5-7B-Nemo-FT (59.6)</strong> 및 **Dream (57.6)**을 능가하며, <strong>1B 토큰</strong>의 미세 조정만으로 기존 AR 모델을 손실 없이 변환하는 높은 데이터 효율성을 보였습니다.</p>
<h2>AI 실무자를 위한 시사점</h2>
<p>Fast-dLLM v2는 고품질의 저지연 LLM 배포를 위한 실용적인 방법을 제시하며, 특히 실시간 응답이 중요한 애플리케이션에 매우 유용합니다. 사전 훈련된 AR 모델을 적은 미세 조정 데이터(<strong>1B 토큰</strong>)로 효율적인 dLLM으로 전환하는 능력은 기존 모델의 가치를 극대화하는 강력한 전략입니다. 또한, 배치 크기가 증가할수록 우수한 확장성을 보여, <strong>NVIDIA H100</strong>과 같은 최신 하드웨어에서 높은 효율성을 제공합니다.</p>
<blockquote>
<p>⚠️ <strong>알림:</strong> 이 리뷰는 AI로 작성되었습니다.</p>
</blockquote>
2:["$","div",null,{"className":"flex flex-col lg:flex-row gap-8","children":[["$","aside",null,{"className":"lg:w-64 xl:w-72 order-1 lg:order-none","children":["$","div",null,{"className":"sidebar sticky","children":["$","nav",null,{"className":"space-y-4","children":[["$","div","Backend",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"Backend"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Django",{"children":["$","a",null,{"href":"/backend/django/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Django"," (",6,")"]}]}],["$","li","Logging",{"children":["$","a",null,{"href":"/backend/logging/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Logging"," (",1,")"]}]}]]}]]}],["$","div","Python",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"Python"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","PEP",{"children":["$","a",null,{"href":"/python/pep/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["PEP"," (",650,")"]}]}]]}]]}],["$","div","AI/ML",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"AI/ML"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","LLM",{"children":["$","a",null,{"href":"/ai/llm/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["LLM"," (",1,")"]}]}],["$","li","Review",{"children":["$","a",null,{"href":"/ai/review/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Review"," (",1318,")"]}]}]]}]]}],["$","div","DevOps",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"DevOps"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Nginx",{"children":["$","a",null,{"href":"/devops/nginx/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Nginx"," (",1,")"]}]}],["$","li","Docker",{"children":["$","a",null,{"href":"/devops/docker/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Docker"," (",1,")"]}]}],["$","li","SafeLine",{"children":["$","a",null,{"href":"/devops/safeline/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["SafeLine"," (",1,")"]}]}],["$","li","Jenkins",{"children":["$","a",null,{"href":"/devops/jenkins/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Jenkins"," (",3,")"]}]}],["$","li","GitHub Actions",{"children":["$","a",null,{"href":"/devops/github-actions/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["GitHub Actions"," (",1,")"]}]}],["$","li","AWS",{"children":["$","a",null,{"href":"/devops/aws/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["AWS"," (",1,")"]}]}]]}]]}],["$","div","etc",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"etc"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Me",{"children":["$","a",null,{"href":"/etc/me/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Me"," (",3,")"]}]}],["$","li","Chrome Extension",{"children":["$","a",null,{"href":"/etc/chrome-extension/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Chrome Extension"," (",1,")"]}]}]]}]]}]]}]}]}],["$","main",null,{"className":"flex-1","children":["$","article",null,{"className":"page","children":[["$","header",null,{"className":"mb-8","children":[["$","h1",null,{"className":"page__title","children":"[논문리뷰] Fast-dLLM v2: Efficient Block-Diffusion LLM"}],["$","div",null,{"className":"page__meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","span",null,{"className":"ml-4","children":["수정: ","2025년 10월 8일"]}]]}]]}],["$","div",null,{"className":"page__content","children":["$","div",null,{"dangerouslySetInnerHTML":{"__html":"$9"}}]}],["$","footer",null,{"className":"page__meta mt-8","children":["$","div",null,{"className":"page__taxonomy","children":[["$","h4",null,{"className":"text-sm font-medium text-gray-900 mb-2","children":"태그"}],[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion LLMs",{"className":"page__taxonomy-item","children":["#","Diffusion LLMs"]}],["$","span","Inference Acceleration",{"className":"page__taxonomy-item","children":["#","Inference Acceleration"]}],["$","span","Parallel Decoding",{"className":"page__taxonomy-item","children":["#","Parallel Decoding"]}],["$","span","Autoregressive Models",{"className":"page__taxonomy-item","children":["#","Autoregressive Models"]}],["$","span","Caching",{"className":"page__taxonomy-item","children":["#","Caching"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Block-wise Attention",{"className":"page__taxonomy-item","children":["#","Block-wise Attention"]}]]]}]}]]}]}]]}]
8:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"secrett2633's blog"}],["$","meta","3",{"name":"description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","meta","4",{"name":"author","content":"secrett2633"}],["$","meta","5",{"name":"keywords","content":"Django, Python, DevOps, AI, ML, 블로그, 기술"}],["$","meta","6",{"name":"creator","content":"secrett2633"}],["$","meta","7",{"name":"publisher","content":"secrett2633"}],["$","meta","8",{"name":"robots","content":"index, follow"}],["$","meta","9",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","10",{"rel":"canonical","href":"https://secrett2633.github.io/"}],["$","meta","11",{"name":"format-detection","content":"telephone=no, address=no, email=no"}],["$","meta","12",{"property":"og:title","content":"secrett2633's blog"}],["$","meta","13",{"property":"og:description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","meta","14",{"property":"og:url","content":"https://secrett2633.github.io/"}],["$","meta","15",{"property":"og:site_name","content":"secrett2633's blog"}],["$","meta","16",{"property":"og:locale","content":"ko_KR"}],["$","meta","17",{"property":"og:type","content":"website"}],["$","meta","18",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","19",{"name":"twitter:title","content":"secrett2633's blog"}],["$","meta","20",{"name":"twitter:description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","link","21",{"rel":"icon","href":"/icon.ico?6d9f34d4948640b8","type":"image/x-icon","sizes":"16x16"}]]
1:null
