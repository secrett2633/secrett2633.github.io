<!DOCTYPE html><html lang="ko" class="no-js"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/edb8d4ad4fe2f3b0.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-90b03762f46d1ba4.js"/><script src="/_next/static/chunks/fd9d1056-4b0d66bdf1ba1813.js" async=""></script><script src="/_next/static/chunks/23-41c976638cd1a58c.js" async=""></script><script src="/_next/static/chunks/main-app-6087bc228fd56b83.js" async=""></script><script src="/_next/static/chunks/231-ee5764c1002761f9.js" async=""></script><script src="/_next/static/chunks/132-273e49420772df1e.js" async=""></script><script src="/_next/static/chunks/app/layout-d443cbc354279241.js" async=""></script><script src="/_next/static/chunks/app/%5B...slug%5D/page-ef33f0f4c1a350bd.js" async=""></script><link rel="preload" href="https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY" as="script"/><title>[논문리뷰] Diffusion Knows Transparency: Repurposing Video Diffusion for Transparent Object Depth and Normal Estimation - secrett2633&#x27;s blog</title><meta name="description" content="arXiv에 게시된 &#x27;Diffusion Knows Transparency: Repurposing Video Diffusion for Transparent Object Depth and Normal Estimation&#x27; 논문에 대한 자세한 리뷰입니다."/><meta name="author" content="secrett2633"/><link rel="manifest" href="/manifest.json" crossorigin="use-credentials"/><meta name="keywords" content="Django, Python, DevOps, AI, ML, 블로그, 기술"/><meta name="creator" content="secrett2633"/><meta name="publisher" content="secrett2633"/><meta name="robots" content="index, follow"/><meta name="googlebot" content="index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"/><link rel="canonical" href="https://blog.secrett2633.cloud/ai/review/2025-12-30-Diffusion-Knows-Transparency-Repurposing-Video-Diffusion-for-Transparent-Object-Depth-and-Normal-Estimation"/><meta name="format-detection" content="telephone=no, address=no, email=no"/><meta property="og:title" content="[논문리뷰] Diffusion Knows Transparency: Repurposing Video Diffusion for Transparent Object Depth and Normal Estimation"/><meta property="og:description" content="arXiv에 게시된 &#x27;Diffusion Knows Transparency: Repurposing Video Diffusion for Transparent Object Depth and Normal Estimation&#x27; 논문에 대한 자세한 리뷰입니다."/><meta property="og:url" content="https://blog.secrett2633.cloud/ai/review/2025-12-30-Diffusion-Knows-Transparency-Repurposing-Video-Diffusion-for-Transparent-Object-Depth-and-Normal-Estimation"/><meta property="og:type" content="article"/><meta property="article:published_time" content="2025-12-29T15:00:00.000Z"/><meta property="article:modified_time" content="2025-12-29T15:00:00.000Z"/><meta property="article:author" content="secrett2633"/><meta property="article:section" content="Review"/><meta property="article:tag" content="Review"/><meta property="article:tag" content="Video Diffusion Model"/><meta property="article:tag" content="Depth Estimation"/><meta property="article:tag" content="Normal Estimation"/><meta property="article:tag" content="Transparent Objects"/><meta property="article:tag" content="Robotics"/><meta property="article:tag" content="Data Generation"/><meta property="article:tag" content="LoRA Fine-tuning"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:creator" content="@secrett2633"/><meta name="twitter:title" content="[논문리뷰] Diffusion Knows Transparency: Repurposing Video Diffusion for Transparent Object Depth and Normal Estimation"/><meta name="twitter:description" content="arXiv에 게시된 &#x27;Diffusion Knows Transparency: Repurposing Video Diffusion for Transparent Object Depth and Normal Estimation&#x27; 논문에 대한 자세한 리뷰입니다."/><link rel="icon" href="/icon.ico?6d9f34d4948640b8" type="image/x-icon" sizes="16x16"/><meta name="next-size-adjust"/><meta name="msapplication-TileColor" content="#ffc40d"/><meta name="theme-color" content="#ffffff"/><link rel="dns-prefetch" href="https://www.googletagmanager.com"/><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"/><link rel="dns-prefetch" href="https://giscus.app"/><link rel="preconnect" href="https://giscus.app" crossorigin="anonymous"/><meta http-equiv="X-Content-Type-Options" content="nosniff"/><meta name="referrer" content="strict-origin-when-cross-origin"/><script type="application/ld+json">{"@context":"https://schema.org","@type":"WebSite","name":"secrett2633's blog","url":"https://blog.secrett2633.cloud","description":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트","inLanguage":"ko","publisher":{"@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud"}}</script><script type="application/ld+json">{"@context":"https://schema.org","@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud","sameAs":["https://github.com/secrett2633"]}</script><script src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body class="__className_f367f3 layout--default"><a href="#main-content" class="sr-only focus:not-sr-only focus:absolute focus:z-50 focus:p-4 focus:bg-white focus:text-blue-600">본문으로 건너뛰기</a><div class="min-h-screen bg-gray-50"><div class="masthead"><div class="masthead__inner-wrap"><div class="masthead__menu"><nav id="site-nav" class="greedy-nav" aria-label="메인 네비게이션"><a class="site-title" href="/">secrett2633&#x27;s blog</a><div class="flex items-center space-x-4"><ul class="visible-links"><li class="masthead__menu-item"><a href="https://github.com/secrett2633" target="_blank" rel="noopener noreferrer">GitHub</a></li></ul><button class="search__toggle" type="button" aria-label="검색"><svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16"><path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path></svg></button></div></nav></div></div></div><main id="main-content" class="initial-content"><!--$--><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","headline":"[논문리뷰] Diffusion Knows Transparency: Repurposing Video Diffusion for Transparent Object Depth and Normal Estimation","description":"arXiv에 게시된 'Diffusion Knows Transparency: Repurposing Video Diffusion for Transparent Object Depth and Normal Estimation' 논문에 대한 자세한 리뷰입니다.","url":"https://blog.secrett2633.cloud/ai/review/2025-12-30-Diffusion-Knows-Transparency-Repurposing-Video-Diffusion-for-Transparent-Object-Depth-and-Normal-Estimation","datePublished":"2025-12-29T15:00:00.000Z","dateModified":"2025-12-29T15:00:00.000Z","author":{"@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud"},"publisher":{"@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.secrett2633.cloud/ai/review/2025-12-30-Diffusion-Knows-Transparency-Repurposing-Video-Diffusion-for-Transparent-Object-Depth-and-Normal-Estimation"},"image":"https://blog.secrett2633.cloud/og-default.png","isAccessibleForFree":true,"inLanguage":"ko","wordCount":287,"articleSection":"Review","keywords":"Review, Video Diffusion Model, Depth Estimation, Normal Estimation, Transparent Objects, Robotics, Data Generation, LoRA Fine-tuning"}</script><script type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"홈","item":"https://blog.secrett2633.cloud/"},{"@type":"ListItem","position":2,"name":"Review","item":"https://blog.secrett2633.cloud/ai/review"},{"@type":"ListItem","position":3,"name":"[논문리뷰] Diffusion Knows Transparency: Repurposing Video Diffusion for Transparent Object Depth and Normal Estimation","item":"https://blog.secrett2633.cloud/ai/review/2025-12-30-Diffusion-Knows-Transparency-Repurposing-Video-Diffusion-for-Transparent-Object-Depth-and-Normal-Estimation"}]}</script><div class="space-y-6"><div class="flex flex-col lg:flex-row gap-8"><aside class="lg:w-64 xl:w-72 order-1 lg:order-none"><div class="sidebar sticky"><nav class="space-y-4" aria-label="카테고리 네비게이션"><div><p class="font-medium text-gray-900 mb-2">Backend</p><ul class="space-y-1 ml-4"><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/backend/django">Django<!-- --> (<!-- -->6<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/backend/logging">Logging<!-- --> (<!-- -->1<!-- -->)</a></li></ul></div><div><p class="font-medium text-gray-900 mb-2">Python</p><ul class="space-y-1 ml-4"><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/python/pep">PEP<!-- --> (<!-- -->650<!-- -->)</a></li></ul></div><div><p class="font-medium text-gray-900 mb-2">AI/ML</p><ul class="space-y-1 ml-4"><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/ai/llm">LLM<!-- --> (<!-- -->1<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/ai/review">Review<!-- --> (<!-- -->2741<!-- -->)</a></li></ul></div><div><p class="font-medium text-gray-900 mb-2">DevOps</p><ul class="space-y-1 ml-4"><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/devops/nginx">Nginx<!-- --> (<!-- -->1<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/devops/docker">Docker<!-- --> (<!-- -->1<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/devops/safeline">SafeLine<!-- --> (<!-- -->1<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/devops/jenkins">Jenkins<!-- --> (<!-- -->3<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/devops/github-actions">GitHub Actions<!-- --> (<!-- -->1<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/devops/aws">AWS<!-- --> (<!-- -->1<!-- -->)</a></li></ul></div><div><p class="font-medium text-gray-900 mb-2">etc</p><ul class="space-y-1 ml-4"><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/etc/me">Me<!-- --> (<!-- -->3<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/etc/chrome-extension">Chrome Extension<!-- --> (<!-- -->1<!-- -->)</a></li></ul></div></nav></div></aside><div class="flex-1"><nav aria-label="breadcrumb" class="text-sm text-gray-500 mb-4"><ol class="flex flex-wrap items-center gap-1"><li><a class="hover:text-gray-700" href="/">홈</a></li><li class="flex items-center gap-1"><span aria-hidden="true">/</span><a class="hover:text-gray-700" href="/ai/review">Review</a></li><li class="flex items-center gap-1"><span aria-hidden="true">/</span><span class="text-gray-900" aria-current="page">[논문리뷰] Diffusion Knows Transparency: Repurposing Video Diffusion for Transparent Object Depth and Normal Estimation</span></li></ol></nav><article class="page"><header class="mb-8"><h1 class="page__title">[논문리뷰] Diffusion Knows Transparency: Repurposing Video Diffusion for Transparent Object Depth and Normal Estimation</h1><div class="page__meta"><time dateTime="2025-12-30 00:00:00+0900+0900">2025년 12월 30일</time><time class="ml-4" dateTime="2025-12-29T15:00:00.000Z">수정: <!-- -->2025년 12월 30일</time></div></header><div class="page__content"><div><blockquote>
<p><strong>링크:</strong> <a href="https://arxiv.org/abs/2512.23705" target="_blank" rel="noopener noreferrer">논문 PDF로 바로 열기</a></p>
</blockquote>
<p><strong>저자:</strong> Shaocong Xu, Songlin Wei, Qizhe Wei, Zheng Geng, Hong Li, Licheng Shen, Qianpu Sun, Shu Han, Bin Ma, Bohan Li, Chongjie Ye, Yuhang Zheng, Nan Wang, Saining Zhang, Hao Zhao</p>
<h2 id="핵심-연구-목표"><a href="#핵심-연구-목표">핵심 연구 목표</a></h2>
<p>본 논문은 투명하거나 반사되는 객체에 대한 깊이 및 법선 추정의 고질적인 문제를 해결하고자 합니다. 기존 방식의 시간적 불일치성과 제한된 데이터로 인한 일반화 능력 부족을 극복하고, 현대 <strong>비디오 확산 모델(Video Diffusion Model)</strong> 이 내재적으로 학습한 광학 규칙을 활용하여 <strong>강력하고 시간적으로 일관된</strong> 예측을 제공하는 것을 목표로 합니다.</p>
<h2 id="핵심-방법론"><a href="#핵심-방법론">핵심 방법론</a></h2>
<p>연구진은 먼저 1.32M 프레임 규모의 새로운 합성 비디오 데이터셋 <strong>TransPhy3D</strong> 를 구축했습니다. 이를 바탕으로 대규모 <strong>비디오 확산 모델(WAN [14])</strong> 을 기반으로 하는 <strong>DKT(Diffusion Knows Transparency)</strong> 모델을 개발했습니다. 이 모델은 <strong>LoRA(Low-Rank Adaptation) 어댑터</strong> 를 사용하여 RGB 및 노이즈 깊이 잠재 공간을 <strong>DiT(Diffusion Transformer) 백본</strong> 에 연결하고, <strong>TransPhy3D</strong> 와 기존 프레임 단위 데이터셋을 <strong>결합 학습(co-training)</strong> 하여 깊이 및 법선 추정 성능을 최적화합니다.</p>
<h2 id="주요-결과"><a href="#주요-결과">주요 결과</a></h2>
<p><strong>DKT</strong> 는 <strong>ClearPose</strong> , <strong>DREDS (CatKnown/CatNovel)</strong> , <strong>TransPhy3D-Test</strong> 등 실제 및 합성 비디오 벤치마크에서 <strong>제로샷 SOTA 성능</strong> 을 달성했습니다. 특히 <strong>ClearPose</strong> 깊이 추정에서 <strong>REL 9.72↓</strong> , <strong>δ1.05 38.17↑</strong> , <strong>δ1.10 65.50↑</strong> , <strong>δ1.25 93.04↑</strong> 를 기록하며 우수성을 보였습니다. 또한, <strong>DKT-Normal</strong> 은 <strong>ClearPose</strong> 에서 최고의 비디오 법선 추정 결과를 설정했으며, <strong>1.3B 버전</strong> 은 832x480 해상도에서 <strong>프레임당 0.17초</strong> 의 빠른 속도를 보여줍니다. 로봇 그립핑 실험에서는 투명, 반사, 확산 표면 전반에 걸쳐 이전 추정기보다 성공률을 향상시켰습니다.</p>
<h2 id="ai-실무자를-위한-시사점"><a href="#ai-실무자를-위한-시사점">AI 실무자를 위한 시사점</a></h2>
<p><strong>생성형 비디오 모델</strong> 이 투명 객체의 물리적 특성을 효과적으로 이해하고 있음을 보여주어, 복잡한 물리 기반 렌더링 없이도 현실적인 비전 태스크를 해결할 수 있는 새로운 가능성을 제시합니다. <strong>LoRA 어댑터</strong> 와 <strong>합성 데이터셋</strong> 을 활용한 효율적인 학습 전략은 AI 엔지니어에게 시간적 일관성과 일반화 능력이 중요한 로봇 조작과 같은 실시간 응용 분야에서 <strong>비용 효율적인 솔루션</strong> 을 제공할 수 있습니다.</p>
<blockquote>
<p>⚠️ <strong>알림:</strong> 이 리뷰는 AI로 작성되었습니다.</p>
</blockquote>
</div></div><footer class="page__meta mt-8"><div class="page__taxonomy"><span class="text-sm font-medium text-gray-900 mb-2 block">태그</span><a class="page__taxonomy-item" href="/tags/Review">#<!-- -->Review</a><a class="page__taxonomy-item" href="/tags/Video%20Diffusion%20Model">#<!-- -->Video Diffusion Model</a><a class="page__taxonomy-item" href="/tags/Depth%20Estimation">#<!-- -->Depth Estimation</a><a class="page__taxonomy-item" href="/tags/Normal%20Estimation">#<!-- -->Normal Estimation</a><a class="page__taxonomy-item" href="/tags/Transparent%20Objects">#<!-- -->Transparent Objects</a><a class="page__taxonomy-item" href="/tags/Robotics">#<!-- -->Robotics</a><a class="page__taxonomy-item" href="/tags/Data%20Generation">#<!-- -->Data Generation</a><a class="page__taxonomy-item" href="/tags/LoRA%20Fine-tuning">#<!-- -->LoRA Fine-tuning</a></div></footer><section class="comments-section mt-12 pt-8 border-t border-gray-200"></section><section class="mt-12 border-t border-gray-200 pt-8"><h3 class="text-base font-semibold text-gray-900 mb-4">Review<!-- --> 의 다른글</h3><ul class="space-y-2 text-sm"><li class="text-gray-500">이전글<!-- --> <a class="text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4" href="/ai/review/2025-12-30-DiRL-An-Efficient-Post-Training-Framework-for-Diffusion-Language-Models">[논문리뷰] DiRL: An Efficient Post-Training Framework for Diffusion Language Models</a></li><li class="text-gray-900 font-semibold">현재글 : <!-- -->[논문리뷰] Diffusion Knows Transparency: Repurposing Video Diffusion for Transparent Object Depth and Normal Estimation</li><li class="text-gray-500">다음글<!-- --> <a class="text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4" href="/ai/review/2025-12-30-Dream-VL-Dream-VLA-Open-Vision-Language-and-Vision-Language-Action-Models-with-Diffusion-Language-Model-Backbone">[논문리뷰] Dream-VL &amp; Dream-VLA: Open Vision-Language and Vision-Language-Action Models with Diffusion Language Model Backbone</a></li></ul></section></article></div></div></div><!--/$--></main><div id="footer" class="page__footer"><footer class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8"><div class="text-center text-gray-500 text-sm"><p>© <!-- -->2026<!-- --> secrett2633. All rights reserved.</p></div></footer></div></div><script src="/_next/static/chunks/webpack-90b03762f46d1ba4.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/media/e4af272ccee01ff0-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n2:HL[\"/_next/static/css/edb8d4ad4fe2f3b0.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"3:I[5751,[],\"\"]\n6:I[9275,[],\"\"]\n8:I[1343,[],\"\"]\n9:I[9157,[\"231\",\"static/chunks/231-ee5764c1002761f9.js\",\"132\",\"static/chunks/132-273e49420772df1e.js\",\"185\",\"static/chunks/app/layout-d443cbc354279241.js\"],\"default\"]\na:I[231,[\"231\",\"static/chunks/231-ee5764c1002761f9.js\",\"877\",\"static/chunks/app/%5B...slug%5D/page-ef33f0f4c1a350bd.js\"],\"\"]\nb:I[4080,[\"231\",\"static/chunks/231-ee5764c1002761f9.js\",\"132\",\"static/chunks/132-273e49420772df1e.js\",\"185\",\"static/chunks/app/layout-d443cbc354279241.js\"],\"\"]\nd:I[6130,[],\"\"]\n7:[\"slug\",\"ai/review/2025-12-30-Diffusion-Knows-Transparency-Repurposing-Video-Diffusion-for-Transparent-Object-Depth-and-Normal-Estimation\",\"c\"]\ne:[]\n"])</script><script>self.__next_f.push([1,"0:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/edb8d4ad4fe2f3b0.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L3\",null,{\"buildId\":\"mJI0q5Z-SQWBtT83kG_N7\",\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/ai/review/2025-12-30-Diffusion-Knows-Transparency-Repurposing-Video-Diffusion-for-Transparent-Object-Depth-and-Normal-Estimation\",\"initialTree\":[\"\",{\"children\":[[\"slug\",\"ai/review/2025-12-30-Diffusion-Knows-Transparency-Repurposing-Video-Diffusion-for-Transparent-Object-Depth-and-Normal-Estimation\",\"c\"],{\"children\":[\"__PAGE__?{\\\"slug\\\":[\\\"ai\\\",\\\"review\\\",\\\"2025-12-30-Diffusion-Knows-Transparency-Repurposing-Video-Diffusion-for-Transparent-Object-Depth-and-Normal-Estimation\\\"]}\",{}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[[\"slug\",\"ai/review/2025-12-30-Diffusion-Knows-Transparency-Repurposing-Video-Diffusion-for-Transparent-Object-Depth-and-Normal-Estimation\",\"c\"],{\"children\":[\"__PAGE__\",{},[[\"$L4\",\"$L5\"],null],null]},[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"$7\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}],null]},[[\"$\",\"html\",null,{\"lang\":\"ko\",\"className\":\"no-js\",\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"meta\",null,{\"name\":\"msapplication-TileColor\",\"content\":\"#ffc40d\"}],[\"$\",\"meta\",null,{\"name\":\"theme-color\",\"content\":\"#ffffff\"}],[\"$\",\"link\",null,{\"rel\":\"dns-prefetch\",\"href\":\"https://www.googletagmanager.com\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://www.googletagmanager.com\",\"crossOrigin\":\"anonymous\"}],[\"$\",\"link\",null,{\"rel\":\"dns-prefetch\",\"href\":\"https://giscus.app\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://giscus.app\",\"crossOrigin\":\"anonymous\"}],[\"$\",\"meta\",null,{\"httpEquiv\":\"X-Content-Type-Options\",\"content\":\"nosniff\"}],[\"$\",\"meta\",null,{\"name\":\"referrer\",\"content\":\"strict-origin-when-cross-origin\"}],[\"$\",\"script\",null,{\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"{\\\"@context\\\":\\\"https://schema.org\\\",\\\"@type\\\":\\\"WebSite\\\",\\\"name\\\":\\\"secrett2633's blog\\\",\\\"url\\\":\\\"https://blog.secrett2633.cloud\\\",\\\"description\\\":\\\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\\\",\\\"inLanguage\\\":\\\"ko\\\",\\\"publisher\\\":{\\\"@type\\\":\\\"Person\\\",\\\"name\\\":\\\"secrett2633\\\",\\\"url\\\":\\\"https://blog.secrett2633.cloud\\\"}}\"}}],[\"$\",\"script\",null,{\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"{\\\"@context\\\":\\\"https://schema.org\\\",\\\"@type\\\":\\\"Person\\\",\\\"name\\\":\\\"secrett2633\\\",\\\"url\\\":\\\"https://blog.secrett2633.cloud\\\",\\\"sameAs\\\":[\\\"https://github.com/secrett2633\\\"]}\"}}]]}],[\"$\",\"body\",null,{\"className\":\"__className_f367f3 layout--default\",\"children\":[[\"$\",\"a\",null,{\"href\":\"#main-content\",\"className\":\"sr-only focus:not-sr-only focus:absolute focus:z-50 focus:p-4 focus:bg-white focus:text-blue-600\",\"children\":\"본문으로 건너뛰기\"}],[\"$\",\"div\",null,{\"className\":\"min-h-screen bg-gray-50\",\"children\":[[\"$\",\"$L9\",null,{}],[\"$\",\"main\",null,{\"id\":\"main-content\",\"className\":\"initial-content\",\"children\":[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[\"$\",\"div\",null,{\"className\":\"min-h-screen flex items-center justify-center bg-gray-50\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-6xl font-bold text-primary-600 mb-4\",\"children\":\"404\"}],[\"$\",\"h2\",null,{\"className\":\"text-2xl font-semibold text-gray-900 mb-4\",\"children\":\"페이지를 찾을 수 없습니다\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-600 mb-8\",\"children\":\"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다.\"}],[\"$\",\"$La\",null,{\"href\":\"/\",\"className\":\"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors\",\"children\":\"홈으로 돌아가기\"}]]}]}],\"notFoundStyles\":[],\"styles\":null}]}],[\"$\",\"div\",null,{\"id\":\"footer\",\"className\":\"page__footer\",\"children\":[\"$\",\"footer\",null,{\"className\":\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"text-center text-gray-500 text-sm\",\"children\":[\"$\",\"p\",null,{\"children\":[\"© \",2026,\" secrett2633. All rights reserved.\"]}]}]}]}]]}],[\"$\",\"$Lb\",null,{\"src\":\"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY\",\"strategy\":\"afterInteractive\"}],[\"$\",\"$Lb\",null,{\"id\":\"gtag-init\",\"strategy\":\"afterInteractive\",\"children\":\"window.dataLayer = window.dataLayer || [];\\n            function gtag(){dataLayer.push(arguments);}\\n            gtag('js', new Date());\\n            gtag('config', 'G-NE2W3CFPNY');\"}]]}]]}],null],[[\"$\",\"div\",null,{\"className\":\"flex items-center justify-center min-h-screen\",\"role\":\"status\",\"aria-label\":\"로딩 중\",\"children\":[[\"$\",\"div\",null,{\"className\":\"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600\"}],[\"$\",\"span\",null,{\"className\":\"sr-only\",\"children\":\"로딩 중...\"}]]}],[],[]]],\"couldBeIntercepted\":false,\"initialHead\":[null,\"$Lc\"],\"globalErrorComponent\":\"$d\",\"missingSlots\":\"$We\"}]]\n"])</script><script>self.__next_f.push([1,"11:I[646,[\"231\",\"static/chunks/231-ee5764c1002761f9.js\",\"877\",\"static/chunks/app/%5B...slug%5D/page-ef33f0f4c1a350bd.js\"],\"default\"]\nf:T51e,{\"@context\":\"https://schema.org\",\"@type\":\"BlogPosting\",\"headline\":\"[논문리뷰] Diffusion Knows Transparency: Repurposing Video Diffusion for Transparent Object Depth and Normal Estimation\",\"description\":\"arXiv에 게시된 'Diffusion Knows Transparency: Repurposing Video Diffusion for Transparent Object Depth and Normal Estimation' 논문에 대한 자세한 리뷰입니다.\",\"url\":\"https://blog.secrett2633.cloud/ai/review/2025-12-30-Diffusion-Knows-Transparency-Repurposing-Video-Diffusion-for-Transparent-Object-Depth-and-Normal-Estimation\",\"datePublished\":\"2025-12-29T15:00:00.000Z\",\"dateModified\":\"2025-12-29T15:00:00.000Z\",\"author\":{\"@type\":\"Person\",\"name\":\"secrett2633\",\"url\":\"https://blog.secrett2633.cloud\"},\"publisher\":{\"@type\":\"Person\",\"name\":\"secrett2633\",\"url\":\"https://blog.secrett2633.cloud\"},\"mainEntityOfPage\":{\"@type\":\"WebPage\",\"@id\":\"https://blog.secrett2633.cloud/ai/review/2025-12-30-Diffusion-Knows-Transparency-Repurposing-Video-Diffusion-for-Transparent-Object-Depth-and-Normal-Estimation\"},\"image\":\"https://blog.secrett2633.cloud/og-default.png\",\"isAccessibleForFree\":true,\"inLanguage\":\"ko\",\"wordCount\":287,\"articleSection\":\"Review\",\"keywords\":\"Review, Video Diffusion Model, Depth Estimation, Normal Estimation, Transparent Objects, Robotics, Data Generation, LoRA Fine-tuning\"}10:Tdec,"])</script><script>self.__next_f.push([1,"\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e링크:\u003c/strong\u003e \u003ca href=\"https://arxiv.org/abs/2512.23705\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e논문 PDF로 바로 열기\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003e저자:\u003c/strong\u003e Shaocong Xu, Songlin Wei, Qizhe Wei, Zheng Geng, Hong Li, Licheng Shen, Qianpu Sun, Shu Han, Bin Ma, Bohan Li, Chongjie Ye, Yuhang Zheng, Nan Wang, Saining Zhang, Hao Zhao\u003c/p\u003e\n\u003ch2 id=\"핵심-연구-목표\"\u003e\u003ca href=\"#핵심-연구-목표\"\u003e핵심 연구 목표\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003e본 논문은 투명하거나 반사되는 객체에 대한 깊이 및 법선 추정의 고질적인 문제를 해결하고자 합니다. 기존 방식의 시간적 불일치성과 제한된 데이터로 인한 일반화 능력 부족을 극복하고, 현대 \u003cstrong\u003e비디오 확산 모델(Video Diffusion Model)\u003c/strong\u003e 이 내재적으로 학습한 광학 규칙을 활용하여 \u003cstrong\u003e강력하고 시간적으로 일관된\u003c/strong\u003e 예측을 제공하는 것을 목표로 합니다.\u003c/p\u003e\n\u003ch2 id=\"핵심-방법론\"\u003e\u003ca href=\"#핵심-방법론\"\u003e핵심 방법론\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003e연구진은 먼저 1.32M 프레임 규모의 새로운 합성 비디오 데이터셋 \u003cstrong\u003eTransPhy3D\u003c/strong\u003e 를 구축했습니다. 이를 바탕으로 대규모 \u003cstrong\u003e비디오 확산 모델(WAN [14])\u003c/strong\u003e 을 기반으로 하는 \u003cstrong\u003eDKT(Diffusion Knows Transparency)\u003c/strong\u003e 모델을 개발했습니다. 이 모델은 \u003cstrong\u003eLoRA(Low-Rank Adaptation) 어댑터\u003c/strong\u003e 를 사용하여 RGB 및 노이즈 깊이 잠재 공간을 \u003cstrong\u003eDiT(Diffusion Transformer) 백본\u003c/strong\u003e 에 연결하고, \u003cstrong\u003eTransPhy3D\u003c/strong\u003e 와 기존 프레임 단위 데이터셋을 \u003cstrong\u003e결합 학습(co-training)\u003c/strong\u003e 하여 깊이 및 법선 추정 성능을 최적화합니다.\u003c/p\u003e\n\u003ch2 id=\"주요-결과\"\u003e\u003ca href=\"#주요-결과\"\u003e주요 결과\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eDKT\u003c/strong\u003e 는 \u003cstrong\u003eClearPose\u003c/strong\u003e , \u003cstrong\u003eDREDS (CatKnown/CatNovel)\u003c/strong\u003e , \u003cstrong\u003eTransPhy3D-Test\u003c/strong\u003e 등 실제 및 합성 비디오 벤치마크에서 \u003cstrong\u003e제로샷 SOTA 성능\u003c/strong\u003e 을 달성했습니다. 특히 \u003cstrong\u003eClearPose\u003c/strong\u003e 깊이 추정에서 \u003cstrong\u003eREL 9.72↓\u003c/strong\u003e , \u003cstrong\u003eδ1.05 38.17↑\u003c/strong\u003e , \u003cstrong\u003eδ1.10 65.50↑\u003c/strong\u003e , \u003cstrong\u003eδ1.25 93.04↑\u003c/strong\u003e 를 기록하며 우수성을 보였습니다. 또한, \u003cstrong\u003eDKT-Normal\u003c/strong\u003e 은 \u003cstrong\u003eClearPose\u003c/strong\u003e 에서 최고의 비디오 법선 추정 결과를 설정했으며, \u003cstrong\u003e1.3B 버전\u003c/strong\u003e 은 832x480 해상도에서 \u003cstrong\u003e프레임당 0.17초\u003c/strong\u003e 의 빠른 속도를 보여줍니다. 로봇 그립핑 실험에서는 투명, 반사, 확산 표면 전반에 걸쳐 이전 추정기보다 성공률을 향상시켰습니다.\u003c/p\u003e\n\u003ch2 id=\"ai-실무자를-위한-시사점\"\u003e\u003ca href=\"#ai-실무자를-위한-시사점\"\u003eAI 실무자를 위한 시사점\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e생성형 비디오 모델\u003c/strong\u003e 이 투명 객체의 물리적 특성을 효과적으로 이해하고 있음을 보여주어, 복잡한 물리 기반 렌더링 없이도 현실적인 비전 태스크를 해결할 수 있는 새로운 가능성을 제시합니다. \u003cstrong\u003eLoRA 어댑터\u003c/strong\u003e 와 \u003cstrong\u003e합성 데이터셋\u003c/strong\u003e 을 활용한 효율적인 학습 전략은 AI 엔지니어에게 시간적 일관성과 일반화 능력이 중요한 로봇 조작과 같은 실시간 응용 분야에서 \u003cstrong\u003e비용 효율적인 솔루션\u003c/strong\u003e 을 제공할 수 있습니다.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e⚠️ \u003cstrong\u003e알림:\u003c/strong\u003e 이 리뷰는 AI로 작성되었습니다.\u003c/p\u003e\n\u003c/blockquote\u003e\n"])</script><script>self.__next_f.push([1,"5:[[\"$\",\"script\",null,{\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"$f\"}}],[\"$\",\"script\",null,{\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"{\\\"@context\\\":\\\"https://schema.org\\\",\\\"@type\\\":\\\"BreadcrumbList\\\",\\\"itemListElement\\\":[{\\\"@type\\\":\\\"ListItem\\\",\\\"position\\\":1,\\\"name\\\":\\\"홈\\\",\\\"item\\\":\\\"https://blog.secrett2633.cloud/\\\"},{\\\"@type\\\":\\\"ListItem\\\",\\\"position\\\":2,\\\"name\\\":\\\"Review\\\",\\\"item\\\":\\\"https://blog.secrett2633.cloud/ai/review\\\"},{\\\"@type\\\":\\\"ListItem\\\",\\\"position\\\":3,\\\"name\\\":\\\"[논문리뷰] Diffusion Knows Transparency: Repurposing Video Diffusion for Transparent Object Depth and Normal Estimation\\\",\\\"item\\\":\\\"https://blog.secrett2633.cloud/ai/review/2025-12-30-Diffusion-Knows-Transparency-Repurposing-Video-Diffusion-for-Transparent-Object-Depth-and-Normal-Estimation\\\"}]}\"}}],[\"$\",\"div\",null,{\"className\":\"space-y-6\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex flex-col lg:flex-row gap-8\",\"children\":[[\"$\",\"aside\",null,{\"className\":\"lg:w-64 xl:w-72 order-1 lg:order-none\",\"children\":[\"$\",\"div\",null,{\"className\":\"sidebar sticky\",\"children\":[\"$\",\"nav\",null,{\"className\":\"space-y-4\",\"aria-label\":\"카테고리 네비게이션\",\"children\":[[\"$\",\"div\",\"Backend\",{\"children\":[[\"$\",\"p\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"Backend\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"Django\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/backend/django\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Django\",\" (\",6,\")\"]}]}],[\"$\",\"li\",\"Logging\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/backend/logging\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Logging\",\" (\",1,\")\"]}]}]]}]]}],[\"$\",\"div\",\"Python\",{\"children\":[[\"$\",\"p\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"Python\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"PEP\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/python/pep\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"PEP\",\" (\",650,\")\"]}]}]]}]]}],[\"$\",\"div\",\"AI/ML\",{\"children\":[[\"$\",\"p\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"AI/ML\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"LLM\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/ai/llm\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"LLM\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"Review\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/ai/review\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Review\",\" (\",2741,\")\"]}]}]]}]]}],[\"$\",\"div\",\"DevOps\",{\"children\":[[\"$\",\"p\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"DevOps\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"Nginx\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/devops/nginx\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Nginx\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"Docker\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/devops/docker\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Docker\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"SafeLine\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/devops/safeline\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"SafeLine\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"Jenkins\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/devops/jenkins\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Jenkins\",\" (\",3,\")\"]}]}],[\"$\",\"li\",\"GitHub Actions\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/devops/github-actions\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"GitHub Actions\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"AWS\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/devops/aws\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"AWS\",\" (\",1,\")\"]}]}]]}]]}],[\"$\",\"div\",\"etc\",{\"children\":[[\"$\",\"p\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"etc\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"Me\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/etc/me\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Me\",\" (\",3,\")\"]}]}],[\"$\",\"li\",\"Chrome Extension\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/etc/chrome-extension\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Chrome Extension\",\" (\",1,\")\"]}]}]]}]]}]]}]}]}],[\"$\",\"div\",null,{\"className\":\"flex-1\",\"children\":[[\"$\",\"nav\",null,{\"aria-label\":\"breadcrumb\",\"className\":\"text-sm text-gray-500 mb-4\",\"children\":[\"$\",\"ol\",null,{\"className\":\"flex flex-wrap items-center gap-1\",\"children\":[[\"$\",\"li\",null,{\"children\":[\"$\",\"$La\",null,{\"href\":\"/\",\"className\":\"hover:text-gray-700\",\"children\":\"홈\"}]}],[[\"$\",\"li\",\"/ai/review\",{\"className\":\"flex items-center gap-1\",\"children\":[[\"$\",\"span\",null,{\"aria-hidden\":\"true\",\"children\":\"/\"}],[\"$\",\"$La\",null,{\"href\":\"/ai/review\",\"className\":\"hover:text-gray-700\",\"children\":\"Review\"}]]}],[\"$\",\"li\",\"/ai/review/2025-12-30-Diffusion-Knows-Transparency-Repurposing-Video-Diffusion-for-Transparent-Object-Depth-and-Normal-Estimation\",{\"className\":\"flex items-center gap-1\",\"children\":[[\"$\",\"span\",null,{\"aria-hidden\":\"true\",\"children\":\"/\"}],[\"$\",\"span\",null,{\"className\":\"text-gray-900\",\"aria-current\":\"page\",\"children\":\"[논문리뷰] Diffusion Knows Transparency: Repurposing Video Diffusion for Transparent Object Depth and Normal Estimation\"}]]}]]]}]}],[\"$\",\"article\",null,{\"className\":\"page\",\"children\":[[\"$\",\"header\",null,{\"className\":\"mb-8\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"page__title\",\"children\":\"[논문리뷰] Diffusion Knows Transparency: Repurposing Video Diffusion for Transparent Object Depth and Normal Estimation\"}],[\"$\",\"div\",null,{\"className\":\"page__meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-12-30 00:00:00+0900+0900\",\"children\":\"2025년 12월 30일\"}],[\"$\",\"time\",null,{\"className\":\"ml-4\",\"dateTime\":\"2025-12-29T15:00:00.000Z\",\"children\":[\"수정: \",\"2025년 12월 30일\"]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"page__content\",\"children\":[\"$\",\"div\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$10\"}}]}],[\"$\",\"footer\",null,{\"className\":\"page__meta mt-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"page__taxonomy\",\"children\":[[\"$\",\"span\",null,{\"className\":\"text-sm font-medium text-gray-900 mb-2 block\",\"children\":\"태그\"}],[[\"$\",\"$La\",\"Review\",{\"href\":\"/tags/Review\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"$La\",\"Video Diffusion Model\",{\"href\":\"/tags/Video%20Diffusion%20Model\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Diffusion Model\"]}],[\"$\",\"$La\",\"Depth Estimation\",{\"href\":\"/tags/Depth%20Estimation\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Depth Estimation\"]}],[\"$\",\"$La\",\"Normal Estimation\",{\"href\":\"/tags/Normal%20Estimation\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Normal Estimation\"]}],[\"$\",\"$La\",\"Transparent Objects\",{\"href\":\"/tags/Transparent%20Objects\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transparent Objects\"]}],[\"$\",\"$La\",\"Robotics\",{\"href\":\"/tags/Robotics\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robotics\"]}],[\"$\",\"$La\",\"Data Generation\",{\"href\":\"/tags/Data%20Generation\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Generation\"]}],[\"$\",\"$La\",\"LoRA Fine-tuning\",{\"href\":\"/tags/LoRA%20Fine-tuning\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LoRA Fine-tuning\"]}]]]}]}],[\"$\",\"$L11\",null,{\"postPermalink\":\"/ai/review/2025-12-30-Diffusion-Knows-Transparency-Repurposing-Video-Diffusion-for-Transparent-Object-Depth-and-Normal-Estimation\",\"postId\":\"2025-12-30-Diffusion-Knows-Transparency-Repurposing-Video-Diffusion-for-Transparent-Object-Depth-and-Normal-Estimation\"}],[\"$\",\"section\",null,{\"className\":\"mt-12 border-t border-gray-200 pt-8\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-base font-semibold text-gray-900 mb-4\",\"children\":[\"Review\",\" 의 다른글\"]}],[\"$\",\"ul\",null,{\"className\":\"space-y-2 text-sm\",\"children\":[[\"$\",\"li\",null,{\"className\":\"text-gray-500\",\"children\":[\"이전글\",\" \",[\"$\",\"$La\",null,{\"href\":\"/ai/review/2025-12-30-DiRL-An-Efficient-Post-Training-Framework-for-Diffusion-Language-Models\",\"className\":\"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4\",\"children\":\"[논문리뷰] DiRL: An Efficient Post-Training Framework for Diffusion Language Models\"}]]}],[\"$\",\"li\",null,{\"className\":\"text-gray-900 font-semibold\",\"children\":[\"현재글 : \",\"[논문리뷰] Diffusion Knows Transparency: Repurposing Video Diffusion for Transparent Object Depth and Normal Estimation\"]}],[\"$\",\"li\",null,{\"className\":\"text-gray-500\",\"children\":[\"다음글\",\" \",[\"$\",\"$La\",null,{\"href\":\"/ai/review/2025-12-30-Dream-VL-Dream-VLA-Open-Vision-Language-and-Vision-Language-Action-Models-with-Diffusion-Language-Model-Backbone\",\"className\":\"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4\",\"children\":\"[논문리뷰] Dream-VL \u0026 Dream-VLA: Open Vision-Language and Vision-Language-Action Models with Diffusion Language Model Backbone\"}]]}]]}]]}]]}]]}]]}]}]]\n"])</script><script>self.__next_f.push([1,"c:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"[논문리뷰] Diffusion Knows Transparency: Repurposing Video Diffusion for Transparent Object Depth and Normal Estimation - secrett2633's blog\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"arXiv에 게시된 'Diffusion Knows Transparency: Repurposing Video Diffusion for Transparent Object Depth and Normal Estimation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"meta\",\"4\",{\"name\":\"author\",\"content\":\"secrett2633\"}],[\"$\",\"link\",\"5\",{\"rel\":\"manifest\",\"href\":\"/manifest.json\",\"crossOrigin\":\"use-credentials\"}],[\"$\",\"meta\",\"6\",{\"name\":\"keywords\",\"content\":\"Django, Python, DevOps, AI, ML, 블로그, 기술\"}],[\"$\",\"meta\",\"7\",{\"name\":\"creator\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"8\",{\"name\":\"publisher\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"9\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"10\",{\"name\":\"googlebot\",\"content\":\"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1\"}],[\"$\",\"link\",\"11\",{\"rel\":\"canonical\",\"href\":\"https://blog.secrett2633.cloud/ai/review/2025-12-30-Diffusion-Knows-Transparency-Repurposing-Video-Diffusion-for-Transparent-Object-Depth-and-Normal-Estimation\"}],[\"$\",\"meta\",\"12\",{\"name\":\"format-detection\",\"content\":\"telephone=no, address=no, email=no\"}],[\"$\",\"meta\",\"13\",{\"property\":\"og:title\",\"content\":\"[논문리뷰] Diffusion Knows Transparency: Repurposing Video Diffusion for Transparent Object Depth and Normal Estimation\"}],[\"$\",\"meta\",\"14\",{\"property\":\"og:description\",\"content\":\"arXiv에 게시된 'Diffusion Knows Transparency: Repurposing Video Diffusion for Transparent Object Depth and Normal Estimation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"meta\",\"15\",{\"property\":\"og:url\",\"content\":\"https://blog.secrett2633.cloud/ai/review/2025-12-30-Diffusion-Knows-Transparency-Repurposing-Video-Diffusion-for-Transparent-Object-Depth-and-Normal-Estimation\"}],[\"$\",\"meta\",\"16\",{\"property\":\"og:type\",\"content\":\"article\"}],[\"$\",\"meta\",\"17\",{\"property\":\"article:published_time\",\"content\":\"2025-12-29T15:00:00.000Z\"}],[\"$\",\"meta\",\"18\",{\"property\":\"article:modified_time\",\"content\":\"2025-12-29T15:00:00.000Z\"}],[\"$\",\"meta\",\"19\",{\"property\":\"article:author\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"20\",{\"property\":\"article:section\",\"content\":\"Review\"}],[\"$\",\"meta\",\"21\",{\"property\":\"article:tag\",\"content\":\"Review\"}],[\"$\",\"meta\",\"22\",{\"property\":\"article:tag\",\"content\":\"Video Diffusion Model\"}],[\"$\",\"meta\",\"23\",{\"property\":\"article:tag\",\"content\":\"Depth Estimation\"}],[\"$\",\"meta\",\"24\",{\"property\":\"article:tag\",\"content\":\"Normal Estimation\"}],[\"$\",\"meta\",\"25\",{\"property\":\"article:tag\",\"content\":\"Transparent Objects\"}],[\"$\",\"meta\",\"26\",{\"property\":\"article:tag\",\"content\":\"Robotics\"}],[\"$\",\"meta\",\"27\",{\"property\":\"article:tag\",\"content\":\"Data Generation\"}],[\"$\",\"meta\",\"28\",{\"property\":\"article:tag\",\"content\":\"LoRA Fine-tuning\"}],[\"$\",\"meta\",\"29\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"30\",{\"name\":\"twitter:creator\",\"content\":\"@secrett2633\"}],[\"$\",\"meta\",\"31\",{\"name\":\"twitter:title\",\"content\":\"[논문리뷰] Diffusion Knows Transparency: Repurposing Video Diffusion for Transparent Object Depth and Normal Estimation\"}],[\"$\",\"meta\",\"32\",{\"name\":\"twitter:description\",\"content\":\"arXiv에 게시된 'Diffusion Knows Transparency: Repurposing Video Diffusion for Transparent Object Depth and Normal Estimation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"link\",\"33\",{\"rel\":\"icon\",\"href\":\"/icon.ico?6d9f34d4948640b8\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}],[\"$\",\"meta\",\"34\",{\"name\":\"next-size-adjust\"}]]\n"])</script><script>self.__next_f.push([1,"4:null\n"])</script></body></html>