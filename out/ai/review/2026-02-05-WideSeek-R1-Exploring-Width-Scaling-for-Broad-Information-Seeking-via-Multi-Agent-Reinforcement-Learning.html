<!DOCTYPE html><html lang="ko" class="no-js"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/ddc331716d5e47a2.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-90b03762f46d1ba4.js"/><script src="/_next/static/chunks/fd9d1056-0395f68b8cc78a20.js" async=""></script><script src="/_next/static/chunks/23-7d3f7f0b78aa2fd3.js" async=""></script><script src="/_next/static/chunks/main-app-6087bc228fd56b83.js" async=""></script><script src="/_next/static/chunks/231-467e37449c5a68fc.js" async=""></script><script src="/_next/static/chunks/app/layout-b0a450f8e4964582.js" async=""></script><script src="/_next/static/chunks/app/%5B...slug%5D/page-1f60377561abdb46.js" async=""></script><link rel="preload" href="https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY" as="script"/><title>[논문리뷰] WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning - secrett2633&#x27;s blog</title><meta name="description" content="이 [arXiv]에 게시한 &#x27;WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning&#x27; 논문에 대한 자세한 리뷰입니다."/><meta name="author" content="secrett2633"/><link rel="manifest" href="/manifest.json" crossorigin="use-credentials"/><meta name="keywords" content="Django, Python, DevOps, AI, ML, 블로그, 기술"/><meta name="creator" content="secrett2633"/><meta name="publisher" content="secrett2633"/><meta name="robots" content="index, follow"/><meta name="googlebot" content="index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"/><link rel="canonical" href="https://blog.secrett2633.cloud/ai/review/2026-02-05-WideSeek-R1-Exploring-Width-Scaling-for-Broad-Information-Seeking-via-Multi-Agent-Reinforcement-Learning"/><meta name="format-detection" content="telephone=no, address=no, email=no"/><meta property="og:title" content="[논문리뷰] WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning"/><meta property="og:description" content="이 [arXiv]에 게시한 &#x27;WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning&#x27; 논문에 대한 자세한 리뷰입니다."/><meta property="og:url" content="https://blog.secrett2633.cloud/ai/review/2026-02-05-WideSeek-R1-Exploring-Width-Scaling-for-Broad-Information-Seeking-via-Multi-Agent-Reinforcement-Learning"/><meta property="og:type" content="article"/><meta property="article:published_time" content="2026-02-04T15:00:00.000Z"/><meta property="article:modified_time" content="2026-02-04T15:00:00.000Z"/><meta property="article:author" content="secrett2633"/><meta property="article:section" content="Review"/><meta property="article:tag" content="Review"/><meta property="article:tag" content="Multi-Agent Reinforcement Learning"/><meta property="article:tag" content="Width Scaling"/><meta property="article:tag" content="Large Language Models"/><meta property="article:tag" content="Information Seeking"/><meta property="article:tag" content="Task Decomposition"/><meta property="article:tag" content="Parallel Execution"/><meta property="article:tag" content="Lead-Agent-Subagent Framework"/><meta property="article:tag" content="Orchestration"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:creator" content="@secrett2633"/><meta name="twitter:title" content="[논문리뷰] WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning"/><meta name="twitter:description" content="이 [arXiv]에 게시한 &#x27;WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning&#x27; 논문에 대한 자세한 리뷰입니다."/><link rel="icon" href="/icon.ico?6d9f34d4948640b8" type="image/x-icon" sizes="16x16"/><meta name="next-size-adjust"/><meta name="msapplication-TileColor" content="#ffc40d"/><meta name="theme-color" content="#ffffff"/><link rel="dns-prefetch" href="https://www.googletagmanager.com"/><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"/><link rel="dns-prefetch" href="https://giscus.app"/><link rel="preconnect" href="https://giscus.app" crossorigin="anonymous"/><meta http-equiv="X-Content-Type-Options" content="nosniff"/><meta name="referrer" content="strict-origin-when-cross-origin"/><script type="application/ld+json">{"@context":"https://schema.org","@type":"WebSite","name":"secrett2633's blog","url":"https://blog.secrett2633.cloud","description":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트","inLanguage":"ko","publisher":{"@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud"}}</script><script type="application/ld+json">{"@context":"https://schema.org","@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud","sameAs":["https://github.com/secrett2633"]}</script><script src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body class="__className_f367f3 layout--default"><a href="#main-content" class="sr-only focus:not-sr-only focus:absolute focus:z-50 focus:p-4 focus:bg-white focus:text-blue-600">본문으로 건너뛰기</a><div class="min-h-screen bg-gray-50"><div class="masthead"><div class="masthead__inner-wrap"><div class="masthead__menu"><nav id="site-nav" class="greedy-nav" aria-label="메인 네비게이션"><a class="site-title" href="/">secrett2633&#x27;s blog</a><div class="flex items-center space-x-4"><ul class="visible-links"><li class="masthead__menu-item"><a href="https://github.com/secrett2633" target="_blank" rel="noopener noreferrer">GitHub</a></li></ul><button class="search__toggle" type="button" aria-label="검색"><svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16"><path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path></svg></button></div></nav></div></div></div><main id="main-content" class="initial-content"><!--$--><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","headline":"[논문리뷰] WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning","description":"이 [arXiv]에 게시한 'WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.","url":"https://blog.secrett2633.cloud/ai/review/2026-02-05-WideSeek-R1-Exploring-Width-Scaling-for-Broad-Information-Seeking-via-Multi-Agent-Reinforcement-Learning","datePublished":"2026-02-04T15:00:00.000Z","dateModified":"2026-02-04T15:00:00.000Z","author":{"@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud"},"publisher":{"@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.secrett2633.cloud/ai/review/2026-02-05-WideSeek-R1-Exploring-Width-Scaling-for-Broad-Information-Seeking-via-Multi-Agent-Reinforcement-Learning"},"image":"https://blog.secrett2633.cloud/og-default.png","isAccessibleForFree":true,"inLanguage":"ko","wordCount":272,"articleSection":"Review","keywords":"Review, Multi-Agent Reinforcement Learning, Width Scaling, Large Language Models, Information Seeking, Task Decomposition, Parallel Execution, Lead-Agent-Subagent Framework, Orchestration"}</script><script type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"홈","item":"https://blog.secrett2633.cloud/"},{"@type":"ListItem","position":2,"name":"Review","item":"https://blog.secrett2633.cloud/ai/review"},{"@type":"ListItem","position":3,"name":"[논문리뷰] WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning","item":"https://blog.secrett2633.cloud/ai/review/2026-02-05-WideSeek-R1-Exploring-Width-Scaling-for-Broad-Information-Seeking-via-Multi-Agent-Reinforcement-Learning"}]}</script><div class="flex flex-col lg:flex-row gap-8"><aside class="lg:w-64 xl:w-72 order-1 lg:order-none"><div class="sidebar sticky"><nav class="space-y-4" aria-label="카테고리 네비게이션"><div><p class="font-medium text-gray-900 mb-2">Backend</p><ul class="space-y-1 ml-4"><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/backend/django">Django<!-- --> (<!-- -->6<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/backend/logging">Logging<!-- --> (<!-- -->1<!-- -->)</a></li></ul></div><div><p class="font-medium text-gray-900 mb-2">Python</p><ul class="space-y-1 ml-4"><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/python/pep">PEP<!-- --> (<!-- -->650<!-- -->)</a></li></ul></div><div><p class="font-medium text-gray-900 mb-2">AI/ML</p><ul class="space-y-1 ml-4"><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/ai/llm">LLM<!-- --> (<!-- -->1<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/ai/review">Review<!-- --> (<!-- -->2728<!-- -->)</a></li></ul></div><div><p class="font-medium text-gray-900 mb-2">DevOps</p><ul class="space-y-1 ml-4"><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/devops/nginx">Nginx<!-- --> (<!-- -->1<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/devops/docker">Docker<!-- --> (<!-- -->1<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/devops/safeline">SafeLine<!-- --> (<!-- -->1<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/devops/jenkins">Jenkins<!-- --> (<!-- -->3<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/devops/github-actions">GitHub Actions<!-- --> (<!-- -->1<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/devops/aws">AWS<!-- --> (<!-- -->1<!-- -->)</a></li></ul></div><div><p class="font-medium text-gray-900 mb-2">etc</p><ul class="space-y-1 ml-4"><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/etc/me">Me<!-- --> (<!-- -->3<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/etc/chrome-extension">Chrome Extension<!-- --> (<!-- -->1<!-- -->)</a></li></ul></div></nav></div></aside><div class="flex-1"><nav aria-label="breadcrumb" class="text-sm text-gray-500 mb-4"><ol class="flex flex-wrap items-center gap-1"><li><a class="hover:text-gray-700" href="/">홈</a></li><li class="flex items-center gap-1"><span aria-hidden="true">/</span><a class="hover:text-gray-700" href="/ai/review">Review</a></li><li class="flex items-center gap-1"><span aria-hidden="true">/</span><span class="text-gray-900" aria-current="page">[논문리뷰] WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning</span></li></ol></nav><article class="page"><header class="mb-8"><h1 class="page__title">[논문리뷰] WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning</h1><div class="page__meta"><time dateTime="2026-02-05 00:00:00+0900+0900">2026년 2월 5일</time><time class="ml-4" dateTime="2026-02-04T15:00:00.000Z">수정: <!-- -->2026년 2월 5일</time></div></header><div class="page__content"><div><blockquote>
<p><strong>링크:</strong> <a href="https://arxiv.org/abs/2602.04634" target="_blank" rel="noopener noreferrer">논문 PDF로 바로 열기</a></p>
</blockquote>
<p><strong>저자:</strong> Zelai Xu, Zhexuan Xu, Ruize Zhang, Chunyang Zhu, Shi Yu, Weilin Liu, Quanlu Zhang, Wenbo Ding, Chao Yu, Yu Wang</p>
<h2 id="핵심-연구-목표"><a href="#핵심-연구-목표">핵심 연구 목표</a></h2>
<p>본 논문은 LLM의 "깊이 스케일링"이 아닌 <strong>"폭 스케일링(width scaling)"</strong> 이라는 새로운 차원을 탐구하여 광범위한 정보 탐색 문제 해결을 목표로 합니다. 기존 다중 에이전트 시스템이 수작업 워크플로우와 순차적 상호작용으로 인해 효과적인 작업 병렬화를 달성하지 못하는 한계를 극복하고, <strong>다중 에이전트 강화 학습(MARL)</strong> 을 통해 확장 가능한 오케스트레이션과 병렬 실행을 통합하는 방법론을 제시합니다.</p>
<h2 id="핵심-방법론"><a href="#핵심-방법론">핵심 방법론</a></h2>
<p>저자들은 <strong>WIDESEEK-R1</strong> 이라는 <strong>계층적 리드 에이전트-서브 에이전트 프레임워크</strong> 를 제안하며, 이는 <strong>Qwen3-4B</strong> 공유 LLM을 기반으로 합니다. <strong>리드 에이전트</strong> 는 <code>call_subagent</code> 도구를 사용하여 복잡한 태스크를 병렬 가능한 하위 태스크로 <strong>분해 및 오케스트레이션</strong> 합니다. 각 <strong>서브 에이전트</strong> 는 검색 및 접근 도구를 활용하여 할당된 하위 태스크를 <strong>병렬로 실행</strong> 합니다. 시스템은 <strong>20k 개의 광범위한 정보 탐색 태스크 데이터셋</strong> 에서 <strong>MARL</strong> 을 통해 리드 에이전트와 서브 에이전트를 공동으로 최적화합니다.</p>
<h2 id="주요-결과"><a href="#주요-결과">주요 결과</a></h2>
<p><strong>WIDESEEK-R1-4B</strong> 는 WideSearch 벤치마크에서 <strong>40.0%의 아이템 F1 점수</strong> 를 달성했으며, 이는 단일 에이전트 <strong>DeepSeek-R1-671B</strong> 와 비견되는 성능입니다. 이는 DeepSeek-R1-671B보다 약 <strong>170배 적은 파라미터</strong> 를 사용했음에도 불구하고 달성된 결과입니다. 특히, 병렬 서브 에이전트 수가 증가함에 따라 지속적인 성능 향상을 보이며 폭 스케일링의 효과를 입증한 반면, 깊이 스케일링은 빠르게 포화되었습니다.</p>
<h2 id="ai-실무자를-위한-시사점"><a href="#ai-실무자를-위한-시사점">AI 실무자를 위한 시사점</a></h2>
<p>이 연구는 LLM 기반 시스템 설계에서 <strong>"폭 스케일링"의 중요한 가능성</strong> 을 제시하며, <strong>조직 역량을 통한 성능 향상</strong> 의 새로운 방향을 제시합니다. <strong>작은 모델(4B)</strong> 로도 <strong>대규모 모델(671B)</strong> 에 필적하는 성능을 달성하여, <strong>제한된 컴퓨팅 자원</strong> 으로도 고성능 AI를 개발할 수 있는 실용적인 길을 열었습니다. 또한, <strong>MARL 기반의 학습 가능한 오케스트레이션</strong> 이 복잡하고 광범위한 정보 탐색 문제에 효과적임을 보여주어, 실제 AI 시스템 설계에 있어 다중 에이전트 협업의 중요성을 강조합니다.</p>
<blockquote>
<p>⚠️ <strong>알림:</strong> 이 리뷰는 AI로 작성되었습니다.</p>
</blockquote>
</div></div><footer class="page__meta mt-8"><div class="page__taxonomy"><span class="text-sm font-medium text-gray-900 mb-2 block">태그</span><a class="page__taxonomy-item" href="/tags/Review">#<!-- -->Review</a><a class="page__taxonomy-item" href="/tags/Multi-Agent%20Reinforcement%20Learning">#<!-- -->Multi-Agent Reinforcement Learning</a><a class="page__taxonomy-item" href="/tags/Width%20Scaling">#<!-- -->Width Scaling</a><a class="page__taxonomy-item" href="/tags/Large%20Language%20Models">#<!-- -->Large Language Models</a><a class="page__taxonomy-item" href="/tags/Information%20Seeking">#<!-- -->Information Seeking</a><a class="page__taxonomy-item" href="/tags/Task%20Decomposition">#<!-- -->Task Decomposition</a><a class="page__taxonomy-item" href="/tags/Parallel%20Execution">#<!-- -->Parallel Execution</a><a class="page__taxonomy-item" href="/tags/Lead-Agent-Subagent%20Framework">#<!-- -->Lead-Agent-Subagent Framework</a><a class="page__taxonomy-item" href="/tags/Orchestration">#<!-- -->Orchestration</a></div></footer><section class="comments-section mt-12 pt-8 border-t border-gray-200"></section><section class="mt-12 border-t border-gray-200 pt-8"><h3 class="text-base font-semibold text-gray-900 mb-4">Review<!-- --> 의 다른글</h3><ul class="space-y-2 text-sm"><li class="text-gray-500">이전글<!-- --> <a class="text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4" href="/ai/review/2026-02-05-Vibe-AIGC-A-New-Paradigm-for-Content-Generation-via-Agentic-Orchestration">[논문리뷰] Vibe AIGC: A New Paradigm for Content Generation via Agentic Orchestration</a></li><li class="text-gray-900 font-semibold">현재글 : <!-- -->[논문리뷰] WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning</li><li class="text-gray-500">다음글<!-- --> <a class="text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4" href="/ai/review/2026-02-06-BABE-Biology-Arena-BEnchmark">[논문리뷰] BABE: Biology Arena BEnchmark</a></li></ul></section></article></div></div><!--/$--></main><div id="footer" class="page__footer"><footer class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8"><div class="text-center text-gray-500 text-sm"><p>© <!-- -->2026<!-- --> secrett2633. All rights reserved.</p></div></footer></div></div><script src="/_next/static/chunks/webpack-90b03762f46d1ba4.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/media/e4af272ccee01ff0-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n2:HL[\"/_next/static/css/ddc331716d5e47a2.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"3:I[5751,[],\"\"]\n6:I[9275,[],\"\"]\n8:I[1343,[],\"\"]\n9:I[9157,[\"231\",\"static/chunks/231-467e37449c5a68fc.js\",\"185\",\"static/chunks/app/layout-b0a450f8e4964582.js\"],\"default\"]\na:I[231,[\"231\",\"static/chunks/231-467e37449c5a68fc.js\",\"877\",\"static/chunks/app/%5B...slug%5D/page-1f60377561abdb46.js\"],\"\"]\nb:I[4080,[\"231\",\"static/chunks/231-467e37449c5a68fc.js\",\"185\",\"static/chunks/app/layout-b0a450f8e4964582.js\"],\"\"]\nd:I[6130,[],\"\"]\n7:[\"slug\",\"ai/review/2026-02-05-WideSeek-R1-Exploring-Width-Scaling-for-Broad-Information-Seeking-via-Multi-Agent-Reinforcement-Learning\",\"c\"]\ne:[]\n"])</script><script>self.__next_f.push([1,"0:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/ddc331716d5e47a2.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L3\",null,{\"buildId\":\"WcxaIiCPz9cbpnkGvOjOK\",\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/ai/review/2026-02-05-WideSeek-R1-Exploring-Width-Scaling-for-Broad-Information-Seeking-via-Multi-Agent-Reinforcement-Learning\",\"initialTree\":[\"\",{\"children\":[[\"slug\",\"ai/review/2026-02-05-WideSeek-R1-Exploring-Width-Scaling-for-Broad-Information-Seeking-via-Multi-Agent-Reinforcement-Learning\",\"c\"],{\"children\":[\"__PAGE__?{\\\"slug\\\":[\\\"ai\\\",\\\"review\\\",\\\"2026-02-05-WideSeek-R1-Exploring-Width-Scaling-for-Broad-Information-Seeking-via-Multi-Agent-Reinforcement-Learning\\\"]}\",{}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[[\"slug\",\"ai/review/2026-02-05-WideSeek-R1-Exploring-Width-Scaling-for-Broad-Information-Seeking-via-Multi-Agent-Reinforcement-Learning\",\"c\"],{\"children\":[\"__PAGE__\",{},[[\"$L4\",\"$L5\"],null],null]},[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"$7\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}],null]},[[\"$\",\"html\",null,{\"lang\":\"ko\",\"className\":\"no-js\",\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"meta\",null,{\"name\":\"msapplication-TileColor\",\"content\":\"#ffc40d\"}],[\"$\",\"meta\",null,{\"name\":\"theme-color\",\"content\":\"#ffffff\"}],[\"$\",\"link\",null,{\"rel\":\"dns-prefetch\",\"href\":\"https://www.googletagmanager.com\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://www.googletagmanager.com\",\"crossOrigin\":\"anonymous\"}],[\"$\",\"link\",null,{\"rel\":\"dns-prefetch\",\"href\":\"https://giscus.app\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://giscus.app\",\"crossOrigin\":\"anonymous\"}],[\"$\",\"meta\",null,{\"httpEquiv\":\"X-Content-Type-Options\",\"content\":\"nosniff\"}],[\"$\",\"meta\",null,{\"name\":\"referrer\",\"content\":\"strict-origin-when-cross-origin\"}],[\"$\",\"script\",null,{\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"{\\\"@context\\\":\\\"https://schema.org\\\",\\\"@type\\\":\\\"WebSite\\\",\\\"name\\\":\\\"secrett2633's blog\\\",\\\"url\\\":\\\"https://blog.secrett2633.cloud\\\",\\\"description\\\":\\\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\\\",\\\"inLanguage\\\":\\\"ko\\\",\\\"publisher\\\":{\\\"@type\\\":\\\"Person\\\",\\\"name\\\":\\\"secrett2633\\\",\\\"url\\\":\\\"https://blog.secrett2633.cloud\\\"}}\"}}],[\"$\",\"script\",null,{\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"{\\\"@context\\\":\\\"https://schema.org\\\",\\\"@type\\\":\\\"Person\\\",\\\"name\\\":\\\"secrett2633\\\",\\\"url\\\":\\\"https://blog.secrett2633.cloud\\\",\\\"sameAs\\\":[\\\"https://github.com/secrett2633\\\"]}\"}}]]}],[\"$\",\"body\",null,{\"className\":\"__className_f367f3 layout--default\",\"children\":[[\"$\",\"a\",null,{\"href\":\"#main-content\",\"className\":\"sr-only focus:not-sr-only focus:absolute focus:z-50 focus:p-4 focus:bg-white focus:text-blue-600\",\"children\":\"본문으로 건너뛰기\"}],[\"$\",\"div\",null,{\"className\":\"min-h-screen bg-gray-50\",\"children\":[[\"$\",\"$L9\",null,{}],[\"$\",\"main\",null,{\"id\":\"main-content\",\"className\":\"initial-content\",\"children\":[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[\"$\",\"div\",null,{\"className\":\"min-h-screen flex items-center justify-center bg-gray-50\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-6xl font-bold text-primary-600 mb-4\",\"children\":\"404\"}],[\"$\",\"h2\",null,{\"className\":\"text-2xl font-semibold text-gray-900 mb-4\",\"children\":\"페이지를 찾을 수 없습니다\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-600 mb-8\",\"children\":\"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다.\"}],[\"$\",\"$La\",null,{\"href\":\"/\",\"className\":\"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors\",\"children\":\"홈으로 돌아가기\"}]]}]}],\"notFoundStyles\":[],\"styles\":null}]}],[\"$\",\"div\",null,{\"id\":\"footer\",\"className\":\"page__footer\",\"children\":[\"$\",\"footer\",null,{\"className\":\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"text-center text-gray-500 text-sm\",\"children\":[\"$\",\"p\",null,{\"children\":[\"© \",2026,\" secrett2633. All rights reserved.\"]}]}]}]}]]}],[\"$\",\"$Lb\",null,{\"src\":\"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY\",\"strategy\":\"afterInteractive\"}],[\"$\",\"$Lb\",null,{\"id\":\"gtag-init\",\"strategy\":\"afterInteractive\",\"children\":\"window.dataLayer = window.dataLayer || [];\\n            function gtag(){dataLayer.push(arguments);}\\n            gtag('js', new Date());\\n            gtag('config', 'G-NE2W3CFPNY');\"}]]}]]}],null],[[\"$\",\"div\",null,{\"className\":\"flex items-center justify-center min-h-screen\",\"role\":\"status\",\"aria-label\":\"로딩 중\",\"children\":[[\"$\",\"div\",null,{\"className\":\"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600\"}],[\"$\",\"span\",null,{\"className\":\"sr-only\",\"children\":\"로딩 중...\"}]]}],[],[]]],\"couldBeIntercepted\":false,\"initialHead\":[null,\"$Lc\"],\"globalErrorComponent\":\"$d\",\"missingSlots\":\"$We\"}]]\n"])</script><script>self.__next_f.push([1,"11:I[646,[\"231\",\"static/chunks/231-467e37449c5a68fc.js\",\"877\",\"static/chunks/app/%5B...slug%5D/page-1f60377561abdb46.js\"],\"default\"]\nf:T54f,{\"@context\":\"https://schema.org\",\"@type\":\"BlogPosting\",\"headline\":\"[논문리뷰] WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning\",\"description\":\"이 [arXiv]에 게시한 'WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.\",\"url\":\"https://blog.secrett2633.cloud/ai/review/2026-02-05-WideSeek-R1-Exploring-Width-Scaling-for-Broad-Information-Seeking-via-Multi-Agent-Reinforcement-Learning\",\"datePublished\":\"2026-02-04T15:00:00.000Z\",\"dateModified\":\"2026-02-04T15:00:00.000Z\",\"author\":{\"@type\":\"Person\",\"name\":\"secrett2633\",\"url\":\"https://blog.secrett2633.cloud\"},\"publisher\":{\"@type\":\"Person\",\"name\":\"secrett2633\",\"url\":\"https://blog.secrett2633.cloud\"},\"mainEntityOfPage\":{\"@type\":\"WebPage\",\"@id\":\"https://blog.secrett2633.cloud/ai/review/2026-02-05-WideSeek-R1-Exploring-Width-Scaling-for-Broad-Information-Seeking-via-Multi-Agent-Reinforcement-Learning\"},\"image\":\"https://blog.secrett2633.cloud/og-default.png\",\"isAccessibleForFree\":true,\"inLanguage\":\"ko\",\"wordCount\":272,\"articleSection\":\"Review\",\"keywords\":\"Review, Multi-Agent Reinforcement Learning, Width Scaling, Large Language Models, Information Seeking, Task Decomposition, Parallel Execution, Lead-Agent-Subagent Framework, Orchestration\"}10:Tdb5,"])</script><script>self.__next_f.push([1,"\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e링크:\u003c/strong\u003e \u003ca href=\"https://arxiv.org/abs/2602.04634\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e논문 PDF로 바로 열기\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003e저자:\u003c/strong\u003e Zelai Xu, Zhexuan Xu, Ruize Zhang, Chunyang Zhu, Shi Yu, Weilin Liu, Quanlu Zhang, Wenbo Ding, Chao Yu, Yu Wang\u003c/p\u003e\n\u003ch2 id=\"핵심-연구-목표\"\u003e\u003ca href=\"#핵심-연구-목표\"\u003e핵심 연구 목표\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003e본 논문은 LLM의 \"깊이 스케일링\"이 아닌 \u003cstrong\u003e\"폭 스케일링(width scaling)\"\u003c/strong\u003e 이라는 새로운 차원을 탐구하여 광범위한 정보 탐색 문제 해결을 목표로 합니다. 기존 다중 에이전트 시스템이 수작업 워크플로우와 순차적 상호작용으로 인해 효과적인 작업 병렬화를 달성하지 못하는 한계를 극복하고, \u003cstrong\u003e다중 에이전트 강화 학습(MARL)\u003c/strong\u003e 을 통해 확장 가능한 오케스트레이션과 병렬 실행을 통합하는 방법론을 제시합니다.\u003c/p\u003e\n\u003ch2 id=\"핵심-방법론\"\u003e\u003ca href=\"#핵심-방법론\"\u003e핵심 방법론\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003e저자들은 \u003cstrong\u003eWIDESEEK-R1\u003c/strong\u003e 이라는 \u003cstrong\u003e계층적 리드 에이전트-서브 에이전트 프레임워크\u003c/strong\u003e 를 제안하며, 이는 \u003cstrong\u003eQwen3-4B\u003c/strong\u003e 공유 LLM을 기반으로 합니다. \u003cstrong\u003e리드 에이전트\u003c/strong\u003e 는 \u003ccode\u003ecall_subagent\u003c/code\u003e 도구를 사용하여 복잡한 태스크를 병렬 가능한 하위 태스크로 \u003cstrong\u003e분해 및 오케스트레이션\u003c/strong\u003e 합니다. 각 \u003cstrong\u003e서브 에이전트\u003c/strong\u003e 는 검색 및 접근 도구를 활용하여 할당된 하위 태스크를 \u003cstrong\u003e병렬로 실행\u003c/strong\u003e 합니다. 시스템은 \u003cstrong\u003e20k 개의 광범위한 정보 탐색 태스크 데이터셋\u003c/strong\u003e 에서 \u003cstrong\u003eMARL\u003c/strong\u003e 을 통해 리드 에이전트와 서브 에이전트를 공동으로 최적화합니다.\u003c/p\u003e\n\u003ch2 id=\"주요-결과\"\u003e\u003ca href=\"#주요-결과\"\u003e주요 결과\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eWIDESEEK-R1-4B\u003c/strong\u003e 는 WideSearch 벤치마크에서 \u003cstrong\u003e40.0%의 아이템 F1 점수\u003c/strong\u003e 를 달성했으며, 이는 단일 에이전트 \u003cstrong\u003eDeepSeek-R1-671B\u003c/strong\u003e 와 비견되는 성능입니다. 이는 DeepSeek-R1-671B보다 약 \u003cstrong\u003e170배 적은 파라미터\u003c/strong\u003e 를 사용했음에도 불구하고 달성된 결과입니다. 특히, 병렬 서브 에이전트 수가 증가함에 따라 지속적인 성능 향상을 보이며 폭 스케일링의 효과를 입증한 반면, 깊이 스케일링은 빠르게 포화되었습니다.\u003c/p\u003e\n\u003ch2 id=\"ai-실무자를-위한-시사점\"\u003e\u003ca href=\"#ai-실무자를-위한-시사점\"\u003eAI 실무자를 위한 시사점\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003e이 연구는 LLM 기반 시스템 설계에서 \u003cstrong\u003e\"폭 스케일링\"의 중요한 가능성\u003c/strong\u003e 을 제시하며, \u003cstrong\u003e조직 역량을 통한 성능 향상\u003c/strong\u003e 의 새로운 방향을 제시합니다. \u003cstrong\u003e작은 모델(4B)\u003c/strong\u003e 로도 \u003cstrong\u003e대규모 모델(671B)\u003c/strong\u003e 에 필적하는 성능을 달성하여, \u003cstrong\u003e제한된 컴퓨팅 자원\u003c/strong\u003e 으로도 고성능 AI를 개발할 수 있는 실용적인 길을 열었습니다. 또한, \u003cstrong\u003eMARL 기반의 학습 가능한 오케스트레이션\u003c/strong\u003e 이 복잡하고 광범위한 정보 탐색 문제에 효과적임을 보여주어, 실제 AI 시스템 설계에 있어 다중 에이전트 협업의 중요성을 강조합니다.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e⚠️ \u003cstrong\u003e알림:\u003c/strong\u003e 이 리뷰는 AI로 작성되었습니다.\u003c/p\u003e\n\u003c/blockquote\u003e\n"])</script><script>self.__next_f.push([1,"5:[[\"$\",\"script\",null,{\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"$f\"}}],[\"$\",\"script\",null,{\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"{\\\"@context\\\":\\\"https://schema.org\\\",\\\"@type\\\":\\\"BreadcrumbList\\\",\\\"itemListElement\\\":[{\\\"@type\\\":\\\"ListItem\\\",\\\"position\\\":1,\\\"name\\\":\\\"홈\\\",\\\"item\\\":\\\"https://blog.secrett2633.cloud/\\\"},{\\\"@type\\\":\\\"ListItem\\\",\\\"position\\\":2,\\\"name\\\":\\\"Review\\\",\\\"item\\\":\\\"https://blog.secrett2633.cloud/ai/review\\\"},{\\\"@type\\\":\\\"ListItem\\\",\\\"position\\\":3,\\\"name\\\":\\\"[논문리뷰] WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning\\\",\\\"item\\\":\\\"https://blog.secrett2633.cloud/ai/review/2026-02-05-WideSeek-R1-Exploring-Width-Scaling-for-Broad-Information-Seeking-via-Multi-Agent-Reinforcement-Learning\\\"}]}\"}}],[\"$\",\"div\",null,{\"className\":\"flex flex-col lg:flex-row gap-8\",\"children\":[[\"$\",\"aside\",null,{\"className\":\"lg:w-64 xl:w-72 order-1 lg:order-none\",\"children\":[\"$\",\"div\",null,{\"className\":\"sidebar sticky\",\"children\":[\"$\",\"nav\",null,{\"className\":\"space-y-4\",\"aria-label\":\"카테고리 네비게이션\",\"children\":[[\"$\",\"div\",\"Backend\",{\"children\":[[\"$\",\"p\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"Backend\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"Django\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/backend/django\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Django\",\" (\",6,\")\"]}]}],[\"$\",\"li\",\"Logging\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/backend/logging\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Logging\",\" (\",1,\")\"]}]}]]}]]}],[\"$\",\"div\",\"Python\",{\"children\":[[\"$\",\"p\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"Python\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"PEP\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/python/pep\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"PEP\",\" (\",650,\")\"]}]}]]}]]}],[\"$\",\"div\",\"AI/ML\",{\"children\":[[\"$\",\"p\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"AI/ML\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"LLM\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/ai/llm\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"LLM\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"Review\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/ai/review\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Review\",\" (\",2728,\")\"]}]}]]}]]}],[\"$\",\"div\",\"DevOps\",{\"children\":[[\"$\",\"p\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"DevOps\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"Nginx\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/devops/nginx\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Nginx\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"Docker\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/devops/docker\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Docker\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"SafeLine\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/devops/safeline\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"SafeLine\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"Jenkins\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/devops/jenkins\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Jenkins\",\" (\",3,\")\"]}]}],[\"$\",\"li\",\"GitHub Actions\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/devops/github-actions\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"GitHub Actions\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"AWS\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/devops/aws\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"AWS\",\" (\",1,\")\"]}]}]]}]]}],[\"$\",\"div\",\"etc\",{\"children\":[[\"$\",\"p\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"etc\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"Me\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/etc/me\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Me\",\" (\",3,\")\"]}]}],[\"$\",\"li\",\"Chrome Extension\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/etc/chrome-extension\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Chrome Extension\",\" (\",1,\")\"]}]}]]}]]}]]}]}]}],[\"$\",\"div\",null,{\"className\":\"flex-1\",\"children\":[[\"$\",\"nav\",null,{\"aria-label\":\"breadcrumb\",\"className\":\"text-sm text-gray-500 mb-4\",\"children\":[\"$\",\"ol\",null,{\"className\":\"flex flex-wrap items-center gap-1\",\"children\":[[\"$\",\"li\",null,{\"children\":[\"$\",\"$La\",null,{\"href\":\"/\",\"className\":\"hover:text-gray-700\",\"children\":\"홈\"}]}],[[\"$\",\"li\",\"/ai/review\",{\"className\":\"flex items-center gap-1\",\"children\":[[\"$\",\"span\",null,{\"aria-hidden\":\"true\",\"children\":\"/\"}],[\"$\",\"$La\",null,{\"href\":\"/ai/review\",\"className\":\"hover:text-gray-700\",\"children\":\"Review\"}]]}],[\"$\",\"li\",\"/ai/review/2026-02-05-WideSeek-R1-Exploring-Width-Scaling-for-Broad-Information-Seeking-via-Multi-Agent-Reinforcement-Learning\",{\"className\":\"flex items-center gap-1\",\"children\":[[\"$\",\"span\",null,{\"aria-hidden\":\"true\",\"children\":\"/\"}],[\"$\",\"span\",null,{\"className\":\"text-gray-900\",\"aria-current\":\"page\",\"children\":\"[논문리뷰] WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning\"}]]}]]]}]}],[\"$\",\"article\",null,{\"className\":\"page\",\"children\":[[\"$\",\"header\",null,{\"className\":\"mb-8\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"page__title\",\"children\":\"[논문리뷰] WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning\"}],[\"$\",\"div\",null,{\"className\":\"page__meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2026-02-05 00:00:00+0900+0900\",\"children\":\"2026년 2월 5일\"}],[\"$\",\"time\",null,{\"className\":\"ml-4\",\"dateTime\":\"2026-02-04T15:00:00.000Z\",\"children\":[\"수정: \",\"2026년 2월 5일\"]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"page__content\",\"children\":[\"$\",\"div\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$10\"}}]}],[\"$\",\"footer\",null,{\"className\":\"page__meta mt-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"page__taxonomy\",\"children\":[[\"$\",\"span\",null,{\"className\":\"text-sm font-medium text-gray-900 mb-2 block\",\"children\":\"태그\"}],[[\"$\",\"$La\",\"Review\",{\"href\":\"/tags/Review\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"$La\",\"Multi-Agent Reinforcement Learning\",{\"href\":\"/tags/Multi-Agent%20Reinforcement%20Learning\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Agent Reinforcement Learning\"]}],[\"$\",\"$La\",\"Width Scaling\",{\"href\":\"/tags/Width%20Scaling\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Width Scaling\"]}],[\"$\",\"$La\",\"Large Language Models\",{\"href\":\"/tags/Large%20Language%20Models\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"$La\",\"Information Seeking\",{\"href\":\"/tags/Information%20Seeking\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Information Seeking\"]}],[\"$\",\"$La\",\"Task Decomposition\",{\"href\":\"/tags/Task%20Decomposition\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Task Decomposition\"]}],[\"$\",\"$La\",\"Parallel Execution\",{\"href\":\"/tags/Parallel%20Execution\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Parallel Execution\"]}],[\"$\",\"$La\",\"Lead-Agent-Subagent Framework\",{\"href\":\"/tags/Lead-Agent-Subagent%20Framework\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Lead-Agent-Subagent Framework\"]}],[\"$\",\"$La\",\"Orchestration\",{\"href\":\"/tags/Orchestration\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Orchestration\"]}]]]}]}],[\"$\",\"$L11\",null,{\"postPermalink\":\"/ai/review/2026-02-05-WideSeek-R1-Exploring-Width-Scaling-for-Broad-Information-Seeking-via-Multi-Agent-Reinforcement-Learning\",\"postId\":\"2026-02-05-WideSeek-R1-Exploring-Width-Scaling-for-Broad-Information-Seeking-via-Multi-Agent-Reinforcement-Learning\"}],[\"$\",\"section\",null,{\"className\":\"mt-12 border-t border-gray-200 pt-8\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-base font-semibold text-gray-900 mb-4\",\"children\":[\"Review\",\" 의 다른글\"]}],[\"$\",\"ul\",null,{\"className\":\"space-y-2 text-sm\",\"children\":[[\"$\",\"li\",null,{\"className\":\"text-gray-500\",\"children\":[\"이전글\",\" \",[\"$\",\"$La\",null,{\"href\":\"/ai/review/2026-02-05-Vibe-AIGC-A-New-Paradigm-for-Content-Generation-via-Agentic-Orchestration\",\"className\":\"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4\",\"children\":\"[논문리뷰] Vibe AIGC: A New Paradigm for Content Generation via Agentic Orchestration\"}]]}],[\"$\",\"li\",null,{\"className\":\"text-gray-900 font-semibold\",\"children\":[\"현재글 : \",\"[논문리뷰] WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning\"]}],[\"$\",\"li\",null,{\"className\":\"text-gray-500\",\"children\":[\"다음글\",\" \",[\"$\",\"$La\",null,{\"href\":\"/ai/review/2026-02-06-BABE-Biology-Arena-BEnchmark\",\"className\":\"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4\",\"children\":\"[논문리뷰] BABE: Biology Arena BEnchmark\"}]]}]]}]]}]]}]]}]]}]]\n"])</script><script>self.__next_f.push([1,"c:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"[논문리뷰] WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning - secrett2633's blog\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"이 [arXiv]에 게시한 'WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"meta\",\"4\",{\"name\":\"author\",\"content\":\"secrett2633\"}],[\"$\",\"link\",\"5\",{\"rel\":\"manifest\",\"href\":\"/manifest.json\",\"crossOrigin\":\"use-credentials\"}],[\"$\",\"meta\",\"6\",{\"name\":\"keywords\",\"content\":\"Django, Python, DevOps, AI, ML, 블로그, 기술\"}],[\"$\",\"meta\",\"7\",{\"name\":\"creator\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"8\",{\"name\":\"publisher\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"9\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"10\",{\"name\":\"googlebot\",\"content\":\"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1\"}],[\"$\",\"link\",\"11\",{\"rel\":\"canonical\",\"href\":\"https://blog.secrett2633.cloud/ai/review/2026-02-05-WideSeek-R1-Exploring-Width-Scaling-for-Broad-Information-Seeking-via-Multi-Agent-Reinforcement-Learning\"}],[\"$\",\"meta\",\"12\",{\"name\":\"format-detection\",\"content\":\"telephone=no, address=no, email=no\"}],[\"$\",\"meta\",\"13\",{\"property\":\"og:title\",\"content\":\"[논문리뷰] WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning\"}],[\"$\",\"meta\",\"14\",{\"property\":\"og:description\",\"content\":\"이 [arXiv]에 게시한 'WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"meta\",\"15\",{\"property\":\"og:url\",\"content\":\"https://blog.secrett2633.cloud/ai/review/2026-02-05-WideSeek-R1-Exploring-Width-Scaling-for-Broad-Information-Seeking-via-Multi-Agent-Reinforcement-Learning\"}],[\"$\",\"meta\",\"16\",{\"property\":\"og:type\",\"content\":\"article\"}],[\"$\",\"meta\",\"17\",{\"property\":\"article:published_time\",\"content\":\"2026-02-04T15:00:00.000Z\"}],[\"$\",\"meta\",\"18\",{\"property\":\"article:modified_time\",\"content\":\"2026-02-04T15:00:00.000Z\"}],[\"$\",\"meta\",\"19\",{\"property\":\"article:author\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"20\",{\"property\":\"article:section\",\"content\":\"Review\"}],[\"$\",\"meta\",\"21\",{\"property\":\"article:tag\",\"content\":\"Review\"}],[\"$\",\"meta\",\"22\",{\"property\":\"article:tag\",\"content\":\"Multi-Agent Reinforcement Learning\"}],[\"$\",\"meta\",\"23\",{\"property\":\"article:tag\",\"content\":\"Width Scaling\"}],[\"$\",\"meta\",\"24\",{\"property\":\"article:tag\",\"content\":\"Large Language Models\"}],[\"$\",\"meta\",\"25\",{\"property\":\"article:tag\",\"content\":\"Information Seeking\"}],[\"$\",\"meta\",\"26\",{\"property\":\"article:tag\",\"content\":\"Task Decomposition\"}],[\"$\",\"meta\",\"27\",{\"property\":\"article:tag\",\"content\":\"Parallel Execution\"}],[\"$\",\"meta\",\"28\",{\"property\":\"article:tag\",\"content\":\"Lead-Agent-Subagent Framework\"}],[\"$\",\"meta\",\"29\",{\"property\":\"article:tag\",\"content\":\"Orchestration\"}],[\"$\",\"meta\",\"30\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"31\",{\"name\":\"twitter:creator\",\"content\":\"@secrett2633\"}],[\"$\",\"meta\",\"32\",{\"name\":\"twitter:title\",\"content\":\"[논문리뷰] WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning\"}],[\"$\",\"meta\",\"33\",{\"name\":\"twitter:description\",\"content\":\"이 [arXiv]에 게시한 'WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"link\",\"34\",{\"rel\":\"icon\",\"href\":\"/icon.ico?6d9f34d4948640b8\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}],[\"$\",\"meta\",\"35\",{\"name\":\"next-size-adjust\"}]]\n"])</script><script>self.__next_f.push([1,"4:null\n"])</script></body></html>