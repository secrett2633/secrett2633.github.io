3:I[9275,[],""]
5:I[1343,[],""]
6:I[9157,["231","static/chunks/231-ee5764c1002761f9.js","132","static/chunks/132-273e49420772df1e.js","185","static/chunks/app/layout-d443cbc354279241.js"],"default"]
7:I[231,["231","static/chunks/231-ee5764c1002761f9.js","877","static/chunks/app/%5B...slug%5D/page-ef33f0f4c1a350bd.js"],""]
8:I[4080,["231","static/chunks/231-ee5764c1002761f9.js","132","static/chunks/132-273e49420772df1e.js","185","static/chunks/app/layout-d443cbc354279241.js"],""]
4:["slug","ai/review/2025-11-13-MathSE-Improving-Multimodal-Mathematical-Reasoning-via-Self-Evolving-Iterative-Reflection-and-Reward-Guided-Fine-Tuning","c"]
0:["mJI0q5Z-SQWBtT83kG_N7",[[["",{"children":[["slug","ai/review/2025-11-13-MathSE-Improving-Multimodal-Mathematical-Reasoning-via-Self-Evolving-Iterative-Reflection-and-Reward-Guided-Fine-Tuning","c"],{"children":["__PAGE__?{\"slug\":[\"ai\",\"review\",\"2025-11-13-MathSE-Improving-Multimodal-Mathematical-Reasoning-via-Self-Evolving-Iterative-Reflection-and-Reward-Guided-Fine-Tuning\"]}",{}]}]},"$undefined","$undefined",true],["",{"children":[["slug","ai/review/2025-11-13-MathSE-Improving-Multimodal-Mathematical-Reasoning-via-Self-Evolving-Iterative-Reflection-and-Reward-Guided-Fine-Tuning","c"],{"children":["__PAGE__",{},[["$L1","$L2"],null],null]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","$4","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},[["$","html",null,{"lang":"ko","className":"no-js","children":[["$","head",null,{"children":[["$","meta",null,{"name":"msapplication-TileColor","content":"#ffc40d"}],["$","meta",null,{"name":"theme-color","content":"#ffffff"}],["$","link",null,{"rel":"dns-prefetch","href":"https://www.googletagmanager.com"}],["$","link",null,{"rel":"preconnect","href":"https://www.googletagmanager.com","crossOrigin":"anonymous"}],["$","link",null,{"rel":"dns-prefetch","href":"https://giscus.app"}],["$","link",null,{"rel":"preconnect","href":"https://giscus.app","crossOrigin":"anonymous"}],["$","meta",null,{"httpEquiv":"X-Content-Type-Options","content":"nosniff"}],["$","meta",null,{"name":"referrer","content":"strict-origin-when-cross-origin"}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"WebSite\",\"name\":\"secrett2633's blog\",\"url\":\"https://blog.secrett2633.cloud\",\"description\":\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\",\"inLanguage\":\"ko\",\"publisher\":{\"@type\":\"Person\",\"name\":\"secrett2633\",\"url\":\"https://blog.secrett2633.cloud\"}}"}}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"Person\",\"name\":\"secrett2633\",\"url\":\"https://blog.secrett2633.cloud\",\"sameAs\":[\"https://github.com/secrett2633\"]}"}}]]}],["$","body",null,{"className":"__className_f367f3 layout--default","children":[["$","a",null,{"href":"#main-content","className":"sr-only focus:not-sr-only focus:absolute focus:z-50 focus:p-4 focus:bg-white focus:text-blue-600","children":"본문으로 건너뛰기"}],["$","div",null,{"className":"min-h-screen bg-gray-50","children":[["$","$L6",null,{}],["$","main",null,{"id":"main-content","className":"initial-content","children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","div",null,{"className":"min-h-screen flex items-center justify-center bg-gray-50","children":["$","div",null,{"className":"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center","children":[["$","h1",null,{"className":"text-6xl font-bold text-primary-600 mb-4","children":"404"}],["$","h2",null,{"className":"text-2xl font-semibold text-gray-900 mb-4","children":"페이지를 찾을 수 없습니다"}],["$","p",null,{"className":"text-gray-600 mb-8","children":"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다."}],["$","$L7",null,{"href":"/","className":"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors","children":"홈으로 돌아가기"}]]}]}],"notFoundStyles":[],"styles":null}]}],["$","div",null,{"id":"footer","className":"page__footer","children":["$","footer",null,{"className":"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8","children":["$","div",null,{"className":"text-center text-gray-500 text-sm","children":["$","p",null,{"children":["© ",2026," secrett2633. All rights reserved."]}]}]}]}]]}],["$","$L8",null,{"src":"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY","strategy":"afterInteractive"}],["$","$L8",null,{"id":"gtag-init","strategy":"afterInteractive","children":"window.dataLayer = window.dataLayer || [];\n            function gtag(){dataLayer.push(arguments);}\n            gtag('js', new Date());\n            gtag('config', 'G-NE2W3CFPNY');"}]]}]]}],null],[["$","div",null,{"className":"flex items-center justify-center min-h-screen","role":"status","aria-label":"로딩 중","children":[["$","div",null,{"className":"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600"}],["$","span",null,{"className":"sr-only","children":"로딩 중..."}]]}],[],[]]],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/edb8d4ad4fe2f3b0.css","precedence":"next","crossOrigin":"$undefined"}]],[null,"$L9"]]]]]
c:I[646,["231","static/chunks/231-ee5764c1002761f9.js","877","static/chunks/app/%5B...slug%5D/page-ef33f0f4c1a350bd.js"],"default"]
a:T563,{"@context":"https://schema.org","@type":"BlogPosting","headline":"[논문리뷰] MathSE: Improving Multimodal Mathematical Reasoning via Self-Evolving Iterative Reflection and Reward-Guided Fine-Tuning","description":"arXiv에 게시된 'MathSE: Improving Multimodal Mathematical Reasoning via Self-Evolving Iterative Reflection and Reward-Guided Fine-Tuning' 논문에 대한 자세한 리뷰입니다.","url":"https://blog.secrett2633.cloud/ai/review/2025-11-13-MathSE-Improving-Multimodal-Mathematical-Reasoning-via-Self-Evolving-Iterative-Reflection-and-Reward-Guided-Fine-Tuning","datePublished":"2025-11-12T15:00:00.000Z","dateModified":"2025-11-12T15:00:00.000Z","author":{"@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud"},"publisher":{"@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.secrett2633.cloud/ai/review/2025-11-13-MathSE-Improving-Multimodal-Mathematical-Reasoning-via-Self-Evolving-Iterative-Reflection-and-Reward-Guided-Fine-Tuning"},"image":"https://blog.secrett2633.cloud/og-default.png","isAccessibleForFree":true,"inLanguage":"ko","wordCount":261,"articleSection":"Review","keywords":"Review, Multimodal Reasoning, Mathematical Problem Solving, Self-Evolving, Iterative Fine-Tuning, Reward Models, Reflection, Large Language Models (LLMs)"}b:Td22,<blockquote>
<p><strong>링크:</strong> <a href="https://arxiv.org/abs/2511.06805" target="_blank" rel="noopener noreferrer">논문 PDF로 바로 열기</a></p>
</blockquote>
<p><strong>저자:</strong> Jinhao Chen, Zhen Yang, Jianxin Shi, Tianyu Wo, Jie Tang</p>
<h2 id="핵심-연구-목표"><a href="#핵심-연구-목표">핵심 연구 목표</a></h2>
<p>본 연구는 멀티모달 대규모 언어 모델(MLLM)이 복잡한 수학 문제 해결과 같은 추론 태스크에서 겪는 어려움을 극복하는 것을 목표로 합니다. 특히, 기존의 정적인 교사 모델 유래 데이터셋에 의존하는 방식이 모델의 새로운 문제 적응력과 견고한 일반화 능력을 제한한다는 한계를 해결하고자 합니다.</p>
<h2 id="핵심-방법론"><a href="#핵심-방법론">핵심 방법론</a></h2>
<p><strong>MathSE</strong> 는 <strong>반복적 미세 조정(iterative fine-tuning)</strong> , <strong>보상 기반 피드백(reward-guided feedback)</strong> , <strong>반성(reflection)</strong> 의 순환을 통해 MLLM의 수학적 추론 능력을 지속적으로 향상시키는 프레임워크입니다. 초기 <strong>GPT-4o</strong> 로 증류(distilled)된 데이터로 기본 모델을 미세 조정한 후, <strong>Outcome Reward Model (ORM)</strong> 이 추론 경로의 정확성을 평가하고 오류 단계 및 상세 분석을 제공합니다. 모델은 ORM 피드백을 바탕으로 자신의 실수를 <strong>반성</strong> 하고 수정하여 개선된 추론 경로를 생성하며, 이는 다시 훈련 데이터에 통합되어 모델을 반복적으로 재훈련합니다.</p>
<h2 id="주요-결과"><a href="#주요-결과">주요 결과</a></h2>
<p><strong>MathSE</strong> 는 <strong>MathVista</strong> , <strong>MathVL-test</strong> , <strong>MathVerse</strong> , <strong>Math-Vision</strong> 등 주요 멀티모달 수학 추론 벤치마크에서 백본 모델 대비 상당한 성능 향상을 입증했습니다. 특히 <strong>MathVL-test</strong> 에서 <strong>CogVLM2</strong> 의 정확도를 30.85%에서 <strong>64.70%</strong> 로, <strong>Qwen2-VL-7B</strong> 는 40.60%에서 <strong>57.00%</strong> 로, <strong>InternVL2.5-8B</strong> 는 33.20%에서 <strong>65.13%</strong> 로 향상시켰습니다. 이는 선두 오픈소스 모델인 <strong>QVQ</strong> 의 성능을 능가하는 결과입니다.</p>
<h2 id="ai-실무자를-위한-시사점"><a href="#ai-실무자를-위한-시사점">AI 실무자를 위한 시사점</a></h2>
<p>이 연구는 <strong>반복적인 학습 및 피드백 루프</strong> 가 MLLM의 복잡한 추론 능력을 효과적으로 개선할 수 있음을 보여줍니다. 정적 데이터셋 의존성에서 벗어나 <strong>동적이고 적응적인 학습 패러다임</strong> 의 중요성을 강조하며, <strong>ORM과 같은 정교한 보상 모델</strong> 은 단순 정답 평가를 넘어 기술적인 오류 진단 및 수정에 필수적임을 시사합니다. <strong>MathSE</strong> 프레임워크는 수학적 추론 외 다른 복잡한 멀티모달 또는 일반 추론 태스크에도 확장될 잠재력을 가지고 있어, AI 모델의 신뢰성과 투명성 향상에 기여할 수 있습니다.</p>
<blockquote>
<p>⚠️ <strong>알림:</strong> 이 리뷰는 AI로 작성되었습니다.</p>
</blockquote>
2:[["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"$a"}}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"BreadcrumbList\",\"itemListElement\":[{\"@type\":\"ListItem\",\"position\":1,\"name\":\"홈\",\"item\":\"https://blog.secrett2633.cloud/\"},{\"@type\":\"ListItem\",\"position\":2,\"name\":\"Review\",\"item\":\"https://blog.secrett2633.cloud/ai/review\"},{\"@type\":\"ListItem\",\"position\":3,\"name\":\"[논문리뷰] MathSE: Improving Multimodal Mathematical Reasoning via Self-Evolving Iterative Reflection and Reward-Guided Fine-Tuning\",\"item\":\"https://blog.secrett2633.cloud/ai/review/2025-11-13-MathSE-Improving-Multimodal-Mathematical-Reasoning-via-Self-Evolving-Iterative-Reflection-and-Reward-Guided-Fine-Tuning\"}]}"}}],["$","div",null,{"className":"space-y-6","children":["$","div",null,{"className":"flex flex-col lg:flex-row gap-8","children":[["$","aside",null,{"className":"lg:w-64 xl:w-72 order-1 lg:order-none","children":["$","div",null,{"className":"sidebar sticky","children":["$","nav",null,{"className":"space-y-4","aria-label":"카테고리 네비게이션","children":[["$","div","Backend",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"Backend"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Django",{"children":["$","$L7",null,{"href":"/backend/django","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Django"," (",6,")"]}]}],["$","li","Logging",{"children":["$","$L7",null,{"href":"/backend/logging","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Logging"," (",1,")"]}]}]]}]]}],["$","div","Python",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"Python"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","PEP",{"children":["$","$L7",null,{"href":"/python/pep","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["PEP"," (",650,")"]}]}]]}]]}],["$","div","AI/ML",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"AI/ML"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","LLM",{"children":["$","$L7",null,{"href":"/ai/llm","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["LLM"," (",1,")"]}]}],["$","li","Review",{"children":["$","$L7",null,{"href":"/ai/review","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Review"," (",2741,")"]}]}]]}]]}],["$","div","DevOps",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"DevOps"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Nginx",{"children":["$","$L7",null,{"href":"/devops/nginx","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Nginx"," (",1,")"]}]}],["$","li","Docker",{"children":["$","$L7",null,{"href":"/devops/docker","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Docker"," (",1,")"]}]}],["$","li","SafeLine",{"children":["$","$L7",null,{"href":"/devops/safeline","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["SafeLine"," (",1,")"]}]}],["$","li","Jenkins",{"children":["$","$L7",null,{"href":"/devops/jenkins","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Jenkins"," (",3,")"]}]}],["$","li","GitHub Actions",{"children":["$","$L7",null,{"href":"/devops/github-actions","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["GitHub Actions"," (",1,")"]}]}],["$","li","AWS",{"children":["$","$L7",null,{"href":"/devops/aws","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["AWS"," (",1,")"]}]}]]}]]}],["$","div","etc",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"etc"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Me",{"children":["$","$L7",null,{"href":"/etc/me","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Me"," (",3,")"]}]}],["$","li","Chrome Extension",{"children":["$","$L7",null,{"href":"/etc/chrome-extension","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Chrome Extension"," (",1,")"]}]}]]}]]}]]}]}]}],["$","div",null,{"className":"flex-1","children":[["$","nav",null,{"aria-label":"breadcrumb","className":"text-sm text-gray-500 mb-4","children":["$","ol",null,{"className":"flex flex-wrap items-center gap-1","children":[["$","li",null,{"children":["$","$L7",null,{"href":"/","className":"hover:text-gray-700","children":"홈"}]}],[["$","li","/ai/review",{"className":"flex items-center gap-1","children":[["$","span",null,{"aria-hidden":"true","children":"/"}],["$","$L7",null,{"href":"/ai/review","className":"hover:text-gray-700","children":"Review"}]]}],["$","li","/ai/review/2025-11-13-MathSE-Improving-Multimodal-Mathematical-Reasoning-via-Self-Evolving-Iterative-Reflection-and-Reward-Guided-Fine-Tuning",{"className":"flex items-center gap-1","children":[["$","span",null,{"aria-hidden":"true","children":"/"}],["$","span",null,{"className":"text-gray-900","aria-current":"page","children":"[논문리뷰] MathSE: Improving Multimodal Mathematical Reasoning via Self-Evolving Iterative Reflection and Reward-Guided Fine-Tuning"}]]}]]]}]}],["$","article",null,{"className":"page","children":[["$","header",null,{"className":"mb-8","children":[["$","h1",null,{"className":"page__title","children":"[논문리뷰] MathSE: Improving Multimodal Mathematical Reasoning via Self-Evolving Iterative Reflection and Reward-Guided Fine-Tuning"}],["$","div",null,{"className":"page__meta","children":[["$","time",null,{"dateTime":"2025-11-13 00:00:00+0900+0900","children":"2025년 11월 13일"}],["$","time",null,{"className":"ml-4","dateTime":"2025-11-12T15:00:00.000Z","children":["수정: ","2025년 11월 13일"]}]]}]]}],["$","div",null,{"className":"page__content","children":["$","div",null,{"dangerouslySetInnerHTML":{"__html":"$b"}}]}],["$","footer",null,{"className":"page__meta mt-8","children":["$","div",null,{"className":"page__taxonomy","children":[["$","span",null,{"className":"text-sm font-medium text-gray-900 mb-2 block","children":"태그"}],[["$","$L7","Review",{"href":"/tags/Review","className":"page__taxonomy-item","children":["#","Review"]}],["$","$L7","Multimodal Reasoning",{"href":"/tags/Multimodal%20Reasoning","className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","$L7","Mathematical Problem Solving",{"href":"/tags/Mathematical%20Problem%20Solving","className":"page__taxonomy-item","children":["#","Mathematical Problem Solving"]}],["$","$L7","Self-Evolving",{"href":"/tags/Self-Evolving","className":"page__taxonomy-item","children":["#","Self-Evolving"]}],["$","$L7","Iterative Fine-Tuning",{"href":"/tags/Iterative%20Fine-Tuning","className":"page__taxonomy-item","children":["#","Iterative Fine-Tuning"]}],["$","$L7","Reward Models",{"href":"/tags/Reward%20Models","className":"page__taxonomy-item","children":["#","Reward Models"]}],["$","$L7","Reflection",{"href":"/tags/Reflection","className":"page__taxonomy-item","children":["#","Reflection"]}],["$","$L7","Large Language Models (LLMs)",{"href":"/tags/Large%20Language%20Models%20(LLMs)","className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}]]]}]}],["$","$Lc",null,{"postPermalink":"/ai/review/2025-11-13-MathSE-Improving-Multimodal-Mathematical-Reasoning-via-Self-Evolving-Iterative-Reflection-and-Reward-Guided-Fine-Tuning","postId":"2025-11-13-MathSE-Improving-Multimodal-Mathematical-Reasoning-via-Self-Evolving-Iterative-Reflection-and-Reward-Guided-Fine-Tuning"}],["$","section",null,{"className":"mt-12 border-t border-gray-200 pt-8","children":[["$","h3",null,{"className":"text-base font-semibold text-gray-900 mb-4","children":["Review"," 의 다른글"]}],["$","ul",null,{"className":"space-y-2 text-sm","children":[["$","li",null,{"className":"text-gray-500","children":["이전글"," ",["$","$L7",null,{"href":"/ai/review/2025-11-13-MADD-Multi-Agent-Drug-Discovery-Orchestra","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] MADD: Multi-Agent Drug Discovery Orchestra"}]]}],["$","li",null,{"className":"text-gray-900 font-semibold","children":["현재글 : ","[논문리뷰] MathSE: Improving Multimodal Mathematical Reasoning via Self-Evolving Iterative Reflection and Reward-Guided Fine-Tuning"]}],["$","li",null,{"className":"text-gray-500","children":["다음글"," ",["$","$L7",null,{"href":"/ai/review/2025-11-13-Motif-2-12-7B-technical-report","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] Motif 2 12.7B technical report"}]]}]]}]]}]]}]]}]]}]}]]
9:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"[논문리뷰] MathSE: Improving Multimodal Mathematical Reasoning via Self-Evolving Iterative Reflection and Reward-Guided Fine-Tuning - secrett2633's blog"}],["$","meta","3",{"name":"description","content":"arXiv에 게시된 'MathSE: Improving Multimodal Mathematical Reasoning via Self-Evolving Iterative Reflection and Reward-Guided Fine-Tuning' 논문에 대한 자세한 리뷰입니다."}],["$","meta","4",{"name":"author","content":"secrett2633"}],["$","link","5",{"rel":"manifest","href":"/manifest.json","crossOrigin":"use-credentials"}],["$","meta","6",{"name":"keywords","content":"Django, Python, DevOps, AI, ML, 블로그, 기술"}],["$","meta","7",{"name":"creator","content":"secrett2633"}],["$","meta","8",{"name":"publisher","content":"secrett2633"}],["$","meta","9",{"name":"robots","content":"index, follow"}],["$","meta","10",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","11",{"rel":"canonical","href":"https://blog.secrett2633.cloud/ai/review/2025-11-13-MathSE-Improving-Multimodal-Mathematical-Reasoning-via-Self-Evolving-Iterative-Reflection-and-Reward-Guided-Fine-Tuning"}],["$","meta","12",{"name":"format-detection","content":"telephone=no, address=no, email=no"}],["$","meta","13",{"property":"og:title","content":"[논문리뷰] MathSE: Improving Multimodal Mathematical Reasoning via Self-Evolving Iterative Reflection and Reward-Guided Fine-Tuning"}],["$","meta","14",{"property":"og:description","content":"arXiv에 게시된 'MathSE: Improving Multimodal Mathematical Reasoning via Self-Evolving Iterative Reflection and Reward-Guided Fine-Tuning' 논문에 대한 자세한 리뷰입니다."}],["$","meta","15",{"property":"og:url","content":"https://blog.secrett2633.cloud/ai/review/2025-11-13-MathSE-Improving-Multimodal-Mathematical-Reasoning-via-Self-Evolving-Iterative-Reflection-and-Reward-Guided-Fine-Tuning"}],["$","meta","16",{"property":"og:type","content":"article"}],["$","meta","17",{"property":"article:published_time","content":"2025-11-12T15:00:00.000Z"}],["$","meta","18",{"property":"article:modified_time","content":"2025-11-12T15:00:00.000Z"}],["$","meta","19",{"property":"article:author","content":"secrett2633"}],["$","meta","20",{"property":"article:section","content":"Review"}],["$","meta","21",{"property":"article:tag","content":"Review"}],["$","meta","22",{"property":"article:tag","content":"Multimodal Reasoning"}],["$","meta","23",{"property":"article:tag","content":"Mathematical Problem Solving"}],["$","meta","24",{"property":"article:tag","content":"Self-Evolving"}],["$","meta","25",{"property":"article:tag","content":"Iterative Fine-Tuning"}],["$","meta","26",{"property":"article:tag","content":"Reward Models"}],["$","meta","27",{"property":"article:tag","content":"Reflection"}],["$","meta","28",{"property":"article:tag","content":"Large Language Models (LLMs)"}],["$","meta","29",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","30",{"name":"twitter:creator","content":"@secrett2633"}],["$","meta","31",{"name":"twitter:title","content":"[논문리뷰] MathSE: Improving Multimodal Mathematical Reasoning via Self-Evolving Iterative Reflection and Reward-Guided Fine-Tuning"}],["$","meta","32",{"name":"twitter:description","content":"arXiv에 게시된 'MathSE: Improving Multimodal Mathematical Reasoning via Self-Evolving Iterative Reflection and Reward-Guided Fine-Tuning' 논문에 대한 자세한 리뷰입니다."}],["$","link","33",{"rel":"icon","href":"/icon.ico?6d9f34d4948640b8","type":"image/x-icon","sizes":"16x16"}],["$","meta","34",{"name":"next-size-adjust"}]]
1:null
