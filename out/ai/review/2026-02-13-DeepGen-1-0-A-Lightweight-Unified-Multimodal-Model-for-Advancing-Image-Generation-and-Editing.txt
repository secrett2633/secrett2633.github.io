3:I[9275,[],""]
5:I[1343,[],""]
6:I[9157,["231","static/chunks/231-467e37449c5a68fc.js","185","static/chunks/app/layout-53ec9cbf619543e1.js"],"default"]
7:I[231,["231","static/chunks/231-467e37449c5a68fc.js","877","static/chunks/app/%5B...slug%5D/page-80e07cee06d17a0b.js"],""]
4:["slug","ai/review/2026-02-13-DeepGen-1-0-A-Lightweight-Unified-Multimodal-Model-for-Advancing-Image-Generation-and-Editing","c"]
0:["_3-KrKKQh7tcSoXiYwQMB",[[["",{"children":[["slug","ai/review/2026-02-13-DeepGen-1-0-A-Lightweight-Unified-Multimodal-Model-for-Advancing-Image-Generation-and-Editing","c"],{"children":["__PAGE__?{\"slug\":[\"ai\",\"review\",\"2026-02-13-DeepGen-1-0-A-Lightweight-Unified-Multimodal-Model-for-Advancing-Image-Generation-and-Editing\"]}",{}]}]},"$undefined","$undefined",true],["",{"children":[["slug","ai/review/2026-02-13-DeepGen-1-0-A-Lightweight-Unified-Multimodal-Model-for-Advancing-Image-Generation-and-Editing","c"],{"children":["__PAGE__",{},[["$L1","$L2"],null],null]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","$4","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},[["$","html",null,{"lang":"ko","className":"no-js","children":[["$","head",null,{"children":[["$","meta",null,{"name":"msapplication-TileColor","content":"#ffc40d"}],["$","meta",null,{"name":"theme-color","content":"#ffffff"}],["$","script",null,{"async":true,"src":"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY"}],["$","script",null,{"dangerouslySetInnerHTML":{"__html":"\n              window.dataLayer = window.dataLayer || [];\n              function gtag(){dataLayer.push(arguments);}\n              gtag('js', new Date());\n              gtag('config', 'G-NE2W3CFPNY');\n            "}}]]}],["$","body",null,{"className":"__className_f367f3 layout--default","children":["$","div",null,{"className":"min-h-screen bg-gray-50","children":[["$","$L6",null,{}],["$","main",null,{"className":"initial-content","children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","div",null,{"className":"min-h-screen flex items-center justify-center bg-gray-50","children":["$","div",null,{"className":"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center","children":[["$","h1",null,{"className":"text-6xl font-bold text-primary-600 mb-4","children":"404"}],["$","h2",null,{"className":"text-2xl font-semibold text-gray-900 mb-4","children":"페이지를 찾을 수 없습니다"}],["$","p",null,{"className":"text-gray-600 mb-8","children":"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다."}],["$","$L7",null,{"href":"/","className":"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors","children":"홈으로 돌아가기"}]]}]}],"notFoundStyles":[],"styles":null}]}],["$","div",null,{"id":"footer","className":"page__footer","children":["$","footer",null,{"className":"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8","children":["$","div",null,{"className":"text-center text-gray-500 text-sm","children":["$","p",null,{"children":"© 2025 secrett2633. All rights reserved."}]}]}]}]]}]}]]}],null],[["$","div",null,{"className":"flex items-center justify-center min-h-screen","children":["$","div",null,{"className":"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600"}]}],[],[]]],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/d6cea809dcbae606.css","precedence":"next","crossOrigin":"$undefined"}]],[null,"$L8"]]]]]
a:I[646,["231","static/chunks/231-467e37449c5a68fc.js","877","static/chunks/app/%5B...slug%5D/page-80e07cee06d17a0b.js"],"default"]
9:Tc46,<blockquote>
<p><strong>링크:</strong> <a href="https://arxiv.org/abs/2602.12205">논문 PDF로 바로 열기</a></p>
</blockquote>
<p><strong>저자:</strong> Dianyi Wang, Ruihang Li, Feng Han, Chaofan Ma, Wei Song, Siyuan Wang, Yibin Wang, Yi Xin, Hongjian Liu, Zhixiong Zhang, Shengyuan Ding, Tianhang Wang, Zhenglin Cheng, Tao Lin, Cheng Jin, Kaicheng Yu, Jingjing Chen, Wenjie Wang, Zhongyu Wei, Jiaqi Wang</p>
<h2>핵심 연구 목표</h2>
<p>본 논문은 현재 대규모(~10B 이상) 파라미터를 요구하는 멀티모달 이미지 생성 및 편집 모델의 높은 훈련 비용과 배포 한계를 극복하는 것을 목표로 합니다. <strong>경량의 5B 파라미터 모델(DeepGen 1.0)</strong> 을 통해 훨씬 큰 모델과 동등하거나 이를 능가하는 포괄적인 생성 및 편집 능력을 달성하고자 합니다.</p>
<h2>핵심 방법론</h2>
<p>DeepGen 1.0은 <strong>3B VLM(Qwen-2.5-VL)</strong> 과 <strong>2B DiT(SD3.5-Medium)</strong> 로 구성된 <strong>VLM-DiT 아키텍처</strong> 를 사용합니다. 핵심 기술인 <strong>Stacked Channel Bridging (SCB)</strong> 은 VLM의 여러 계층에서 계층적 특징을 추출하고, <strong>학습 가능한 "think tokens"</strong> 와 융합하여 DiT에 풍부한 추론 정보를 제공합니다. 훈련은 <strong>정렬 사전 훈련</strong> , <strong>공동 지도 미세 조정 (SFT)</strong> , 그리고 <strong>MR-GRPO를 사용한 강화 학습 (RL)</strong> 의 세 단계로 진행되며, 보조 지도 확산 손실을 통해 능력 저하를 방지합니다.</p>
<h2>주요 결과</h2>
<p>DeepGen 1.0은 <strong>총 5B 파라미터</strong> 로, 자신보다 <strong>3배에서 16배 큰 모델과 경쟁하거나 능가하는 성능</strong> 을 보였습니다. 특히, DPG-Bench에서 <strong>87.90점</strong> 을 달성하여 80B 규모의 <strong>HunyuanImage 3.0 (86.10점)</strong> 을 넘어섰고, WISE 추론 태스크에서는 <strong>0.73점</strong> 으로 <strong>HunyuanImage 3.0 (0.57점)</strong> 대비 <strong>28% 높은 성능</strong> 을 기록했습니다. UniREditBench 편집 태스크에서는 <strong>77.5점</strong> 으로 전용 모델인 <strong>Qwen-Image-Edit (56.5점)</strong> 를 <strong>37% 이상</strong> 앞섰으며, 전체 훈련에 <strong>약 5천만 개의 샘플</strong> 만을 사용했습니다.</p>
<h2>AI 실무자를 위한 시사점</h2>
<p>본 연구는 대규모 파라미터 없이도 정교한 멀티모달 AI 모델을 구축할 수 있음을 입증하여, AI 개발의 <strong>접근성과 지속 가능성</strong> 을 크게 향상시킬 수 있습니다. 공개된 <strong>DeepGen 1.0</strong> 은 <strong>소비자 등급 하드웨어</strong> 에서도 고급 이미지 생성 및 편집 작업을 수행할 수 있는 효율적인 대안을 제공하며, <strong>SCB</strong> 와 <strong>"think tokens"</strong> 는 VLM 기반 모델의 추론 능력과 미세 제어 능력을 강화하는 실용적인 기법으로 활용될 수 있습니다.</p>
<blockquote>
<p>⚠️ <strong>알림:</strong> 이 리뷰는 AI로 작성되었습니다.</p>
</blockquote>
2:["$","div",null,{"className":"flex flex-col lg:flex-row gap-8","children":[["$","aside",null,{"className":"lg:w-64 xl:w-72 order-1 lg:order-none","children":["$","div",null,{"className":"sidebar sticky","children":["$","nav",null,{"className":"space-y-4","children":[["$","div","Backend",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"Backend"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Django",{"children":["$","a",null,{"href":"/backend/django","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Django"," (",6,")"]}]}],["$","li","Logging",{"children":["$","a",null,{"href":"/backend/logging","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Logging"," (",1,")"]}]}]]}]]}],["$","div","Python",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"Python"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","PEP",{"children":["$","a",null,{"href":"/python/pep","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["PEP"," (",650,")"]}]}]]}]]}],["$","div","AI/ML",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"AI/ML"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","LLM",{"children":["$","a",null,{"href":"/ai/llm","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["LLM"," (",1,")"]}]}],["$","li","Review",{"children":["$","a",null,{"href":"/ai/review","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Review"," (",2728,")"]}]}]]}]]}],["$","div","DevOps",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"DevOps"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Nginx",{"children":["$","a",null,{"href":"/devops/nginx","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Nginx"," (",1,")"]}]}],["$","li","Docker",{"children":["$","a",null,{"href":"/devops/docker","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Docker"," (",1,")"]}]}],["$","li","SafeLine",{"children":["$","a",null,{"href":"/devops/safeline","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["SafeLine"," (",1,")"]}]}],["$","li","Jenkins",{"children":["$","a",null,{"href":"/devops/jenkins","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Jenkins"," (",3,")"]}]}],["$","li","GitHub Actions",{"children":["$","a",null,{"href":"/devops/github-actions","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["GitHub Actions"," (",1,")"]}]}],["$","li","AWS",{"children":["$","a",null,{"href":"/devops/aws","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["AWS"," (",1,")"]}]}]]}]]}],["$","div","etc",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"etc"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Me",{"children":["$","a",null,{"href":"/etc/me","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Me"," (",3,")"]}]}],["$","li","Chrome Extension",{"children":["$","a",null,{"href":"/etc/chrome-extension","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Chrome Extension"," (",1,")"]}]}]]}]]}]]}]}]}],["$","main",null,{"className":"flex-1","children":["$","article",null,{"className":"page","children":[["$","header",null,{"className":"mb-8","children":[["$","h1",null,{"className":"page__title","children":"[논문리뷰] DeepGen 1.0: A Lightweight Unified Multimodal Model for Advancing Image Generation and Editing"}],["$","div",null,{"className":"page__meta","children":[["$","time",null,{"dateTime":"2026-02-13 00:00:00+0900+0900","children":"2026년 2월 13일"}],["$","span",null,{"className":"ml-4","children":["수정: ","2026년 2월 13일"]}]]}]]}],["$","div",null,{"className":"page__content","children":["$","div",null,{"dangerouslySetInnerHTML":{"__html":"$9"}}]}],["$","footer",null,{"className":"page__meta mt-8","children":["$","div",null,{"className":"page__taxonomy","children":[["$","h4",null,{"className":"text-sm font-medium text-gray-900 mb-2","children":"태그"}],[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Model",{"className":"page__taxonomy-item","children":["#","Multimodal Model"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","VLM-DiT Architecture",{"className":"page__taxonomy-item","children":["#","VLM-DiT Architecture"]}],["$","span","Stacked Channel Bridging",{"className":"page__taxonomy-item","children":["#","Stacked Channel Bridging"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Lightweight Models",{"className":"page__taxonomy-item","children":["#","Lightweight Models"]}]]]}]}],["$","$La",null,{"postPermalink":"/ai/review/2026-02-13-DeepGen-1-0-A-Lightweight-Unified-Multimodal-Model-for-Advancing-Image-Generation-and-Editing","postId":"2026-02-13-DeepGen-1-0-A-Lightweight-Unified-Multimodal-Model-for-Advancing-Image-Generation-and-Editing"}],["$","section",null,{"className":"mt-12 border-t border-gray-200 pt-8","children":[["$","h3",null,{"className":"text-base font-semibold text-gray-900 mb-4","children":["Review"," 의 다른글"]}],["$","ul",null,{"className":"space-y-2 text-sm","children":[["$","li",null,{"className":"text-gray-500","children":["이전글"," ",["$","$L7",null,{"href":"/ai/review/2026-02-13-Composition-RL-Compose-Your-Verifiable-Prompts-for-Reinforcement-Learning-of-Large-Language-Models","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] Composition-RL: Compose Your Verifiable Prompts for Reinforcement Learning of Large Language Models"}]]}],["$","li",null,{"className":"text-gray-900 font-semibold","children":["현재글 : ","[논문리뷰] DeepGen 1.0: A Lightweight Unified Multimodal Model for Advancing Image Generation and Editing"]}],["$","li",null,{"className":"text-gray-500","children":["다음글"," ",["$","$L7",null,{"href":"/ai/review/2026-02-13-DeepSight-An-All-in-One-LM-Safety-Toolkit","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] DeepSight: An All-in-One LM Safety Toolkit"}]]}]]}]]}]]}]}]]}]
8:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"[논문리뷰] DeepGen 1.0: A Lightweight Unified Multimodal Model for Advancing Image Generation and Editing - secrett2633's blog"}],["$","meta","3",{"name":"description","content":"이 [arXiv]에 게시한 'DeepGen 1.0: A Lightweight Unified Multimodal Model for Advancing Image Generation and Editing' 논문에 대한 자세한 리뷰입니다."}],["$","meta","4",{"name":"author","content":"secrett2633"}],["$","meta","5",{"name":"keywords","content":"Django, Python, DevOps, AI, ML, 블로그, 기술"}],["$","meta","6",{"name":"creator","content":"secrett2633"}],["$","meta","7",{"name":"publisher","content":"secrett2633"}],["$","meta","8",{"name":"robots","content":"index, follow"}],["$","meta","9",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","10",{"rel":"canonical","href":"https://blog.secrett2633.cloud/ai/review/2026-02-13-DeepGen-1-0-A-Lightweight-Unified-Multimodal-Model-for-Advancing-Image-Generation-and-Editing"}],["$","meta","11",{"name":"format-detection","content":"telephone=no, address=no, email=no"}],["$","meta","12",{"property":"og:title","content":"[논문리뷰] DeepGen 1.0: A Lightweight Unified Multimodal Model for Advancing Image Generation and Editing"}],["$","meta","13",{"property":"og:description","content":"이 [arXiv]에 게시한 'DeepGen 1.0: A Lightweight Unified Multimodal Model for Advancing Image Generation and Editing' 논문에 대한 자세한 리뷰입니다."}],["$","meta","14",{"property":"og:url","content":"https://blog.secrett2633.cloud/ai/review/2026-02-13-DeepGen-1-0-A-Lightweight-Unified-Multimodal-Model-for-Advancing-Image-Generation-and-Editing"}],["$","meta","15",{"property":"og:type","content":"article"}],["$","meta","16",{"name":"twitter:card","content":"summary"}],["$","meta","17",{"name":"twitter:title","content":"[논문리뷰] DeepGen 1.0: A Lightweight Unified Multimodal Model for Advancing Image Generation and Editing"}],["$","meta","18",{"name":"twitter:description","content":"이 [arXiv]에 게시한 'DeepGen 1.0: A Lightweight Unified Multimodal Model for Advancing Image Generation and Editing' 논문에 대한 자세한 리뷰입니다."}],["$","link","19",{"rel":"icon","href":"/icon.ico?6d9f34d4948640b8","type":"image/x-icon","sizes":"16x16"}]]
1:null
