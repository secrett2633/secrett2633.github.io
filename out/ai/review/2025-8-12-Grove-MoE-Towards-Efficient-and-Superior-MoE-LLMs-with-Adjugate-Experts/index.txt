3:I[9275,[],""]
5:I[1343,[],""]
6:I[9157,["231","static/chunks/231-c27e618569e042bc.js","157","static/chunks/157-66db9680a8c2215d.js","185","static/chunks/app/layout-b06e577e11976c7d.js"],"default"]
7:I[231,["231","static/chunks/231-c27e618569e042bc.js","931","static/chunks/app/page-d94f9df6fcdd5a21.js"],""]
4:["slug","ai/review/2025-8-12-Grove-MoE-Towards-Efficient-and-Superior-MoE-LLMs-with-Adjugate-Experts","c"]
0:["nzohOLWTNWtwOpdfo2_Ao",[[["",{"children":[["slug","ai/review/2025-8-12-Grove-MoE-Towards-Efficient-and-Superior-MoE-LLMs-with-Adjugate-Experts","c"],{"children":["__PAGE__?{\"slug\":[\"ai\",\"review\",\"2025-8-12-Grove-MoE-Towards-Efficient-and-Superior-MoE-LLMs-with-Adjugate-Experts\"]}",{}]}]},"$undefined","$undefined",true],["",{"children":[["slug","ai/review/2025-8-12-Grove-MoE-Towards-Efficient-and-Superior-MoE-LLMs-with-Adjugate-Experts","c"],{"children":["__PAGE__",{},[["$L1","$L2"],null],null]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","$4","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},[["$","html",null,{"lang":"ko","className":"no-js","children":[["$","head",null,{"children":[["$","meta",null,{"name":"msapplication-TileColor","content":"#ffc40d"}],["$","meta",null,{"name":"theme-color","content":"#ffffff"}],["$","script",null,{"async":true,"src":"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY"}],["$","script",null,{"dangerouslySetInnerHTML":{"__html":"\n              window.dataLayer = window.dataLayer || [];\n              function gtag(){dataLayer.push(arguments);}\n              gtag('js', new Date());\n              gtag('config', 'G-NE2W3CFPNY');\n            "}}]]}],["$","body",null,{"className":"__className_f367f3 layout--default","children":["$","div",null,{"className":"min-h-screen bg-gray-50","children":[["$","$L6",null,{}],["$","main",null,{"className":"initial-content","children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","div",null,{"className":"min-h-screen flex items-center justify-center bg-gray-50","children":["$","div",null,{"className":"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center","children":[["$","h1",null,{"className":"text-6xl font-bold text-primary-600 mb-4","children":"404"}],["$","h2",null,{"className":"text-2xl font-semibold text-gray-900 mb-4","children":"페이지를 찾을 수 없습니다"}],["$","p",null,{"className":"text-gray-600 mb-8","children":"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다."}],["$","$L7",null,{"href":"/","className":"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors","children":"홈으로 돌아가기"}]]}]}],"notFoundStyles":[],"styles":null}]}],["$","div",null,{"id":"footer","className":"page__footer","children":["$","footer",null,{"className":"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8","children":["$","div",null,{"className":"text-center text-gray-500 text-sm","children":["$","p",null,{"children":"© 2025 secrett2633. All rights reserved."}]}]}]}]]}]}]]}],null],[["$","div",null,{"className":"flex items-center justify-center min-h-screen","children":["$","div",null,{"className":"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600"}]}],[],[]]],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/edf391eeca43d999.css","precedence":"next","crossOrigin":"$undefined"}]],[null,"$L8"]]]]]
9:Tc80,<blockquote>
<p><strong>링크:</strong> <a href="https://arxiv.org/abs/2508.07785">논문 PDF로 바로 열기</a></p>
</blockquote>
<p><strong>저자:</strong> Tieyuan Chen, Zhanchao Zhou, Xiaodong Chen, Haoxing Chen, Haoyuan Wu</p>
<h2>핵심 연구 목표</h2>
<p>본 논문은 기존 <strong>MoE (Mixture of Experts)</strong> LLM의 한계인 고정된 파라미터 활성화와 이로 인한 비효율적인 계산 문제를 해결하는 것을 목표로 합니다. 특히, 입력 복잡도에 관계없이 균일한 크기의 전문가를 활성화하는 방식의 비효율성을 개선하여, 모델 용량을 확장하면서도 연산 오버헤드를 관리 가능한 수준으로 유지하는 새로운 <strong>MoE 아키텍처</strong> 를 제안합니다.</p>
<h2>핵심 방법론</h2>
<p>본 연구는 <strong>big.LITTLE CPU 아키텍처</strong> 에서 영감을 받아, 크기가 다른 전문가들을 통합하는 <strong>Grove MoE 아키텍처</strong> 를 제안합니다. 이 아키텍처는 전문가들을 그룹으로 나누고, 각 그룹에 <strong>adjugate expert</strong> 를 도입하여, 여러 활성화된 전문가가 동일 그룹에 속할 경우 공유되는 adjugate expert는 한 번만 계산되도록 <strong>동적 활성화 메커니즘</strong> 을 구현합니다. 또한, <strong>Qwen3-30B-A3B-Base 모델</strong> 을 기반으로 <strong>업사이클링 전략</strong> 을 통해 <strong>GroveMoE-Base</strong> 및 <strong>GroveMoE-Inst</strong> 모델을 개발했으며, <strong>무손실 부하 균형 전략</strong> 을 적용하여 전문가 활용의 효율성을 높였습니다.</p>
<h2>주요 결과</h2>
<p><strong>GroveMoE</strong> 모델은 토큰 복잡도에 따라 동적으로 <strong>3.14–3.28B</strong> 파라미터를 활성화하여, 유사하거나 더 큰 규모의 <strong>SOTA 오픈소스 LLM</strong> 에 필적하는 성능을 달성했습니다 (Figure 1). 특히 <strong>GroveMoE-Inst</strong> 는 다양한 벤치마크에서 기존 모델들을 능가하는 성능을 보였으며 (Table 4), <strong>GroveMoE-Base</strong> 는 <strong>Qwen3-30B-A3B-Base</strong> 보다 우수한 성능을 입증했습니다 (Figure 4). <strong>g=64</strong> 그룹 구성 시 약 <strong>5%</strong> 의 계산 절감 효과를 보였으며, <strong>g=16</strong> 구성에서는 최대 <strong>20%</strong> 까지 절감되었습니다.</p>
<h2>AI 실무자를 위한 시사점</h2>
<p><strong>Grove MoE 아키텍처</strong> 는 효율적인 <strong>LLM</strong> 구축을 위한 새로운 패러다임을 제시하며, 제한된 연산 자원 내에서 모델 용량을 확장하려는 <strong>AI 엔지니어</strong> 에게 유용합니다. 특히, <strong>업사이클링 전략</strong> 의 효과를 재확인하여 기존 모델을 활용한 효율적인 성능 향상 가능성을 보여줍니다. 다만, 현재 구현에서는 이론적 이점 대비 <strong>추론 속도 오버헤드</strong> 가 존재하므로, 최적화된 커널 개발이 실제 배포를 위한 핵심 과제로 남아 있습니다.</p>
<blockquote>
<p>⚠️ <strong>알림:</strong> 이 리뷰는 AI로 작성되었습니다.</p>
</blockquote>
2:["$","div",null,{"className":"flex flex-col lg:flex-row gap-8","children":[["$","aside",null,{"className":"lg:w-64 xl:w-72 order-1 lg:order-none","children":["$","div",null,{"className":"sidebar sticky","children":["$","nav",null,{"className":"space-y-4","children":[["$","div","Backend",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"Backend"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Django",{"children":["$","a",null,{"href":"/backend/django/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Django"," (",6,")"]}]}],["$","li","Logging",{"children":["$","a",null,{"href":"/backend/logging/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Logging"," (",1,")"]}]}]]}]]}],["$","div","Python",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"Python"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","PEP",{"children":["$","a",null,{"href":"/python/pep/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["PEP"," (",650,")"]}]}]]}]]}],["$","div","AI/ML",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"AI/ML"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","LLM",{"children":["$","a",null,{"href":"/ai/llm/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["LLM"," (",1,")"]}]}],["$","li","Review",{"children":["$","a",null,{"href":"/ai/review/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Review"," (",2009,")"]}]}]]}]]}],["$","div","DevOps",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"DevOps"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Nginx",{"children":["$","a",null,{"href":"/devops/nginx/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Nginx"," (",1,")"]}]}],["$","li","Docker",{"children":["$","a",null,{"href":"/devops/docker/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Docker"," (",1,")"]}]}],["$","li","SafeLine",{"children":["$","a",null,{"href":"/devops/safeline/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["SafeLine"," (",1,")"]}]}],["$","li","Jenkins",{"children":["$","a",null,{"href":"/devops/jenkins/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Jenkins"," (",3,")"]}]}],["$","li","GitHub Actions",{"children":["$","a",null,{"href":"/devops/github-actions/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["GitHub Actions"," (",1,")"]}]}],["$","li","AWS",{"children":["$","a",null,{"href":"/devops/aws/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["AWS"," (",1,")"]}]}]]}]]}],["$","div","etc",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"etc"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Me",{"children":["$","a",null,{"href":"/etc/me/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Me"," (",3,")"]}]}],["$","li","Chrome Extension",{"children":["$","a",null,{"href":"/etc/chrome-extension/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Chrome Extension"," (",1,")"]}]}]]}]]}]]}]}]}],["$","main",null,{"className":"flex-1","children":["$","article",null,{"className":"page","children":[["$","header",null,{"className":"mb-8","children":[["$","h1",null,{"className":"page__title","children":"[논문리뷰] Grove MoE: Towards Efficient and Superior MoE LLMs with Adjugate Experts"}],["$","div",null,{"className":"page__meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","span",null,{"className":"ml-4","children":["수정: ","2025년 8월 12일"]}]]}]]}],["$","div",null,{"className":"page__content","children":["$","div",null,{"dangerouslySetInnerHTML":{"__html":"$9"}}]}],["$","footer",null,{"className":"page__meta mt-8","children":["$","div",null,{"className":"page__taxonomy","children":[["$","h4",null,{"className":"text-sm font-medium text-gray-900 mb-2","children":"태그"}],[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Mixture of Experts",{"className":"page__taxonomy-item","children":["#","Mixture of Experts"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","MoE Architecture",{"className":"page__taxonomy-item","children":["#","MoE Architecture"]}],["$","span","Dynamic Activation",{"className":"page__taxonomy-item","children":["#","Dynamic Activation"]}],["$","span","Adjugate Experts",{"className":"page__taxonomy-item","children":["#","Adjugate Experts"]}],["$","span","Upcycling Strategy",{"className":"page__taxonomy-item","children":["#","Upcycling Strategy"]}],["$","span","Load Balancing",{"className":"page__taxonomy-item","children":["#","Load Balancing"]}]]]}]}],["$","section",null,{"className":"mt-12 border-t border-gray-200 pt-8","children":[["$","h3",null,{"className":"text-base font-semibold text-gray-900 mb-4","children":["Review"," 의 다른글"]}],["$","ul",null,{"className":"space-y-2 text-sm","children":[["$","li",null,{"className":"text-gray-500","children":["이전글"," ",["$","$L7",null,{"href":"/ai/review/2025-8-12-GLiClass-Generalist-Lightweight-Model-for-Sequence-Classification-Tasks/","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] GLiClass: Generalist Lightweight Model for Sequence Classification Tasks"}]]}],["$","li",null,{"className":"text-gray-900 font-semibold","children":["현재글 : ","[논문리뷰] Grove MoE: Towards Efficient and Superior MoE LLMs with Adjugate Experts"]}],["$","li",null,{"className":"text-gray-500","children":["다음글"," ",["$","$L7",null,{"href":"/ai/review/2025-8-12-Klear-Reasoner-Advancing-Reasoning-Capability-via-Gradient-Preserving-Clipping-Policy-Optimization/","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] Klear-Reasoner: Advancing Reasoning Capability via Gradient-Preserving Clipping Policy Optimization"}]]}]]}]]}]]}]}]]}]
8:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"secrett2633's blog"}],["$","meta","3",{"name":"description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","meta","4",{"name":"author","content":"secrett2633"}],["$","meta","5",{"name":"keywords","content":"Django, Python, DevOps, AI, ML, 블로그, 기술"}],["$","meta","6",{"name":"creator","content":"secrett2633"}],["$","meta","7",{"name":"publisher","content":"secrett2633"}],["$","meta","8",{"name":"robots","content":"index, follow"}],["$","meta","9",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","10",{"rel":"canonical","href":"https://blog.secrett2633.site/"}],["$","meta","11",{"name":"format-detection","content":"telephone=no, address=no, email=no"}],["$","meta","12",{"property":"og:title","content":"secrett2633's blog"}],["$","meta","13",{"property":"og:description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","meta","14",{"property":"og:url","content":"https://blog.secrett2633.site/"}],["$","meta","15",{"property":"og:site_name","content":"secrett2633's blog"}],["$","meta","16",{"property":"og:locale","content":"ko_KR"}],["$","meta","17",{"property":"og:type","content":"website"}],["$","meta","18",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","19",{"name":"twitter:title","content":"secrett2633's blog"}],["$","meta","20",{"name":"twitter:description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","link","21",{"rel":"icon","href":"/icon.ico?6d9f34d4948640b8","type":"image/x-icon","sizes":"16x16"}],["$","meta","22",{"name":"next-size-adjust"}]]
1:null
