3:I[9275,[],""]
5:I[1343,[],""]
6:I[9157,["231","static/chunks/231-c27e618569e042bc.js","157","static/chunks/157-0ec5cf06f346236d.js","185","static/chunks/app/layout-c3e2e457f12fb6f6.js"],"default"]
7:I[231,["231","static/chunks/231-c27e618569e042bc.js","931","static/chunks/app/page-e3ea38185bb36cd2.js"],""]
4:["slug","ai/review/2025-10-10-Agent-Learning-via-Early-Experience","c"]
0:["J5cbkfStV-uQJU0kFEPzo",[[["",{"children":[["slug","ai/review/2025-10-10-Agent-Learning-via-Early-Experience","c"],{"children":["__PAGE__?{\"slug\":[\"ai\",\"review\",\"2025-10-10-Agent-Learning-via-Early-Experience\"]}",{}]}]},"$undefined","$undefined",true],["",{"children":[["slug","ai/review/2025-10-10-Agent-Learning-via-Early-Experience","c"],{"children":["__PAGE__",{},[["$L1","$L2"],null],null]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","$4","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},[["$","html",null,{"lang":"ko","className":"no-js","children":[["$","head",null,{"children":[["$","meta",null,{"name":"msapplication-TileColor","content":"#ffc40d"}],["$","meta",null,{"name":"theme-color","content":"#ffffff"}],["$","script",null,{"async":true,"src":"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY"}],["$","script",null,{"dangerouslySetInnerHTML":{"__html":"\n              window.dataLayer = window.dataLayer || [];\n              function gtag(){dataLayer.push(arguments);}\n              gtag('js', new Date());\n              gtag('config', 'G-NE2W3CFPNY');\n            "}}]]}],["$","body",null,{"className":"__className_f367f3 layout--default","children":["$","div",null,{"className":"min-h-screen bg-gray-50","children":[["$","$L6",null,{}],["$","main",null,{"className":"initial-content","children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","div",null,{"className":"min-h-screen flex items-center justify-center bg-gray-50","children":["$","div",null,{"className":"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center","children":[["$","h1",null,{"className":"text-6xl font-bold text-primary-600 mb-4","children":"404"}],["$","h2",null,{"className":"text-2xl font-semibold text-gray-900 mb-4","children":"페이지를 찾을 수 없습니다"}],["$","p",null,{"className":"text-gray-600 mb-8","children":"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다."}],["$","$L7",null,{"href":"/","className":"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors","children":"홈으로 돌아가기"}]]}]}],"notFoundStyles":[],"styles":null}]}],["$","div",null,{"id":"footer","className":"page__footer","children":["$","footer",null,{"className":"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8","children":["$","div",null,{"className":"text-center text-gray-500 text-sm","children":["$","p",null,{"children":"© 2025 secrett2633. All rights reserved."}]}]}]}]]}]}]]}],null],[["$","div",null,{"className":"flex items-center justify-center min-h-screen","children":["$","div",null,{"className":"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600"}]}],[],[]]],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/edf391eeca43d999.css","precedence":"next","crossOrigin":"$undefined"}]],[null,"$L8"]]]]]
9:Tf05,<blockquote>
<p><strong>링크:</strong> <a href="https://arxiv.org/abs/2510.08558">논문 PDF로 바로 열기</a></p>
</blockquote>
<p><strong>저자:</strong> Kai Zhang, Xiangchao Chen, Bo Liu, Tianci Xue, Zeyi Liao, Zhihan Liu, Xiyao Wang, Yuting Ning, Zhaorun Chen, Xiaohan Fu, Jian Xie, Yuxuan Sun, Boyu Gou, Qi Qi, Zihang Meng, Jianwei Yang, Ning Zhang, Xian Li, Ashish Shah, Dat Huynh, Hengduo Li, Zi Yang, Sara Cao, Lawrence Jang, Shuyan Zhou, Jiacheng Zhu, Huan Sun, Jason Weston, Yu Su, Yifan Wu</p>
<h2>핵심 연구 목표</h2>
<p>본 논문은 보상이 없거나 불명확한 환경에서 <strong>언어 에이전트</strong> 가 스스로 경험을 통해 학습하고 개선하는 데 따르는 어려움을 해결하고자 합니다. 특히, 기존의 <strong>모방 학습(Imitation Learning)</strong> 이 가진 데이터 스케일링 및 일반화 한계와 <strong>강화 학습(Reinforcement Learning)</strong> 의 보상 신호 부족 문제를 연결하는 새로운 패러다임인 <strong>'Early Experience'</strong> 를 제시하고 그 효과를 검증하는 것이 주된 목표입니다.</p>
<h2>핵심 방법론</h2>
<p><strong>Early Experience</strong> 패러다임은 에이전트가 자체적으로 생성한 상호작용 데이터를 미래 상태에 대한 <strong>감시 신호(supervision signal)</strong> 로 활용합니다. 이를 위해 두 가지 전략을 탐구하는데, 첫째는 수집된 미래 상태를 통해 환경 역학에 대한 내부 표현을 구축하는 <strong>Implicit World Modeling (IWM)</strong> 이며, 이는 <strong>다음 토큰 예측 손실(L_IWM)</strong> 을 사용하여 정책을 학습합니다. 둘째는 에이전트의 차선책 행동에서 얻은 교훈을 통해 의사결정을 개선하는 <strong>Self-Reflection (SR)</strong> 으로, 전문가 행동과 대안 행동의 결과 차이를 바탕으로 <strong>자연어 설명(chain-of-thought)</strong> 을 생성하여 학습합니다. 이 방법론은 <strong>여덟 가지 다양한 환경</strong> 과 <strong>여러 LLM 계열(Llama-3.2-3B, Qwen-2.5-7B, Llama-3.1-8B)</strong> 에서 평가되었습니다.</p>
<h2>주요 결과</h2>
<p><strong>Early Experience</strong> 방법론은 순수 <strong>모방 학습</strong> 대비 평균 <strong>+9.6%의 성공률</strong> 과 <strong>+9.4%의 도메인 외 일반화(Out-of-Domain Generalization)</strong> 성능 향상을 일관되게 달성했습니다. 특히, 보상 신호가 있는 환경에서 <strong>강화 학습(GRPO 알고리즘)</strong> 의 초기화에 <strong>Early Experience</strong> 를 활용하면 최종 성공률이 최대 <strong>+6.4%</strong> 추가로 개선되는 효과를 보였습니다. 또한, 이 패러다임은 전문가 데이터의 <strong>절반 이하</strong> 만으로도 유사하거나 우수한 성능을 달성하며 <strong>대규모 모델(Llama-3.3-70B)</strong> 에도 효과적으로 적용됨을 입증했습니다.</p>
<h2>AI 실무자를 위한 시사점</h2>
<p>본 연구는 보상이 부족한 실제 환경에서 <strong>언어 에이전트</strong> 의 <strong>보상 없는 학습</strong> 을 가능하게 하는 실용적인 접근법을 제시합니다. 에이전트의 자체 상호작용 데이터를 <strong>확장 가능한 학습 신호</strong> 로 활용함으로써, <strong>전문가 데이터</strong> 수집의 제약을 넘어설 수 있는 새로운 학습 패러다임을 제공합니다. 이는 <strong>도메인 외 일반화 능력</strong> 을 향상시키고, 향후 <strong>강화 학습</strong> 의 강력한 초기화 지점 역할을 하여, 궁극적으로 <strong>경험 기반 에이전트</strong> 개발을 가속화할 잠재력을 가집니다.</p>
<blockquote>
<p>⚠️ <strong>알림:</strong> 이 리뷰는 AI로 작성되었습니다.</p>
</blockquote>
2:["$","div",null,{"className":"flex flex-col lg:flex-row gap-8","children":[["$","aside",null,{"className":"lg:w-64 xl:w-72 order-1 lg:order-none","children":["$","div",null,{"className":"sidebar sticky","children":["$","nav",null,{"className":"space-y-4","children":[["$","div","Backend",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"Backend"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Django",{"children":["$","a",null,{"href":"/backend/django/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Django"," (",6,")"]}]}],["$","li","Logging",{"children":["$","a",null,{"href":"/backend/logging/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Logging"," (",1,")"]}]}]]}]]}],["$","div","Python",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"Python"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","PEP",{"children":["$","a",null,{"href":"/python/pep/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["PEP"," (",650,")"]}]}]]}]]}],["$","div","AI/ML",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"AI/ML"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","LLM",{"children":["$","a",null,{"href":"/ai/llm/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["LLM"," (",1,")"]}]}],["$","li","Review",{"children":["$","a",null,{"href":"/ai/review/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Review"," (",2082,")"]}]}]]}]]}],["$","div","DevOps",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"DevOps"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Nginx",{"children":["$","a",null,{"href":"/devops/nginx/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Nginx"," (",1,")"]}]}],["$","li","Docker",{"children":["$","a",null,{"href":"/devops/docker/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Docker"," (",1,")"]}]}],["$","li","SafeLine",{"children":["$","a",null,{"href":"/devops/safeline/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["SafeLine"," (",1,")"]}]}],["$","li","Jenkins",{"children":["$","a",null,{"href":"/devops/jenkins/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Jenkins"," (",3,")"]}]}],["$","li","GitHub Actions",{"children":["$","a",null,{"href":"/devops/github-actions/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["GitHub Actions"," (",1,")"]}]}],["$","li","AWS",{"children":["$","a",null,{"href":"/devops/aws/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["AWS"," (",1,")"]}]}]]}]]}],["$","div","etc",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"etc"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Me",{"children":["$","a",null,{"href":"/etc/me/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Me"," (",3,")"]}]}],["$","li","Chrome Extension",{"children":["$","a",null,{"href":"/etc/chrome-extension/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Chrome Extension"," (",1,")"]}]}]]}]]}]]}]}]}],["$","main",null,{"className":"flex-1","children":["$","article",null,{"className":"page","children":[["$","header",null,{"className":"mb-8","children":[["$","h1",null,{"className":"page__title","children":"[논문리뷰] Agent Learning via Early Experience"}],["$","div",null,{"className":"page__meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","span",null,{"className":"ml-4","children":["수정: ","2025년 10월 10일"]}]]}]]}],["$","div",null,{"className":"page__content","children":["$","div",null,{"dangerouslySetInnerHTML":{"__html":"$9"}}]}],["$","footer",null,{"className":"page__meta mt-8","children":["$","div",null,{"className":"page__taxonomy","children":[["$","h4",null,{"className":"text-sm font-medium text-gray-900 mb-2","children":"태그"}],[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Language Agents",{"className":"page__taxonomy-item","children":["#","Language Agents"]}],["$","span","Early Experience",{"className":"page__taxonomy-item","children":["#","Early Experience"]}],["$","span","Reward-Free Learning",{"className":"page__taxonomy-item","children":["#","Reward-Free Learning"]}],["$","span","World Modeling",{"className":"page__taxonomy-item","children":["#","World Modeling"]}],["$","span","Self-Reflection",{"className":"page__taxonomy-item","children":["#","Self-Reflection"]}],["$","span","Imitation Learning",{"className":"page__taxonomy-item","children":["#","Imitation Learning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Out-of-Domain Generalization",{"className":"page__taxonomy-item","children":["#","Out-of-Domain Generalization"]}]]]}]}],["$","section",null,{"className":"mt-12 border-t border-gray-200 pt-8","children":[["$","h3",null,{"className":"text-base font-semibold text-gray-900 mb-4","children":["Review"," 의 다른글"]}],["$","ul",null,{"className":"space-y-2 text-sm","children":[["$","li",null,{"className":"text-gray-500","children":["이전글"," ",["$","$L7",null,{"href":"/ai/review/2025-10-10-A2Search-Ambiguity-Aware-Question-Answering-with-Reinforcement-Learning/","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] A^2Search: Ambiguity-Aware Question Answering with Reinforcement Learning"}]]}],["$","li",null,{"className":"text-gray-900 font-semibold","children":["현재글 : ","[논문리뷰] Agent Learning via Early Experience"]}],["$","li",null,{"className":"text-gray-500","children":["다음글"," ",["$","$L7",null,{"href":"/ai/review/2025-10-10-ARTDECO-Towards-Efficient-and-High-Fidelity-On-the-Fly-3D-Reconstruction-with-Structured-Scene-Representation/","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] ARTDECO: Towards Efficient and High-Fidelity On-the-Fly 3D Reconstruction with Structured Scene Representation"}]]}]]}]]}]]}]}]]}]
8:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"secrett2633's blog"}],["$","meta","3",{"name":"description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","meta","4",{"name":"author","content":"secrett2633"}],["$","meta","5",{"name":"keywords","content":"Django, Python, DevOps, AI, ML, 블로그, 기술"}],["$","meta","6",{"name":"creator","content":"secrett2633"}],["$","meta","7",{"name":"publisher","content":"secrett2633"}],["$","meta","8",{"name":"robots","content":"index, follow"}],["$","meta","9",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","10",{"rel":"canonical","href":"https://blog.secrett2633.site/"}],["$","meta","11",{"name":"format-detection","content":"telephone=no, address=no, email=no"}],["$","meta","12",{"property":"og:title","content":"secrett2633's blog"}],["$","meta","13",{"property":"og:description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","meta","14",{"property":"og:url","content":"https://blog.secrett2633.site/"}],["$","meta","15",{"property":"og:site_name","content":"secrett2633's blog"}],["$","meta","16",{"property":"og:locale","content":"ko_KR"}],["$","meta","17",{"property":"og:type","content":"website"}],["$","meta","18",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","19",{"name":"twitter:title","content":"secrett2633's blog"}],["$","meta","20",{"name":"twitter:description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","link","21",{"rel":"icon","href":"/icon.ico?6d9f34d4948640b8","type":"image/x-icon","sizes":"16x16"}]]
1:null
