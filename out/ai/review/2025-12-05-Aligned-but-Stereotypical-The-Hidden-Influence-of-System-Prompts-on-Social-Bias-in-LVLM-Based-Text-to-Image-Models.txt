3:I[9275,[],""]
5:I[1343,[],""]
6:I[9157,["231","static/chunks/231-467e37449c5a68fc.js","185","static/chunks/app/layout-b0a450f8e4964582.js"],"default"]
7:I[231,["231","static/chunks/231-467e37449c5a68fc.js","877","static/chunks/app/%5B...slug%5D/page-1f60377561abdb46.js"],""]
8:I[4080,["231","static/chunks/231-467e37449c5a68fc.js","185","static/chunks/app/layout-b0a450f8e4964582.js"],""]
4:["slug","ai/review/2025-12-05-Aligned-but-Stereotypical-The-Hidden-Influence-of-System-Prompts-on-Social-Bias-in-LVLM-Based-Text-to-Image-Models","c"]
0:["WcxaIiCPz9cbpnkGvOjOK",[[["",{"children":[["slug","ai/review/2025-12-05-Aligned-but-Stereotypical-The-Hidden-Influence-of-System-Prompts-on-Social-Bias-in-LVLM-Based-Text-to-Image-Models","c"],{"children":["__PAGE__?{\"slug\":[\"ai\",\"review\",\"2025-12-05-Aligned-but-Stereotypical-The-Hidden-Influence-of-System-Prompts-on-Social-Bias-in-LVLM-Based-Text-to-Image-Models\"]}",{}]}]},"$undefined","$undefined",true],["",{"children":[["slug","ai/review/2025-12-05-Aligned-but-Stereotypical-The-Hidden-Influence-of-System-Prompts-on-Social-Bias-in-LVLM-Based-Text-to-Image-Models","c"],{"children":["__PAGE__",{},[["$L1","$L2"],null],null]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","$4","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},[["$","html",null,{"lang":"ko","className":"no-js","children":[["$","head",null,{"children":[["$","meta",null,{"name":"msapplication-TileColor","content":"#ffc40d"}],["$","meta",null,{"name":"theme-color","content":"#ffffff"}],["$","link",null,{"rel":"dns-prefetch","href":"https://www.googletagmanager.com"}],["$","link",null,{"rel":"preconnect","href":"https://www.googletagmanager.com","crossOrigin":"anonymous"}],["$","link",null,{"rel":"dns-prefetch","href":"https://giscus.app"}],["$","link",null,{"rel":"preconnect","href":"https://giscus.app","crossOrigin":"anonymous"}],["$","meta",null,{"httpEquiv":"X-Content-Type-Options","content":"nosniff"}],["$","meta",null,{"name":"referrer","content":"strict-origin-when-cross-origin"}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"WebSite\",\"name\":\"secrett2633's blog\",\"url\":\"https://blog.secrett2633.cloud\",\"description\":\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\",\"inLanguage\":\"ko\",\"publisher\":{\"@type\":\"Person\",\"name\":\"secrett2633\",\"url\":\"https://blog.secrett2633.cloud\"}}"}}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"Person\",\"name\":\"secrett2633\",\"url\":\"https://blog.secrett2633.cloud\",\"sameAs\":[\"https://github.com/secrett2633\"]}"}}]]}],["$","body",null,{"className":"__className_f367f3 layout--default","children":[["$","a",null,{"href":"#main-content","className":"sr-only focus:not-sr-only focus:absolute focus:z-50 focus:p-4 focus:bg-white focus:text-blue-600","children":"본문으로 건너뛰기"}],["$","div",null,{"className":"min-h-screen bg-gray-50","children":[["$","$L6",null,{}],["$","main",null,{"id":"main-content","className":"initial-content","children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","div",null,{"className":"min-h-screen flex items-center justify-center bg-gray-50","children":["$","div",null,{"className":"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center","children":[["$","h1",null,{"className":"text-6xl font-bold text-primary-600 mb-4","children":"404"}],["$","h2",null,{"className":"text-2xl font-semibold text-gray-900 mb-4","children":"페이지를 찾을 수 없습니다"}],["$","p",null,{"className":"text-gray-600 mb-8","children":"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다."}],["$","$L7",null,{"href":"/","className":"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors","children":"홈으로 돌아가기"}]]}]}],"notFoundStyles":[],"styles":null}]}],["$","div",null,{"id":"footer","className":"page__footer","children":["$","footer",null,{"className":"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8","children":["$","div",null,{"className":"text-center text-gray-500 text-sm","children":["$","p",null,{"children":["© ",2026," secrett2633. All rights reserved."]}]}]}]}]]}],["$","$L8",null,{"src":"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY","strategy":"afterInteractive"}],["$","$L8",null,{"id":"gtag-init","strategy":"afterInteractive","children":"window.dataLayer = window.dataLayer || [];\n            function gtag(){dataLayer.push(arguments);}\n            gtag('js', new Date());\n            gtag('config', 'G-NE2W3CFPNY');"}]]}]]}],null],[["$","div",null,{"className":"flex items-center justify-center min-h-screen","role":"status","aria-label":"로딩 중","children":[["$","div",null,{"className":"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600"}],["$","span",null,{"className":"sr-only","children":"로딩 중..."}]]}],[],[]]],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/ddc331716d5e47a2.css","precedence":"next","crossOrigin":"$undefined"}]],[null,"$L9"]]]]]
c:I[646,["231","static/chunks/231-467e37449c5a68fc.js","877","static/chunks/app/%5B...slug%5D/page-1f60377561abdb46.js"],"default"]
a:T52e,{"@context":"https://schema.org","@type":"BlogPosting","headline":"[논문리뷰] Aligned but Stereotypical? The Hidden Influence of System Prompts on Social Bias in LVLM-Based Text-to-Image Models","description":"이 [arXiv]에 게시한 'Aligned but Stereotypical? The Hidden Influence of System Prompts on Social Bias in LVLM-Based Text-to-Image Models' 논문에 대한 자세한 리뷰입니다.","url":"https://blog.secrett2633.cloud/ai/review/2025-12-05-Aligned-but-Stereotypical-The-Hidden-Influence-of-System-Prompts-on-Social-Bias-in-LVLM-Based-Text-to-Image-Models","datePublished":"2025-12-04T15:00:00.000Z","dateModified":"2025-12-04T15:00:00.000Z","author":{"@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud"},"publisher":{"@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.secrett2633.cloud/ai/review/2025-12-05-Aligned-but-Stereotypical-The-Hidden-Influence-of-System-Prompts-on-Social-Bias-in-LVLM-Based-Text-to-Image-Models"},"image":"https://blog.secrett2633.cloud/og-default.png","isAccessibleForFree":true,"inLanguage":"ko","wordCount":331,"articleSection":"Review","keywords":"Review, Text-to-Image, LVLM, Social Bias, System Prompts, Bias Mitigation, Meta-Prompting, Fairness, Generative AI"}b:T101a,<blockquote>
<p><strong>링크:</strong> <a href="https://arxiv.org/abs/2512.04981" target="_blank" rel="noopener noreferrer">논문 PDF로 바로 열기</a></p>
</blockquote>
<p><strong>저자:</strong> NaHyeon Park, Na Min An, Kunhee Kim, Soyeon Yoon, Jiahao Huo, Hyunjung Shim</p>
<h2 id="핵심-연구-목표"><a href="#핵심-연구-목표">핵심 연구 목표</a></h2>
<p>본 연구는 최근 <strong>LVLM(Large Vision-Language Model) 기반 텍스트-투-이미지(T2I) 모델</strong> 이 이미지 생성에서 높은 품질을 달성했음에도 불구하고, 사회적 편향을 얼마나 증폭시키는지에 대한 이해가 부족하다는 문제의식을 제기합니다. 특히, LVLM 기반 T2I 모델에서 편향이 발생하는 근본적인 메커니즘을 규명하고, 시스템 프롬프트가 편향 전파에 미치는 숨겨진 영향을 분석하며, 이를 효과적으로 완화할 수 있는 훈련 없는(training-free) 방법론을 제안하는 것을 목표로 합니다.</p>
<h2 id="핵심-방법론"><a href="#핵심-방법론">핵심 방법론</a></h2>
<p>연구팀은 <strong>1,024개의 다단계 프롬프트 벤치마크</strong> 를 구축하여 <strong>SD3.5, FLUX, SANA, Qwen-Image</strong> 등 6개 모델의 편향을 평가했습니다. 편향 측정에는 <strong>Llama3.2-11B VQA 모델</strong> 을 평가자로 활용하고 <strong>Fair Discrepancy(FD) 지표</strong> 를 사용하여 <strong>성별, 연령, 민족성, 외모</strong> 편향을 정량화했습니다. 편향 전파 메커니즘을 분석하기 위해 <strong>디코딩된 텍스트, 토큰 확률 진단, 임베딩 연관성 분석</strong> 을 수행했으며, 이를 바탕으로 LVLM이 사용자 입력을 <strong>자체 감사(self-audit)</strong> 하고 공정성 인식 시스템 프롬프트를 생성하는 훈련 없는 <strong>FAIRPRO 메타-프롬프팅 프레임워크</strong> 를 제안했습니다.</p>
<h2 id="주요-결과"><a href="#주요-결과">주요 결과</a></h2>
<p><strong>LVLM 기반 T2I 모델(SANA, Qwen-Image)</strong> 은 비-LVLM 모델 대비 일관되게 <strong>더 높은 사회적 편향</strong> 을 보였습니다. 특히 <strong>Qwen-Image</strong> 는 연령, 성별, 외모 속성에서 가장 높은 편향을 나타냈습니다. 프롬프트 복잡성 증가와 명시적인 인구통계학적 속성 추가는 편향을 증폭시켰으며, 텍스트-이미지 정렬과 사회적 편향 간에 <strong>0.948의 강한 양의 피어슨 상관관계</strong> 가 있음을 발견했습니다. 제안된 <strong>FAIRPRO</strong> 는 <strong>SANA의 성별 편향 점수를 0.906에서 0.771로 감소</strong> 시키는 등 <strong>두 LVLM 기반 모델 모두에서 모든 속성과 프롬프트 유형에 걸쳐 편향을 현저히 줄이면서</strong> 텍스트-이미지 정렬 성능을 유지했습니다.</p>
<h2 id="ai-실무자를-위한-시사점"><a href="#ai-실무자를-위한-시사점">AI 실무자를 위한 시사점</a></h2>
<p>LVLM 기반 T2I 시스템을 활용하는 AI 실무자들은 <strong>시스템 프롬프트</strong> 가 생성 이미지의 사회적 편향에 지대한 영향을 미친다는 점을 인지해야 합니다. <strong>FAIRPRO</strong> 와 같은 <strong>메타-프롬프팅 기법</strong> 은 추가적인 모델 재훈련 없이도 테스트 시점에 <strong>동적으로 편향을 완화</strong> 할 수 있는 효과적이고 실용적인 전략을 제공합니다. 이는 특히 사용자 프롬프트에 내재된 편향이나 <strong>모델의 암묵적인 사회적 고정관념</strong> 이 이미지 생성 과정에서 증폭되는 것을 방지하는 데 기여할 수 있습니다. 또한, 모델의 <strong>텍스트-이미지 정렬도 향상</strong> 이 때로는 <strong>사회적 편향 증가</strong> 와 함께 발생할 수 있다는 시사점은 AI 시스템 개발 시 성능과 윤리적 공정성 사이의 균형을 신중하게 고려해야 함을 강조합니다.</p>
<blockquote>
<p>⚠️ <strong>알림:</strong> 이 리뷰는 AI로 작성되었습니다.</p>
</blockquote>
2:[["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"$a"}}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"BreadcrumbList\",\"itemListElement\":[{\"@type\":\"ListItem\",\"position\":1,\"name\":\"홈\",\"item\":\"https://blog.secrett2633.cloud/\"},{\"@type\":\"ListItem\",\"position\":2,\"name\":\"Review\",\"item\":\"https://blog.secrett2633.cloud/ai/review\"},{\"@type\":\"ListItem\",\"position\":3,\"name\":\"[논문리뷰] Aligned but Stereotypical? The Hidden Influence of System Prompts on Social Bias in LVLM-Based Text-to-Image Models\",\"item\":\"https://blog.secrett2633.cloud/ai/review/2025-12-05-Aligned-but-Stereotypical-The-Hidden-Influence-of-System-Prompts-on-Social-Bias-in-LVLM-Based-Text-to-Image-Models\"}]}"}}],["$","div",null,{"className":"flex flex-col lg:flex-row gap-8","children":[["$","aside",null,{"className":"lg:w-64 xl:w-72 order-1 lg:order-none","children":["$","div",null,{"className":"sidebar sticky","children":["$","nav",null,{"className":"space-y-4","aria-label":"카테고리 네비게이션","children":[["$","div","Backend",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"Backend"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Django",{"children":["$","$L7",null,{"href":"/backend/django","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Django"," (",6,")"]}]}],["$","li","Logging",{"children":["$","$L7",null,{"href":"/backend/logging","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Logging"," (",1,")"]}]}]]}]]}],["$","div","Python",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"Python"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","PEP",{"children":["$","$L7",null,{"href":"/python/pep","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["PEP"," (",650,")"]}]}]]}]]}],["$","div","AI/ML",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"AI/ML"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","LLM",{"children":["$","$L7",null,{"href":"/ai/llm","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["LLM"," (",1,")"]}]}],["$","li","Review",{"children":["$","$L7",null,{"href":"/ai/review","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Review"," (",2728,")"]}]}]]}]]}],["$","div","DevOps",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"DevOps"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Nginx",{"children":["$","$L7",null,{"href":"/devops/nginx","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Nginx"," (",1,")"]}]}],["$","li","Docker",{"children":["$","$L7",null,{"href":"/devops/docker","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Docker"," (",1,")"]}]}],["$","li","SafeLine",{"children":["$","$L7",null,{"href":"/devops/safeline","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["SafeLine"," (",1,")"]}]}],["$","li","Jenkins",{"children":["$","$L7",null,{"href":"/devops/jenkins","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Jenkins"," (",3,")"]}]}],["$","li","GitHub Actions",{"children":["$","$L7",null,{"href":"/devops/github-actions","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["GitHub Actions"," (",1,")"]}]}],["$","li","AWS",{"children":["$","$L7",null,{"href":"/devops/aws","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["AWS"," (",1,")"]}]}]]}]]}],["$","div","etc",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"etc"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Me",{"children":["$","$L7",null,{"href":"/etc/me","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Me"," (",3,")"]}]}],["$","li","Chrome Extension",{"children":["$","$L7",null,{"href":"/etc/chrome-extension","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Chrome Extension"," (",1,")"]}]}]]}]]}]]}]}]}],["$","div",null,{"className":"flex-1","children":[["$","nav",null,{"aria-label":"breadcrumb","className":"text-sm text-gray-500 mb-4","children":["$","ol",null,{"className":"flex flex-wrap items-center gap-1","children":[["$","li",null,{"children":["$","$L7",null,{"href":"/","className":"hover:text-gray-700","children":"홈"}]}],[["$","li","/ai/review",{"className":"flex items-center gap-1","children":[["$","span",null,{"aria-hidden":"true","children":"/"}],["$","$L7",null,{"href":"/ai/review","className":"hover:text-gray-700","children":"Review"}]]}],["$","li","/ai/review/2025-12-05-Aligned-but-Stereotypical-The-Hidden-Influence-of-System-Prompts-on-Social-Bias-in-LVLM-Based-Text-to-Image-Models",{"className":"flex items-center gap-1","children":[["$","span",null,{"aria-hidden":"true","children":"/"}],["$","span",null,{"className":"text-gray-900","aria-current":"page","children":"[논문리뷰] Aligned but Stereotypical? The Hidden Influence of System Prompts on Social Bias in LVLM-Based Text-to-Image Models"}]]}]]]}]}],["$","article",null,{"className":"page","children":[["$","header",null,{"className":"mb-8","children":[["$","h1",null,{"className":"page__title","children":"[논문리뷰] Aligned but Stereotypical? The Hidden Influence of System Prompts on Social Bias in LVLM-Based Text-to-Image Models"}],["$","div",null,{"className":"page__meta","children":[["$","time",null,{"dateTime":"2025-12-05 00:00:00+0900+0900","children":"2025년 12월 5일"}],["$","time",null,{"className":"ml-4","dateTime":"2025-12-04T15:00:00.000Z","children":["수정: ","2025년 12월 5일"]}]]}]]}],["$","div",null,{"className":"page__content","children":["$","div",null,{"dangerouslySetInnerHTML":{"__html":"$b"}}]}],["$","footer",null,{"className":"page__meta mt-8","children":["$","div",null,{"className":"page__taxonomy","children":[["$","span",null,{"className":"text-sm font-medium text-gray-900 mb-2 block","children":"태그"}],[["$","$L7","Review",{"href":"/tags/Review","className":"page__taxonomy-item","children":["#","Review"]}],["$","$L7","Text-to-Image",{"href":"/tags/Text-to-Image","className":"page__taxonomy-item","children":["#","Text-to-Image"]}],["$","$L7","LVLM",{"href":"/tags/LVLM","className":"page__taxonomy-item","children":["#","LVLM"]}],["$","$L7","Social Bias",{"href":"/tags/Social%20Bias","className":"page__taxonomy-item","children":["#","Social Bias"]}],["$","$L7","System Prompts",{"href":"/tags/System%20Prompts","className":"page__taxonomy-item","children":["#","System Prompts"]}],["$","$L7","Bias Mitigation",{"href":"/tags/Bias%20Mitigation","className":"page__taxonomy-item","children":["#","Bias Mitigation"]}],["$","$L7","Meta-Prompting",{"href":"/tags/Meta-Prompting","className":"page__taxonomy-item","children":["#","Meta-Prompting"]}],["$","$L7","Fairness",{"href":"/tags/Fairness","className":"page__taxonomy-item","children":["#","Fairness"]}],["$","$L7","Generative AI",{"href":"/tags/Generative%20AI","className":"page__taxonomy-item","children":["#","Generative AI"]}]]]}]}],["$","$Lc",null,{"postPermalink":"/ai/review/2025-12-05-Aligned-but-Stereotypical-The-Hidden-Influence-of-System-Prompts-on-Social-Bias-in-LVLM-Based-Text-to-Image-Models","postId":"2025-12-05-Aligned-but-Stereotypical-The-Hidden-Influence-of-System-Prompts-on-Social-Bias-in-LVLM-Based-Text-to-Image-Models"}],["$","section",null,{"className":"mt-12 border-t border-gray-200 pt-8","children":[["$","h3",null,{"className":"text-base font-semibold text-gray-900 mb-4","children":["Review"," 의 다른글"]}],["$","ul",null,{"className":"space-y-2 text-sm","children":[["$","li",null,{"className":"text-gray-500","children":["이전글"," ",["$","$L7",null,{"href":"/ai/review/2025-12-05-ARM-Thinker-Reinforcing-Multimodal-Generative-Reward-Models-with-Agentic-Tool-Use-and-Visual-Reasoning","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] ARM-Thinker: Reinforcing Multimodal Generative Reward Models with Agentic Tool Use and Visual Reasoning"}]]}],["$","li",null,{"className":"text-gray-900 font-semibold","children":["현재글 : ","[논문리뷰] Aligned but Stereotypical? The Hidden Influence of System Prompts on Social Bias in LVLM-Based Text-to-Image Models"]}],["$","li",null,{"className":"text-gray-500","children":["다음글"," ",["$","$L7",null,{"href":"/ai/review/2025-12-05-BulletTime-Decoupled-Control-of-Time-and-Camera-Pose-for-Video-Generation","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] BulletTime: Decoupled Control of Time and Camera Pose for Video Generation"}]]}]]}]]}]]}]]}]]}]]
9:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"[논문리뷰] Aligned but Stereotypical? The Hidden Influence of System Prompts on Social Bias in LVLM-Based Text-to-Image Models - secrett2633's blog"}],["$","meta","3",{"name":"description","content":"이 [arXiv]에 게시한 'Aligned but Stereotypical? The Hidden Influence of System Prompts on Social Bias in LVLM-Based Text-to-Image Models' 논문에 대한 자세한 리뷰입니다."}],["$","meta","4",{"name":"author","content":"secrett2633"}],["$","link","5",{"rel":"manifest","href":"/manifest.json","crossOrigin":"use-credentials"}],["$","meta","6",{"name":"keywords","content":"Django, Python, DevOps, AI, ML, 블로그, 기술"}],["$","meta","7",{"name":"creator","content":"secrett2633"}],["$","meta","8",{"name":"publisher","content":"secrett2633"}],["$","meta","9",{"name":"robots","content":"index, follow"}],["$","meta","10",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","11",{"rel":"canonical","href":"https://blog.secrett2633.cloud/ai/review/2025-12-05-Aligned-but-Stereotypical-The-Hidden-Influence-of-System-Prompts-on-Social-Bias-in-LVLM-Based-Text-to-Image-Models"}],["$","meta","12",{"name":"format-detection","content":"telephone=no, address=no, email=no"}],["$","meta","13",{"property":"og:title","content":"[논문리뷰] Aligned but Stereotypical? The Hidden Influence of System Prompts on Social Bias in LVLM-Based Text-to-Image Models"}],["$","meta","14",{"property":"og:description","content":"이 [arXiv]에 게시한 'Aligned but Stereotypical? The Hidden Influence of System Prompts on Social Bias in LVLM-Based Text-to-Image Models' 논문에 대한 자세한 리뷰입니다."}],["$","meta","15",{"property":"og:url","content":"https://blog.secrett2633.cloud/ai/review/2025-12-05-Aligned-but-Stereotypical-The-Hidden-Influence-of-System-Prompts-on-Social-Bias-in-LVLM-Based-Text-to-Image-Models"}],["$","meta","16",{"property":"og:type","content":"article"}],["$","meta","17",{"property":"article:published_time","content":"2025-12-04T15:00:00.000Z"}],["$","meta","18",{"property":"article:modified_time","content":"2025-12-04T15:00:00.000Z"}],["$","meta","19",{"property":"article:author","content":"secrett2633"}],["$","meta","20",{"property":"article:section","content":"Review"}],["$","meta","21",{"property":"article:tag","content":"Review"}],["$","meta","22",{"property":"article:tag","content":"Text-to-Image"}],["$","meta","23",{"property":"article:tag","content":"LVLM"}],["$","meta","24",{"property":"article:tag","content":"Social Bias"}],["$","meta","25",{"property":"article:tag","content":"System Prompts"}],["$","meta","26",{"property":"article:tag","content":"Bias Mitigation"}],["$","meta","27",{"property":"article:tag","content":"Meta-Prompting"}],["$","meta","28",{"property":"article:tag","content":"Fairness"}],["$","meta","29",{"property":"article:tag","content":"Generative AI"}],["$","meta","30",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","31",{"name":"twitter:creator","content":"@secrett2633"}],["$","meta","32",{"name":"twitter:title","content":"[논문리뷰] Aligned but Stereotypical? The Hidden Influence of System Prompts on Social Bias in LVLM-Based Text-to-Image Models"}],["$","meta","33",{"name":"twitter:description","content":"이 [arXiv]에 게시한 'Aligned but Stereotypical? The Hidden Influence of System Prompts on Social Bias in LVLM-Based Text-to-Image Models' 논문에 대한 자세한 리뷰입니다."}],["$","link","34",{"rel":"icon","href":"/icon.ico?6d9f34d4948640b8","type":"image/x-icon","sizes":"16x16"}],["$","meta","35",{"name":"next-size-adjust"}]]
1:null
