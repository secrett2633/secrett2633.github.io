3:I[9275,[],""]
5:I[1343,[],""]
6:I[9157,["231","static/chunks/231-467e37449c5a68fc.js","185","static/chunks/app/layout-e359f205e3380aec.js"],"default"]
7:I[231,["231","static/chunks/231-467e37449c5a68fc.js","931","static/chunks/app/page-90c91ef098171651.js"],""]
4:["slug","ai/review/2026-01-16-FlowAct-R1-Towards-Interactive-Humanoid-Video-Generation","c"]
0:["vlNzklkFwxZlDtaCTE3RF",[[["",{"children":[["slug","ai/review/2026-01-16-FlowAct-R1-Towards-Interactive-Humanoid-Video-Generation","c"],{"children":["__PAGE__?{\"slug\":[\"ai\",\"review\",\"2026-01-16-FlowAct-R1-Towards-Interactive-Humanoid-Video-Generation\"]}",{}]}]},"$undefined","$undefined",true],["",{"children":[["slug","ai/review/2026-01-16-FlowAct-R1-Towards-Interactive-Humanoid-Video-Generation","c"],{"children":["__PAGE__",{},[["$L1","$L2"],null],null]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","$4","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},[["$","html",null,{"lang":"ko","className":"no-js","children":[["$","head",null,{"children":[["$","meta",null,{"name":"msapplication-TileColor","content":"#ffc40d"}],["$","meta",null,{"name":"theme-color","content":"#ffffff"}],["$","script",null,{"async":true,"src":"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY"}],["$","script",null,{"dangerouslySetInnerHTML":{"__html":"\n              window.dataLayer = window.dataLayer || [];\n              function gtag(){dataLayer.push(arguments);}\n              gtag('js', new Date());\n              gtag('config', 'G-NE2W3CFPNY');\n            "}}]]}],["$","body",null,{"className":"__className_f367f3 layout--default","children":["$","div",null,{"className":"min-h-screen bg-gray-50","children":[["$","$L6",null,{}],["$","main",null,{"className":"initial-content","children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","div",null,{"className":"min-h-screen flex items-center justify-center bg-gray-50","children":["$","div",null,{"className":"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center","children":[["$","h1",null,{"className":"text-6xl font-bold text-primary-600 mb-4","children":"404"}],["$","h2",null,{"className":"text-2xl font-semibold text-gray-900 mb-4","children":"페이지를 찾을 수 없습니다"}],["$","p",null,{"className":"text-gray-600 mb-8","children":"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다."}],["$","$L7",null,{"href":"/","className":"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors","children":"홈으로 돌아가기"}]]}]}],"notFoundStyles":[],"styles":null}]}],["$","div",null,{"id":"footer","className":"page__footer","children":["$","footer",null,{"className":"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8","children":["$","div",null,{"className":"text-center text-gray-500 text-sm","children":["$","p",null,{"children":"© 2025 secrett2633. All rights reserved."}]}]}]}]]}]}]]}],null],[["$","div",null,{"className":"flex items-center justify-center min-h-screen","children":["$","div",null,{"className":"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600"}]}],[],[]]],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/d6cea809dcbae606.css","precedence":"next","crossOrigin":"$undefined"}]],[null,"$L8"]]]]]
a:I[646,["231","static/chunks/231-467e37449c5a68fc.js","877","static/chunks/app/%5B...slug%5D/page-dfe24a3bbd58f9b9.js"],"default"]
9:Tc94,<blockquote>
<p><strong>링크:</strong> <a href="https://arxiv.org/abs/2601.10103">논문 PDF로 바로 열기</a></p>
</blockquote>
<p><strong>저자:</strong> Lizhen Wang, Yongming Zhu, Zhipeng Ge, Youwei Zheng, Longhao Zhang, Tianshu Hu, Shiyang Qin, Mingshuang Luo, Jiaxu Zhang, Xin Chen, Yulong Wang, Zerong Zheng, Jianwen Jiang, Chao Liang, Weifeng Chen, Xing Wang, Yuan Zhang, Mingyuan Gao (ByteDance Intelligent Creation)</p>
<h2>핵심 연구 목표</h2>
<p>본 논문은 실시간 상호작용이 가능한 휴머노이드 비디오 생성을 목표로 하며, 기존 비디오 합성 방법론이 고품질 합성 및 실시간 상호작용 요구사항 사이에서 겪는 한계를 극복하고자 합니다. 특히, 연속적이고 반응적인 방식으로 인간과 상호작용할 수 있는 생체와 같은 시각적 에이전트를 합성하는 것을 주된 연구 목적으로 합니다.</p>
<h2>핵심 방법론</h2>
<p>제안된 FlowAct-R1 프레임워크는 <strong>MMDiT(Multimodal Diffusion Transformer)</strong> 아키텍처를 기반으로 하며, 무기한 길이 스트리밍 비디오 합성을 위해 <strong>청크 단위 확산 강제 전략(chunkwise diffusion forcing strategy)</strong> 을 도입했습니다. 오류 누적을 완화하고 장기적인 시간적 일관성을 보장하기 위해 <strong>자가 강제(self-forcing) 변형</strong> 과 <strong>구조화된 메모리 뱅크</strong> 를 활용합니다. 실시간 성능은 <strong>효율적인 증류 기술(3 NFEs)</strong> , <strong>FP8 양자화</strong> , <strong>프레임 단위 하이브리드 병렬화</strong> 및 <strong>비동기 파이프라인</strong> 을 통해 달성됩니다.</p>
<h2>주요 결과</h2>
<p>FlowAct-R1은 <strong>NVIDIA A100</strong> 플랫폼에서 <strong>480p 해상도로 25fps</strong> 의 안정적인 실시간 비디오 생성을 지원하며, <strong>최초 프레임까지의 시간(TTFF)은 약 1.5초</strong> 입니다. 사용자 연구(GSB metric) 결과, FlowAct-R1은 모션 자연스러움, 립싱크 정확도, 프레임 구조 안정성 및 모션 풍부도에서 경쟁 모델들을 뛰어넘는 우수한 성능을 보였으며, <strong>LiveAvatar 대비 91%</strong> , <strong>KlingAvatar 2.0 대비 74%</strong> , <strong>Omnihuman-1.5 대비 62%</strong> 의 선호도를 얻었습니다.</p>
<h2>AI 실무자를 위한 시사점</h2>
<p>본 연구는 실시간 스트리밍이 필수적인 라이브 스트리밍, 가상 동반자, 화상 회의와 같은 상호작용형 AI 애플리케이션 개발에 중요한 이정표를 제시합니다. <strong>MMDiT 아키텍처</strong> 와 <strong>청크 단위 확산 강제 전략</strong> , 그리고 <strong>증류 기술</strong> 의 결합은 효율적이고 고품질의 생성 모델을 구축하는 데 활용될 수 있습니다. 또한, <strong>MLLM 기반의 액션 플래닝</strong> 과 <strong>메모리 개선 전략</strong> 은 장기 비디오 생성 시 시간적 일관성과 자연스러운 행동 표현을 확보하는 데 유용한 기법으로 응용될 수 있습니다.</p>
<blockquote>
<p>⚠️ <strong>알림:</strong> 이 리뷰는 AI로 작성되었습니다.</p>
</blockquote>
2:["$","div",null,{"className":"flex flex-col lg:flex-row gap-8","children":[["$","aside",null,{"className":"lg:w-64 xl:w-72 order-1 lg:order-none","children":["$","div",null,{"className":"sidebar sticky","children":["$","nav",null,{"className":"space-y-4","children":[["$","div","Backend",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"Backend"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Django",{"children":["$","a",null,{"href":"/backend/django/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Django"," (",6,")"]}]}],["$","li","Logging",{"children":["$","a",null,{"href":"/backend/logging/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Logging"," (",1,")"]}]}]]}]]}],["$","div","Python",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"Python"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","PEP",{"children":["$","a",null,{"href":"/python/pep/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["PEP"," (",650,")"]}]}]]}]]}],["$","div","AI/ML",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"AI/ML"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","LLM",{"children":["$","a",null,{"href":"/ai/llm/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["LLM"," (",1,")"]}]}],["$","li","Review",{"children":["$","a",null,{"href":"/ai/review/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Review"," (",2420,")"]}]}]]}]]}],["$","div","DevOps",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"DevOps"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Nginx",{"children":["$","a",null,{"href":"/devops/nginx/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Nginx"," (",1,")"]}]}],["$","li","Docker",{"children":["$","a",null,{"href":"/devops/docker/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Docker"," (",1,")"]}]}],["$","li","SafeLine",{"children":["$","a",null,{"href":"/devops/safeline/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["SafeLine"," (",1,")"]}]}],["$","li","Jenkins",{"children":["$","a",null,{"href":"/devops/jenkins/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Jenkins"," (",3,")"]}]}],["$","li","GitHub Actions",{"children":["$","a",null,{"href":"/devops/github-actions/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["GitHub Actions"," (",1,")"]}]}],["$","li","AWS",{"children":["$","a",null,{"href":"/devops/aws/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["AWS"," (",1,")"]}]}]]}]]}],["$","div","etc",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"etc"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Me",{"children":["$","a",null,{"href":"/etc/me/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Me"," (",3,")"]}]}],["$","li","Chrome Extension",{"children":["$","a",null,{"href":"/etc/chrome-extension/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Chrome Extension"," (",1,")"]}]}]]}]]}]]}]}]}],["$","main",null,{"className":"flex-1","children":["$","article",null,{"className":"page","children":[["$","header",null,{"className":"mb-8","children":[["$","h1",null,{"className":"page__title","children":"[논문리뷰] FlowAct-R1: Towards Interactive Humanoid Video Generation"}],["$","div",null,{"className":"page__meta","children":[["$","time",null,{"dateTime":"2026-01-16 00:00:00+0900+0900","children":"2026년 1월 16일"}],["$","span",null,{"className":"ml-4","children":["수정: ","2026년 1월 16일"]}]]}]]}],["$","div",null,{"className":"page__content","children":["$","div",null,{"dangerouslySetInnerHTML":{"__html":"$9"}}]}],["$","footer",null,{"className":"page__meta mt-8","children":["$","div",null,{"className":"page__taxonomy","children":[["$","h4",null,{"className":"text-sm font-medium text-gray-900 mb-2","children":"태그"}],[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Interactive Video Generation",{"className":"page__taxonomy-item","children":["#","Interactive Video Generation"]}],["$","span","Humanoid Synthesis",{"className":"page__taxonomy-item","children":["#","Humanoid Synthesis"]}],["$","span","Real-time",{"className":"page__taxonomy-item","children":["#","Real-time"]}],["$","span","Streaming Diffusion",{"className":"page__taxonomy-item","children":["#","Streaming Diffusion"]}],["$","span","MMDiT",{"className":"page__taxonomy-item","children":["#","MMDiT"]}],["$","span","Temporal Consistency",{"className":"page__taxonomy-item","children":["#","Temporal Consistency"]}],["$","span","Multimodal Control",{"className":"page__taxonomy-item","children":["#","Multimodal Control"]}],["$","span","Low Latency",{"className":"page__taxonomy-item","children":["#","Low Latency"]}]]]}]}],["$","$La",null,{"postPermalink":"/ai/review/2026-01-16-FlowAct-R1-Towards-Interactive-Humanoid-Video-Generation/","postId":"2026-01-16-FlowAct-R1-Towards-Interactive-Humanoid-Video-Generation"}],["$","section",null,{"className":"mt-12 border-t border-gray-200 pt-8","children":[["$","h3",null,{"className":"text-base font-semibold text-gray-900 mb-4","children":["Review"," 의 다른글"]}],["$","ul",null,{"className":"space-y-2 text-sm","children":[["$","li",null,{"className":"text-gray-500","children":["이전글"," ",["$","$L7",null,{"href":"/ai/review/2026-01-16-EvasionBench-Detecting-Evasive-Answers-in-Financial-QA-via-Multi-Model-Consensus-and-LLM-as-Judge/","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] EvasionBench: Detecting Evasive Answers in Financial Q&A via Multi-Model Consensus and LLM-as-Judge"}]]}],["$","li",null,{"className":"text-gray-900 font-semibold","children":["현재글 : ","[논문리뷰] FlowAct-R1: Towards Interactive Humanoid Video Generation"]}],["$","li",null,{"className":"text-gray-500","children":["다음글"," ",["$","$L7",null,{"href":"/ai/review/2026-01-16-LSRIF-Logic-Structured-Reinforcement-Learning-for-Instruction-Following/","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] LSRIF: Logic-Structured Reinforcement Learning for Instruction Following"}]]}]]}]]}]]}]}]]}]
8:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"secrett2633's blog"}],["$","meta","3",{"name":"description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","meta","4",{"name":"author","content":"secrett2633"}],["$","meta","5",{"name":"keywords","content":"Django, Python, DevOps, AI, ML, 블로그, 기술"}],["$","meta","6",{"name":"creator","content":"secrett2633"}],["$","meta","7",{"name":"publisher","content":"secrett2633"}],["$","meta","8",{"name":"robots","content":"index, follow"}],["$","meta","9",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","10",{"rel":"canonical","href":"https://blog.secrett2633.cloud/"}],["$","meta","11",{"name":"format-detection","content":"telephone=no, address=no, email=no"}],["$","meta","12",{"property":"og:title","content":"secrett2633's blog"}],["$","meta","13",{"property":"og:description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","meta","14",{"property":"og:url","content":"https://blog.secrett2633.cloud/"}],["$","meta","15",{"property":"og:site_name","content":"secrett2633's blog"}],["$","meta","16",{"property":"og:locale","content":"ko_KR"}],["$","meta","17",{"property":"og:type","content":"website"}],["$","meta","18",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","19",{"name":"twitter:title","content":"secrett2633's blog"}],["$","meta","20",{"name":"twitter:description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","link","21",{"rel":"icon","href":"/icon.ico?6d9f34d4948640b8","type":"image/x-icon","sizes":"16x16"}],["$","meta","22",{"name":"next-size-adjust"}]]
1:null
