<!DOCTYPE html><html lang="ko" class="no-js"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/edb8d4ad4fe2f3b0.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-90b03762f46d1ba4.js"/><script src="/_next/static/chunks/fd9d1056-4b0d66bdf1ba1813.js" async=""></script><script src="/_next/static/chunks/23-41c976638cd1a58c.js" async=""></script><script src="/_next/static/chunks/main-app-6087bc228fd56b83.js" async=""></script><script src="/_next/static/chunks/231-ee5764c1002761f9.js" async=""></script><script src="/_next/static/chunks/132-273e49420772df1e.js" async=""></script><script src="/_next/static/chunks/app/layout-d443cbc354279241.js" async=""></script><script src="/_next/static/chunks/app/%5B...slug%5D/page-ef33f0f4c1a350bd.js" async=""></script><link rel="preload" href="https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY" as="script"/><title>[논문리뷰] PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model - secrett2633&#x27;s blog</title><meta name="description" content="arXiv에 게시된 &#x27;PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model&#x27; 논문에 대한 자세한 리뷰입니다."/><meta name="author" content="secrett2633"/><link rel="manifest" href="/manifest.json" crossorigin="use-credentials"/><meta name="keywords" content="Django, Python, DevOps, AI, ML, 블로그, 기술"/><meta name="creator" content="secrett2633"/><meta name="publisher" content="secrett2633"/><meta name="robots" content="index, follow"/><meta name="googlebot" content="index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"/><link rel="canonical" href="https://blog.secrett2633.cloud/ai/review/2025-10-17-PaddleOCR-VL-Boosting-Multilingual-Document-Parsing-via-a-0-9B-Ultra-Compact-Vision-Language-Model"/><meta name="format-detection" content="telephone=no, address=no, email=no"/><meta property="og:title" content="[논문리뷰] PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model"/><meta property="og:description" content="arXiv에 게시된 &#x27;PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model&#x27; 논문에 대한 자세한 리뷰입니다."/><meta property="og:url" content="https://blog.secrett2633.cloud/ai/review/2025-10-17-PaddleOCR-VL-Boosting-Multilingual-Document-Parsing-via-a-0-9B-Ultra-Compact-Vision-Language-Model"/><meta property="og:type" content="article"/><meta property="article:published_time" content="2025-10-17T04:09:57.000Z"/><meta property="article:modified_time" content="2025-10-17T04:09:57.000Z"/><meta property="article:author" content="secrett2633"/><meta property="article:section" content="Review"/><meta property="article:tag" content="Review"/><meta property="article:tag" content="Document Parsing"/><meta property="article:tag" content="Vision-Language Model"/><meta property="article:tag" content="Multilingual OCR"/><meta property="article:tag" content="Layout Analysis"/><meta property="article:tag" content="Resource-Efficient AI"/><meta property="article:tag" content="Table Recognition"/><meta property="article:tag" content="Formula Recognition"/><meta property="article:tag" content="Chart Recognition"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:creator" content="@secrett2633"/><meta name="twitter:title" content="[논문리뷰] PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model"/><meta name="twitter:description" content="arXiv에 게시된 &#x27;PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model&#x27; 논문에 대한 자세한 리뷰입니다."/><link rel="icon" href="/icon.ico?6d9f34d4948640b8" type="image/x-icon" sizes="16x16"/><meta name="next-size-adjust"/><meta name="msapplication-TileColor" content="#ffc40d"/><meta name="theme-color" content="#ffffff"/><link rel="dns-prefetch" href="https://www.googletagmanager.com"/><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"/><link rel="dns-prefetch" href="https://giscus.app"/><link rel="preconnect" href="https://giscus.app" crossorigin="anonymous"/><meta http-equiv="X-Content-Type-Options" content="nosniff"/><meta name="referrer" content="strict-origin-when-cross-origin"/><script type="application/ld+json">{"@context":"https://schema.org","@type":"WebSite","name":"secrett2633's blog","url":"https://blog.secrett2633.cloud","description":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트","inLanguage":"ko","publisher":{"@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud"}}</script><script type="application/ld+json">{"@context":"https://schema.org","@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud","sameAs":["https://github.com/secrett2633"]}</script><script src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body class="__className_f367f3 layout--default"><a href="#main-content" class="sr-only focus:not-sr-only focus:absolute focus:z-50 focus:p-4 focus:bg-white focus:text-blue-600">본문으로 건너뛰기</a><div class="min-h-screen bg-gray-50"><div class="masthead"><div class="masthead__inner-wrap"><div class="masthead__menu"><nav id="site-nav" class="greedy-nav" aria-label="메인 네비게이션"><a class="site-title" href="/">secrett2633&#x27;s blog</a><div class="flex items-center space-x-4"><ul class="visible-links"><li class="masthead__menu-item"><a href="https://github.com/secrett2633" target="_blank" rel="noopener noreferrer">GitHub</a></li></ul><button class="search__toggle" type="button" aria-label="검색"><svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16"><path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path></svg></button></div></nav></div></div></div><main id="main-content" class="initial-content"><!--$--><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","headline":"[논문리뷰] PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model","description":"arXiv에 게시된 'PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model' 논문에 대한 자세한 리뷰입니다.","url":"https://blog.secrett2633.cloud/ai/review/2025-10-17-PaddleOCR-VL-Boosting-Multilingual-Document-Parsing-via-a-0-9B-Ultra-Compact-Vision-Language-Model","datePublished":"2025-10-17T04:09:57.000Z","dateModified":"2025-10-17T04:09:57.000Z","author":{"@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud"},"publisher":{"@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.secrett2633.cloud/ai/review/2025-10-17-PaddleOCR-VL-Boosting-Multilingual-Document-Parsing-via-a-0-9B-Ultra-Compact-Vision-Language-Model"},"image":"https://blog.secrett2633.cloud/og-default.png","isAccessibleForFree":true,"inLanguage":"ko","wordCount":306,"articleSection":"Review","keywords":"Review, Document Parsing, Vision-Language Model, Multilingual OCR, Layout Analysis, Resource-Efficient AI, Table Recognition, Formula Recognition, Chart Recognition"}</script><script type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"홈","item":"https://blog.secrett2633.cloud/"},{"@type":"ListItem","position":2,"name":"Review","item":"https://blog.secrett2633.cloud/ai/review"},{"@type":"ListItem","position":3,"name":"[논문리뷰] PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model","item":"https://blog.secrett2633.cloud/ai/review/2025-10-17-PaddleOCR-VL-Boosting-Multilingual-Document-Parsing-via-a-0-9B-Ultra-Compact-Vision-Language-Model"}]}</script><div class="space-y-6"><div class="flex flex-col lg:flex-row gap-8"><aside class="lg:w-64 xl:w-72 order-1 lg:order-none"><div class="sidebar sticky"><nav class="space-y-4" aria-label="카테고리 네비게이션"><div><p class="font-medium text-gray-900 mb-2">Backend</p><ul class="space-y-1 ml-4"><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/backend/django">Django<!-- --> (<!-- -->6<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/backend/logging">Logging<!-- --> (<!-- -->1<!-- -->)</a></li></ul></div><div><p class="font-medium text-gray-900 mb-2">Python</p><ul class="space-y-1 ml-4"><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/python/pep">PEP<!-- --> (<!-- -->650<!-- -->)</a></li></ul></div><div><p class="font-medium text-gray-900 mb-2">AI/ML</p><ul class="space-y-1 ml-4"><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/ai/llm">LLM<!-- --> (<!-- -->1<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/ai/review">Review<!-- --> (<!-- -->2741<!-- -->)</a></li></ul></div><div><p class="font-medium text-gray-900 mb-2">DevOps</p><ul class="space-y-1 ml-4"><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/devops/nginx">Nginx<!-- --> (<!-- -->1<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/devops/docker">Docker<!-- --> (<!-- -->1<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/devops/safeline">SafeLine<!-- --> (<!-- -->1<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/devops/jenkins">Jenkins<!-- --> (<!-- -->3<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/devops/github-actions">GitHub Actions<!-- --> (<!-- -->1<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/devops/aws">AWS<!-- --> (<!-- -->1<!-- -->)</a></li></ul></div><div><p class="font-medium text-gray-900 mb-2">etc</p><ul class="space-y-1 ml-4"><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/etc/me">Me<!-- --> (<!-- -->3<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/etc/chrome-extension">Chrome Extension<!-- --> (<!-- -->1<!-- -->)</a></li></ul></div></nav></div></aside><div class="flex-1"><nav aria-label="breadcrumb" class="text-sm text-gray-500 mb-4"><ol class="flex flex-wrap items-center gap-1"><li><a class="hover:text-gray-700" href="/">홈</a></li><li class="flex items-center gap-1"><span aria-hidden="true">/</span><a class="hover:text-gray-700" href="/ai/review">Review</a></li><li class="flex items-center gap-1"><span aria-hidden="true">/</span><span class="text-gray-900" aria-current="page">[논문리뷰] PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model</span></li></ol></nav><article class="page"><header class="mb-8"><h1 class="page__title">[논문리뷰] PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model</h1><div class="page__meta"><time dateTime="2025-10-17 13:09:57+0900">2025년 10월 17일</time><time class="ml-4" dateTime="2025-10-17T04:09:57.000Z">수정: <!-- -->2025년 10월 17일</time></div></header><div class="page__content"><div><blockquote>
<p><strong>링크:</strong> <a href="https://arxiv.org/abs/2510.14528" target="_blank" rel="noopener noreferrer">논문 PDF로 바로 열기</a></p>
</blockquote>
<p><strong>저자:</strong> Cheng Cui, Ting Sun, Suyin Liang, Tingquan Gao, Zelun Zhang, Jiaxuan Liu, Xueqing Wang, Changda Zhou, Hongen Liu, Manhui Lin, Yue Zhang, Yubo Zhang, Handong Zheng, Jing Zhang, Jun Zhang, Yi Liu, Dianhai Yu, Yanjun Ma</p>
<h2 id="핵심-연구-목표"><a href="#핵심-연구-목표">핵심 연구 목표</a></h2>
<p>본 논문은 다국어 문서 파싱을 위한 <strong>SOTA(State-of-the-Art)</strong> 및 <strong>자원 효율적인</strong> 모델인 PaddleOCR-VL을 개발하는 것을 목표로 합니다. 복잡한 문서 요소(텍스트, 표, 수식, 차트)를 <strong>109개 언어</strong> 로 정확하게 인식하면서도 최소한의 자원 소비와 빠른 추론 속도를 유지하는 것을 주된 연구 목적으로 삼습니다.</p>
<h2 id="핵심-방법론"><a href="#핵심-방법론">핵심 방법론</a></h2>
<p>PaddleOCR-VL은 두 단계로 구성된 아키텍처를 사용합니다. 첫 번째 단계인 <strong>PP-DocLayoutV2</strong> 는 <strong>RT-DETR 기반 객체 탐지 모델</strong> 과 <strong>포인터 네트워크(18)</strong> 를 활용하여 레이아웃 분석 및 읽기 순서 예측을 수행합니다. 두 번째 단계인 <strong>PaddleOCR-VL-0.9B</strong> 는 <strong>NaViT 스타일 동적 고해상도 시각 인코더(15)</strong> 와 경량 <strong>ERNIE-4.5-0.3B 언어 모델(5)</strong> 을 통합한 소형 <strong>비전-언어 모델(VLM)</strong> 로, 세분화된 요소 인식을 담당합니다. 모델 훈련에는 대규모 모델을 통한 자동 주석 및 데이터 합성을 통해 구축된 <strong>3천만 개의 고품질 훈련 샘플</strong> 이 활용되었습니다.</p>
<h2 id="주요-결과"><a href="#주요-결과">주요 결과</a></h2>
<p>PaddleOCR-VL은 <strong>OmniDocBench v1.5</strong> 에서 <strong>전체 점수 92.56</strong> 를 달성하며 <strong>SOTA 성능</strong> 를 입증했으며, 이는 다음으로 우수한 모델인 <strong>MinerU2.5-1.2B(90.67)</strong> 를 능가하는 수치입니다. 특히, <strong>최저 텍스트-편집 거리 0.035</strong> , <strong>최고 수식-CDM 점수 91.43</strong> , 그리고 표-TEDS 및 읽기 순서 편집에서 선두적인 점수를 기록했습니다. 추론 성능 면에서는 <strong>A100 GPU</strong> 에서 MinerU2.5 대비 <strong>페이지 처리량 15.8%</strong> , <strong>토큰 처리량 14.2% 향상</strong> 을 보여주며 뛰어난 효율성을 입증했습니다.</p>
<h2 id="ai-실무자를-위한-시사점"><a href="#ai-실무자를-위한-시사점">AI 실무자를 위한 시사점</a></h2>
<p>PaddleOCR-VL은 복잡하고 다양한 언어로 구성된 문서를 효율적으로 처리해야 하는 <strong>AI/ML 엔지니어</strong> 및 <strong>데이터 사이언티스트</strong> 에게 매우 실용적인 솔루션을 제공합니다. <strong>0.9B 규모의 초소형 VLM</strong> 이 <strong>SOTA 성능</strong> 를 달성했다는 점은 <strong>자원 제약적인 환경</strong> 에서의 문서 파싱 애플리케이션 개발에 중요한 시사점을 줍니다. 특히 <strong>109개 언어를 지원</strong> 하는 광범위한 다국어 역량과 <strong>빠른 추론 속도</strong> , <strong>낮은 GPU 메모리 사용량</strong> 은 실제 서비스 배포 및 <strong>RAG(Retrieval-Augmented Generation) 시스템</strong> 의 정보 추출 효율성 향상에 크게 기여할 수 있습니다.</p>
<blockquote>
<p>⚠️ <strong>알림:</strong> 이 리뷰는 AI로 작성되었습니다.</p>
</blockquote>
</div></div><footer class="page__meta mt-8"><div class="page__taxonomy"><span class="text-sm font-medium text-gray-900 mb-2 block">태그</span><a class="page__taxonomy-item" href="/tags/Review">#<!-- -->Review</a><a class="page__taxonomy-item" href="/tags/Document%20Parsing">#<!-- -->Document Parsing</a><a class="page__taxonomy-item" href="/tags/Vision-Language%20Model">#<!-- -->Vision-Language Model</a><a class="page__taxonomy-item" href="/tags/Multilingual%20OCR">#<!-- -->Multilingual OCR</a><a class="page__taxonomy-item" href="/tags/Layout%20Analysis">#<!-- -->Layout Analysis</a><a class="page__taxonomy-item" href="/tags/Resource-Efficient%20AI">#<!-- -->Resource-Efficient AI</a><a class="page__taxonomy-item" href="/tags/Table%20Recognition">#<!-- -->Table Recognition</a><a class="page__taxonomy-item" href="/tags/Formula%20Recognition">#<!-- -->Formula Recognition</a><a class="page__taxonomy-item" href="/tags/Chart%20Recognition">#<!-- -->Chart Recognition</a></div></footer><section class="comments-section mt-12 pt-8 border-t border-gray-200"></section><section class="mt-12 border-t border-gray-200 pt-8"><h3 class="text-base font-semibold text-gray-900 mb-4">Review<!-- --> 의 다른글</h3><ul class="space-y-2 text-sm"><li class="text-gray-500">이전글<!-- --> <a class="text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4" href="/ai/review/2025-10-17-On-Pretraining-for-Project-Level-Code-Completion">[논문리뷰] On Pretraining for Project-Level Code Completion</a></li><li class="text-gray-900 font-semibold">현재글 : <!-- -->[논문리뷰] PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model</li><li class="text-gray-500">다음글<!-- --> <a class="text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4" href="/ai/review/2025-10-17-Ponimator-Unfolding-Interactive-Pose-for-Versatile-Human-human-Interaction-Animation">[논문리뷰] Ponimator: Unfolding Interactive Pose for Versatile Human-human Interaction Animation</a></li></ul></section></article></div></div></div><!--/$--></main><div id="footer" class="page__footer"><footer class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8"><div class="text-center text-gray-500 text-sm"><p>© <!-- -->2026<!-- --> secrett2633. All rights reserved.</p></div></footer></div></div><script src="/_next/static/chunks/webpack-90b03762f46d1ba4.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/media/e4af272ccee01ff0-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n2:HL[\"/_next/static/css/edb8d4ad4fe2f3b0.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"3:I[5751,[],\"\"]\n6:I[9275,[],\"\"]\n8:I[1343,[],\"\"]\n9:I[9157,[\"231\",\"static/chunks/231-ee5764c1002761f9.js\",\"132\",\"static/chunks/132-273e49420772df1e.js\",\"185\",\"static/chunks/app/layout-d443cbc354279241.js\"],\"default\"]\na:I[231,[\"231\",\"static/chunks/231-ee5764c1002761f9.js\",\"877\",\"static/chunks/app/%5B...slug%5D/page-ef33f0f4c1a350bd.js\"],\"\"]\nb:I[4080,[\"231\",\"static/chunks/231-ee5764c1002761f9.js\",\"132\",\"static/chunks/132-273e49420772df1e.js\",\"185\",\"static/chunks/app/layout-d443cbc354279241.js\"],\"\"]\nd:I[6130,[],\"\"]\n7:[\"slug\",\"ai/review/2025-10-17-PaddleOCR-VL-Boosting-Multilingual-Document-Parsing-via-a-0-9B-Ultra-Compact-Vision-Language-Model\",\"c\"]\ne:[]\n"])</script><script>self.__next_f.push([1,"0:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/edb8d4ad4fe2f3b0.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L3\",null,{\"buildId\":\"mJI0q5Z-SQWBtT83kG_N7\",\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/ai/review/2025-10-17-PaddleOCR-VL-Boosting-Multilingual-Document-Parsing-via-a-0-9B-Ultra-Compact-Vision-Language-Model\",\"initialTree\":[\"\",{\"children\":[[\"slug\",\"ai/review/2025-10-17-PaddleOCR-VL-Boosting-Multilingual-Document-Parsing-via-a-0-9B-Ultra-Compact-Vision-Language-Model\",\"c\"],{\"children\":[\"__PAGE__?{\\\"slug\\\":[\\\"ai\\\",\\\"review\\\",\\\"2025-10-17-PaddleOCR-VL-Boosting-Multilingual-Document-Parsing-via-a-0-9B-Ultra-Compact-Vision-Language-Model\\\"]}\",{}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[[\"slug\",\"ai/review/2025-10-17-PaddleOCR-VL-Boosting-Multilingual-Document-Parsing-via-a-0-9B-Ultra-Compact-Vision-Language-Model\",\"c\"],{\"children\":[\"__PAGE__\",{},[[\"$L4\",\"$L5\"],null],null]},[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"$7\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}],null]},[[\"$\",\"html\",null,{\"lang\":\"ko\",\"className\":\"no-js\",\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"meta\",null,{\"name\":\"msapplication-TileColor\",\"content\":\"#ffc40d\"}],[\"$\",\"meta\",null,{\"name\":\"theme-color\",\"content\":\"#ffffff\"}],[\"$\",\"link\",null,{\"rel\":\"dns-prefetch\",\"href\":\"https://www.googletagmanager.com\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://www.googletagmanager.com\",\"crossOrigin\":\"anonymous\"}],[\"$\",\"link\",null,{\"rel\":\"dns-prefetch\",\"href\":\"https://giscus.app\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://giscus.app\",\"crossOrigin\":\"anonymous\"}],[\"$\",\"meta\",null,{\"httpEquiv\":\"X-Content-Type-Options\",\"content\":\"nosniff\"}],[\"$\",\"meta\",null,{\"name\":\"referrer\",\"content\":\"strict-origin-when-cross-origin\"}],[\"$\",\"script\",null,{\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"{\\\"@context\\\":\\\"https://schema.org\\\",\\\"@type\\\":\\\"WebSite\\\",\\\"name\\\":\\\"secrett2633's blog\\\",\\\"url\\\":\\\"https://blog.secrett2633.cloud\\\",\\\"description\\\":\\\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\\\",\\\"inLanguage\\\":\\\"ko\\\",\\\"publisher\\\":{\\\"@type\\\":\\\"Person\\\",\\\"name\\\":\\\"secrett2633\\\",\\\"url\\\":\\\"https://blog.secrett2633.cloud\\\"}}\"}}],[\"$\",\"script\",null,{\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"{\\\"@context\\\":\\\"https://schema.org\\\",\\\"@type\\\":\\\"Person\\\",\\\"name\\\":\\\"secrett2633\\\",\\\"url\\\":\\\"https://blog.secrett2633.cloud\\\",\\\"sameAs\\\":[\\\"https://github.com/secrett2633\\\"]}\"}}]]}],[\"$\",\"body\",null,{\"className\":\"__className_f367f3 layout--default\",\"children\":[[\"$\",\"a\",null,{\"href\":\"#main-content\",\"className\":\"sr-only focus:not-sr-only focus:absolute focus:z-50 focus:p-4 focus:bg-white focus:text-blue-600\",\"children\":\"본문으로 건너뛰기\"}],[\"$\",\"div\",null,{\"className\":\"min-h-screen bg-gray-50\",\"children\":[[\"$\",\"$L9\",null,{}],[\"$\",\"main\",null,{\"id\":\"main-content\",\"className\":\"initial-content\",\"children\":[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[\"$\",\"div\",null,{\"className\":\"min-h-screen flex items-center justify-center bg-gray-50\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-6xl font-bold text-primary-600 mb-4\",\"children\":\"404\"}],[\"$\",\"h2\",null,{\"className\":\"text-2xl font-semibold text-gray-900 mb-4\",\"children\":\"페이지를 찾을 수 없습니다\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-600 mb-8\",\"children\":\"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다.\"}],[\"$\",\"$La\",null,{\"href\":\"/\",\"className\":\"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors\",\"children\":\"홈으로 돌아가기\"}]]}]}],\"notFoundStyles\":[],\"styles\":null}]}],[\"$\",\"div\",null,{\"id\":\"footer\",\"className\":\"page__footer\",\"children\":[\"$\",\"footer\",null,{\"className\":\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"text-center text-gray-500 text-sm\",\"children\":[\"$\",\"p\",null,{\"children\":[\"© \",2026,\" secrett2633. All rights reserved.\"]}]}]}]}]]}],[\"$\",\"$Lb\",null,{\"src\":\"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY\",\"strategy\":\"afterInteractive\"}],[\"$\",\"$Lb\",null,{\"id\":\"gtag-init\",\"strategy\":\"afterInteractive\",\"children\":\"window.dataLayer = window.dataLayer || [];\\n            function gtag(){dataLayer.push(arguments);}\\n            gtag('js', new Date());\\n            gtag('config', 'G-NE2W3CFPNY');\"}]]}]]}],null],[[\"$\",\"div\",null,{\"className\":\"flex items-center justify-center min-h-screen\",\"role\":\"status\",\"aria-label\":\"로딩 중\",\"children\":[[\"$\",\"div\",null,{\"className\":\"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600\"}],[\"$\",\"span\",null,{\"className\":\"sr-only\",\"children\":\"로딩 중...\"}]]}],[],[]]],\"couldBeIntercepted\":false,\"initialHead\":[null,\"$Lc\"],\"globalErrorComponent\":\"$d\",\"missingSlots\":\"$We\"}]]\n"])</script><script>self.__next_f.push([1,"11:I[646,[\"231\",\"static/chunks/231-ee5764c1002761f9.js\",\"877\",\"static/chunks/app/%5B...slug%5D/page-ef33f0f4c1a350bd.js\"],\"default\"]\nf:T51a,{\"@context\":\"https://schema.org\",\"@type\":\"BlogPosting\",\"headline\":\"[논문리뷰] PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model\",\"description\":\"arXiv에 게시된 'PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model' 논문에 대한 자세한 리뷰입니다.\",\"url\":\"https://blog.secrett2633.cloud/ai/review/2025-10-17-PaddleOCR-VL-Boosting-Multilingual-Document-Parsing-via-a-0-9B-Ultra-Compact-Vision-Language-Model\",\"datePublished\":\"2025-10-17T04:09:57.000Z\",\"dateModified\":\"2025-10-17T04:09:57.000Z\",\"author\":{\"@type\":\"Person\",\"name\":\"secrett2633\",\"url\":\"https://blog.secrett2633.cloud\"},\"publisher\":{\"@type\":\"Person\",\"name\":\"secrett2633\",\"url\":\"https://blog.secrett2633.cloud\"},\"mainEntityOfPage\":{\"@type\":\"WebPage\",\"@id\":\"https://blog.secrett2633.cloud/ai/review/2025-10-17-PaddleOCR-VL-Boosting-Multilingual-Document-Parsing-via-a-0-9B-Ultra-Compact-Vision-Language-Model\"},\"image\":\"https://blog.secrett2633.cloud/og-default.png\",\"isAccessibleForFree\":true,\"inLanguage\":\"ko\",\"wordCount\":306,\"articleSection\":\"Review\",\"keywords\":\"Review, Document Parsing, Vision-Language Model, Multilingual OCR, Layout Analysis, Resource-Efficient AI, Table Recognition, Formula Recognition, Chart Recognition\"}10:Te86,"])</script><script>self.__next_f.push([1,"\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e링크:\u003c/strong\u003e \u003ca href=\"https://arxiv.org/abs/2510.14528\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e논문 PDF로 바로 열기\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003e저자:\u003c/strong\u003e Cheng Cui, Ting Sun, Suyin Liang, Tingquan Gao, Zelun Zhang, Jiaxuan Liu, Xueqing Wang, Changda Zhou, Hongen Liu, Manhui Lin, Yue Zhang, Yubo Zhang, Handong Zheng, Jing Zhang, Jun Zhang, Yi Liu, Dianhai Yu, Yanjun Ma\u003c/p\u003e\n\u003ch2 id=\"핵심-연구-목표\"\u003e\u003ca href=\"#핵심-연구-목표\"\u003e핵심 연구 목표\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003e본 논문은 다국어 문서 파싱을 위한 \u003cstrong\u003eSOTA(State-of-the-Art)\u003c/strong\u003e 및 \u003cstrong\u003e자원 효율적인\u003c/strong\u003e 모델인 PaddleOCR-VL을 개발하는 것을 목표로 합니다. 복잡한 문서 요소(텍스트, 표, 수식, 차트)를 \u003cstrong\u003e109개 언어\u003c/strong\u003e 로 정확하게 인식하면서도 최소한의 자원 소비와 빠른 추론 속도를 유지하는 것을 주된 연구 목적으로 삼습니다.\u003c/p\u003e\n\u003ch2 id=\"핵심-방법론\"\u003e\u003ca href=\"#핵심-방법론\"\u003e핵심 방법론\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003ePaddleOCR-VL은 두 단계로 구성된 아키텍처를 사용합니다. 첫 번째 단계인 \u003cstrong\u003ePP-DocLayoutV2\u003c/strong\u003e 는 \u003cstrong\u003eRT-DETR 기반 객체 탐지 모델\u003c/strong\u003e 과 \u003cstrong\u003e포인터 네트워크(18)\u003c/strong\u003e 를 활용하여 레이아웃 분석 및 읽기 순서 예측을 수행합니다. 두 번째 단계인 \u003cstrong\u003ePaddleOCR-VL-0.9B\u003c/strong\u003e 는 \u003cstrong\u003eNaViT 스타일 동적 고해상도 시각 인코더(15)\u003c/strong\u003e 와 경량 \u003cstrong\u003eERNIE-4.5-0.3B 언어 모델(5)\u003c/strong\u003e 을 통합한 소형 \u003cstrong\u003e비전-언어 모델(VLM)\u003c/strong\u003e 로, 세분화된 요소 인식을 담당합니다. 모델 훈련에는 대규모 모델을 통한 자동 주석 및 데이터 합성을 통해 구축된 \u003cstrong\u003e3천만 개의 고품질 훈련 샘플\u003c/strong\u003e 이 활용되었습니다.\u003c/p\u003e\n\u003ch2 id=\"주요-결과\"\u003e\u003ca href=\"#주요-결과\"\u003e주요 결과\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003ePaddleOCR-VL은 \u003cstrong\u003eOmniDocBench v1.5\u003c/strong\u003e 에서 \u003cstrong\u003e전체 점수 92.56\u003c/strong\u003e 를 달성하며 \u003cstrong\u003eSOTA 성능\u003c/strong\u003e 를 입증했으며, 이는 다음으로 우수한 모델인 \u003cstrong\u003eMinerU2.5-1.2B(90.67)\u003c/strong\u003e 를 능가하는 수치입니다. 특히, \u003cstrong\u003e최저 텍스트-편집 거리 0.035\u003c/strong\u003e , \u003cstrong\u003e최고 수식-CDM 점수 91.43\u003c/strong\u003e , 그리고 표-TEDS 및 읽기 순서 편집에서 선두적인 점수를 기록했습니다. 추론 성능 면에서는 \u003cstrong\u003eA100 GPU\u003c/strong\u003e 에서 MinerU2.5 대비 \u003cstrong\u003e페이지 처리량 15.8%\u003c/strong\u003e , \u003cstrong\u003e토큰 처리량 14.2% 향상\u003c/strong\u003e 을 보여주며 뛰어난 효율성을 입증했습니다.\u003c/p\u003e\n\u003ch2 id=\"ai-실무자를-위한-시사점\"\u003e\u003ca href=\"#ai-실무자를-위한-시사점\"\u003eAI 실무자를 위한 시사점\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003ePaddleOCR-VL은 복잡하고 다양한 언어로 구성된 문서를 효율적으로 처리해야 하는 \u003cstrong\u003eAI/ML 엔지니어\u003c/strong\u003e 및 \u003cstrong\u003e데이터 사이언티스트\u003c/strong\u003e 에게 매우 실용적인 솔루션을 제공합니다. \u003cstrong\u003e0.9B 규모의 초소형 VLM\u003c/strong\u003e 이 \u003cstrong\u003eSOTA 성능\u003c/strong\u003e 를 달성했다는 점은 \u003cstrong\u003e자원 제약적인 환경\u003c/strong\u003e 에서의 문서 파싱 애플리케이션 개발에 중요한 시사점을 줍니다. 특히 \u003cstrong\u003e109개 언어를 지원\u003c/strong\u003e 하는 광범위한 다국어 역량과 \u003cstrong\u003e빠른 추론 속도\u003c/strong\u003e , \u003cstrong\u003e낮은 GPU 메모리 사용량\u003c/strong\u003e 은 실제 서비스 배포 및 \u003cstrong\u003eRAG(Retrieval-Augmented Generation) 시스템\u003c/strong\u003e 의 정보 추출 효율성 향상에 크게 기여할 수 있습니다.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e⚠️ \u003cstrong\u003e알림:\u003c/strong\u003e 이 리뷰는 AI로 작성되었습니다.\u003c/p\u003e\n\u003c/blockquote\u003e\n"])</script><script>self.__next_f.push([1,"5:[[\"$\",\"script\",null,{\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"$f\"}}],[\"$\",\"script\",null,{\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"{\\\"@context\\\":\\\"https://schema.org\\\",\\\"@type\\\":\\\"BreadcrumbList\\\",\\\"itemListElement\\\":[{\\\"@type\\\":\\\"ListItem\\\",\\\"position\\\":1,\\\"name\\\":\\\"홈\\\",\\\"item\\\":\\\"https://blog.secrett2633.cloud/\\\"},{\\\"@type\\\":\\\"ListItem\\\",\\\"position\\\":2,\\\"name\\\":\\\"Review\\\",\\\"item\\\":\\\"https://blog.secrett2633.cloud/ai/review\\\"},{\\\"@type\\\":\\\"ListItem\\\",\\\"position\\\":3,\\\"name\\\":\\\"[논문리뷰] PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model\\\",\\\"item\\\":\\\"https://blog.secrett2633.cloud/ai/review/2025-10-17-PaddleOCR-VL-Boosting-Multilingual-Document-Parsing-via-a-0-9B-Ultra-Compact-Vision-Language-Model\\\"}]}\"}}],[\"$\",\"div\",null,{\"className\":\"space-y-6\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex flex-col lg:flex-row gap-8\",\"children\":[[\"$\",\"aside\",null,{\"className\":\"lg:w-64 xl:w-72 order-1 lg:order-none\",\"children\":[\"$\",\"div\",null,{\"className\":\"sidebar sticky\",\"children\":[\"$\",\"nav\",null,{\"className\":\"space-y-4\",\"aria-label\":\"카테고리 네비게이션\",\"children\":[[\"$\",\"div\",\"Backend\",{\"children\":[[\"$\",\"p\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"Backend\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"Django\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/backend/django\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Django\",\" (\",6,\")\"]}]}],[\"$\",\"li\",\"Logging\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/backend/logging\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Logging\",\" (\",1,\")\"]}]}]]}]]}],[\"$\",\"div\",\"Python\",{\"children\":[[\"$\",\"p\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"Python\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"PEP\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/python/pep\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"PEP\",\" (\",650,\")\"]}]}]]}]]}],[\"$\",\"div\",\"AI/ML\",{\"children\":[[\"$\",\"p\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"AI/ML\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"LLM\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/ai/llm\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"LLM\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"Review\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/ai/review\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Review\",\" (\",2741,\")\"]}]}]]}]]}],[\"$\",\"div\",\"DevOps\",{\"children\":[[\"$\",\"p\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"DevOps\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"Nginx\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/devops/nginx\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Nginx\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"Docker\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/devops/docker\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Docker\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"SafeLine\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/devops/safeline\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"SafeLine\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"Jenkins\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/devops/jenkins\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Jenkins\",\" (\",3,\")\"]}]}],[\"$\",\"li\",\"GitHub Actions\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/devops/github-actions\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"GitHub Actions\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"AWS\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/devops/aws\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"AWS\",\" (\",1,\")\"]}]}]]}]]}],[\"$\",\"div\",\"etc\",{\"children\":[[\"$\",\"p\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"etc\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"Me\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/etc/me\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Me\",\" (\",3,\")\"]}]}],[\"$\",\"li\",\"Chrome Extension\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/etc/chrome-extension\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Chrome Extension\",\" (\",1,\")\"]}]}]]}]]}]]}]}]}],[\"$\",\"div\",null,{\"className\":\"flex-1\",\"children\":[[\"$\",\"nav\",null,{\"aria-label\":\"breadcrumb\",\"className\":\"text-sm text-gray-500 mb-4\",\"children\":[\"$\",\"ol\",null,{\"className\":\"flex flex-wrap items-center gap-1\",\"children\":[[\"$\",\"li\",null,{\"children\":[\"$\",\"$La\",null,{\"href\":\"/\",\"className\":\"hover:text-gray-700\",\"children\":\"홈\"}]}],[[\"$\",\"li\",\"/ai/review\",{\"className\":\"flex items-center gap-1\",\"children\":[[\"$\",\"span\",null,{\"aria-hidden\":\"true\",\"children\":\"/\"}],[\"$\",\"$La\",null,{\"href\":\"/ai/review\",\"className\":\"hover:text-gray-700\",\"children\":\"Review\"}]]}],[\"$\",\"li\",\"/ai/review/2025-10-17-PaddleOCR-VL-Boosting-Multilingual-Document-Parsing-via-a-0-9B-Ultra-Compact-Vision-Language-Model\",{\"className\":\"flex items-center gap-1\",\"children\":[[\"$\",\"span\",null,{\"aria-hidden\":\"true\",\"children\":\"/\"}],[\"$\",\"span\",null,{\"className\":\"text-gray-900\",\"aria-current\":\"page\",\"children\":\"[논문리뷰] PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model\"}]]}]]]}]}],[\"$\",\"article\",null,{\"className\":\"page\",\"children\":[[\"$\",\"header\",null,{\"className\":\"mb-8\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"page__title\",\"children\":\"[논문리뷰] PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model\"}],[\"$\",\"div\",null,{\"className\":\"page__meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-17 13:09:57+0900\",\"children\":\"2025년 10월 17일\"}],[\"$\",\"time\",null,{\"className\":\"ml-4\",\"dateTime\":\"2025-10-17T04:09:57.000Z\",\"children\":[\"수정: \",\"2025년 10월 17일\"]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"page__content\",\"children\":[\"$\",\"div\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$10\"}}]}],[\"$\",\"footer\",null,{\"className\":\"page__meta mt-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"page__taxonomy\",\"children\":[[\"$\",\"span\",null,{\"className\":\"text-sm font-medium text-gray-900 mb-2 block\",\"children\":\"태그\"}],[[\"$\",\"$La\",\"Review\",{\"href\":\"/tags/Review\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"$La\",\"Document Parsing\",{\"href\":\"/tags/Document%20Parsing\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Document Parsing\"]}],[\"$\",\"$La\",\"Vision-Language Model\",{\"href\":\"/tags/Vision-Language%20Model\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Model\"]}],[\"$\",\"$La\",\"Multilingual OCR\",{\"href\":\"/tags/Multilingual%20OCR\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multilingual OCR\"]}],[\"$\",\"$La\",\"Layout Analysis\",{\"href\":\"/tags/Layout%20Analysis\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Layout Analysis\"]}],[\"$\",\"$La\",\"Resource-Efficient AI\",{\"href\":\"/tags/Resource-Efficient%20AI\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Resource-Efficient AI\"]}],[\"$\",\"$La\",\"Table Recognition\",{\"href\":\"/tags/Table%20Recognition\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Table Recognition\"]}],[\"$\",\"$La\",\"Formula Recognition\",{\"href\":\"/tags/Formula%20Recognition\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Formula Recognition\"]}],[\"$\",\"$La\",\"Chart Recognition\",{\"href\":\"/tags/Chart%20Recognition\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chart Recognition\"]}]]]}]}],[\"$\",\"$L11\",null,{\"postPermalink\":\"/ai/review/2025-10-17-PaddleOCR-VL-Boosting-Multilingual-Document-Parsing-via-a-0-9B-Ultra-Compact-Vision-Language-Model\",\"postId\":\"2025-10-17-PaddleOCR-VL-Boosting-Multilingual-Document-Parsing-via-a-0-9B-Ultra-Compact-Vision-Language-Model\"}],[\"$\",\"section\",null,{\"className\":\"mt-12 border-t border-gray-200 pt-8\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-base font-semibold text-gray-900 mb-4\",\"children\":[\"Review\",\" 의 다른글\"]}],[\"$\",\"ul\",null,{\"className\":\"space-y-2 text-sm\",\"children\":[[\"$\",\"li\",null,{\"className\":\"text-gray-500\",\"children\":[\"이전글\",\" \",[\"$\",\"$La\",null,{\"href\":\"/ai/review/2025-10-17-On-Pretraining-for-Project-Level-Code-Completion\",\"className\":\"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4\",\"children\":\"[논문리뷰] On Pretraining for Project-Level Code Completion\"}]]}],[\"$\",\"li\",null,{\"className\":\"text-gray-900 font-semibold\",\"children\":[\"현재글 : \",\"[논문리뷰] PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model\"]}],[\"$\",\"li\",null,{\"className\":\"text-gray-500\",\"children\":[\"다음글\",\" \",[\"$\",\"$La\",null,{\"href\":\"/ai/review/2025-10-17-Ponimator-Unfolding-Interactive-Pose-for-Versatile-Human-human-Interaction-Animation\",\"className\":\"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4\",\"children\":\"[논문리뷰] Ponimator: Unfolding Interactive Pose for Versatile Human-human Interaction Animation\"}]]}]]}]]}]]}]]}]]}]}]]\n"])</script><script>self.__next_f.push([1,"c:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"[논문리뷰] PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model - secrett2633's blog\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"arXiv에 게시된 'PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"meta\",\"4\",{\"name\":\"author\",\"content\":\"secrett2633\"}],[\"$\",\"link\",\"5\",{\"rel\":\"manifest\",\"href\":\"/manifest.json\",\"crossOrigin\":\"use-credentials\"}],[\"$\",\"meta\",\"6\",{\"name\":\"keywords\",\"content\":\"Django, Python, DevOps, AI, ML, 블로그, 기술\"}],[\"$\",\"meta\",\"7\",{\"name\":\"creator\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"8\",{\"name\":\"publisher\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"9\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"10\",{\"name\":\"googlebot\",\"content\":\"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1\"}],[\"$\",\"link\",\"11\",{\"rel\":\"canonical\",\"href\":\"https://blog.secrett2633.cloud/ai/review/2025-10-17-PaddleOCR-VL-Boosting-Multilingual-Document-Parsing-via-a-0-9B-Ultra-Compact-Vision-Language-Model\"}],[\"$\",\"meta\",\"12\",{\"name\":\"format-detection\",\"content\":\"telephone=no, address=no, email=no\"}],[\"$\",\"meta\",\"13\",{\"property\":\"og:title\",\"content\":\"[논문리뷰] PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model\"}],[\"$\",\"meta\",\"14\",{\"property\":\"og:description\",\"content\":\"arXiv에 게시된 'PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"meta\",\"15\",{\"property\":\"og:url\",\"content\":\"https://blog.secrett2633.cloud/ai/review/2025-10-17-PaddleOCR-VL-Boosting-Multilingual-Document-Parsing-via-a-0-9B-Ultra-Compact-Vision-Language-Model\"}],[\"$\",\"meta\",\"16\",{\"property\":\"og:type\",\"content\":\"article\"}],[\"$\",\"meta\",\"17\",{\"property\":\"article:published_time\",\"content\":\"2025-10-17T04:09:57.000Z\"}],[\"$\",\"meta\",\"18\",{\"property\":\"article:modified_time\",\"content\":\"2025-10-17T04:09:57.000Z\"}],[\"$\",\"meta\",\"19\",{\"property\":\"article:author\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"20\",{\"property\":\"article:section\",\"content\":\"Review\"}],[\"$\",\"meta\",\"21\",{\"property\":\"article:tag\",\"content\":\"Review\"}],[\"$\",\"meta\",\"22\",{\"property\":\"article:tag\",\"content\":\"Document Parsing\"}],[\"$\",\"meta\",\"23\",{\"property\":\"article:tag\",\"content\":\"Vision-Language Model\"}],[\"$\",\"meta\",\"24\",{\"property\":\"article:tag\",\"content\":\"Multilingual OCR\"}],[\"$\",\"meta\",\"25\",{\"property\":\"article:tag\",\"content\":\"Layout Analysis\"}],[\"$\",\"meta\",\"26\",{\"property\":\"article:tag\",\"content\":\"Resource-Efficient AI\"}],[\"$\",\"meta\",\"27\",{\"property\":\"article:tag\",\"content\":\"Table Recognition\"}],[\"$\",\"meta\",\"28\",{\"property\":\"article:tag\",\"content\":\"Formula Recognition\"}],[\"$\",\"meta\",\"29\",{\"property\":\"article:tag\",\"content\":\"Chart Recognition\"}],[\"$\",\"meta\",\"30\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"31\",{\"name\":\"twitter:creator\",\"content\":\"@secrett2633\"}],[\"$\",\"meta\",\"32\",{\"name\":\"twitter:title\",\"content\":\"[논문리뷰] PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model\"}],[\"$\",\"meta\",\"33\",{\"name\":\"twitter:description\",\"content\":\"arXiv에 게시된 'PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"link\",\"34\",{\"rel\":\"icon\",\"href\":\"/icon.ico?6d9f34d4948640b8\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}],[\"$\",\"meta\",\"35\",{\"name\":\"next-size-adjust\"}]]\n"])</script><script>self.__next_f.push([1,"4:null\n"])</script></body></html>