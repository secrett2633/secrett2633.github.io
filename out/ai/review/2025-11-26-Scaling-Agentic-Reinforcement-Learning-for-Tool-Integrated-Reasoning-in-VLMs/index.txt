3:I[9275,[],""]
5:I[1343,[],""]
6:I[9157,["231","static/chunks/231-c27e618569e042bc.js","157","static/chunks/157-add0e5976b965783.js","185","static/chunks/app/layout-b06e577e11976c7d.js"],"default"]
7:I[231,["231","static/chunks/231-c27e618569e042bc.js","877","static/chunks/app/%5B...slug%5D/page-9d772c571b4668c1.js"],""]
4:["slug","ai/review/2025-11-26-Scaling-Agentic-Reinforcement-Learning-for-Tool-Integrated-Reasoning-in-VLMs","c"]
0:["aOFrxA-GgCmLq_YHxEu_b",[[["",{"children":[["slug","ai/review/2025-11-26-Scaling-Agentic-Reinforcement-Learning-for-Tool-Integrated-Reasoning-in-VLMs","c"],{"children":["__PAGE__?{\"slug\":[\"ai\",\"review\",\"2025-11-26-Scaling-Agentic-Reinforcement-Learning-for-Tool-Integrated-Reasoning-in-VLMs\"]}",{}]}]},"$undefined","$undefined",true],["",{"children":[["slug","ai/review/2025-11-26-Scaling-Agentic-Reinforcement-Learning-for-Tool-Integrated-Reasoning-in-VLMs","c"],{"children":["__PAGE__",{},[["$L1","$L2"],null],null]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","$4","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},[["$","html",null,{"lang":"ko","className":"no-js","children":[["$","head",null,{"children":[["$","meta",null,{"name":"msapplication-TileColor","content":"#ffc40d"}],["$","meta",null,{"name":"theme-color","content":"#ffffff"}],["$","script",null,{"async":true,"src":"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY"}],["$","script",null,{"dangerouslySetInnerHTML":{"__html":"\n              window.dataLayer = window.dataLayer || [];\n              function gtag(){dataLayer.push(arguments);}\n              gtag('js', new Date());\n              gtag('config', 'G-NE2W3CFPNY');\n            "}}]]}],["$","body",null,{"className":"__className_f367f3 layout--default","children":["$","div",null,{"className":"min-h-screen bg-gray-50","children":[["$","$L6",null,{}],["$","main",null,{"className":"initial-content","children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","div",null,{"className":"min-h-screen flex items-center justify-center bg-gray-50","children":["$","div",null,{"className":"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center","children":[["$","h1",null,{"className":"text-6xl font-bold text-primary-600 mb-4","children":"404"}],["$","h2",null,{"className":"text-2xl font-semibold text-gray-900 mb-4","children":"페이지를 찾을 수 없습니다"}],["$","p",null,{"className":"text-gray-600 mb-8","children":"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다."}],["$","$L7",null,{"href":"/","className":"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors","children":"홈으로 돌아가기"}]]}]}],"notFoundStyles":[],"styles":null}]}],["$","div",null,{"id":"footer","className":"page__footer","children":["$","footer",null,{"className":"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8","children":["$","div",null,{"className":"text-center text-gray-500 text-sm","children":["$","p",null,{"children":"© 2025 secrett2633. All rights reserved."}]}]}]}]]}]}]]}],null],[["$","div",null,{"className":"flex items-center justify-center min-h-screen","children":["$","div",null,{"className":"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600"}]}],[],[]]],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/edf391eeca43d999.css","precedence":"next","crossOrigin":"$undefined"}]],[null,"$L8"]]]]]
9:Tbe1,<blockquote>
<p><strong>링크:</strong> <a href="https://arxiv.org/abs/2511.19773">논문 PDF로 바로 열기</a></p>
</blockquote>
<p><strong>저자:</strong> Meng Lu, Ran Xu, Yi Fang, Wenxuan Zhang, Yue Yu, Gaurav Srivastava, Yuchen Zhuang, Mohamed Elhoseiny, Charles Fleming, Carl Yang, Zhengzhong Tu, Guanghua Xiao, Yang Xie, Hanrui Wang, Di Jin, Wenqi Shi, Xuan Wang</p>
<h2>핵심 연구 목표</h2>
<p>본 연구는 VLM이 다단계 시각적 상호작용 및 효과적인 도구 통합 추론에서 겪는 한계를 해결하고자 합니다. 특히, 도구 선택, 호출 및 조율 능력이 부족한 기존 VLM의 문제를 극복하고, 확장 가능한 훈련 환경과 에이전트 학습 전략을 통해 VLM의 <strong>도구 통합 시각적 추론 능력</strong> 을 체계적으로 향상시키는 것을 목표로 합니다.</p>
<h2>핵심 방법론</h2>
<p>논문은 <strong>VISTA-Gym</strong> 이라는 확장 가능한 도구 통합 에이전트 훈련 환경을 제안하며, 7가지 다양한 멀티모달 추론 태스크와 26가지 시각 도구(예: <strong>GroundingDINO</strong> , <strong>ChartMoE</strong> , <strong>G-LLaVA</strong> )를 통합합니다. <strong>VISTA-R1</strong> 에이전트는 <strong>행동 복제(BC)</strong> 를 통한 초기 훈련과 <strong>Group Relative Policy Optimization (GRPO)</strong> 을 활용한 온라인 강화 학습의 <strong>2단계 프레임워크</strong> 로 훈련되어, 도구 사용 문법 및 추론을 학습하고 복잡한 시각적 문제를 해결하도록 설계되었습니다.</p>
<h2>주요 결과</h2>
<p><strong>VISTA-R1-8B</strong> 는 11개 VQA 벤치마크에서 기존 오픈소스 모델 대비 <strong>9.51%-18.72%</strong> 높은 성능을 달성하여 최첨단 결과를 보였습니다. 특히, 도구 없이도 <strong>2.03%-11.24%</strong> 의 개선을 보였으며, <strong>GPT-03</strong> 및 <strong>Claude-4.5-Sonnet</strong> 과 같은 대규모 상용 모델과 유사한 수준의 <strong>일반화 성능</strong> 을 입증했습니다. 이는 <strong>VISTA-Gym</strong> 이 VLM의 도구 통합 추론 능력을 개발하는 효과적인 훈련 환경임을 시사합니다.</p>
<h2>AI 실무자를 위한 시사점</h2>
<p><strong>VISTA-Gym</strong> 은 복잡한 시각적 추론 문제를 해결하는 <strong>도구 통합 에이전트 VLM</strong> 개발을 위한 강력하고 확장 가능한 훈련 환경을 제공합니다. AI 실무자들은 <strong>행동 복제(BC)와 온라인 강화 학습(RL)의 2단계 훈련 프레임워크</strong> 를 활용하여 VLM의 도구 사용 및 추론 능력을 체계적으로 개선할 수 있습니다. 또한, 다양한 태스크와 도구를 혼합한 훈련 및 <strong>Tail-Patch Curriculum</strong> 과 같은 난이도 적응형 학습 전략이 모델의 <strong>일반화 및 장기 추론 능력</strong> 향상에 중요함을 시사합니다.</p>
<blockquote>
<p>⚠️ <strong>알림:</strong> 이 리뷰는 AI로 작성되었습니다.</p>
</blockquote>
2:["$","div",null,{"className":"flex flex-col lg:flex-row gap-8","children":[["$","aside",null,{"className":"lg:w-64 xl:w-72 order-1 lg:order-none","children":["$","div",null,{"className":"sidebar sticky","children":["$","nav",null,{"className":"space-y-4","children":[["$","div","Backend",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"Backend"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Django",{"children":["$","a",null,{"href":"/backend/django/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Django"," (",6,")"]}]}],["$","li","Logging",{"children":["$","a",null,{"href":"/backend/logging/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Logging"," (",1,")"]}]}]]}]]}],["$","div","Python",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"Python"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","PEP",{"children":["$","a",null,{"href":"/python/pep/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["PEP"," (",650,")"]}]}]]}]]}],["$","div","AI/ML",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"AI/ML"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","LLM",{"children":["$","a",null,{"href":"/ai/llm/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["LLM"," (",1,")"]}]}],["$","li","Review",{"children":["$","a",null,{"href":"/ai/review/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Review"," (",1847,")"]}]}]]}]]}],["$","div","DevOps",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"DevOps"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Nginx",{"children":["$","a",null,{"href":"/devops/nginx/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Nginx"," (",1,")"]}]}],["$","li","Docker",{"children":["$","a",null,{"href":"/devops/docker/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Docker"," (",1,")"]}]}],["$","li","SafeLine",{"children":["$","a",null,{"href":"/devops/safeline/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["SafeLine"," (",1,")"]}]}],["$","li","Jenkins",{"children":["$","a",null,{"href":"/devops/jenkins/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Jenkins"," (",3,")"]}]}],["$","li","GitHub Actions",{"children":["$","a",null,{"href":"/devops/github-actions/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["GitHub Actions"," (",1,")"]}]}],["$","li","AWS",{"children":["$","a",null,{"href":"/devops/aws/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["AWS"," (",1,")"]}]}]]}]]}],["$","div","etc",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"etc"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Me",{"children":["$","a",null,{"href":"/etc/me/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Me"," (",3,")"]}]}],["$","li","Chrome Extension",{"children":["$","a",null,{"href":"/etc/chrome-extension/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Chrome Extension"," (",1,")"]}]}]]}]]}]]}]}]}],["$","main",null,{"className":"flex-1","children":["$","article",null,{"className":"page","children":[["$","header",null,{"className":"mb-8","children":[["$","h1",null,{"className":"page__title","children":"[논문리뷰] Scaling Agentic Reinforcement Learning for Tool-Integrated Reasoning in VLMs"}],["$","div",null,{"className":"page__meta","children":[["$","time",null,{"dateTime":"2025-11-26 00:00:00+0900+0900","children":"2025년 11월 26일"}],["$","span",null,{"className":"ml-4","children":["수정: ","2025년 11월 26일"]}]]}]]}],["$","div",null,{"className":"page__content","children":["$","div",null,{"dangerouslySetInnerHTML":{"__html":"$9"}}]}],["$","footer",null,{"className":"page__meta mt-8","children":["$","div",null,{"className":"page__taxonomy","children":[["$","h4",null,{"className":"text-sm font-medium text-gray-900 mb-2","children":"태그"}],[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision-Language Models (VLMs)"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Tool-Integrated Reasoning (TIR)",{"className":"page__taxonomy-item","children":["#","Tool-Integrated Reasoning (TIR)"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","VQA",{"className":"page__taxonomy-item","children":["#","VQA"]}],["$","span","Training Environment",{"className":"page__taxonomy-item","children":["#","Training Environment"]}],["$","span","Behavioral Cloning",{"className":"page__taxonomy-item","children":["#","Behavioral Cloning"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}]]]}]}],["$","section",null,{"className":"mt-12 border-t border-gray-200 pt-8","children":[["$","h3",null,{"className":"text-base font-semibold text-gray-900 mb-4","children":["Review"," 의 다른글"]}],["$","ul",null,{"className":"space-y-2 text-sm","children":[["$","li",null,{"className":"text-gray-500","children":["이전글"," ",["$","$L7",null,{"href":"/ai/review/2025-11-26-SSA-Sparse-Sparse-Attention-by-Aligning-Full-and-Sparse-Attention-Outputs-in-Feature-Space/","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] SSA: Sparse Sparse Attention by Aligning Full and Sparse Attention Outputs in Feature Space"}]]}],["$","li",null,{"className":"text-gray-900 font-semibold","children":["현재글 : ","[논문리뷰] Scaling Agentic Reinforcement Learning for Tool-Integrated Reasoning in VLMs"]}],["$","li",null,{"className":"text-gray-500","children":["다음글"," ",["$","$L7",null,{"href":"/ai/review/2025-11-26-SciEducator-Scientific-Video-Understanding-and-Educating-via-Deming-Cycle-Multi-Agent-System/","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] SciEducator: Scientific Video Understanding and Educating via Deming-Cycle Multi-Agent System"}]]}]]}]]}]]}]}]]}]
8:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"secrett2633's blog"}],["$","meta","3",{"name":"description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","meta","4",{"name":"author","content":"secrett2633"}],["$","meta","5",{"name":"keywords","content":"Django, Python, DevOps, AI, ML, 블로그, 기술"}],["$","meta","6",{"name":"creator","content":"secrett2633"}],["$","meta","7",{"name":"publisher","content":"secrett2633"}],["$","meta","8",{"name":"robots","content":"index, follow"}],["$","meta","9",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","10",{"rel":"canonical","href":"https://blog.secrett2633.site/"}],["$","meta","11",{"name":"format-detection","content":"telephone=no, address=no, email=no"}],["$","meta","12",{"property":"og:title","content":"secrett2633's blog"}],["$","meta","13",{"property":"og:description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","meta","14",{"property":"og:url","content":"https://blog.secrett2633.site/"}],["$","meta","15",{"property":"og:site_name","content":"secrett2633's blog"}],["$","meta","16",{"property":"og:locale","content":"ko_KR"}],["$","meta","17",{"property":"og:type","content":"website"}],["$","meta","18",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","19",{"name":"twitter:title","content":"secrett2633's blog"}],["$","meta","20",{"name":"twitter:description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","link","21",{"rel":"icon","href":"/icon.ico?6d9f34d4948640b8","type":"image/x-icon","sizes":"16x16"}],["$","meta","22",{"name":"next-size-adjust"}]]
1:null
