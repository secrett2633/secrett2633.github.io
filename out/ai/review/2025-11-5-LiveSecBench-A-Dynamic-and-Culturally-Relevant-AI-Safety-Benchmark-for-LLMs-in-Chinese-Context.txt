3:I[9275,[],""]
5:I[1343,[],""]
6:I[9157,["231","static/chunks/231-ee5764c1002761f9.js","132","static/chunks/132-273e49420772df1e.js","185","static/chunks/app/layout-d443cbc354279241.js"],"default"]
7:I[231,["231","static/chunks/231-ee5764c1002761f9.js","877","static/chunks/app/%5B...slug%5D/page-ef33f0f4c1a350bd.js"],""]
8:I[4080,["231","static/chunks/231-ee5764c1002761f9.js","132","static/chunks/132-273e49420772df1e.js","185","static/chunks/app/layout-d443cbc354279241.js"],""]
4:["slug","ai/review/2025-11-5-LiveSecBench-A-Dynamic-and-Culturally-Relevant-AI-Safety-Benchmark-for-LLMs-in-Chinese-Context","c"]
0:["mJI0q5Z-SQWBtT83kG_N7",[[["",{"children":[["slug","ai/review/2025-11-5-LiveSecBench-A-Dynamic-and-Culturally-Relevant-AI-Safety-Benchmark-for-LLMs-in-Chinese-Context","c"],{"children":["__PAGE__?{\"slug\":[\"ai\",\"review\",\"2025-11-5-LiveSecBench-A-Dynamic-and-Culturally-Relevant-AI-Safety-Benchmark-for-LLMs-in-Chinese-Context\"]}",{}]}]},"$undefined","$undefined",true],["",{"children":[["slug","ai/review/2025-11-5-LiveSecBench-A-Dynamic-and-Culturally-Relevant-AI-Safety-Benchmark-for-LLMs-in-Chinese-Context","c"],{"children":["__PAGE__",{},[["$L1","$L2"],null],null]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","$4","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},[["$","html",null,{"lang":"ko","className":"no-js","children":[["$","head",null,{"children":[["$","meta",null,{"name":"msapplication-TileColor","content":"#ffc40d"}],["$","meta",null,{"name":"theme-color","content":"#ffffff"}],["$","link",null,{"rel":"dns-prefetch","href":"https://www.googletagmanager.com"}],["$","link",null,{"rel":"preconnect","href":"https://www.googletagmanager.com","crossOrigin":"anonymous"}],["$","link",null,{"rel":"dns-prefetch","href":"https://giscus.app"}],["$","link",null,{"rel":"preconnect","href":"https://giscus.app","crossOrigin":"anonymous"}],["$","meta",null,{"httpEquiv":"X-Content-Type-Options","content":"nosniff"}],["$","meta",null,{"name":"referrer","content":"strict-origin-when-cross-origin"}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"WebSite\",\"name\":\"secrett2633's blog\",\"url\":\"https://blog.secrett2633.cloud\",\"description\":\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\",\"inLanguage\":\"ko\",\"publisher\":{\"@type\":\"Person\",\"name\":\"secrett2633\",\"url\":\"https://blog.secrett2633.cloud\"}}"}}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"Person\",\"name\":\"secrett2633\",\"url\":\"https://blog.secrett2633.cloud\",\"sameAs\":[\"https://github.com/secrett2633\"]}"}}]]}],["$","body",null,{"className":"__className_f367f3 layout--default","children":[["$","a",null,{"href":"#main-content","className":"sr-only focus:not-sr-only focus:absolute focus:z-50 focus:p-4 focus:bg-white focus:text-blue-600","children":"본문으로 건너뛰기"}],["$","div",null,{"className":"min-h-screen bg-gray-50","children":[["$","$L6",null,{}],["$","main",null,{"id":"main-content","className":"initial-content","children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","div",null,{"className":"min-h-screen flex items-center justify-center bg-gray-50","children":["$","div",null,{"className":"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center","children":[["$","h1",null,{"className":"text-6xl font-bold text-primary-600 mb-4","children":"404"}],["$","h2",null,{"className":"text-2xl font-semibold text-gray-900 mb-4","children":"페이지를 찾을 수 없습니다"}],["$","p",null,{"className":"text-gray-600 mb-8","children":"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다."}],["$","$L7",null,{"href":"/","className":"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors","children":"홈으로 돌아가기"}]]}]}],"notFoundStyles":[],"styles":null}]}],["$","div",null,{"id":"footer","className":"page__footer","children":["$","footer",null,{"className":"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8","children":["$","div",null,{"className":"text-center text-gray-500 text-sm","children":["$","p",null,{"children":["© ",2026," secrett2633. All rights reserved."]}]}]}]}]]}],["$","$L8",null,{"src":"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY","strategy":"afterInteractive"}],["$","$L8",null,{"id":"gtag-init","strategy":"afterInteractive","children":"window.dataLayer = window.dataLayer || [];\n            function gtag(){dataLayer.push(arguments);}\n            gtag('js', new Date());\n            gtag('config', 'G-NE2W3CFPNY');"}]]}]]}],null],[["$","div",null,{"className":"flex items-center justify-center min-h-screen","role":"status","aria-label":"로딩 중","children":[["$","div",null,{"className":"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600"}],["$","span",null,{"className":"sr-only","children":"로딩 중..."}]]}],[],[]]],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/edb8d4ad4fe2f3b0.css","precedence":"next","crossOrigin":"$undefined"}]],[null,"$L9"]]]]]
c:I[646,["231","static/chunks/231-ee5764c1002761f9.js","877","static/chunks/app/%5B...slug%5D/page-ef33f0f4c1a350bd.js"],"default"]
a:T500,{"@context":"https://schema.org","@type":"BlogPosting","headline":"[논문리뷰] LiveSecBench: A Dynamic and Culturally-Relevant AI Safety Benchmark for LLMs in Chinese Context","description":"Tianxin Zhang이 arXiv에 게시한 'LiveSecBench: A Dynamic and Culturally-Relevant AI Safety Benchmark for LLMs in Chinese Context' 논문에 대한 자세한 리뷰입니다.","url":"https://blog.secrett2633.cloud/ai/review/2025-11-5-LiveSecBench-A-Dynamic-and-Culturally-Relevant-AI-Safety-Benchmark-for-LLMs-in-Chinese-Context","datePublished":"2025-11-09T10:35:02.000Z","dateModified":"2025-11-09T10:35:02.000Z","author":{"@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud"},"publisher":{"@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.secrett2633.cloud/ai/review/2025-11-5-LiveSecBench-A-Dynamic-and-Culturally-Relevant-AI-Safety-Benchmark-for-LLMs-in-Chinese-Context"},"image":"https://blog.secrett2633.cloud/og-default.png","isAccessibleForFree":true,"inLanguage":"ko","wordCount":274,"articleSection":"Review","keywords":"Review, LLM Safety, AI Safety Benchmark, Chinese Context, Dynamic Evaluation, Cultural Relevance, Adversarial Robustness, ELO Rating System"}b:Tddb,<blockquote>
<p><strong>링크:</strong> <a href="https://arxiv.org/abs/2511.02366" target="_blank" rel="noopener noreferrer">논문 PDF로 바로 열기</a></p>
</blockquote>
<p><strong>저자:</strong> Yudong Li, Zhongliang Yang, Kejiang Chen, Wenxuan Wang, Tianxin Zhang, Sifang Wan, Kecheng Wang, Haitian Li, Xu Wang, Lefan Cheng, Youdan Yang, Baocheng Chen, Ziyu Liu, Yufei Sun, Liyan Wu, Wenya Wen, Xingchi Gu, Peiru Yang</p>
<h2 id="핵심-연구-목표"><a href="#핵심-연구-목표">핵심 연구 목표</a></h2>
<p>본 연구는 중국어 환경에서 대규모 언어 모델(LLMs)의 안전성 평가를 위한 <strong>동적(dynamic)</strong> 이며 <strong>문화적으로 적합한(culturally-relevant)</strong> 벤치마크인 <strong>LiveSecBench</strong> 를 제안하는 것을 목표로 합니다. 기존 영어 중심의 정적 벤치마크가 놓치기 쉬운 중국 특유의 법률, 윤리, 사회적 맥락 및 신종 위협을 포착하여 LLM 안전성 평가의 정확성과 관련성을 높이고자 합니다.</p>
<h2 id="핵심-방법론"><a href="#핵심-방법론">핵심 방법론</a></h2>
<p><strong>LiveSecBench</strong> 는 법률(Legality), 윤리(Ethics), 사실성(Factuality), 프라이버시(Privacy), 적대적 강건성(Adversarial Robustness), 추론 안전성(Reasoning Safety)의 <strong>여섯 가지 핵심 차원</strong> 에서 모델을 평가합니다. 평가 데이터셋은 중국어 화자가 직접 구성하여 문화적 적합성을 보장하며, <strong>ELO 레이팅 시스템</strong> 을 사용하여 모델 간의 <strong>일대일 비교(head-to-head)</strong> 기반 순위를 도출합니다. 또한, 새로운 위협 벡터를 반영하기 위해 <strong>정기적인 업데이트 스케줄</strong> 을 통해 벤치마크의 관련성을 유지합니다.</p>
<h2 id="주요-결과"><a href="#주요-결과">주요 결과</a></h2>
<p><strong>LiveSecBench (v251030)</strong> 는 현재까지 <strong>18개 LLM</strong> 에 대한 평가를 완료했으며, <strong>GPT-5-Mini</strong> 가 <strong>77.30점</strong> 으로 가장 높은 종합 점수를 기록했습니다. 각 차원별 세부 성능을 제공하며, 예를 들어 <strong>Claude-Haiku-4.5</strong> 는 추론 안전성(Reasoning Safety)에서 <strong>85.30%</strong> 의 높은 점수를 보였습니다. 이러한 결과는 중국어 환경에서 LLM 안전성 수준에 대한 포괄적인 현황을 제시하며, <strong><a href="https://livesecbench.intokentech.cn/" target="_blank" rel="noopener noreferrer">https://livesecbench.intokentech.cn/</a></strong> 에서 공개적으로 확인할 수 있습니다.</p>
<h2 id="ai-실무자를-위한-시사점"><a href="#ai-실무자를-위한-시사점">AI 실무자를 위한 시사점</a></h2>
<p><strong>LiveSecBench</strong> 는 AI 실무자들에게 중국어 시장을 위한 LLM을 개발하고 배포할 때 필수적인 안전성 평가 도구를 제공합니다. 특히 <strong>문화적 특수성</strong> 과 <strong>동적인 위협 환경</strong> 에 대한 깊이 있는 이해를 돕고, 모델의 특정 취약점을 식별하는 데 유용합니다. 향후 <strong>Text-to-Image 생성 안전성</strong> 및 <strong>Agentic 안전성</strong> 과 같은 새로운 평가 차원 추가 계획은 LLM의 확장된 응용 분야에 대한 안전성 고려 사항을 선제적으로 반영할 수 있도록 지원할 것입니다.</p>
<blockquote>
<p>⚠️ <strong>알림:</strong> 이 리뷰는 AI로 작성되었습니다.</p>
</blockquote>
2:[["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"$a"}}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"BreadcrumbList\",\"itemListElement\":[{\"@type\":\"ListItem\",\"position\":1,\"name\":\"홈\",\"item\":\"https://blog.secrett2633.cloud/\"},{\"@type\":\"ListItem\",\"position\":2,\"name\":\"Review\",\"item\":\"https://blog.secrett2633.cloud/ai/review\"},{\"@type\":\"ListItem\",\"position\":3,\"name\":\"[논문리뷰] LiveSecBench: A Dynamic and Culturally-Relevant AI Safety Benchmark for LLMs in Chinese Context\",\"item\":\"https://blog.secrett2633.cloud/ai/review/2025-11-5-LiveSecBench-A-Dynamic-and-Culturally-Relevant-AI-Safety-Benchmark-for-LLMs-in-Chinese-Context\"}]}"}}],["$","div",null,{"className":"space-y-6","children":["$","div",null,{"className":"flex flex-col lg:flex-row gap-8","children":[["$","aside",null,{"className":"lg:w-64 xl:w-72 order-1 lg:order-none","children":["$","div",null,{"className":"sidebar sticky","children":["$","nav",null,{"className":"space-y-4","aria-label":"카테고리 네비게이션","children":[["$","div","Backend",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"Backend"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Django",{"children":["$","$L7",null,{"href":"/backend/django","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Django"," (",6,")"]}]}],["$","li","Logging",{"children":["$","$L7",null,{"href":"/backend/logging","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Logging"," (",1,")"]}]}]]}]]}],["$","div","Python",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"Python"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","PEP",{"children":["$","$L7",null,{"href":"/python/pep","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["PEP"," (",650,")"]}]}]]}]]}],["$","div","AI/ML",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"AI/ML"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","LLM",{"children":["$","$L7",null,{"href":"/ai/llm","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["LLM"," (",1,")"]}]}],["$","li","Review",{"children":["$","$L7",null,{"href":"/ai/review","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Review"," (",2741,")"]}]}]]}]]}],["$","div","DevOps",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"DevOps"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Nginx",{"children":["$","$L7",null,{"href":"/devops/nginx","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Nginx"," (",1,")"]}]}],["$","li","Docker",{"children":["$","$L7",null,{"href":"/devops/docker","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Docker"," (",1,")"]}]}],["$","li","SafeLine",{"children":["$","$L7",null,{"href":"/devops/safeline","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["SafeLine"," (",1,")"]}]}],["$","li","Jenkins",{"children":["$","$L7",null,{"href":"/devops/jenkins","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Jenkins"," (",3,")"]}]}],["$","li","GitHub Actions",{"children":["$","$L7",null,{"href":"/devops/github-actions","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["GitHub Actions"," (",1,")"]}]}],["$","li","AWS",{"children":["$","$L7",null,{"href":"/devops/aws","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["AWS"," (",1,")"]}]}]]}]]}],["$","div","etc",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"etc"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Me",{"children":["$","$L7",null,{"href":"/etc/me","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Me"," (",3,")"]}]}],["$","li","Chrome Extension",{"children":["$","$L7",null,{"href":"/etc/chrome-extension","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Chrome Extension"," (",1,")"]}]}]]}]]}]]}]}]}],["$","div",null,{"className":"flex-1","children":[["$","nav",null,{"aria-label":"breadcrumb","className":"text-sm text-gray-500 mb-4","children":["$","ol",null,{"className":"flex flex-wrap items-center gap-1","children":[["$","li",null,{"children":["$","$L7",null,{"href":"/","className":"hover:text-gray-700","children":"홈"}]}],[["$","li","/ai/review",{"className":"flex items-center gap-1","children":[["$","span",null,{"aria-hidden":"true","children":"/"}],["$","$L7",null,{"href":"/ai/review","className":"hover:text-gray-700","children":"Review"}]]}],["$","li","/ai/review/2025-11-5-LiveSecBench-A-Dynamic-and-Culturally-Relevant-AI-Safety-Benchmark-for-LLMs-in-Chinese-Context",{"className":"flex items-center gap-1","children":[["$","span",null,{"aria-hidden":"true","children":"/"}],["$","span",null,{"className":"text-gray-900","aria-current":"page","children":"[논문리뷰] LiveSecBench: A Dynamic and Culturally-Relevant AI Safety Benchmark for LLMs in Chinese Context"}]]}]]]}]}],["$","article",null,{"className":"page","children":[["$","header",null,{"className":"mb-8","children":[["$","h1",null,{"className":"page__title","children":"[논문리뷰] LiveSecBench: A Dynamic and Culturally-Relevant AI Safety Benchmark for LLMs in Chinese Context"}],["$","div",null,{"className":"page__meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:35:02+0900","children":"2025년 11월 9일"}],["$","time",null,{"className":"ml-4","dateTime":"2025-11-09T10:35:02.000Z","children":["수정: ","2025년 11월 9일"]}]]}]]}],["$","div",null,{"className":"page__content","children":["$","div",null,{"dangerouslySetInnerHTML":{"__html":"$b"}}]}],["$","footer",null,{"className":"page__meta mt-8","children":["$","div",null,{"className":"page__taxonomy","children":[["$","span",null,{"className":"text-sm font-medium text-gray-900 mb-2 block","children":"태그"}],[["$","$L7","Review",{"href":"/tags/Review","className":"page__taxonomy-item","children":["#","Review"]}],["$","$L7","LLM Safety",{"href":"/tags/LLM%20Safety","className":"page__taxonomy-item","children":["#","LLM Safety"]}],["$","$L7","AI Safety Benchmark",{"href":"/tags/AI%20Safety%20Benchmark","className":"page__taxonomy-item","children":["#","AI Safety Benchmark"]}],["$","$L7","Chinese Context",{"href":"/tags/Chinese%20Context","className":"page__taxonomy-item","children":["#","Chinese Context"]}],["$","$L7","Dynamic Evaluation",{"href":"/tags/Dynamic%20Evaluation","className":"page__taxonomy-item","children":["#","Dynamic Evaluation"]}],["$","$L7","Cultural Relevance",{"href":"/tags/Cultural%20Relevance","className":"page__taxonomy-item","children":["#","Cultural Relevance"]}],["$","$L7","Adversarial Robustness",{"href":"/tags/Adversarial%20Robustness","className":"page__taxonomy-item","children":["#","Adversarial Robustness"]}],["$","$L7","ELO Rating System",{"href":"/tags/ELO%20Rating%20System","className":"page__taxonomy-item","children":["#","ELO Rating System"]}]]]}]}],["$","$Lc",null,{"postPermalink":"/ai/review/2025-11-5-LiveSecBench-A-Dynamic-and-Culturally-Relevant-AI-Safety-Benchmark-for-LLMs-in-Chinese-Context","postId":"2025-11-5-LiveSecBench-A-Dynamic-and-Culturally-Relevant-AI-Safety-Benchmark-for-LLMs-in-Chinese-Context"}],["$","section",null,{"className":"mt-12 border-t border-gray-200 pt-8","children":[["$","h3",null,{"className":"text-base font-semibold text-gray-900 mb-4","children":["Review"," 의 다른글"]}],["$","ul",null,{"className":"space-y-2 text-sm","children":[["$","li",null,{"className":"text-gray-500","children":["이전글"," ",["$","$L7",null,{"href":"/ai/review/2025-11-5-LTD-Bench-Evaluating-Large-Language-Models-by-Letting-Them-Draw","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] LTD-Bench: Evaluating Large Language Models by Letting Them Draw"}]]}],["$","li",null,{"className":"text-gray-900 font-semibold","children":["현재글 : ","[논문리뷰] LiveSecBench: A Dynamic and Culturally-Relevant AI Safety Benchmark for LLMs in Chinese Context"]}],["$","li",null,{"className":"text-gray-500","children":["다음글"," ",["$","$L7",null,{"href":"/ai/review/2025-11-5-Reg-DPO-SFT-Regularized-Direct-Preference-Optimization-with-GT-Pair-for-Improving-Video-Generation","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] Reg-DPO: SFT-Regularized Direct Preference Optimization with GT-Pair for Improving Video Generation"}]]}]]}]]}]]}]]}]]}]}]]
9:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"[논문리뷰] LiveSecBench: A Dynamic and Culturally-Relevant AI Safety Benchmark for LLMs in Chinese Context - secrett2633's blog"}],["$","meta","3",{"name":"description","content":"Tianxin Zhang이 arXiv에 게시한 'LiveSecBench: A Dynamic and Culturally-Relevant AI Safety Benchmark for LLMs in Chinese Context' 논문에 대한 자세한 리뷰입니다."}],["$","meta","4",{"name":"author","content":"secrett2633"}],["$","link","5",{"rel":"manifest","href":"/manifest.json","crossOrigin":"use-credentials"}],["$","meta","6",{"name":"keywords","content":"Django, Python, DevOps, AI, ML, 블로그, 기술"}],["$","meta","7",{"name":"creator","content":"secrett2633"}],["$","meta","8",{"name":"publisher","content":"secrett2633"}],["$","meta","9",{"name":"robots","content":"index, follow"}],["$","meta","10",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","11",{"rel":"canonical","href":"https://blog.secrett2633.cloud/ai/review/2025-11-5-LiveSecBench-A-Dynamic-and-Culturally-Relevant-AI-Safety-Benchmark-for-LLMs-in-Chinese-Context"}],["$","meta","12",{"name":"format-detection","content":"telephone=no, address=no, email=no"}],["$","meta","13",{"property":"og:title","content":"[논문리뷰] LiveSecBench: A Dynamic and Culturally-Relevant AI Safety Benchmark for LLMs in Chinese Context"}],["$","meta","14",{"property":"og:description","content":"Tianxin Zhang이 arXiv에 게시한 'LiveSecBench: A Dynamic and Culturally-Relevant AI Safety Benchmark for LLMs in Chinese Context' 논문에 대한 자세한 리뷰입니다."}],["$","meta","15",{"property":"og:url","content":"https://blog.secrett2633.cloud/ai/review/2025-11-5-LiveSecBench-A-Dynamic-and-Culturally-Relevant-AI-Safety-Benchmark-for-LLMs-in-Chinese-Context"}],["$","meta","16",{"property":"og:type","content":"article"}],["$","meta","17",{"property":"article:published_time","content":"2025-11-09T10:35:02.000Z"}],["$","meta","18",{"property":"article:modified_time","content":"2025-11-09T10:35:02.000Z"}],["$","meta","19",{"property":"article:author","content":"secrett2633"}],["$","meta","20",{"property":"article:section","content":"Review"}],["$","meta","21",{"property":"article:tag","content":"Review"}],["$","meta","22",{"property":"article:tag","content":"LLM Safety"}],["$","meta","23",{"property":"article:tag","content":"AI Safety Benchmark"}],["$","meta","24",{"property":"article:tag","content":"Chinese Context"}],["$","meta","25",{"property":"article:tag","content":"Dynamic Evaluation"}],["$","meta","26",{"property":"article:tag","content":"Cultural Relevance"}],["$","meta","27",{"property":"article:tag","content":"Adversarial Robustness"}],["$","meta","28",{"property":"article:tag","content":"ELO Rating System"}],["$","meta","29",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","30",{"name":"twitter:creator","content":"@secrett2633"}],["$","meta","31",{"name":"twitter:title","content":"[논문리뷰] LiveSecBench: A Dynamic and Culturally-Relevant AI Safety Benchmark for LLMs in Chinese Context"}],["$","meta","32",{"name":"twitter:description","content":"Tianxin Zhang이 arXiv에 게시한 'LiveSecBench: A Dynamic and Culturally-Relevant AI Safety Benchmark for LLMs in Chinese Context' 논문에 대한 자세한 리뷰입니다."}],["$","link","33",{"rel":"icon","href":"/icon.ico?6d9f34d4948640b8","type":"image/x-icon","sizes":"16x16"}],["$","meta","34",{"name":"next-size-adjust"}]]
1:null
