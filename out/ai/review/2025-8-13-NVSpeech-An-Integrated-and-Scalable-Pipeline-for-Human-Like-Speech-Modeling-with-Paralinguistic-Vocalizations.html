<!DOCTYPE html><html lang="ko" class="no-js"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/ddc331716d5e47a2.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-90b03762f46d1ba4.js"/><script src="/_next/static/chunks/fd9d1056-0395f68b8cc78a20.js" async=""></script><script src="/_next/static/chunks/23-7d3f7f0b78aa2fd3.js" async=""></script><script src="/_next/static/chunks/main-app-6087bc228fd56b83.js" async=""></script><script src="/_next/static/chunks/231-467e37449c5a68fc.js" async=""></script><script src="/_next/static/chunks/app/layout-b0a450f8e4964582.js" async=""></script><script src="/_next/static/chunks/app/%5B...slug%5D/page-1f60377561abdb46.js" async=""></script><link rel="preload" href="https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY" as="script"/><title>[논문리뷰] NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations - secrett2633&#x27;s blog</title><meta name="description" content="Haoyue Zhan이 [arXiv]에 게시한 &#x27;NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations&#x27; 논문에 대한 자세한 리뷰입니다."/><meta name="author" content="secrett2633"/><link rel="manifest" href="/manifest.json" crossorigin="use-credentials"/><meta name="keywords" content="Django, Python, DevOps, AI, ML, 블로그, 기술"/><meta name="creator" content="secrett2633"/><meta name="publisher" content="secrett2633"/><meta name="robots" content="index, follow"/><meta name="googlebot" content="index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"/><link rel="canonical" href="https://blog.secrett2633.cloud/ai/review/2025-8-13-NVSpeech-An-Integrated-and-Scalable-Pipeline-for-Human-Like-Speech-Modeling-with-Paralinguistic-Vocalizations"/><meta name="format-detection" content="telephone=no, address=no, email=no"/><meta property="og:title" content="[논문리뷰] NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations"/><meta property="og:description" content="Haoyue Zhan이 [arXiv]에 게시한 &#x27;NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations&#x27; 논문에 대한 자세한 리뷰입니다."/><meta property="og:url" content="https://blog.secrett2633.cloud/ai/review/2025-8-13-NVSpeech-An-Integrated-and-Scalable-Pipeline-for-Human-Like-Speech-Modeling-with-Paralinguistic-Vocalizations"/><meta property="og:type" content="article"/><meta property="article:published_time" content="2025-08-13T04:29:23.000Z"/><meta property="article:modified_time" content="2025-08-13T04:29:23.000Z"/><meta property="article:author" content="secrett2633"/><meta property="article:section" content="Review"/><meta property="article:tag" content="Review"/><meta property="article:tag" content="Paralinguistic Vocalizations"/><meta property="article:tag" content="Speech Recognition"/><meta property="article:tag" content="Text-to-Speech"/><meta property="article:tag" content="Speech Synthesis"/><meta property="article:tag" content="Data Annotation"/><meta property="article:tag" content="Mandarin Speech"/><meta property="article:tag" content="Expressive Speech"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:creator" content="@secrett2633"/><meta name="twitter:title" content="[논문리뷰] NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations"/><meta name="twitter:description" content="Haoyue Zhan이 [arXiv]에 게시한 &#x27;NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations&#x27; 논문에 대한 자세한 리뷰입니다."/><link rel="icon" href="/icon.ico?6d9f34d4948640b8" type="image/x-icon" sizes="16x16"/><meta name="next-size-adjust"/><meta name="msapplication-TileColor" content="#ffc40d"/><meta name="theme-color" content="#ffffff"/><link rel="dns-prefetch" href="https://www.googletagmanager.com"/><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"/><link rel="dns-prefetch" href="https://giscus.app"/><link rel="preconnect" href="https://giscus.app" crossorigin="anonymous"/><meta http-equiv="X-Content-Type-Options" content="nosniff"/><meta name="referrer" content="strict-origin-when-cross-origin"/><script type="application/ld+json">{"@context":"https://schema.org","@type":"WebSite","name":"secrett2633's blog","url":"https://blog.secrett2633.cloud","description":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트","inLanguage":"ko","publisher":{"@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud"}}</script><script type="application/ld+json">{"@context":"https://schema.org","@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud","sameAs":["https://github.com/secrett2633"]}</script><script src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body class="__className_f367f3 layout--default"><a href="#main-content" class="sr-only focus:not-sr-only focus:absolute focus:z-50 focus:p-4 focus:bg-white focus:text-blue-600">본문으로 건너뛰기</a><div class="min-h-screen bg-gray-50"><div class="masthead"><div class="masthead__inner-wrap"><div class="masthead__menu"><nav id="site-nav" class="greedy-nav" aria-label="메인 네비게이션"><a class="site-title" href="/">secrett2633&#x27;s blog</a><div class="flex items-center space-x-4"><ul class="visible-links"><li class="masthead__menu-item"><a href="https://github.com/secrett2633" target="_blank" rel="noopener noreferrer">GitHub</a></li></ul><button class="search__toggle" type="button" aria-label="검색"><svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16"><path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path></svg></button></div></nav></div></div></div><main id="main-content" class="initial-content"><!--$--><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","headline":"[논문리뷰] NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations","description":"Haoyue Zhan이 [arXiv]에 게시한 'NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations' 논문에 대한 자세한 리뷰입니다.","url":"https://blog.secrett2633.cloud/ai/review/2025-8-13-NVSpeech-An-Integrated-and-Scalable-Pipeline-for-Human-Like-Speech-Modeling-with-Paralinguistic-Vocalizations","datePublished":"2025-08-13T04:29:23.000Z","dateModified":"2025-08-13T04:29:23.000Z","author":{"@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud"},"publisher":{"@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.secrett2633.cloud/ai/review/2025-8-13-NVSpeech-An-Integrated-and-Scalable-Pipeline-for-Human-Like-Speech-Modeling-with-Paralinguistic-Vocalizations"},"image":"https://blog.secrett2633.cloud/og-default.png","isAccessibleForFree":true,"inLanguage":"ko","wordCount":268,"articleSection":"Review","keywords":"Review, Paralinguistic Vocalizations, Speech Recognition, Text-to-Speech, Speech Synthesis, Data Annotation, Mandarin Speech, Expressive Speech"}</script><script type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"홈","item":"https://blog.secrett2633.cloud/"},{"@type":"ListItem","position":2,"name":"Review","item":"https://blog.secrett2633.cloud/ai/review"},{"@type":"ListItem","position":3,"name":"[논문리뷰] NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations","item":"https://blog.secrett2633.cloud/ai/review/2025-8-13-NVSpeech-An-Integrated-and-Scalable-Pipeline-for-Human-Like-Speech-Modeling-with-Paralinguistic-Vocalizations"}]}</script><div class="flex flex-col lg:flex-row gap-8"><aside class="lg:w-64 xl:w-72 order-1 lg:order-none"><div class="sidebar sticky"><nav class="space-y-4" aria-label="카테고리 네비게이션"><div><p class="font-medium text-gray-900 mb-2">Backend</p><ul class="space-y-1 ml-4"><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/backend/django">Django<!-- --> (<!-- -->6<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/backend/logging">Logging<!-- --> (<!-- -->1<!-- -->)</a></li></ul></div><div><p class="font-medium text-gray-900 mb-2">Python</p><ul class="space-y-1 ml-4"><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/python/pep">PEP<!-- --> (<!-- -->650<!-- -->)</a></li></ul></div><div><p class="font-medium text-gray-900 mb-2">AI/ML</p><ul class="space-y-1 ml-4"><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/ai/llm">LLM<!-- --> (<!-- -->1<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/ai/review">Review<!-- --> (<!-- -->2728<!-- -->)</a></li></ul></div><div><p class="font-medium text-gray-900 mb-2">DevOps</p><ul class="space-y-1 ml-4"><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/devops/nginx">Nginx<!-- --> (<!-- -->1<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/devops/docker">Docker<!-- --> (<!-- -->1<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/devops/safeline">SafeLine<!-- --> (<!-- -->1<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/devops/jenkins">Jenkins<!-- --> (<!-- -->3<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/devops/github-actions">GitHub Actions<!-- --> (<!-- -->1<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/devops/aws">AWS<!-- --> (<!-- -->1<!-- -->)</a></li></ul></div><div><p class="font-medium text-gray-900 mb-2">etc</p><ul class="space-y-1 ml-4"><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/etc/me">Me<!-- --> (<!-- -->3<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/etc/chrome-extension">Chrome Extension<!-- --> (<!-- -->1<!-- -->)</a></li></ul></div></nav></div></aside><div class="flex-1"><nav aria-label="breadcrumb" class="text-sm text-gray-500 mb-4"><ol class="flex flex-wrap items-center gap-1"><li><a class="hover:text-gray-700" href="/">홈</a></li><li class="flex items-center gap-1"><span aria-hidden="true">/</span><a class="hover:text-gray-700" href="/ai/review">Review</a></li><li class="flex items-center gap-1"><span aria-hidden="true">/</span><span class="text-gray-900" aria-current="page">[논문리뷰] NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations</span></li></ol></nav><article class="page"><header class="mb-8"><h1 class="page__title">[논문리뷰] NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations</h1><div class="page__meta"><time dateTime="2025-08-13 13:29:23+0900">2025년 8월 13일</time><time class="ml-4" dateTime="2025-08-13T04:29:23.000Z">수정: <!-- -->2025년 8월 13일</time></div></header><div class="page__content"><div><blockquote>
<p><strong>링크:</strong> <a href="https://arxiv.org/abs/2508.04195" target="_blank" rel="noopener noreferrer">논문 PDF로 바로 열기</a></p>
</blockquote>
<p><strong>저자:</strong> Huan Liao, Qinke Ni, Yuancheng Wang, Yiheng Lu, Haoyue Zhan</p>
<h2 id="핵심-연구-목표"><a href="#핵심-연구-목표">핵심 연구 목표</a></h2>
<p>본 연구는 자연스러운 음성 의사소통에 필수적인 웃음, 호흡, 감탄사 등의 <strong>비언어적 발성(paralinguistic vocalizations)</strong> 이 기존 ASR 및 TTS 시스템에서 간과되는 문제를 해결하고자 합니다. 궁극적으로 중국어 음성에서 비언어적 발성의 인식과 합성을 아우르는 통합적이고 확장 가능한 파이프라인을 구축하여 인간과 유사한 표현적인 음성 모델링을 목표로 합니다.</p>
<h2 id="핵심-방법론"><a href="#핵심-방법론">핵심 방법론</a></h2>
<p>연구팀은 <strong>18가지 단어 수준의 비언어적 범주</strong> 로 수동으로 주석 처리된 <strong>48,430개</strong> 의 발화 데이터셋( <strong>NVSpeech_human</strong> )을 구축했습니다. 이 데이터를 활용하여 비언어적 단서를 인라인 디코딩 가능한 토큰으로 처리하는 <strong>비언어적 인지 ASR 모델</strong> 을 개발했으며, 이를 통해 <strong>174,179개</strong> 의 발화(총 <strong>573시간</strong> )로 구성된 대규모 코퍼스를 자동으로 주석 처리했습니다. 마지막으로, 자동 및 수동 주석 데이터를 모두 사용하여 <strong>CosyVoice</strong> 및 <strong>CosyVoice2</strong> 와 같은 제로샷 TTS 모델을 미세 조정하여 단어 수준에서 비언어적 발성을 제어할 수 있도록 했습니다.</p>
<h2 id="주요-결과"><a href="#주요-결과">주요 결과</a></h2>
<p>비언어적 인지 ASR 모델은 <strong>SenseVoice</strong> 가 인(in-domain) 테스트셋에서 <strong>0.83</strong> , 오픈(open-domain) 테스트셋에서 <strong>0.85</strong> 의 가장 높은 <strong>F1 점수</strong> 를 달성하며 탁월한 성능을 보였습니다. TTS 실험에서는 대규모 자동 주석 데이터셋으로 미세 조정된 모델이 가장 우수했으며, 청취자들이 기존 음성 대비 <strong>78.7%</strong> (CosyVoice) 및 <strong>75.4%</strong> (CosyVoice2)의 높은 선호도를 보였습니다. 또한, 합성된 음성은 높은 자연성(NMOS: <strong>3.9-4.0</strong> )과 음질(QMOS: <strong>4.04-3.96</strong> )을 유지했습니다.</p>
<h2 id="ai-실무자를-위한-시사점"><a href="#ai-실무자를-위한-시사점">AI 실무자를 위한 시사점</a></h2>
<p>본 연구는 대규모, 단어 수준으로 주석 처리된 비언어적 음성 데이터셋( <strong>NVSpeech</strong> )의 중요성을 강조하며, 이는 인간과 유사한 음성 AI 개발의 핵심 기반이 됩니다. 제안된 통합 파이프라인은 복잡한 비언어적 단서를 인식하고 합성하는 실용적이고 확장 가능한 방법을 제공하여, 대화형 AI, 표현적 챗봇, 가상 비서 등의 개발에 직접 적용될 수 있습니다. 또한, 이 연구는 만다린어와 같은 성조 언어의 표현적 음성 모델링에 대한 향후 연구 방향을 제시합니다.</p>
<blockquote>
<p>⚠️ <strong>알림:</strong> 이 리뷰는 AI로 작성되었습니다.</p>
</blockquote>
</div></div><footer class="page__meta mt-8"><div class="page__taxonomy"><span class="text-sm font-medium text-gray-900 mb-2 block">태그</span><a class="page__taxonomy-item" href="/tags/Review">#<!-- -->Review</a><a class="page__taxonomy-item" href="/tags/Paralinguistic%20Vocalizations">#<!-- -->Paralinguistic Vocalizations</a><a class="page__taxonomy-item" href="/tags/Speech%20Recognition">#<!-- -->Speech Recognition</a><a class="page__taxonomy-item" href="/tags/Text-to-Speech">#<!-- -->Text-to-Speech</a><a class="page__taxonomy-item" href="/tags/Speech%20Synthesis">#<!-- -->Speech Synthesis</a><a class="page__taxonomy-item" href="/tags/Data%20Annotation">#<!-- -->Data Annotation</a><a class="page__taxonomy-item" href="/tags/Mandarin%20Speech">#<!-- -->Mandarin Speech</a><a class="page__taxonomy-item" href="/tags/Expressive%20Speech">#<!-- -->Expressive Speech</a></div></footer><section class="comments-section mt-12 pt-8 border-t border-gray-200"></section><section class="mt-12 border-t border-gray-200 pt-8"><h3 class="text-base font-semibold text-gray-900 mb-4">Review<!-- --> 의 다른글</h3><ul class="space-y-2 text-sm"><li class="text-gray-500">이전글<!-- --> <a class="text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4" href="/ai/review/2025-8-13-Matrix-3D-Omnidirectional-Explorable-3D-World-Generation">[논문리뷰] Matrix-3D: Omnidirectional Explorable 3D World Generation</a></li><li class="text-gray-900 font-semibold">현재글 : <!-- -->[논문리뷰] NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations</li><li class="text-gray-500">다음글<!-- --> <a class="text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4" href="/ai/review/2025-8-13-OpenCUA-Open-Foundations-for-Computer-Use-Agents">[논문리뷰] OpenCUA: Open Foundations for Computer-Use Agents</a></li></ul></section></article></div></div><!--/$--></main><div id="footer" class="page__footer"><footer class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8"><div class="text-center text-gray-500 text-sm"><p>© <!-- -->2026<!-- --> secrett2633. All rights reserved.</p></div></footer></div></div><script src="/_next/static/chunks/webpack-90b03762f46d1ba4.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/media/e4af272ccee01ff0-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n2:HL[\"/_next/static/css/ddc331716d5e47a2.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"3:I[5751,[],\"\"]\n6:I[9275,[],\"\"]\n8:I[1343,[],\"\"]\n9:I[9157,[\"231\",\"static/chunks/231-467e37449c5a68fc.js\",\"185\",\"static/chunks/app/layout-b0a450f8e4964582.js\"],\"default\"]\na:I[231,[\"231\",\"static/chunks/231-467e37449c5a68fc.js\",\"877\",\"static/chunks/app/%5B...slug%5D/page-1f60377561abdb46.js\"],\"\"]\nb:I[4080,[\"231\",\"static/chunks/231-467e37449c5a68fc.js\",\"185\",\"static/chunks/app/layout-b0a450f8e4964582.js\"],\"\"]\nd:I[6130,[],\"\"]\n7:[\"slug\",\"ai/review/2025-8-13-NVSpeech-An-Integrated-and-Scalable-Pipeline-for-Human-Like-Speech-Modeling-with-Paralinguistic-Vocalizations\",\"c\"]\ne:[]\n"])</script><script>self.__next_f.push([1,"0:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/ddc331716d5e47a2.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L3\",null,{\"buildId\":\"WcxaIiCPz9cbpnkGvOjOK\",\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/ai/review/2025-8-13-NVSpeech-An-Integrated-and-Scalable-Pipeline-for-Human-Like-Speech-Modeling-with-Paralinguistic-Vocalizations\",\"initialTree\":[\"\",{\"children\":[[\"slug\",\"ai/review/2025-8-13-NVSpeech-An-Integrated-and-Scalable-Pipeline-for-Human-Like-Speech-Modeling-with-Paralinguistic-Vocalizations\",\"c\"],{\"children\":[\"__PAGE__?{\\\"slug\\\":[\\\"ai\\\",\\\"review\\\",\\\"2025-8-13-NVSpeech-An-Integrated-and-Scalable-Pipeline-for-Human-Like-Speech-Modeling-with-Paralinguistic-Vocalizations\\\"]}\",{}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[[\"slug\",\"ai/review/2025-8-13-NVSpeech-An-Integrated-and-Scalable-Pipeline-for-Human-Like-Speech-Modeling-with-Paralinguistic-Vocalizations\",\"c\"],{\"children\":[\"__PAGE__\",{},[[\"$L4\",\"$L5\"],null],null]},[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"$7\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}],null]},[[\"$\",\"html\",null,{\"lang\":\"ko\",\"className\":\"no-js\",\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"meta\",null,{\"name\":\"msapplication-TileColor\",\"content\":\"#ffc40d\"}],[\"$\",\"meta\",null,{\"name\":\"theme-color\",\"content\":\"#ffffff\"}],[\"$\",\"link\",null,{\"rel\":\"dns-prefetch\",\"href\":\"https://www.googletagmanager.com\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://www.googletagmanager.com\",\"crossOrigin\":\"anonymous\"}],[\"$\",\"link\",null,{\"rel\":\"dns-prefetch\",\"href\":\"https://giscus.app\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://giscus.app\",\"crossOrigin\":\"anonymous\"}],[\"$\",\"meta\",null,{\"httpEquiv\":\"X-Content-Type-Options\",\"content\":\"nosniff\"}],[\"$\",\"meta\",null,{\"name\":\"referrer\",\"content\":\"strict-origin-when-cross-origin\"}],[\"$\",\"script\",null,{\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"{\\\"@context\\\":\\\"https://schema.org\\\",\\\"@type\\\":\\\"WebSite\\\",\\\"name\\\":\\\"secrett2633's blog\\\",\\\"url\\\":\\\"https://blog.secrett2633.cloud\\\",\\\"description\\\":\\\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\\\",\\\"inLanguage\\\":\\\"ko\\\",\\\"publisher\\\":{\\\"@type\\\":\\\"Person\\\",\\\"name\\\":\\\"secrett2633\\\",\\\"url\\\":\\\"https://blog.secrett2633.cloud\\\"}}\"}}],[\"$\",\"script\",null,{\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"{\\\"@context\\\":\\\"https://schema.org\\\",\\\"@type\\\":\\\"Person\\\",\\\"name\\\":\\\"secrett2633\\\",\\\"url\\\":\\\"https://blog.secrett2633.cloud\\\",\\\"sameAs\\\":[\\\"https://github.com/secrett2633\\\"]}\"}}]]}],[\"$\",\"body\",null,{\"className\":\"__className_f367f3 layout--default\",\"children\":[[\"$\",\"a\",null,{\"href\":\"#main-content\",\"className\":\"sr-only focus:not-sr-only focus:absolute focus:z-50 focus:p-4 focus:bg-white focus:text-blue-600\",\"children\":\"본문으로 건너뛰기\"}],[\"$\",\"div\",null,{\"className\":\"min-h-screen bg-gray-50\",\"children\":[[\"$\",\"$L9\",null,{}],[\"$\",\"main\",null,{\"id\":\"main-content\",\"className\":\"initial-content\",\"children\":[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[\"$\",\"div\",null,{\"className\":\"min-h-screen flex items-center justify-center bg-gray-50\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-6xl font-bold text-primary-600 mb-4\",\"children\":\"404\"}],[\"$\",\"h2\",null,{\"className\":\"text-2xl font-semibold text-gray-900 mb-4\",\"children\":\"페이지를 찾을 수 없습니다\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-600 mb-8\",\"children\":\"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다.\"}],[\"$\",\"$La\",null,{\"href\":\"/\",\"className\":\"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors\",\"children\":\"홈으로 돌아가기\"}]]}]}],\"notFoundStyles\":[],\"styles\":null}]}],[\"$\",\"div\",null,{\"id\":\"footer\",\"className\":\"page__footer\",\"children\":[\"$\",\"footer\",null,{\"className\":\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"text-center text-gray-500 text-sm\",\"children\":[\"$\",\"p\",null,{\"children\":[\"© \",2026,\" secrett2633. All rights reserved.\"]}]}]}]}]]}],[\"$\",\"$Lb\",null,{\"src\":\"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY\",\"strategy\":\"afterInteractive\"}],[\"$\",\"$Lb\",null,{\"id\":\"gtag-init\",\"strategy\":\"afterInteractive\",\"children\":\"window.dataLayer = window.dataLayer || [];\\n            function gtag(){dataLayer.push(arguments);}\\n            gtag('js', new Date());\\n            gtag('config', 'G-NE2W3CFPNY');\"}]]}]]}],null],[[\"$\",\"div\",null,{\"className\":\"flex items-center justify-center min-h-screen\",\"role\":\"status\",\"aria-label\":\"로딩 중\",\"children\":[[\"$\",\"div\",null,{\"className\":\"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600\"}],[\"$\",\"span\",null,{\"className\":\"sr-only\",\"children\":\"로딩 중...\"}]]}],[],[]]],\"couldBeIntercepted\":false,\"initialHead\":[null,\"$Lc\"],\"globalErrorComponent\":\"$d\",\"missingSlots\":\"$We\"}]]\n"])</script><script>self.__next_f.push([1,"11:I[646,[\"231\",\"static/chunks/231-467e37449c5a68fc.js\",\"877\",\"static/chunks/app/%5B...slug%5D/page-1f60377561abdb46.js\"],\"default\"]\nf:T540,{\"@context\":\"https://schema.org\",\"@type\":\"BlogPosting\",\"headline\":\"[논문리뷰] NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations\",\"description\":\"Haoyue Zhan이 [arXiv]에 게시한 'NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations' 논문에 대한 자세한 리뷰입니다.\",\"url\":\"https://blog.secrett2633.cloud/ai/review/2025-8-13-NVSpeech-An-Integrated-and-Scalable-Pipeline-for-Human-Like-Speech-Modeling-with-Paralinguistic-Vocalizations\",\"datePublished\":\"2025-08-13T04:29:23.000Z\",\"dateModified\":\"2025-08-13T04:29:23.000Z\",\"author\":{\"@type\":\"Person\",\"name\":\"secrett2633\",\"url\":\"https://blog.secrett2633.cloud\"},\"publisher\":{\"@type\":\"Person\",\"name\":\"secrett2633\",\"url\":\"https://blog.secrett2633.cloud\"},\"mainEntityOfPage\":{\"@type\":\"WebPage\",\"@id\":\"https://blog.secrett2633.cloud/ai/review/2025-8-13-NVSpeech-An-Integrated-and-Scalable-Pipeline-for-Human-Like-Speech-Modeling-with-Paralinguistic-Vocalizations\"},\"image\":\"https://blog.secrett2633.cloud/og-default.png\",\"isAccessibleForFree\":true,\"inLanguage\":\"ko\",\"wordCount\":268,\"articleSection\":\"Review\",\"keywords\":\"Review, Paralinguistic Vocalizations, Speech Recognition, Text-to-Speech, Speech Synthesis, Data Annotation, Mandarin Speech, Expressive Speech\"}10:Td51,"])</script><script>self.__next_f.push([1,"\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e링크:\u003c/strong\u003e \u003ca href=\"https://arxiv.org/abs/2508.04195\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e논문 PDF로 바로 열기\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003e저자:\u003c/strong\u003e Huan Liao, Qinke Ni, Yuancheng Wang, Yiheng Lu, Haoyue Zhan\u003c/p\u003e\n\u003ch2 id=\"핵심-연구-목표\"\u003e\u003ca href=\"#핵심-연구-목표\"\u003e핵심 연구 목표\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003e본 연구는 자연스러운 음성 의사소통에 필수적인 웃음, 호흡, 감탄사 등의 \u003cstrong\u003e비언어적 발성(paralinguistic vocalizations)\u003c/strong\u003e 이 기존 ASR 및 TTS 시스템에서 간과되는 문제를 해결하고자 합니다. 궁극적으로 중국어 음성에서 비언어적 발성의 인식과 합성을 아우르는 통합적이고 확장 가능한 파이프라인을 구축하여 인간과 유사한 표현적인 음성 모델링을 목표로 합니다.\u003c/p\u003e\n\u003ch2 id=\"핵심-방법론\"\u003e\u003ca href=\"#핵심-방법론\"\u003e핵심 방법론\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003e연구팀은 \u003cstrong\u003e18가지 단어 수준의 비언어적 범주\u003c/strong\u003e 로 수동으로 주석 처리된 \u003cstrong\u003e48,430개\u003c/strong\u003e 의 발화 데이터셋( \u003cstrong\u003eNVSpeech_human\u003c/strong\u003e )을 구축했습니다. 이 데이터를 활용하여 비언어적 단서를 인라인 디코딩 가능한 토큰으로 처리하는 \u003cstrong\u003e비언어적 인지 ASR 모델\u003c/strong\u003e 을 개발했으며, 이를 통해 \u003cstrong\u003e174,179개\u003c/strong\u003e 의 발화(총 \u003cstrong\u003e573시간\u003c/strong\u003e )로 구성된 대규모 코퍼스를 자동으로 주석 처리했습니다. 마지막으로, 자동 및 수동 주석 데이터를 모두 사용하여 \u003cstrong\u003eCosyVoice\u003c/strong\u003e 및 \u003cstrong\u003eCosyVoice2\u003c/strong\u003e 와 같은 제로샷 TTS 모델을 미세 조정하여 단어 수준에서 비언어적 발성을 제어할 수 있도록 했습니다.\u003c/p\u003e\n\u003ch2 id=\"주요-결과\"\u003e\u003ca href=\"#주요-결과\"\u003e주요 결과\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003e비언어적 인지 ASR 모델은 \u003cstrong\u003eSenseVoice\u003c/strong\u003e 가 인(in-domain) 테스트셋에서 \u003cstrong\u003e0.83\u003c/strong\u003e , 오픈(open-domain) 테스트셋에서 \u003cstrong\u003e0.85\u003c/strong\u003e 의 가장 높은 \u003cstrong\u003eF1 점수\u003c/strong\u003e 를 달성하며 탁월한 성능을 보였습니다. TTS 실험에서는 대규모 자동 주석 데이터셋으로 미세 조정된 모델이 가장 우수했으며, 청취자들이 기존 음성 대비 \u003cstrong\u003e78.7%\u003c/strong\u003e (CosyVoice) 및 \u003cstrong\u003e75.4%\u003c/strong\u003e (CosyVoice2)의 높은 선호도를 보였습니다. 또한, 합성된 음성은 높은 자연성(NMOS: \u003cstrong\u003e3.9-4.0\u003c/strong\u003e )과 음질(QMOS: \u003cstrong\u003e4.04-3.96\u003c/strong\u003e )을 유지했습니다.\u003c/p\u003e\n\u003ch2 id=\"ai-실무자를-위한-시사점\"\u003e\u003ca href=\"#ai-실무자를-위한-시사점\"\u003eAI 실무자를 위한 시사점\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003e본 연구는 대규모, 단어 수준으로 주석 처리된 비언어적 음성 데이터셋( \u003cstrong\u003eNVSpeech\u003c/strong\u003e )의 중요성을 강조하며, 이는 인간과 유사한 음성 AI 개발의 핵심 기반이 됩니다. 제안된 통합 파이프라인은 복잡한 비언어적 단서를 인식하고 합성하는 실용적이고 확장 가능한 방법을 제공하여, 대화형 AI, 표현적 챗봇, 가상 비서 등의 개발에 직접 적용될 수 있습니다. 또한, 이 연구는 만다린어와 같은 성조 언어의 표현적 음성 모델링에 대한 향후 연구 방향을 제시합니다.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e⚠️ \u003cstrong\u003e알림:\u003c/strong\u003e 이 리뷰는 AI로 작성되었습니다.\u003c/p\u003e\n\u003c/blockquote\u003e\n"])</script><script>self.__next_f.push([1,"5:[[\"$\",\"script\",null,{\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"$f\"}}],[\"$\",\"script\",null,{\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"{\\\"@context\\\":\\\"https://schema.org\\\",\\\"@type\\\":\\\"BreadcrumbList\\\",\\\"itemListElement\\\":[{\\\"@type\\\":\\\"ListItem\\\",\\\"position\\\":1,\\\"name\\\":\\\"홈\\\",\\\"item\\\":\\\"https://blog.secrett2633.cloud/\\\"},{\\\"@type\\\":\\\"ListItem\\\",\\\"position\\\":2,\\\"name\\\":\\\"Review\\\",\\\"item\\\":\\\"https://blog.secrett2633.cloud/ai/review\\\"},{\\\"@type\\\":\\\"ListItem\\\",\\\"position\\\":3,\\\"name\\\":\\\"[논문리뷰] NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations\\\",\\\"item\\\":\\\"https://blog.secrett2633.cloud/ai/review/2025-8-13-NVSpeech-An-Integrated-and-Scalable-Pipeline-for-Human-Like-Speech-Modeling-with-Paralinguistic-Vocalizations\\\"}]}\"}}],[\"$\",\"div\",null,{\"className\":\"flex flex-col lg:flex-row gap-8\",\"children\":[[\"$\",\"aside\",null,{\"className\":\"lg:w-64 xl:w-72 order-1 lg:order-none\",\"children\":[\"$\",\"div\",null,{\"className\":\"sidebar sticky\",\"children\":[\"$\",\"nav\",null,{\"className\":\"space-y-4\",\"aria-label\":\"카테고리 네비게이션\",\"children\":[[\"$\",\"div\",\"Backend\",{\"children\":[[\"$\",\"p\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"Backend\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"Django\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/backend/django\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Django\",\" (\",6,\")\"]}]}],[\"$\",\"li\",\"Logging\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/backend/logging\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Logging\",\" (\",1,\")\"]}]}]]}]]}],[\"$\",\"div\",\"Python\",{\"children\":[[\"$\",\"p\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"Python\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"PEP\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/python/pep\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"PEP\",\" (\",650,\")\"]}]}]]}]]}],[\"$\",\"div\",\"AI/ML\",{\"children\":[[\"$\",\"p\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"AI/ML\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"LLM\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/ai/llm\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"LLM\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"Review\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/ai/review\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Review\",\" (\",2728,\")\"]}]}]]}]]}],[\"$\",\"div\",\"DevOps\",{\"children\":[[\"$\",\"p\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"DevOps\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"Nginx\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/devops/nginx\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Nginx\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"Docker\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/devops/docker\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Docker\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"SafeLine\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/devops/safeline\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"SafeLine\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"Jenkins\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/devops/jenkins\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Jenkins\",\" (\",3,\")\"]}]}],[\"$\",\"li\",\"GitHub Actions\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/devops/github-actions\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"GitHub Actions\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"AWS\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/devops/aws\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"AWS\",\" (\",1,\")\"]}]}]]}]]}],[\"$\",\"div\",\"etc\",{\"children\":[[\"$\",\"p\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"etc\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"Me\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/etc/me\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Me\",\" (\",3,\")\"]}]}],[\"$\",\"li\",\"Chrome Extension\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/etc/chrome-extension\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Chrome Extension\",\" (\",1,\")\"]}]}]]}]]}]]}]}]}],[\"$\",\"div\",null,{\"className\":\"flex-1\",\"children\":[[\"$\",\"nav\",null,{\"aria-label\":\"breadcrumb\",\"className\":\"text-sm text-gray-500 mb-4\",\"children\":[\"$\",\"ol\",null,{\"className\":\"flex flex-wrap items-center gap-1\",\"children\":[[\"$\",\"li\",null,{\"children\":[\"$\",\"$La\",null,{\"href\":\"/\",\"className\":\"hover:text-gray-700\",\"children\":\"홈\"}]}],[[\"$\",\"li\",\"/ai/review\",{\"className\":\"flex items-center gap-1\",\"children\":[[\"$\",\"span\",null,{\"aria-hidden\":\"true\",\"children\":\"/\"}],[\"$\",\"$La\",null,{\"href\":\"/ai/review\",\"className\":\"hover:text-gray-700\",\"children\":\"Review\"}]]}],[\"$\",\"li\",\"/ai/review/2025-8-13-NVSpeech-An-Integrated-and-Scalable-Pipeline-for-Human-Like-Speech-Modeling-with-Paralinguistic-Vocalizations\",{\"className\":\"flex items-center gap-1\",\"children\":[[\"$\",\"span\",null,{\"aria-hidden\":\"true\",\"children\":\"/\"}],[\"$\",\"span\",null,{\"className\":\"text-gray-900\",\"aria-current\":\"page\",\"children\":\"[논문리뷰] NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations\"}]]}]]]}]}],[\"$\",\"article\",null,{\"className\":\"page\",\"children\":[[\"$\",\"header\",null,{\"className\":\"mb-8\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"page__title\",\"children\":\"[논문리뷰] NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations\"}],[\"$\",\"div\",null,{\"className\":\"page__meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-13 13:29:23+0900\",\"children\":\"2025년 8월 13일\"}],[\"$\",\"time\",null,{\"className\":\"ml-4\",\"dateTime\":\"2025-08-13T04:29:23.000Z\",\"children\":[\"수정: \",\"2025년 8월 13일\"]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"page__content\",\"children\":[\"$\",\"div\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$10\"}}]}],[\"$\",\"footer\",null,{\"className\":\"page__meta mt-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"page__taxonomy\",\"children\":[[\"$\",\"span\",null,{\"className\":\"text-sm font-medium text-gray-900 mb-2 block\",\"children\":\"태그\"}],[[\"$\",\"$La\",\"Review\",{\"href\":\"/tags/Review\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"$La\",\"Paralinguistic Vocalizations\",{\"href\":\"/tags/Paralinguistic%20Vocalizations\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Paralinguistic Vocalizations\"]}],[\"$\",\"$La\",\"Speech Recognition\",{\"href\":\"/tags/Speech%20Recognition\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Speech Recognition\"]}],[\"$\",\"$La\",\"Text-to-Speech\",{\"href\":\"/tags/Text-to-Speech\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Speech\"]}],[\"$\",\"$La\",\"Speech Synthesis\",{\"href\":\"/tags/Speech%20Synthesis\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Speech Synthesis\"]}],[\"$\",\"$La\",\"Data Annotation\",{\"href\":\"/tags/Data%20Annotation\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Annotation\"]}],[\"$\",\"$La\",\"Mandarin Speech\",{\"href\":\"/tags/Mandarin%20Speech\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mandarin Speech\"]}],[\"$\",\"$La\",\"Expressive Speech\",{\"href\":\"/tags/Expressive%20Speech\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Expressive Speech\"]}]]]}]}],[\"$\",\"$L11\",null,{\"postPermalink\":\"/ai/review/2025-8-13-NVSpeech-An-Integrated-and-Scalable-Pipeline-for-Human-Like-Speech-Modeling-with-Paralinguistic-Vocalizations\",\"postId\":\"2025-8-13-NVSpeech-An-Integrated-and-Scalable-Pipeline-for-Human-Like-Speech-Modeling-with-Paralinguistic-Vocalizations\"}],[\"$\",\"section\",null,{\"className\":\"mt-12 border-t border-gray-200 pt-8\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-base font-semibold text-gray-900 mb-4\",\"children\":[\"Review\",\" 의 다른글\"]}],[\"$\",\"ul\",null,{\"className\":\"space-y-2 text-sm\",\"children\":[[\"$\",\"li\",null,{\"className\":\"text-gray-500\",\"children\":[\"이전글\",\" \",[\"$\",\"$La\",null,{\"href\":\"/ai/review/2025-8-13-Matrix-3D-Omnidirectional-Explorable-3D-World-Generation\",\"className\":\"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4\",\"children\":\"[논문리뷰] Matrix-3D: Omnidirectional Explorable 3D World Generation\"}]]}],[\"$\",\"li\",null,{\"className\":\"text-gray-900 font-semibold\",\"children\":[\"현재글 : \",\"[논문리뷰] NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations\"]}],[\"$\",\"li\",null,{\"className\":\"text-gray-500\",\"children\":[\"다음글\",\" \",[\"$\",\"$La\",null,{\"href\":\"/ai/review/2025-8-13-OpenCUA-Open-Foundations-for-Computer-Use-Agents\",\"className\":\"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4\",\"children\":\"[논문리뷰] OpenCUA: Open Foundations for Computer-Use Agents\"}]]}]]}]]}]]}]]}]]}]]\n"])</script><script>self.__next_f.push([1,"c:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"[논문리뷰] NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations - secrett2633's blog\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"Haoyue Zhan이 [arXiv]에 게시한 'NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"meta\",\"4\",{\"name\":\"author\",\"content\":\"secrett2633\"}],[\"$\",\"link\",\"5\",{\"rel\":\"manifest\",\"href\":\"/manifest.json\",\"crossOrigin\":\"use-credentials\"}],[\"$\",\"meta\",\"6\",{\"name\":\"keywords\",\"content\":\"Django, Python, DevOps, AI, ML, 블로그, 기술\"}],[\"$\",\"meta\",\"7\",{\"name\":\"creator\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"8\",{\"name\":\"publisher\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"9\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"10\",{\"name\":\"googlebot\",\"content\":\"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1\"}],[\"$\",\"link\",\"11\",{\"rel\":\"canonical\",\"href\":\"https://blog.secrett2633.cloud/ai/review/2025-8-13-NVSpeech-An-Integrated-and-Scalable-Pipeline-for-Human-Like-Speech-Modeling-with-Paralinguistic-Vocalizations\"}],[\"$\",\"meta\",\"12\",{\"name\":\"format-detection\",\"content\":\"telephone=no, address=no, email=no\"}],[\"$\",\"meta\",\"13\",{\"property\":\"og:title\",\"content\":\"[논문리뷰] NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations\"}],[\"$\",\"meta\",\"14\",{\"property\":\"og:description\",\"content\":\"Haoyue Zhan이 [arXiv]에 게시한 'NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"meta\",\"15\",{\"property\":\"og:url\",\"content\":\"https://blog.secrett2633.cloud/ai/review/2025-8-13-NVSpeech-An-Integrated-and-Scalable-Pipeline-for-Human-Like-Speech-Modeling-with-Paralinguistic-Vocalizations\"}],[\"$\",\"meta\",\"16\",{\"property\":\"og:type\",\"content\":\"article\"}],[\"$\",\"meta\",\"17\",{\"property\":\"article:published_time\",\"content\":\"2025-08-13T04:29:23.000Z\"}],[\"$\",\"meta\",\"18\",{\"property\":\"article:modified_time\",\"content\":\"2025-08-13T04:29:23.000Z\"}],[\"$\",\"meta\",\"19\",{\"property\":\"article:author\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"20\",{\"property\":\"article:section\",\"content\":\"Review\"}],[\"$\",\"meta\",\"21\",{\"property\":\"article:tag\",\"content\":\"Review\"}],[\"$\",\"meta\",\"22\",{\"property\":\"article:tag\",\"content\":\"Paralinguistic Vocalizations\"}],[\"$\",\"meta\",\"23\",{\"property\":\"article:tag\",\"content\":\"Speech Recognition\"}],[\"$\",\"meta\",\"24\",{\"property\":\"article:tag\",\"content\":\"Text-to-Speech\"}],[\"$\",\"meta\",\"25\",{\"property\":\"article:tag\",\"content\":\"Speech Synthesis\"}],[\"$\",\"meta\",\"26\",{\"property\":\"article:tag\",\"content\":\"Data Annotation\"}],[\"$\",\"meta\",\"27\",{\"property\":\"article:tag\",\"content\":\"Mandarin Speech\"}],[\"$\",\"meta\",\"28\",{\"property\":\"article:tag\",\"content\":\"Expressive Speech\"}],[\"$\",\"meta\",\"29\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"30\",{\"name\":\"twitter:creator\",\"content\":\"@secrett2633\"}],[\"$\",\"meta\",\"31\",{\"name\":\"twitter:title\",\"content\":\"[논문리뷰] NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations\"}],[\"$\",\"meta\",\"32\",{\"name\":\"twitter:description\",\"content\":\"Haoyue Zhan이 [arXiv]에 게시한 'NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"link\",\"33\",{\"rel\":\"icon\",\"href\":\"/icon.ico?6d9f34d4948640b8\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}],[\"$\",\"meta\",\"34\",{\"name\":\"next-size-adjust\"}]]\n"])</script><script>self.__next_f.push([1,"4:null\n"])</script></body></html>