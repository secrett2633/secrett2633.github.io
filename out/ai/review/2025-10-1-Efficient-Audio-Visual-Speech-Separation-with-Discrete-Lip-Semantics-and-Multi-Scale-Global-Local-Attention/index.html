<!DOCTYPE html><html lang="ko" class="no-js"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/edf391eeca43d999.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-15a70ff5b484f3df.js"/><script src="/_next/static/chunks/fd9d1056-4e1a26e2d413ba3c.js" async=""></script><script src="/_next/static/chunks/23-e8ded9e1e67d56dc.js" async=""></script><script src="/_next/static/chunks/main-app-6087bc228fd56b83.js" async=""></script><script src="/_next/static/chunks/231-c27e618569e042bc.js" async=""></script><script src="/_next/static/chunks/157-167bfed393319721.js" async=""></script><script src="/_next/static/chunks/app/layout-b06e577e11976c7d.js" async=""></script><script src="/_next/static/chunks/app/%5B...slug%5D/page-eb985a9c6ac1f073.js" async=""></script><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY"></script><title>secrett2633&#x27;s blog</title><meta name="description" content="기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"/><meta name="author" content="secrett2633"/><meta name="keywords" content="Django, Python, DevOps, AI, ML, 블로그, 기술"/><meta name="creator" content="secrett2633"/><meta name="publisher" content="secrett2633"/><meta name="robots" content="index, follow"/><meta name="googlebot" content="index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"/><link rel="canonical" href="https://blog.secrett2633.site/"/><meta name="format-detection" content="telephone=no, address=no, email=no"/><meta property="og:title" content="secrett2633&#x27;s blog"/><meta property="og:description" content="기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"/><meta property="og:url" content="https://blog.secrett2633.site/"/><meta property="og:site_name" content="secrett2633&#x27;s blog"/><meta property="og:locale" content="ko_KR"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="secrett2633&#x27;s blog"/><meta name="twitter:description" content="기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"/><link rel="icon" href="/icon.ico?6d9f34d4948640b8" type="image/x-icon" sizes="16x16"/><meta name="next-size-adjust"/><meta name="msapplication-TileColor" content="#ffc40d"/><meta name="theme-color" content="#ffffff"/><script>
              window.dataLayer = window.dataLayer || [];
              function gtag(){dataLayer.push(arguments);}
              gtag('js', new Date());
              gtag('config', 'G-NE2W3CFPNY');
            </script><script src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body class="__className_f367f3 layout--default"><div class="min-h-screen bg-gray-50"><div class="masthead"><div class="masthead__inner-wrap"><div class="masthead__menu"><nav id="site-nav" class="greedy-nav"><a class="site-title" href="/">secrett2633&#x27;s blog</a><div class="flex items-center space-x-4"><ul class="visible-links"><li class="masthead__menu-item"><a href="https://github.com/secrett2633" target="_blank" rel="noopener noreferrer">GitHub</a></li></ul><button class="search__toggle" type="button"><svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16"><path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path></svg></button></div></nav></div></div></div><main class="initial-content"><!--$--><div class="flex flex-col lg:flex-row gap-8"><aside class="lg:w-64 xl:w-72 order-1 lg:order-none"><div class="sidebar sticky"><nav class="space-y-4"><div><h4 class="font-medium text-gray-900 mb-2">Backend</h4><ul class="space-y-1 ml-4"><li><a href="/backend/django/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Django<!-- --> (<!-- -->6<!-- -->)</a></li><li><a href="/backend/logging/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Logging<!-- --> (<!-- -->1<!-- -->)</a></li></ul></div><div><h4 class="font-medium text-gray-900 mb-2">Python</h4><ul class="space-y-1 ml-4"><li><a href="/python/pep/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">PEP<!-- --> (<!-- -->650<!-- -->)</a></li></ul></div><div><h4 class="font-medium text-gray-900 mb-2">AI/ML</h4><ul class="space-y-1 ml-4"><li><a href="/ai/llm/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">LLM<!-- --> (<!-- -->1<!-- -->)</a></li><li><a href="/ai/review/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Review<!-- --> (<!-- -->1734<!-- -->)</a></li></ul></div><div><h4 class="font-medium text-gray-900 mb-2">DevOps</h4><ul class="space-y-1 ml-4"><li><a href="/devops/nginx/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Nginx<!-- --> (<!-- -->1<!-- -->)</a></li><li><a href="/devops/docker/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Docker<!-- --> (<!-- -->1<!-- -->)</a></li><li><a href="/devops/safeline/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">SafeLine<!-- --> (<!-- -->1<!-- -->)</a></li><li><a href="/devops/jenkins/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Jenkins<!-- --> (<!-- -->3<!-- -->)</a></li><li><a href="/devops/github-actions/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">GitHub Actions<!-- --> (<!-- -->1<!-- -->)</a></li><li><a href="/devops/aws/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">AWS<!-- --> (<!-- -->1<!-- -->)</a></li></ul></div><div><h4 class="font-medium text-gray-900 mb-2">etc</h4><ul class="space-y-1 ml-4"><li><a href="/etc/me/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Me<!-- --> (<!-- -->3<!-- -->)</a></li><li><a href="/etc/chrome-extension/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Chrome Extension<!-- --> (<!-- -->1<!-- -->)</a></li></ul></div></nav></div></aside><main class="flex-1"><article class="page"><header class="mb-8"><h1 class="page__title">[논문리뷰] Efficient Audio-Visual Speech Separation with Discrete Lip Semantics and Multi-Scale Global-Local Attention</h1><div class="page__meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><span class="ml-4">수정: <!-- -->2025년 10월 1일</span></div></header><div class="page__content"><div><blockquote>
<p><strong>링크:</strong> <a href="https://arxiv.org/abs/2509.23610">논문 PDF로 바로 열기</a></p>
</blockquote>
<p><strong>저자:</strong> Kai Li, Kejun Gao, Xiaolin Hu</p>
<h2>핵심 연구 목표</h2>
<p>오디오-비주얼 음성 분리(AVSS) 분야에서 기존 모델들의 높은 연산 비용과 파라미터 수로 인해 발생하는 실용적 배포의 한계를 해결하는 것을 목표로 합니다. 특히, 시각 인코더의 '경로 의존성' 문제와 반복적 분리기의 추론 지연 문제를 극복하면서 분리 성능 저하 없이 효율성을 극대화하는 <strong>경량 AVSS 모델</strong> 을 개발하고자 합니다.</p>
<h2>핵심 방법론</h2>
<p>본 연구는 효율적인 AVSS 모델인 <strong>Dolphin</strong> 을 제안합니다. 이를 위해, 립 모션을 이산적인 오디오 정렬 의미 토큰으로 변환하는 이중 경로 경량 비디오 인코더인 <strong>DP-LipCoder</strong> 를 개발했습니다. 음성 분리에는 각 레이어에 멀티 스케일 종속성을 효율적으로 캡처하는 <strong>Global-Local Attention (GLA) 블록</strong> 을 통합한 경량 인코더-디코더 분리기를 구축했습니다.</p>
<h2>주요 결과</h2>
<p><strong>Dolphin</strong> 은 LRS2, LRS3, VoxCeleb2 벤치마크 데이터셋에서 최신 <strong>SOTA IIANet 모델</strong> 보다 우수한 분리 품질을 달성했습니다. 특히, 효율성 측면에서 <strong>IIANet</strong> 대비 <strong>파라미터 50% 이상 감소</strong> , <strong>MACs 2.4배 이상 감소</strong> , <strong>GPU 추론 속도 6배 이상 향상</strong> 이라는 놀라운 성과를 보였습니다. <strong>DP-LipCoder</strong> 는 <strong>3D ResNet-18</strong> 대비 파라미터 93%, MACs 70%를 줄이면서도 유사한 SI-SNRi 성능을 유지했습니다.</p>
<h2>AI 실무자를 위한 시사점</h2>
<p><strong>Dolphin</strong> 은 고성능 AVSS를 요구하면서도 리소스가 제한적인 실제 시나리오, 특히 에지 디바이스에서의 배포에 실용적인 해결책을 제시합니다. <strong>DP-LipCoder</strong> 의 이산 립 의미론 사용과 <strong>GLA 블록</strong> 을 통한 효율적인 멀티스케일 특징 학습은 경량 모델 설계에 대한 새로운 방향을 제시하여, 향후 <strong>온디바이스 AI 음성 처리 애플리케이션</strong> 개발에 기여할 수 있습니다.</p>
<blockquote>
<p>⚠️ <strong>알림:</strong> 이 리뷰는 AI로 작성되었습니다.</p>
</blockquote>
</div></div><footer class="page__meta mt-8"><div class="page__taxonomy"><h4 class="text-sm font-medium text-gray-900 mb-2">태그</h4><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Audio-Visual Speech Separation</span><span class="page__taxonomy-item">#<!-- -->Deep Learning</span><span class="page__taxonomy-item">#<!-- -->Efficiency</span><span class="page__taxonomy-item">#<!-- -->Discrete Lip Semantics</span><span class="page__taxonomy-item">#<!-- -->Global-Local Attention</span><span class="page__taxonomy-item">#<!-- -->Lightweight Models</span><span class="page__taxonomy-item">#<!-- -->VQ-VAE</span></div></footer><section class="mt-12 border-t border-gray-200 pt-8"><h3 class="text-base font-semibold text-gray-900 mb-4">Review<!-- --> 의 다른글</h3><ul class="space-y-2 text-sm"><li class="text-gray-500">이전글<!-- --> <a class="text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4" href="/ai/review/2025-10-1-DeepScientist-Advancing-Frontier-Pushing-Scientific-Findings-Progressively/">[논문리뷰] DeepScientist: Advancing Frontier-Pushing Scientific Findings Progressively</a></li><li class="text-gray-900 font-semibold">현재글 : <!-- -->[논문리뷰] Efficient Audio-Visual Speech Separation with Discrete Lip Semantics and Multi-Scale Global-Local Attention</li><li class="text-gray-500">다음글<!-- --> <a class="text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4" href="/ai/review/2025-10-1-EntroPE-Entropy-Guided-Dynamic-Patch-Encoder-for-Time-Series-Forecasting/">[논문리뷰] EntroPE: Entropy-Guided Dynamic Patch Encoder for Time Series Forecasting</a></li></ul></section></article></main></div><!--/$--></main><div id="footer" class="page__footer"><footer class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8"><div class="text-center text-gray-500 text-sm"><p>© 2025 secrett2633. All rights reserved.</p></div></footer></div></div><script src="/_next/static/chunks/webpack-15a70ff5b484f3df.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/media/e4af272ccee01ff0-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n2:HL[\"/_next/static/css/edf391eeca43d999.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"3:I[5751,[],\"\"]\n6:I[9275,[],\"\"]\n8:I[1343,[],\"\"]\n9:I[9157,[\"231\",\"static/chunks/231-c27e618569e042bc.js\",\"157\",\"static/chunks/157-167bfed393319721.js\",\"185\",\"static/chunks/app/layout-b06e577e11976c7d.js\"],\"default\"]\na:I[231,[\"231\",\"static/chunks/231-c27e618569e042bc.js\",\"877\",\"static/chunks/app/%5B...slug%5D/page-eb985a9c6ac1f073.js\"],\"\"]\nc:I[6130,[],\"\"]\n7:[\"slug\",\"ai/review/2025-10-1-Efficient-Audio-Visual-Speech-Separation-with-Discrete-Lip-Semantics-and-Multi-Scale-Global-Local-Attention\",\"c\"]\nd:[]\n"])</script><script>self.__next_f.push([1,"0:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/edf391eeca43d999.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L3\",null,{\"buildId\":\"q8gP0CJE_7T-dGWg_B3Wl\",\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/ai/review/2025-10-1-Efficient-Audio-Visual-Speech-Separation-with-Discrete-Lip-Semantics-and-Multi-Scale-Global-Local-Attention/\",\"initialTree\":[\"\",{\"children\":[[\"slug\",\"ai/review/2025-10-1-Efficient-Audio-Visual-Speech-Separation-with-Discrete-Lip-Semantics-and-Multi-Scale-Global-Local-Attention\",\"c\"],{\"children\":[\"__PAGE__?{\\\"slug\\\":[\\\"ai\\\",\\\"review\\\",\\\"2025-10-1-Efficient-Audio-Visual-Speech-Separation-with-Discrete-Lip-Semantics-and-Multi-Scale-Global-Local-Attention\\\"]}\",{}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[[\"slug\",\"ai/review/2025-10-1-Efficient-Audio-Visual-Speech-Separation-with-Discrete-Lip-Semantics-and-Multi-Scale-Global-Local-Attention\",\"c\"],{\"children\":[\"__PAGE__\",{},[[\"$L4\",\"$L5\"],null],null]},[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"$7\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}],null]},[[\"$\",\"html\",null,{\"lang\":\"ko\",\"className\":\"no-js\",\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"meta\",null,{\"name\":\"msapplication-TileColor\",\"content\":\"#ffc40d\"}],[\"$\",\"meta\",null,{\"name\":\"theme-color\",\"content\":\"#ffffff\"}],[\"$\",\"script\",null,{\"async\":true,\"src\":\"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY\"}],[\"$\",\"script\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\\n              window.dataLayer = window.dataLayer || [];\\n              function gtag(){dataLayer.push(arguments);}\\n              gtag('js', new Date());\\n              gtag('config', 'G-NE2W3CFPNY');\\n            \"}}]]}],[\"$\",\"body\",null,{\"className\":\"__className_f367f3 layout--default\",\"children\":[\"$\",\"div\",null,{\"className\":\"min-h-screen bg-gray-50\",\"children\":[[\"$\",\"$L9\",null,{}],[\"$\",\"main\",null,{\"className\":\"initial-content\",\"children\":[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[\"$\",\"div\",null,{\"className\":\"min-h-screen flex items-center justify-center bg-gray-50\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-6xl font-bold text-primary-600 mb-4\",\"children\":\"404\"}],[\"$\",\"h2\",null,{\"className\":\"text-2xl font-semibold text-gray-900 mb-4\",\"children\":\"페이지를 찾을 수 없습니다\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-600 mb-8\",\"children\":\"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다.\"}],[\"$\",\"$La\",null,{\"href\":\"/\",\"className\":\"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors\",\"children\":\"홈으로 돌아가기\"}]]}]}],\"notFoundStyles\":[],\"styles\":null}]}],[\"$\",\"div\",null,{\"id\":\"footer\",\"className\":\"page__footer\",\"children\":[\"$\",\"footer\",null,{\"className\":\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"text-center text-gray-500 text-sm\",\"children\":[\"$\",\"p\",null,{\"children\":\"© 2025 secrett2633. All rights reserved.\"}]}]}]}]]}]}]]}],null],[[\"$\",\"div\",null,{\"className\":\"flex items-center justify-center min-h-screen\",\"children\":[\"$\",\"div\",null,{\"className\":\"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600\"}]}],[],[]]],\"couldBeIntercepted\":false,\"initialHead\":[null,\"$Lb\"],\"globalErrorComponent\":\"$c\",\"missingSlots\":\"$Wd\"}]]\n"])</script><script>self.__next_f.push([1,"e:T9ea,"])</script><script>self.__next_f.push([1,"\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e링크:\u003c/strong\u003e \u003ca href=\"https://arxiv.org/abs/2509.23610\"\u003e논문 PDF로 바로 열기\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003e저자:\u003c/strong\u003e Kai Li, Kejun Gao, Xiaolin Hu\u003c/p\u003e\n\u003ch2\u003e핵심 연구 목표\u003c/h2\u003e\n\u003cp\u003e오디오-비주얼 음성 분리(AVSS) 분야에서 기존 모델들의 높은 연산 비용과 파라미터 수로 인해 발생하는 실용적 배포의 한계를 해결하는 것을 목표로 합니다. 특히, 시각 인코더의 '경로 의존성' 문제와 반복적 분리기의 추론 지연 문제를 극복하면서 분리 성능 저하 없이 효율성을 극대화하는 \u003cstrong\u003e경량 AVSS 모델\u003c/strong\u003e 을 개발하고자 합니다.\u003c/p\u003e\n\u003ch2\u003e핵심 방법론\u003c/h2\u003e\n\u003cp\u003e본 연구는 효율적인 AVSS 모델인 \u003cstrong\u003eDolphin\u003c/strong\u003e 을 제안합니다. 이를 위해, 립 모션을 이산적인 오디오 정렬 의미 토큰으로 변환하는 이중 경로 경량 비디오 인코더인 \u003cstrong\u003eDP-LipCoder\u003c/strong\u003e 를 개발했습니다. 음성 분리에는 각 레이어에 멀티 스케일 종속성을 효율적으로 캡처하는 \u003cstrong\u003eGlobal-Local Attention (GLA) 블록\u003c/strong\u003e 을 통합한 경량 인코더-디코더 분리기를 구축했습니다.\u003c/p\u003e\n\u003ch2\u003e주요 결과\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eDolphin\u003c/strong\u003e 은 LRS2, LRS3, VoxCeleb2 벤치마크 데이터셋에서 최신 \u003cstrong\u003eSOTA IIANet 모델\u003c/strong\u003e 보다 우수한 분리 품질을 달성했습니다. 특히, 효율성 측면에서 \u003cstrong\u003eIIANet\u003c/strong\u003e 대비 \u003cstrong\u003e파라미터 50% 이상 감소\u003c/strong\u003e , \u003cstrong\u003eMACs 2.4배 이상 감소\u003c/strong\u003e , \u003cstrong\u003eGPU 추론 속도 6배 이상 향상\u003c/strong\u003e 이라는 놀라운 성과를 보였습니다. \u003cstrong\u003eDP-LipCoder\u003c/strong\u003e 는 \u003cstrong\u003e3D ResNet-18\u003c/strong\u003e 대비 파라미터 93%, MACs 70%를 줄이면서도 유사한 SI-SNRi 성능을 유지했습니다.\u003c/p\u003e\n\u003ch2\u003eAI 실무자를 위한 시사점\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eDolphin\u003c/strong\u003e 은 고성능 AVSS를 요구하면서도 리소스가 제한적인 실제 시나리오, 특히 에지 디바이스에서의 배포에 실용적인 해결책을 제시합니다. \u003cstrong\u003eDP-LipCoder\u003c/strong\u003e 의 이산 립 의미론 사용과 \u003cstrong\u003eGLA 블록\u003c/strong\u003e 을 통한 효율적인 멀티스케일 특징 학습은 경량 모델 설계에 대한 새로운 방향을 제시하여, 향후 \u003cstrong\u003e온디바이스 AI 음성 처리 애플리케이션\u003c/strong\u003e 개발에 기여할 수 있습니다.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e⚠️ \u003cstrong\u003e알림:\u003c/strong\u003e 이 리뷰는 AI로 작성되었습니다.\u003c/p\u003e\n\u003c/blockquote\u003e\n"])</script><script>self.__next_f.push([1,"5:[\"$\",\"div\",null,{\"className\":\"flex flex-col lg:flex-row gap-8\",\"children\":[[\"$\",\"aside\",null,{\"className\":\"lg:w-64 xl:w-72 order-1 lg:order-none\",\"children\":[\"$\",\"div\",null,{\"className\":\"sidebar sticky\",\"children\":[\"$\",\"nav\",null,{\"className\":\"space-y-4\",\"children\":[[\"$\",\"div\",\"Backend\",{\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"Backend\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"Django\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/backend/django/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Django\",\" (\",6,\")\"]}]}],[\"$\",\"li\",\"Logging\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/backend/logging/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Logging\",\" (\",1,\")\"]}]}]]}]]}],[\"$\",\"div\",\"Python\",{\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"Python\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"PEP\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/python/pep/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"PEP\",\" (\",650,\")\"]}]}]]}]]}],[\"$\",\"div\",\"AI/ML\",{\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"AI/ML\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"LLM\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/ai/llm/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"LLM\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"Review\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/ai/review/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Review\",\" (\",1734,\")\"]}]}]]}]]}],[\"$\",\"div\",\"DevOps\",{\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"DevOps\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"Nginx\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/devops/nginx/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Nginx\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"Docker\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/devops/docker/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Docker\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"SafeLine\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/devops/safeline/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"SafeLine\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"Jenkins\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/devops/jenkins/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Jenkins\",\" (\",3,\")\"]}]}],[\"$\",\"li\",\"GitHub Actions\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/devops/github-actions/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"GitHub Actions\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"AWS\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/devops/aws/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"AWS\",\" (\",1,\")\"]}]}]]}]]}],[\"$\",\"div\",\"etc\",{\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"etc\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"Me\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/etc/me/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Me\",\" (\",3,\")\"]}]}],[\"$\",\"li\",\"Chrome Extension\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/etc/chrome-extension/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Chrome Extension\",\" (\",1,\")\"]}]}]]}]]}]]}]}]}],[\"$\",\"main\",null,{\"className\":\"flex-1\",\"children\":[\"$\",\"article\",null,{\"className\":\"page\",\"children\":[[\"$\",\"header\",null,{\"className\":\"mb-8\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"page__title\",\"children\":\"[논문리뷰] Efficient Audio-Visual Speech Separation with Discrete Lip Semantics and Multi-Scale Global-Local Attention\"}],[\"$\",\"div\",null,{\"className\":\"page__meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"span\",null,{\"className\":\"ml-4\",\"children\":[\"수정: \",\"2025년 10월 1일\"]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"page__content\",\"children\":[\"$\",\"div\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$e\"}}]}],[\"$\",\"footer\",null,{\"className\":\"page__meta mt-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"page__taxonomy\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"text-sm font-medium text-gray-900 mb-2\",\"children\":\"태그\"}],[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Audio-Visual Speech Separation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Audio-Visual Speech Separation\"]}],[\"$\",\"span\",\"Deep Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deep Learning\"]}],[\"$\",\"span\",\"Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Efficiency\"]}],[\"$\",\"span\",\"Discrete Lip Semantics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Discrete Lip Semantics\"]}],[\"$\",\"span\",\"Global-Local Attention\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Global-Local Attention\"]}],[\"$\",\"span\",\"Lightweight Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Lightweight Models\"]}],[\"$\",\"span\",\"VQ-VAE\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"VQ-VAE\"]}]]]}]}],[\"$\",\"section\",null,{\"className\":\"mt-12 border-t border-gray-200 pt-8\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-base font-semibold text-gray-900 mb-4\",\"children\":[\"Review\",\" 의 다른글\"]}],[\"$\",\"ul\",null,{\"className\":\"space-y-2 text-sm\",\"children\":[[\"$\",\"li\",null,{\"className\":\"text-gray-500\",\"children\":[\"이전글\",\" \",[\"$\",\"$La\",null,{\"href\":\"/ai/review/2025-10-1-DeepScientist-Advancing-Frontier-Pushing-Scientific-Findings-Progressively/\",\"className\":\"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4\",\"children\":\"[논문리뷰] DeepScientist: Advancing Frontier-Pushing Scientific Findings Progressively\"}]]}],[\"$\",\"li\",null,{\"className\":\"text-gray-900 font-semibold\",\"children\":[\"현재글 : \",\"[논문리뷰] Efficient Audio-Visual Speech Separation with Discrete Lip Semantics and Multi-Scale Global-Local Attention\"]}],[\"$\",\"li\",null,{\"className\":\"text-gray-500\",\"children\":[\"다음글\",\" \",[\"$\",\"$La\",null,{\"href\":\"/ai/review/2025-10-1-EntroPE-Entropy-Guided-Dynamic-Patch-Encoder-for-Time-Series-Forecasting/\",\"className\":\"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4\",\"children\":\"[논문리뷰] EntroPE: Entropy-Guided Dynamic Patch Encoder for Time Series Forecasting\"}]]}]]}]]}]]}]}]]}]\n"])</script><script>self.__next_f.push([1,"b:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"secrett2633's blog\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\"}],[\"$\",\"meta\",\"4\",{\"name\":\"author\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"5\",{\"name\":\"keywords\",\"content\":\"Django, Python, DevOps, AI, ML, 블로그, 기술\"}],[\"$\",\"meta\",\"6\",{\"name\":\"creator\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"7\",{\"name\":\"publisher\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"8\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"9\",{\"name\":\"googlebot\",\"content\":\"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1\"}],[\"$\",\"link\",\"10\",{\"rel\":\"canonical\",\"href\":\"https://blog.secrett2633.site/\"}],[\"$\",\"meta\",\"11\",{\"name\":\"format-detection\",\"content\":\"telephone=no, address=no, email=no\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:title\",\"content\":\"secrett2633's blog\"}],[\"$\",\"meta\",\"13\",{\"property\":\"og:description\",\"content\":\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\"}],[\"$\",\"meta\",\"14\",{\"property\":\"og:url\",\"content\":\"https://blog.secrett2633.site/\"}],[\"$\",\"meta\",\"15\",{\"property\":\"og:site_name\",\"content\":\"secrett2633's blog\"}],[\"$\",\"meta\",\"16\",{\"property\":\"og:locale\",\"content\":\"ko_KR\"}],[\"$\",\"meta\",\"17\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"18\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"19\",{\"name\":\"twitter:title\",\"content\":\"secrett2633's blog\"}],[\"$\",\"meta\",\"20\",{\"name\":\"twitter:description\",\"content\":\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\"}],[\"$\",\"link\",\"21\",{\"rel\":\"icon\",\"href\":\"/icon.ico?6d9f34d4948640b8\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}],[\"$\",\"meta\",\"22\",{\"name\":\"next-size-adjust\"}]]\n4:null\n"])</script></body></html>