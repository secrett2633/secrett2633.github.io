3:I[9275,[],""]
5:I[1343,[],""]
6:I[9157,["231","static/chunks/231-ee5764c1002761f9.js","132","static/chunks/132-273e49420772df1e.js","185","static/chunks/app/layout-d443cbc354279241.js"],"default"]
7:I[231,["231","static/chunks/231-ee5764c1002761f9.js","877","static/chunks/app/%5B...slug%5D/page-ef33f0f4c1a350bd.js"],""]
8:I[4080,["231","static/chunks/231-ee5764c1002761f9.js","132","static/chunks/132-273e49420772df1e.js","185","static/chunks/app/layout-d443cbc354279241.js"],""]
4:["slug","ai/review/2025-9-12-FLUX-Reason-6M-PRISM-Bench-A-Million-Scale-Text-to-Image-Reasoning-Dataset-and-Comprehensive-Benchmark","c"]
0:["mJI0q5Z-SQWBtT83kG_N7",[[["",{"children":[["slug","ai/review/2025-9-12-FLUX-Reason-6M-PRISM-Bench-A-Million-Scale-Text-to-Image-Reasoning-Dataset-and-Comprehensive-Benchmark","c"],{"children":["__PAGE__?{\"slug\":[\"ai\",\"review\",\"2025-9-12-FLUX-Reason-6M-PRISM-Bench-A-Million-Scale-Text-to-Image-Reasoning-Dataset-and-Comprehensive-Benchmark\"]}",{}]}]},"$undefined","$undefined",true],["",{"children":[["slug","ai/review/2025-9-12-FLUX-Reason-6M-PRISM-Bench-A-Million-Scale-Text-to-Image-Reasoning-Dataset-and-Comprehensive-Benchmark","c"],{"children":["__PAGE__",{},[["$L1","$L2"],null],null]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","$4","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},[["$","html",null,{"lang":"ko","className":"no-js","children":[["$","head",null,{"children":[["$","meta",null,{"name":"msapplication-TileColor","content":"#ffc40d"}],["$","meta",null,{"name":"theme-color","content":"#ffffff"}],["$","link",null,{"rel":"dns-prefetch","href":"https://www.googletagmanager.com"}],["$","link",null,{"rel":"preconnect","href":"https://www.googletagmanager.com","crossOrigin":"anonymous"}],["$","link",null,{"rel":"dns-prefetch","href":"https://giscus.app"}],["$","link",null,{"rel":"preconnect","href":"https://giscus.app","crossOrigin":"anonymous"}],["$","meta",null,{"httpEquiv":"X-Content-Type-Options","content":"nosniff"}],["$","meta",null,{"name":"referrer","content":"strict-origin-when-cross-origin"}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"WebSite\",\"name\":\"secrett2633's blog\",\"url\":\"https://blog.secrett2633.cloud\",\"description\":\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\",\"inLanguage\":\"ko\",\"publisher\":{\"@type\":\"Person\",\"name\":\"secrett2633\",\"url\":\"https://blog.secrett2633.cloud\"}}"}}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"Person\",\"name\":\"secrett2633\",\"url\":\"https://blog.secrett2633.cloud\",\"sameAs\":[\"https://github.com/secrett2633\"]}"}}]]}],["$","body",null,{"className":"__className_f367f3 layout--default","children":[["$","a",null,{"href":"#main-content","className":"sr-only focus:not-sr-only focus:absolute focus:z-50 focus:p-4 focus:bg-white focus:text-blue-600","children":"본문으로 건너뛰기"}],["$","div",null,{"className":"min-h-screen bg-gray-50","children":[["$","$L6",null,{}],["$","main",null,{"id":"main-content","className":"initial-content","children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","div",null,{"className":"min-h-screen flex items-center justify-center bg-gray-50","children":["$","div",null,{"className":"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center","children":[["$","h1",null,{"className":"text-6xl font-bold text-primary-600 mb-4","children":"404"}],["$","h2",null,{"className":"text-2xl font-semibold text-gray-900 mb-4","children":"페이지를 찾을 수 없습니다"}],["$","p",null,{"className":"text-gray-600 mb-8","children":"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다."}],["$","$L7",null,{"href":"/","className":"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors","children":"홈으로 돌아가기"}]]}]}],"notFoundStyles":[],"styles":null}]}],["$","div",null,{"id":"footer","className":"page__footer","children":["$","footer",null,{"className":"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8","children":["$","div",null,{"className":"text-center text-gray-500 text-sm","children":["$","p",null,{"children":["© ",2026," secrett2633. All rights reserved."]}]}]}]}]]}],["$","$L8",null,{"src":"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY","strategy":"afterInteractive"}],["$","$L8",null,{"id":"gtag-init","strategy":"afterInteractive","children":"window.dataLayer = window.dataLayer || [];\n            function gtag(){dataLayer.push(arguments);}\n            gtag('js', new Date());\n            gtag('config', 'G-NE2W3CFPNY');"}]]}]]}],null],[["$","div",null,{"className":"flex items-center justify-center min-h-screen","role":"status","aria-label":"로딩 중","children":[["$","div",null,{"className":"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600"}],["$","span",null,{"className":"sr-only","children":"로딩 중..."}]]}],[],[]]],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/edb8d4ad4fe2f3b0.css","precedence":"next","crossOrigin":"$undefined"}]],[null,"$L9"]]]]]
c:I[646,["231","static/chunks/231-ee5764c1002761f9.js","877","static/chunks/app/%5B...slug%5D/page-ef33f0f4c1a350bd.js"],"default"]
a:T52b,{"@context":"https://schema.org","@type":"BlogPosting","headline":"[논문리뷰] FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark","description":"Shuai Bai이 arXiv에 게시한 'FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark' 논문에 대한 자세한 리뷰입니다.","url":"https://blog.secrett2633.cloud/ai/review/2025-9-12-FLUX-Reason-6M-PRISM-Bench-A-Million-Scale-Text-to-Image-Reasoning-Dataset-and-Comprehensive-Benchmark","datePublished":"2025-09-12T04:12:46.000Z","dateModified":"2025-09-12T04:12:46.000Z","author":{"@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud"},"publisher":{"@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.secrett2633.cloud/ai/review/2025-9-12-FLUX-Reason-6M-PRISM-Bench-A-Million-Scale-Text-to-Image-Reasoning-Dataset-and-Comprehensive-Benchmark"},"image":"https://blog.secrett2633.cloud/og-default.png","isAccessibleForFree":true,"inLanguage":"ko","wordCount":293,"articleSection":"Review","keywords":"Review, Text-to-Image Generation, Reasoning Dataset, Benchmark, Generation Chain-of-Thought, Vision-Language Model, Image Aesthetics, Prompt Alignment"}b:Tdf5,<blockquote>
<p><strong>링크:</strong> <a href="https://arxiv.org/abs/2509.09680" target="_blank" rel="noopener noreferrer">논문 PDF로 바로 열기</a></p>
</blockquote>
<p><strong>저자:</strong> Rongyao Fang, Aldrich Yu, Chengqi Duan, Linjiang Huang, Shuai Bai, Yuxuan Cai, Kun Wang, Si Liu, Xihui Liu, Hongsheng Li</p>
<h2 id="핵심-연구-목표"><a href="#핵심-연구-목표">핵심 연구 목표</a></h2>
<p>본 연구는 오픈소스 Text-to-Image (T2I) 모델의 추론 능력 발전을 저해하는 대규모 추론 중심 데이터셋과 포괄적인 평가 벤치마크의 부재를 해결하는 것을 목표로 합니다. 이를 통해 선도적인 클로즈드소스 시스템과의 성능 격차를 해소하고, 복잡한 지시 사항을 따르는 T2I 모델의 개발 및 평가를 촉진하고자 합니다.</p>
<h2 id="핵심-방법론"><a href="#핵심-방법론">핵심 방법론</a></h2>
<p>연구진은 <strong>6백만 개 고품질 FLUX 생성 이미지</strong> 와 <strong>2천만 개 이중 언어 설명</strong> 으로 구성된 <strong>FLUX-Reason-6M 데이터셋</strong> 을 구축했습니다. 이 데이터셋은 <strong>Imagination, Entity, Text rendering, Style, Affection, Composition</strong> 의 여섯 가지 핵심 특성으로 구성되며, 복잡한 이미지 생성 단계를 상세히 설명하는 <strong>Generation Chain-of-Thought (GCoT)</strong> 를 포함합니다. 또한, 이 데이터셋과 GCoT를 기반으로 <strong>PRISM-Bench 벤치마크</strong> 를 개발하여, 7가지 트랙(6가지 특성 및 <strong>Long Text</strong> )에서 <strong>GPT-4.1</strong> 및 <strong>Qwen2.5-VL-72B</strong> 와 같은 고급 VLM을 사용하여 프롬프트-이미지 정렬 및 이미지 미학을 평가합니다.</p>
<h2 id="주요-결과"><a href="#주요-결과">주요 결과</a></h2>
<p><strong>PRISM-Bench</strong> 에 대한 19개 선도 T2I 모델의 광범위한 평가 결과, <strong>GPT-Image-1</strong> 이 총점 <strong>86.3</strong> 으로 가장 높은 성능을 보였고, <strong>Gemini2.5-Flash-Image</strong> 가 <strong>85.3</strong> 으로 뒤를 이었습니다. 그러나 모든 모델은 <strong>Text rendering</strong> (모든 트랙 중 가장 낮은 평균 점수) 및 <strong>Long Text</strong> 와 같은 복잡한 추론 작업에서 상당한 성능 격차를 보였습니다. 예를 들어, <strong>Long Text</strong> 트랙의 영어 평가에서 <strong>Gemini2.5-Flash-Image</strong> 는 <strong>81.1</strong> , <strong>GPT-Image-1</strong> 은 <strong>78.3</strong> 을 기록하며, 모델들의 추론 능력에 상당한 개선 여지가 있음을 강조했습니다.</p>
<h2 id="ai-실무자를-위한-시사점"><a href="#ai-실무자를-위한-시사점">AI 실무자를 위한 시사점</a></h2>
<p><strong>FLUX-Reason-6M</strong> 은 대규모의 추론 중심 데이터셋으로서, 차세대 T2I 모델이 복잡한 지시 사항을 이해하고 생성하는 능력을 학습하는 데 필수적인 자원을 제공합니다. <strong>PRISM-Bench</strong> 는 고급 VLM을 활용한 미세하고 견고한 평가 프레임워크를 제공하여, 실무자들이 모델의 특정 약점(예: 텍스트 렌더링, 장문 추론)을 식별하고 개선 방향을 설정하는 데 도움을 줍니다. 이는 T2I 모델 개발 로드맵을 제시하며, 특히 복잡한 추론 작업에 대한 지속적인 연구 개발의 중요성을 시사합니다.</p>
<blockquote>
<p>⚠️ <strong>알림:</strong> 이 리뷰는 AI로 작성되었습니다.</p>
</blockquote>
2:[["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"$a"}}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"BreadcrumbList\",\"itemListElement\":[{\"@type\":\"ListItem\",\"position\":1,\"name\":\"홈\",\"item\":\"https://blog.secrett2633.cloud/\"},{\"@type\":\"ListItem\",\"position\":2,\"name\":\"Review\",\"item\":\"https://blog.secrett2633.cloud/ai/review\"},{\"@type\":\"ListItem\",\"position\":3,\"name\":\"[논문리뷰] FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark\",\"item\":\"https://blog.secrett2633.cloud/ai/review/2025-9-12-FLUX-Reason-6M-PRISM-Bench-A-Million-Scale-Text-to-Image-Reasoning-Dataset-and-Comprehensive-Benchmark\"}]}"}}],["$","div",null,{"className":"space-y-6","children":["$","div",null,{"className":"flex flex-col lg:flex-row gap-8","children":[["$","aside",null,{"className":"lg:w-64 xl:w-72 order-1 lg:order-none","children":["$","div",null,{"className":"sidebar sticky","children":["$","nav",null,{"className":"space-y-4","aria-label":"카테고리 네비게이션","children":[["$","div","Backend",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"Backend"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Django",{"children":["$","$L7",null,{"href":"/backend/django","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Django"," (",6,")"]}]}],["$","li","Logging",{"children":["$","$L7",null,{"href":"/backend/logging","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Logging"," (",1,")"]}]}]]}]]}],["$","div","Python",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"Python"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","PEP",{"children":["$","$L7",null,{"href":"/python/pep","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["PEP"," (",650,")"]}]}]]}]]}],["$","div","AI/ML",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"AI/ML"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","LLM",{"children":["$","$L7",null,{"href":"/ai/llm","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["LLM"," (",1,")"]}]}],["$","li","Review",{"children":["$","$L7",null,{"href":"/ai/review","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Review"," (",2741,")"]}]}]]}]]}],["$","div","DevOps",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"DevOps"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Nginx",{"children":["$","$L7",null,{"href":"/devops/nginx","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Nginx"," (",1,")"]}]}],["$","li","Docker",{"children":["$","$L7",null,{"href":"/devops/docker","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Docker"," (",1,")"]}]}],["$","li","SafeLine",{"children":["$","$L7",null,{"href":"/devops/safeline","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["SafeLine"," (",1,")"]}]}],["$","li","Jenkins",{"children":["$","$L7",null,{"href":"/devops/jenkins","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Jenkins"," (",3,")"]}]}],["$","li","GitHub Actions",{"children":["$","$L7",null,{"href":"/devops/github-actions","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["GitHub Actions"," (",1,")"]}]}],["$","li","AWS",{"children":["$","$L7",null,{"href":"/devops/aws","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["AWS"," (",1,")"]}]}]]}]]}],["$","div","etc",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"etc"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Me",{"children":["$","$L7",null,{"href":"/etc/me","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Me"," (",3,")"]}]}],["$","li","Chrome Extension",{"children":["$","$L7",null,{"href":"/etc/chrome-extension","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Chrome Extension"," (",1,")"]}]}]]}]]}]]}]}]}],["$","div",null,{"className":"flex-1","children":[["$","nav",null,{"aria-label":"breadcrumb","className":"text-sm text-gray-500 mb-4","children":["$","ol",null,{"className":"flex flex-wrap items-center gap-1","children":[["$","li",null,{"children":["$","$L7",null,{"href":"/","className":"hover:text-gray-700","children":"홈"}]}],[["$","li","/ai/review",{"className":"flex items-center gap-1","children":[["$","span",null,{"aria-hidden":"true","children":"/"}],["$","$L7",null,{"href":"/ai/review","className":"hover:text-gray-700","children":"Review"}]]}],["$","li","/ai/review/2025-9-12-FLUX-Reason-6M-PRISM-Bench-A-Million-Scale-Text-to-Image-Reasoning-Dataset-and-Comprehensive-Benchmark",{"className":"flex items-center gap-1","children":[["$","span",null,{"aria-hidden":"true","children":"/"}],["$","span",null,{"className":"text-gray-900","aria-current":"page","children":"[논문리뷰] FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark"}]]}]]]}]}],["$","article",null,{"className":"page","children":[["$","header",null,{"className":"mb-8","children":[["$","h1",null,{"className":"page__title","children":"[논문리뷰] FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark"}],["$","div",null,{"className":"page__meta","children":[["$","time",null,{"dateTime":"2025-09-12 13:12:46+0900","children":"2025년 9월 12일"}],["$","time",null,{"className":"ml-4","dateTime":"2025-09-12T04:12:46.000Z","children":["수정: ","2025년 9월 12일"]}]]}]]}],["$","div",null,{"className":"page__content","children":["$","div",null,{"dangerouslySetInnerHTML":{"__html":"$b"}}]}],["$","footer",null,{"className":"page__meta mt-8","children":["$","div",null,{"className":"page__taxonomy","children":[["$","span",null,{"className":"text-sm font-medium text-gray-900 mb-2 block","children":"태그"}],[["$","$L7","Review",{"href":"/tags/Review","className":"page__taxonomy-item","children":["#","Review"]}],["$","$L7","Text-to-Image Generation",{"href":"/tags/Text-to-Image%20Generation","className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","$L7","Reasoning Dataset",{"href":"/tags/Reasoning%20Dataset","className":"page__taxonomy-item","children":["#","Reasoning Dataset"]}],["$","$L7","Benchmark",{"href":"/tags/Benchmark","className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","$L7","Generation Chain-of-Thought",{"href":"/tags/Generation%20Chain-of-Thought","className":"page__taxonomy-item","children":["#","Generation Chain-of-Thought"]}],["$","$L7","Vision-Language Model",{"href":"/tags/Vision-Language%20Model","className":"page__taxonomy-item","children":["#","Vision-Language Model"]}],["$","$L7","Image Aesthetics",{"href":"/tags/Image%20Aesthetics","className":"page__taxonomy-item","children":["#","Image Aesthetics"]}],["$","$L7","Prompt Alignment",{"href":"/tags/Prompt%20Alignment","className":"page__taxonomy-item","children":["#","Prompt Alignment"]}]]]}]}],["$","$Lc",null,{"postPermalink":"/ai/review/2025-9-12-FLUX-Reason-6M-PRISM-Bench-A-Million-Scale-Text-to-Image-Reasoning-Dataset-and-Comprehensive-Benchmark","postId":"2025-9-12-FLUX-Reason-6M-PRISM-Bench-A-Million-Scale-Text-to-Image-Reasoning-Dataset-and-Comprehensive-Benchmark"}],["$","section",null,{"className":"mt-12 border-t border-gray-200 pt-8","children":[["$","h3",null,{"className":"text-base font-semibold text-gray-900 mb-4","children":["Review"," 의 다른글"]}],["$","ul",null,{"className":"space-y-2 text-sm","children":[["$","li",null,{"className":"text-gray-500","children":["이전글"," ",["$","$L7",null,{"href":"/ai/review/2025-9-12-EchoX-Towards-Mitigating-Acoustic-Semantic-Gap-via-Echo-Training-for-Speech-to-Speech-LLMs","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] EchoX: Towards Mitigating Acoustic-Semantic Gap via Echo Training for Speech-to-Speech LLMs"}]]}],["$","li",null,{"className":"text-gray-900 font-semibold","children":["현재글 : ","[논문리뷰] FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark"]}],["$","li",null,{"className":"text-gray-500","children":["다음글"," ",["$","$L7",null,{"href":"/ai/review/2025-9-12-Gradient-Attention-Guided-Dual-Masking-Synergetic-Framework-for-Robust-Text-based-Person-Retrieval","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] Gradient-Attention Guided Dual-Masking Synergetic Framework for Robust Text-based Person Retrieval"}]]}]]}]]}]]}]]}]]}]}]]
9:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"[논문리뷰] FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark - secrett2633's blog"}],["$","meta","3",{"name":"description","content":"Shuai Bai이 arXiv에 게시한 'FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark' 논문에 대한 자세한 리뷰입니다."}],["$","meta","4",{"name":"author","content":"secrett2633"}],["$","link","5",{"rel":"manifest","href":"/manifest.json","crossOrigin":"use-credentials"}],["$","meta","6",{"name":"keywords","content":"Django, Python, DevOps, AI, ML, 블로그, 기술"}],["$","meta","7",{"name":"creator","content":"secrett2633"}],["$","meta","8",{"name":"publisher","content":"secrett2633"}],["$","meta","9",{"name":"robots","content":"index, follow"}],["$","meta","10",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","11",{"rel":"canonical","href":"https://blog.secrett2633.cloud/ai/review/2025-9-12-FLUX-Reason-6M-PRISM-Bench-A-Million-Scale-Text-to-Image-Reasoning-Dataset-and-Comprehensive-Benchmark"}],["$","meta","12",{"name":"format-detection","content":"telephone=no, address=no, email=no"}],["$","meta","13",{"property":"og:title","content":"[논문리뷰] FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark"}],["$","meta","14",{"property":"og:description","content":"Shuai Bai이 arXiv에 게시한 'FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark' 논문에 대한 자세한 리뷰입니다."}],["$","meta","15",{"property":"og:url","content":"https://blog.secrett2633.cloud/ai/review/2025-9-12-FLUX-Reason-6M-PRISM-Bench-A-Million-Scale-Text-to-Image-Reasoning-Dataset-and-Comprehensive-Benchmark"}],["$","meta","16",{"property":"og:type","content":"article"}],["$","meta","17",{"property":"article:published_time","content":"2025-09-12T04:12:46.000Z"}],["$","meta","18",{"property":"article:modified_time","content":"2025-09-12T04:12:46.000Z"}],["$","meta","19",{"property":"article:author","content":"secrett2633"}],["$","meta","20",{"property":"article:section","content":"Review"}],["$","meta","21",{"property":"article:tag","content":"Review"}],["$","meta","22",{"property":"article:tag","content":"Text-to-Image Generation"}],["$","meta","23",{"property":"article:tag","content":"Reasoning Dataset"}],["$","meta","24",{"property":"article:tag","content":"Benchmark"}],["$","meta","25",{"property":"article:tag","content":"Generation Chain-of-Thought"}],["$","meta","26",{"property":"article:tag","content":"Vision-Language Model"}],["$","meta","27",{"property":"article:tag","content":"Image Aesthetics"}],["$","meta","28",{"property":"article:tag","content":"Prompt Alignment"}],["$","meta","29",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","30",{"name":"twitter:creator","content":"@secrett2633"}],["$","meta","31",{"name":"twitter:title","content":"[논문리뷰] FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark"}],["$","meta","32",{"name":"twitter:description","content":"Shuai Bai이 arXiv에 게시한 'FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark' 논문에 대한 자세한 리뷰입니다."}],["$","link","33",{"rel":"icon","href":"/icon.ico?6d9f34d4948640b8","type":"image/x-icon","sizes":"16x16"}],["$","meta","34",{"name":"next-size-adjust"}]]
1:null
