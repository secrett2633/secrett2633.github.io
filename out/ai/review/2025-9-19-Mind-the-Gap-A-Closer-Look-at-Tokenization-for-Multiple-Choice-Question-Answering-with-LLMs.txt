3:I[9275,[],""]
5:I[1343,[],""]
6:I[9157,["231","static/chunks/231-ee5764c1002761f9.js","132","static/chunks/132-273e49420772df1e.js","185","static/chunks/app/layout-d443cbc354279241.js"],"default"]
7:I[231,["231","static/chunks/231-ee5764c1002761f9.js","877","static/chunks/app/%5B...slug%5D/page-ef33f0f4c1a350bd.js"],""]
8:I[4080,["231","static/chunks/231-ee5764c1002761f9.js","132","static/chunks/132-273e49420772df1e.js","185","static/chunks/app/layout-d443cbc354279241.js"],""]
4:["slug","ai/review/2025-9-19-Mind-the-Gap-A-Closer-Look-at-Tokenization-for-Multiple-Choice-Question-Answering-with-LLMs","c"]
0:["mJI0q5Z-SQWBtT83kG_N7",[[["",{"children":[["slug","ai/review/2025-9-19-Mind-the-Gap-A-Closer-Look-at-Tokenization-for-Multiple-Choice-Question-Answering-with-LLMs","c"],{"children":["__PAGE__?{\"slug\":[\"ai\",\"review\",\"2025-9-19-Mind-the-Gap-A-Closer-Look-at-Tokenization-for-Multiple-Choice-Question-Answering-with-LLMs\"]}",{}]}]},"$undefined","$undefined",true],["",{"children":[["slug","ai/review/2025-9-19-Mind-the-Gap-A-Closer-Look-at-Tokenization-for-Multiple-Choice-Question-Answering-with-LLMs","c"],{"children":["__PAGE__",{},[["$L1","$L2"],null],null]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","$4","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},[["$","html",null,{"lang":"ko","className":"no-js","children":[["$","head",null,{"children":[["$","meta",null,{"name":"msapplication-TileColor","content":"#ffc40d"}],["$","meta",null,{"name":"theme-color","content":"#ffffff"}],["$","link",null,{"rel":"dns-prefetch","href":"https://www.googletagmanager.com"}],["$","link",null,{"rel":"preconnect","href":"https://www.googletagmanager.com","crossOrigin":"anonymous"}],["$","link",null,{"rel":"dns-prefetch","href":"https://giscus.app"}],["$","link",null,{"rel":"preconnect","href":"https://giscus.app","crossOrigin":"anonymous"}],["$","meta",null,{"httpEquiv":"X-Content-Type-Options","content":"nosniff"}],["$","meta",null,{"name":"referrer","content":"strict-origin-when-cross-origin"}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"WebSite\",\"name\":\"secrett2633's blog\",\"url\":\"https://blog.secrett2633.cloud\",\"description\":\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\",\"inLanguage\":\"ko\",\"publisher\":{\"@type\":\"Person\",\"name\":\"secrett2633\",\"url\":\"https://blog.secrett2633.cloud\"}}"}}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"Person\",\"name\":\"secrett2633\",\"url\":\"https://blog.secrett2633.cloud\",\"sameAs\":[\"https://github.com/secrett2633\"]}"}}]]}],["$","body",null,{"className":"__className_f367f3 layout--default","children":[["$","a",null,{"href":"#main-content","className":"sr-only focus:not-sr-only focus:absolute focus:z-50 focus:p-4 focus:bg-white focus:text-blue-600","children":"본문으로 건너뛰기"}],["$","div",null,{"className":"min-h-screen bg-gray-50","children":[["$","$L6",null,{}],["$","main",null,{"id":"main-content","className":"initial-content","children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","div",null,{"className":"min-h-screen flex items-center justify-center bg-gray-50","children":["$","div",null,{"className":"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center","children":[["$","h1",null,{"className":"text-6xl font-bold text-primary-600 mb-4","children":"404"}],["$","h2",null,{"className":"text-2xl font-semibold text-gray-900 mb-4","children":"페이지를 찾을 수 없습니다"}],["$","p",null,{"className":"text-gray-600 mb-8","children":"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다."}],["$","$L7",null,{"href":"/","className":"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors","children":"홈으로 돌아가기"}]]}]}],"notFoundStyles":[],"styles":null}]}],["$","div",null,{"id":"footer","className":"page__footer","children":["$","footer",null,{"className":"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8","children":["$","div",null,{"className":"text-center text-gray-500 text-sm","children":["$","p",null,{"children":["© ",2026," secrett2633. All rights reserved."]}]}]}]}]]}],["$","$L8",null,{"src":"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY","strategy":"afterInteractive"}],["$","$L8",null,{"id":"gtag-init","strategy":"afterInteractive","children":"window.dataLayer = window.dataLayer || [];\n            function gtag(){dataLayer.push(arguments);}\n            gtag('js', new Date());\n            gtag('config', 'G-NE2W3CFPNY');"}]]}]]}],null],[["$","div",null,{"className":"flex items-center justify-center min-h-screen","role":"status","aria-label":"로딩 중","children":[["$","div",null,{"className":"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600"}],["$","span",null,{"className":"sr-only","children":"로딩 중..."}]]}],[],[]]],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/edb8d4ad4fe2f3b0.css","precedence":"next","crossOrigin":"$undefined"}]],[null,"$L9"]]]]]
c:I[646,["231","static/chunks/231-ee5764c1002761f9.js","877","static/chunks/app/%5B...slug%5D/page-ef33f0f4c1a350bd.js"],"default"]
a:T4e5,{"@context":"https://schema.org","@type":"BlogPosting","headline":"[논문리뷰] Mind the Gap: A Closer Look at Tokenization for Multiple-Choice Question Answering with LLMs","description":"Katharina von der Wense이 arXiv에 게시한 'Mind the Gap: A Closer Look at Tokenization for Multiple-Choice Question Answering with LLMs' 논문에 대한 자세한 리뷰입니다.","url":"https://blog.secrett2633.cloud/ai/review/2025-9-19-Mind-the-Gap-A-Closer-Look-at-Tokenization-for-Multiple-Choice-Question-Answering-with-LLMs","datePublished":"2025-09-19T04:12:21.000Z","dateModified":"2025-09-19T04:12:21.000Z","author":{"@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud"},"publisher":{"@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.secrett2633.cloud/ai/review/2025-9-19-Mind-the-Gap-A-Closer-Look-at-Tokenization-for-Multiple-Choice-Question-Answering-with-LLMs"},"image":"https://blog.secrett2633.cloud/og-default.png","isAccessibleForFree":true,"inLanguage":"ko","wordCount":277,"articleSection":"Review","keywords":"Review, LLM Evaluation, Multiple-Choice QA, Tokenization, Prompt Sensitivity, Accuracy, Calibration, Model Ranking"}b:Tced,<blockquote>
<p><strong>링크:</strong> <a href="https://arxiv.org/abs/2509.15020" target="_blank" rel="noopener noreferrer">논문 PDF로 바로 열기</a></p>
</blockquote>
<p><strong>저자:</strong> Mario Sanz-Guerrero, Minh Duc Bui, Katharina von der Wense</p>
<h2 id="핵심-연구-목표"><a href="#핵심-연구-목표">핵심 연구 목표</a></h2>
<p>본 논문은 대규모 언어 모델(LLM)의 객관식 질문 답변(MCQA) 평가 시, 답변 레이블 직전의 공백 문자 토큰화 방식이 모델 성능에 미치는 영향을 규명하는 것을 목표로 합니다. 현재 표준화되지 않은 관행으로 인해 발생하는 성능 및 모델 순위 변화를 분석하고, 신뢰성 있는 LLM 비교를 위한 최적의 토큰화 전략을 제시하고자 합니다.</p>
<h2 id="핵심-방법론"><a href="#핵심-방법론">핵심 방법론</a></h2>
<p>연구진은 <strong>15개 LLM</strong> 과 <strong>6개 MCQA 데이터셋</strong> ( <strong>MMLU, ARC Challenge, HellaSwag 등</strong> )을 사용하여 실험을 수행했습니다. 공백이 없는 "Letter token" ( <strong>"X"</strong> ) 방식과 공백이 포함된 "Space-Letter token" ( <strong>"_X"</strong> ) 방식의 두 가지 토큰화 전략을 비교했으며, <strong>정확도</strong> 와 <strong>예측 보정 오차(ECE)</strong> 를 주요 지표로 측정했습니다. 통계적 유의성 검정( <strong>McNemar's test</strong> 및 <strong>paired bootstrap resampling</strong> )을 통해 결과의 신뢰성을 확보하고, 다양한 프롬프트 형식과 언어에 대한 <strong>강건성</strong> 을 검증했습니다.</p>
<h2 id="주요-결과"><a href="#주요-결과">주요 결과</a></h2>
<p>"Space-Letter token" ( <strong>"_X"</strong> ) 전략을 사용했을 때 대부분의 모델과 데이터셋에서 <strong>최대 11%의 정확도 향상</strong> 이 관찰되었으며, 이는 통계적으로 유의미했습니다. 또한, <strong>예측 보정 오차(ECE)가 최대 4배 감소</strong> 하여 모델 예측의 신뢰성이 크게 개선되었습니다. 흥미롭게도 이 사소한 토큰화 방식의 변화만으로 <strong>모델 순위가 재편</strong> 되었는데, 예를 들어 Llama 3.1 70B Instruct가 "Letter token" 방식에서 1위였으나, "Space-Letter token" 방식에서는 Qwen 2.5 72B가 1위로 올라섰습니다.</p>
<h2 id="ai-실무자를-위한-시사점"><a href="#ai-실무자를-위한-시사점">AI 실무자를 위한 시사점</a></h2>
<p>AI 실무자는 LLM 평가 시 <strong>사소해 보이는 토큰화 방식</strong> 이 모델의 <strong>정확도, 보정, 그리고 순위에 심대한 영향</strong> 을 미칠 수 있음을 인지해야 합니다. MCQA 평가에서는 공백을 답변 레이블과 함께 토큰화하는 <strong>"Space-Letter token" ("_X") 전략</strong> 이 일관된 성능 향상과 더 높은 예측 신뢰성을 제공하므로 이를 채택하는 것이 권장됩니다. 이는 <strong>LLM 평가 프로토콜의 표준화</strong> 가 필수적임을 강조하며, 신뢰할 수 있는 모델 비교를 위해 세부적인 구현 사항에 대한 투명성이 중요함을 시사합니다.</p>
<blockquote>
<p>⚠️ <strong>알림:</strong> 이 리뷰는 AI로 작성되었습니다.</p>
</blockquote>
2:[["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"$a"}}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"BreadcrumbList\",\"itemListElement\":[{\"@type\":\"ListItem\",\"position\":1,\"name\":\"홈\",\"item\":\"https://blog.secrett2633.cloud/\"},{\"@type\":\"ListItem\",\"position\":2,\"name\":\"Review\",\"item\":\"https://blog.secrett2633.cloud/ai/review\"},{\"@type\":\"ListItem\",\"position\":3,\"name\":\"[논문리뷰] Mind the Gap: A Closer Look at Tokenization for Multiple-Choice Question Answering with LLMs\",\"item\":\"https://blog.secrett2633.cloud/ai/review/2025-9-19-Mind-the-Gap-A-Closer-Look-at-Tokenization-for-Multiple-Choice-Question-Answering-with-LLMs\"}]}"}}],["$","div",null,{"className":"space-y-6","children":["$","div",null,{"className":"flex flex-col lg:flex-row gap-8","children":[["$","aside",null,{"className":"lg:w-64 xl:w-72 order-1 lg:order-none","children":["$","div",null,{"className":"sidebar sticky","children":["$","nav",null,{"className":"space-y-4","aria-label":"카테고리 네비게이션","children":[["$","div","Backend",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"Backend"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Django",{"children":["$","$L7",null,{"href":"/backend/django","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Django"," (",6,")"]}]}],["$","li","Logging",{"children":["$","$L7",null,{"href":"/backend/logging","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Logging"," (",1,")"]}]}]]}]]}],["$","div","Python",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"Python"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","PEP",{"children":["$","$L7",null,{"href":"/python/pep","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["PEP"," (",650,")"]}]}]]}]]}],["$","div","AI/ML",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"AI/ML"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","LLM",{"children":["$","$L7",null,{"href":"/ai/llm","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["LLM"," (",1,")"]}]}],["$","li","Review",{"children":["$","$L7",null,{"href":"/ai/review","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Review"," (",2741,")"]}]}]]}]]}],["$","div","DevOps",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"DevOps"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Nginx",{"children":["$","$L7",null,{"href":"/devops/nginx","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Nginx"," (",1,")"]}]}],["$","li","Docker",{"children":["$","$L7",null,{"href":"/devops/docker","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Docker"," (",1,")"]}]}],["$","li","SafeLine",{"children":["$","$L7",null,{"href":"/devops/safeline","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["SafeLine"," (",1,")"]}]}],["$","li","Jenkins",{"children":["$","$L7",null,{"href":"/devops/jenkins","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Jenkins"," (",3,")"]}]}],["$","li","GitHub Actions",{"children":["$","$L7",null,{"href":"/devops/github-actions","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["GitHub Actions"," (",1,")"]}]}],["$","li","AWS",{"children":["$","$L7",null,{"href":"/devops/aws","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["AWS"," (",1,")"]}]}]]}]]}],["$","div","etc",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"etc"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Me",{"children":["$","$L7",null,{"href":"/etc/me","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Me"," (",3,")"]}]}],["$","li","Chrome Extension",{"children":["$","$L7",null,{"href":"/etc/chrome-extension","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Chrome Extension"," (",1,")"]}]}]]}]]}]]}]}]}],["$","div",null,{"className":"flex-1","children":[["$","nav",null,{"aria-label":"breadcrumb","className":"text-sm text-gray-500 mb-4","children":["$","ol",null,{"className":"flex flex-wrap items-center gap-1","children":[["$","li",null,{"children":["$","$L7",null,{"href":"/","className":"hover:text-gray-700","children":"홈"}]}],[["$","li","/ai/review",{"className":"flex items-center gap-1","children":[["$","span",null,{"aria-hidden":"true","children":"/"}],["$","$L7",null,{"href":"/ai/review","className":"hover:text-gray-700","children":"Review"}]]}],["$","li","/ai/review/2025-9-19-Mind-the-Gap-A-Closer-Look-at-Tokenization-for-Multiple-Choice-Question-Answering-with-LLMs",{"className":"flex items-center gap-1","children":[["$","span",null,{"aria-hidden":"true","children":"/"}],["$","span",null,{"className":"text-gray-900","aria-current":"page","children":"[논문리뷰] Mind the Gap: A Closer Look at Tokenization for Multiple-Choice Question Answering with LLMs"}]]}]]]}]}],["$","article",null,{"className":"page","children":[["$","header",null,{"className":"mb-8","children":[["$","h1",null,{"className":"page__title","children":"[논문리뷰] Mind the Gap: A Closer Look at Tokenization for Multiple-Choice Question Answering with LLMs"}],["$","div",null,{"className":"page__meta","children":[["$","time",null,{"dateTime":"2025-09-19 13:12:21+0900","children":"2025년 9월 19일"}],["$","time",null,{"className":"ml-4","dateTime":"2025-09-19T04:12:21.000Z","children":["수정: ","2025년 9월 19일"]}]]}]]}],["$","div",null,{"className":"page__content","children":["$","div",null,{"dangerouslySetInnerHTML":{"__html":"$b"}}]}],["$","footer",null,{"className":"page__meta mt-8","children":["$","div",null,{"className":"page__taxonomy","children":[["$","span",null,{"className":"text-sm font-medium text-gray-900 mb-2 block","children":"태그"}],[["$","$L7","Review",{"href":"/tags/Review","className":"page__taxonomy-item","children":["#","Review"]}],["$","$L7","LLM Evaluation",{"href":"/tags/LLM%20Evaluation","className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","$L7","Multiple-Choice QA",{"href":"/tags/Multiple-Choice%20QA","className":"page__taxonomy-item","children":["#","Multiple-Choice QA"]}],["$","$L7","Tokenization",{"href":"/tags/Tokenization","className":"page__taxonomy-item","children":["#","Tokenization"]}],["$","$L7","Prompt Sensitivity",{"href":"/tags/Prompt%20Sensitivity","className":"page__taxonomy-item","children":["#","Prompt Sensitivity"]}],["$","$L7","Accuracy",{"href":"/tags/Accuracy","className":"page__taxonomy-item","children":["#","Accuracy"]}],["$","$L7","Calibration",{"href":"/tags/Calibration","className":"page__taxonomy-item","children":["#","Calibration"]}],["$","$L7","Model Ranking",{"href":"/tags/Model%20Ranking","className":"page__taxonomy-item","children":["#","Model Ranking"]}]]]}]}],["$","$Lc",null,{"postPermalink":"/ai/review/2025-9-19-Mind-the-Gap-A-Closer-Look-at-Tokenization-for-Multiple-Choice-Question-Answering-with-LLMs","postId":"2025-9-19-Mind-the-Gap-A-Closer-Look-at-Tokenization-for-Multiple-Choice-Question-Answering-with-LLMs"}],["$","section",null,{"className":"mt-12 border-t border-gray-200 pt-8","children":[["$","h3",null,{"className":"text-base font-semibold text-gray-900 mb-4","children":["Review"," 의 다른글"]}],["$","ul",null,{"className":"space-y-2 text-sm","children":[["$","li",null,{"className":"text-gray-500","children":["이전글"," ",["$","$L7",null,{"href":"/ai/review/2025-9-19-FlowRL-Matching-Reward-Distributions-for-LLM-Reasoning","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] FlowRL: Matching Reward Distributions for LLM Reasoning"}]]}],["$","li",null,{"className":"text-gray-900 font-semibold","children":["현재글 : ","[논문리뷰] Mind the Gap: A Closer Look at Tokenization for Multiple-Choice Question Answering with LLMs"]}],["$","li",null,{"className":"text-gray-500","children":["다음글"," ",["$","$L7",null,{"href":"/ai/review/2025-9-19-MultiEdit-Advancing-Instruction-based-Image-Editing-on-Diverse-and-Challenging-Tasks","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] MultiEdit: Advancing Instruction-based Image Editing on Diverse and Challenging Tasks"}]]}]]}]]}]]}]]}]]}]}]]
9:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"[논문리뷰] Mind the Gap: A Closer Look at Tokenization for Multiple-Choice Question Answering with LLMs - secrett2633's blog"}],["$","meta","3",{"name":"description","content":"Katharina von der Wense이 arXiv에 게시한 'Mind the Gap: A Closer Look at Tokenization for Multiple-Choice Question Answering with LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","meta","4",{"name":"author","content":"secrett2633"}],["$","link","5",{"rel":"manifest","href":"/manifest.json","crossOrigin":"use-credentials"}],["$","meta","6",{"name":"keywords","content":"Django, Python, DevOps, AI, ML, 블로그, 기술"}],["$","meta","7",{"name":"creator","content":"secrett2633"}],["$","meta","8",{"name":"publisher","content":"secrett2633"}],["$","meta","9",{"name":"robots","content":"index, follow"}],["$","meta","10",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","11",{"rel":"canonical","href":"https://blog.secrett2633.cloud/ai/review/2025-9-19-Mind-the-Gap-A-Closer-Look-at-Tokenization-for-Multiple-Choice-Question-Answering-with-LLMs"}],["$","meta","12",{"name":"format-detection","content":"telephone=no, address=no, email=no"}],["$","meta","13",{"property":"og:title","content":"[논문리뷰] Mind the Gap: A Closer Look at Tokenization for Multiple-Choice Question Answering with LLMs"}],["$","meta","14",{"property":"og:description","content":"Katharina von der Wense이 arXiv에 게시한 'Mind the Gap: A Closer Look at Tokenization for Multiple-Choice Question Answering with LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","meta","15",{"property":"og:url","content":"https://blog.secrett2633.cloud/ai/review/2025-9-19-Mind-the-Gap-A-Closer-Look-at-Tokenization-for-Multiple-Choice-Question-Answering-with-LLMs"}],["$","meta","16",{"property":"og:type","content":"article"}],["$","meta","17",{"property":"article:published_time","content":"2025-09-19T04:12:21.000Z"}],["$","meta","18",{"property":"article:modified_time","content":"2025-09-19T04:12:21.000Z"}],["$","meta","19",{"property":"article:author","content":"secrett2633"}],["$","meta","20",{"property":"article:section","content":"Review"}],["$","meta","21",{"property":"article:tag","content":"Review"}],["$","meta","22",{"property":"article:tag","content":"LLM Evaluation"}],["$","meta","23",{"property":"article:tag","content":"Multiple-Choice QA"}],["$","meta","24",{"property":"article:tag","content":"Tokenization"}],["$","meta","25",{"property":"article:tag","content":"Prompt Sensitivity"}],["$","meta","26",{"property":"article:tag","content":"Accuracy"}],["$","meta","27",{"property":"article:tag","content":"Calibration"}],["$","meta","28",{"property":"article:tag","content":"Model Ranking"}],["$","meta","29",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","30",{"name":"twitter:creator","content":"@secrett2633"}],["$","meta","31",{"name":"twitter:title","content":"[논문리뷰] Mind the Gap: A Closer Look at Tokenization for Multiple-Choice Question Answering with LLMs"}],["$","meta","32",{"name":"twitter:description","content":"Katharina von der Wense이 arXiv에 게시한 'Mind the Gap: A Closer Look at Tokenization for Multiple-Choice Question Answering with LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","link","33",{"rel":"icon","href":"/icon.ico?6d9f34d4948640b8","type":"image/x-icon","sizes":"16x16"}],["$","meta","34",{"name":"next-size-adjust"}]]
1:null
