3:I[9275,[],""]
5:I[1343,[],""]
6:I[9157,["231","static/chunks/231-c27e618569e042bc.js","185","static/chunks/app/layout-29f3b81c3a382114.js"],"default"]
7:I[231,["231","static/chunks/231-c27e618569e042bc.js","877","static/chunks/app/%5B...slug%5D/page-d9dbb0d3ac265797.js"],""]
4:["slug","ai/review/2025-11-14-Benchmarking-Diversity-in-Image-Generation-via-Attribute-Conditional-Human-Evaluation","c"]
0:["vurCQsCzY_vgt4Jj6xcPJ",[[["",{"children":[["slug","ai/review/2025-11-14-Benchmarking-Diversity-in-Image-Generation-via-Attribute-Conditional-Human-Evaluation","c"],{"children":["__PAGE__?{\"slug\":[\"ai\",\"review\",\"2025-11-14-Benchmarking-Diversity-in-Image-Generation-via-Attribute-Conditional-Human-Evaluation\"]}",{}]}]},"$undefined","$undefined",true],["",{"children":[["slug","ai/review/2025-11-14-Benchmarking-Diversity-in-Image-Generation-via-Attribute-Conditional-Human-Evaluation","c"],{"children":["__PAGE__",{},[["$L1","$L2"],null],null]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","$4","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},[["$","html",null,{"lang":"ko","className":"no-js","children":[["$","head",null,{"children":[["$","meta",null,{"name":"msapplication-TileColor","content":"#ffc40d"}],["$","meta",null,{"name":"theme-color","content":"#ffffff"}],["$","script",null,{"async":true,"src":"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY"}],["$","script",null,{"dangerouslySetInnerHTML":{"__html":"\n              window.dataLayer = window.dataLayer || [];\n              function gtag(){dataLayer.push(arguments);}\n              gtag('js', new Date());\n              gtag('config', 'G-NE2W3CFPNY');\n            "}}]]}],["$","body",null,{"className":"__className_f367f3 layout--default","children":["$","div",null,{"className":"min-h-screen bg-gray-50","children":[["$","$L6",null,{}],["$","main",null,{"className":"initial-content","children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","div",null,{"className":"min-h-screen flex items-center justify-center bg-gray-50","children":["$","div",null,{"className":"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center","children":[["$","h1",null,{"className":"text-6xl font-bold text-primary-600 mb-4","children":"404"}],["$","h2",null,{"className":"text-2xl font-semibold text-gray-900 mb-4","children":"페이지를 찾을 수 없습니다"}],["$","p",null,{"className":"text-gray-600 mb-8","children":"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다."}],["$","$L7",null,{"href":"/","className":"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors","children":"홈으로 돌아가기"}]]}]}],"notFoundStyles":[],"styles":null}]}],["$","div",null,{"id":"footer","className":"page__footer","children":["$","footer",null,{"className":"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8","children":["$","div",null,{"className":"text-center text-gray-500 text-sm","children":["$","p",null,{"children":"© 2025 secrett2633. All rights reserved."}]}]}]}]]}]}]]}],null],[["$","div",null,{"className":"flex items-center justify-center min-h-screen","children":["$","div",null,{"className":"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600"}]}],[],[]]],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/773b243a13a00265.css","precedence":"next","crossOrigin":"$undefined"}]],[null,"$L8"]]]]]
a:I[646,["231","static/chunks/231-c27e618569e042bc.js","877","static/chunks/app/%5B...slug%5D/page-d9dbb0d3ac265797.js"],"default"]
9:Tbec,<blockquote>
<p><strong>링크:</strong> <a href="https://arxiv.org/abs/2511.10547">논문 PDF로 바로 열기</a></p>
</blockquote>
<p><strong>저자:</strong> Isabela Albuquerque¹, Ira Ktena², Olivia Wiles¹, Ivana Kajić¹, Amal Rannen-Triki¹, Cristina Vasconcelos¹ and Aida Nematzadeh¹</p>
<h2>핵심 연구 목표</h2>
<p>현재 텍스트-투-이미지(T2I) 모델이 종종 동질적인 이미지를 생성하며 다양성이 부족하다는 문제를 해결하고자 합니다. 기존 다양성 평가 지표들이 충실도(fidelity)와 혼동되거나 표준화되지 않아 모호한 결과를 초래하는 한계를 극복하고, T2I 모델의 다양성을 체계적이고 견고하게 평가하기 위한 프레임워크를 제시하는 것이 이 연구의 주된 목표입니다.</p>
<h2>핵심 방법론</h2>
<p>본 연구는 <strong>속성 조건부 인간 평가 (Attribute-Conditional Human Evaluation)</strong> 프레임워크를 도입합니다. 이 프레임워크는 다양한 개념과 그 변형 요인(예: '사과'의 '색상')을 포함하는 <strong>큐레이션된 프롬프트 세트</strong> 와 <strong>미묘한 다양성 평가를 위한 새로운 인간 평가 템플릿</strong> 을 포함합니다. 모델 간의 다양성 비교를 위해 인간 주석에 대한 <strong>이항 테스트 (Binomial Tests)</strong> 를 사용하며, 자동 평가 지표의 신뢰성을 검증하기 위해 <strong>Vendi Score</strong> 와 Inception, ViT, DINOv2, PALI, CLIP 등 다양한 이미지 임베딩을 활용합니다.</p>
<h2>주요 결과</h2>
<p>인간 평가 결과, <strong>Imagen 3</strong> 와 <strong>Flux 1.1</strong> 이 속성 다양성 측면에서 가장 우수한 T2I 모델로 나타났습니다. <strong>Vendi Score 기반 자동 평가 접근 방식</strong> 은 적절한 표현 공간에서 최적화될 경우 <strong>약 80%의 정확도</strong> 로 인간이 인지하는 다양성을 포착할 수 있음을 보여주었습니다. 특히 <strong>Gemini v2.5 Flash</strong> 모델은 골든 세트 다양성 평가에서 <strong>0.926의 정확도</strong> 를 달성하여 인간 평가자(0.815)보다 뛰어난 성능을 보였습니다.</p>
<h2>AI 실무자를 위한 시사점</h2>
<p>T2I 모델의 다양성 평가 시 <strong>명확하게 정의된 속성 기반 평가</strong> 가 인간 판단의 일관성과 정확도를 크게 향상시킨다는 점을 시사합니다. <strong>Vendi Score</strong> 와 같은 자동 지표는 유용하지만, 인간의 다양성 인식을 정확히 반영하려면 <strong>적절한 임베딩 모델과 컨디셔닝 프롬프트 선택</strong> 이 중요함을 강조합니다. <strong>Gemini v2.5 Flash</strong> 와 같은 강력한 LLM은 임베딩 추출 없이도 다양성 평가에 효과적으로 활용될 수 있어, 향후 평가 프로세스 자동화 및 확장 가능성에 대한 새로운 방향을 제시합니다.</p>
<blockquote>
<p>⚠️ <strong>알림:</strong> 이 리뷰는 AI로 작성되었습니다.</p>
</blockquote>
2:["$","div",null,{"className":"flex flex-col lg:flex-row gap-8","children":[["$","aside",null,{"className":"lg:w-64 xl:w-72 order-1 lg:order-none","children":["$","div",null,{"className":"sidebar sticky","children":["$","nav",null,{"className":"space-y-4","children":[["$","div","Backend",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"Backend"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Django",{"children":["$","a",null,{"href":"/backend/django/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Django"," (",6,")"]}]}],["$","li","Logging",{"children":["$","a",null,{"href":"/backend/logging/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Logging"," (",1,")"]}]}]]}]]}],["$","div","Python",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"Python"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","PEP",{"children":["$","a",null,{"href":"/python/pep/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["PEP"," (",650,")"]}]}]]}]]}],["$","div","AI/ML",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"AI/ML"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","LLM",{"children":["$","a",null,{"href":"/ai/llm/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["LLM"," (",1,")"]}]}],["$","li","Review",{"children":["$","a",null,{"href":"/ai/review/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Review"," (",2279,")"]}]}]]}]]}],["$","div","DevOps",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"DevOps"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Nginx",{"children":["$","a",null,{"href":"/devops/nginx/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Nginx"," (",1,")"]}]}],["$","li","Docker",{"children":["$","a",null,{"href":"/devops/docker/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Docker"," (",1,")"]}]}],["$","li","SafeLine",{"children":["$","a",null,{"href":"/devops/safeline/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["SafeLine"," (",1,")"]}]}],["$","li","Jenkins",{"children":["$","a",null,{"href":"/devops/jenkins/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Jenkins"," (",3,")"]}]}],["$","li","GitHub Actions",{"children":["$","a",null,{"href":"/devops/github-actions/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["GitHub Actions"," (",1,")"]}]}],["$","li","AWS",{"children":["$","a",null,{"href":"/devops/aws/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["AWS"," (",1,")"]}]}]]}]]}],["$","div","etc",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"etc"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Me",{"children":["$","a",null,{"href":"/etc/me/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Me"," (",3,")"]}]}],["$","li","Chrome Extension",{"children":["$","a",null,{"href":"/etc/chrome-extension/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Chrome Extension"," (",1,")"]}]}]]}]]}]]}]}]}],["$","main",null,{"className":"flex-1","children":["$","article",null,{"className":"page","children":[["$","header",null,{"className":"mb-8","children":[["$","h1",null,{"className":"page__title","children":"[논문리뷰] Benchmarking Diversity in Image Generation via Attribute-Conditional Human Evaluation"}],["$","div",null,{"className":"page__meta","children":[["$","time",null,{"dateTime":"2025-11-14 00:00:00+0900+0900","children":"2025년 11월 14일"}],["$","span",null,{"className":"ml-4","children":["수정: ","2025년 11월 14일"]}]]}]]}],["$","div",null,{"className":"page__content","children":["$","div",null,{"dangerouslySetInnerHTML":{"__html":"$9"}}]}],["$","footer",null,{"className":"page__meta mt-8","children":["$","div",null,{"className":"page__taxonomy","children":[["$","h4",null,{"className":"text-sm font-medium text-gray-900 mb-2","children":"태그"}],[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Image Models",{"className":"page__taxonomy-item","children":["#","Text-to-Image Models"]}],["$","span","Diversity Evaluation",{"className":"page__taxonomy-item","children":["#","Diversity Evaluation"]}],["$","span","Human Evaluation",{"className":"page__taxonomy-item","children":["#","Human Evaluation"]}],["$","span","Attribute-Conditional",{"className":"page__taxonomy-item","children":["#","Attribute-Conditional"]}],["$","span","Vendi Score",{"className":"page__taxonomy-item","children":["#","Vendi Score"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}]]]}]}],["$","$La",null,{"postPermalink":"/ai/review/2025-11-14-Benchmarking-Diversity-in-Image-Generation-via-Attribute-Conditional-Human-Evaluation/","postId":"2025-11-14-Benchmarking-Diversity-in-Image-Generation-via-Attribute-Conditional-Human-Evaluation"}],["$","section",null,{"className":"mt-12 border-t border-gray-200 pt-8","children":[["$","h3",null,{"className":"text-base font-semibold text-gray-900 mb-4","children":["Review"," 의 다른글"]}],["$","ul",null,{"className":"space-y-2 text-sm","children":[["$","li",null,{"className":"text-gray-500","children":["이전글"," ",["$","$L7",null,{"href":"/ai/review/2025-11-14-AffordBot-3D-Fine-grained-Embodied-Reasoning-via-Multimodal-Large-Language-Models/","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] AffordBot: 3D Fine-grained Embodied Reasoning via Multimodal Large Language Models"}]]}],["$","li",null,{"className":"text-gray-900 font-semibold","children":["현재글 : ","[논문리뷰] Benchmarking Diversity in Image Generation via Attribute-Conditional Human Evaluation"]}],["$","li",null,{"className":"text-gray-500","children":["다음글"," ",["$","$L7",null,{"href":"/ai/review/2025-11-14-Black-Box-On-Policy-Distillation-of-Large-Language-Models/","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] Black-Box On-Policy Distillation of Large Language Models"}]]}]]}]]}]]}]}]]}]
8:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"secrett2633's blog"}],["$","meta","3",{"name":"description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","meta","4",{"name":"author","content":"secrett2633"}],["$","meta","5",{"name":"keywords","content":"Django, Python, DevOps, AI, ML, 블로그, 기술"}],["$","meta","6",{"name":"creator","content":"secrett2633"}],["$","meta","7",{"name":"publisher","content":"secrett2633"}],["$","meta","8",{"name":"robots","content":"index, follow"}],["$","meta","9",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","10",{"rel":"canonical","href":"https://blog.secrett2633.cloud/"}],["$","meta","11",{"name":"format-detection","content":"telephone=no, address=no, email=no"}],["$","meta","12",{"property":"og:title","content":"secrett2633's blog"}],["$","meta","13",{"property":"og:description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","meta","14",{"property":"og:url","content":"https://blog.secrett2633.cloud/"}],["$","meta","15",{"property":"og:site_name","content":"secrett2633's blog"}],["$","meta","16",{"property":"og:locale","content":"ko_KR"}],["$","meta","17",{"property":"og:type","content":"website"}],["$","meta","18",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","19",{"name":"twitter:title","content":"secrett2633's blog"}],["$","meta","20",{"name":"twitter:description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","link","21",{"rel":"icon","href":"/icon.ico?6d9f34d4948640b8","type":"image/x-icon","sizes":"16x16"}],["$","meta","22",{"name":"next-size-adjust"}]]
1:null
