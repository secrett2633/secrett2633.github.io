<!DOCTYPE html><html lang="ko" class="no-js"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/d6cea809dcbae606.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-90b03762f46d1ba4.js"/><script src="/_next/static/chunks/fd9d1056-0395f68b8cc78a20.js" async=""></script><script src="/_next/static/chunks/23-706b53707bbf0661.js" async=""></script><script src="/_next/static/chunks/main-app-6087bc228fd56b83.js" async=""></script><script src="/_next/static/chunks/231-467e37449c5a68fc.js" async=""></script><script src="/_next/static/chunks/app/layout-e359f205e3380aec.js" async=""></script><script src="/_next/static/chunks/app/page-90c91ef098171651.js" async=""></script><script src="/_next/static/chunks/app/%5B...slug%5D/page-dfe24a3bbd58f9b9.js" async=""></script><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY"></script><title>secrett2633&#x27;s blog</title><meta name="description" content="기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"/><meta name="author" content="secrett2633"/><meta name="keywords" content="Django, Python, DevOps, AI, ML, 블로그, 기술"/><meta name="creator" content="secrett2633"/><meta name="publisher" content="secrett2633"/><meta name="robots" content="index, follow"/><meta name="googlebot" content="index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"/><link rel="canonical" href="https://blog.secrett2633.cloud/"/><meta name="format-detection" content="telephone=no, address=no, email=no"/><meta property="og:title" content="secrett2633&#x27;s blog"/><meta property="og:description" content="기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"/><meta property="og:url" content="https://blog.secrett2633.cloud/"/><meta property="og:site_name" content="secrett2633&#x27;s blog"/><meta property="og:locale" content="ko_KR"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="secrett2633&#x27;s blog"/><meta name="twitter:description" content="기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"/><link rel="icon" href="/icon.ico?6d9f34d4948640b8" type="image/x-icon" sizes="16x16"/><meta name="next-size-adjust"/><meta name="msapplication-TileColor" content="#ffc40d"/><meta name="theme-color" content="#ffffff"/><script>
              window.dataLayer = window.dataLayer || [];
              function gtag(){dataLayer.push(arguments);}
              gtag('js', new Date());
              gtag('config', 'G-NE2W3CFPNY');
            </script><script src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body class="__className_f367f3 layout--default"><div class="min-h-screen bg-gray-50"><div class="masthead"><div class="masthead__inner-wrap"><div class="masthead__menu"><nav id="site-nav" class="greedy-nav"><a class="site-title" href="/">secrett2633&#x27;s blog</a><div class="flex items-center space-x-4"><ul class="visible-links"><li class="masthead__menu-item"><a href="https://github.com/secrett2633" target="_blank" rel="noopener noreferrer">GitHub</a></li></ul><button class="search__toggle" type="button"><svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16"><path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path></svg></button></div></nav></div></div></div><main class="initial-content"><!--$--><div class="flex flex-col lg:flex-row gap-8"><aside class="lg:w-64 xl:w-72 order-1 lg:order-none"><div class="sidebar sticky"><nav class="space-y-4"><div><h4 class="font-medium text-gray-900 mb-2">Backend</h4><ul class="space-y-1 ml-4"><li><a href="/backend/django/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Django<!-- --> (<!-- -->6<!-- -->)</a></li><li><a href="/backend/logging/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Logging<!-- --> (<!-- -->1<!-- -->)</a></li></ul></div><div><h4 class="font-medium text-gray-900 mb-2">Python</h4><ul class="space-y-1 ml-4"><li><a href="/python/pep/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">PEP<!-- --> (<!-- -->650<!-- -->)</a></li></ul></div><div><h4 class="font-medium text-gray-900 mb-2">AI/ML</h4><ul class="space-y-1 ml-4"><li><a href="/ai/llm/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">LLM<!-- --> (<!-- -->1<!-- -->)</a></li><li><a href="/ai/review/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Review<!-- --> (<!-- -->2420<!-- -->)</a></li></ul></div><div><h4 class="font-medium text-gray-900 mb-2">DevOps</h4><ul class="space-y-1 ml-4"><li><a href="/devops/nginx/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Nginx<!-- --> (<!-- -->1<!-- -->)</a></li><li><a href="/devops/docker/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Docker<!-- --> (<!-- -->1<!-- -->)</a></li><li><a href="/devops/safeline/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">SafeLine<!-- --> (<!-- -->1<!-- -->)</a></li><li><a href="/devops/jenkins/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Jenkins<!-- --> (<!-- -->3<!-- -->)</a></li><li><a href="/devops/github-actions/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">GitHub Actions<!-- --> (<!-- -->1<!-- -->)</a></li><li><a href="/devops/aws/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">AWS<!-- --> (<!-- -->1<!-- -->)</a></li></ul></div><div><h4 class="font-medium text-gray-900 mb-2">etc</h4><ul class="space-y-1 ml-4"><li><a href="/etc/me/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Me<!-- --> (<!-- -->3<!-- -->)</a></li><li><a href="/etc/chrome-extension/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Chrome Extension<!-- --> (<!-- -->1<!-- -->)</a></li></ul></div></nav></div></aside><main class="flex-1"><article class="page"><header class="mb-8"><h1 class="page__title">[논문리뷰] IF-VidCap: Can Video Caption Models Follow Instructions?</h1><div class="page__meta"><time dateTime="2025-10-22 13:07:20+0900">2025년 10월 22일</time><span class="ml-4">수정: <!-- -->2025년 10월 22일</span></div></header><div class="page__content"><div><blockquote>
<p><strong>링크:</strong> <a href="https://arxiv.org/abs/2510.18726">논문 PDF로 바로 열기</a></p>
</blockquote>
<p><strong>저자:</strong> Shihao Li, Yuanxing Zhang, Jiangtao Wu, Zhide Lei, Yiwen He, Runzhe Wen, Chenxi Liao, Chengkang Jiang, An Ping, Shuo Gao, Suhan Wang, Zhaozhou Bian, Zijun Zhou, Jingyi Xie, Jiayi Zhou, Jing Wang, Yifan Yao, Weihao Xie, Yingshui Tan, Yanghai Wang, Qianqian Xie, Zhaoxiang Zhang, Jiaheng Liu</p>
<h2>핵심 연구 목표</h2>
<p>비디오 캡셔닝 분야에서 <strong>멀티모달 대규모 언어 모델(MLLM)</strong> 이 사용자의 특정 지시사항(예: 출력 형식, 길이, 내용 제약)을 얼마나 잘 따르는지 평가하는 새로운 벤치마크를 제시하는 것이 목표입니다. 기존 벤치마크들이 주로 설명의 포괄성에 초점을 맞춰왔으나, 실용적인 응용 분야에서는 지시사항 준수 능력이 중요하므로 이 공백을 해결하고자 합니다.</p>
<h2>핵심 방법론</h2>
<p><strong>IF-VidCap</strong> 이라는 <strong>1,400개의 고품질 샘플</strong> 로 구성된 벤치마크를 구축했으며, 이는 <strong>27가지</strong> 의 다양한 제약 유형(예: 형식, 내용, 요소 집중)을 포함합니다. 이 벤치마크는 <strong>형식 정확성</strong> 과 <strong>내용 정확성</strong> 이라는 두 가지 차원에서 캡션을 평가하는 체계적인 자동 평가 프로토콜을 사용하며, <strong>규칙 기반 검사</strong> 와 <strong>LLM 기반 개방형 질문</strong> 을 결합합니다. 또한, 지시사항 준수 능력을 강화하기 위한 <strong>11K 비디오-캡션 쌍</strong> 으로 구성된 새로운 훈련 데이터셋을 공개하고, 이를 통해 <strong>Qwen2.5-VL-7B-Instruct</strong> 모델을 <strong>IF-Captioner-Qwen</strong> 으로 미세 조정했습니다.</p>
<h2>주요 결과</h2>
<p><strong>20개 이상의 최신 모델</strong> 평가 결과, <strong>소유 모델(proprietary models)</strong> 이 일반적으로 <strong>오픈소스 모델</strong> 보다 우수한 성능을 보였으나, 격차가 줄어들고 있음을 확인했습니다. <strong>IF-Captioner-Qwen</strong> 은 미세 조정을 통해 기준 모델인 <strong>Qwen2.5-VL-7B-Instruct</strong> 보다 <strong>ISR (Instruction Satisfaction Rate) 12.76%</strong> 대 <strong>10.92%</strong> , <strong>CSR (Constraint Satisfaction Rate) 61.64%</strong> 대 <strong>58.12%</strong> 로 크게 향상된 성능을 보였습니다. 지시사항 복잡도(제약 조건 수, 길이)가 증가함에 따라 모델의 성능이 저하되며, 특히 <strong>내용 제약</strong> 에 대한 처리 능력이 <strong>형식 제약</strong> 보다 훨씬 취약함이 드러났습니다.</p>
<h2>AI 실무자를 위한 시사점</h2>
<p>본 벤치마크는 AI 모델이 단순한 비디오 설명 생성뿐만 아니라 <strong>사용자 지시사항을 정확하게 따르는 능력</strong> 의 중요성을 강조합니다. 특히 <strong>멀티모달 추론 능력</strong> 이 필요한 내용 관련 제약 조건에서 모델의 한계가 명확하게 드러나므로, 향후 연구는 <strong>설명의 풍부함과 지시사항 준수 능력</strong> 을 동시에 발전시키는 데 집중해야 할 것입니다. 또한, 공개된 훈련 데이터셋과 미세 조정된 모델은 <strong>표적 미세 조정을 통해 MLLM의 지시사항 준수 능력을 효과적으로 향상</strong> 시킬 수 있음을 보여주며 실무 적용 가능성을 제시합니다.</p>
<blockquote>
<p>⚠️ <strong>알림:</strong> 이 리뷰는 AI로 작성되었습니다.</p>
</blockquote>
</div></div><footer class="page__meta mt-8"><div class="page__taxonomy"><h4 class="text-sm font-medium text-gray-900 mb-2">태그</h4><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Video Captioning</span><span class="page__taxonomy-item">#<!-- -->Instruction Following</span><span class="page__taxonomy-item">#<!-- -->MLLMs</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Controllable Generation</span><span class="page__taxonomy-item">#<!-- -->Multimodal Evaluation</span><span class="page__taxonomy-item">#<!-- -->Fine-tuning</span></div></footer><section class="comments-section mt-12 pt-8 border-t border-gray-200"></section><section class="mt-12 border-t border-gray-200 pt-8"><h3 class="text-base font-semibold text-gray-900 mb-4">Review<!-- --> 의 다른글</h3><ul class="space-y-2 text-sm"><li class="text-gray-500">이전글<!-- --> <a class="text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4" href="/ai/review/2025-10-22-Grasp-Any-Region-Towards-Precise-Contextual-Pixel-Understanding-for-Multimodal-LLMs/">[논문리뷰] Grasp Any Region: Towards Precise, Contextual Pixel Understanding for Multimodal LLMs</a></li><li class="text-gray-900 font-semibold">현재글 : <!-- -->[논문리뷰] IF-VidCap: Can Video Caption Models Follow Instructions?</li><li class="text-gray-500">다음글<!-- --> <a class="text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4" href="/ai/review/2025-10-22-MT-Video-Bench-A-Holistic-Video-Understanding-Benchmark-for-Evaluating-Multimodal-LLMs-in-Multi-Turn-Dialogues/">[논문리뷰] MT-Video-Bench: A Holistic Video Understanding Benchmark for Evaluating Multimodal LLMs in Multi-Turn Dialogues</a></li></ul></section></article></main></div><!--/$--></main><div id="footer" class="page__footer"><footer class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8"><div class="text-center text-gray-500 text-sm"><p>© 2025 secrett2633. All rights reserved.</p></div></footer></div></div><script src="/_next/static/chunks/webpack-90b03762f46d1ba4.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/media/e4af272ccee01ff0-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n2:HL[\"/_next/static/css/d6cea809dcbae606.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"3:I[5751,[],\"\"]\n6:I[9275,[],\"\"]\n8:I[1343,[],\"\"]\n9:I[9157,[\"231\",\"static/chunks/231-467e37449c5a68fc.js\",\"185\",\"static/chunks/app/layout-e359f205e3380aec.js\"],\"default\"]\na:I[231,[\"231\",\"static/chunks/231-467e37449c5a68fc.js\",\"931\",\"static/chunks/app/page-90c91ef098171651.js\"],\"\"]\nc:I[6130,[],\"\"]\n7:[\"slug\",\"ai/review/2025-10-22-IF-VidCap-Can-Video-Caption-Models-Follow-Instructions\",\"c\"]\nd:[]\n"])</script><script>self.__next_f.push([1,"0:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/d6cea809dcbae606.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L3\",null,{\"buildId\":\"vlNzklkFwxZlDtaCTE3RF\",\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/ai/review/2025-10-22-IF-VidCap-Can-Video-Caption-Models-Follow-Instructions/\",\"initialTree\":[\"\",{\"children\":[[\"slug\",\"ai/review/2025-10-22-IF-VidCap-Can-Video-Caption-Models-Follow-Instructions\",\"c\"],{\"children\":[\"__PAGE__?{\\\"slug\\\":[\\\"ai\\\",\\\"review\\\",\\\"2025-10-22-IF-VidCap-Can-Video-Caption-Models-Follow-Instructions\\\"]}\",{}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[[\"slug\",\"ai/review/2025-10-22-IF-VidCap-Can-Video-Caption-Models-Follow-Instructions\",\"c\"],{\"children\":[\"__PAGE__\",{},[[\"$L4\",\"$L5\"],null],null]},[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"$7\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}],null]},[[\"$\",\"html\",null,{\"lang\":\"ko\",\"className\":\"no-js\",\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"meta\",null,{\"name\":\"msapplication-TileColor\",\"content\":\"#ffc40d\"}],[\"$\",\"meta\",null,{\"name\":\"theme-color\",\"content\":\"#ffffff\"}],[\"$\",\"script\",null,{\"async\":true,\"src\":\"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY\"}],[\"$\",\"script\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\\n              window.dataLayer = window.dataLayer || [];\\n              function gtag(){dataLayer.push(arguments);}\\n              gtag('js', new Date());\\n              gtag('config', 'G-NE2W3CFPNY');\\n            \"}}]]}],[\"$\",\"body\",null,{\"className\":\"__className_f367f3 layout--default\",\"children\":[\"$\",\"div\",null,{\"className\":\"min-h-screen bg-gray-50\",\"children\":[[\"$\",\"$L9\",null,{}],[\"$\",\"main\",null,{\"className\":\"initial-content\",\"children\":[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[\"$\",\"div\",null,{\"className\":\"min-h-screen flex items-center justify-center bg-gray-50\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-6xl font-bold text-primary-600 mb-4\",\"children\":\"404\"}],[\"$\",\"h2\",null,{\"className\":\"text-2xl font-semibold text-gray-900 mb-4\",\"children\":\"페이지를 찾을 수 없습니다\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-600 mb-8\",\"children\":\"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다.\"}],[\"$\",\"$La\",null,{\"href\":\"/\",\"className\":\"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors\",\"children\":\"홈으로 돌아가기\"}]]}]}],\"notFoundStyles\":[],\"styles\":null}]}],[\"$\",\"div\",null,{\"id\":\"footer\",\"className\":\"page__footer\",\"children\":[\"$\",\"footer\",null,{\"className\":\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"text-center text-gray-500 text-sm\",\"children\":[\"$\",\"p\",null,{\"children\":\"© 2025 secrett2633. All rights reserved.\"}]}]}]}]]}]}]]}],null],[[\"$\",\"div\",null,{\"className\":\"flex items-center justify-center min-h-screen\",\"children\":[\"$\",\"div\",null,{\"className\":\"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600\"}]}],[],[]]],\"couldBeIntercepted\":false,\"initialHead\":[null,\"$Lb\"],\"globalErrorComponent\":\"$c\",\"missingSlots\":\"$Wd\"}]]\n"])</script><script>self.__next_f.push([1,"f:I[646,[\"231\",\"static/chunks/231-467e37449c5a68fc.js\",\"877\",\"static/chunks/app/%5B...slug%5D/page-dfe24a3bbd58f9b9.js\"],\"default\"]\ne:Te53,"])</script><script>self.__next_f.push([1,"\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e링크:\u003c/strong\u003e \u003ca href=\"https://arxiv.org/abs/2510.18726\"\u003e논문 PDF로 바로 열기\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003e저자:\u003c/strong\u003e Shihao Li, Yuanxing Zhang, Jiangtao Wu, Zhide Lei, Yiwen He, Runzhe Wen, Chenxi Liao, Chengkang Jiang, An Ping, Shuo Gao, Suhan Wang, Zhaozhou Bian, Zijun Zhou, Jingyi Xie, Jiayi Zhou, Jing Wang, Yifan Yao, Weihao Xie, Yingshui Tan, Yanghai Wang, Qianqian Xie, Zhaoxiang Zhang, Jiaheng Liu\u003c/p\u003e\n\u003ch2\u003e핵심 연구 목표\u003c/h2\u003e\n\u003cp\u003e비디오 캡셔닝 분야에서 \u003cstrong\u003e멀티모달 대규모 언어 모델(MLLM)\u003c/strong\u003e 이 사용자의 특정 지시사항(예: 출력 형식, 길이, 내용 제약)을 얼마나 잘 따르는지 평가하는 새로운 벤치마크를 제시하는 것이 목표입니다. 기존 벤치마크들이 주로 설명의 포괄성에 초점을 맞춰왔으나, 실용적인 응용 분야에서는 지시사항 준수 능력이 중요하므로 이 공백을 해결하고자 합니다.\u003c/p\u003e\n\u003ch2\u003e핵심 방법론\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eIF-VidCap\u003c/strong\u003e 이라는 \u003cstrong\u003e1,400개의 고품질 샘플\u003c/strong\u003e 로 구성된 벤치마크를 구축했으며, 이는 \u003cstrong\u003e27가지\u003c/strong\u003e 의 다양한 제약 유형(예: 형식, 내용, 요소 집중)을 포함합니다. 이 벤치마크는 \u003cstrong\u003e형식 정확성\u003c/strong\u003e 과 \u003cstrong\u003e내용 정확성\u003c/strong\u003e 이라는 두 가지 차원에서 캡션을 평가하는 체계적인 자동 평가 프로토콜을 사용하며, \u003cstrong\u003e규칙 기반 검사\u003c/strong\u003e 와 \u003cstrong\u003eLLM 기반 개방형 질문\u003c/strong\u003e 을 결합합니다. 또한, 지시사항 준수 능력을 강화하기 위한 \u003cstrong\u003e11K 비디오-캡션 쌍\u003c/strong\u003e 으로 구성된 새로운 훈련 데이터셋을 공개하고, 이를 통해 \u003cstrong\u003eQwen2.5-VL-7B-Instruct\u003c/strong\u003e 모델을 \u003cstrong\u003eIF-Captioner-Qwen\u003c/strong\u003e 으로 미세 조정했습니다.\u003c/p\u003e\n\u003ch2\u003e주요 결과\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e20개 이상의 최신 모델\u003c/strong\u003e 평가 결과, \u003cstrong\u003e소유 모델(proprietary models)\u003c/strong\u003e 이 일반적으로 \u003cstrong\u003e오픈소스 모델\u003c/strong\u003e 보다 우수한 성능을 보였으나, 격차가 줄어들고 있음을 확인했습니다. \u003cstrong\u003eIF-Captioner-Qwen\u003c/strong\u003e 은 미세 조정을 통해 기준 모델인 \u003cstrong\u003eQwen2.5-VL-7B-Instruct\u003c/strong\u003e 보다 \u003cstrong\u003eISR (Instruction Satisfaction Rate) 12.76%\u003c/strong\u003e 대 \u003cstrong\u003e10.92%\u003c/strong\u003e , \u003cstrong\u003eCSR (Constraint Satisfaction Rate) 61.64%\u003c/strong\u003e 대 \u003cstrong\u003e58.12%\u003c/strong\u003e 로 크게 향상된 성능을 보였습니다. 지시사항 복잡도(제약 조건 수, 길이)가 증가함에 따라 모델의 성능이 저하되며, 특히 \u003cstrong\u003e내용 제약\u003c/strong\u003e 에 대한 처리 능력이 \u003cstrong\u003e형식 제약\u003c/strong\u003e 보다 훨씬 취약함이 드러났습니다.\u003c/p\u003e\n\u003ch2\u003eAI 실무자를 위한 시사점\u003c/h2\u003e\n\u003cp\u003e본 벤치마크는 AI 모델이 단순한 비디오 설명 생성뿐만 아니라 \u003cstrong\u003e사용자 지시사항을 정확하게 따르는 능력\u003c/strong\u003e 의 중요성을 강조합니다. 특히 \u003cstrong\u003e멀티모달 추론 능력\u003c/strong\u003e 이 필요한 내용 관련 제약 조건에서 모델의 한계가 명확하게 드러나므로, 향후 연구는 \u003cstrong\u003e설명의 풍부함과 지시사항 준수 능력\u003c/strong\u003e 을 동시에 발전시키는 데 집중해야 할 것입니다. 또한, 공개된 훈련 데이터셋과 미세 조정된 모델은 \u003cstrong\u003e표적 미세 조정을 통해 MLLM의 지시사항 준수 능력을 효과적으로 향상\u003c/strong\u003e 시킬 수 있음을 보여주며 실무 적용 가능성을 제시합니다.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e⚠️ \u003cstrong\u003e알림:\u003c/strong\u003e 이 리뷰는 AI로 작성되었습니다.\u003c/p\u003e\n\u003c/blockquote\u003e\n"])</script><script>self.__next_f.push([1,"5:[\"$\",\"div\",null,{\"className\":\"flex flex-col lg:flex-row gap-8\",\"children\":[[\"$\",\"aside\",null,{\"className\":\"lg:w-64 xl:w-72 order-1 lg:order-none\",\"children\":[\"$\",\"div\",null,{\"className\":\"sidebar sticky\",\"children\":[\"$\",\"nav\",null,{\"className\":\"space-y-4\",\"children\":[[\"$\",\"div\",\"Backend\",{\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"Backend\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"Django\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/backend/django/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Django\",\" (\",6,\")\"]}]}],[\"$\",\"li\",\"Logging\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/backend/logging/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Logging\",\" (\",1,\")\"]}]}]]}]]}],[\"$\",\"div\",\"Python\",{\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"Python\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"PEP\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/python/pep/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"PEP\",\" (\",650,\")\"]}]}]]}]]}],[\"$\",\"div\",\"AI/ML\",{\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"AI/ML\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"LLM\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/ai/llm/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"LLM\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"Review\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/ai/review/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Review\",\" (\",2420,\")\"]}]}]]}]]}],[\"$\",\"div\",\"DevOps\",{\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"DevOps\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"Nginx\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/devops/nginx/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Nginx\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"Docker\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/devops/docker/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Docker\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"SafeLine\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/devops/safeline/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"SafeLine\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"Jenkins\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/devops/jenkins/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Jenkins\",\" (\",3,\")\"]}]}],[\"$\",\"li\",\"GitHub Actions\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/devops/github-actions/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"GitHub Actions\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"AWS\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/devops/aws/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"AWS\",\" (\",1,\")\"]}]}]]}]]}],[\"$\",\"div\",\"etc\",{\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"etc\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"Me\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/etc/me/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Me\",\" (\",3,\")\"]}]}],[\"$\",\"li\",\"Chrome Extension\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/etc/chrome-extension/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Chrome Extension\",\" (\",1,\")\"]}]}]]}]]}]]}]}]}],[\"$\",\"main\",null,{\"className\":\"flex-1\",\"children\":[\"$\",\"article\",null,{\"className\":\"page\",\"children\":[[\"$\",\"header\",null,{\"className\":\"mb-8\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"page__title\",\"children\":\"[논문리뷰] IF-VidCap: Can Video Caption Models Follow Instructions?\"}],[\"$\",\"div\",null,{\"className\":\"page__meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-22 13:07:20+0900\",\"children\":\"2025년 10월 22일\"}],[\"$\",\"span\",null,{\"className\":\"ml-4\",\"children\":[\"수정: \",\"2025년 10월 22일\"]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"page__content\",\"children\":[\"$\",\"div\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$e\"}}]}],[\"$\",\"footer\",null,{\"className\":\"page__meta mt-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"page__taxonomy\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"text-sm font-medium text-gray-900 mb-2\",\"children\":\"태그\"}],[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Video Captioning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Captioning\"]}],[\"$\",\"span\",\"Instruction Following\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Instruction Following\"]}],[\"$\",\"span\",\"MLLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"MLLMs\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Controllable Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Controllable Generation\"]}],[\"$\",\"span\",\"Multimodal Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Evaluation\"]}],[\"$\",\"span\",\"Fine-tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fine-tuning\"]}]]]}]}],[\"$\",\"$Lf\",null,{\"postPermalink\":\"/ai/review/2025-10-22-IF-VidCap-Can-Video-Caption-Models-Follow-Instructions/\",\"postId\":\"2025-10-22-IF-VidCap-Can-Video-Caption-Models-Follow-Instructions\"}],[\"$\",\"section\",null,{\"className\":\"mt-12 border-t border-gray-200 pt-8\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-base font-semibold text-gray-900 mb-4\",\"children\":[\"Review\",\" 의 다른글\"]}],[\"$\",\"ul\",null,{\"className\":\"space-y-2 text-sm\",\"children\":[[\"$\",\"li\",null,{\"className\":\"text-gray-500\",\"children\":[\"이전글\",\" \",[\"$\",\"$La\",null,{\"href\":\"/ai/review/2025-10-22-Grasp-Any-Region-Towards-Precise-Contextual-Pixel-Understanding-for-Multimodal-LLMs/\",\"className\":\"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4\",\"children\":\"[논문리뷰] Grasp Any Region: Towards Precise, Contextual Pixel Understanding for Multimodal LLMs\"}]]}],[\"$\",\"li\",null,{\"className\":\"text-gray-900 font-semibold\",\"children\":[\"현재글 : \",\"[논문리뷰] IF-VidCap: Can Video Caption Models Follow Instructions?\"]}],[\"$\",\"li\",null,{\"className\":\"text-gray-500\",\"children\":[\"다음글\",\" \",[\"$\",\"$La\",null,{\"href\":\"/ai/review/2025-10-22-MT-Video-Bench-A-Holistic-Video-Understanding-Benchmark-for-Evaluating-Multimodal-LLMs-in-Multi-Turn-Dialogues/\",\"className\":\"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4\",\"children\":\"[논문리뷰] MT-Video-Bench: A Holistic Video Understanding Benchmark for Evaluating Multimodal LLMs in Multi-Turn Dialogues\"}]]}]]}]]}]]}]}]]}]\n"])</script><script>self.__next_f.push([1,"b:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"secrett2633's blog\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\"}],[\"$\",\"meta\",\"4\",{\"name\":\"author\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"5\",{\"name\":\"keywords\",\"content\":\"Django, Python, DevOps, AI, ML, 블로그, 기술\"}],[\"$\",\"meta\",\"6\",{\"name\":\"creator\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"7\",{\"name\":\"publisher\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"8\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"9\",{\"name\":\"googlebot\",\"content\":\"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1\"}],[\"$\",\"link\",\"10\",{\"rel\":\"canonical\",\"href\":\"https://blog.secrett2633.cloud/\"}],[\"$\",\"meta\",\"11\",{\"name\":\"format-detection\",\"content\":\"telephone=no, address=no, email=no\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:title\",\"content\":\"secrett2633's blog\"}],[\"$\",\"meta\",\"13\",{\"property\":\"og:description\",\"content\":\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\"}],[\"$\",\"meta\",\"14\",{\"property\":\"og:url\",\"content\":\"https://blog.secrett2633.cloud/\"}],[\"$\",\"meta\",\"15\",{\"property\":\"og:site_name\",\"content\":\"secrett2633's blog\"}],[\"$\",\"meta\",\"16\",{\"property\":\"og:locale\",\"content\":\"ko_KR\"}],[\"$\",\"meta\",\"17\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"18\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"19\",{\"name\":\"twitter:title\",\"content\":\"secrett2633's blog\"}],[\"$\",\"meta\",\"20\",{\"name\":\"twitter:description\",\"content\":\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\"}],[\"$\",\"link\",\"21\",{\"rel\":\"icon\",\"href\":\"/icon.ico?6d9f34d4948640b8\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}],[\"$\",\"meta\",\"22\",{\"name\":\"next-size-adjust\"}]]\n4:null\n"])</script></body></html>