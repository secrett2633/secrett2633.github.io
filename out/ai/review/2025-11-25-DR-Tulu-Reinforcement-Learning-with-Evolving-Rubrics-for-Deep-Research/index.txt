3:I[9275,[],""]
5:I[1343,[],""]
6:I[9157,["231","static/chunks/231-c27e618569e042bc.js","157","static/chunks/157-167bfed393319721.js","185","static/chunks/app/layout-b06e577e11976c7d.js"],"default"]
7:I[231,["231","static/chunks/231-c27e618569e042bc.js","877","static/chunks/app/%5B...slug%5D/page-eb985a9c6ac1f073.js"],""]
4:["slug","ai/review/2025-11-25-DR-Tulu-Reinforcement-Learning-with-Evolving-Rubrics-for-Deep-Research","c"]
0:["q8gP0CJE_7T-dGWg_B3Wl",[[["",{"children":[["slug","ai/review/2025-11-25-DR-Tulu-Reinforcement-Learning-with-Evolving-Rubrics-for-Deep-Research","c"],{"children":["__PAGE__?{\"slug\":[\"ai\",\"review\",\"2025-11-25-DR-Tulu-Reinforcement-Learning-with-Evolving-Rubrics-for-Deep-Research\"]}",{}]}]},"$undefined","$undefined",true],["",{"children":[["slug","ai/review/2025-11-25-DR-Tulu-Reinforcement-Learning-with-Evolving-Rubrics-for-Deep-Research","c"],{"children":["__PAGE__",{},[["$L1","$L2"],null],null]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","$4","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},[["$","html",null,{"lang":"ko","className":"no-js","children":[["$","head",null,{"children":[["$","meta",null,{"name":"msapplication-TileColor","content":"#ffc40d"}],["$","meta",null,{"name":"theme-color","content":"#ffffff"}],["$","script",null,{"async":true,"src":"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY"}],["$","script",null,{"dangerouslySetInnerHTML":{"__html":"\n              window.dataLayer = window.dataLayer || [];\n              function gtag(){dataLayer.push(arguments);}\n              gtag('js', new Date());\n              gtag('config', 'G-NE2W3CFPNY');\n            "}}]]}],["$","body",null,{"className":"__className_f367f3 layout--default","children":["$","div",null,{"className":"min-h-screen bg-gray-50","children":[["$","$L6",null,{}],["$","main",null,{"className":"initial-content","children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","div",null,{"className":"min-h-screen flex items-center justify-center bg-gray-50","children":["$","div",null,{"className":"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center","children":[["$","h1",null,{"className":"text-6xl font-bold text-primary-600 mb-4","children":"404"}],["$","h2",null,{"className":"text-2xl font-semibold text-gray-900 mb-4","children":"페이지를 찾을 수 없습니다"}],["$","p",null,{"className":"text-gray-600 mb-8","children":"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다."}],["$","$L7",null,{"href":"/","className":"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors","children":"홈으로 돌아가기"}]]}]}],"notFoundStyles":[],"styles":null}]}],["$","div",null,{"id":"footer","className":"page__footer","children":["$","footer",null,{"className":"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8","children":["$","div",null,{"className":"text-center text-gray-500 text-sm","children":["$","p",null,{"children":"© 2025 secrett2633. All rights reserved."}]}]}]}]]}]}]]}],null],[["$","div",null,{"className":"flex items-center justify-center min-h-screen","children":["$","div",null,{"className":"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600"}]}],[],[]]],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/edf391eeca43d999.css","precedence":"next","crossOrigin":"$undefined"}]],[null,"$L8"]]]]]
9:Teb0,<blockquote>
<p><strong>링크:</strong> <a href="https://arxiv.org/abs/2511.19399">논문 PDF로 바로 열기</a></p>
</blockquote>
<p><strong>저자:</strong> Rulin Shao, Akari Asai, Shannon Zejiang Shen, et al.</p>
<h2>핵심 연구 목표</h2>
<p>이 논문의 핵심 목표는 기존 개방형 심층 연구 모델들이 짧은 형식의 질문 답변(QA)에 초점을 맞춰 실제 장문형 심층 연구 작업에 적용하기 어렵다는 한계를 극복하는 것입니다. 특히, 모호한 평가 기준과 동적인 세계 지식의 필요성으로 인해 장문형 응답을 평가하기 어려운 문제를 해결하고, 개방형 장문 심층 연구를 위해 직접 훈련된 최초의 개방형 모델을 개발하는 것을 목표로 합니다.</p>
<h2>핵심 방법론</h2>
<p>본 연구는 <strong>RLER (Reinforcement Learning with Evolving Rubrics)</strong> 이라는 새로운 방법론을 제안합니다. 이는 훈련 중 정책 모델과 함께 평가 기준(rubrics)을 구성하고 동적으로 발전시켜, 모델이 새롭게 탐색한 정보를 반영하고 온-정책(on-policy) 피드백을 제공하도록 합니다. 훈련은 먼저 교사 모델(GPT-5)이 생성한 장문형 추론 궤적 데이터로 <strong>SFT (Supervised Fine-Tuning)</strong> 를 수행하여 초기 도구 사용 및 인용 능력을 학습시킨 후, <strong>GRPO</strong> 알고리즘과 <strong>RLER</strong> 를 이용한 온라인 강화 학습으로 세부적인 검색 및 추론 전략을 개선합니다. 특히, <strong>GPT-4.1</strong> 기반의 rubric 생성 모델은 모델의 롤아웃을 대조하여 긍정적/부정적 측면을 학습하고, <strong>dr-agent-lib</strong> 인프라를 통해 <strong>google_search</strong> , <strong>web_browse</strong> , <strong>paper_search</strong> 등 다양한 검색 도구를 유연하게 활용합니다.</p>
<h2>주요 결과</h2>
<p><strong>DR Tulu-8B</strong> 는 4가지 장문형 심층 연구 벤치마크(ScholarQA-CSv2, HealthBench, ResearchQA, DeepResearchBench)에서 기존 개방형 모델들을 평균 <strong>2.8~40.3%p</strong> 압도적으로 능가했으며, 심지어 독점적인 심층 연구 시스템과도 동등하거나 그 이상의 성능을 보였습니다. 특히, ScholarQA-CSv2에서 OpenAI Deep Research가 쿼리당 <strong>USD 1.8</strong> 인 반면, <strong>DR Tulu-8B</strong> 는 <strong>USD 0.0019</strong> 로 거의 <strong>3배 이상</strong> 비용 효율적입니다. 또한, <strong>RLER</strong> 는 SQAv2에서 인용 정확도 <strong>+23.3%p</strong> , 리콜 <strong>+22.1%p</strong> 를 포함해 심층 연구 응답의 내용 및 속성 측면에서 큰 개선을 가져왔습니다.</p>
<h2>AI 실무자를 위한 시사점</h2>
<p><strong>DR Tulu</strong> 는 작은 규모의 <strong>8B</strong> 파라미터 개방형 모델로도 최첨단 심층 연구 성능을 훨씬 저렴한 비용으로 달성할 수 있음을 입증하여, 고급 연구 기능을 더욱 접근 가능하게 합니다. <strong>RLER</strong> 는 복잡하고 불명확한 작업에 대한 적응형 온-정책 피드백을 생성하여 동적 평가의 새로운 패러다임을 제시하며, 이는 단순한 검증 가능한 QA를 넘어선 작업에 중요합니다. 또한, <strong>MCP 기반 dr-agent-lib</strong> 인프라는 비동기식 도구 호출을 지원하여 유연하고 확장 가능한 멀티 도구 연구 에이전트 개발 및 훈련을 위한 기반을 제공합니다. 모든 데이터, 모델, 코드를 공개하여 심층 연구 에이전트 분야의 개방형 연구와 커스터마이징을 촉진합니다.</p>
<blockquote>
<p>⚠️ <strong>알림:</strong> 이 리뷰는 AI로 작성되었습니다.</p>
</blockquote>
2:["$","div",null,{"className":"flex flex-col lg:flex-row gap-8","children":[["$","aside",null,{"className":"lg:w-64 xl:w-72 order-1 lg:order-none","children":["$","div",null,{"className":"sidebar sticky","children":["$","nav",null,{"className":"space-y-4","children":[["$","div","Backend",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"Backend"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Django",{"children":["$","a",null,{"href":"/backend/django/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Django"," (",6,")"]}]}],["$","li","Logging",{"children":["$","a",null,{"href":"/backend/logging/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Logging"," (",1,")"]}]}]]}]]}],["$","div","Python",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"Python"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","PEP",{"children":["$","a",null,{"href":"/python/pep/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["PEP"," (",650,")"]}]}]]}]]}],["$","div","AI/ML",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"AI/ML"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","LLM",{"children":["$","a",null,{"href":"/ai/llm/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["LLM"," (",1,")"]}]}],["$","li","Review",{"children":["$","a",null,{"href":"/ai/review/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Review"," (",1734,")"]}]}]]}]]}],["$","div","DevOps",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"DevOps"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Nginx",{"children":["$","a",null,{"href":"/devops/nginx/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Nginx"," (",1,")"]}]}],["$","li","Docker",{"children":["$","a",null,{"href":"/devops/docker/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Docker"," (",1,")"]}]}],["$","li","SafeLine",{"children":["$","a",null,{"href":"/devops/safeline/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["SafeLine"," (",1,")"]}]}],["$","li","Jenkins",{"children":["$","a",null,{"href":"/devops/jenkins/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Jenkins"," (",3,")"]}]}],["$","li","GitHub Actions",{"children":["$","a",null,{"href":"/devops/github-actions/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["GitHub Actions"," (",1,")"]}]}],["$","li","AWS",{"children":["$","a",null,{"href":"/devops/aws/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["AWS"," (",1,")"]}]}]]}]]}],["$","div","etc",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"etc"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Me",{"children":["$","a",null,{"href":"/etc/me/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Me"," (",3,")"]}]}],["$","li","Chrome Extension",{"children":["$","a",null,{"href":"/etc/chrome-extension/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Chrome Extension"," (",1,")"]}]}]]}]]}]]}]}]}],["$","main",null,{"className":"flex-1","children":["$","article",null,{"className":"page","children":[["$","header",null,{"className":"mb-8","children":[["$","h1",null,{"className":"page__title","children":"[논문리뷰] DR Tulu: Reinforcement Learning with Evolving Rubrics for Deep Research"}],["$","div",null,{"className":"page__meta","children":[["$","time",null,{"dateTime":"2025-11-25 00:00:00+0900+0900","children":"2025년 11월 25일"}],["$","span",null,{"className":"ml-4","children":["수정: ","2025년 11월 25일"]}]]}]]}],["$","div",null,{"className":"page__content","children":["$","div",null,{"dangerouslySetInnerHTML":{"__html":"$9"}}]}],["$","footer",null,{"className":"page__meta mt-8","children":["$","div",null,{"className":"page__taxonomy","children":[["$","h4",null,{"className":"text-sm font-medium text-gray-900 mb-2","children":"태그"}],[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Evolving Rubrics",{"className":"page__taxonomy-item","children":["#","Evolving Rubrics"]}],["$","span","Deep Research",{"className":"page__taxonomy-item","children":["#","Deep Research"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Long-form QA",{"className":"page__taxonomy-item","children":["#","Long-form QA"]}],["$","span","Open-source AI",{"className":"page__taxonomy-item","children":["#","Open-source AI"]}],["$","span","Dynamic Evaluation",{"className":"page__taxonomy-item","children":["#","Dynamic Evaluation"]}]]]}]}],["$","section",null,{"className":"mt-12 border-t border-gray-200 pt-8","children":[["$","h3",null,{"className":"text-base font-semibold text-gray-900 mb-4","children":["Review"," 의 다른글"]}],["$","ul",null,{"className":"space-y-2 text-sm","children":[["$","li",null,{"className":"text-gray-500","children":["이전글"," ",["$","$L7",null,{"href":"/ai/review/2025-11-25-Controllable-Layer-Decomposition-for-Reversible-Multi-Layer-Image-Generation/","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] Controllable Layer Decomposition for Reversible Multi-Layer Image Generation"}]]}],["$","li",null,{"className":"text-gray-900 font-semibold","children":["현재글 : ","[논문리뷰] DR Tulu: Reinforcement Learning with Evolving Rubrics for Deep Research"]}],["$","li",null,{"className":"text-gray-500","children":["다음글"," ",["$","$L7",null,{"href":"/ai/review/2025-11-25-DeCo-Frequency-Decoupled-Pixel-Diffusion-for-End-to-End-Image-Generation/","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] DeCo: Frequency-Decoupled Pixel Diffusion for End-to-End Image Generation"}]]}]]}]]}]]}]}]]}]
8:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"secrett2633's blog"}],["$","meta","3",{"name":"description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","meta","4",{"name":"author","content":"secrett2633"}],["$","meta","5",{"name":"keywords","content":"Django, Python, DevOps, AI, ML, 블로그, 기술"}],["$","meta","6",{"name":"creator","content":"secrett2633"}],["$","meta","7",{"name":"publisher","content":"secrett2633"}],["$","meta","8",{"name":"robots","content":"index, follow"}],["$","meta","9",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","10",{"rel":"canonical","href":"https://blog.secrett2633.site/"}],["$","meta","11",{"name":"format-detection","content":"telephone=no, address=no, email=no"}],["$","meta","12",{"property":"og:title","content":"secrett2633's blog"}],["$","meta","13",{"property":"og:description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","meta","14",{"property":"og:url","content":"https://blog.secrett2633.site/"}],["$","meta","15",{"property":"og:site_name","content":"secrett2633's blog"}],["$","meta","16",{"property":"og:locale","content":"ko_KR"}],["$","meta","17",{"property":"og:type","content":"website"}],["$","meta","18",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","19",{"name":"twitter:title","content":"secrett2633's blog"}],["$","meta","20",{"name":"twitter:description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","link","21",{"rel":"icon","href":"/icon.ico?6d9f34d4948640b8","type":"image/x-icon","sizes":"16x16"}],["$","meta","22",{"name":"next-size-adjust"}]]
1:null
