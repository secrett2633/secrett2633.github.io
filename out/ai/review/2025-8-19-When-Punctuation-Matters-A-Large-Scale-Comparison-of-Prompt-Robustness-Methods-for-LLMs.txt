3:I[9275,[],""]
5:I[1343,[],""]
6:I[9157,["231","static/chunks/231-ee5764c1002761f9.js","132","static/chunks/132-273e49420772df1e.js","185","static/chunks/app/layout-d443cbc354279241.js"],"default"]
7:I[231,["231","static/chunks/231-ee5764c1002761f9.js","877","static/chunks/app/%5B...slug%5D/page-ef33f0f4c1a350bd.js"],""]
8:I[4080,["231","static/chunks/231-ee5764c1002761f9.js","132","static/chunks/132-273e49420772df1e.js","185","static/chunks/app/layout-d443cbc354279241.js"],""]
4:["slug","ai/review/2025-8-19-When-Punctuation-Matters-A-Large-Scale-Comparison-of-Prompt-Robustness-Methods-for-LLMs","c"]
0:["mJI0q5Z-SQWBtT83kG_N7",[[["",{"children":[["slug","ai/review/2025-8-19-When-Punctuation-Matters-A-Large-Scale-Comparison-of-Prompt-Robustness-Methods-for-LLMs","c"],{"children":["__PAGE__?{\"slug\":[\"ai\",\"review\",\"2025-8-19-When-Punctuation-Matters-A-Large-Scale-Comparison-of-Prompt-Robustness-Methods-for-LLMs\"]}",{}]}]},"$undefined","$undefined",true],["",{"children":[["slug","ai/review/2025-8-19-When-Punctuation-Matters-A-Large-Scale-Comparison-of-Prompt-Robustness-Methods-for-LLMs","c"],{"children":["__PAGE__",{},[["$L1","$L2"],null],null]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","$4","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},[["$","html",null,{"lang":"ko","className":"no-js","children":[["$","head",null,{"children":[["$","meta",null,{"name":"msapplication-TileColor","content":"#ffc40d"}],["$","meta",null,{"name":"theme-color","content":"#ffffff"}],["$","link",null,{"rel":"dns-prefetch","href":"https://www.googletagmanager.com"}],["$","link",null,{"rel":"preconnect","href":"https://www.googletagmanager.com","crossOrigin":"anonymous"}],["$","link",null,{"rel":"dns-prefetch","href":"https://giscus.app"}],["$","link",null,{"rel":"preconnect","href":"https://giscus.app","crossOrigin":"anonymous"}],["$","meta",null,{"httpEquiv":"X-Content-Type-Options","content":"nosniff"}],["$","meta",null,{"name":"referrer","content":"strict-origin-when-cross-origin"}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"WebSite\",\"name\":\"secrett2633's blog\",\"url\":\"https://blog.secrett2633.cloud\",\"description\":\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\",\"inLanguage\":\"ko\",\"publisher\":{\"@type\":\"Person\",\"name\":\"secrett2633\",\"url\":\"https://blog.secrett2633.cloud\"}}"}}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"Person\",\"name\":\"secrett2633\",\"url\":\"https://blog.secrett2633.cloud\",\"sameAs\":[\"https://github.com/secrett2633\"]}"}}]]}],["$","body",null,{"className":"__className_f367f3 layout--default","children":[["$","a",null,{"href":"#main-content","className":"sr-only focus:not-sr-only focus:absolute focus:z-50 focus:p-4 focus:bg-white focus:text-blue-600","children":"본문으로 건너뛰기"}],["$","div",null,{"className":"min-h-screen bg-gray-50","children":[["$","$L6",null,{}],["$","main",null,{"id":"main-content","className":"initial-content","children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","div",null,{"className":"min-h-screen flex items-center justify-center bg-gray-50","children":["$","div",null,{"className":"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center","children":[["$","h1",null,{"className":"text-6xl font-bold text-primary-600 mb-4","children":"404"}],["$","h2",null,{"className":"text-2xl font-semibold text-gray-900 mb-4","children":"페이지를 찾을 수 없습니다"}],["$","p",null,{"className":"text-gray-600 mb-8","children":"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다."}],["$","$L7",null,{"href":"/","className":"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors","children":"홈으로 돌아가기"}]]}]}],"notFoundStyles":[],"styles":null}]}],["$","div",null,{"id":"footer","className":"page__footer","children":["$","footer",null,{"className":"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8","children":["$","div",null,{"className":"text-center text-gray-500 text-sm","children":["$","p",null,{"children":["© ",2026," secrett2633. All rights reserved."]}]}]}]}]]}],["$","$L8",null,{"src":"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY","strategy":"afterInteractive"}],["$","$L8",null,{"id":"gtag-init","strategy":"afterInteractive","children":"window.dataLayer = window.dataLayer || [];\n            function gtag(){dataLayer.push(arguments);}\n            gtag('js', new Date());\n            gtag('config', 'G-NE2W3CFPNY');"}]]}]]}],null],[["$","div",null,{"className":"flex items-center justify-center min-h-screen","role":"status","aria-label":"로딩 중","children":[["$","div",null,{"className":"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600"}],["$","span",null,{"className":"sr-only","children":"로딩 중..."}]]}],[],[]]],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/edb8d4ad4fe2f3b0.css","precedence":"next","crossOrigin":"$undefined"}]],[null,"$L9"]]]]]
c:I[646,["231","static/chunks/231-ee5764c1002761f9.js","877","static/chunks/app/%5B...slug%5D/page-ef33f0f4c1a350bd.js"],"default"]
a:T4e3,{"@context":"https://schema.org","@type":"BlogPosting","headline":"[논문리뷰] When Punctuation Matters: A Large-Scale Comparison of Prompt Robustness Methods for LLMs","description":"Elena Tutubalina이 arXiv에 게시한 'When Punctuation Matters: A Large-Scale Comparison of Prompt Robustness Methods for LLMs' 논문에 대한 자세한 리뷰입니다.","url":"https://blog.secrett2633.cloud/ai/review/2025-8-19-When-Punctuation-Matters-A-Large-Scale-Comparison-of-Prompt-Robustness-Methods-for-LLMs","datePublished":"2025-08-19T04:15:01.000Z","dateModified":"2025-08-19T04:15:01.000Z","author":{"@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud"},"publisher":{"@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.secrett2633.cloud/ai/review/2025-8-19-When-Punctuation-Matters-A-Large-Scale-Comparison-of-Prompt-Robustness-Methods-for-LLMs"},"image":"https://blog.secrett2633.cloud/og-default.png","isAccessibleForFree":true,"inLanguage":"ko","wordCount":313,"articleSection":"Review","keywords":"Review, LLM Robustness, Prompt Sensitivity, In-Context Learning, Fine-Tuning, Batch Calibration, Template Ensembles, Distribution Shift"}b:Tf67,<blockquote>
<p><strong>링크:</strong> <a href="https://arxiv.org/abs/2508.11383" target="_blank" rel="noopener noreferrer">논문 PDF로 바로 열기</a></p>
</blockquote>
<p><strong>저자:</strong> Mikhail Seleznyov, Mikhail Chaichuk, Gleb Ershov, Alexander Panchenko, Elena Tutubalina, Oleg Somov</p>
<h2 id="핵심-연구-목표"><a href="#핵심-연구-목표">핵심 연구 목표</a></h2>
<p>본 연구는 LLM이 프롬프트 구문 및 형식의 미묘한 비의미적 변화에 매우 민감하게 반응하는 문제를 해결하고자 합니다. 기존의 프롬프트 강건성(robustness) 향상 방법론들이 개별적으로 평가되어 실무자가 비교하고 선택하기 어려웠던 공백을 채우기 위해, 다양한 LLM 패밀리, 학습 패러다임, 분포 변화 유형에 걸쳐 5가지 프롬프트 강건성 방법론을 체계적으로 비교 평가하는 것을 목표로 합니다.</p>
<h2 id="핵심-방법론"><a href="#핵심-방법론">핵심 방법론</a></h2>
<p>저자들은 <strong>Natural Instructions</strong> 데이터셋의 52개 태스크와 <strong>Llama, Qwen, Gemma</strong> 패밀리의 8개 모델(1.5B~9B 파라미터)을 사용하여 실험을 수행했습니다. 비교 대상 방법론으로는 <strong>Few-shot (FS)</strong> , <strong>Batch Calibration (BC)</strong> , <strong>Template Ensembles (TE)</strong> , <strong>Sensitivity-Aware Decoding (SAD)</strong> , 그리고 <strong>LoRA with format augmentations (LoRA)</strong> 가 포함됩니다. 추가적으로 <strong>GPT-4.1</strong> 및 <strong>DeepSeek V3</strong> 와 같은 최신 모델에 대한 평가도 진행했으며, <strong>그리디 디코딩(greedy decoding)</strong> 과 <strong>확률 랭킹(probability ranking)</strong> 등 두 가지 추론 전략의 영향을 분석했습니다.</p>
<h2 id="주요-결과"><a href="#주요-결과">주요 결과</a></h2>
<p><strong>Batch Calibration</strong> 은 분포 변화가 없을 때 가장 높은 정확도를 달성하고 확산을 크게 줄여 강건성을 향상시켰습니다. 반면, <strong>LoRA with augmentations</strong> 는 정확도를 크게 높였지만 프롬프트 형식 변화에 대한 강건성 개선에는 효과적이지 않았고, <strong>Template Ensembles</strong> 는 확산을 줄였지만 정확도를 낮출 수 있었습니다. <strong>그리디 디코딩</strong> 은 <strong>확률 랭킹</strong> 보다 훨씬 낮은 강건성을 보였습니다. 최신 모델인 <strong>DeepSeek V3</strong> 와 <strong>GPT-4.1</strong> 은 소규모 오픈소스 모델보다 강건했지만, 특정 태스크에서는 여전히 <strong>8-10%</strong> 의 정확도 확산을 보였으며, <strong>다수결 투표(majority voting)</strong> 를 사용한 <strong>Template Ensembles</strong> 가 이러한 불안정성을 완화하는 데 효과적이었습니다.</p>
<h2 id="ai-실무자를-위한-시사점"><a href="#ai-실무자를-위한-시사점">AI 실무자를 위한 시사점</a></h2>
<p>실무자는 프롬프트 형식에 대한 LLM의 민감성을 완화하기 위해 여러 전략을 고려할 수 있습니다. 배치 캘리브레이션은 데이터 분포 편향이 심하지 않은 경우 정확도와 강건성 모두를 개선하는 효율적인 방법입니다. 프롬프트 형식 변화에 대한 강건성을 위해서는 파인튜닝 기반의 <strong>LoRA with augmentations</strong> 만으로는 충분하지 않으며, <strong>확률 랭킹</strong> 과 같은 추론 전략을 우선적으로 고려해야 합니다. 또한, 최신 LLM도 특정 상황에서는 여전히 프롬프트 민감도를 보이며, 로짓 접근이 제한적인 블랙박스 모델의 경우 <strong>다수결 투표 기반의 Template Ensembles</strong> 가 유용한 강건성 확보 기법이 될 수 있습니다.</p>
<blockquote>
<p>⚠️ <strong>알림:</strong> 이 리뷰는 AI로 작성되었습니다.</p>
</blockquote>
2:[["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"$a"}}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"BreadcrumbList\",\"itemListElement\":[{\"@type\":\"ListItem\",\"position\":1,\"name\":\"홈\",\"item\":\"https://blog.secrett2633.cloud/\"},{\"@type\":\"ListItem\",\"position\":2,\"name\":\"Review\",\"item\":\"https://blog.secrett2633.cloud/ai/review\"},{\"@type\":\"ListItem\",\"position\":3,\"name\":\"[논문리뷰] When Punctuation Matters: A Large-Scale Comparison of Prompt Robustness Methods for LLMs\",\"item\":\"https://blog.secrett2633.cloud/ai/review/2025-8-19-When-Punctuation-Matters-A-Large-Scale-Comparison-of-Prompt-Robustness-Methods-for-LLMs\"}]}"}}],["$","div",null,{"className":"space-y-6","children":["$","div",null,{"className":"flex flex-col lg:flex-row gap-8","children":[["$","aside",null,{"className":"lg:w-64 xl:w-72 order-1 lg:order-none","children":["$","div",null,{"className":"sidebar sticky","children":["$","nav",null,{"className":"space-y-4","aria-label":"카테고리 네비게이션","children":[["$","div","Backend",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"Backend"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Django",{"children":["$","$L7",null,{"href":"/backend/django","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Django"," (",6,")"]}]}],["$","li","Logging",{"children":["$","$L7",null,{"href":"/backend/logging","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Logging"," (",1,")"]}]}]]}]]}],["$","div","Python",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"Python"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","PEP",{"children":["$","$L7",null,{"href":"/python/pep","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["PEP"," (",650,")"]}]}]]}]]}],["$","div","AI/ML",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"AI/ML"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","LLM",{"children":["$","$L7",null,{"href":"/ai/llm","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["LLM"," (",1,")"]}]}],["$","li","Review",{"children":["$","$L7",null,{"href":"/ai/review","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Review"," (",2741,")"]}]}]]}]]}],["$","div","DevOps",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"DevOps"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Nginx",{"children":["$","$L7",null,{"href":"/devops/nginx","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Nginx"," (",1,")"]}]}],["$","li","Docker",{"children":["$","$L7",null,{"href":"/devops/docker","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Docker"," (",1,")"]}]}],["$","li","SafeLine",{"children":["$","$L7",null,{"href":"/devops/safeline","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["SafeLine"," (",1,")"]}]}],["$","li","Jenkins",{"children":["$","$L7",null,{"href":"/devops/jenkins","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Jenkins"," (",3,")"]}]}],["$","li","GitHub Actions",{"children":["$","$L7",null,{"href":"/devops/github-actions","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["GitHub Actions"," (",1,")"]}]}],["$","li","AWS",{"children":["$","$L7",null,{"href":"/devops/aws","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["AWS"," (",1,")"]}]}]]}]]}],["$","div","etc",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"etc"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Me",{"children":["$","$L7",null,{"href":"/etc/me","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Me"," (",3,")"]}]}],["$","li","Chrome Extension",{"children":["$","$L7",null,{"href":"/etc/chrome-extension","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Chrome Extension"," (",1,")"]}]}]]}]]}]]}]}]}],["$","div",null,{"className":"flex-1","children":[["$","nav",null,{"aria-label":"breadcrumb","className":"text-sm text-gray-500 mb-4","children":["$","ol",null,{"className":"flex flex-wrap items-center gap-1","children":[["$","li",null,{"children":["$","$L7",null,{"href":"/","className":"hover:text-gray-700","children":"홈"}]}],[["$","li","/ai/review",{"className":"flex items-center gap-1","children":[["$","span",null,{"aria-hidden":"true","children":"/"}],["$","$L7",null,{"href":"/ai/review","className":"hover:text-gray-700","children":"Review"}]]}],["$","li","/ai/review/2025-8-19-When-Punctuation-Matters-A-Large-Scale-Comparison-of-Prompt-Robustness-Methods-for-LLMs",{"className":"flex items-center gap-1","children":[["$","span",null,{"aria-hidden":"true","children":"/"}],["$","span",null,{"className":"text-gray-900","aria-current":"page","children":"[논문리뷰] When Punctuation Matters: A Large-Scale Comparison of Prompt Robustness Methods for LLMs"}]]}]]]}]}],["$","article",null,{"className":"page","children":[["$","header",null,{"className":"mb-8","children":[["$","h1",null,{"className":"page__title","children":"[논문리뷰] When Punctuation Matters: A Large-Scale Comparison of Prompt Robustness Methods for LLMs"}],["$","div",null,{"className":"page__meta","children":[["$","time",null,{"dateTime":"2025-08-19 13:15:01+0900","children":"2025년 8월 19일"}],["$","time",null,{"className":"ml-4","dateTime":"2025-08-19T04:15:01.000Z","children":["수정: ","2025년 8월 19일"]}]]}]]}],["$","div",null,{"className":"page__content","children":["$","div",null,{"dangerouslySetInnerHTML":{"__html":"$b"}}]}],["$","footer",null,{"className":"page__meta mt-8","children":["$","div",null,{"className":"page__taxonomy","children":[["$","span",null,{"className":"text-sm font-medium text-gray-900 mb-2 block","children":"태그"}],[["$","$L7","Review",{"href":"/tags/Review","className":"page__taxonomy-item","children":["#","Review"]}],["$","$L7","LLM Robustness",{"href":"/tags/LLM%20Robustness","className":"page__taxonomy-item","children":["#","LLM Robustness"]}],["$","$L7","Prompt Sensitivity",{"href":"/tags/Prompt%20Sensitivity","className":"page__taxonomy-item","children":["#","Prompt Sensitivity"]}],["$","$L7","In-Context Learning",{"href":"/tags/In-Context%20Learning","className":"page__taxonomy-item","children":["#","In-Context Learning"]}],["$","$L7","Fine-Tuning",{"href":"/tags/Fine-Tuning","className":"page__taxonomy-item","children":["#","Fine-Tuning"]}],["$","$L7","Batch Calibration",{"href":"/tags/Batch%20Calibration","className":"page__taxonomy-item","children":["#","Batch Calibration"]}],["$","$L7","Template Ensembles",{"href":"/tags/Template%20Ensembles","className":"page__taxonomy-item","children":["#","Template Ensembles"]}],["$","$L7","Distribution Shift",{"href":"/tags/Distribution%20Shift","className":"page__taxonomy-item","children":["#","Distribution Shift"]}]]]}]}],["$","$Lc",null,{"postPermalink":"/ai/review/2025-8-19-When-Punctuation-Matters-A-Large-Scale-Comparison-of-Prompt-Robustness-Methods-for-LLMs","postId":"2025-8-19-When-Punctuation-Matters-A-Large-Scale-Comparison-of-Prompt-Robustness-Methods-for-LLMs"}],["$","section",null,{"className":"mt-12 border-t border-gray-200 pt-8","children":[["$","h3",null,{"className":"text-base font-semibold text-gray-900 mb-4","children":["Review"," 의 다른글"]}],["$","ul",null,{"className":"space-y-2 text-sm","children":[["$","li",null,{"className":"text-gray-500","children":["이전글"," ",["$","$L7",null,{"href":"/ai/review/2025-8-19-Speed-Always-Wins-A-Survey-on-Efficient-Architectures-for-Large-Language-Models","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] Speed Always Wins: A Survey on Efficient Architectures for Large Language Models"}]]}],["$","li",null,{"className":"text-gray-900 font-semibold","children":["현재글 : ","[논문리뷰] When Punctuation Matters: A Large-Scale Comparison of Prompt Robustness Methods for LLMs"]}],["$","li",null,{"className":"text-gray-500","children":["다음글"," ",["$","$L7",null,{"href":"/ai/review/2025-8-20-A-Stitch-in-Time-Saves-Nine-Proactive-Self-Refinement-for-Language-Models","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] A Stitch in Time Saves Nine: Proactive Self-Refinement for Language Models"}]]}]]}]]}]]}]]}]]}]}]]
9:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"[논문리뷰] When Punctuation Matters: A Large-Scale Comparison of Prompt Robustness Methods for LLMs - secrett2633's blog"}],["$","meta","3",{"name":"description","content":"Elena Tutubalina이 arXiv에 게시한 'When Punctuation Matters: A Large-Scale Comparison of Prompt Robustness Methods for LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","meta","4",{"name":"author","content":"secrett2633"}],["$","link","5",{"rel":"manifest","href":"/manifest.json","crossOrigin":"use-credentials"}],["$","meta","6",{"name":"keywords","content":"Django, Python, DevOps, AI, ML, 블로그, 기술"}],["$","meta","7",{"name":"creator","content":"secrett2633"}],["$","meta","8",{"name":"publisher","content":"secrett2633"}],["$","meta","9",{"name":"robots","content":"index, follow"}],["$","meta","10",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","11",{"rel":"canonical","href":"https://blog.secrett2633.cloud/ai/review/2025-8-19-When-Punctuation-Matters-A-Large-Scale-Comparison-of-Prompt-Robustness-Methods-for-LLMs"}],["$","meta","12",{"name":"format-detection","content":"telephone=no, address=no, email=no"}],["$","meta","13",{"property":"og:title","content":"[논문리뷰] When Punctuation Matters: A Large-Scale Comparison of Prompt Robustness Methods for LLMs"}],["$","meta","14",{"property":"og:description","content":"Elena Tutubalina이 arXiv에 게시한 'When Punctuation Matters: A Large-Scale Comparison of Prompt Robustness Methods for LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","meta","15",{"property":"og:url","content":"https://blog.secrett2633.cloud/ai/review/2025-8-19-When-Punctuation-Matters-A-Large-Scale-Comparison-of-Prompt-Robustness-Methods-for-LLMs"}],["$","meta","16",{"property":"og:type","content":"article"}],["$","meta","17",{"property":"article:published_time","content":"2025-08-19T04:15:01.000Z"}],["$","meta","18",{"property":"article:modified_time","content":"2025-08-19T04:15:01.000Z"}],["$","meta","19",{"property":"article:author","content":"secrett2633"}],["$","meta","20",{"property":"article:section","content":"Review"}],["$","meta","21",{"property":"article:tag","content":"Review"}],["$","meta","22",{"property":"article:tag","content":"LLM Robustness"}],["$","meta","23",{"property":"article:tag","content":"Prompt Sensitivity"}],["$","meta","24",{"property":"article:tag","content":"In-Context Learning"}],["$","meta","25",{"property":"article:tag","content":"Fine-Tuning"}],["$","meta","26",{"property":"article:tag","content":"Batch Calibration"}],["$","meta","27",{"property":"article:tag","content":"Template Ensembles"}],["$","meta","28",{"property":"article:tag","content":"Distribution Shift"}],["$","meta","29",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","30",{"name":"twitter:creator","content":"@secrett2633"}],["$","meta","31",{"name":"twitter:title","content":"[논문리뷰] When Punctuation Matters: A Large-Scale Comparison of Prompt Robustness Methods for LLMs"}],["$","meta","32",{"name":"twitter:description","content":"Elena Tutubalina이 arXiv에 게시한 'When Punctuation Matters: A Large-Scale Comparison of Prompt Robustness Methods for LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","link","33",{"rel":"icon","href":"/icon.ico?6d9f34d4948640b8","type":"image/x-icon","sizes":"16x16"}],["$","meta","34",{"name":"next-size-adjust"}]]
1:null
