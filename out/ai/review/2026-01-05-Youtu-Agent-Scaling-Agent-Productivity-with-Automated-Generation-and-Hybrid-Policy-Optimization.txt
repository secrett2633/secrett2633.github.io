3:I[9275,[],""]
5:I[1343,[],""]
6:I[9157,["231","static/chunks/231-ee5764c1002761f9.js","132","static/chunks/132-273e49420772df1e.js","185","static/chunks/app/layout-d443cbc354279241.js"],"default"]
7:I[231,["231","static/chunks/231-ee5764c1002761f9.js","877","static/chunks/app/%5B...slug%5D/page-ef33f0f4c1a350bd.js"],""]
8:I[4080,["231","static/chunks/231-ee5764c1002761f9.js","132","static/chunks/132-273e49420772df1e.js","185","static/chunks/app/layout-d443cbc354279241.js"],""]
4:["slug","ai/review/2026-01-05-Youtu-Agent-Scaling-Agent-Productivity-with-Automated-Generation-and-Hybrid-Policy-Optimization","c"]
0:["mJI0q5Z-SQWBtT83kG_N7",[[["",{"children":[["slug","ai/review/2026-01-05-Youtu-Agent-Scaling-Agent-Productivity-with-Automated-Generation-and-Hybrid-Policy-Optimization","c"],{"children":["__PAGE__?{\"slug\":[\"ai\",\"review\",\"2026-01-05-Youtu-Agent-Scaling-Agent-Productivity-with-Automated-Generation-and-Hybrid-Policy-Optimization\"]}",{}]}]},"$undefined","$undefined",true],["",{"children":[["slug","ai/review/2026-01-05-Youtu-Agent-Scaling-Agent-Productivity-with-Automated-Generation-and-Hybrid-Policy-Optimization","c"],{"children":["__PAGE__",{},[["$L1","$L2"],null],null]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","$4","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},[["$","html",null,{"lang":"ko","className":"no-js","children":[["$","head",null,{"children":[["$","meta",null,{"name":"msapplication-TileColor","content":"#ffc40d"}],["$","meta",null,{"name":"theme-color","content":"#ffffff"}],["$","link",null,{"rel":"dns-prefetch","href":"https://www.googletagmanager.com"}],["$","link",null,{"rel":"preconnect","href":"https://www.googletagmanager.com","crossOrigin":"anonymous"}],["$","link",null,{"rel":"dns-prefetch","href":"https://giscus.app"}],["$","link",null,{"rel":"preconnect","href":"https://giscus.app","crossOrigin":"anonymous"}],["$","meta",null,{"httpEquiv":"X-Content-Type-Options","content":"nosniff"}],["$","meta",null,{"name":"referrer","content":"strict-origin-when-cross-origin"}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"WebSite\",\"name\":\"secrett2633's blog\",\"url\":\"https://blog.secrett2633.cloud\",\"description\":\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\",\"inLanguage\":\"ko\",\"publisher\":{\"@type\":\"Person\",\"name\":\"secrett2633\",\"url\":\"https://blog.secrett2633.cloud\"}}"}}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"Person\",\"name\":\"secrett2633\",\"url\":\"https://blog.secrett2633.cloud\",\"sameAs\":[\"https://github.com/secrett2633\"]}"}}]]}],["$","body",null,{"className":"__className_f367f3 layout--default","children":[["$","a",null,{"href":"#main-content","className":"sr-only focus:not-sr-only focus:absolute focus:z-50 focus:p-4 focus:bg-white focus:text-blue-600","children":"본문으로 건너뛰기"}],["$","div",null,{"className":"min-h-screen bg-gray-50","children":[["$","$L6",null,{}],["$","main",null,{"id":"main-content","className":"initial-content","children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","div",null,{"className":"min-h-screen flex items-center justify-center bg-gray-50","children":["$","div",null,{"className":"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center","children":[["$","h1",null,{"className":"text-6xl font-bold text-primary-600 mb-4","children":"404"}],["$","h2",null,{"className":"text-2xl font-semibold text-gray-900 mb-4","children":"페이지를 찾을 수 없습니다"}],["$","p",null,{"className":"text-gray-600 mb-8","children":"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다."}],["$","$L7",null,{"href":"/","className":"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors","children":"홈으로 돌아가기"}]]}]}],"notFoundStyles":[],"styles":null}]}],["$","div",null,{"id":"footer","className":"page__footer","children":["$","footer",null,{"className":"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8","children":["$","div",null,{"className":"text-center text-gray-500 text-sm","children":["$","p",null,{"children":["© ",2026," secrett2633. All rights reserved."]}]}]}]}]]}],["$","$L8",null,{"src":"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY","strategy":"afterInteractive"}],["$","$L8",null,{"id":"gtag-init","strategy":"afterInteractive","children":"window.dataLayer = window.dataLayer || [];\n            function gtag(){dataLayer.push(arguments);}\n            gtag('js', new Date());\n            gtag('config', 'G-NE2W3CFPNY');"}]]}]]}],null],[["$","div",null,{"className":"flex items-center justify-center min-h-screen","role":"status","aria-label":"로딩 중","children":[["$","div",null,{"className":"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600"}],["$","span",null,{"className":"sr-only","children":"로딩 중..."}]]}],[],[]]],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/edb8d4ad4fe2f3b0.css","precedence":"next","crossOrigin":"$undefined"}]],[null,"$L9"]]]]]
c:I[646,["231","static/chunks/231-ee5764c1002761f9.js","877","static/chunks/app/%5B...slug%5D/page-ef33f0f4c1a350bd.js"],"default"]
a:T50f,{"@context":"https://schema.org","@type":"BlogPosting","headline":"[논문리뷰] Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization","description":"arXiv에 게시된 'Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization' 논문에 대한 자세한 리뷰입니다.","url":"https://blog.secrett2633.cloud/ai/review/2026-01-05-Youtu-Agent-Scaling-Agent-Productivity-with-Automated-Generation-and-Hybrid-Policy-Optimization","datePublished":"2026-01-04T15:00:00.000Z","dateModified":"2026-01-04T15:00:00.000Z","author":{"@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud"},"publisher":{"@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.secrett2633.cloud/ai/review/2026-01-05-Youtu-Agent-Scaling-Agent-Productivity-with-Automated-Generation-and-Hybrid-Policy-Optimization"},"image":"https://blog.secrett2633.cloud/og-default.png","isAccessibleForFree":true,"inLanguage":"ko","wordCount":329,"articleSection":"Review","keywords":"Review, LLM Agents, Automated Agent Generation, Reinforcement Learning, Hybrid Policy Optimization, Tool Synthesis, In-context Learning, Agent Framework, Scalability"}b:Tf58,<blockquote>
<p><strong>링크:</strong> <a href="https://arxiv.org/abs/2512.24615" target="_blank" rel="noopener noreferrer">논문 PDF로 바로 열기</a></p>
</blockquote>
<p><strong>저자:</strong> Yuchen Shi, Yuzheng Cai, Siqi Cai, Zihan Xu, Lichao Chen, Yulei Qin, Zhijian Zhou, Xiang Fei, Chaofan Qiu, Xiaoyu Tan, Gang Li, Zongyi Li, Haojia Lin, Guocan Cai, Yong Mao, Yunsheng Wu, Ke Li, Xing Sun</p>
<h2 id="핵심-연구-목표"><a href="#핵심-연구-목표">핵심 연구 목표</a></h2>
<p>본 논문은 기존 LLM 에이전트 프레임워크가 겪는 <strong>높은 구성 비용</strong> 과 <strong>정적 기능</strong> 문제를 해결하는 것을 목표로 합니다. 특히, 수동적인 툴 통합 및 프롬프트 엔지니어링의 부담을 줄이고, 배포된 에이전트가 동적 환경에 적응하기 어려운 한계를 극복하기 위해 <strong>자동화된 생성</strong> 과 <strong>지속적인 진화</strong> 를 위한 모듈형 프레임워크 <strong>Youtu-Agent</strong> 를 제안합니다.</p>
<h2 id="핵심-방법론"><a href="#핵심-방법론">핵심 방법론</a></h2>
<p><strong>Youtu-Agent</strong> 는 환경, 툴킷, 컨텍스트 관리를 분리하는 <strong>모듈형 YAML 기반 구성 시스템</strong> 을 특징으로 합니다. 에이전트 생성에는 <strong>Workflow 모드</strong> (표준 작업용)와 <strong>Meta-Agent 모드</strong> (복잡한 요구사항에 대해 <strong>툴 코드, 프롬프트, 구성 자동 생성</strong> ) 두 가지 패러다임을 도입합니다. 또한, <strong>Agent Practice 모듈</strong> 을 통해 파라미터 업데이트 없이 <strong>인-컨텍스트 경험 축적</strong> 을 통한 성능 개선을 지원하고, <strong>Agent RL 모듈</strong> 은 분산 학습 프레임워크와 통합하여 <strong>대규모 종단 간 강화 학습</strong> 을 위한 확장 가능하고 안정적인 최적화 시스템을 구축합니다.</p>
<h2 id="주요-결과"><a href="#주요-결과">주요 결과</a></h2>
<p><strong>Youtu-Agent</strong> 는 오픈 소스 모델(DeepSeek-V3 시리즈, Qwen2.5-7B)만을 사용하여 <strong>WebWalkerQA에서 71.47% pass@1</strong> 및 <strong>GAIA(텍스트 전용)에서 72.8% pass@1</strong> 의 최첨단 성능을 달성했습니다. 자동화된 툴 합성 파이프라인은 <strong>81% 이상의 툴 합성 성공률</strong> 을 보였습니다. <strong>Practice 모듈</strong> 은 단 100개 샘플 및 $18의 비용으로 AIME 2024/2025에서 각각 <strong>+2.7% 및 +5.4%</strong> 의 성능 향상을 가져왔습니다. <strong>Agent RL 학습</strong> 은 학습 반복 시간을 <strong>40% 단축</strong> 하고 Qwen2.5-7B 모델의 AIME 2024 정확도를 <strong>10%에서 45%로 향상</strong> 시켰습니다.</p>
<h2 id="ai-실무자를-위한-시사점"><a href="#ai-실무자를-위한-시사점">AI 실무자를 위한 시사점</a></h2>
<p><strong>Youtu-Agent</strong> 는 LLM 에이전트 개발의 <strong>높은 초기 비용</strong> 과 <strong>정적 기능 문제</strong> 를 해결하여 실무자들이 복잡한 에이전트를 보다 효율적으로 구축하고 지속적으로 개선할 수 있는 강력한 프레임워크를 제공합니다. <strong>자동화된 툴 코드 및 프롬프트 생성</strong> 기능은 에이전트 개발의 <strong>진입 장벽을 낮추고 확장성</strong> 을 크게 높이며, <strong>인-컨텍스트 학습</strong> 을 통한 저비용 성능 개선과 <strong>대규모 강화 학습</strong> 지원은 에이전트의 <strong>지속적인 진화</strong> 를 가능하게 합니다. 또한, <strong>오픈 소스 모델</strong> 만으로 경쟁력 있는 성능을 달성하여 비용 효율적인 에이전트 개발 및 배포에 활용 가치가 높습니다.</p>
<blockquote>
<p>⚠️ <strong>알림:</strong> 이 리뷰는 AI로 작성되었습니다.</p>
</blockquote>
2:[["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"$a"}}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"BreadcrumbList\",\"itemListElement\":[{\"@type\":\"ListItem\",\"position\":1,\"name\":\"홈\",\"item\":\"https://blog.secrett2633.cloud/\"},{\"@type\":\"ListItem\",\"position\":2,\"name\":\"Review\",\"item\":\"https://blog.secrett2633.cloud/ai/review\"},{\"@type\":\"ListItem\",\"position\":3,\"name\":\"[논문리뷰] Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization\",\"item\":\"https://blog.secrett2633.cloud/ai/review/2026-01-05-Youtu-Agent-Scaling-Agent-Productivity-with-Automated-Generation-and-Hybrid-Policy-Optimization\"}]}"}}],["$","div",null,{"className":"space-y-6","children":["$","div",null,{"className":"flex flex-col lg:flex-row gap-8","children":[["$","aside",null,{"className":"lg:w-64 xl:w-72 order-1 lg:order-none","children":["$","div",null,{"className":"sidebar sticky","children":["$","nav",null,{"className":"space-y-4","aria-label":"카테고리 네비게이션","children":[["$","div","Backend",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"Backend"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Django",{"children":["$","$L7",null,{"href":"/backend/django","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Django"," (",6,")"]}]}],["$","li","Logging",{"children":["$","$L7",null,{"href":"/backend/logging","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Logging"," (",1,")"]}]}]]}]]}],["$","div","Python",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"Python"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","PEP",{"children":["$","$L7",null,{"href":"/python/pep","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["PEP"," (",650,")"]}]}]]}]]}],["$","div","AI/ML",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"AI/ML"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","LLM",{"children":["$","$L7",null,{"href":"/ai/llm","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["LLM"," (",1,")"]}]}],["$","li","Review",{"children":["$","$L7",null,{"href":"/ai/review","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Review"," (",2741,")"]}]}]]}]]}],["$","div","DevOps",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"DevOps"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Nginx",{"children":["$","$L7",null,{"href":"/devops/nginx","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Nginx"," (",1,")"]}]}],["$","li","Docker",{"children":["$","$L7",null,{"href":"/devops/docker","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Docker"," (",1,")"]}]}],["$","li","SafeLine",{"children":["$","$L7",null,{"href":"/devops/safeline","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["SafeLine"," (",1,")"]}]}],["$","li","Jenkins",{"children":["$","$L7",null,{"href":"/devops/jenkins","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Jenkins"," (",3,")"]}]}],["$","li","GitHub Actions",{"children":["$","$L7",null,{"href":"/devops/github-actions","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["GitHub Actions"," (",1,")"]}]}],["$","li","AWS",{"children":["$","$L7",null,{"href":"/devops/aws","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["AWS"," (",1,")"]}]}]]}]]}],["$","div","etc",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"etc"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Me",{"children":["$","$L7",null,{"href":"/etc/me","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Me"," (",3,")"]}]}],["$","li","Chrome Extension",{"children":["$","$L7",null,{"href":"/etc/chrome-extension","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Chrome Extension"," (",1,")"]}]}]]}]]}]]}]}]}],["$","div",null,{"className":"flex-1","children":[["$","nav",null,{"aria-label":"breadcrumb","className":"text-sm text-gray-500 mb-4","children":["$","ol",null,{"className":"flex flex-wrap items-center gap-1","children":[["$","li",null,{"children":["$","$L7",null,{"href":"/","className":"hover:text-gray-700","children":"홈"}]}],[["$","li","/ai/review",{"className":"flex items-center gap-1","children":[["$","span",null,{"aria-hidden":"true","children":"/"}],["$","$L7",null,{"href":"/ai/review","className":"hover:text-gray-700","children":"Review"}]]}],["$","li","/ai/review/2026-01-05-Youtu-Agent-Scaling-Agent-Productivity-with-Automated-Generation-and-Hybrid-Policy-Optimization",{"className":"flex items-center gap-1","children":[["$","span",null,{"aria-hidden":"true","children":"/"}],["$","span",null,{"className":"text-gray-900","aria-current":"page","children":"[논문리뷰] Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization"}]]}]]]}]}],["$","article",null,{"className":"page","children":[["$","header",null,{"className":"mb-8","children":[["$","h1",null,{"className":"page__title","children":"[논문리뷰] Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization"}],["$","div",null,{"className":"page__meta","children":[["$","time",null,{"dateTime":"2026-01-05 00:00:00+0900+0900","children":"2026년 1월 5일"}],["$","time",null,{"className":"ml-4","dateTime":"2026-01-04T15:00:00.000Z","children":["수정: ","2026년 1월 5일"]}]]}]]}],["$","div",null,{"className":"page__content","children":["$","div",null,{"dangerouslySetInnerHTML":{"__html":"$b"}}]}],["$","footer",null,{"className":"page__meta mt-8","children":["$","div",null,{"className":"page__taxonomy","children":[["$","span",null,{"className":"text-sm font-medium text-gray-900 mb-2 block","children":"태그"}],[["$","$L7","Review",{"href":"/tags/Review","className":"page__taxonomy-item","children":["#","Review"]}],["$","$L7","LLM Agents",{"href":"/tags/LLM%20Agents","className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","$L7","Automated Agent Generation",{"href":"/tags/Automated%20Agent%20Generation","className":"page__taxonomy-item","children":["#","Automated Agent Generation"]}],["$","$L7","Reinforcement Learning",{"href":"/tags/Reinforcement%20Learning","className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","$L7","Hybrid Policy Optimization",{"href":"/tags/Hybrid%20Policy%20Optimization","className":"page__taxonomy-item","children":["#","Hybrid Policy Optimization"]}],["$","$L7","Tool Synthesis",{"href":"/tags/Tool%20Synthesis","className":"page__taxonomy-item","children":["#","Tool Synthesis"]}],["$","$L7","In-context Learning",{"href":"/tags/In-context%20Learning","className":"page__taxonomy-item","children":["#","In-context Learning"]}],["$","$L7","Agent Framework",{"href":"/tags/Agent%20Framework","className":"page__taxonomy-item","children":["#","Agent Framework"]}],["$","$L7","Scalability",{"href":"/tags/Scalability","className":"page__taxonomy-item","children":["#","Scalability"]}]]]}]}],["$","$Lc",null,{"postPermalink":"/ai/review/2026-01-05-Youtu-Agent-Scaling-Agent-Productivity-with-Automated-Generation-and-Hybrid-Policy-Optimization","postId":"2026-01-05-Youtu-Agent-Scaling-Agent-Productivity-with-Automated-Generation-and-Hybrid-Policy-Optimization"}],["$","section",null,{"className":"mt-12 border-t border-gray-200 pt-8","children":[["$","h3",null,{"className":"text-base font-semibold text-gray-900 mb-4","children":["Review"," 의 다른글"]}],["$","ul",null,{"className":"space-y-2 text-sm","children":[["$","li",null,{"className":"text-gray-500","children":["이전글"," ",["$","$L7",null,{"href":"/ai/review/2026-01-05-Taming-Hallucinations-Boosting-MLLMs-Video-Understanding-via-Counterfactual-Video-Generation","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] Taming Hallucinations: Boosting MLLMs' Video Understanding via Counterfactual Video Generation"}]]}],["$","li",null,{"className":"text-gray-900 font-semibold","children":["현재글 : ","[논문리뷰] Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization"]}],["$","li",null,{"className":"text-gray-500","children":["다음글"," ",["$","$L7",null,{"href":"/ai/review/2026-01-06-COMPASS-A-Framework-for-Evaluating-Organization-Specific-Policy-Alignment-in-LLMs","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] COMPASS: A Framework for Evaluating Organization-Specific Policy Alignment in LLMs"}]]}]]}]]}]]}]]}]]}]}]]
9:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"[논문리뷰] Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization - secrett2633's blog"}],["$","meta","3",{"name":"description","content":"arXiv에 게시된 'Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","meta","4",{"name":"author","content":"secrett2633"}],["$","link","5",{"rel":"manifest","href":"/manifest.json","crossOrigin":"use-credentials"}],["$","meta","6",{"name":"keywords","content":"Django, Python, DevOps, AI, ML, 블로그, 기술"}],["$","meta","7",{"name":"creator","content":"secrett2633"}],["$","meta","8",{"name":"publisher","content":"secrett2633"}],["$","meta","9",{"name":"robots","content":"index, follow"}],["$","meta","10",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","11",{"rel":"canonical","href":"https://blog.secrett2633.cloud/ai/review/2026-01-05-Youtu-Agent-Scaling-Agent-Productivity-with-Automated-Generation-and-Hybrid-Policy-Optimization"}],["$","meta","12",{"name":"format-detection","content":"telephone=no, address=no, email=no"}],["$","meta","13",{"property":"og:title","content":"[논문리뷰] Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization"}],["$","meta","14",{"property":"og:description","content":"arXiv에 게시된 'Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","meta","15",{"property":"og:url","content":"https://blog.secrett2633.cloud/ai/review/2026-01-05-Youtu-Agent-Scaling-Agent-Productivity-with-Automated-Generation-and-Hybrid-Policy-Optimization"}],["$","meta","16",{"property":"og:type","content":"article"}],["$","meta","17",{"property":"article:published_time","content":"2026-01-04T15:00:00.000Z"}],["$","meta","18",{"property":"article:modified_time","content":"2026-01-04T15:00:00.000Z"}],["$","meta","19",{"property":"article:author","content":"secrett2633"}],["$","meta","20",{"property":"article:section","content":"Review"}],["$","meta","21",{"property":"article:tag","content":"Review"}],["$","meta","22",{"property":"article:tag","content":"LLM Agents"}],["$","meta","23",{"property":"article:tag","content":"Automated Agent Generation"}],["$","meta","24",{"property":"article:tag","content":"Reinforcement Learning"}],["$","meta","25",{"property":"article:tag","content":"Hybrid Policy Optimization"}],["$","meta","26",{"property":"article:tag","content":"Tool Synthesis"}],["$","meta","27",{"property":"article:tag","content":"In-context Learning"}],["$","meta","28",{"property":"article:tag","content":"Agent Framework"}],["$","meta","29",{"property":"article:tag","content":"Scalability"}],["$","meta","30",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","31",{"name":"twitter:creator","content":"@secrett2633"}],["$","meta","32",{"name":"twitter:title","content":"[논문리뷰] Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization"}],["$","meta","33",{"name":"twitter:description","content":"arXiv에 게시된 'Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","link","34",{"rel":"icon","href":"/icon.ico?6d9f34d4948640b8","type":"image/x-icon","sizes":"16x16"}],["$","meta","35",{"name":"next-size-adjust"}]]
1:null
