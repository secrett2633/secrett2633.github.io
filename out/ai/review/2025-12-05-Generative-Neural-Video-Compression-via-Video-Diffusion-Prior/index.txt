3:I[9275,[],""]
5:I[1343,[],""]
6:I[9157,["231","static/chunks/231-c27e618569e042bc.js","185","static/chunks/app/layout-f2c168e996e2da30.js"],"default"]
7:I[231,["231","static/chunks/231-c27e618569e042bc.js","877","static/chunks/app/%5B...slug%5D/page-d9dbb0d3ac265797.js"],""]
4:["slug","ai/review/2025-12-05-Generative-Neural-Video-Compression-via-Video-Diffusion-Prior","c"]
0:["-9tNcy1wwtJPV_mfE6jXv",[[["",{"children":[["slug","ai/review/2025-12-05-Generative-Neural-Video-Compression-via-Video-Diffusion-Prior","c"],{"children":["__PAGE__?{\"slug\":[\"ai\",\"review\",\"2025-12-05-Generative-Neural-Video-Compression-via-Video-Diffusion-Prior\"]}",{}]}]},"$undefined","$undefined",true],["",{"children":[["slug","ai/review/2025-12-05-Generative-Neural-Video-Compression-via-Video-Diffusion-Prior","c"],{"children":["__PAGE__",{},[["$L1","$L2"],null],null]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","$4","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},[["$","html",null,{"lang":"ko","className":"no-js","children":[["$","head",null,{"children":[["$","meta",null,{"name":"msapplication-TileColor","content":"#ffc40d"}],["$","meta",null,{"name":"theme-color","content":"#ffffff"}],["$","script",null,{"async":true,"src":"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY"}],["$","script",null,{"dangerouslySetInnerHTML":{"__html":"\n              window.dataLayer = window.dataLayer || [];\n              function gtag(){dataLayer.push(arguments);}\n              gtag('js', new Date());\n              gtag('config', 'G-NE2W3CFPNY');\n            "}}]]}],["$","body",null,{"className":"__className_f367f3 layout--default","children":["$","div",null,{"className":"min-h-screen bg-gray-50","children":[["$","$L6",null,{}],["$","main",null,{"className":"initial-content","children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","div",null,{"className":"min-h-screen flex items-center justify-center bg-gray-50","children":["$","div",null,{"className":"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center","children":[["$","h1",null,{"className":"text-6xl font-bold text-primary-600 mb-4","children":"404"}],["$","h2",null,{"className":"text-2xl font-semibold text-gray-900 mb-4","children":"페이지를 찾을 수 없습니다"}],["$","p",null,{"className":"text-gray-600 mb-8","children":"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다."}],["$","$L7",null,{"href":"/","className":"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors","children":"홈으로 돌아가기"}]]}]}],"notFoundStyles":[],"styles":null}]}],["$","div",null,{"id":"footer","className":"page__footer","children":["$","footer",null,{"className":"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8","children":["$","div",null,{"className":"text-center text-gray-500 text-sm","children":["$","p",null,{"children":"© 2025 secrett2633. All rights reserved."}]}]}]}]]}]}]]}],null],[["$","div",null,{"className":"flex items-center justify-center min-h-screen","children":["$","div",null,{"className":"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600"}]}],[],[]]],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/773b243a13a00265.css","precedence":"next","crossOrigin":"$undefined"}]],[null,"$L8"]]]]]
a:I[646,["231","static/chunks/231-c27e618569e042bc.js","877","static/chunks/app/%5B...slug%5D/page-d9dbb0d3ac265797.js"],"default"]
9:Tc55,<blockquote>
<p><strong>링크:</strong> <a href="https://arxiv.org/abs/2512.05016">논문 PDF로 바로 열기</a></p>
</blockquote>
<p><strong>저자:</strong> Qi Mao, Hao Cheng, Tinghan Yang, Libiao Jin, Siwei Ma</p>
<h2>핵심 연구 목표</h2>
<p>본 논문은 기존 비디오 압축 방식이 초저비트레이트 환경에서 발생하는 흐릿함, 세부 정보 손실, 그리고 지각적 깜빡임(perceptual flickering) 문제를 해결하는 것을 목표로 합니다. 특히, 이미지 기반 생성형 모델을 활용한 이전 접근 방식의 프레임 단위 한계를 극복하고, <strong>비디오 네이티브 확산 모델</strong> 을 활용하여 시간적으로 일관되고 지각적으로 충실한 비디오 재구성을 달성하고자 합니다.</p>
<h2>핵심 방법론</h2>
<p>제안하는 <strong>GNVC-VD</strong> 는 <strong>contextual transform codec</strong> 를 통해 시공간 잠재 표현을 압축하고, 사전 훈련된 <strong>VideoDiT(Video Diffusion Transformer)</strong> 기반의 <strong>flow-matching latent refinement module</strong> 을 사용하여 시퀀스 레벨에서 잠재 표현을 개선합니다. 순수한 가우시안 노이즈 대신 디코딩된 시공간 잠재 표현에서 직접 정제를 시작하고, <strong>압축 인식 조건부 어댑터(compression-aware conditioning adapter)</strong> 를 통해 압축으로 인한 왜곡에 확산 모델을 적응시킵니다. 효과적인 학습을 위해 <strong>잠재 레벨 정렬(latent-level alignment)</strong> 과 <strong>픽셀 레벨 미세 조정(pixel-level fine-tuning)</strong> 의 두 단계 훈련 전략을 사용합니다.</p>
<h2>주요 결과</h2>
<p><strong>GNVC-VD</strong> 는 UVG 데이터셋에서 왜곡 중심의 <strong>DCVC-RT</strong> 대비 DISTS에서 <strong>98% 이상의 BD-rate 감소</strong> 및 LPIPS에서 <strong>56%의 BD-rate 감소</strong> 를 달성했습니다. 또한, 기존 생성형 코덱인 <strong>GLC-Video</strong> 와 비교했을 때, DISTS에서 <strong>86% BD-rate 감소</strong> 및 LPIPS에서 <strong>21% BD-rate 감소</strong> 를 기록했습니다. 정성적 비교와 사용자 연구에서 <strong>GNVC-VD</strong> 는 기존 방식 대비 더 선명한 텍스처와 현저히 감소된 깜빡임, 강력한 시간적 일관성을 제공함을 입증했습니다.</p>
<h2>AI 실무자를 위한 시사점</h2>
<p>이 연구는 <strong>비디오 네이티브 확산 모델</strong> 이 초저비트레이트 비디오 압축에서 지각 품질과 시간적 일관성을 혁신적으로 개선할 수 있음을 보여줍니다. AI 실무자들은 <strong>DiT 기반의 시퀀스 레벨 생성형 정제</strong> 방식이 미래 비디오 압축 시스템 설계의 핵심 요소가 될 수 있음을 인지해야 합니다. 특히, <strong>flow-matching</strong> 및 <strong>압축 인식 조건부</strong> 메커니즘은 다른 멀티미디어 압축 및 생성 태스크에도 적용될 수 있는 중요한 기술적 통찰력을 제공합니다.</p>
<blockquote>
<p>⚠️ <strong>알림:</strong> 이 리뷰는 AI로 작성되었습니다.</p>
</blockquote>
2:["$","div",null,{"className":"flex flex-col lg:flex-row gap-8","children":[["$","aside",null,{"className":"lg:w-64 xl:w-72 order-1 lg:order-none","children":["$","div",null,{"className":"sidebar sticky","children":["$","nav",null,{"className":"space-y-4","children":[["$","div","Backend",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"Backend"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Django",{"children":["$","a",null,{"href":"/backend/django/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Django"," (",6,")"]}]}],["$","li","Logging",{"children":["$","a",null,{"href":"/backend/logging/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Logging"," (",1,")"]}]}]]}]]}],["$","div","Python",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"Python"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","PEP",{"children":["$","a",null,{"href":"/python/pep/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["PEP"," (",650,")"]}]}]]}]]}],["$","div","AI/ML",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"AI/ML"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","LLM",{"children":["$","a",null,{"href":"/ai/llm/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["LLM"," (",1,")"]}]}],["$","li","Review",{"children":["$","a",null,{"href":"/ai/review/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Review"," (",2335,")"]}]}]]}]]}],["$","div","DevOps",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"DevOps"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Nginx",{"children":["$","a",null,{"href":"/devops/nginx/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Nginx"," (",1,")"]}]}],["$","li","Docker",{"children":["$","a",null,{"href":"/devops/docker/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Docker"," (",1,")"]}]}],["$","li","SafeLine",{"children":["$","a",null,{"href":"/devops/safeline/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["SafeLine"," (",1,")"]}]}],["$","li","Jenkins",{"children":["$","a",null,{"href":"/devops/jenkins/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Jenkins"," (",3,")"]}]}],["$","li","GitHub Actions",{"children":["$","a",null,{"href":"/devops/github-actions/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["GitHub Actions"," (",1,")"]}]}],["$","li","AWS",{"children":["$","a",null,{"href":"/devops/aws/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["AWS"," (",1,")"]}]}]]}]]}],["$","div","etc",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"etc"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Me",{"children":["$","a",null,{"href":"/etc/me/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Me"," (",3,")"]}]}],["$","li","Chrome Extension",{"children":["$","a",null,{"href":"/etc/chrome-extension/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Chrome Extension"," (",1,")"]}]}]]}]]}]]}]}]}],["$","main",null,{"className":"flex-1","children":["$","article",null,{"className":"page","children":[["$","header",null,{"className":"mb-8","children":[["$","h1",null,{"className":"page__title","children":"[논문리뷰] Generative Neural Video Compression via Video Diffusion Prior"}],["$","div",null,{"className":"page__meta","children":[["$","time",null,{"dateTime":"2025-12-05 00:00:00+0900+0900","children":"2025년 12월 5일"}],["$","span",null,{"className":"ml-4","children":["수정: ","2025년 12월 5일"]}]]}]]}],["$","div",null,{"className":"page__content","children":["$","div",null,{"dangerouslySetInnerHTML":{"__html":"$9"}}]}],["$","footer",null,{"className":"page__meta mt-8","children":["$","div",null,{"className":"page__taxonomy","children":[["$","h4",null,{"className":"text-sm font-medium text-gray-900 mb-2","children":"태그"}],[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Neural Video Compression",{"className":"page__taxonomy-item","children":["#","Neural Video Compression"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Video Compression",{"className":"page__taxonomy-item","children":["#","Video Compression"]}],["$","span","Temporal Coherence",{"className":"page__taxonomy-item","children":["#","Temporal Coherence"]}],["$","span","Perceptual Quality",{"className":"page__taxonomy-item","children":["#","Perceptual Quality"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Video Diffusion Transformer (VideoDiT)",{"className":"page__taxonomy-item","children":["#","Video Diffusion Transformer (VideoDiT)"]}]]]}]}],["$","$La",null,{"postPermalink":"/ai/review/2025-12-05-Generative-Neural-Video-Compression-via-Video-Diffusion-Prior/","postId":"2025-12-05-Generative-Neural-Video-Compression-via-Video-Diffusion-Prior"}],["$","section",null,{"className":"mt-12 border-t border-gray-200 pt-8","children":[["$","h3",null,{"className":"text-base font-semibold text-gray-900 mb-4","children":["Review"," 의 다른글"]}],["$","ul",null,{"className":"space-y-2 text-sm","children":[["$","li",null,{"className":"text-gray-500","children":["이전글"," ",["$","$L7",null,{"href":"/ai/review/2025-12-05-GaussianBlender-Instant-Stylization-of-3D-Gaussians-with-Disentangled-Latent-Spaces/","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] GaussianBlender: Instant Stylization of 3D Gaussians with Disentangled Latent Spaces"}]]}],["$","li",null,{"className":"text-gray-900 font-semibold","children":["현재글 : ","[논문리뷰] Generative Neural Video Compression via Video Diffusion Prior"]}],["$","li",null,{"className":"text-gray-500","children":["다음글"," ",["$","$L7",null,{"href":"/ai/review/2025-12-05-LATTICE-Democratize-High-Fidelity-3D-Generation-at-Scale/","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] LATTICE: Democratize High-Fidelity 3D Generation at Scale"}]]}]]}]]}]]}]}]]}]
8:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"secrett2633's blog"}],["$","meta","3",{"name":"description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","meta","4",{"name":"author","content":"secrett2633"}],["$","meta","5",{"name":"keywords","content":"Django, Python, DevOps, AI, ML, 블로그, 기술"}],["$","meta","6",{"name":"creator","content":"secrett2633"}],["$","meta","7",{"name":"publisher","content":"secrett2633"}],["$","meta","8",{"name":"robots","content":"index, follow"}],["$","meta","9",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","10",{"rel":"canonical","href":"https://blog.secrett2633.cloud/"}],["$","meta","11",{"name":"format-detection","content":"telephone=no, address=no, email=no"}],["$","meta","12",{"property":"og:title","content":"secrett2633's blog"}],["$","meta","13",{"property":"og:description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","meta","14",{"property":"og:url","content":"https://blog.secrett2633.cloud/"}],["$","meta","15",{"property":"og:site_name","content":"secrett2633's blog"}],["$","meta","16",{"property":"og:locale","content":"ko_KR"}],["$","meta","17",{"property":"og:type","content":"website"}],["$","meta","18",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","19",{"name":"twitter:title","content":"secrett2633's blog"}],["$","meta","20",{"name":"twitter:description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","link","21",{"rel":"icon","href":"/icon.ico?6d9f34d4948640b8","type":"image/x-icon","sizes":"16x16"}],["$","meta","22",{"name":"next-size-adjust"}]]
1:null
