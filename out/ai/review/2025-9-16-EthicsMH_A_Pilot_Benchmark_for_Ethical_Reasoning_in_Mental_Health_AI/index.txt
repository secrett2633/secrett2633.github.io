3:I[9275,[],""]
5:I[1343,[],""]
6:I[9157,["231","static/chunks/231-c27e618569e042bc.js","157","static/chunks/157-19cfc001fdac3337.js","185","static/chunks/app/layout-c3e2e457f12fb6f6.js"],"default"]
7:I[231,["231","static/chunks/231-c27e618569e042bc.js","931","static/chunks/app/page-51594f997fc19690.js"],""]
4:["slug","ai/review/2025-9-16-EthicsMH_A_Pilot_Benchmark_for_Ethical_Reasoning_in_Mental_Health_AI","c"]
0:["FeyCvJug7In7AgUZlfHUx",[[["",{"children":[["slug","ai/review/2025-9-16-EthicsMH_A_Pilot_Benchmark_for_Ethical_Reasoning_in_Mental_Health_AI","c"],{"children":["__PAGE__?{\"slug\":[\"ai\",\"review\",\"2025-9-16-EthicsMH_A_Pilot_Benchmark_for_Ethical_Reasoning_in_Mental_Health_AI\"]}",{}]}]},"$undefined","$undefined",true],["",{"children":[["slug","ai/review/2025-9-16-EthicsMH_A_Pilot_Benchmark_for_Ethical_Reasoning_in_Mental_Health_AI","c"],{"children":["__PAGE__",{},[["$L1","$L2"],null],null]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","$4","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},[["$","html",null,{"lang":"ko","className":"no-js","children":[["$","head",null,{"children":[["$","meta",null,{"name":"msapplication-TileColor","content":"#ffc40d"}],["$","meta",null,{"name":"theme-color","content":"#ffffff"}],["$","script",null,{"async":true,"src":"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY"}],["$","script",null,{"dangerouslySetInnerHTML":{"__html":"\n              window.dataLayer = window.dataLayer || [];\n              function gtag(){dataLayer.push(arguments);}\n              gtag('js', new Date());\n              gtag('config', 'G-NE2W3CFPNY');\n            "}}]]}],["$","body",null,{"className":"__className_f367f3 layout--default","children":["$","div",null,{"className":"min-h-screen bg-gray-50","children":[["$","$L6",null,{}],["$","main",null,{"className":"initial-content","children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","div",null,{"className":"min-h-screen flex items-center justify-center bg-gray-50","children":["$","div",null,{"className":"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center","children":[["$","h1",null,{"className":"text-6xl font-bold text-primary-600 mb-4","children":"404"}],["$","h2",null,{"className":"text-2xl font-semibold text-gray-900 mb-4","children":"페이지를 찾을 수 없습니다"}],["$","p",null,{"className":"text-gray-600 mb-8","children":"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다."}],["$","$L7",null,{"href":"/","className":"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors","children":"홈으로 돌아가기"}]]}]}],"notFoundStyles":[],"styles":null}]}],["$","div",null,{"id":"footer","className":"page__footer","children":["$","footer",null,{"className":"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8","children":["$","div",null,{"className":"text-center text-gray-500 text-sm","children":["$","p",null,{"children":"© 2025 secrett2633. All rights reserved."}]}]}]}]]}]}]]}],null],[["$","div",null,{"className":"flex items-center justify-center min-h-screen","children":["$","div",null,{"className":"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600"}]}],[],[]]],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/e975486d410ad4e9.css","precedence":"next","crossOrigin":"$undefined"}]],[null,"$L8"]]]]]
9:Tc1a,<blockquote>
<p><strong>링크:</strong> <a href="https://arxiv.org/abs/2509.11648">논문 PDF로 바로 열기</a></p>
</blockquote>
<p><strong>저자:</strong> Sai Kartheek Reddy Kasu</p>
<h2>핵심 연구 목표</h2>
<p>본 논문은 대규모 언어 모델(LLM)이 정신 건강과 같은 민감한 도메인에서 직면하는 윤리적 추론의 한계를 해결하고자 합니다. 기존 벤치마크들이 정신 건강 분야의 고유한 윤리적 딜레마(기밀 유지, 자율성, 선행, 편향 등)를 충분히 포착하지 못하는 문제를 인식하고, 이를 평가하기 위한 <strong>새로운 파일럿 데이터셋인 EthicsMH</strong>를 구축하는 것을 목표로 합니다.</p>
<h2>핵심 방법론</h2>
<p>제안된 <code>EthicsMH</code>는 정신 건강 맥락에서 윤리적으로 복잡한 <strong>125개의 시나리오</strong>로 구성된 파일럿 데이터셋입니다. 각 시나리오는 <code>다중 의사결정 옵션</code>, <code>전문가 정렬 추론</code>, <code>예상 모델 행동</code>, <code>실제 세계 영향</code>, <code>다중 이해관계자 관점</code> 등의 <strong>구조화된 필드</strong>를 포함합니다. 이 데이터셋은 <strong>LLM 기반 생성</strong>과 정신 건강 전문가의 <strong>지속적인 감독 및 반복적인 개선</strong>을 포함하는 <strong>Human-in-the-loop 프로세스</strong>를 통해 구축되었습니다.</p>
<h2>주요 결과</h2>
<p><code>EthicsMH</code> 데이터셋은 모델의 <strong>결정 정확도</strong>뿐만 아니라 <strong>설명 품질</strong> 및 <strong>전문가 규범과의 일치 여부</strong>까지 평가할 수 있는 독특한 프레임워크를 제공합니다. 본 논문 자체는 모델 평가 결과를 제시하기보다는 데이터셋의 구조와 구축 과정을 설명하며, 이를 통해 <strong>윤리적 문제를 인식하고 해결하는 AI 시스템 개발</strong>을 위한 기초 자원을 마련했습니다. 이 파일럿 데이터셋은 향후 더 크고 전문가 검증을 거친 윤리적 벤치마크 구축을 위한 <strong>절차적 청사진</strong> 역할을 합니다.</p>
<h2>AI 실무자를 위한 시사점</h2>
<p>AI 실무자들은 <code>EthicsMH</code>를 활용하여 LLM의 <strong>윤리적 추론 능력</strong>을 프로토타이핑하고, 초기 단계의 시스템 설계 및 <strong>안전 장치</strong>를 검증할 수 있습니다. 특히 모델의 <strong>편향된 행동</strong>이나 <strong>주요 이해관계자 관점 누락</strong>과 같은 실패 모드를 <strong>진단적으로 평가</strong>하는 데 유용하며, 이는 표준 평가 지표를 넘어선 통찰력을 제공합니다. 또한, 이 데이터셋은 윤리적 AI 벤치마크를 <strong>확장하고 전문가 검증을 통합</strong>하는 방법론적 가이드라인을 제시하여, 정신 건강 AI 개발의 <strong>사회적 책임성</strong>을 높이는 데 기여합니다.</p>
<blockquote>
<p>⚠️ <strong>알림:</strong> 이 리뷰는 AI로 작성되었습니다.</p>
</blockquote>
2:["$","div",null,{"className":"flex flex-col lg:flex-row gap-8","children":[["$","aside",null,{"className":"lg:w-64 xl:w-72 order-1 lg:order-none","children":["$","div",null,{"className":"sidebar sticky","children":["$","nav",null,{"className":"space-y-4","children":[["$","div","Backend",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"Backend"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Django",{"children":["$","a",null,{"href":"/backend/django/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Django"," (",6,")"]}]}],["$","li","Logging",{"children":["$","a",null,{"href":"/backend/logging/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Logging"," (",1,")"]}]}]]}]]}],["$","div","Python",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"Python"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","PEP",{"children":["$","a",null,{"href":"/python/pep/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["PEP"," (",650,")"]}]}]]}]]}],["$","div","AI/ML",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"AI/ML"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","LLM",{"children":["$","a",null,{"href":"/ai/llm/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["LLM"," (",1,")"]}]}],["$","li","Review",{"children":["$","a",null,{"href":"/ai/review/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Review"," (",1098,")"]}]}]]}]]}],["$","div","DevOps",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"DevOps"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Nginx",{"children":["$","a",null,{"href":"/devops/nginx/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Nginx"," (",1,")"]}]}],["$","li","Docker",{"children":["$","a",null,{"href":"/devops/docker/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Docker"," (",1,")"]}]}],["$","li","SafeLine",{"children":["$","a",null,{"href":"/devops/safeline/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["SafeLine"," (",1,")"]}]}],["$","li","Jenkins",{"children":["$","a",null,{"href":"/devops/jenkins/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Jenkins"," (",3,")"]}]}],["$","li","GitHub Actions",{"children":["$","a",null,{"href":"/devops/github-actions/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["GitHub Actions"," (",1,")"]}]}],["$","li","AWS",{"children":["$","a",null,{"href":"/devops/aws/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["AWS"," (",1,")"]}]}]]}]]}],["$","div","etc",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"etc"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Me",{"children":["$","a",null,{"href":"/etc/me/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Me"," (",3,")"]}]}],["$","li","Chrome Extension",{"children":["$","a",null,{"href":"/etc/chrome-extension/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Chrome Extension"," (",1,")"]}]}]]}]]}]]}]}]}],["$","main",null,{"className":"flex-1","children":["$","article",null,{"className":"page","children":[["$","header",null,{"className":"mb-8","children":[["$","h1",null,{"className":"page__title","children":"[논문리뷰] EthicsMH: A Pilot Benchmark for Ethical Reasoning in Mental Health AI"}],["$","div",null,{"className":"page__meta","children":[["$","time",null,{"dateTime":"2025-09-16 13:16:41+0900","children":"2025년 9월 16일"}],["$","span",null,{"className":"ml-4","children":["수정: ","2025년 9월 16일"]}]]}]]}],["$","div",null,{"className":"page__content","children":["$","div",null,{"dangerouslySetInnerHTML":{"__html":"$9"}}]}],["$","footer",null,{"className":"page__meta mt-8","children":["$","div",null,{"className":"page__taxonomy","children":[["$","h4",null,{"className":"text-sm font-medium text-gray-900 mb-2","children":"태그"}],[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Ethical Reasoning",{"className":"page__taxonomy-item","children":["#","Ethical Reasoning"]}],["$","span","Mental Health AI",{"className":"page__taxonomy-item","children":["#","Mental Health AI"]}],["$","span","Benchmark Dataset",{"className":"page__taxonomy-item","children":["#","Benchmark Dataset"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","AI Ethics",{"className":"page__taxonomy-item","children":["#","AI Ethics"]}],["$","span","Clinical Decision Support",{"className":"page__taxonomy-item","children":["#","Clinical Decision Support"]}],["$","span","Human-in-the-loop",{"className":"page__taxonomy-item","children":["#","Human-in-the-loop"]}]]]}]}]]}]}]]}]
8:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"secrett2633's blog"}],["$","meta","3",{"name":"description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","meta","4",{"name":"author","content":"secrett2633"}],["$","meta","5",{"name":"keywords","content":"Django, Python, DevOps, AI, ML, 블로그, 기술"}],["$","meta","6",{"name":"creator","content":"secrett2633"}],["$","meta","7",{"name":"publisher","content":"secrett2633"}],["$","meta","8",{"name":"robots","content":"index, follow"}],["$","meta","9",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","10",{"rel":"canonical","href":"https://secrett2633.github.io/"}],["$","meta","11",{"name":"format-detection","content":"telephone=no, address=no, email=no"}],["$","meta","12",{"property":"og:title","content":"secrett2633's blog"}],["$","meta","13",{"property":"og:description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","meta","14",{"property":"og:url","content":"https://secrett2633.github.io/"}],["$","meta","15",{"property":"og:site_name","content":"secrett2633's blog"}],["$","meta","16",{"property":"og:locale","content":"ko_KR"}],["$","meta","17",{"property":"og:type","content":"website"}],["$","meta","18",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","19",{"name":"twitter:title","content":"secrett2633's blog"}],["$","meta","20",{"name":"twitter:description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","link","21",{"rel":"icon","href":"/icon.ico?6d9f34d4948640b8","type":"image/x-icon","sizes":"16x16"}]]
1:null
