3:I[9275,[],""]
5:I[1343,[],""]
6:I[9157,["231","static/chunks/231-467e37449c5a68fc.js","185","static/chunks/app/layout-b0a450f8e4964582.js"],"default"]
7:I[231,["231","static/chunks/231-467e37449c5a68fc.js","877","static/chunks/app/%5B...slug%5D/page-1f60377561abdb46.js"],""]
8:I[4080,["231","static/chunks/231-467e37449c5a68fc.js","185","static/chunks/app/layout-b0a450f8e4964582.js"],""]
4:["slug","ai/review/2025-12-12-Fed-SE-Federated-Self-Evolution-for-Privacy-Constrained-Multi-Environment-LLM-Agents","c"]
0:["WcxaIiCPz9cbpnkGvOjOK",[[["",{"children":[["slug","ai/review/2025-12-12-Fed-SE-Federated-Self-Evolution-for-Privacy-Constrained-Multi-Environment-LLM-Agents","c"],{"children":["__PAGE__?{\"slug\":[\"ai\",\"review\",\"2025-12-12-Fed-SE-Federated-Self-Evolution-for-Privacy-Constrained-Multi-Environment-LLM-Agents\"]}",{}]}]},"$undefined","$undefined",true],["",{"children":[["slug","ai/review/2025-12-12-Fed-SE-Federated-Self-Evolution-for-Privacy-Constrained-Multi-Environment-LLM-Agents","c"],{"children":["__PAGE__",{},[["$L1","$L2"],null],null]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","$4","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},[["$","html",null,{"lang":"ko","className":"no-js","children":[["$","head",null,{"children":[["$","meta",null,{"name":"msapplication-TileColor","content":"#ffc40d"}],["$","meta",null,{"name":"theme-color","content":"#ffffff"}],["$","link",null,{"rel":"dns-prefetch","href":"https://www.googletagmanager.com"}],["$","link",null,{"rel":"preconnect","href":"https://www.googletagmanager.com","crossOrigin":"anonymous"}],["$","link",null,{"rel":"dns-prefetch","href":"https://giscus.app"}],["$","link",null,{"rel":"preconnect","href":"https://giscus.app","crossOrigin":"anonymous"}],["$","meta",null,{"httpEquiv":"X-Content-Type-Options","content":"nosniff"}],["$","meta",null,{"name":"referrer","content":"strict-origin-when-cross-origin"}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"WebSite\",\"name\":\"secrett2633's blog\",\"url\":\"https://blog.secrett2633.cloud\",\"description\":\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\",\"inLanguage\":\"ko\",\"publisher\":{\"@type\":\"Person\",\"name\":\"secrett2633\",\"url\":\"https://blog.secrett2633.cloud\"}}"}}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"Person\",\"name\":\"secrett2633\",\"url\":\"https://blog.secrett2633.cloud\",\"sameAs\":[\"https://github.com/secrett2633\"]}"}}]]}],["$","body",null,{"className":"__className_f367f3 layout--default","children":[["$","a",null,{"href":"#main-content","className":"sr-only focus:not-sr-only focus:absolute focus:z-50 focus:p-4 focus:bg-white focus:text-blue-600","children":"본문으로 건너뛰기"}],["$","div",null,{"className":"min-h-screen bg-gray-50","children":[["$","$L6",null,{}],["$","main",null,{"id":"main-content","className":"initial-content","children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","div",null,{"className":"min-h-screen flex items-center justify-center bg-gray-50","children":["$","div",null,{"className":"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center","children":[["$","h1",null,{"className":"text-6xl font-bold text-primary-600 mb-4","children":"404"}],["$","h2",null,{"className":"text-2xl font-semibold text-gray-900 mb-4","children":"페이지를 찾을 수 없습니다"}],["$","p",null,{"className":"text-gray-600 mb-8","children":"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다."}],["$","$L7",null,{"href":"/","className":"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors","children":"홈으로 돌아가기"}]]}]}],"notFoundStyles":[],"styles":null}]}],["$","div",null,{"id":"footer","className":"page__footer","children":["$","footer",null,{"className":"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8","children":["$","div",null,{"className":"text-center text-gray-500 text-sm","children":["$","p",null,{"children":["© ",2026," secrett2633. All rights reserved."]}]}]}]}]]}],["$","$L8",null,{"src":"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY","strategy":"afterInteractive"}],["$","$L8",null,{"id":"gtag-init","strategy":"afterInteractive","children":"window.dataLayer = window.dataLayer || [];\n            function gtag(){dataLayer.push(arguments);}\n            gtag('js', new Date());\n            gtag('config', 'G-NE2W3CFPNY');"}]]}]]}],null],[["$","div",null,{"className":"flex items-center justify-center min-h-screen","role":"status","aria-label":"로딩 중","children":[["$","div",null,{"className":"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600"}],["$","span",null,{"className":"sr-only","children":"로딩 중..."}]]}],[],[]]],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/ddc331716d5e47a2.css","precedence":"next","crossOrigin":"$undefined"}]],[null,"$L9"]]]]]
c:I[646,["231","static/chunks/231-467e37449c5a68fc.js","877","static/chunks/app/%5B...slug%5D/page-1f60377561abdb46.js"],"default"]
a:T500,{"@context":"https://schema.org","@type":"BlogPosting","headline":"[논문리뷰] Fed-SE: Federated Self-Evolution for Privacy-Constrained Multi-Environment LLM Agents","description":"Xiaodong Gu이 [arXiv]에 게시한 'Fed-SE: Federated Self-Evolution for Privacy-Constrained Multi-Environment LLM Agents' 논문에 대한 자세한 리뷰입니다.","url":"https://blog.secrett2633.cloud/ai/review/2025-12-12-Fed-SE-Federated-Self-Evolution-for-Privacy-Constrained-Multi-Environment-LLM-Agents","datePublished":"2025-12-11T15:00:00.000Z","dateModified":"2025-12-11T15:00:00.000Z","author":{"@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud"},"publisher":{"@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.secrett2633.cloud/ai/review/2025-12-12-Fed-SE-Federated-Self-Evolution-for-Privacy-Constrained-Multi-Environment-LLM-Agents"},"image":"https://blog.secrett2633.cloud/og-default.png","isAccessibleForFree":true,"inLanguage":"ko","wordCount":274,"articleSection":"Review","keywords":"Review, Federated Learning (FL), LLM Agents, Self-Evolution, Privacy-Preserving, Multi-Environment, Parameter-Efficient Fine-Tuning, Low-Rank Aggregation, Reinforcement Learning"}b:Te31,<blockquote>
<p><strong>링크:</strong> <a href="https://arxiv.org/abs/2512.08870" target="_blank" rel="noopener noreferrer">논문 PDF로 바로 열기</a></p>
</blockquote>
<p><strong>저자:</strong> Xiang Chen, Yuling Shi, Qizhen Lan, Yuchao Qiu, Xiaodong Gu</p>
<h2 id="핵심-연구-목표"><a href="#핵심-연구-목표">핵심 연구 목표</a></h2>
<p>본 논문은 복잡한 인터랙티브 태스크에서 LLM 에이전트가 직면하는 프라이버시 제약으로 인해 중앙 집중식 최적화 및 동적 환경 간 공동 진화가 어려운 문제를 해결하고자 합니다. 특히 이질적인 태스크, 희소한 보상, 그리고 그래디언트 충돌로 인해 발생하는 기존의 연합 학습(FL) 적용의 불안정성을 극복하고, 프라이버시가 보장되는 환경에서 에이전트의 견고한 교차 환경 지식 전달을 가능하게 하는 것을 목표로 합니다.</p>
<h2 id="핵심-방법론"><a href="#핵심-방법론">핵심 방법론</a></h2>
<p>제안하는 <strong>Fed-SE</strong> 프레임워크는 로컬 에이전트의 자기 진화와 경량 어댑터의 글로벌 집계 패러다임을 결합합니다. 로컬에서는 에이전트가 <strong>필터링된 고수익 궤적(successful trajectories)</strong> 에 대해 <strong>매개변수 효율적인 미세 조정(PEFT)</strong> 을 수행하여 그래디언트 업데이트의 안정성을 확보하며, 경험 리플레이를 통해 분포 변화와 파국적 망각을 완화합니다. 글로벌 서버는 <strong>낮은 랭크 서브스페이스</strong> 내에서 <strong>로컬 어댑터 업데이트(LoRA matrices)</strong> 를 집계하여 환경별 역학을 분리하고 부정적인 전이를 줄이며, 주기적인 <strong>글로벌 매개변수 동기화</strong> 를 통해 클라이언트 드리프트를 방지합니다.</p>
<h2 id="주요-결과"><a href="#주요-결과">주요 결과</a></h2>
<p>Fed-SE는 연합 학습 기준선 대비 <strong>평균 태스크 성공률을 약 18%</strong> 향상시켜 <strong>0.66</strong> 을 달성했으며, 이는 FedAvg(0.56), Local(0.53), Centralized(0.49)보다 우수한 성능입니다. 특히 <strong>BabyAI(0.92)</strong> 및 <strong>Maze(0.80)</strong> 와 같은 추론 중심 태스크에서 상당한 이점을 보였습니다. 어블레이션 연구를 통해 <strong>성공 궤적 필터링</strong> 이 <strong>40.5%</strong> 의 성능 하락을 방지하는 데 결정적임이 확인되었으며, <strong>누적된 과거 경험(experience replay)</strong> 이 <strong>Maze 태스크</strong> 에서 성능을 <strong>40.0%</strong> 에서 <strong>80.0%</strong> 로 끌어올리는 데 필수적임이 입증되었습니다.</p>
<h2 id="ai-실무자를-위한-시사점"><a href="#ai-실무자를-위한-시사점">AI 실무자를 위한 시사점</a></h2>
<p>Fed-SE는 원본 데이터 공유가 제한된 실제 환경에서 <strong>확장 가능하고 프라이버시를 보장하는 에이전트 학습</strong> 을 위한 실용적인 패러다임을 제시합니다. <strong>매개변수 효율적인 미세 조정(PEFT)</strong> 및 <strong>저랭크 집계</strong> 사용은 엣지 환경 배포에 필수적인 통신 효율성을 높입니다. 특히 <strong>성공 궤적 필터링</strong> 과 <strong>경험 리플레이</strong> 의 중요성은 희소한 보상 환경에서 더욱 견고하고 안정적인 연합 강화 학습 시스템을 설계하는 데 중요한 통찰력을 제공합니다.</p>
<blockquote>
<p>⚠️ <strong>알림:</strong> 이 리뷰는 AI로 작성되었습니다.</p>
</blockquote>
2:[["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"$a"}}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"BreadcrumbList\",\"itemListElement\":[{\"@type\":\"ListItem\",\"position\":1,\"name\":\"홈\",\"item\":\"https://blog.secrett2633.cloud/\"},{\"@type\":\"ListItem\",\"position\":2,\"name\":\"Review\",\"item\":\"https://blog.secrett2633.cloud/ai/review\"},{\"@type\":\"ListItem\",\"position\":3,\"name\":\"[논문리뷰] Fed-SE: Federated Self-Evolution for Privacy-Constrained Multi-Environment LLM Agents\",\"item\":\"https://blog.secrett2633.cloud/ai/review/2025-12-12-Fed-SE-Federated-Self-Evolution-for-Privacy-Constrained-Multi-Environment-LLM-Agents\"}]}"}}],["$","div",null,{"className":"flex flex-col lg:flex-row gap-8","children":[["$","aside",null,{"className":"lg:w-64 xl:w-72 order-1 lg:order-none","children":["$","div",null,{"className":"sidebar sticky","children":["$","nav",null,{"className":"space-y-4","aria-label":"카테고리 네비게이션","children":[["$","div","Backend",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"Backend"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Django",{"children":["$","$L7",null,{"href":"/backend/django","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Django"," (",6,")"]}]}],["$","li","Logging",{"children":["$","$L7",null,{"href":"/backend/logging","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Logging"," (",1,")"]}]}]]}]]}],["$","div","Python",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"Python"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","PEP",{"children":["$","$L7",null,{"href":"/python/pep","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["PEP"," (",650,")"]}]}]]}]]}],["$","div","AI/ML",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"AI/ML"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","LLM",{"children":["$","$L7",null,{"href":"/ai/llm","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["LLM"," (",1,")"]}]}],["$","li","Review",{"children":["$","$L7",null,{"href":"/ai/review","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Review"," (",2728,")"]}]}]]}]]}],["$","div","DevOps",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"DevOps"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Nginx",{"children":["$","$L7",null,{"href":"/devops/nginx","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Nginx"," (",1,")"]}]}],["$","li","Docker",{"children":["$","$L7",null,{"href":"/devops/docker","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Docker"," (",1,")"]}]}],["$","li","SafeLine",{"children":["$","$L7",null,{"href":"/devops/safeline","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["SafeLine"," (",1,")"]}]}],["$","li","Jenkins",{"children":["$","$L7",null,{"href":"/devops/jenkins","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Jenkins"," (",3,")"]}]}],["$","li","GitHub Actions",{"children":["$","$L7",null,{"href":"/devops/github-actions","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["GitHub Actions"," (",1,")"]}]}],["$","li","AWS",{"children":["$","$L7",null,{"href":"/devops/aws","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["AWS"," (",1,")"]}]}]]}]]}],["$","div","etc",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"etc"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Me",{"children":["$","$L7",null,{"href":"/etc/me","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Me"," (",3,")"]}]}],["$","li","Chrome Extension",{"children":["$","$L7",null,{"href":"/etc/chrome-extension","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Chrome Extension"," (",1,")"]}]}]]}]]}]]}]}]}],["$","div",null,{"className":"flex-1","children":[["$","nav",null,{"aria-label":"breadcrumb","className":"text-sm text-gray-500 mb-4","children":["$","ol",null,{"className":"flex flex-wrap items-center gap-1","children":[["$","li",null,{"children":["$","$L7",null,{"href":"/","className":"hover:text-gray-700","children":"홈"}]}],[["$","li","/ai/review",{"className":"flex items-center gap-1","children":[["$","span",null,{"aria-hidden":"true","children":"/"}],["$","$L7",null,{"href":"/ai/review","className":"hover:text-gray-700","children":"Review"}]]}],["$","li","/ai/review/2025-12-12-Fed-SE-Federated-Self-Evolution-for-Privacy-Constrained-Multi-Environment-LLM-Agents",{"className":"flex items-center gap-1","children":[["$","span",null,{"aria-hidden":"true","children":"/"}],["$","span",null,{"className":"text-gray-900","aria-current":"page","children":"[논문리뷰] Fed-SE: Federated Self-Evolution for Privacy-Constrained Multi-Environment LLM Agents"}]]}]]]}]}],["$","article",null,{"className":"page","children":[["$","header",null,{"className":"mb-8","children":[["$","h1",null,{"className":"page__title","children":"[논문리뷰] Fed-SE: Federated Self-Evolution for Privacy-Constrained Multi-Environment LLM Agents"}],["$","div",null,{"className":"page__meta","children":[["$","time",null,{"dateTime":"2025-12-12 00:00:00+0900+0900","children":"2025년 12월 12일"}],["$","time",null,{"className":"ml-4","dateTime":"2025-12-11T15:00:00.000Z","children":["수정: ","2025년 12월 12일"]}]]}]]}],["$","div",null,{"className":"page__content","children":["$","div",null,{"dangerouslySetInnerHTML":{"__html":"$b"}}]}],["$","footer",null,{"className":"page__meta mt-8","children":["$","div",null,{"className":"page__taxonomy","children":[["$","span",null,{"className":"text-sm font-medium text-gray-900 mb-2 block","children":"태그"}],[["$","$L7","Review",{"href":"/tags/Review","className":"page__taxonomy-item","children":["#","Review"]}],["$","$L7","Federated Learning (FL)",{"href":"/tags/Federated%20Learning%20(FL)","className":"page__taxonomy-item","children":["#","Federated Learning (FL)"]}],["$","$L7","LLM Agents",{"href":"/tags/LLM%20Agents","className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","$L7","Self-Evolution",{"href":"/tags/Self-Evolution","className":"page__taxonomy-item","children":["#","Self-Evolution"]}],["$","$L7","Privacy-Preserving",{"href":"/tags/Privacy-Preserving","className":"page__taxonomy-item","children":["#","Privacy-Preserving"]}],["$","$L7","Multi-Environment",{"href":"/tags/Multi-Environment","className":"page__taxonomy-item","children":["#","Multi-Environment"]}],["$","$L7","Parameter-Efficient Fine-Tuning",{"href":"/tags/Parameter-Efficient%20Fine-Tuning","className":"page__taxonomy-item","children":["#","Parameter-Efficient Fine-Tuning"]}],["$","$L7","Low-Rank Aggregation",{"href":"/tags/Low-Rank%20Aggregation","className":"page__taxonomy-item","children":["#","Low-Rank Aggregation"]}],["$","$L7","Reinforcement Learning",{"href":"/tags/Reinforcement%20Learning","className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}]]]}]}],["$","$Lc",null,{"postPermalink":"/ai/review/2025-12-12-Fed-SE-Federated-Self-Evolution-for-Privacy-Constrained-Multi-Environment-LLM-Agents","postId":"2025-12-12-Fed-SE-Federated-Self-Evolution-for-Privacy-Constrained-Multi-Environment-LLM-Agents"}],["$","section",null,{"className":"mt-12 border-t border-gray-200 pt-8","children":[["$","h3",null,{"className":"text-base font-semibold text-gray-900 mb-4","children":["Review"," 의 다른글"]}],["$","ul",null,{"className":"space-y-2 text-sm","children":[["$","li",null,{"className":"text-gray-500","children":["이전글"," ",["$","$L7",null,{"href":"/ai/review/2025-12-12-Evaluating-Gemini-Robotics-Policies-in-a-Veo-World-Simulator","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] Evaluating Gemini Robotics Policies in a Veo World Simulator"}]]}],["$","li",null,{"className":"text-gray-900 font-semibold","children":["현재글 : ","[논문리뷰] Fed-SE: Federated Self-Evolution for Privacy-Constrained Multi-Environment LLM Agents"]}],["$","li",null,{"className":"text-gray-500","children":["다음글"," ",["$","$L7",null,{"href":"/ai/review/2025-12-12-From-Macro-to-Micro-Benchmarking-Microscopic-Spatial-Intelligence-on-Molecules-via-Vision-Language-Models","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] From Macro to Micro: Benchmarking Microscopic Spatial Intelligence on Molecules via Vision-Language Models"}]]}]]}]]}]]}]]}]]}]]
9:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"[논문리뷰] Fed-SE: Federated Self-Evolution for Privacy-Constrained Multi-Environment LLM Agents - secrett2633's blog"}],["$","meta","3",{"name":"description","content":"Xiaodong Gu이 [arXiv]에 게시한 'Fed-SE: Federated Self-Evolution for Privacy-Constrained Multi-Environment LLM Agents' 논문에 대한 자세한 리뷰입니다."}],["$","meta","4",{"name":"author","content":"secrett2633"}],["$","link","5",{"rel":"manifest","href":"/manifest.json","crossOrigin":"use-credentials"}],["$","meta","6",{"name":"keywords","content":"Django, Python, DevOps, AI, ML, 블로그, 기술"}],["$","meta","7",{"name":"creator","content":"secrett2633"}],["$","meta","8",{"name":"publisher","content":"secrett2633"}],["$","meta","9",{"name":"robots","content":"index, follow"}],["$","meta","10",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","11",{"rel":"canonical","href":"https://blog.secrett2633.cloud/ai/review/2025-12-12-Fed-SE-Federated-Self-Evolution-for-Privacy-Constrained-Multi-Environment-LLM-Agents"}],["$","meta","12",{"name":"format-detection","content":"telephone=no, address=no, email=no"}],["$","meta","13",{"property":"og:title","content":"[논문리뷰] Fed-SE: Federated Self-Evolution for Privacy-Constrained Multi-Environment LLM Agents"}],["$","meta","14",{"property":"og:description","content":"Xiaodong Gu이 [arXiv]에 게시한 'Fed-SE: Federated Self-Evolution for Privacy-Constrained Multi-Environment LLM Agents' 논문에 대한 자세한 리뷰입니다."}],["$","meta","15",{"property":"og:url","content":"https://blog.secrett2633.cloud/ai/review/2025-12-12-Fed-SE-Federated-Self-Evolution-for-Privacy-Constrained-Multi-Environment-LLM-Agents"}],["$","meta","16",{"property":"og:type","content":"article"}],["$","meta","17",{"property":"article:published_time","content":"2025-12-11T15:00:00.000Z"}],["$","meta","18",{"property":"article:modified_time","content":"2025-12-11T15:00:00.000Z"}],["$","meta","19",{"property":"article:author","content":"secrett2633"}],["$","meta","20",{"property":"article:section","content":"Review"}],["$","meta","21",{"property":"article:tag","content":"Review"}],["$","meta","22",{"property":"article:tag","content":"Federated Learning (FL)"}],["$","meta","23",{"property":"article:tag","content":"LLM Agents"}],["$","meta","24",{"property":"article:tag","content":"Self-Evolution"}],["$","meta","25",{"property":"article:tag","content":"Privacy-Preserving"}],["$","meta","26",{"property":"article:tag","content":"Multi-Environment"}],["$","meta","27",{"property":"article:tag","content":"Parameter-Efficient Fine-Tuning"}],["$","meta","28",{"property":"article:tag","content":"Low-Rank Aggregation"}],["$","meta","29",{"property":"article:tag","content":"Reinforcement Learning"}],["$","meta","30",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","31",{"name":"twitter:creator","content":"@secrett2633"}],["$","meta","32",{"name":"twitter:title","content":"[논문리뷰] Fed-SE: Federated Self-Evolution for Privacy-Constrained Multi-Environment LLM Agents"}],["$","meta","33",{"name":"twitter:description","content":"Xiaodong Gu이 [arXiv]에 게시한 'Fed-SE: Federated Self-Evolution for Privacy-Constrained Multi-Environment LLM Agents' 논문에 대한 자세한 리뷰입니다."}],["$","link","34",{"rel":"icon","href":"/icon.ico?6d9f34d4948640b8","type":"image/x-icon","sizes":"16x16"}],["$","meta","35",{"name":"next-size-adjust"}]]
1:null
