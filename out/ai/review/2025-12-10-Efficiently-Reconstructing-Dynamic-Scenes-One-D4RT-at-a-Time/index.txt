3:I[9275,[],""]
5:I[1343,[],""]
6:I[9157,["231","static/chunks/231-c27e618569e042bc.js","157","static/chunks/157-ad5f81b531af48c1.js","185","static/chunks/app/layout-c3e2e457f12fb6f6.js"],"default"]
7:I[231,["231","static/chunks/231-c27e618569e042bc.js","931","static/chunks/app/page-51594f997fc19690.js"],""]
4:["slug","ai/review/2025-12-10-Efficiently-Reconstructing-Dynamic-Scenes-One-D4RT-at-a-Time","c"]
0:["ogGio3genoY6eym-8SYbg",[[["",{"children":[["slug","ai/review/2025-12-10-Efficiently-Reconstructing-Dynamic-Scenes-One-D4RT-at-a-Time","c"],{"children":["__PAGE__?{\"slug\":[\"ai\",\"review\",\"2025-12-10-Efficiently-Reconstructing-Dynamic-Scenes-One-D4RT-at-a-Time\"]}",{}]}]},"$undefined","$undefined",true],["",{"children":[["slug","ai/review/2025-12-10-Efficiently-Reconstructing-Dynamic-Scenes-One-D4RT-at-a-Time","c"],{"children":["__PAGE__",{},[["$L1","$L2"],null],null]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","$4","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},[["$","html",null,{"lang":"ko","className":"no-js","children":[["$","head",null,{"children":[["$","meta",null,{"name":"msapplication-TileColor","content":"#ffc40d"}],["$","meta",null,{"name":"theme-color","content":"#ffffff"}],["$","script",null,{"async":true,"src":"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY"}],["$","script",null,{"dangerouslySetInnerHTML":{"__html":"\n              window.dataLayer = window.dataLayer || [];\n              function gtag(){dataLayer.push(arguments);}\n              gtag('js', new Date());\n              gtag('config', 'G-NE2W3CFPNY');\n            "}}]]}],["$","body",null,{"className":"__className_f367f3 layout--default","children":["$","div",null,{"className":"min-h-screen bg-gray-50","children":[["$","$L6",null,{}],["$","main",null,{"className":"initial-content","children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","div",null,{"className":"min-h-screen flex items-center justify-center bg-gray-50","children":["$","div",null,{"className":"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center","children":[["$","h1",null,{"className":"text-6xl font-bold text-primary-600 mb-4","children":"404"}],["$","h2",null,{"className":"text-2xl font-semibold text-gray-900 mb-4","children":"페이지를 찾을 수 없습니다"}],["$","p",null,{"className":"text-gray-600 mb-8","children":"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다."}],["$","$L7",null,{"href":"/","className":"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors","children":"홈으로 돌아가기"}]]}]}],"notFoundStyles":[],"styles":null}]}],["$","div",null,{"id":"footer","className":"page__footer","children":["$","footer",null,{"className":"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8","children":["$","div",null,{"className":"text-center text-gray-500 text-sm","children":["$","p",null,{"children":"© 2025 secrett2633. All rights reserved."}]}]}]}]]}]}]]}],null],[["$","div",null,{"className":"flex items-center justify-center min-h-screen","children":["$","div",null,{"className":"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600"}]}],[],[]]],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/edf391eeca43d999.css","precedence":"next","crossOrigin":"$undefined"}]],[null,"$L8"]]]]]
9:Tb33,<blockquote>
<p><strong>링크:</strong> <a href="https://arxiv.org/abs/2512.08924">논문 PDF로 바로 열기</a></p>
</blockquote>
<p><strong>저자:</strong> Chuhan Zhang, Guillaume Le Moing, Skanda Koppula, Ignacio Rocco, Liliane Momeni, Junyu Xie, Shuyang Sun, Rahul Sukthankar, Joëlle K. Barral, Raia Hadsell, Zoubin Ghahramani, Andrew Zisserman, Junlin Zhang, Mehdi S. M. Sajjadi</p>
<h2>핵심 연구 목표</h2>
<p>논문은 복잡한 동적 장면의 기하학적 구조와 움직임을 비디오로부터 효율적으로 재구성하는 것을 목표로 합니다. 기존의 단편적이고 컴퓨팅 비용이 높은 3D 재구성 접근 방식의 한계를 극복하고, 단일의 통일된 모델로 깊이, 시공간 대응, 전체 카메라 파라미터 추론을 수행하는 <strong>4D 이해 프레임워크</strong> 를 제시하고자 합니다.</p>
<h2>핵심 방법론</h2>
<p>본 논문은 <strong>D4RT</strong> 라는 새로운 <strong>피드포워드 모델</strong> 을 제안합니다. 이 모델은 입력 비디오를 <strong>Global Scene Representation F</strong> 로 인코딩한 후, 경량의 디코더가 <strong>쿼리 메커니즘</strong> 을 통해 시공간상의 임의의 점에 대한 3D 위치를 독립적으로 예측합니다. 쿼리는 <strong>2D 좌표 (u, v)</strong> , <strong>소스/타겟 타임스텝 (tsrc, ttgt)</strong> , <strong>카메라 참조 타임스텝 (tcam)</strong> 및 <strong>로컬 RGB 패치 임베딩</strong> 을 포함하며, <strong>L1 손실</strong> 과 다양한 보조 손실을 사용하여 엔드투엔드로 훈련됩니다.</p>
<h2>주요 결과</h2>
<p><strong>D4RT</strong> 는 다양한 4D 재구성 태스크에서 새로운 최고 성능을 달성했습니다. 카메라 포즈 추정에서 <strong>200+ FPS</strong> 를 달성하여 <strong>VGGT보다 9배, MegaSaM보다 100배 빠르게</strong> 우수한 정확도를 제공합니다. 3D 트래킹 처리량에서는 다른 기존 방법들보다 <strong>18~300배 빠르며</strong> , Sintel 및 ScanNet 데이터셋에서 비디오 깊이 및 포인트 맵 추정에서도 최고 수준의 성능을 보였습니다.</p>
<h2>AI 실무자를 위한 시사점</h2>
<p><strong>D4RT</strong> 는 동적 4D 장면 재구성을 위한 효율적이고 확장 가능한 단일 통합 솔루션을 제공합니다. <strong>쿼리 기반 추론</strong> 방식은 특정 3D 정보를 필요로 하는 애플리케이션에서 유연한 온디맨드 데이터 추출을 가능하게 하여, 불필요한 전체 프레임 디코딩을 피하고 <strong>계산 비용을 크게 절감</strong> 할 수 있습니다. 이는 실시간 또는 대규모 비디오 처리 시스템 구현에 매우 유용할 수 있습니다.</p>
<blockquote>
<p>⚠️ <strong>알림:</strong> 이 리뷰는 AI로 작성되었습니다.</p>
</blockquote>
2:["$","div",null,{"className":"flex flex-col lg:flex-row gap-8","children":[["$","aside",null,{"className":"lg:w-64 xl:w-72 order-1 lg:order-none","children":["$","div",null,{"className":"sidebar sticky","children":["$","nav",null,{"className":"space-y-4","children":[["$","div","Backend",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"Backend"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Django",{"children":["$","a",null,{"href":"/backend/django/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Django"," (",6,")"]}]}],["$","li","Logging",{"children":["$","a",null,{"href":"/backend/logging/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Logging"," (",1,")"]}]}]]}]]}],["$","div","Python",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"Python"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","PEP",{"children":["$","a",null,{"href":"/python/pep/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["PEP"," (",650,")"]}]}]]}]]}],["$","div","AI/ML",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"AI/ML"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","LLM",{"children":["$","a",null,{"href":"/ai/llm/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["LLM"," (",1,")"]}]}],["$","li","Review",{"children":["$","a",null,{"href":"/ai/review/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Review"," (",1962,")"]}]}]]}]]}],["$","div","DevOps",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"DevOps"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Nginx",{"children":["$","a",null,{"href":"/devops/nginx/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Nginx"," (",1,")"]}]}],["$","li","Docker",{"children":["$","a",null,{"href":"/devops/docker/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Docker"," (",1,")"]}]}],["$","li","SafeLine",{"children":["$","a",null,{"href":"/devops/safeline/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["SafeLine"," (",1,")"]}]}],["$","li","Jenkins",{"children":["$","a",null,{"href":"/devops/jenkins/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Jenkins"," (",3,")"]}]}],["$","li","GitHub Actions",{"children":["$","a",null,{"href":"/devops/github-actions/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["GitHub Actions"," (",1,")"]}]}],["$","li","AWS",{"children":["$","a",null,{"href":"/devops/aws/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["AWS"," (",1,")"]}]}]]}]]}],["$","div","etc",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"etc"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Me",{"children":["$","a",null,{"href":"/etc/me/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Me"," (",3,")"]}]}],["$","li","Chrome Extension",{"children":["$","a",null,{"href":"/etc/chrome-extension/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Chrome Extension"," (",1,")"]}]}]]}]]}]]}]}]}],["$","main",null,{"className":"flex-1","children":["$","article",null,{"className":"page","children":[["$","header",null,{"className":"mb-8","children":[["$","h1",null,{"className":"page__title","children":"[논문리뷰] Efficiently Reconstructing Dynamic Scenes One D4RT at a Time"}],["$","div",null,{"className":"page__meta","children":[["$","time",null,{"dateTime":"2025-12-10 00:00:00+0900+0900","children":"2025년 12월 10일"}],["$","span",null,{"className":"ml-4","children":["수정: ","2025년 12월 10일"]}]]}]]}],["$","div",null,{"className":"page__content","children":["$","div",null,{"dangerouslySetInnerHTML":{"__html":"$9"}}]}],["$","footer",null,{"className":"page__meta mt-8","children":["$","div",null,{"className":"page__taxonomy","children":[["$","h4",null,{"className":"text-sm font-medium text-gray-900 mb-2","children":"태그"}],[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Dynamic Scene Reconstruction",{"className":"page__taxonomy-item","children":["#","Dynamic Scene Reconstruction"]}],["$","span","4D Reconstruction",{"className":"page__taxonomy-item","children":["#","4D Reconstruction"]}],["$","span","Point Tracking",{"className":"page__taxonomy-item","children":["#","Point Tracking"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Feedforward Model",{"className":"page__taxonomy-item","children":["#","Feedforward Model"]}],["$","span","Query-based Inference",{"className":"page__taxonomy-item","children":["#","Query-based Inference"]}],["$","span","Computer Vision",{"className":"page__taxonomy-item","children":["#","Computer Vision"]}],["$","span","Geometric Consistency",{"className":"page__taxonomy-item","children":["#","Geometric Consistency"]}]]]}]}],["$","section",null,{"className":"mt-12 border-t border-gray-200 pt-8","children":[["$","h3",null,{"className":"text-base font-semibold text-gray-900 mb-4","children":["Review"," 의 다른글"]}],["$","ul",null,{"className":"space-y-2 text-sm","children":[["$","li",null,{"className":"text-gray-500","children":["이전글"," ",["$","$L7",null,{"href":"/ai/review/2025-12-10-EcomBench-Towards-Holistic-Evaluation-of-Foundation-Agents-in-E-commerce/","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] EcomBench: Towards Holistic Evaluation of Foundation Agents in E-commerce"}]]}],["$","li",null,{"className":"text-gray-900 font-semibold","children":["현재글 : ","[논문리뷰] Efficiently Reconstructing Dynamic Scenes One D4RT at a Time"]}],["$","li",null,{"className":"text-gray-500","children":["다음글"," ",["$","$L7",null,{"href":"/ai/review/2025-12-10-From-Next-Token-to-Next-Block-A-Principled-Adaptation-Path-for-Diffusion-LLMs/","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] From Next-Token to Next-Block: A Principled Adaptation Path for Diffusion LLMs"}]]}]]}]]}]]}]}]]}]
8:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"secrett2633's blog"}],["$","meta","3",{"name":"description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","meta","4",{"name":"author","content":"secrett2633"}],["$","meta","5",{"name":"keywords","content":"Django, Python, DevOps, AI, ML, 블로그, 기술"}],["$","meta","6",{"name":"creator","content":"secrett2633"}],["$","meta","7",{"name":"publisher","content":"secrett2633"}],["$","meta","8",{"name":"robots","content":"index, follow"}],["$","meta","9",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","10",{"rel":"canonical","href":"https://blog.secrett2633.site/"}],["$","meta","11",{"name":"format-detection","content":"telephone=no, address=no, email=no"}],["$","meta","12",{"property":"og:title","content":"secrett2633's blog"}],["$","meta","13",{"property":"og:description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","meta","14",{"property":"og:url","content":"https://blog.secrett2633.site/"}],["$","meta","15",{"property":"og:site_name","content":"secrett2633's blog"}],["$","meta","16",{"property":"og:locale","content":"ko_KR"}],["$","meta","17",{"property":"og:type","content":"website"}],["$","meta","18",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","19",{"name":"twitter:title","content":"secrett2633's blog"}],["$","meta","20",{"name":"twitter:description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","link","21",{"rel":"icon","href":"/icon.ico?6d9f34d4948640b8","type":"image/x-icon","sizes":"16x16"}]]
1:null
