3:I[9275,[],""]
5:I[1343,[],""]
6:I[9157,["231","static/chunks/231-467e37449c5a68fc.js","185","static/chunks/app/layout-53ec9cbf619543e1.js"],"default"]
7:I[231,["231","static/chunks/231-467e37449c5a68fc.js","877","static/chunks/app/%5B...slug%5D/page-80e07cee06d17a0b.js"],""]
4:["slug","ai/review/2025-12-30-Coupling-Experts-and-Routers-in-Mixture-of-Experts-via-an-Auxiliary-Loss","c"]
0:["_3-KrKKQh7tcSoXiYwQMB",[[["",{"children":[["slug","ai/review/2025-12-30-Coupling-Experts-and-Routers-in-Mixture-of-Experts-via-an-Auxiliary-Loss","c"],{"children":["__PAGE__?{\"slug\":[\"ai\",\"review\",\"2025-12-30-Coupling-Experts-and-Routers-in-Mixture-of-Experts-via-an-Auxiliary-Loss\"]}",{}]}]},"$undefined","$undefined",true],["",{"children":[["slug","ai/review/2025-12-30-Coupling-Experts-and-Routers-in-Mixture-of-Experts-via-an-Auxiliary-Loss","c"],{"children":["__PAGE__",{},[["$L1","$L2"],null],null]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","$4","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},[["$","html",null,{"lang":"ko","className":"no-js","children":[["$","head",null,{"children":[["$","meta",null,{"name":"msapplication-TileColor","content":"#ffc40d"}],["$","meta",null,{"name":"theme-color","content":"#ffffff"}],["$","script",null,{"async":true,"src":"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY"}],["$","script",null,{"dangerouslySetInnerHTML":{"__html":"\n              window.dataLayer = window.dataLayer || [];\n              function gtag(){dataLayer.push(arguments);}\n              gtag('js', new Date());\n              gtag('config', 'G-NE2W3CFPNY');\n            "}}]]}],["$","body",null,{"className":"__className_f367f3 layout--default","children":["$","div",null,{"className":"min-h-screen bg-gray-50","children":[["$","$L6",null,{}],["$","main",null,{"className":"initial-content","children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","div",null,{"className":"min-h-screen flex items-center justify-center bg-gray-50","children":["$","div",null,{"className":"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center","children":[["$","h1",null,{"className":"text-6xl font-bold text-primary-600 mb-4","children":"404"}],["$","h2",null,{"className":"text-2xl font-semibold text-gray-900 mb-4","children":"페이지를 찾을 수 없습니다"}],["$","p",null,{"className":"text-gray-600 mb-8","children":"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다."}],["$","$L7",null,{"href":"/","className":"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors","children":"홈으로 돌아가기"}]]}]}],"notFoundStyles":[],"styles":null}]}],["$","div",null,{"id":"footer","className":"page__footer","children":["$","footer",null,{"className":"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8","children":["$","div",null,{"className":"text-center text-gray-500 text-sm","children":["$","p",null,{"children":"© 2025 secrett2633. All rights reserved."}]}]}]}]]}]}]]}],null],[["$","div",null,{"className":"flex items-center justify-center min-h-screen","children":["$","div",null,{"className":"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600"}]}],[],[]]],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/d6cea809dcbae606.css","precedence":"next","crossOrigin":"$undefined"}]],[null,"$L8"]]]]]
a:I[646,["231","static/chunks/231-467e37449c5a68fc.js","877","static/chunks/app/%5B...slug%5D/page-80e07cee06d17a0b.js"],"default"]
9:Taf4,<blockquote>
<p><strong>링크:</strong> <a href="https://arxiv.org/abs/2512.23447">논문 PDF로 바로 열기</a></p>
</blockquote>
<p><strong>저자:</strong> Ang Lv, Jin Ma, Yiyuan Ma, Siyuan Qiao</p>
<h2>핵심 연구 목표</h2>
<p>본 논문은 Mixture-of-Experts (MoE) 모델에서 라우터의 결정이 개별 전문가의 실제 역량과 충분히 연동되지 않아 발생하는 성능 한계를 해결하고자 합니다. 라우터와 전문가 간의 약한 결합 문제를 개선하여 모델 성능을 향상시키는 동시에 효율성을 유지하는 가벼운 보조 손실 함수를 제안하는 것이 목표입니다.</p>
<h2>핵심 방법론</h2>
<p>제안하는 <strong>Expert-Router Coupling (ERC) loss</strong> 는 라우터 임베딩을 토큰의 프록시로 활용하여 모든 전문가에 입력한 후, 중간 활성화의 L2 노름으로 구성된 행렬 <strong>M</strong> 을 생성합니다. 이 손실은 두 가지 핵심 제약 조건을 적용합니다: (1) 각 전문가가 자신의 프록시 토큰에 대해 다른 전문가보다 높은 활성화를 보여야 하며, (2) 각 프록시 토큰이 해당 전문가로부터 더 강한 활성화를 유발해야 합니다. 이 과정에서 <strong>유니폼 노이즈(δ_i)</strong> 를 라우터 임베딩에 추가하여 일반화 성능을 높이고, 스칼라 하이퍼파라미터 <strong>α</strong> 로 결합 강도를 조절합니다.</p>
<h2>주요 결과</h2>
<p>ERC 손실을 적용한 MoE-LLM은 <strong>3B에서 15B</strong> 파라미터 모델 전반에서 <strong>상당하고 안정적인 성능 향상</strong> 을 달성했습니다. 특히, <strong>15B 모델</strong> 에서는 <strong>MMLU, C-Eval, GSM8K</strong> 와 같은 벤치마크에서 기준 MoE 모델 대비 성능을 개선했으며, <strong>AoE (Autonomy-of-Experts) 모델</strong> 과의 성능 격차를 줄였습니다. ERC 손실은 <strong>0.2-0.8%</strong> 의 <strong>매우 낮은 추가 훈련 오버헤드</strong> 를 유지하고 추론 시에는 오버헤드가 전혀 없습니다.</p>
<h2>AI 실무자를 위한 시사점</h2>
<p>ERC 손실은 MoE 모델의 성능과 훈련 안정성을 향상시키는 효과적인 방법론으로, 특히 <strong>대규모 LLM</strong> 훈련 시 라우터와 전문가 간의 비효율적인 상호작용 문제를 해결하는 데 기여합니다. 또한, <strong>하이퍼파라미터 α</strong> 와 <strong>노이즈 수준 ε</strong> 를 통해 전문가 전문화 정도를 정량적으로 추적하고 제어할 수 있어, MoE 모델의 내부 동작을 이해하고 최적의 모델 설계를 탐색하는 데 유용한 도구를 제공합니다.</p>
<blockquote>
<p>⚠️ <strong>알림:</strong> 이 리뷰는 AI로 작성되었습니다.</p>
</blockquote>
2:["$","div",null,{"className":"flex flex-col lg:flex-row gap-8","children":[["$","aside",null,{"className":"lg:w-64 xl:w-72 order-1 lg:order-none","children":["$","div",null,{"className":"sidebar sticky","children":["$","nav",null,{"className":"space-y-4","children":[["$","div","Backend",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"Backend"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Django",{"children":["$","a",null,{"href":"/backend/django","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Django"," (",6,")"]}]}],["$","li","Logging",{"children":["$","a",null,{"href":"/backend/logging","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Logging"," (",1,")"]}]}]]}]]}],["$","div","Python",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"Python"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","PEP",{"children":["$","a",null,{"href":"/python/pep","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["PEP"," (",650,")"]}]}]]}]]}],["$","div","AI/ML",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"AI/ML"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","LLM",{"children":["$","a",null,{"href":"/ai/llm","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["LLM"," (",1,")"]}]}],["$","li","Review",{"children":["$","a",null,{"href":"/ai/review","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Review"," (",2728,")"]}]}]]}]]}],["$","div","DevOps",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"DevOps"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Nginx",{"children":["$","a",null,{"href":"/devops/nginx","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Nginx"," (",1,")"]}]}],["$","li","Docker",{"children":["$","a",null,{"href":"/devops/docker","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Docker"," (",1,")"]}]}],["$","li","SafeLine",{"children":["$","a",null,{"href":"/devops/safeline","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["SafeLine"," (",1,")"]}]}],["$","li","Jenkins",{"children":["$","a",null,{"href":"/devops/jenkins","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Jenkins"," (",3,")"]}]}],["$","li","GitHub Actions",{"children":["$","a",null,{"href":"/devops/github-actions","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["GitHub Actions"," (",1,")"]}]}],["$","li","AWS",{"children":["$","a",null,{"href":"/devops/aws","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["AWS"," (",1,")"]}]}]]}]]}],["$","div","etc",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"etc"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Me",{"children":["$","a",null,{"href":"/etc/me","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Me"," (",3,")"]}]}],["$","li","Chrome Extension",{"children":["$","a",null,{"href":"/etc/chrome-extension","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Chrome Extension"," (",1,")"]}]}]]}]]}]]}]}]}],["$","main",null,{"className":"flex-1","children":["$","article",null,{"className":"page","children":[["$","header",null,{"className":"mb-8","children":[["$","h1",null,{"className":"page__title","children":"[논문리뷰] Coupling Experts and Routers in Mixture-of-Experts via an Auxiliary Loss"}],["$","div",null,{"className":"page__meta","children":[["$","time",null,{"dateTime":"2025-12-30 00:00:00+0900+0900","children":"2025년 12월 30일"}],["$","span",null,{"className":"ml-4","children":["수정: ","2025년 12월 30일"]}]]}]]}],["$","div",null,{"className":"page__content","children":["$","div",null,{"dangerouslySetInnerHTML":{"__html":"$9"}}]}],["$","footer",null,{"className":"page__meta mt-8","children":["$","div",null,{"className":"page__taxonomy","children":[["$","h4",null,{"className":"text-sm font-medium text-gray-900 mb-2","children":"태그"}],[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Mixture-of-Experts (MoE)",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts (MoE)"]}],["$","span","Router-Expert Coupling",{"className":"page__taxonomy-item","children":["#","Router-Expert Coupling"]}],["$","span","Auxiliary Loss",{"className":"page__taxonomy-item","children":["#","Auxiliary Loss"]}],["$","span","Expert Specialization",{"className":"page__taxonomy-item","children":["#","Expert Specialization"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}]]]}]}],["$","$La",null,{"postPermalink":"/ai/review/2025-12-30-Coupling-Experts-and-Routers-in-Mixture-of-Experts-via-an-Auxiliary-Loss","postId":"2025-12-30-Coupling-Experts-and-Routers-in-Mixture-of-Experts-via-an-Auxiliary-Loss"}],["$","section",null,{"className":"mt-12 border-t border-gray-200 pt-8","children":[["$","h3",null,{"className":"text-base font-semibold text-gray-900 mb-4","children":["Review"," 의 다른글"]}],["$","ul",null,{"className":"space-y-2 text-sm","children":[["$","li",null,{"className":"text-gray-500","children":["이전글"," ",["$","$L7",null,{"href":"/ai/review/2025-12-30-An-Information-Theoretic-Perspective-on-Agentic-System-Design","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] An Information Theoretic Perspective on Agentic System Design"}]]}],["$","li",null,{"className":"text-gray-900 font-semibold","children":["현재글 : ","[논문리뷰] Coupling Experts and Routers in Mixture-of-Experts via an Auxiliary Loss"]}],["$","li",null,{"className":"text-gray-500","children":["다음글"," ",["$","$L7",null,{"href":"/ai/review/2025-12-30-Diffusion-Knows-Transparency-Repurposing-Video-Diffusion-for-Transparent-Object-Depth-and-Normal-Estimation","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] Diffusion Knows Transparency: Repurposing Video Diffusion for Transparent Object Depth and Normal Estimation"}]]}]]}]]}]]}]}]]}]
8:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"[논문리뷰] Coupling Experts and Routers in Mixture-of-Experts via an Auxiliary Loss - secrett2633's blog"}],["$","meta","3",{"name":"description","content":"이 [arXiv]에 게시한 'Coupling Experts and Routers in Mixture-of-Experts via an Auxiliary Loss' 논문에 대한 자세한 리뷰입니다."}],["$","meta","4",{"name":"author","content":"secrett2633"}],["$","meta","5",{"name":"keywords","content":"Django, Python, DevOps, AI, ML, 블로그, 기술"}],["$","meta","6",{"name":"creator","content":"secrett2633"}],["$","meta","7",{"name":"publisher","content":"secrett2633"}],["$","meta","8",{"name":"robots","content":"index, follow"}],["$","meta","9",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","10",{"rel":"canonical","href":"https://blog.secrett2633.cloud/ai/review/2025-12-30-Coupling-Experts-and-Routers-in-Mixture-of-Experts-via-an-Auxiliary-Loss"}],["$","meta","11",{"name":"format-detection","content":"telephone=no, address=no, email=no"}],["$","meta","12",{"property":"og:title","content":"[논문리뷰] Coupling Experts and Routers in Mixture-of-Experts via an Auxiliary Loss"}],["$","meta","13",{"property":"og:description","content":"이 [arXiv]에 게시한 'Coupling Experts and Routers in Mixture-of-Experts via an Auxiliary Loss' 논문에 대한 자세한 리뷰입니다."}],["$","meta","14",{"property":"og:url","content":"https://blog.secrett2633.cloud/ai/review/2025-12-30-Coupling-Experts-and-Routers-in-Mixture-of-Experts-via-an-Auxiliary-Loss"}],["$","meta","15",{"property":"og:type","content":"article"}],["$","meta","16",{"name":"twitter:card","content":"summary"}],["$","meta","17",{"name":"twitter:title","content":"[논문리뷰] Coupling Experts and Routers in Mixture-of-Experts via an Auxiliary Loss"}],["$","meta","18",{"name":"twitter:description","content":"이 [arXiv]에 게시한 'Coupling Experts and Routers in Mixture-of-Experts via an Auxiliary Loss' 논문에 대한 자세한 리뷰입니다."}],["$","link","19",{"rel":"icon","href":"/icon.ico?6d9f34d4948640b8","type":"image/x-icon","sizes":"16x16"}]]
1:null
