3:I[9275,[],""]
5:I[1343,[],""]
6:I[9157,["231","static/chunks/231-467e37449c5a68fc.js","185","static/chunks/app/layout-e359f205e3380aec.js"],"default"]
7:I[231,["231","static/chunks/231-467e37449c5a68fc.js","931","static/chunks/app/page-90c91ef098171651.js"],""]
4:["slug","ai/review/2025-12-05-TV2TV-A-Unified-Framework-for-Interleaved-Language-and-Video-Generation","c"]
0:["vlNzklkFwxZlDtaCTE3RF",[[["",{"children":[["slug","ai/review/2025-12-05-TV2TV-A-Unified-Framework-for-Interleaved-Language-and-Video-Generation","c"],{"children":["__PAGE__?{\"slug\":[\"ai\",\"review\",\"2025-12-05-TV2TV-A-Unified-Framework-for-Interleaved-Language-and-Video-Generation\"]}",{}]}]},"$undefined","$undefined",true],["",{"children":[["slug","ai/review/2025-12-05-TV2TV-A-Unified-Framework-for-Interleaved-Language-and-Video-Generation","c"],{"children":["__PAGE__",{},[["$L1","$L2"],null],null]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","$4","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},[["$","html",null,{"lang":"ko","className":"no-js","children":[["$","head",null,{"children":[["$","meta",null,{"name":"msapplication-TileColor","content":"#ffc40d"}],["$","meta",null,{"name":"theme-color","content":"#ffffff"}],["$","script",null,{"async":true,"src":"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY"}],["$","script",null,{"dangerouslySetInnerHTML":{"__html":"\n              window.dataLayer = window.dataLayer || [];\n              function gtag(){dataLayer.push(arguments);}\n              gtag('js', new Date());\n              gtag('config', 'G-NE2W3CFPNY');\n            "}}]]}],["$","body",null,{"className":"__className_f367f3 layout--default","children":["$","div",null,{"className":"min-h-screen bg-gray-50","children":[["$","$L6",null,{}],["$","main",null,{"className":"initial-content","children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","div",null,{"className":"min-h-screen flex items-center justify-center bg-gray-50","children":["$","div",null,{"className":"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center","children":[["$","h1",null,{"className":"text-6xl font-bold text-primary-600 mb-4","children":"404"}],["$","h2",null,{"className":"text-2xl font-semibold text-gray-900 mb-4","children":"페이지를 찾을 수 없습니다"}],["$","p",null,{"className":"text-gray-600 mb-8","children":"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다."}],["$","$L7",null,{"href":"/","className":"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors","children":"홈으로 돌아가기"}]]}]}],"notFoundStyles":[],"styles":null}]}],["$","div",null,{"id":"footer","className":"page__footer","children":["$","footer",null,{"className":"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8","children":["$","div",null,{"className":"text-center text-gray-500 text-sm","children":["$","p",null,{"children":"© 2025 secrett2633. All rights reserved."}]}]}]}]]}]}]]}],null],[["$","div",null,{"className":"flex items-center justify-center min-h-screen","children":["$","div",null,{"className":"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600"}]}],[],[]]],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/d6cea809dcbae606.css","precedence":"next","crossOrigin":"$undefined"}]],[null,"$L8"]]]]]
a:I[646,["231","static/chunks/231-467e37449c5a68fc.js","877","static/chunks/app/%5B...slug%5D/page-dfe24a3bbd58f9b9.js"],"default"]
9:Td24,<blockquote>
<p><strong>링크:</strong> <a href="https://arxiv.org/abs/2512.05103">논문 PDF로 바로 열기</a></p>
</blockquote>
<p><strong>저자:</strong> Xiaochuang Han, Youssef Emad, Melissa Hall, John Nguyen, Karthik Padthe, Liam Robbins, Amir Bar, Delong Chen, Michal Drozdzal, Maha Elbayad, Yushi Hu, Shang-Wen Li, Sreya Dutta Roy, Jakob Verbeek, XuDong Wang, Marjan Ghazvininejad, Luke Zettlemoyer, Emily Dinan</p>
<h2>핵심 연구 목표</h2>
<p>본 논문은 복잡한 시맨틱 추론이나 반복적인 고수준 계획이 필요한 비디오 생성에서 기존 모델들이 겪는 한계를 극복하고자 합니다. 비디오 생성을 텍스트와 비디오 생성의 교차 프로세스로 분해함으로써 시각적 품질과 사용자 제어 가능성을 획기적으로 향상시키는 것을 목표로 합니다.</p>
<h2>핵심 방법론</h2>
<p><strong>TV2TV</strong> 는 <strong>Mixture-of-Transformers (MoT)</strong> 아키텍처를 기반으로 언어 모델링(다음 토큰 예측)과 비디오 플로우 매칭(다음 프레임 예측)을 <strong>공동으로 학습</strong> 하는 통합 프레임워크입니다. 추론 시 <strong>BOF (beginning-of-frame) 토큰</strong> 을 활용하여 텍스트 생성과 비디오 프레임 청크 생성을 동적으로 전환하며, 이는 <strong>사전 훈련된 Llama 모델</strong> 로 초기화된 텍스트 타워와 비디오 타워 간의 글로벌 셀프 어텐션을 통해 이루어집니다. 학습 데이터는 비디오 게임 ( <strong>CS:GO</strong> ) 데이터와 <strong>VLM (Vision-Language Model)</strong> 으로 증강된 실제 스포츠 비디오 데이터를 활용합니다.</p>
<h2>주요 결과</h2>
<p><strong>CS:GO</strong> 비디오 게임 데이터에 대한 제어 실험에서, <strong>TV2TV</strong> 는 비교 대상인 <strong>Text-to-Video (T2V) 모델</strong> 보다 <strong>91%</strong> 의 시간 동안 인간 평가에서 시각적 품질이 더 우수했습니다. 또한, <strong>"think-then-act" (Think2V) 접근 방식</strong> 대비 세밀한 명령어 추종 정확도에서 <strong>19% 포인트</strong> 향상을 보였습니다. 실제 스포츠 비디오 데이터셋에서는 <strong>TV2TV</strong> 가 외부 및 제어 기준선 대비 프롬프트 정렬, 실제 fidelity, 전반적인 선호도 측면에서 뛰어난 성능을 달성했습니다 ( <strong>T2V 대비 54.0% vs 34.7% 선호</strong> , <strong>Think2V 대비 53.3% vs 41.3% 선호</strong> ).</p>
<h2>AI 실무자를 위한 시사점</h2>
<p><strong>TV2TV</strong> 는 비디오 생성 과정에서 <strong>언어 모델의 추론 능력</strong> 을 활용하여 시맨틱 복잡성을 텍스트 생성으로 위임하는 효과적인 전략을 제시합니다. 이는 비디오 생성의 시각적 품질과 제어 가능성을 크게 향상시킬 수 있는 실용적인 방안입니다. 사용자 개입을 통한 비디오 생성 궤적 수정 기능은 <strong>대화형 AI 시스템</strong> 및 <strong>창작 도구</strong> 개발에 중요한 잠재력을 제공하며, <strong>VLM 기반 데이터 증강 파이프라인</strong> 은 실제 비디오 데이터의 텍스트 캡션 부족 문제를 해결하는 데 기여합니다.</p>
<blockquote>
<p>⚠️ <strong>알림:</strong> 이 리뷰는 AI로 작성되었습니다.</p>
</blockquote>
2:["$","div",null,{"className":"flex flex-col lg:flex-row gap-8","children":[["$","aside",null,{"className":"lg:w-64 xl:w-72 order-1 lg:order-none","children":["$","div",null,{"className":"sidebar sticky","children":["$","nav",null,{"className":"space-y-4","children":[["$","div","Backend",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"Backend"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Django",{"children":["$","a",null,{"href":"/backend/django/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Django"," (",6,")"]}]}],["$","li","Logging",{"children":["$","a",null,{"href":"/backend/logging/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Logging"," (",1,")"]}]}]]}]]}],["$","div","Python",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"Python"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","PEP",{"children":["$","a",null,{"href":"/python/pep/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["PEP"," (",650,")"]}]}]]}]]}],["$","div","AI/ML",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"AI/ML"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","LLM",{"children":["$","a",null,{"href":"/ai/llm/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["LLM"," (",1,")"]}]}],["$","li","Review",{"children":["$","a",null,{"href":"/ai/review/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Review"," (",2420,")"]}]}]]}]]}],["$","div","DevOps",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"DevOps"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Nginx",{"children":["$","a",null,{"href":"/devops/nginx/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Nginx"," (",1,")"]}]}],["$","li","Docker",{"children":["$","a",null,{"href":"/devops/docker/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Docker"," (",1,")"]}]}],["$","li","SafeLine",{"children":["$","a",null,{"href":"/devops/safeline/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["SafeLine"," (",1,")"]}]}],["$","li","Jenkins",{"children":["$","a",null,{"href":"/devops/jenkins/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Jenkins"," (",3,")"]}]}],["$","li","GitHub Actions",{"children":["$","a",null,{"href":"/devops/github-actions/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["GitHub Actions"," (",1,")"]}]}],["$","li","AWS",{"children":["$","a",null,{"href":"/devops/aws/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["AWS"," (",1,")"]}]}]]}]]}],["$","div","etc",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"etc"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Me",{"children":["$","a",null,{"href":"/etc/me/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Me"," (",3,")"]}]}],["$","li","Chrome Extension",{"children":["$","a",null,{"href":"/etc/chrome-extension/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Chrome Extension"," (",1,")"]}]}]]}]]}]]}]}]}],["$","main",null,{"className":"flex-1","children":["$","article",null,{"className":"page","children":[["$","header",null,{"className":"mb-8","children":[["$","h1",null,{"className":"page__title","children":"[논문리뷰] TV2TV: A Unified Framework for Interleaved Language and Video Generation"}],["$","div",null,{"className":"page__meta","children":[["$","time",null,{"dateTime":"2025-12-05 00:00:00+0900+0900","children":"2025년 12월 5일"}],["$","span",null,{"className":"ml-4","children":["수정: ","2025년 12월 5일"]}]]}]]}],["$","div",null,{"className":"page__content","children":["$","div",null,{"dangerouslySetInnerHTML":{"__html":"$9"}}]}],["$","footer",null,{"className":"page__meta mt-8","children":["$","div",null,{"className":"page__taxonomy","children":[["$","h4",null,{"className":"text-sm font-medium text-gray-900 mb-2","children":"태그"}],[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Language Modeling",{"className":"page__taxonomy-item","children":["#","Language Modeling"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Interleaved Generation",{"className":"page__taxonomy-item","children":["#","Interleaved Generation"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Controllability",{"className":"page__taxonomy-item","children":["#","Controllability"]}],["$","span","World Models",{"className":"page__taxonomy-item","children":["#","World Models"]}]]]}]}],["$","$La",null,{"postPermalink":"/ai/review/2025-12-05-TV2TV-A-Unified-Framework-for-Interleaved-Language-and-Video-Generation/","postId":"2025-12-05-TV2TV-A-Unified-Framework-for-Interleaved-Language-and-Video-Generation"}],["$","section",null,{"className":"mt-12 border-t border-gray-200 pt-8","children":[["$","h3",null,{"className":"text-base font-semibold text-gray-900 mb-4","children":["Review"," 의 다른글"]}],["$","ul",null,{"className":"space-y-2 text-sm","children":[["$","li",null,{"className":"text-gray-500","children":["이전글"," ",["$","$L7",null,{"href":"/ai/review/2025-12-05-Splannequin-Freezing-Monocular-Mannequin-Challenge-Footage-with-Dual-Detection-Splatting/","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] Splannequin: Freezing Monocular Mannequin-Challenge Footage with Dual-Detection Splatting"}]]}],["$","li",null,{"className":"text-gray-900 font-semibold","children":["현재글 : ","[논문리뷰] TV2TV: A Unified Framework for Interleaved Language and Video Generation"]}],["$","li",null,{"className":"text-gray-500","children":["다음글"," ",["$","$L7",null,{"href":"/ai/review/2025-12-05-UltraImage-Rethinking-Resolution-Extrapolation-in-Image-Diffusion-Transformers/","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] UltraImage: Rethinking Resolution Extrapolation in Image Diffusion Transformers"}]]}]]}]]}]]}]}]]}]
8:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"secrett2633's blog"}],["$","meta","3",{"name":"description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","meta","4",{"name":"author","content":"secrett2633"}],["$","meta","5",{"name":"keywords","content":"Django, Python, DevOps, AI, ML, 블로그, 기술"}],["$","meta","6",{"name":"creator","content":"secrett2633"}],["$","meta","7",{"name":"publisher","content":"secrett2633"}],["$","meta","8",{"name":"robots","content":"index, follow"}],["$","meta","9",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","10",{"rel":"canonical","href":"https://blog.secrett2633.cloud/"}],["$","meta","11",{"name":"format-detection","content":"telephone=no, address=no, email=no"}],["$","meta","12",{"property":"og:title","content":"secrett2633's blog"}],["$","meta","13",{"property":"og:description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","meta","14",{"property":"og:url","content":"https://blog.secrett2633.cloud/"}],["$","meta","15",{"property":"og:site_name","content":"secrett2633's blog"}],["$","meta","16",{"property":"og:locale","content":"ko_KR"}],["$","meta","17",{"property":"og:type","content":"website"}],["$","meta","18",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","19",{"name":"twitter:title","content":"secrett2633's blog"}],["$","meta","20",{"name":"twitter:description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","link","21",{"rel":"icon","href":"/icon.ico?6d9f34d4948640b8","type":"image/x-icon","sizes":"16x16"}],["$","meta","22",{"name":"next-size-adjust"}]]
1:null
