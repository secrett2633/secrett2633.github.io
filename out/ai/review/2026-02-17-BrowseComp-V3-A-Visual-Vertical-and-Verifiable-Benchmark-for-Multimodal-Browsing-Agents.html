<!DOCTYPE html><html lang="ko" class="no-js"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/_next/static/css/d6cea809dcbae606.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-61c2b369a48bb953.js"/><script src="/_next/static/chunks/fd9d1056-0395f68b8cc78a20.js" async=""></script><script src="/_next/static/chunks/23-7d3f7f0b78aa2fd3.js" async=""></script><script src="/_next/static/chunks/main-app-cf4c503f60a850f8.js" async=""></script><script src="/_next/static/chunks/231-467e37449c5a68fc.js" async=""></script><script src="/_next/static/chunks/app/layout-53ec9cbf619543e1.js" async=""></script><script src="/_next/static/chunks/app/%5B...slug%5D/page-80e07cee06d17a0b.js" async=""></script><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY"></script><title>[논문리뷰] BrowseComp-V^3: A Visual, Vertical, and Verifiable Benchmark for Multimodal Browsing Agents - secrett2633&#x27;s blog</title><meta name="description" content="Yanzhe Dan이 [arXiv]에 게시한 &#x27;BrowseComp-V^3: A Visual, Vertical, and Verifiable Benchmark for Multimodal Browsing Agents&#x27; 논문에 대한 자세한 리뷰입니다."/><meta name="author" content="secrett2633"/><meta name="keywords" content="Django, Python, DevOps, AI, ML, 블로그, 기술"/><meta name="creator" content="secrett2633"/><meta name="publisher" content="secrett2633"/><meta name="robots" content="index, follow"/><meta name="googlebot" content="index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"/><link rel="canonical" href="https://blog.secrett2633.cloud/ai/review/2026-02-17-BrowseComp-V3-A-Visual-Vertical-and-Verifiable-Benchmark-for-Multimodal-Browsing-Agents"/><meta name="format-detection" content="telephone=no, address=no, email=no"/><meta property="og:title" content="[논문리뷰] BrowseComp-V^3: A Visual, Vertical, and Verifiable Benchmark for Multimodal Browsing Agents"/><meta property="og:description" content="Yanzhe Dan이 [arXiv]에 게시한 &#x27;BrowseComp-V^3: A Visual, Vertical, and Verifiable Benchmark for Multimodal Browsing Agents&#x27; 논문에 대한 자세한 리뷰입니다."/><meta property="og:url" content="https://blog.secrett2633.cloud/ai/review/2026-02-17-BrowseComp-V3-A-Visual-Vertical-and-Verifiable-Benchmark-for-Multimodal-Browsing-Agents"/><meta property="og:type" content="article"/><meta name="twitter:card" content="summary"/><meta name="twitter:title" content="[논문리뷰] BrowseComp-V^3: A Visual, Vertical, and Verifiable Benchmark for Multimodal Browsing Agents"/><meta name="twitter:description" content="Yanzhe Dan이 [arXiv]에 게시한 &#x27;BrowseComp-V^3: A Visual, Vertical, and Verifiable Benchmark for Multimodal Browsing Agents&#x27; 논문에 대한 자세한 리뷰입니다."/><link rel="icon" href="/icon.ico?6d9f34d4948640b8" type="image/x-icon" sizes="16x16"/><meta name="msapplication-TileColor" content="#ffc40d"/><meta name="theme-color" content="#ffffff"/><script>
              window.dataLayer = window.dataLayer || [];
              function gtag(){dataLayer.push(arguments);}
              gtag('js', new Date());
              gtag('config', 'G-NE2W3CFPNY');
            </script><script src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body class="__className_f367f3 layout--default"><div class="min-h-screen bg-gray-50"><div class="masthead"><div class="masthead__inner-wrap"><div class="masthead__menu"><nav id="site-nav" class="greedy-nav"><a class="site-title" href="/">secrett2633&#x27;s blog</a><div class="flex items-center space-x-4"><ul class="visible-links"><li class="masthead__menu-item"><a href="https://github.com/secrett2633" target="_blank" rel="noopener noreferrer">GitHub</a></li></ul><button class="search__toggle" type="button"><svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16"><path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path></svg></button></div></nav></div></div></div><main class="initial-content"><!--$--><div class="flex flex-col lg:flex-row gap-8"><aside class="lg:w-64 xl:w-72 order-1 lg:order-none"><div class="sidebar sticky"><nav class="space-y-4"><div><h4 class="font-medium text-gray-900 mb-2">Backend</h4><ul class="space-y-1 ml-4"><li><a href="/backend/django" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Django<!-- --> (<!-- -->6<!-- -->)</a></li><li><a href="/backend/logging" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Logging<!-- --> (<!-- -->1<!-- -->)</a></li></ul></div><div><h4 class="font-medium text-gray-900 mb-2">Python</h4><ul class="space-y-1 ml-4"><li><a href="/python/pep" class="text-sm text-gray-600 hover:text-primary-600 block py-1">PEP<!-- --> (<!-- -->650<!-- -->)</a></li></ul></div><div><h4 class="font-medium text-gray-900 mb-2">AI/ML</h4><ul class="space-y-1 ml-4"><li><a href="/ai/llm" class="text-sm text-gray-600 hover:text-primary-600 block py-1">LLM<!-- --> (<!-- -->1<!-- -->)</a></li><li><a href="/ai/review" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Review<!-- --> (<!-- -->2728<!-- -->)</a></li></ul></div><div><h4 class="font-medium text-gray-900 mb-2">DevOps</h4><ul class="space-y-1 ml-4"><li><a href="/devops/nginx" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Nginx<!-- --> (<!-- -->1<!-- -->)</a></li><li><a href="/devops/docker" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Docker<!-- --> (<!-- -->1<!-- -->)</a></li><li><a href="/devops/safeline" class="text-sm text-gray-600 hover:text-primary-600 block py-1">SafeLine<!-- --> (<!-- -->1<!-- -->)</a></li><li><a href="/devops/jenkins" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Jenkins<!-- --> (<!-- -->3<!-- -->)</a></li><li><a href="/devops/github-actions" class="text-sm text-gray-600 hover:text-primary-600 block py-1">GitHub Actions<!-- --> (<!-- -->1<!-- -->)</a></li><li><a href="/devops/aws" class="text-sm text-gray-600 hover:text-primary-600 block py-1">AWS<!-- --> (<!-- -->1<!-- -->)</a></li></ul></div><div><h4 class="font-medium text-gray-900 mb-2">etc</h4><ul class="space-y-1 ml-4"><li><a href="/etc/me" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Me<!-- --> (<!-- -->3<!-- -->)</a></li><li><a href="/etc/chrome-extension" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Chrome Extension<!-- --> (<!-- -->1<!-- -->)</a></li></ul></div></nav></div></aside><main class="flex-1"><article class="page"><header class="mb-8"><h1 class="page__title">[논문리뷰] BrowseComp-V^3: A Visual, Vertical, and Verifiable Benchmark for Multimodal Browsing Agents</h1><div class="page__meta"><time dateTime="2026-02-17 00:00:00+0900+0900">2026년 2월 17일</time><span class="ml-4">수정: <!-- -->2026년 2월 17일</span></div></header><div class="page__content"><div><blockquote>
<p><strong>링크:</strong> <a href="https://arxiv.org/abs/2602.12876">논문 PDF로 바로 열기</a></p>
</blockquote>
<p><strong>저자:</strong> Huanyao Zhang, Jiepeng Zhou, Bo Li, Bowen Zhou, Yanzhe Dan, Haishan Lu, Zhiyong Cao, Jiaoyang Chen, Yuqian Han, Zinan Sheng, Zhengwei Tao, Hao Liang, Jialong Wu, Yang Shi, Yuanpeng He, Jiaye Lin, Qintong Zhang, Guochen Yan, Runhao Zhao, Zhengpin Li, Xiaohan Yu, Lang Mei, Chong Chen, Wentao Zhang, Bin Cui</p>
<h2>핵심 연구 목표</h2>
<p>기존 벤치마크의 제한적인 태스크 복잡도, 정보 검색 가능성, 평가 차원의 문제를 해결하여 멀티모달 웹 브라우징 에이전트의 심층 검색 역량을 포괄적으로 평가할 수 있는 새롭고 검증 가능한 벤치마크를 개발하는 것을 목표로 합니다. 특히, 모델의 파라미터 지식에만 의존하지 않고 웹 브라우징 도구 사용이 필수적인 심층, 다단계, 교차 모달 다중 홉 추론 태스크를 제시하고자 합니다.</p>
<h2>핵심 방법론</h2>
<p>논문은 24개 도메인에 걸쳐 <strong>300개의 정교하게 수작업된 질문</strong> 으로 구성된 새로운 벤치마크인 <strong>BrowseComp-V³</strong> 를 제시합니다. 모든 증거의 <strong>공개적 검색 가능성</strong> 을 엄격히 적용하며, 전문가가 검증한 <strong>서브골 기반 프로세스 평가 메커니즘</strong> 을 통합하여 검색 행동과 역량 한계를 세분화하여 분석합니다. 또한, 일반적인 멀티모달 브라우징 에이전트 프레임워크인 <strong>OmniSeeker</strong> 를 제공합니다.</p>
<h2>주요 결과</h2>
<p>인간은 BrowseComp-V³ 태스크에서 <strong>68.03%의 평균 성공률(SR)</strong> 과 <strong>82.93%의 프로세스 점수(PS)</strong> 를 달성하며 모델을 크게 능가했습니다. GPT-5.2와 같은 최첨단 모델조차 <strong>36%의 정확도</strong> 에 그쳤으며, 어떤 모델도 <strong>40% SR 이상</strong> 을 달성하지 못했습니다. 도구 증강은 모델 성능을 크게 향상시켰으며 (예: <strong>GPT-5.2-Thinking 39.13% SR</strong> vs. 도구 미사용 GPT-5.2 <strong>6.00% SR</strong> ), <strong>OmniSeeker</strong> 를 장착한 Doubao-Seed-1.8은 <strong>33.67% SR</strong> 을 기록했습니다. 분석 결과, 멀티모달 정보 통합 및 세밀한 인지 능력의 부족이 주요 병목 현상으로 나타났습니다.</p>
<h2>AI 실무자를 위한 시사점</h2>
<p>이 벤치마크는 현재 MLLM이 복잡한 멀티모달 심층 검색 태스크에서 <strong>외부 도구 활용 능력</strong> 과 <strong>네이티브 멀티모달 추론 능력</strong> 이 부족함을 명확히 보여줍니다. AI 실무자들은 <strong>도구 증강 프레임워크</strong> 와 <strong>세분화된 프로세스 평가 지표</strong> 를 활용하여 모델의 강점과 약점을 진단하고 개선하는 데 집중할 수 있습니다. <strong>OmniSeeker</strong> 는 개방형 멀티모달 브라우징 에이전트 개발을 위한 효과적인 기반을 제공합니다.</p>
<blockquote>
<p>⚠️ <strong>알림:</strong> 이 리뷰는 AI로 작성되었습니다.</p>
</blockquote>
</div></div><footer class="page__meta mt-8"><div class="page__taxonomy"><h4 class="text-sm font-medium text-gray-900 mb-2">태그</h4><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal LLMs</span><span class="page__taxonomy-item">#<!-- -->Web Browsing Agents</span><span class="page__taxonomy-item">#<!-- -->Deep Search</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Tool Use</span><span class="page__taxonomy-item">#<!-- -->Process Evaluation</span><span class="page__taxonomy-item">#<!-- -->Multimodal Reasoning</span><span class="page__taxonomy-item">#<!-- -->Open-world QA</span></div></footer><section class="comments-section mt-12 pt-8 border-t border-gray-200"></section><section class="mt-12 border-t border-gray-200 pt-8"><h3 class="text-base font-semibold text-gray-900 mb-4">Review<!-- --> 의 다른글</h3><ul class="space-y-2 text-sm"><li class="text-gray-500">이전글<!-- --> <a class="text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4" href="/ai/review/2026-02-17-Blind-to-the-Human-Touch-Overlap-Bias-in-LLM-Based-Summary-Evaluation">[논문리뷰] Blind to the Human Touch: Overlap Bias in LLM-Based Summary Evaluation</a></li><li class="text-gray-900 font-semibold">현재글 : <!-- -->[논문리뷰] BrowseComp-V^3: A Visual, Vertical, and Verifiable Benchmark for Multimodal Browsing Agents</li><li class="text-gray-500">다음글<!-- --> <a class="text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4" href="/ai/review/2026-02-17-Data-Darwinism-Part-I-Unlocking-the-Value-of-Scientific-Data-for-Pre-training">[논문리뷰] Data Darwinism Part I: Unlocking the Value of Scientific Data for Pre-training</a></li></ul></section></article></main></div><!--/$--></main><div id="footer" class="page__footer"><footer class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8"><div class="text-center text-gray-500 text-sm"><p>© 2025 secrett2633. All rights reserved.</p></div></footer></div></div><script src="/_next/static/chunks/webpack-61c2b369a48bb953.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/css/d6cea809dcbae606.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"2:I[5751,[],\"\"]\n5:I[9275,[],\"\"]\n7:I[1343,[],\"\"]\n8:I[9157,[\"231\",\"static/chunks/231-467e37449c5a68fc.js\",\"185\",\"static/chunks/app/layout-53ec9cbf619543e1.js\"],\"default\"]\n9:I[231,[\"231\",\"static/chunks/231-467e37449c5a68fc.js\",\"877\",\"static/chunks/app/%5B...slug%5D/page-80e07cee06d17a0b.js\"],\"\"]\nb:I[6130,[],\"\"]\n6:[\"slug\",\"ai/review/2026-02-17-BrowseComp-V3-A-Visual-Vertical-and-Verifiable-Benchmark-for-Multimodal-Browsing-Agents\",\"c\"]\nc:[]\n"])</script><script>self.__next_f.push([1,"0:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/d6cea809dcbae606.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L2\",null,{\"buildId\":\"_3-KrKKQh7tcSoXiYwQMB\",\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/ai/review/2026-02-17-BrowseComp-V3-A-Visual-Vertical-and-Verifiable-Benchmark-for-Multimodal-Browsing-Agents\",\"initialTree\":[\"\",{\"children\":[[\"slug\",\"ai/review/2026-02-17-BrowseComp-V3-A-Visual-Vertical-and-Verifiable-Benchmark-for-Multimodal-Browsing-Agents\",\"c\"],{\"children\":[\"__PAGE__?{\\\"slug\\\":[\\\"ai\\\",\\\"review\\\",\\\"2026-02-17-BrowseComp-V3-A-Visual-Vertical-and-Verifiable-Benchmark-for-Multimodal-Browsing-Agents\\\"]}\",{}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[[\"slug\",\"ai/review/2026-02-17-BrowseComp-V3-A-Visual-Vertical-and-Verifiable-Benchmark-for-Multimodal-Browsing-Agents\",\"c\"],{\"children\":[\"__PAGE__\",{},[[\"$L3\",\"$L4\"],null],null]},[\"$\",\"$L5\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"$6\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L7\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}],null]},[[\"$\",\"html\",null,{\"lang\":\"ko\",\"className\":\"no-js\",\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"meta\",null,{\"name\":\"msapplication-TileColor\",\"content\":\"#ffc40d\"}],[\"$\",\"meta\",null,{\"name\":\"theme-color\",\"content\":\"#ffffff\"}],[\"$\",\"script\",null,{\"async\":true,\"src\":\"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY\"}],[\"$\",\"script\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\\n              window.dataLayer = window.dataLayer || [];\\n              function gtag(){dataLayer.push(arguments);}\\n              gtag('js', new Date());\\n              gtag('config', 'G-NE2W3CFPNY');\\n            \"}}]]}],[\"$\",\"body\",null,{\"className\":\"__className_f367f3 layout--default\",\"children\":[\"$\",\"div\",null,{\"className\":\"min-h-screen bg-gray-50\",\"children\":[[\"$\",\"$L8\",null,{}],[\"$\",\"main\",null,{\"className\":\"initial-content\",\"children\":[\"$\",\"$L5\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L7\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[\"$\",\"div\",null,{\"className\":\"min-h-screen flex items-center justify-center bg-gray-50\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-6xl font-bold text-primary-600 mb-4\",\"children\":\"404\"}],[\"$\",\"h2\",null,{\"className\":\"text-2xl font-semibold text-gray-900 mb-4\",\"children\":\"페이지를 찾을 수 없습니다\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-600 mb-8\",\"children\":\"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다.\"}],[\"$\",\"$L9\",null,{\"href\":\"/\",\"className\":\"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors\",\"children\":\"홈으로 돌아가기\"}]]}]}],\"notFoundStyles\":[],\"styles\":null}]}],[\"$\",\"div\",null,{\"id\":\"footer\",\"className\":\"page__footer\",\"children\":[\"$\",\"footer\",null,{\"className\":\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"text-center text-gray-500 text-sm\",\"children\":[\"$\",\"p\",null,{\"children\":\"© 2025 secrett2633. All rights reserved.\"}]}]}]}]]}]}]]}],null],[[\"$\",\"div\",null,{\"className\":\"flex items-center justify-center min-h-screen\",\"children\":[\"$\",\"div\",null,{\"className\":\"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600\"}]}],[],[]]],\"couldBeIntercepted\":false,\"initialHead\":[null,\"$La\"],\"globalErrorComponent\":\"$b\",\"missingSlots\":\"$Wc\"}]]\n"])</script><script>self.__next_f.push([1,"e:I[646,[\"231\",\"static/chunks/231-467e37449c5a68fc.js\",\"877\",\"static/chunks/app/%5B...slug%5D/page-80e07cee06d17a0b.js\"],\"default\"]\nd:Tc93,"])</script><script>self.__next_f.push([1,"\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e링크:\u003c/strong\u003e \u003ca href=\"https://arxiv.org/abs/2602.12876\"\u003e논문 PDF로 바로 열기\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003e저자:\u003c/strong\u003e Huanyao Zhang, Jiepeng Zhou, Bo Li, Bowen Zhou, Yanzhe Dan, Haishan Lu, Zhiyong Cao, Jiaoyang Chen, Yuqian Han, Zinan Sheng, Zhengwei Tao, Hao Liang, Jialong Wu, Yang Shi, Yuanpeng He, Jiaye Lin, Qintong Zhang, Guochen Yan, Runhao Zhao, Zhengpin Li, Xiaohan Yu, Lang Mei, Chong Chen, Wentao Zhang, Bin Cui\u003c/p\u003e\n\u003ch2\u003e핵심 연구 목표\u003c/h2\u003e\n\u003cp\u003e기존 벤치마크의 제한적인 태스크 복잡도, 정보 검색 가능성, 평가 차원의 문제를 해결하여 멀티모달 웹 브라우징 에이전트의 심층 검색 역량을 포괄적으로 평가할 수 있는 새롭고 검증 가능한 벤치마크를 개발하는 것을 목표로 합니다. 특히, 모델의 파라미터 지식에만 의존하지 않고 웹 브라우징 도구 사용이 필수적인 심층, 다단계, 교차 모달 다중 홉 추론 태스크를 제시하고자 합니다.\u003c/p\u003e\n\u003ch2\u003e핵심 방법론\u003c/h2\u003e\n\u003cp\u003e논문은 24개 도메인에 걸쳐 \u003cstrong\u003e300개의 정교하게 수작업된 질문\u003c/strong\u003e 으로 구성된 새로운 벤치마크인 \u003cstrong\u003eBrowseComp-V³\u003c/strong\u003e 를 제시합니다. 모든 증거의 \u003cstrong\u003e공개적 검색 가능성\u003c/strong\u003e 을 엄격히 적용하며, 전문가가 검증한 \u003cstrong\u003e서브골 기반 프로세스 평가 메커니즘\u003c/strong\u003e 을 통합하여 검색 행동과 역량 한계를 세분화하여 분석합니다. 또한, 일반적인 멀티모달 브라우징 에이전트 프레임워크인 \u003cstrong\u003eOmniSeeker\u003c/strong\u003e 를 제공합니다.\u003c/p\u003e\n\u003ch2\u003e주요 결과\u003c/h2\u003e\n\u003cp\u003e인간은 BrowseComp-V³ 태스크에서 \u003cstrong\u003e68.03%의 평균 성공률(SR)\u003c/strong\u003e 과 \u003cstrong\u003e82.93%의 프로세스 점수(PS)\u003c/strong\u003e 를 달성하며 모델을 크게 능가했습니다. GPT-5.2와 같은 최첨단 모델조차 \u003cstrong\u003e36%의 정확도\u003c/strong\u003e 에 그쳤으며, 어떤 모델도 \u003cstrong\u003e40% SR 이상\u003c/strong\u003e 을 달성하지 못했습니다. 도구 증강은 모델 성능을 크게 향상시켰으며 (예: \u003cstrong\u003eGPT-5.2-Thinking 39.13% SR\u003c/strong\u003e vs. 도구 미사용 GPT-5.2 \u003cstrong\u003e6.00% SR\u003c/strong\u003e ), \u003cstrong\u003eOmniSeeker\u003c/strong\u003e 를 장착한 Doubao-Seed-1.8은 \u003cstrong\u003e33.67% SR\u003c/strong\u003e 을 기록했습니다. 분석 결과, 멀티모달 정보 통합 및 세밀한 인지 능력의 부족이 주요 병목 현상으로 나타났습니다.\u003c/p\u003e\n\u003ch2\u003eAI 실무자를 위한 시사점\u003c/h2\u003e\n\u003cp\u003e이 벤치마크는 현재 MLLM이 복잡한 멀티모달 심층 검색 태스크에서 \u003cstrong\u003e외부 도구 활용 능력\u003c/strong\u003e 과 \u003cstrong\u003e네이티브 멀티모달 추론 능력\u003c/strong\u003e 이 부족함을 명확히 보여줍니다. AI 실무자들은 \u003cstrong\u003e도구 증강 프레임워크\u003c/strong\u003e 와 \u003cstrong\u003e세분화된 프로세스 평가 지표\u003c/strong\u003e 를 활용하여 모델의 강점과 약점을 진단하고 개선하는 데 집중할 수 있습니다. \u003cstrong\u003eOmniSeeker\u003c/strong\u003e 는 개방형 멀티모달 브라우징 에이전트 개발을 위한 효과적인 기반을 제공합니다.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e⚠️ \u003cstrong\u003e알림:\u003c/strong\u003e 이 리뷰는 AI로 작성되었습니다.\u003c/p\u003e\n\u003c/blockquote\u003e\n"])</script><script>self.__next_f.push([1,"4:[\"$\",\"div\",null,{\"className\":\"flex flex-col lg:flex-row gap-8\",\"children\":[[\"$\",\"aside\",null,{\"className\":\"lg:w-64 xl:w-72 order-1 lg:order-none\",\"children\":[\"$\",\"div\",null,{\"className\":\"sidebar sticky\",\"children\":[\"$\",\"nav\",null,{\"className\":\"space-y-4\",\"children\":[[\"$\",\"div\",\"Backend\",{\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"Backend\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"Django\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/backend/django\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Django\",\" (\",6,\")\"]}]}],[\"$\",\"li\",\"Logging\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/backend/logging\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Logging\",\" (\",1,\")\"]}]}]]}]]}],[\"$\",\"div\",\"Python\",{\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"Python\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"PEP\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/python/pep\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"PEP\",\" (\",650,\")\"]}]}]]}]]}],[\"$\",\"div\",\"AI/ML\",{\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"AI/ML\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"LLM\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/ai/llm\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"LLM\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"Review\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/ai/review\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Review\",\" (\",2728,\")\"]}]}]]}]]}],[\"$\",\"div\",\"DevOps\",{\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"DevOps\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"Nginx\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/devops/nginx\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Nginx\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"Docker\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/devops/docker\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Docker\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"SafeLine\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/devops/safeline\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"SafeLine\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"Jenkins\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/devops/jenkins\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Jenkins\",\" (\",3,\")\"]}]}],[\"$\",\"li\",\"GitHub Actions\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/devops/github-actions\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"GitHub Actions\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"AWS\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/devops/aws\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"AWS\",\" (\",1,\")\"]}]}]]}]]}],[\"$\",\"div\",\"etc\",{\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"etc\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"Me\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/etc/me\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Me\",\" (\",3,\")\"]}]}],[\"$\",\"li\",\"Chrome Extension\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/etc/chrome-extension\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Chrome Extension\",\" (\",1,\")\"]}]}]]}]]}]]}]}]}],[\"$\",\"main\",null,{\"className\":\"flex-1\",\"children\":[\"$\",\"article\",null,{\"className\":\"page\",\"children\":[[\"$\",\"header\",null,{\"className\":\"mb-8\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"page__title\",\"children\":\"[논문리뷰] BrowseComp-V^3: A Visual, Vertical, and Verifiable Benchmark for Multimodal Browsing Agents\"}],[\"$\",\"div\",null,{\"className\":\"page__meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2026-02-17 00:00:00+0900+0900\",\"children\":\"2026년 2월 17일\"}],[\"$\",\"span\",null,{\"className\":\"ml-4\",\"children\":[\"수정: \",\"2026년 2월 17일\"]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"page__content\",\"children\":[\"$\",\"div\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$d\"}}]}],[\"$\",\"footer\",null,{\"className\":\"page__meta mt-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"page__taxonomy\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"text-sm font-medium text-gray-900 mb-2\",\"children\":\"태그\"}],[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal LLMs\"]}],[\"$\",\"span\",\"Web Browsing Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Web Browsing Agents\"]}],[\"$\",\"span\",\"Deep Search\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deep Search\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Tool Use\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool Use\"]}],[\"$\",\"span\",\"Process Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Process Evaluation\"]}],[\"$\",\"span\",\"Multimodal Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Reasoning\"]}],[\"$\",\"span\",\"Open-world QA\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Open-world QA\"]}]]]}]}],[\"$\",\"$Le\",null,{\"postPermalink\":\"/ai/review/2026-02-17-BrowseComp-V3-A-Visual-Vertical-and-Verifiable-Benchmark-for-Multimodal-Browsing-Agents\",\"postId\":\"2026-02-17-BrowseComp-V3-A-Visual-Vertical-and-Verifiable-Benchmark-for-Multimodal-Browsing-Agents\"}],[\"$\",\"section\",null,{\"className\":\"mt-12 border-t border-gray-200 pt-8\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-base font-semibold text-gray-900 mb-4\",\"children\":[\"Review\",\" 의 다른글\"]}],[\"$\",\"ul\",null,{\"className\":\"space-y-2 text-sm\",\"children\":[[\"$\",\"li\",null,{\"className\":\"text-gray-500\",\"children\":[\"이전글\",\" \",[\"$\",\"$L9\",null,{\"href\":\"/ai/review/2026-02-17-Blind-to-the-Human-Touch-Overlap-Bias-in-LLM-Based-Summary-Evaluation\",\"className\":\"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4\",\"children\":\"[논문리뷰] Blind to the Human Touch: Overlap Bias in LLM-Based Summary Evaluation\"}]]}],[\"$\",\"li\",null,{\"className\":\"text-gray-900 font-semibold\",\"children\":[\"현재글 : \",\"[논문리뷰] BrowseComp-V^3: A Visual, Vertical, and Verifiable Benchmark for Multimodal Browsing Agents\"]}],[\"$\",\"li\",null,{\"className\":\"text-gray-500\",\"children\":[\"다음글\",\" \",[\"$\",\"$L9\",null,{\"href\":\"/ai/review/2026-02-17-Data-Darwinism-Part-I-Unlocking-the-Value-of-Scientific-Data-for-Pre-training\",\"className\":\"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4\",\"children\":\"[논문리뷰] Data Darwinism Part I: Unlocking the Value of Scientific Data for Pre-training\"}]]}]]}]]}]]}]}]]}]\n"])</script><script>self.__next_f.push([1,"a:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"[논문리뷰] BrowseComp-V^3: A Visual, Vertical, and Verifiable Benchmark for Multimodal Browsing Agents - secrett2633's blog\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"Yanzhe Dan이 [arXiv]에 게시한 'BrowseComp-V^3: A Visual, Vertical, and Verifiable Benchmark for Multimodal Browsing Agents' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"meta\",\"4\",{\"name\":\"author\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"5\",{\"name\":\"keywords\",\"content\":\"Django, Python, DevOps, AI, ML, 블로그, 기술\"}],[\"$\",\"meta\",\"6\",{\"name\":\"creator\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"7\",{\"name\":\"publisher\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"8\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"9\",{\"name\":\"googlebot\",\"content\":\"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1\"}],[\"$\",\"link\",\"10\",{\"rel\":\"canonical\",\"href\":\"https://blog.secrett2633.cloud/ai/review/2026-02-17-BrowseComp-V3-A-Visual-Vertical-and-Verifiable-Benchmark-for-Multimodal-Browsing-Agents\"}],[\"$\",\"meta\",\"11\",{\"name\":\"format-detection\",\"content\":\"telephone=no, address=no, email=no\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:title\",\"content\":\"[논문리뷰] BrowseComp-V^3: A Visual, Vertical, and Verifiable Benchmark for Multimodal Browsing Agents\"}],[\"$\",\"meta\",\"13\",{\"property\":\"og:description\",\"content\":\"Yanzhe Dan이 [arXiv]에 게시한 'BrowseComp-V^3: A Visual, Vertical, and Verifiable Benchmark for Multimodal Browsing Agents' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"meta\",\"14\",{\"property\":\"og:url\",\"content\":\"https://blog.secrett2633.cloud/ai/review/2026-02-17-BrowseComp-V3-A-Visual-Vertical-and-Verifiable-Benchmark-for-Multimodal-Browsing-Agents\"}],[\"$\",\"meta\",\"15\",{\"property\":\"og:type\",\"content\":\"article\"}],[\"$\",\"meta\",\"16\",{\"name\":\"twitter:card\",\"content\":\"summary\"}],[\"$\",\"meta\",\"17\",{\"name\":\"twitter:title\",\"content\":\"[논문리뷰] BrowseComp-V^3: A Visual, Vertical, and Verifiable Benchmark for Multimodal Browsing Agents\"}],[\"$\",\"meta\",\"18\",{\"name\":\"twitter:description\",\"content\":\"Yanzhe Dan이 [arXiv]에 게시한 'BrowseComp-V^3: A Visual, Vertical, and Verifiable Benchmark for Multimodal Browsing Agents' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"link\",\"19\",{\"rel\":\"icon\",\"href\":\"/icon.ico?6d9f34d4948640b8\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}]]\n"])</script><script>self.__next_f.push([1,"3:null\n"])</script></body></html>