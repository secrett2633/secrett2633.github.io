3:I[9275,[],""]
5:I[1343,[],""]
6:I[9157,["231","static/chunks/231-467e37449c5a68fc.js","185","static/chunks/app/layout-b0a450f8e4964582.js"],"default"]
7:I[231,["231","static/chunks/231-467e37449c5a68fc.js","877","static/chunks/app/%5B...slug%5D/page-1f60377561abdb46.js"],""]
8:I[4080,["231","static/chunks/231-467e37449c5a68fc.js","185","static/chunks/app/layout-b0a450f8e4964582.js"],""]
4:["slug","ai/review/2025-10-9-RLinf-VLA-A-Unified-and-Efficient-Framework-for-VLARL-Training","c"]
0:["WcxaIiCPz9cbpnkGvOjOK",[[["",{"children":[["slug","ai/review/2025-10-9-RLinf-VLA-A-Unified-and-Efficient-Framework-for-VLARL-Training","c"],{"children":["__PAGE__?{\"slug\":[\"ai\",\"review\",\"2025-10-9-RLinf-VLA-A-Unified-and-Efficient-Framework-for-VLARL-Training\"]}",{}]}]},"$undefined","$undefined",true],["",{"children":[["slug","ai/review/2025-10-9-RLinf-VLA-A-Unified-and-Efficient-Framework-for-VLARL-Training","c"],{"children":["__PAGE__",{},[["$L1","$L2"],null],null]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","$4","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},[["$","html",null,{"lang":"ko","className":"no-js","children":[["$","head",null,{"children":[["$","meta",null,{"name":"msapplication-TileColor","content":"#ffc40d"}],["$","meta",null,{"name":"theme-color","content":"#ffffff"}],["$","link",null,{"rel":"dns-prefetch","href":"https://www.googletagmanager.com"}],["$","link",null,{"rel":"preconnect","href":"https://www.googletagmanager.com","crossOrigin":"anonymous"}],["$","link",null,{"rel":"dns-prefetch","href":"https://giscus.app"}],["$","link",null,{"rel":"preconnect","href":"https://giscus.app","crossOrigin":"anonymous"}],["$","meta",null,{"httpEquiv":"X-Content-Type-Options","content":"nosniff"}],["$","meta",null,{"name":"referrer","content":"strict-origin-when-cross-origin"}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"WebSite\",\"name\":\"secrett2633's blog\",\"url\":\"https://blog.secrett2633.cloud\",\"description\":\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\",\"inLanguage\":\"ko\",\"publisher\":{\"@type\":\"Person\",\"name\":\"secrett2633\",\"url\":\"https://blog.secrett2633.cloud\"}}"}}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"Person\",\"name\":\"secrett2633\",\"url\":\"https://blog.secrett2633.cloud\",\"sameAs\":[\"https://github.com/secrett2633\"]}"}}]]}],["$","body",null,{"className":"__className_f367f3 layout--default","children":[["$","a",null,{"href":"#main-content","className":"sr-only focus:not-sr-only focus:absolute focus:z-50 focus:p-4 focus:bg-white focus:text-blue-600","children":"본문으로 건너뛰기"}],["$","div",null,{"className":"min-h-screen bg-gray-50","children":[["$","$L6",null,{}],["$","main",null,{"id":"main-content","className":"initial-content","children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","div",null,{"className":"min-h-screen flex items-center justify-center bg-gray-50","children":["$","div",null,{"className":"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center","children":[["$","h1",null,{"className":"text-6xl font-bold text-primary-600 mb-4","children":"404"}],["$","h2",null,{"className":"text-2xl font-semibold text-gray-900 mb-4","children":"페이지를 찾을 수 없습니다"}],["$","p",null,{"className":"text-gray-600 mb-8","children":"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다."}],["$","$L7",null,{"href":"/","className":"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors","children":"홈으로 돌아가기"}]]}]}],"notFoundStyles":[],"styles":null}]}],["$","div",null,{"id":"footer","className":"page__footer","children":["$","footer",null,{"className":"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8","children":["$","div",null,{"className":"text-center text-gray-500 text-sm","children":["$","p",null,{"children":["© ",2026," secrett2633. All rights reserved."]}]}]}]}]]}],["$","$L8",null,{"src":"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY","strategy":"afterInteractive"}],["$","$L8",null,{"id":"gtag-init","strategy":"afterInteractive","children":"window.dataLayer = window.dataLayer || [];\n            function gtag(){dataLayer.push(arguments);}\n            gtag('js', new Date());\n            gtag('config', 'G-NE2W3CFPNY');"}]]}]]}],null],[["$","div",null,{"className":"flex items-center justify-center min-h-screen","role":"status","aria-label":"로딩 중","children":[["$","div",null,{"className":"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600"}],["$","span",null,{"className":"sr-only","children":"로딩 중..."}]]}],[],[]]],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/ddc331716d5e47a2.css","precedence":"next","crossOrigin":"$undefined"}]],[null,"$L9"]]]]]
c:I[646,["231","static/chunks/231-467e37449c5a68fc.js","877","static/chunks/app/%5B...slug%5D/page-1f60377561abdb46.js"],"default"]
a:T448,{"@context":"https://schema.org","@type":"BlogPosting","headline":"[논문리뷰] RLinf-VLA: A Unified and Efficient Framework for VLA+RL Training","description":"이 [arXiv]에 게시한 'RLinf-VLA: A Unified and Efficient Framework for VLA+RL Training' 논문에 대한 자세한 리뷰입니다.","url":"https://blog.secrett2633.cloud/ai/review/2025-10-9-RLinf-VLA-A-Unified-and-Efficient-Framework-for-VLARL-Training","datePublished":"2025-10-09T04:45:06.000Z","dateModified":"2025-10-09T04:45:06.000Z","author":{"@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud"},"publisher":{"@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.secrett2633.cloud/ai/review/2025-10-9-RLinf-VLA-A-Unified-and-Efficient-Framework-for-VLARL-Training"},"image":"https://blog.secrett2633.cloud/og-default.png","isAccessibleForFree":true,"inLanguage":"ko","wordCount":270,"articleSection":"Review","keywords":"Review, Reinforcement Learning, VLA Models, Robotics, GPU Management, PPO, GRPO, Sim-to-Real"}b:Tcde,<blockquote>
<p><strong>링크:</strong> <a href="https://arxiv.org/abs/2510.06710" target="_blank" rel="noopener noreferrer">논문 PDF로 바로 열기</a></p>
</blockquote>
<p><strong>저자:</strong> Hongzhi Zang, Mingjie Wei, Si Xu, Yongji Wu, Zhen Guo, Yuanqing Wang, Hao Lin, Liangzhi Shi, Yuqing Xie, Zhexuan Xu, Zhihao Liu, Kang Chen, Wenhao Tang, Quanlu Zhang, Weinan Zhang, Chao Yu, Ziyi Xu, Yu Wang</p>
<h2 id="핵심-연구-목표"><a href="#핵심-연구-목표">핵심 연구 목표</a></h2>
<p>본 논문은 <strong>Vision-Language-Action (VLA) 모델</strong> 에 강화 학습(RL)을 적용할 때 발생하는 소규모 및 파편화된 실험의 문제점을 해결하고자 합니다. 대규모 실험을 지원하고 다양한 모델, 알고리즘, 평가 설정 간의 공정한 비교를 가능하게 하는 <strong>통합적이고 효율적인 프레임워크</strong> 를 제공하는 것을 목표로 합니다.</p>
<h2 id="핵심-방법론"><a href="#핵심-방법론">핵심 방법론</a></h2>
<p><strong>RLinf-VLA</strong> 프레임워크는 <strong>OpenVLA, OpenVLA-OFT</strong> 와 같은 다양한 VLA 아키텍처, <strong>PPO, GRPO</strong> 알고리즘, <strong>ManiSkill, LIBERO</strong> 시뮬레이터를 통합합니다. 특히, 렌더링, 훈련, 추론의 효율적 통합을 위해 <strong>colocated, disaggregated, hybrid</strong> 세 가지 GPU 할당 모드를 도입했으며, <strong>정교한 파이프라이닝 메커니즘</strong> 과 <strong>경량 크리틱, 손실 정규화, 액션 마스킹</strong> 등의 알고리즘적 개선을 포함합니다.</p>
<h2 id="주요-결과"><a href="#주요-결과">주요 결과</a></h2>
<p><strong>RLinf-VLA</strong> 는 기존 프레임워크 대비 <strong>2.27배</strong> 높은 처리량을 달성했으며, GPU 병렬 시뮬레이터에서는 <strong>1.61배–1.88배</strong> 의 속도 향상을 보였습니다. 시뮬레이션 환경에서 단일 통합 모델이 130개 LIBERO 태스크에서 <strong>98.11%</strong> 성공률, 25개 ManiSkill 태스크에서 <strong>97.66%</strong> 성공률을 기록했습니다. 실제 환경에서는 RL 훈련 정책이 <strong>SFT 모델 대비 우수한 제로샷 일반화 능력</strong> 을 보여주며 ( <strong>RL 8/30 성공 vs. SFT 0/30 성공</strong> ), <strong>액션 레벨 가치 추정</strong> 및 <strong>부분 리셋</strong> 이 PPO 성능에 필수적임을 입증했습니다.</p>
<h2 id="ai-실무자를-위한-시사점"><a href="#ai-실무자를-위한-시사점">AI 실무자를 위한 시사점</a></h2>
<p><strong>RLinf-VLA</strong> 는 VLA+RL 연구를 가속화하고 표준화할 수 있는 강력한 오픈소스 기반을 제공합니다. 특히, <strong>다양한 시뮬레이터 유형에 최적화된 유연한 GPU 리소스 관리 전략</strong> 을 제시하여 AI 엔지니어들이 실제 배포에서 직면하는 효율성 문제를 해결하는 데 기여합니다. 또한, <strong>PPO 및 GRPO 훈련에 대한 실용적인 모범 사례</strong> 와 <strong>Sim-to-Real 이전의 성공적인 결과</strong> 는 로봇 공학 및 embodied AI 분야의 발전을 촉진할 것입니다.</p>
<blockquote>
<p>⚠️ <strong>알림:</strong> 이 리뷰는 AI로 작성되었습니다.</p>
</blockquote>
2:[["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"$a"}}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"BreadcrumbList\",\"itemListElement\":[{\"@type\":\"ListItem\",\"position\":1,\"name\":\"홈\",\"item\":\"https://blog.secrett2633.cloud/\"},{\"@type\":\"ListItem\",\"position\":2,\"name\":\"Review\",\"item\":\"https://blog.secrett2633.cloud/ai/review\"},{\"@type\":\"ListItem\",\"position\":3,\"name\":\"[논문리뷰] RLinf-VLA: A Unified and Efficient Framework for VLA+RL Training\",\"item\":\"https://blog.secrett2633.cloud/ai/review/2025-10-9-RLinf-VLA-A-Unified-and-Efficient-Framework-for-VLARL-Training\"}]}"}}],["$","div",null,{"className":"flex flex-col lg:flex-row gap-8","children":[["$","aside",null,{"className":"lg:w-64 xl:w-72 order-1 lg:order-none","children":["$","div",null,{"className":"sidebar sticky","children":["$","nav",null,{"className":"space-y-4","aria-label":"카테고리 네비게이션","children":[["$","div","Backend",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"Backend"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Django",{"children":["$","$L7",null,{"href":"/backend/django","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Django"," (",6,")"]}]}],["$","li","Logging",{"children":["$","$L7",null,{"href":"/backend/logging","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Logging"," (",1,")"]}]}]]}]]}],["$","div","Python",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"Python"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","PEP",{"children":["$","$L7",null,{"href":"/python/pep","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["PEP"," (",650,")"]}]}]]}]]}],["$","div","AI/ML",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"AI/ML"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","LLM",{"children":["$","$L7",null,{"href":"/ai/llm","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["LLM"," (",1,")"]}]}],["$","li","Review",{"children":["$","$L7",null,{"href":"/ai/review","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Review"," (",2728,")"]}]}]]}]]}],["$","div","DevOps",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"DevOps"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Nginx",{"children":["$","$L7",null,{"href":"/devops/nginx","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Nginx"," (",1,")"]}]}],["$","li","Docker",{"children":["$","$L7",null,{"href":"/devops/docker","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Docker"," (",1,")"]}]}],["$","li","SafeLine",{"children":["$","$L7",null,{"href":"/devops/safeline","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["SafeLine"," (",1,")"]}]}],["$","li","Jenkins",{"children":["$","$L7",null,{"href":"/devops/jenkins","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Jenkins"," (",3,")"]}]}],["$","li","GitHub Actions",{"children":["$","$L7",null,{"href":"/devops/github-actions","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["GitHub Actions"," (",1,")"]}]}],["$","li","AWS",{"children":["$","$L7",null,{"href":"/devops/aws","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["AWS"," (",1,")"]}]}]]}]]}],["$","div","etc",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"etc"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Me",{"children":["$","$L7",null,{"href":"/etc/me","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Me"," (",3,")"]}]}],["$","li","Chrome Extension",{"children":["$","$L7",null,{"href":"/etc/chrome-extension","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Chrome Extension"," (",1,")"]}]}]]}]]}]]}]}]}],["$","div",null,{"className":"flex-1","children":[["$","nav",null,{"aria-label":"breadcrumb","className":"text-sm text-gray-500 mb-4","children":["$","ol",null,{"className":"flex flex-wrap items-center gap-1","children":[["$","li",null,{"children":["$","$L7",null,{"href":"/","className":"hover:text-gray-700","children":"홈"}]}],[["$","li","/ai/review",{"className":"flex items-center gap-1","children":[["$","span",null,{"aria-hidden":"true","children":"/"}],["$","$L7",null,{"href":"/ai/review","className":"hover:text-gray-700","children":"Review"}]]}],["$","li","/ai/review/2025-10-9-RLinf-VLA-A-Unified-and-Efficient-Framework-for-VLARL-Training",{"className":"flex items-center gap-1","children":[["$","span",null,{"aria-hidden":"true","children":"/"}],["$","span",null,{"className":"text-gray-900","aria-current":"page","children":"[논문리뷰] RLinf-VLA: A Unified and Efficient Framework for VLA+RL Training"}]]}]]]}]}],["$","article",null,{"className":"page","children":[["$","header",null,{"className":"mb-8","children":[["$","h1",null,{"className":"page__title","children":"[논문리뷰] RLinf-VLA: A Unified and Efficient Framework for VLA+RL Training"}],["$","div",null,{"className":"page__meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","time",null,{"className":"ml-4","dateTime":"2025-10-09T04:45:06.000Z","children":["수정: ","2025년 10월 9일"]}]]}]]}],["$","div",null,{"className":"page__content","children":["$","div",null,{"dangerouslySetInnerHTML":{"__html":"$b"}}]}],["$","footer",null,{"className":"page__meta mt-8","children":["$","div",null,{"className":"page__taxonomy","children":[["$","span",null,{"className":"text-sm font-medium text-gray-900 mb-2 block","children":"태그"}],[["$","$L7","Review",{"href":"/tags/Review","className":"page__taxonomy-item","children":["#","Review"]}],["$","$L7","Reinforcement Learning",{"href":"/tags/Reinforcement%20Learning","className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","$L7","VLA Models",{"href":"/tags/VLA%20Models","className":"page__taxonomy-item","children":["#","VLA Models"]}],["$","$L7","Robotics",{"href":"/tags/Robotics","className":"page__taxonomy-item","children":["#","Robotics"]}],["$","$L7","GPU Management",{"href":"/tags/GPU%20Management","className":"page__taxonomy-item","children":["#","GPU Management"]}],["$","$L7","PPO",{"href":"/tags/PPO","className":"page__taxonomy-item","children":["#","PPO"]}],["$","$L7","GRPO",{"href":"/tags/GRPO","className":"page__taxonomy-item","children":["#","GRPO"]}],["$","$L7","Sim-to-Real",{"href":"/tags/Sim-to-Real","className":"page__taxonomy-item","children":["#","Sim-to-Real"]}]]]}]}],["$","$Lc",null,{"postPermalink":"/ai/review/2025-10-9-RLinf-VLA-A-Unified-and-Efficient-Framework-for-VLARL-Training","postId":"2025-10-9-RLinf-VLA-A-Unified-and-Efficient-Framework-for-VLARL-Training"}],["$","section",null,{"className":"mt-12 border-t border-gray-200 pt-8","children":[["$","h3",null,{"className":"text-base font-semibold text-gray-900 mb-4","children":["Review"," 의 다른글"]}],["$","ul",null,{"className":"space-y-2 text-sm","children":[["$","li",null,{"className":"text-gray-500","children":["이전글"," ",["$","$L7",null,{"href":"/ai/review/2025-10-9-Pushing-on-Multilingual-Reasoning-Models-with-Language-Mixed-Chain-of-Thought","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] Pushing on Multilingual Reasoning Models with Language-Mixed Chain-of-Thought"}]]}],["$","li",null,{"className":"text-gray-900 font-semibold","children":["현재글 : ","[논문리뷰] RLinf-VLA: A Unified and Efficient Framework for VLA+RL Training"]}],["$","li",null,{"className":"text-gray-500","children":["다음글"," ",["$","$L7",null,{"href":"/ai/review/2025-10-9-Revisiting-Long-context-Modeling-from-Context-Denoising-Perspective","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] Revisiting Long-context Modeling from Context Denoising Perspective"}]]}]]}]]}]]}]]}]]}]]
9:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"[논문리뷰] RLinf-VLA: A Unified and Efficient Framework for VLA+RL Training - secrett2633's blog"}],["$","meta","3",{"name":"description","content":"이 [arXiv]에 게시한 'RLinf-VLA: A Unified and Efficient Framework for VLA+RL Training' 논문에 대한 자세한 리뷰입니다."}],["$","meta","4",{"name":"author","content":"secrett2633"}],["$","link","5",{"rel":"manifest","href":"/manifest.json","crossOrigin":"use-credentials"}],["$","meta","6",{"name":"keywords","content":"Django, Python, DevOps, AI, ML, 블로그, 기술"}],["$","meta","7",{"name":"creator","content":"secrett2633"}],["$","meta","8",{"name":"publisher","content":"secrett2633"}],["$","meta","9",{"name":"robots","content":"index, follow"}],["$","meta","10",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","11",{"rel":"canonical","href":"https://blog.secrett2633.cloud/ai/review/2025-10-9-RLinf-VLA-A-Unified-and-Efficient-Framework-for-VLARL-Training"}],["$","meta","12",{"name":"format-detection","content":"telephone=no, address=no, email=no"}],["$","meta","13",{"property":"og:title","content":"[논문리뷰] RLinf-VLA: A Unified and Efficient Framework for VLA+RL Training"}],["$","meta","14",{"property":"og:description","content":"이 [arXiv]에 게시한 'RLinf-VLA: A Unified and Efficient Framework for VLA+RL Training' 논문에 대한 자세한 리뷰입니다."}],["$","meta","15",{"property":"og:url","content":"https://blog.secrett2633.cloud/ai/review/2025-10-9-RLinf-VLA-A-Unified-and-Efficient-Framework-for-VLARL-Training"}],["$","meta","16",{"property":"og:type","content":"article"}],["$","meta","17",{"property":"article:published_time","content":"2025-10-09T04:45:06.000Z"}],["$","meta","18",{"property":"article:modified_time","content":"2025-10-09T04:45:06.000Z"}],["$","meta","19",{"property":"article:author","content":"secrett2633"}],["$","meta","20",{"property":"article:section","content":"Review"}],["$","meta","21",{"property":"article:tag","content":"Review"}],["$","meta","22",{"property":"article:tag","content":"Reinforcement Learning"}],["$","meta","23",{"property":"article:tag","content":"VLA Models"}],["$","meta","24",{"property":"article:tag","content":"Robotics"}],["$","meta","25",{"property":"article:tag","content":"GPU Management"}],["$","meta","26",{"property":"article:tag","content":"PPO"}],["$","meta","27",{"property":"article:tag","content":"GRPO"}],["$","meta","28",{"property":"article:tag","content":"Sim-to-Real"}],["$","meta","29",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","30",{"name":"twitter:creator","content":"@secrett2633"}],["$","meta","31",{"name":"twitter:title","content":"[논문리뷰] RLinf-VLA: A Unified and Efficient Framework for VLA+RL Training"}],["$","meta","32",{"name":"twitter:description","content":"이 [arXiv]에 게시한 'RLinf-VLA: A Unified and Efficient Framework for VLA+RL Training' 논문에 대한 자세한 리뷰입니다."}],["$","link","33",{"rel":"icon","href":"/icon.ico?6d9f34d4948640b8","type":"image/x-icon","sizes":"16x16"}],["$","meta","34",{"name":"next-size-adjust"}]]
1:null
