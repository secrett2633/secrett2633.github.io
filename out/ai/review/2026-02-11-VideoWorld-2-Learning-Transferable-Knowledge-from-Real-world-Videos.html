<!DOCTYPE html><html lang="ko" class="no-js"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/edb8d4ad4fe2f3b0.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-90b03762f46d1ba4.js"/><script src="/_next/static/chunks/fd9d1056-4b0d66bdf1ba1813.js" async=""></script><script src="/_next/static/chunks/23-41c976638cd1a58c.js" async=""></script><script src="/_next/static/chunks/main-app-6087bc228fd56b83.js" async=""></script><script src="/_next/static/chunks/231-ee5764c1002761f9.js" async=""></script><script src="/_next/static/chunks/132-273e49420772df1e.js" async=""></script><script src="/_next/static/chunks/app/layout-d443cbc354279241.js" async=""></script><script src="/_next/static/chunks/app/%5B...slug%5D/page-ef33f0f4c1a350bd.js" async=""></script><link rel="preload" href="https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY" as="script"/><title>[논문리뷰] VideoWorld 2: Learning Transferable Knowledge from Real-world Videos - secrett2633&#x27;s blog</title><meta name="description" content="arXiv에 게시된 &#x27;VideoWorld 2: Learning Transferable Knowledge from Real-world Videos&#x27; 논문에 대한 자세한 리뷰입니다."/><meta name="author" content="secrett2633"/><link rel="manifest" href="/manifest.json" crossorigin="use-credentials"/><meta name="keywords" content="Django, Python, DevOps, AI, ML, 블로그, 기술"/><meta name="creator" content="secrett2633"/><meta name="publisher" content="secrett2633"/><meta name="robots" content="index, follow"/><meta name="googlebot" content="index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"/><link rel="canonical" href="https://blog.secrett2633.cloud/ai/review/2026-02-11-VideoWorld-2-Learning-Transferable-Knowledge-from-Real-world-Videos"/><meta name="format-detection" content="telephone=no, address=no, email=no"/><meta property="og:title" content="[논문리뷰] VideoWorld 2: Learning Transferable Knowledge from Real-world Videos"/><meta property="og:description" content="arXiv에 게시된 &#x27;VideoWorld 2: Learning Transferable Knowledge from Real-world Videos&#x27; 논문에 대한 자세한 리뷰입니다."/><meta property="og:url" content="https://blog.secrett2633.cloud/ai/review/2026-02-11-VideoWorld-2-Learning-Transferable-Knowledge-from-Real-world-Videos"/><meta property="og:type" content="article"/><meta property="article:published_time" content="2026-02-10T15:00:00.000Z"/><meta property="article:modified_time" content="2026-02-10T15:00:00.000Z"/><meta property="article:author" content="secrett2633"/><meta property="article:section" content="Review"/><meta property="article:tag" content="Review"/><meta property="article:tag" content="Transferable Knowledge"/><meta property="article:tag" content="Real-world Video Learning"/><meta property="article:tag" content="Latent Dynamics Model"/><meta property="article:tag" content="Video Diffusion"/><meta property="article:tag" content="Robotics Manipulation"/><meta property="article:tag" content="Long-horizon Tasks"/><meta property="article:tag" content="Unlabeled Data"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:creator" content="@secrett2633"/><meta name="twitter:title" content="[논문리뷰] VideoWorld 2: Learning Transferable Knowledge from Real-world Videos"/><meta name="twitter:description" content="arXiv에 게시된 &#x27;VideoWorld 2: Learning Transferable Knowledge from Real-world Videos&#x27; 논문에 대한 자세한 리뷰입니다."/><link rel="icon" href="/icon.ico?6d9f34d4948640b8" type="image/x-icon" sizes="16x16"/><meta name="next-size-adjust"/><meta name="msapplication-TileColor" content="#ffc40d"/><meta name="theme-color" content="#ffffff"/><link rel="dns-prefetch" href="https://www.googletagmanager.com"/><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"/><link rel="dns-prefetch" href="https://giscus.app"/><link rel="preconnect" href="https://giscus.app" crossorigin="anonymous"/><meta http-equiv="X-Content-Type-Options" content="nosniff"/><meta name="referrer" content="strict-origin-when-cross-origin"/><script type="application/ld+json">{"@context":"https://schema.org","@type":"WebSite","name":"secrett2633's blog","url":"https://blog.secrett2633.cloud","description":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트","inLanguage":"ko","publisher":{"@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud"}}</script><script type="application/ld+json">{"@context":"https://schema.org","@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud","sameAs":["https://github.com/secrett2633"]}</script><script src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body class="__className_f367f3 layout--default"><a href="#main-content" class="sr-only focus:not-sr-only focus:absolute focus:z-50 focus:p-4 focus:bg-white focus:text-blue-600">본문으로 건너뛰기</a><div class="min-h-screen bg-gray-50"><div class="masthead"><div class="masthead__inner-wrap"><div class="masthead__menu"><nav id="site-nav" class="greedy-nav" aria-label="메인 네비게이션"><a class="site-title" href="/">secrett2633&#x27;s blog</a><div class="flex items-center space-x-4"><ul class="visible-links"><li class="masthead__menu-item"><a href="https://github.com/secrett2633" target="_blank" rel="noopener noreferrer">GitHub</a></li></ul><button class="search__toggle" type="button" aria-label="검색"><svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16"><path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path></svg></button></div></nav></div></div></div><main id="main-content" class="initial-content"><!--$--><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","headline":"[논문리뷰] VideoWorld 2: Learning Transferable Knowledge from Real-world Videos","description":"arXiv에 게시된 'VideoWorld 2: Learning Transferable Knowledge from Real-world Videos' 논문에 대한 자세한 리뷰입니다.","url":"https://blog.secrett2633.cloud/ai/review/2026-02-11-VideoWorld-2-Learning-Transferable-Knowledge-from-Real-world-Videos","datePublished":"2026-02-10T15:00:00.000Z","dateModified":"2026-02-10T15:00:00.000Z","author":{"@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud"},"publisher":{"@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.secrett2633.cloud/ai/review/2026-02-11-VideoWorld-2-Learning-Transferable-Knowledge-from-Real-world-Videos"},"image":"https://blog.secrett2633.cloud/og-default.png","isAccessibleForFree":true,"inLanguage":"ko","wordCount":256,"articleSection":"Review","keywords":"Review, Transferable Knowledge, Real-world Video Learning, Latent Dynamics Model, Video Diffusion, Robotics Manipulation, Long-horizon Tasks, Unlabeled Data"}</script><script type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"홈","item":"https://blog.secrett2633.cloud/"},{"@type":"ListItem","position":2,"name":"Review","item":"https://blog.secrett2633.cloud/ai/review"},{"@type":"ListItem","position":3,"name":"[논문리뷰] VideoWorld 2: Learning Transferable Knowledge from Real-world Videos","item":"https://blog.secrett2633.cloud/ai/review/2026-02-11-VideoWorld-2-Learning-Transferable-Knowledge-from-Real-world-Videos"}]}</script><div class="space-y-6"><div class="flex flex-col lg:flex-row gap-8"><aside class="lg:w-64 xl:w-72 order-1 lg:order-none"><div class="sidebar sticky"><nav class="space-y-4" aria-label="카테고리 네비게이션"><div><p class="font-medium text-gray-900 mb-2">Backend</p><ul class="space-y-1 ml-4"><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/backend/django">Django<!-- --> (<!-- -->6<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/backend/logging">Logging<!-- --> (<!-- -->1<!-- -->)</a></li></ul></div><div><p class="font-medium text-gray-900 mb-2">Python</p><ul class="space-y-1 ml-4"><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/python/pep">PEP<!-- --> (<!-- -->650<!-- -->)</a></li></ul></div><div><p class="font-medium text-gray-900 mb-2">AI/ML</p><ul class="space-y-1 ml-4"><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/ai/llm">LLM<!-- --> (<!-- -->1<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/ai/review">Review<!-- --> (<!-- -->2741<!-- -->)</a></li></ul></div><div><p class="font-medium text-gray-900 mb-2">DevOps</p><ul class="space-y-1 ml-4"><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/devops/nginx">Nginx<!-- --> (<!-- -->1<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/devops/docker">Docker<!-- --> (<!-- -->1<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/devops/safeline">SafeLine<!-- --> (<!-- -->1<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/devops/jenkins">Jenkins<!-- --> (<!-- -->3<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/devops/github-actions">GitHub Actions<!-- --> (<!-- -->1<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/devops/aws">AWS<!-- --> (<!-- -->1<!-- -->)</a></li></ul></div><div><p class="font-medium text-gray-900 mb-2">etc</p><ul class="space-y-1 ml-4"><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/etc/me">Me<!-- --> (<!-- -->3<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/etc/chrome-extension">Chrome Extension<!-- --> (<!-- -->1<!-- -->)</a></li></ul></div></nav></div></aside><div class="flex-1"><nav aria-label="breadcrumb" class="text-sm text-gray-500 mb-4"><ol class="flex flex-wrap items-center gap-1"><li><a class="hover:text-gray-700" href="/">홈</a></li><li class="flex items-center gap-1"><span aria-hidden="true">/</span><a class="hover:text-gray-700" href="/ai/review">Review</a></li><li class="flex items-center gap-1"><span aria-hidden="true">/</span><span class="text-gray-900" aria-current="page">[논문리뷰] VideoWorld 2: Learning Transferable Knowledge from Real-world Videos</span></li></ol></nav><article class="page"><header class="mb-8"><h1 class="page__title">[논문리뷰] VideoWorld 2: Learning Transferable Knowledge from Real-world Videos</h1><div class="page__meta"><time dateTime="2026-02-11 00:00:00+0900+0900">2026년 2월 11일</time><time class="ml-4" dateTime="2026-02-10T15:00:00.000Z">수정: <!-- -->2026년 2월 11일</time></div></header><div class="page__content"><div><blockquote>
<p><strong>링크:</strong> <a href="https://arxiv.org/abs/2602.10102" target="_blank" rel="noopener noreferrer">논문 PDF로 바로 열기</a></p>
</blockquote>
<p><strong>저자:</strong> Zhongwei Ren, Yunchao Wei, Xiao Yu, Guixun Luo, Yao Zhao, Bingyi Kang, Jiashi Feng, Xiaojie Jin</p>
<h2 id="핵심-연구-목표"><a href="#핵심-연구-목표">핵심 연구 목표</a></h2>
<p>본 연구는 복잡하고 장기적인 태스크를 위해 레이블이 없는 <strong>실세계 비디오 데이터</strong> 로부터 전이 가능한 지식을 학습하는 것을 목표로 합니다. 기존 VideoWorld 모델이 실세계 비디오의 시각적 다양성, 복잡한 액션 다이내믹스, 장기 상호작용 처리에서 겪는 한계를 극복하고, 외형 모델링과 액션 학습을 명확히 분리하여 강건한 일반화 능력을 확보하고자 합니다.</p>
<h2 id="핵심-방법론"><a href="#핵심-방법론">핵심 방법론</a></h2>
<p>핵심 방법론은 액션 다이내믹스를 시각적 외형과 분리하는 <strong>dynamics-enhanced Latent Dynamics Model (dLDM)</strong> 입니다. <strong>사전 훈련된 Video Diffusion Model (VDM)</strong> 이 시각적 외형 모델링을 담당하고, <strong>인과적 VQ-VAE</strong> 는 미래 시각 변화로부터 태스크 관련 다이내믹스를 포착하는 압축된 잠재 코드를 학습합니다. 이 잠재 코드는 <strong>자기회귀(autoregressive) Transformer</strong> 에 의해 모델링되어 태스크 정책을 학습하고 장기적인 추론을 지원합니다.</p>
<h2 id="주요-결과"><a href="#주요-결과">주요 결과</a></h2>
<p><strong>Video-CraftBench</strong> 에서 <strong>VideoWorld 2</strong> 는 기존 방법론 대비 태스크 성공률에서 <strong>최대 70% 향상</strong> 을 달성했으며, 장기 종이 접기 태스크에서 <strong>68.8%</strong> , 블록 쌓기 태스크에서 <strong>81.5%</strong> 의 최종 단계 성공률을 보였습니다. <strong>Open-X 데이터셋</strong> 으로 사전 훈련 후 <strong>CALVIN 환경</strong> 에서 미세 조정했을 때, 장기 태스크에서 <strong>72.3%</strong> 의 최종 단계 성공률을 기록하며 강력한 도메인 간 일반화 능력과 높은 시각적 품질을 입증했습니다.</p>
<h2 id="ai-실무자를-위한-시사점"><a href="#ai-실무자를-위한-시사점">AI 실무자를 위한 시사점</a></h2>
<p>본 연구는 <strong>레이블이 없는 실세계 비디오</strong> 에서 <strong>전이 가능한 지식</strong> 을 학습하는 데 있어 <strong>외형과 다이내믹스 분리</strong> 의 중요성을 강조합니다. 제안된 <strong>dLDM 아키텍처</strong> 는 복잡한 조작 및 장기 계획이 필요한 <strong>로봇 공학 태스크</strong> 에 효율적으로 적용될 수 있습니다. <strong>Video-CraftBench</strong> 와 같은 새로운 벤치마크는 실제 환경에서 <strong>미세한 조작 및 장기 비주얼 추론</strong> 연구를 촉진하여, 향후 AI 에이전트 개발에 중요한 기반을 제공합니다.</p>
<blockquote>
<p>⚠️ <strong>알림:</strong> 이 리뷰는 AI로 작성되었습니다.</p>
</blockquote>
</div></div><footer class="page__meta mt-8"><div class="page__taxonomy"><span class="text-sm font-medium text-gray-900 mb-2 block">태그</span><a class="page__taxonomy-item" href="/tags/Review">#<!-- -->Review</a><a class="page__taxonomy-item" href="/tags/Transferable%20Knowledge">#<!-- -->Transferable Knowledge</a><a class="page__taxonomy-item" href="/tags/Real-world%20Video%20Learning">#<!-- -->Real-world Video Learning</a><a class="page__taxonomy-item" href="/tags/Latent%20Dynamics%20Model">#<!-- -->Latent Dynamics Model</a><a class="page__taxonomy-item" href="/tags/Video%20Diffusion">#<!-- -->Video Diffusion</a><a class="page__taxonomy-item" href="/tags/Robotics%20Manipulation">#<!-- -->Robotics Manipulation</a><a class="page__taxonomy-item" href="/tags/Long-horizon%20Tasks">#<!-- -->Long-horizon Tasks</a><a class="page__taxonomy-item" href="/tags/Unlabeled%20Data">#<!-- -->Unlabeled Data</a></div></footer><section class="comments-section mt-12 pt-8 border-t border-gray-200"></section><section class="mt-12 border-t border-gray-200 pt-8"><h3 class="text-base font-semibold text-gray-900 mb-4">Review<!-- --> 의 다른글</h3><ul class="space-y-2 text-sm"><li class="text-gray-500">이전글<!-- --> <a class="text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4" href="/ai/review/2026-02-11-VLA-JEPA-Enhancing-Vision-Language-Action-Model-with-Latent-World-Model">[논문리뷰] VLA-JEPA: Enhancing Vision-Language-Action Model with Latent World Model</a></li><li class="text-gray-900 font-semibold">현재글 : <!-- -->[논문리뷰] VideoWorld 2: Learning Transferable Knowledge from Real-world Videos</li><li class="text-gray-500">다음글<!-- --> <a class="text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4" href="/ai/review/2026-02-12-ASA-Training-Free-Representation-Engineering-for-Tool-Calling-Agents">[논문리뷰] ASA: Training-Free Representation Engineering for Tool-Calling Agents</a></li></ul></section></article></div></div></div><!--/$--></main><div id="footer" class="page__footer"><footer class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8"><div class="text-center text-gray-500 text-sm"><p>© <!-- -->2026<!-- --> secrett2633. All rights reserved.</p></div></footer></div></div><script src="/_next/static/chunks/webpack-90b03762f46d1ba4.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/media/e4af272ccee01ff0-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n2:HL[\"/_next/static/css/edb8d4ad4fe2f3b0.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"3:I[5751,[],\"\"]\n6:I[9275,[],\"\"]\n8:I[1343,[],\"\"]\n9:I[9157,[\"231\",\"static/chunks/231-ee5764c1002761f9.js\",\"132\",\"static/chunks/132-273e49420772df1e.js\",\"185\",\"static/chunks/app/layout-d443cbc354279241.js\"],\"default\"]\na:I[231,[\"231\",\"static/chunks/231-ee5764c1002761f9.js\",\"877\",\"static/chunks/app/%5B...slug%5D/page-ef33f0f4c1a350bd.js\"],\"\"]\nb:I[4080,[\"231\",\"static/chunks/231-ee5764c1002761f9.js\",\"132\",\"static/chunks/132-273e49420772df1e.js\",\"185\",\"static/chunks/app/layout-d443cbc354279241.js\"],\"\"]\nd:I[6130,[],\"\"]\n7:[\"slug\",\"ai/review/2026-02-11-VideoWorld-2-Learning-Transferable-Knowledge-from-Real-world-Videos\",\"c\"]\ne:[]\n"])</script><script>self.__next_f.push([1,"0:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/edb8d4ad4fe2f3b0.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L3\",null,{\"buildId\":\"mJI0q5Z-SQWBtT83kG_N7\",\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/ai/review/2026-02-11-VideoWorld-2-Learning-Transferable-Knowledge-from-Real-world-Videos\",\"initialTree\":[\"\",{\"children\":[[\"slug\",\"ai/review/2026-02-11-VideoWorld-2-Learning-Transferable-Knowledge-from-Real-world-Videos\",\"c\"],{\"children\":[\"__PAGE__?{\\\"slug\\\":[\\\"ai\\\",\\\"review\\\",\\\"2026-02-11-VideoWorld-2-Learning-Transferable-Knowledge-from-Real-world-Videos\\\"]}\",{}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[[\"slug\",\"ai/review/2026-02-11-VideoWorld-2-Learning-Transferable-Knowledge-from-Real-world-Videos\",\"c\"],{\"children\":[\"__PAGE__\",{},[[\"$L4\",\"$L5\"],null],null]},[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"$7\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}],null]},[[\"$\",\"html\",null,{\"lang\":\"ko\",\"className\":\"no-js\",\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"meta\",null,{\"name\":\"msapplication-TileColor\",\"content\":\"#ffc40d\"}],[\"$\",\"meta\",null,{\"name\":\"theme-color\",\"content\":\"#ffffff\"}],[\"$\",\"link\",null,{\"rel\":\"dns-prefetch\",\"href\":\"https://www.googletagmanager.com\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://www.googletagmanager.com\",\"crossOrigin\":\"anonymous\"}],[\"$\",\"link\",null,{\"rel\":\"dns-prefetch\",\"href\":\"https://giscus.app\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://giscus.app\",\"crossOrigin\":\"anonymous\"}],[\"$\",\"meta\",null,{\"httpEquiv\":\"X-Content-Type-Options\",\"content\":\"nosniff\"}],[\"$\",\"meta\",null,{\"name\":\"referrer\",\"content\":\"strict-origin-when-cross-origin\"}],[\"$\",\"script\",null,{\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"{\\\"@context\\\":\\\"https://schema.org\\\",\\\"@type\\\":\\\"WebSite\\\",\\\"name\\\":\\\"secrett2633's blog\\\",\\\"url\\\":\\\"https://blog.secrett2633.cloud\\\",\\\"description\\\":\\\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\\\",\\\"inLanguage\\\":\\\"ko\\\",\\\"publisher\\\":{\\\"@type\\\":\\\"Person\\\",\\\"name\\\":\\\"secrett2633\\\",\\\"url\\\":\\\"https://blog.secrett2633.cloud\\\"}}\"}}],[\"$\",\"script\",null,{\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"{\\\"@context\\\":\\\"https://schema.org\\\",\\\"@type\\\":\\\"Person\\\",\\\"name\\\":\\\"secrett2633\\\",\\\"url\\\":\\\"https://blog.secrett2633.cloud\\\",\\\"sameAs\\\":[\\\"https://github.com/secrett2633\\\"]}\"}}]]}],[\"$\",\"body\",null,{\"className\":\"__className_f367f3 layout--default\",\"children\":[[\"$\",\"a\",null,{\"href\":\"#main-content\",\"className\":\"sr-only focus:not-sr-only focus:absolute focus:z-50 focus:p-4 focus:bg-white focus:text-blue-600\",\"children\":\"본문으로 건너뛰기\"}],[\"$\",\"div\",null,{\"className\":\"min-h-screen bg-gray-50\",\"children\":[[\"$\",\"$L9\",null,{}],[\"$\",\"main\",null,{\"id\":\"main-content\",\"className\":\"initial-content\",\"children\":[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[\"$\",\"div\",null,{\"className\":\"min-h-screen flex items-center justify-center bg-gray-50\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-6xl font-bold text-primary-600 mb-4\",\"children\":\"404\"}],[\"$\",\"h2\",null,{\"className\":\"text-2xl font-semibold text-gray-900 mb-4\",\"children\":\"페이지를 찾을 수 없습니다\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-600 mb-8\",\"children\":\"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다.\"}],[\"$\",\"$La\",null,{\"href\":\"/\",\"className\":\"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors\",\"children\":\"홈으로 돌아가기\"}]]}]}],\"notFoundStyles\":[],\"styles\":null}]}],[\"$\",\"div\",null,{\"id\":\"footer\",\"className\":\"page__footer\",\"children\":[\"$\",\"footer\",null,{\"className\":\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"text-center text-gray-500 text-sm\",\"children\":[\"$\",\"p\",null,{\"children\":[\"© \",2026,\" secrett2633. All rights reserved.\"]}]}]}]}]]}],[\"$\",\"$Lb\",null,{\"src\":\"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY\",\"strategy\":\"afterInteractive\"}],[\"$\",\"$Lb\",null,{\"id\":\"gtag-init\",\"strategy\":\"afterInteractive\",\"children\":\"window.dataLayer = window.dataLayer || [];\\n            function gtag(){dataLayer.push(arguments);}\\n            gtag('js', new Date());\\n            gtag('config', 'G-NE2W3CFPNY');\"}]]}]]}],null],[[\"$\",\"div\",null,{\"className\":\"flex items-center justify-center min-h-screen\",\"role\":\"status\",\"aria-label\":\"로딩 중\",\"children\":[[\"$\",\"div\",null,{\"className\":\"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600\"}],[\"$\",\"span\",null,{\"className\":\"sr-only\",\"children\":\"로딩 중...\"}]]}],[],[]]],\"couldBeIntercepted\":false,\"initialHead\":[null,\"$Lc\"],\"globalErrorComponent\":\"$d\",\"missingSlots\":\"$We\"}]]\n"])</script><script>self.__next_f.push([1,"11:I[646,[\"231\",\"static/chunks/231-ee5764c1002761f9.js\",\"877\",\"static/chunks/app/%5B...slug%5D/page-ef33f0f4c1a350bd.js\"],\"default\"]\nf:T496,{\"@context\":\"https://schema.org\",\"@type\":\"BlogPosting\",\"headline\":\"[논문리뷰] VideoWorld 2: Learning Transferable Knowledge from Real-world Videos\",\"description\":\"arXiv에 게시된 'VideoWorld 2: Learning Transferable Knowledge from Real-world Videos' 논문에 대한 자세한 리뷰입니다.\",\"url\":\"https://blog.secrett2633.cloud/ai/review/2026-02-11-VideoWorld-2-Learning-Transferable-Knowledge-from-Real-world-Videos\",\"datePublished\":\"2026-02-10T15:00:00.000Z\",\"dateModified\":\"2026-02-10T15:00:00.000Z\",\"author\":{\"@type\":\"Person\",\"name\":\"secrett2633\",\"url\":\"https://blog.secrett2633.cloud\"},\"publisher\":{\"@type\":\"Person\",\"name\":\"secrett2633\",\"url\":\"https://blog.secrett2633.cloud\"},\"mainEntityOfPage\":{\"@type\":\"WebPage\",\"@id\":\"https://blog.secrett2633.cloud/ai/review/2026-02-11-VideoWorld-2-Learning-Transferable-Knowledge-from-Real-world-Videos\"},\"image\":\"https://blog.secrett2633.cloud/og-default.png\",\"isAccessibleForFree\":true,\"inLanguage\":\"ko\",\"wordCount\":256,\"articleSection\":\"Review\",\"keywords\":\"Review, Transferable Knowledge, Real-world Video Learning, Latent Dynamics Model, Video Diffusion, Robotics Manipulation, Long-horizon Tasks, Unlabeled Data\"}10:Tc96,"])</script><script>self.__next_f.push([1,"\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e링크:\u003c/strong\u003e \u003ca href=\"https://arxiv.org/abs/2602.10102\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e논문 PDF로 바로 열기\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003e저자:\u003c/strong\u003e Zhongwei Ren, Yunchao Wei, Xiao Yu, Guixun Luo, Yao Zhao, Bingyi Kang, Jiashi Feng, Xiaojie Jin\u003c/p\u003e\n\u003ch2 id=\"핵심-연구-목표\"\u003e\u003ca href=\"#핵심-연구-목표\"\u003e핵심 연구 목표\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003e본 연구는 복잡하고 장기적인 태스크를 위해 레이블이 없는 \u003cstrong\u003e실세계 비디오 데이터\u003c/strong\u003e 로부터 전이 가능한 지식을 학습하는 것을 목표로 합니다. 기존 VideoWorld 모델이 실세계 비디오의 시각적 다양성, 복잡한 액션 다이내믹스, 장기 상호작용 처리에서 겪는 한계를 극복하고, 외형 모델링과 액션 학습을 명확히 분리하여 강건한 일반화 능력을 확보하고자 합니다.\u003c/p\u003e\n\u003ch2 id=\"핵심-방법론\"\u003e\u003ca href=\"#핵심-방법론\"\u003e핵심 방법론\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003e핵심 방법론은 액션 다이내믹스를 시각적 외형과 분리하는 \u003cstrong\u003edynamics-enhanced Latent Dynamics Model (dLDM)\u003c/strong\u003e 입니다. \u003cstrong\u003e사전 훈련된 Video Diffusion Model (VDM)\u003c/strong\u003e 이 시각적 외형 모델링을 담당하고, \u003cstrong\u003e인과적 VQ-VAE\u003c/strong\u003e 는 미래 시각 변화로부터 태스크 관련 다이내믹스를 포착하는 압축된 잠재 코드를 학습합니다. 이 잠재 코드는 \u003cstrong\u003e자기회귀(autoregressive) Transformer\u003c/strong\u003e 에 의해 모델링되어 태스크 정책을 학습하고 장기적인 추론을 지원합니다.\u003c/p\u003e\n\u003ch2 id=\"주요-결과\"\u003e\u003ca href=\"#주요-결과\"\u003e주요 결과\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eVideo-CraftBench\u003c/strong\u003e 에서 \u003cstrong\u003eVideoWorld 2\u003c/strong\u003e 는 기존 방법론 대비 태스크 성공률에서 \u003cstrong\u003e최대 70% 향상\u003c/strong\u003e 을 달성했으며, 장기 종이 접기 태스크에서 \u003cstrong\u003e68.8%\u003c/strong\u003e , 블록 쌓기 태스크에서 \u003cstrong\u003e81.5%\u003c/strong\u003e 의 최종 단계 성공률을 보였습니다. \u003cstrong\u003eOpen-X 데이터셋\u003c/strong\u003e 으로 사전 훈련 후 \u003cstrong\u003eCALVIN 환경\u003c/strong\u003e 에서 미세 조정했을 때, 장기 태스크에서 \u003cstrong\u003e72.3%\u003c/strong\u003e 의 최종 단계 성공률을 기록하며 강력한 도메인 간 일반화 능력과 높은 시각적 품질을 입증했습니다.\u003c/p\u003e\n\u003ch2 id=\"ai-실무자를-위한-시사점\"\u003e\u003ca href=\"#ai-실무자를-위한-시사점\"\u003eAI 실무자를 위한 시사점\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003e본 연구는 \u003cstrong\u003e레이블이 없는 실세계 비디오\u003c/strong\u003e 에서 \u003cstrong\u003e전이 가능한 지식\u003c/strong\u003e 을 학습하는 데 있어 \u003cstrong\u003e외형과 다이내믹스 분리\u003c/strong\u003e 의 중요성을 강조합니다. 제안된 \u003cstrong\u003edLDM 아키텍처\u003c/strong\u003e 는 복잡한 조작 및 장기 계획이 필요한 \u003cstrong\u003e로봇 공학 태스크\u003c/strong\u003e 에 효율적으로 적용될 수 있습니다. \u003cstrong\u003eVideo-CraftBench\u003c/strong\u003e 와 같은 새로운 벤치마크는 실제 환경에서 \u003cstrong\u003e미세한 조작 및 장기 비주얼 추론\u003c/strong\u003e 연구를 촉진하여, 향후 AI 에이전트 개발에 중요한 기반을 제공합니다.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e⚠️ \u003cstrong\u003e알림:\u003c/strong\u003e 이 리뷰는 AI로 작성되었습니다.\u003c/p\u003e\n\u003c/blockquote\u003e\n"])</script><script>self.__next_f.push([1,"5:[[\"$\",\"script\",null,{\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"$f\"}}],[\"$\",\"script\",null,{\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"{\\\"@context\\\":\\\"https://schema.org\\\",\\\"@type\\\":\\\"BreadcrumbList\\\",\\\"itemListElement\\\":[{\\\"@type\\\":\\\"ListItem\\\",\\\"position\\\":1,\\\"name\\\":\\\"홈\\\",\\\"item\\\":\\\"https://blog.secrett2633.cloud/\\\"},{\\\"@type\\\":\\\"ListItem\\\",\\\"position\\\":2,\\\"name\\\":\\\"Review\\\",\\\"item\\\":\\\"https://blog.secrett2633.cloud/ai/review\\\"},{\\\"@type\\\":\\\"ListItem\\\",\\\"position\\\":3,\\\"name\\\":\\\"[논문리뷰] VideoWorld 2: Learning Transferable Knowledge from Real-world Videos\\\",\\\"item\\\":\\\"https://blog.secrett2633.cloud/ai/review/2026-02-11-VideoWorld-2-Learning-Transferable-Knowledge-from-Real-world-Videos\\\"}]}\"}}],[\"$\",\"div\",null,{\"className\":\"space-y-6\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex flex-col lg:flex-row gap-8\",\"children\":[[\"$\",\"aside\",null,{\"className\":\"lg:w-64 xl:w-72 order-1 lg:order-none\",\"children\":[\"$\",\"div\",null,{\"className\":\"sidebar sticky\",\"children\":[\"$\",\"nav\",null,{\"className\":\"space-y-4\",\"aria-label\":\"카테고리 네비게이션\",\"children\":[[\"$\",\"div\",\"Backend\",{\"children\":[[\"$\",\"p\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"Backend\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"Django\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/backend/django\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Django\",\" (\",6,\")\"]}]}],[\"$\",\"li\",\"Logging\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/backend/logging\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Logging\",\" (\",1,\")\"]}]}]]}]]}],[\"$\",\"div\",\"Python\",{\"children\":[[\"$\",\"p\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"Python\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"PEP\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/python/pep\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"PEP\",\" (\",650,\")\"]}]}]]}]]}],[\"$\",\"div\",\"AI/ML\",{\"children\":[[\"$\",\"p\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"AI/ML\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"LLM\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/ai/llm\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"LLM\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"Review\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/ai/review\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Review\",\" (\",2741,\")\"]}]}]]}]]}],[\"$\",\"div\",\"DevOps\",{\"children\":[[\"$\",\"p\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"DevOps\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"Nginx\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/devops/nginx\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Nginx\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"Docker\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/devops/docker\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Docker\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"SafeLine\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/devops/safeline\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"SafeLine\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"Jenkins\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/devops/jenkins\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Jenkins\",\" (\",3,\")\"]}]}],[\"$\",\"li\",\"GitHub Actions\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/devops/github-actions\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"GitHub Actions\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"AWS\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/devops/aws\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"AWS\",\" (\",1,\")\"]}]}]]}]]}],[\"$\",\"div\",\"etc\",{\"children\":[[\"$\",\"p\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"etc\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"Me\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/etc/me\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Me\",\" (\",3,\")\"]}]}],[\"$\",\"li\",\"Chrome Extension\",{\"children\":[\"$\",\"$La\",null,{\"href\":\"/etc/chrome-extension\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Chrome Extension\",\" (\",1,\")\"]}]}]]}]]}]]}]}]}],[\"$\",\"div\",null,{\"className\":\"flex-1\",\"children\":[[\"$\",\"nav\",null,{\"aria-label\":\"breadcrumb\",\"className\":\"text-sm text-gray-500 mb-4\",\"children\":[\"$\",\"ol\",null,{\"className\":\"flex flex-wrap items-center gap-1\",\"children\":[[\"$\",\"li\",null,{\"children\":[\"$\",\"$La\",null,{\"href\":\"/\",\"className\":\"hover:text-gray-700\",\"children\":\"홈\"}]}],[[\"$\",\"li\",\"/ai/review\",{\"className\":\"flex items-center gap-1\",\"children\":[[\"$\",\"span\",null,{\"aria-hidden\":\"true\",\"children\":\"/\"}],[\"$\",\"$La\",null,{\"href\":\"/ai/review\",\"className\":\"hover:text-gray-700\",\"children\":\"Review\"}]]}],[\"$\",\"li\",\"/ai/review/2026-02-11-VideoWorld-2-Learning-Transferable-Knowledge-from-Real-world-Videos\",{\"className\":\"flex items-center gap-1\",\"children\":[[\"$\",\"span\",null,{\"aria-hidden\":\"true\",\"children\":\"/\"}],[\"$\",\"span\",null,{\"className\":\"text-gray-900\",\"aria-current\":\"page\",\"children\":\"[논문리뷰] VideoWorld 2: Learning Transferable Knowledge from Real-world Videos\"}]]}]]]}]}],[\"$\",\"article\",null,{\"className\":\"page\",\"children\":[[\"$\",\"header\",null,{\"className\":\"mb-8\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"page__title\",\"children\":\"[논문리뷰] VideoWorld 2: Learning Transferable Knowledge from Real-world Videos\"}],[\"$\",\"div\",null,{\"className\":\"page__meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2026-02-11 00:00:00+0900+0900\",\"children\":\"2026년 2월 11일\"}],[\"$\",\"time\",null,{\"className\":\"ml-4\",\"dateTime\":\"2026-02-10T15:00:00.000Z\",\"children\":[\"수정: \",\"2026년 2월 11일\"]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"page__content\",\"children\":[\"$\",\"div\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$10\"}}]}],[\"$\",\"footer\",null,{\"className\":\"page__meta mt-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"page__taxonomy\",\"children\":[[\"$\",\"span\",null,{\"className\":\"text-sm font-medium text-gray-900 mb-2 block\",\"children\":\"태그\"}],[[\"$\",\"$La\",\"Review\",{\"href\":\"/tags/Review\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"$La\",\"Transferable Knowledge\",{\"href\":\"/tags/Transferable%20Knowledge\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transferable Knowledge\"]}],[\"$\",\"$La\",\"Real-world Video Learning\",{\"href\":\"/tags/Real-world%20Video%20Learning\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Real-world Video Learning\"]}],[\"$\",\"$La\",\"Latent Dynamics Model\",{\"href\":\"/tags/Latent%20Dynamics%20Model\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Latent Dynamics Model\"]}],[\"$\",\"$La\",\"Video Diffusion\",{\"href\":\"/tags/Video%20Diffusion\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Diffusion\"]}],[\"$\",\"$La\",\"Robotics Manipulation\",{\"href\":\"/tags/Robotics%20Manipulation\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robotics Manipulation\"]}],[\"$\",\"$La\",\"Long-horizon Tasks\",{\"href\":\"/tags/Long-horizon%20Tasks\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long-horizon Tasks\"]}],[\"$\",\"$La\",\"Unlabeled Data\",{\"href\":\"/tags/Unlabeled%20Data\",\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Unlabeled Data\"]}]]]}]}],[\"$\",\"$L11\",null,{\"postPermalink\":\"/ai/review/2026-02-11-VideoWorld-2-Learning-Transferable-Knowledge-from-Real-world-Videos\",\"postId\":\"2026-02-11-VideoWorld-2-Learning-Transferable-Knowledge-from-Real-world-Videos\"}],[\"$\",\"section\",null,{\"className\":\"mt-12 border-t border-gray-200 pt-8\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-base font-semibold text-gray-900 mb-4\",\"children\":[\"Review\",\" 의 다른글\"]}],[\"$\",\"ul\",null,{\"className\":\"space-y-2 text-sm\",\"children\":[[\"$\",\"li\",null,{\"className\":\"text-gray-500\",\"children\":[\"이전글\",\" \",[\"$\",\"$La\",null,{\"href\":\"/ai/review/2026-02-11-VLA-JEPA-Enhancing-Vision-Language-Action-Model-with-Latent-World-Model\",\"className\":\"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4\",\"children\":\"[논문리뷰] VLA-JEPA: Enhancing Vision-Language-Action Model with Latent World Model\"}]]}],[\"$\",\"li\",null,{\"className\":\"text-gray-900 font-semibold\",\"children\":[\"현재글 : \",\"[논문리뷰] VideoWorld 2: Learning Transferable Knowledge from Real-world Videos\"]}],[\"$\",\"li\",null,{\"className\":\"text-gray-500\",\"children\":[\"다음글\",\" \",[\"$\",\"$La\",null,{\"href\":\"/ai/review/2026-02-12-ASA-Training-Free-Representation-Engineering-for-Tool-Calling-Agents\",\"className\":\"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4\",\"children\":\"[논문리뷰] ASA: Training-Free Representation Engineering for Tool-Calling Agents\"}]]}]]}]]}]]}]]}]]}]}]]\n"])</script><script>self.__next_f.push([1,"c:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"[논문리뷰] VideoWorld 2: Learning Transferable Knowledge from Real-world Videos - secrett2633's blog\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"arXiv에 게시된 'VideoWorld 2: Learning Transferable Knowledge from Real-world Videos' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"meta\",\"4\",{\"name\":\"author\",\"content\":\"secrett2633\"}],[\"$\",\"link\",\"5\",{\"rel\":\"manifest\",\"href\":\"/manifest.json\",\"crossOrigin\":\"use-credentials\"}],[\"$\",\"meta\",\"6\",{\"name\":\"keywords\",\"content\":\"Django, Python, DevOps, AI, ML, 블로그, 기술\"}],[\"$\",\"meta\",\"7\",{\"name\":\"creator\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"8\",{\"name\":\"publisher\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"9\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"10\",{\"name\":\"googlebot\",\"content\":\"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1\"}],[\"$\",\"link\",\"11\",{\"rel\":\"canonical\",\"href\":\"https://blog.secrett2633.cloud/ai/review/2026-02-11-VideoWorld-2-Learning-Transferable-Knowledge-from-Real-world-Videos\"}],[\"$\",\"meta\",\"12\",{\"name\":\"format-detection\",\"content\":\"telephone=no, address=no, email=no\"}],[\"$\",\"meta\",\"13\",{\"property\":\"og:title\",\"content\":\"[논문리뷰] VideoWorld 2: Learning Transferable Knowledge from Real-world Videos\"}],[\"$\",\"meta\",\"14\",{\"property\":\"og:description\",\"content\":\"arXiv에 게시된 'VideoWorld 2: Learning Transferable Knowledge from Real-world Videos' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"meta\",\"15\",{\"property\":\"og:url\",\"content\":\"https://blog.secrett2633.cloud/ai/review/2026-02-11-VideoWorld-2-Learning-Transferable-Knowledge-from-Real-world-Videos\"}],[\"$\",\"meta\",\"16\",{\"property\":\"og:type\",\"content\":\"article\"}],[\"$\",\"meta\",\"17\",{\"property\":\"article:published_time\",\"content\":\"2026-02-10T15:00:00.000Z\"}],[\"$\",\"meta\",\"18\",{\"property\":\"article:modified_time\",\"content\":\"2026-02-10T15:00:00.000Z\"}],[\"$\",\"meta\",\"19\",{\"property\":\"article:author\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"20\",{\"property\":\"article:section\",\"content\":\"Review\"}],[\"$\",\"meta\",\"21\",{\"property\":\"article:tag\",\"content\":\"Review\"}],[\"$\",\"meta\",\"22\",{\"property\":\"article:tag\",\"content\":\"Transferable Knowledge\"}],[\"$\",\"meta\",\"23\",{\"property\":\"article:tag\",\"content\":\"Real-world Video Learning\"}],[\"$\",\"meta\",\"24\",{\"property\":\"article:tag\",\"content\":\"Latent Dynamics Model\"}],[\"$\",\"meta\",\"25\",{\"property\":\"article:tag\",\"content\":\"Video Diffusion\"}],[\"$\",\"meta\",\"26\",{\"property\":\"article:tag\",\"content\":\"Robotics Manipulation\"}],[\"$\",\"meta\",\"27\",{\"property\":\"article:tag\",\"content\":\"Long-horizon Tasks\"}],[\"$\",\"meta\",\"28\",{\"property\":\"article:tag\",\"content\":\"Unlabeled Data\"}],[\"$\",\"meta\",\"29\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"30\",{\"name\":\"twitter:creator\",\"content\":\"@secrett2633\"}],[\"$\",\"meta\",\"31\",{\"name\":\"twitter:title\",\"content\":\"[논문리뷰] VideoWorld 2: Learning Transferable Knowledge from Real-world Videos\"}],[\"$\",\"meta\",\"32\",{\"name\":\"twitter:description\",\"content\":\"arXiv에 게시된 'VideoWorld 2: Learning Transferable Knowledge from Real-world Videos' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"link\",\"33\",{\"rel\":\"icon\",\"href\":\"/icon.ico?6d9f34d4948640b8\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}],[\"$\",\"meta\",\"34\",{\"name\":\"next-size-adjust\"}]]\n"])</script><script>self.__next_f.push([1,"4:null\n"])</script></body></html>