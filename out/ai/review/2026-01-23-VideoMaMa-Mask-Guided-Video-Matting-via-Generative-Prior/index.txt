3:I[9275,[],""]
5:I[1343,[],""]
6:I[9157,["231","static/chunks/231-467e37449c5a68fc.js","185","static/chunks/app/layout-135ad156a55a8fe5.js"],"default"]
7:I[231,["231","static/chunks/231-467e37449c5a68fc.js","877","static/chunks/app/%5B...slug%5D/page-a0fe0cc578429896.js"],""]
4:["slug","ai/review/2026-01-23-VideoMaMa-Mask-Guided-Video-Matting-via-Generative-Prior","c"]
0:["Z3C0dl-eqDisnYDXzkst9",[[["",{"children":[["slug","ai/review/2026-01-23-VideoMaMa-Mask-Guided-Video-Matting-via-Generative-Prior","c"],{"children":["__PAGE__?{\"slug\":[\"ai\",\"review\",\"2026-01-23-VideoMaMa-Mask-Guided-Video-Matting-via-Generative-Prior\"]}",{}]}]},"$undefined","$undefined",true],["",{"children":[["slug","ai/review/2026-01-23-VideoMaMa-Mask-Guided-Video-Matting-via-Generative-Prior","c"],{"children":["__PAGE__",{},[["$L1","$L2"],null],null]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","$4","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},[["$","html",null,{"lang":"ko","className":"no-js","children":[["$","head",null,{"children":[["$","meta",null,{"name":"msapplication-TileColor","content":"#ffc40d"}],["$","meta",null,{"name":"theme-color","content":"#ffffff"}],["$","script",null,{"async":true,"src":"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY"}],["$","script",null,{"dangerouslySetInnerHTML":{"__html":"\n              window.dataLayer = window.dataLayer || [];\n              function gtag(){dataLayer.push(arguments);}\n              gtag('js', new Date());\n              gtag('config', 'G-NE2W3CFPNY');\n            "}}]]}],["$","body",null,{"className":"__className_f367f3 layout--default","children":["$","div",null,{"className":"min-h-screen bg-gray-50","children":[["$","$L6",null,{}],["$","main",null,{"className":"initial-content","children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","div",null,{"className":"min-h-screen flex items-center justify-center bg-gray-50","children":["$","div",null,{"className":"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center","children":[["$","h1",null,{"className":"text-6xl font-bold text-primary-600 mb-4","children":"404"}],["$","h2",null,{"className":"text-2xl font-semibold text-gray-900 mb-4","children":"페이지를 찾을 수 없습니다"}],["$","p",null,{"className":"text-gray-600 mb-8","children":"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다."}],["$","$L7",null,{"href":"/","className":"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors","children":"홈으로 돌아가기"}]]}]}],"notFoundStyles":[],"styles":null}]}],["$","div",null,{"id":"footer","className":"page__footer","children":["$","footer",null,{"className":"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8","children":["$","div",null,{"className":"text-center text-gray-500 text-sm","children":["$","p",null,{"children":"© 2025 secrett2633. All rights reserved."}]}]}]}]]}]}]]}],null],[["$","div",null,{"className":"flex items-center justify-center min-h-screen","children":["$","div",null,{"className":"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600"}]}],[],[]]],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/d6cea809dcbae606.css","precedence":"next","crossOrigin":"$undefined"}]],[null,"$L8"]]]]]
a:I[646,["231","static/chunks/231-467e37449c5a68fc.js","877","static/chunks/app/%5B...slug%5D/page-a0fe0cc578429896.js"],"default"]
9:Tdcd,<blockquote>
<p><strong>링크:</strong> <a href="https://arxiv.org/abs/2601.14255">논문 PDF로 바로 열기</a></p>
</blockquote>
<p><strong>저자:</strong> Sangbeom Lim, Seoung Wug Oh, Seungryong Kim, Jiahui Huang, Heeji Yoon, Joon-Young Lee</p>
<h2>핵심 연구 목표</h2>
<p>논문은 비디오 매팅 모델이 실제 세계 비디오에 효과적으로 일반화되지 못하는 문제, 즉 레이블링된 데이터의 희소성과 합성 비디오와 실제 비디오 간의 도메인 간극을 해결하는 것을 목표로 합니다. 이를 위해 거친 세그멘테이션 마스크를 픽셀 정확도가 높은 알파 매트로 변환하여, 대규모의 고품질 비디오 매팅 주석을 확장성 있게 생성하는 것을 제안합니다.</p>
<h2>핵심 방법론</h2>
<p>본 연구는 <strong>사전 학습된 비디오 확산 모델(SVD)</strong> 기반의 <strong>Video Mask-to-Matte Model (VideoMaMa)</strong> 을 도입하여 이진 마스크로부터 고품질 알파 매트를 생성합니다. <strong>두 단계 훈련 전략</strong> 을 통해 공간적 세부 사항과 시간적 일관성을 각각 학습하며, <strong>마스크 증강</strong> 과 <strong>DINOv3 피처</strong> 를 활용한 <strong>의미론적 지식 주입</strong> 으로 모델의 견고성을 강화합니다. VideoMaMa를 활용해 <strong>MA-V (Matting Anything in Video)</strong> 라는 5만 개 이상의 실제 비디오로 구성된 대규모 <strong>의사 레이블링 데이터셋</strong> 을 구축했으며, <strong>SAM2</strong> 를 MA-V에 파인튜닝하여 <strong>SAM2-Matte</strong> 를 생성했습니다.</p>
<h2>주요 결과</h2>
<p><strong>VideoMaMa</strong> 는 기존 마스크 기반 매팅 모델인 <strong>MaGGIe [14]</strong> 및 <strong>MGM [49]</strong> 보다 <strong>V-HIM60</strong> 및 <strong>YouTubeMatte</strong> 벤치마크에서 일관되게 우수한 성능을 보였습니다. 예를 들어, <strong>V-HIM60 Hard</strong> 에서 <strong>Downsample 8x</strong> 마스크 입력 시 <strong>MAD 1.306</strong> 으로 <strong>MaGGIe</strong> 의 2.3790보다 현저히 낮았습니다. <strong>MA-V 데이터셋</strong> 으로 파인튜닝된 <strong>SAM2-Matte</strong> 는 기존 매팅 데이터셋으로 훈련된 <strong>SAM2</strong> 보다 실제 비디오에서 훨씬 더 견고한 매팅 성능을 달성했으며, <strong>V-HIM60 Easy</strong> 에서 <strong>MAD 1.3446</strong> 을 기록하며 <strong>MatAnyone</strong> 의 3.5803을 크게 앞섰습니다.</p>
<h2>AI 실무자를 위한 시사점</h2>
<p><strong>확산 모델</strong> 의 <strong>생성적 사전 지식</strong> 은 제한된 합성 데이터만으로도 실제 세계 비디오에 대한 강력한 <strong>제로샷 일반화</strong> 를 가능하게 하여, 데이터 부족 문제를 해결하는 데 유용합니다. <strong>VideoMaMa</strong> 와 같은 모델은 거친 세그멘테이션 마스크를 <strong>고품질 알파 매트</strong> 로 변환하여, 기존 세그멘테이션 데이터셋을 활용해 <strong>대규모 매팅 데이터셋(MA-V)</strong> 을 효율적으로 구축하는 <strong>의사 레이블링 파이프라인</strong> 을 구현할 수 있습니다. 이는 AI 엔지니어들이 <strong>SAM2</strong> 와 같은 범용 모델을 실제 환경에 최적화된 매팅 모델로 전환할 수 있는 실용적인 방안을 제시합니다.</p>
<blockquote>
<p>⚠️ <strong>알림:</strong> 이 리뷰는 AI로 작성되었습니다.</p>
</blockquote>
2:["$","div",null,{"className":"flex flex-col lg:flex-row gap-8","children":[["$","aside",null,{"className":"lg:w-64 xl:w-72 order-1 lg:order-none","children":["$","div",null,{"className":"sidebar sticky","children":["$","nav",null,{"className":"space-y-4","children":[["$","div","Backend",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"Backend"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Django",{"children":["$","a",null,{"href":"/backend/django/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Django"," (",6,")"]}]}],["$","li","Logging",{"children":["$","a",null,{"href":"/backend/logging/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Logging"," (",1,")"]}]}]]}]]}],["$","div","Python",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"Python"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","PEP",{"children":["$","a",null,{"href":"/python/pep/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["PEP"," (",650,")"]}]}]]}]]}],["$","div","AI/ML",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"AI/ML"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","LLM",{"children":["$","a",null,{"href":"/ai/llm/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["LLM"," (",1,")"]}]}],["$","li","Review",{"children":["$","a",null,{"href":"/ai/review/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Review"," (",2672,")"]}]}]]}]]}],["$","div","DevOps",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"DevOps"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Nginx",{"children":["$","a",null,{"href":"/devops/nginx/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Nginx"," (",1,")"]}]}],["$","li","Docker",{"children":["$","a",null,{"href":"/devops/docker/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Docker"," (",1,")"]}]}],["$","li","SafeLine",{"children":["$","a",null,{"href":"/devops/safeline/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["SafeLine"," (",1,")"]}]}],["$","li","Jenkins",{"children":["$","a",null,{"href":"/devops/jenkins/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Jenkins"," (",3,")"]}]}],["$","li","GitHub Actions",{"children":["$","a",null,{"href":"/devops/github-actions/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["GitHub Actions"," (",1,")"]}]}],["$","li","AWS",{"children":["$","a",null,{"href":"/devops/aws/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["AWS"," (",1,")"]}]}]]}]]}],["$","div","etc",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"etc"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Me",{"children":["$","a",null,{"href":"/etc/me/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Me"," (",3,")"]}]}],["$","li","Chrome Extension",{"children":["$","a",null,{"href":"/etc/chrome-extension/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Chrome Extension"," (",1,")"]}]}]]}]]}]]}]}]}],["$","main",null,{"className":"flex-1","children":["$","article",null,{"className":"page","children":[["$","header",null,{"className":"mb-8","children":[["$","h1",null,{"className":"page__title","children":"[논문리뷰] VideoMaMa: Mask-Guided Video Matting via Generative Prior"}],["$","div",null,{"className":"page__meta","children":[["$","time",null,{"dateTime":"2026-01-23 00:00:00+0900+0900","children":"2026년 1월 23일"}],["$","span",null,{"className":"ml-4","children":["수정: ","2026년 1월 23일"]}]]}]]}],["$","div",null,{"className":"page__content","children":["$","div",null,{"dangerouslySetInnerHTML":{"__html":"$9"}}]}],["$","footer",null,{"className":"page__meta mt-8","children":["$","div",null,{"className":"page__taxonomy","children":[["$","h4",null,{"className":"text-sm font-medium text-gray-900 mb-2","children":"태그"}],[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Matting",{"className":"page__taxonomy-item","children":["#","Video Matting"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Generative Priors",{"className":"page__taxonomy-item","children":["#","Generative Priors"]}],["$","span","Mask-Guided",{"className":"page__taxonomy-item","children":["#","Mask-Guided"]}],["$","span","Pseudo-labeling",{"className":"page__taxonomy-item","children":["#","Pseudo-labeling"]}],["$","span","Large-scale Dataset",{"className":"page__taxonomy-item","children":["#","Large-scale Dataset"]}],["$","span","Zero-shot Generalization",{"className":"page__taxonomy-item","children":["#","Zero-shot Generalization"]}]]]}]}],["$","$La",null,{"postPermalink":"/ai/review/2026-01-23-VideoMaMa-Mask-Guided-Video-Matting-via-Generative-Prior/","postId":"2026-01-23-VideoMaMa-Mask-Guided-Video-Matting-via-Generative-Prior"}],["$","section",null,{"className":"mt-12 border-t border-gray-200 pt-8","children":[["$","h3",null,{"className":"text-base font-semibold text-gray-900 mb-4","children":["Review"," 의 다른글"]}],["$","ul",null,{"className":"space-y-2 text-sm","children":[["$","li",null,{"className":"text-gray-500","children":["이전글"," ",["$","$L7",null,{"href":"/ai/review/2026-01-23-Towards-Automated-Kernel-Generation-in-the-Era-of-LLMs/","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] Towards Automated Kernel Generation in the Era of LLMs"}]]}],["$","li",null,{"className":"text-gray-900 font-semibold","children":["현재글 : ","[논문리뷰] VideoMaMa: Mask-Guided Video Matting via Generative Prior"]}],["$","li",null,{"className":"text-gray-500","children":["다음글"," ",["$","$L7",null,{"href":"/ai/review/2026-01-23-VIOLA-Towards-Video-In-Context-Learning-with-Minimal-Annotations/","className":"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4","children":"[논문리뷰] VIOLA: Towards Video In-Context Learning with Minimal Annotations"}]]}]]}]]}]]}]}]]}]
8:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"secrett2633's blog"}],["$","meta","3",{"name":"description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","meta","4",{"name":"author","content":"secrett2633"}],["$","meta","5",{"name":"keywords","content":"Django, Python, DevOps, AI, ML, 블로그, 기술"}],["$","meta","6",{"name":"creator","content":"secrett2633"}],["$","meta","7",{"name":"publisher","content":"secrett2633"}],["$","meta","8",{"name":"robots","content":"index, follow"}],["$","meta","9",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","10",{"rel":"canonical","href":"https://blog.secrett2633.cloud/"}],["$","meta","11",{"name":"format-detection","content":"telephone=no, address=no, email=no"}],["$","meta","12",{"property":"og:title","content":"secrett2633's blog"}],["$","meta","13",{"property":"og:description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","meta","14",{"property":"og:url","content":"https://blog.secrett2633.cloud/"}],["$","meta","15",{"property":"og:site_name","content":"secrett2633's blog"}],["$","meta","16",{"property":"og:locale","content":"ko_KR"}],["$","meta","17",{"property":"og:type","content":"website"}],["$","meta","18",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","19",{"name":"twitter:title","content":"secrett2633's blog"}],["$","meta","20",{"name":"twitter:description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","link","21",{"rel":"icon","href":"/icon.ico?6d9f34d4948640b8","type":"image/x-icon","sizes":"16x16"}]]
1:null
