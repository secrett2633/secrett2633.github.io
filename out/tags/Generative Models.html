<!DOCTYPE html><html lang="ko" class="no-js"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/edb8d4ad4fe2f3b0.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-90b03762f46d1ba4.js"/><script src="/_next/static/chunks/fd9d1056-4b0d66bdf1ba1813.js" async=""></script><script src="/_next/static/chunks/23-41c976638cd1a58c.js" async=""></script><script src="/_next/static/chunks/main-app-6087bc228fd56b83.js" async=""></script><script src="/_next/static/chunks/231-ee5764c1002761f9.js" async=""></script><script src="/_next/static/chunks/app/tags/%5Btag%5D/page-a05565f8ea9cbb05.js" async=""></script><script src="/_next/static/chunks/132-273e49420772df1e.js" async=""></script><script src="/_next/static/chunks/app/layout-d443cbc354279241.js" async=""></script><link rel="preload" href="https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY" as="script"/><meta name="msapplication-TileColor" content="#ffc40d"/><meta name="theme-color" content="#ffffff"/><link rel="dns-prefetch" href="https://www.googletagmanager.com"/><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"/><link rel="dns-prefetch" href="https://giscus.app"/><link rel="preconnect" href="https://giscus.app" crossorigin="anonymous"/><meta http-equiv="X-Content-Type-Options" content="nosniff"/><meta name="referrer" content="strict-origin-when-cross-origin"/><title>#Generative Models - secrett2633&#x27;s blog</title><meta name="description" content="Generative Models 태그가 포함된 포스트 목록"/><meta name="author" content="secrett2633"/><link rel="manifest" href="/manifest.json" crossorigin="use-credentials"/><meta name="keywords" content="Django, Python, DevOps, AI, ML, 블로그, 기술"/><meta name="creator" content="secrett2633"/><meta name="publisher" content="secrett2633"/><meta name="robots" content="index, follow"/><meta name="googlebot" content="index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"/><link rel="canonical" href="https://blog.secrett2633.cloud/tags/Generative%20Models"/><meta name="format-detection" content="telephone=no, address=no, email=no"/><meta property="og:title" content="#Generative Models - secrett2633&#x27;s blog"/><meta property="og:description" content="Generative Models 태그가 포함된 포스트 목록"/><meta property="og:url" content="https://blog.secrett2633.cloud/tags/Generative%20Models"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="#Generative Models - secrett2633&#x27;s blog"/><meta name="twitter:description" content="Generative Models 태그가 포함된 포스트 목록"/><link rel="icon" href="/icon.ico?6d9f34d4948640b8" type="image/x-icon" sizes="16x16"/><meta name="next-size-adjust"/><script type="application/ld+json">{"@context":"https://schema.org","@type":"WebSite","name":"secrett2633's blog","url":"https://blog.secrett2633.cloud","description":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트","inLanguage":"ko","publisher":{"@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud"}}</script><script type="application/ld+json">{"@context":"https://schema.org","@type":"Person","name":"secrett2633","url":"https://blog.secrett2633.cloud","sameAs":["https://github.com/secrett2633"]}</script><script src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body class="__className_f367f3 layout--default"><a href="#main-content" class="sr-only focus:not-sr-only focus:absolute focus:z-50 focus:p-4 focus:bg-white focus:text-blue-600">본문으로 건너뛰기</a><div class="min-h-screen bg-gray-50"><div class="masthead"><div class="masthead__inner-wrap"><div class="masthead__menu"><nav id="site-nav" class="greedy-nav" aria-label="메인 네비게이션"><a class="site-title" href="/">secrett2633&#x27;s blog</a><div class="flex items-center space-x-4"><ul class="visible-links"><li class="masthead__menu-item"><a href="https://github.com/secrett2633" target="_blank" rel="noopener noreferrer">GitHub</a></li></ul><button class="search__toggle" type="button" aria-label="검색"><svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16"><path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path></svg></button></div></nav></div></div></div><main id="main-content" class="initial-content"><!--$--><script type="application/ld+json">{"@context":"https://schema.org","@type":"CollectionPage","name":"#Generative Models - secrett2633's blog","description":"Generative Models 태그가 포함된 포스트 목록","url":"https://blog.secrett2633.cloud/tags/Generative%20Models","isPartOf":{"@type":"WebSite","name":"secrett2633's blog","url":"https://blog.secrett2633.cloud"},"inLanguage":"ko"}</script><script type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"홈","item":"https://blog.secrett2633.cloud/"},{"@type":"ListItem","position":2,"name":"#Generative Models","item":"https://blog.secrett2633.cloud/tags/Generative%20Models"}]}</script><div class="space-y-6"><div class="flex flex-col lg:flex-row gap-8"><aside class="lg:w-64 xl:w-72 order-1 lg:order-none"><div class="sidebar sticky"><nav class="space-y-4" aria-label="카테고리 네비게이션"><div><p class="font-medium text-gray-900 mb-2">Backend</p><ul class="space-y-1 ml-4"><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/backend/django">Django<!-- --> (<!-- -->6<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/backend/logging">Logging<!-- --> (<!-- -->1<!-- -->)</a></li></ul></div><div><p class="font-medium text-gray-900 mb-2">Python</p><ul class="space-y-1 ml-4"><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/python/pep">PEP<!-- --> (<!-- -->650<!-- -->)</a></li></ul></div><div><p class="font-medium text-gray-900 mb-2">AI/ML</p><ul class="space-y-1 ml-4"><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/ai/llm">LLM<!-- --> (<!-- -->1<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/ai/review">Review<!-- --> (<!-- -->2741<!-- -->)</a></li></ul></div><div><p class="font-medium text-gray-900 mb-2">DevOps</p><ul class="space-y-1 ml-4"><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/devops/nginx">Nginx<!-- --> (<!-- -->1<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/devops/docker">Docker<!-- --> (<!-- -->1<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/devops/safeline">SafeLine<!-- --> (<!-- -->1<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/devops/jenkins">Jenkins<!-- --> (<!-- -->3<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/devops/github-actions">GitHub Actions<!-- --> (<!-- -->1<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/devops/aws">AWS<!-- --> (<!-- -->1<!-- -->)</a></li></ul></div><div><p class="font-medium text-gray-900 mb-2">etc</p><ul class="space-y-1 ml-4"><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/etc/me">Me<!-- --> (<!-- -->3<!-- -->)</a></li><li><a class="text-sm text-gray-600 hover:text-primary-600 block py-1" href="/etc/chrome-extension">Chrome Extension<!-- --> (<!-- -->1<!-- -->)</a></li></ul></div></nav></div></aside><div class="flex-1"><nav aria-label="breadcrumb" class="text-sm text-gray-500 mb-4"><ol class="flex flex-wrap items-center gap-1"><li><a class="hover:text-gray-700" href="/">홈</a></li><li class="flex items-center gap-1"><span aria-hidden="true">/</span><span class="text-gray-900" aria-current="page">#Generative Models</span></li></ol></nav><h1 class="page__title mb-6">#<!-- -->Generative Models</h1><p class="text-gray-500 mb-6">83<!-- -->개의 포스트</p><div class="entries-list"><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2026-02-19-Optimizing-Few-Step-Generation-with-Adaptive-Matching-Distillation">[논문리뷰] Optimizing Few-Step Generation with Adaptive Matching Distillation</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2026-02-19-Optimizing-Few-Step-Generation-with-Adaptive-Matching-Distillation">arXiv에 게시된 &#x27;Optimizing Few-Step Generation with Adaptive Matching Distillation&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2026-02-19 00:00:00+0900+0900">2026년 2월 19일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2026-02-09-Back-to-Basics-Revisiting-Exploration-in-Reinforcement-Learning-for-LLM-Reasoning-via-Generative-Probabilities">[논문리뷰] Back to Basics: Revisiting Exploration in Reinforcement Learning for LLM Reasoning via Generative Probabilities</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2026-02-09-Back-to-Basics-Revisiting-Exploration-in-Reinforcement-Learning-for-LLM-Reasoning-via-Generative-Probabilities">Ivan Oseledets이 arXiv에 게시한 &#x27;Back to Basics: Revisiting Exploration in Reinforcement Learning for LLM Reasoning via Generative Probabilities&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2026-02-09 00:00:00+0900+0900">2026년 2월 9일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2026-02-04-Research-on-World-Models-Is-Not-Merely-Injecting-World-Knowledge-into-Specific-Tasks">[논문리뷰] Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2026-02-04-Research-on-World-Models-Is-Not-Merely-Injecting-World-Knowledge-into-Specific-Tasks">arXiv에 게시된 &#x27;Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2026-02-04 00:00:00+0900+0900">2026년 2월 4일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2026-02-03-How-Well-Do-Models-Follow-Visual-Instructions-VIBE-A-Systematic-Benchmark-for-Visual-Instruction-Driven-Image-Editing">[논문리뷰] How Well Do Models Follow Visual Instructions? VIBE: A Systematic Benchmark for Visual Instruction-Driven Image Editing</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2026-02-03-How-Well-Do-Models-Follow-Visual-Instructions-VIBE-A-Systematic-Benchmark-for-Visual-Instruction-Driven-Image-Editing">Haochen Tian이 arXiv에 게시한 &#x27;How Well Do Models Follow Visual Instructions? VIBE: A Systematic Benchmark for Visual Instruction-Driven Image Editing&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2026-02-03 00:00:00+0900+0900">2026년 2월 3일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2026-02-02-Revisiting-Diffusion-Model-Predictions-Through-Dimensionality">[논문리뷰] Revisiting Diffusion Model Predictions Through Dimensionality</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2026-02-02-Revisiting-Diffusion-Model-Predictions-Through-Dimensionality">Chaoyang Wang이 arXiv에 게시한 &#x27;Revisiting Diffusion Model Predictions Through Dimensionality&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2026-02-02 00:00:00+0900+0900">2026년 2월 2일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2026-01-29-Advancing-Open-source-World-Models">[논문리뷰] Advancing Open-source World Models</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2026-01-29-Advancing-Open-source-World-Models">arXiv에 게시된 &#x27;Advancing Open-source World Models&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2026-01-29 00:00:00+0900+0900">2026년 1월 29일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2026-01-23-ActionMesh-Animated-3D-Mesh-Generation-with-Temporal-3D-Diffusion">[논문리뷰] ActionMesh: Animated 3D Mesh Generation with Temporal 3D Diffusion</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2026-01-23-ActionMesh-Animated-3D-Mesh-Generation-with-Temporal-3D-Diffusion">arXiv에 게시된 &#x27;ActionMesh: Animated 3D Mesh Generation with Temporal 3D Diffusion&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2026-01-23 00:00:00+0900+0900">2026년 1월 23일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2026-01-13-BabyVision-Visual-Reasoning-Beyond-Language">[논문리뷰] BabyVision: Visual Reasoning Beyond Language</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2026-01-13-BabyVision-Visual-Reasoning-Beyond-Language">Yiyan Liang이 arXiv에 게시한 &#x27;BabyVision: Visual Reasoning Beyond Language&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2026-01-13 00:00:00+0900+0900">2026년 1월 13일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2026-01-12-GenCtrl-A-Formal-Controllability-Toolkit-for-Generative-Models">[논문리뷰] GenCtrl -- A Formal Controllability Toolkit for Generative Models</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2026-01-12-GenCtrl-A-Formal-Controllability-Toolkit-for-Generative-Models">arXiv에 게시된 &#x27;GenCtrl -- A Formal Controllability Toolkit for Generative Models&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2026-01-12 00:00:00+0900+0900">2026년 1월 12일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2026-01-09-Memorization-in-3D-Shape-Generation-An-Empirical-Study">[논문리뷰] Memorization in 3D Shape Generation: An Empirical Study</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2026-01-09-Memorization-in-3D-Shape-Generation-An-Empirical-Study">arXiv에 게시된 &#x27;Memorization in 3D Shape Generation: An Empirical Study&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2026-01-09 00:00:00+0900+0900">2026년 1월 9일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2026-01-07-FFP-300K-Scaling-First-Frame-Propagation-for-Generalizable-Video-Editing">[논문리뷰] FFP-300K: Scaling First-Frame Propagation for Generalizable Video Editing</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2026-01-07-FFP-300K-Scaling-First-Frame-Propagation-for-Generalizable-Video-Editing">Peng Tang이 arXiv에 게시한 &#x27;FFP-300K: Scaling First-Frame Propagation for Generalizable Video Editing&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2026-01-07 00:00:00+0900+0900">2026년 1월 7일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2026-01-05-MorphAny3D-Unleashing-the-Power-of-Structured-Latent-in-3D-Morphing">[논문리뷰] MorphAny3D: Unleashing the Power of Structured Latent in 3D Morphing</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2026-01-05-MorphAny3D-Unleashing-the-Power-of-Structured-Latent-in-3D-Morphing">Jian Yang이 arXiv에 게시한 &#x27;MorphAny3D: Unleashing the Power of Structured Latent in 3D Morphing&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2026-01-05 00:00:00+0900+0900">2026년 1월 5일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-12-23-The-Prism-Hypothesis-Harmonizing-Semantic-and-Pixel-Representations-via-Unified-Autoencoding">[논문리뷰] The Prism Hypothesis: Harmonizing Semantic and Pixel Representations via Unified Autoencoding</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-12-23-The-Prism-Hypothesis-Harmonizing-Semantic-and-Pixel-Representations-via-Unified-Autoencoding">Ziwei Liu이 arXiv에 게시한 &#x27;The Prism Hypothesis: Harmonizing Semantic and Pixel Representations via Unified Autoencoding&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-12-23 00:00:00+0900+0900">2025년 12월 23일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-12-19-Alchemist-Unlocking-Efficiency-in-Text-to-Image-Model-Training-via-Meta-Gradient-Data-Selection">[논문리뷰] Alchemist: Unlocking Efficiency in Text-to-Image Model Training via Meta-Gradient Data Selection</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-12-19-Alchemist-Unlocking-Efficiency-in-Text-to-Image-Model-Training-via-Meta-Gradient-Data-Selection">Jiarong Ou이 arXiv에 게시한 &#x27;Alchemist: Unlocking Efficiency in Text-to-Image Model Training via Meta-Gradient Data Selection&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-12-19 00:00:00+0900+0900">2025년 12월 19일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-12-18-Robust-and-Calibrated-Detection-of-Authentic-Multimedia-Content">[논문리뷰] Robust and Calibrated Detection of Authentic Multimedia Content</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-12-18-Robust-and-Calibrated-Detection-of-Authentic-Multimedia-Content">arXiv에 게시된 &#x27;Robust and Calibrated Detection of Authentic Multimedia Content&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-12-18 00:00:00+0900+0900">2025년 12월 18일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-12-16-Towards-Scalable-Pre-training-of-Visual-Tokenizers-for-Generation">[논문리뷰] Towards Scalable Pre-training of Visual Tokenizers for Generation</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-12-16-Towards-Scalable-Pre-training-of-Visual-Tokenizers-for-Generation">arXiv에 게시된 &#x27;Towards Scalable Pre-training of Visual Tokenizers for Generation&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-12-16 00:00:00+0900+0900">2025년 12월 16일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-12-10-TreeGRPO-Tree-Advantage-GRPO-for-Online-RL-Post-Training-of-Diffusion-Models">[논문리뷰] TreeGRPO: Tree-Advantage GRPO for Online RL Post-Training of Diffusion Models</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-12-10-TreeGRPO-Tree-Advantage-GRPO-for-Online-RL-Post-Training-of-Diffusion-Models">Weirui Ye이 arXiv에 게시한 &#x27;TreeGRPO: Tree-Advantage GRPO for Online RL Post-Training of Diffusion Models&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-12-10 00:00:00+0900+0900">2025년 12월 10일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-12-10-From-Next-Token-to-Next-Block-A-Principled-Adaptation-Path-for-Diffusion-LLMs">[논문리뷰] From Next-Token to Next-Block: A Principled Adaptation Path for Diffusion LLMs</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-12-10-From-Next-Token-to-Next-Block-A-Principled-Adaptation-Path-for-Diffusion-LLMs">arXiv에 게시된 &#x27;From Next-Token to Next-Block: A Principled Adaptation Path for Diffusion LLMs&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-12-10 00:00:00+0900+0900">2025년 12월 10일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-12-09-Distribution-Matching-Variational-AutoEncoder">[논문리뷰] Distribution Matching Variational AutoEncoder</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-12-09-Distribution-Matching-Variational-AutoEncoder">arXiv에 게시된 &#x27;Distribution Matching Variational AutoEncoder&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-12-09 00:00:00+0900+0900">2025년 12월 9일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-12-08-TwinFlow-Realizing-One-step-Generation-on-Large-Models-with-Self-adversarial-Flows">[논문리뷰] TwinFlow: Realizing One-step Generation on Large Models with Self-adversarial Flows</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-12-08-TwinFlow-Realizing-One-step-Generation-on-Large-Models-with-Self-adversarial-Flows">arXiv에 게시된 &#x27;TwinFlow: Realizing One-step Generation on Large Models with Self-adversarial Flows&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-12-08 00:00:00+0900+0900">2025년 12월 8일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-12-05-Generative-Neural-Video-Compression-via-Video-Diffusion-Prior">[논문리뷰] Generative Neural Video Compression via Video Diffusion Prior</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-12-05-Generative-Neural-Video-Compression-via-Video-Diffusion-Prior">arXiv에 게시된 &#x27;Generative Neural Video Compression via Video Diffusion Prior&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-12-05 00:00:00+0900+0900">2025년 12월 5일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-12-04-Flowing-Backwards-Improving-Normalizing-Flows-via-Reverse-Representation-Alignment">[논문리뷰] Flowing Backwards: Improving Normalizing Flows via Reverse Representation Alignment</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-12-04-Flowing-Backwards-Improving-Normalizing-Flows-via-Reverse-Representation-Alignment">arXiv에 게시된 &#x27;Flowing Backwards: Improving Normalizing Flows via Reverse Representation Alignment&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-12-04 00:00:00+0900+0900">2025년 12월 4일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-12-02-Envision-Benchmarking-Unified-Understanding-Generation-for-Causal-World-Process-Insights">[논문리뷰] Envision: Benchmarking Unified Understanding &amp; Generation for Causal World Process Insights</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-12-02-Envision-Benchmarking-Unified-Understanding-Generation-for-Causal-World-Process-Insights">arXiv에 게시된 &#x27;Envision: Benchmarking Unified Understanding &amp; Generation for Causal World Process Insights&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-12-02 00:00:00+0900+0900">2025년 12월 2일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-12-01-Test-time-scaling-of-diffusions-with-flow-maps">[논문리뷰] Test-time scaling of diffusions with flow maps</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-12-01-Test-time-scaling-of-diffusions-with-flow-maps">Sanja Fidler이 arXiv에 게시한 &#x27;Test-time scaling of diffusions with flow maps&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-12-01 00:00:00+0900+0900">2025년 12월 1일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-12-01-Adversarial-Flow-Models">[논문리뷰] Adversarial Flow Models</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-12-01-Adversarial-Flow-Models">arXiv에 게시된 &#x27;Adversarial Flow Models&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-12-01 00:00:00+0900+0900">2025년 12월 1일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-11-27-Terminal-Velocity-Matching">[논문리뷰] Terminal Velocity Matching</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-11-27-Terminal-Velocity-Matching">Jiaming Song이 arXiv에 게시한 &#x27;Terminal Velocity Matching&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-11-27 00:00:00+0900+0900">2025년 11월 27일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-11-25-In-Video-Instructions-Visual-Signals-as-Generative-Control">[논문리뷰] In-Video Instructions: Visual Signals as Generative Control</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-11-25-In-Video-Instructions-Visual-Signals-as-Generative-Control">arXiv에 게시된 &#x27;In-Video Instructions: Visual Signals as Generative Control&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-11-25 00:00:00+0900+0900">2025년 11월 25일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-11-25-Flow-Map-Distillation-Without-Data">[논문리뷰] Flow Map Distillation Without Data</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-11-25-Flow-Map-Distillation-Without-Data">Tommi Jaakkola이 arXiv에 게시한 &#x27;Flow Map Distillation Without Data&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-11-25 00:00:00+0900+0900">2025년 11월 25일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-11-21-SAM-3D-3Dfy-Anything-in-Images">[논문리뷰] SAM 3D: 3Dfy Anything in Images</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-11-21-SAM-3D-3Dfy-Anything-in-Images">arXiv에 게시된 &#x27;SAM 3D: 3Dfy Anything in Images&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-11-21 00:00:00+0900+0900">2025년 11월 21일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-11-14-SliderEdit-Continuous-Image-Editing-with-Fine-Grained-Instruction-Control">[논문리뷰] SliderEdit: Continuous Image Editing with Fine-Grained Instruction Control</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-11-14-SliderEdit-Continuous-Image-Editing-with-Fine-Grained-Instruction-Control">Ryan Rossi이 arXiv에 게시한 &#x27;SliderEdit: Continuous Image Editing with Fine-Grained Instruction Control&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-11-14 00:00:00+0900+0900">2025년 11월 14일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-11-11-Diffusion-SDPO-Safeguarded-Direct-Preference-Optimization-for-Diffusion-Models">[논문리뷰] Diffusion-SDPO: Safeguarded Direct Preference Optimization for Diffusion   Models</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-11-11-Diffusion-SDPO-Safeguarded-Direct-Preference-Optimization-for-Diffusion-Models">Zhao Xu이 arXiv에 게시한 &#x27;Diffusion-SDPO: Safeguarded Direct Preference Optimization for Diffusion   Models&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-11-11 00:00:00+0900+0900">2025년 11월 11일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-11-11-DIMO-Diverse-3D-Motion-Generation-for-Arbitrary-Objects">[논문리뷰] DIMO: Diverse 3D Motion Generation for Arbitrary Objects</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-11-11-DIMO-Diverse-3D-Motion-Generation-for-Arbitrary-Objects">Kostas Daniilidis이 arXiv에 게시한 &#x27;DIMO: Diverse 3D Motion Generation for Arbitrary Objects&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-11-11 00:00:00+0900+0900">2025년 11월 11일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-11-7-Contamination-Detection-for-VLMs-using-Multi-Modal-Semantic-Perturbation">[논문리뷰] Contamination Detection for VLMs using Multi-Modal Semantic Perturbation</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-11-7-Contamination-Detection-for-VLMs-using-Multi-Modal-Semantic-Perturbation">arXiv에 게시된 &#x27;Contamination Detection for VLMs using Multi-Modal Semantic Perturbation&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-11-09 22:08:24+0900">2025년 11월 9일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-11-6-UniAVGen-Unified-Audio-and-Video-Generation-with-Asymmetric-Cross-Modal-Interactions">[논문리뷰] UniAVGen: Unified Audio and Video Generation with Asymmetric Cross-Modal Interactions</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-11-6-UniAVGen-Unified-Audio-and-Video-Generation-with-Asymmetric-Cross-Modal-Interactions">arXiv에 게시된 &#x27;UniAVGen: Unified Audio and Video Generation with Asymmetric Cross-Modal Interactions&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-11-09 21:54:30+0900">2025년 11월 9일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-11-4-UniREditBench-A-Unified-Reasoning-based-Image-Editing-Benchmark">[논문리뷰] UniREditBench: A Unified Reasoning-based Image Editing Benchmark</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-11-4-UniREditBench-A-Unified-Reasoning-based-Image-Editing-Benchmark">arXiv에 게시된 &#x27;UniREditBench: A Unified Reasoning-based Image Editing Benchmark&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-11-09 19:22:42+0900">2025년 11월 9일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-11-3-Phased-DMD-Few-step-Distribution-Matching-Distillation-via-Score-Matching-within-Subintervals">[논문리뷰] Phased DMD: Few-step Distribution Matching Distillation via Score Matching within Subintervals</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-11-3-Phased-DMD-Few-step-Distribution-Matching-Distillation-via-Score-Matching-within-Subintervals">arXiv에 게시된 &#x27;Phased DMD: Few-step Distribution Matching Distillation via Score Matching within Subintervals&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-11-09 19:01:31+0900">2025년 11월 9일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-10-31-OmniLayout-Enabling-Coarse-to-Fine-Learning-with-LLMs-for-Universal-Document-Layout-Generation">[논문리뷰] OmniLayout: Enabling Coarse-to-Fine Learning with LLMs for Universal Document Layout Generation</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-10-31-OmniLayout-Enabling-Coarse-to-Fine-Learning-with-LLMs-for-Universal-Document-Layout-Generation">Bin Wang이 arXiv에 게시한 &#x27;OmniLayout: Enabling Coarse-to-Fine Learning with LLMs for Universal Document Layout Generation&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-10-31 18:37:31+0900">2025년 10월 31일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-10-31-EnzyControl-Adding-Functional-and-Substrate-Specific-Control-for-Enzyme-Backbone-Generation">[논문리뷰] EnzyControl: Adding Functional and Substrate-Specific Control for Enzyme Backbone Generation</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-10-31-EnzyControl-Adding-Functional-and-Substrate-Specific-Control-for-Enzyme-Backbone-Generation">arXiv에 게시된 &#x27;EnzyControl: Adding Functional and Substrate-Specific Control for Enzyme Backbone Generation&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-10-31 18:37:31+0900">2025년 10월 31일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-10-30-Gaperon-A-Peppered-English-French-Generative-Language-Model-Suite">[논문리뷰] Gaperon: A Peppered English-French Generative Language Model Suite</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-10-30-Gaperon-A-Peppered-English-French-Generative-Language-Model-Suite">Éric de la Clergerie이 arXiv에 게시한 &#x27;Gaperon: A Peppered English-French Generative Language Model Suite&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-10-30 13:06:06+0900">2025년 10월 30일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-10-28-Track-Inpaint-Resplat-Subject-driven-3D-and-4D-Generation-with-Progressive-Texture-Infilling">[논문리뷰] Track, Inpaint, Resplat: Subject-driven 3D and 4D Generation with Progressive Texture Infilling</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-10-28-Track-Inpaint-Resplat-Subject-driven-3D-and-4D-Generation-with-Progressive-Texture-Infilling">Igor Gilitschenski이 arXiv에 게시한 &#x27;Track, Inpaint, Resplat: Subject-driven 3D and 4D Generation with Progressive Texture Infilling&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-10-28 13:07:54+0900">2025년 10월 28일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-10-28-FARMER-Flow-AutoRegressive-Transformer-over-Pixels">[논문리뷰] FARMER: Flow AutoRegressive Transformer over Pixels</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-10-28-FARMER-Flow-AutoRegressive-Transformer-over-Pixels">Zhijie Lin이 arXiv에 게시한 &#x27;FARMER: Flow AutoRegressive Transformer over Pixels&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-10-28 13:07:54+0900">2025년 10월 28일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-10-28-Distilled-Decoding-2-One-step-Sampling-of-Image-Auto-regressive-Models-with-Conditional-Score-Distillation">[논문리뷰] Distilled Decoding 2: One-step Sampling of Image Auto-regressive Models with Conditional Score Distillation</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-10-28-Distilled-Decoding-2-One-step-Sampling-of-Image-Auto-regressive-Models-with-Conditional-Score-Distillation">Guohao Dai이 arXiv에 게시한 &#x27;Distilled Decoding 2: One-step Sampling of Image Auto-regressive Models with Conditional Score Distillation&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-10-28 13:07:54+0900">2025년 10월 28일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-10-28-DiffusionLane-Diffusion-Model-for-Lane-Detection">[논문리뷰] DiffusionLane: Diffusion Model for Lane Detection</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-10-28-DiffusionLane-Diffusion-Model-for-Lane-Detection">arXiv에 게시된 &#x27;DiffusionLane: Diffusion Model for Lane Detection&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-10-28 13:07:54+0900">2025년 10월 28일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-10-24-AlphaFlow-Understanding-and-Improving-MeanFlow-Models">[논문리뷰] AlphaFlow: Understanding and Improving MeanFlow Models</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-10-24-AlphaFlow-Understanding-and-Improving-MeanFlow-Models">arXiv에 게시된 &#x27;AlphaFlow: Understanding and Improving MeanFlow Models&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-10-24 13:04:16+0900">2025년 10월 24일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-10-23-Attention-Sinks-in-Diffusion-Language-Models">[논문리뷰] Attention Sinks in Diffusion Language Models</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-10-23-Attention-Sinks-in-Diffusion-Language-Models">Simone Scardapane이 arXiv에 게시한 &#x27;Attention Sinks in Diffusion Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-10-23 13:08:59+0900">2025년 10월 23일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-10-21-GuideFlow3D-Optimization-Guided-Rectified-Flow-For-Appearance-Transfer">[논문리뷰] GuideFlow3D: Optimization-Guided Rectified Flow For Appearance Transfer</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-10-21-GuideFlow3D-Optimization-Guided-Rectified-Flow-For-Appearance-Transfer">arXiv에 게시된 &#x27;GuideFlow3D: Optimization-Guided Rectified Flow For Appearance Transfer&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-10-21 13:08:30+0900">2025년 10월 21일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-10-20-Latent-Diffusion-Model-without-Variational-Autoencoder">[논문리뷰] Latent Diffusion Model without Variational Autoencoder</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-10-20-Latent-Diffusion-Model-without-Variational-Autoencoder">arXiv에 게시된 &#x27;Latent Diffusion Model without Variational Autoencoder&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-10-20 13:04:24+0900">2025년 10월 20일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-10-17-pi-Flow-Policy-Based-Few-Step-Generation-via-Imitation-Distillation">[논문리뷰] pi-Flow: Policy-Based Few-Step Generation via Imitation Distillation</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-10-17-pi-Flow-Policy-Based-Few-Step-Generation-via-Imitation-Distillation">arXiv에 게시된 &#x27;pi-Flow: Policy-Based Few-Step Generation via Imitation Distillation&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-10-17 13:09:57+0900">2025년 10월 17일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-10-17-Beyond-Correctness-Evaluating-Subjective-Writing-Preferences-Across-Cultures">[논문리뷰] Beyond Correctness: Evaluating Subjective Writing Preferences Across Cultures</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-10-17-Beyond-Correctness-Evaluating-Subjective-Writing-Preferences-Across-Cultures">arXiv에 게시된 &#x27;Beyond Correctness: Evaluating Subjective Writing Preferences Across Cultures&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-10-17 13:09:57+0900">2025년 10월 17일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-10-16-Generative-Universal-Verifier-as-Multimodal-Meta-Reasoner">[논문리뷰] Generative Universal Verifier as Multimodal Meta-Reasoner</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-10-16-Generative-Universal-Verifier-as-Multimodal-Meta-Reasoner">arXiv에 게시된 &#x27;Generative Universal Verifier as Multimodal Meta-Reasoner&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-10-16 13:09:51+0900">2025년 10월 16일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-10-16-Attention-Illuminates-LLM-Reasoning-The-Preplan-and-Anchor-Rhythm-Enables-Fine-Grained-Policy-Optimization">[논문리뷰] Attention Illuminates LLM Reasoning: The Preplan-and-Anchor Rhythm Enables Fine-Grained Policy Optimization</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-10-16-Attention-Illuminates-LLM-Reasoning-The-Preplan-and-Anchor-Rhythm-Enables-Fine-Grained-Policy-Optimization">arXiv에 게시된 &#x27;Attention Illuminates LLM Reasoning: The Preplan-and-Anchor Rhythm Enables Fine-Grained Policy Optimization&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-10-16 13:09:51+0900">2025년 10월 16일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-10-15-What-If-Understanding-Motion-Through-Sparse-Interactions">[논문리뷰] What If : Understanding Motion Through Sparse Interactions</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-10-15-What-If-Understanding-Motion-Through-Sparse-Interactions">arXiv에 게시된 &#x27;What If : Understanding Motion Through Sparse Interactions&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-10-15 13:01:40+0900">2025년 10월 15일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-10-15-Temporal-Alignment-Guidance-On-Manifold-Sampling-in-Diffusion-Models">[논문리뷰] Temporal Alignment Guidance: On-Manifold Sampling in Diffusion Models</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-10-15-Temporal-Alignment-Guidance-On-Manifold-Sampling-in-Diffusion-Models">arXiv에 게시된 &#x27;Temporal Alignment Guidance: On-Manifold Sampling in Diffusion Models&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-10-15 13:01:40+0900">2025년 10월 15일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-10-10-Towards-Scalable-and-Consistent-3D-Editing">[논문리뷰] Towards Scalable and Consistent 3D Editing</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-10-10-Towards-Scalable-and-Consistent-3D-Editing">Pan Zhou이 arXiv에 게시한 &#x27;Towards Scalable and Consistent 3D Editing&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-10-10 13:53:45+0900">2025년 10월 10일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-10-9-Heptapod-Language-Modeling-on-Visual-Signals">[논문리뷰] Heptapod: Language Modeling on Visual Signals</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-10-9-Heptapod-Language-Modeling-on-Visual-Signals">arXiv에 게시된 &#x27;Heptapod: Language Modeling on Visual Signals&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-10-09 13:45:06+0900">2025년 10월 9일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-10-9-G2RPO-Granular-GRPO-for-Precise-Reward-in-Flow-Models">[논문리뷰] G^2RPO: Granular GRPO for Precise Reward in Flow Models</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-10-9-G2RPO-Granular-GRPO-for-Precise-Reward-in-Flow-Models">arXiv에 게시된 &#x27;G^2RPO: Granular GRPO for Precise Reward in Flow Models&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-10-09 13:45:06+0900">2025년 10월 9일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-10-9-Bridging-Text-and-Video-Generation-A-Survey">[논문리뷰] Bridging Text and Video Generation: A Survey</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-10-9-Bridging-Text-and-Video-Generation-A-Survey">G. Maragatham이 arXiv에 게시한 &#x27;Bridging Text and Video Generation: A Survey&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-10-09 13:45:06+0900">2025년 10월 9일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-10-8-Equilibrium-Matching-Generative-Modeling-with-Implicit-Energy-Based-Models">[논문리뷰] Equilibrium Matching: Generative Modeling with Implicit Energy-Based Models</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-10-8-Equilibrium-Matching-Generative-Modeling-with-Implicit-Energy-Based-Models">arXiv에 게시된 &#x27;Equilibrium Matching: Generative Modeling with Implicit Energy-Based Models&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-10-08 13:48:12+0900">2025년 10월 8일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-10-8-Drax-Speech-Recognition-with-Discrete-Flow-Matching">[논문리뷰] Drax: Speech Recognition with Discrete Flow Matching</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-10-8-Drax-Speech-Recognition-with-Discrete-Flow-Matching">arXiv에 게시된 &#x27;Drax: Speech Recognition with Discrete Flow Matching&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-10-08 13:48:12+0900">2025년 10월 8일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-10-8-Deforming-Videos-to-Masks-Flow-Matching-for-Referring-Video-Segmentation">[논문리뷰] Deforming Videos to Masks: Flow Matching for Referring Video Segmentation</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-10-8-Deforming-Videos-to-Masks-Flow-Matching-for-Referring-Video-Segmentation">Chengzu Li이 arXiv에 게시한 &#x27;Deforming Videos to Masks: Flow Matching for Referring Video Segmentation&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-10-08 13:48:12+0900">2025년 10월 8일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-10-7-ChronoEdit-Towards-Temporal-Reasoning-for-Image-Editing-and-World-Simulation">[논문리뷰] ChronoEdit: Towards Temporal Reasoning for Image Editing and World Simulation</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-10-7-ChronoEdit-Towards-Temporal-Reasoning-for-Image-Editing-and-World-Simulation">arXiv에 게시된 &#x27;ChronoEdit: Towards Temporal Reasoning for Image Editing and World Simulation&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-10-07 13:36:57+0900">2025년 10월 7일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-10-6-Align-Your-Tangent-Training-Better-Consistency-Models-via-Manifold-Aligned-Tangents">[논문리뷰] Align Your Tangent: Training Better Consistency Models via Manifold-Aligned Tangents</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-10-6-Align-Your-Tangent-Training-Better-Consistency-Models-via-Manifold-Aligned-Tangents">Jong Chul Ye이 arXiv에 게시한 &#x27;Align Your Tangent: Training Better Consistency Models via Manifold-Aligned Tangents&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-10-06 13:29:11+0900">2025년 10월 6일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-9-23-VideoFrom3D-3D-Scene-Video-Generation-via-Complementary-Image-and-Video-Diffusion-Models">[논문리뷰] VideoFrom3D: 3D Scene Video Generation via Complementary Image and Video Diffusion Models</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-9-23-VideoFrom3D-3D-Scene-Video-Generation-via-Complementary-Image-and-Video-Diffusion-Models">Sunghyun Cho이 arXiv에 게시한 &#x27;VideoFrom3D: 3D Scene Video Generation via Complementary Image and Video Diffusion Models&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-09-23 13:36:03+0900">2025년 9월 23일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-9-19-AToken-A-Unified-Tokenizer-for-Vision">[논문리뷰] AToken: A Unified Tokenizer for Vision</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-9-19-AToken-A-Unified-Tokenizer-for-Vision">Mingze Xu이 arXiv에 게시한 &#x27;AToken: A Unified Tokenizer for Vision&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-09-19 13:12:21+0900">2025년 9월 19일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-9-16-Locality-in-Image-Diffusion-Models-Emerges-from-Data-Statistics">[논문리뷰] Locality in Image Diffusion Models Emerges from Data Statistics</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-9-16-Locality-in-Image-Diffusion-Models-Emerges-from-Data-Statistics">Vincent Sitzmann이 arXiv에 게시한 &#x27;Locality in Image Diffusion Models Emerges from Data Statistics&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-09-16 13:16:41+0900">2025년 9월 16일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-9-12-2D-Gaussian-Splatting-with-Semantic-Alignment-for-Image-Inpainting">[논문리뷰] 2D Gaussian Splatting with Semantic Alignment for Image Inpainting</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-9-12-2D-Gaussian-Splatting-with-Semantic-Alignment-for-Image-Inpainting">Guangming Lu이 arXiv에 게시한 &#x27;2D Gaussian Splatting with Semantic Alignment for Image Inpainting&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-09-12 13:12:46+0900">2025년 9월 12일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-9-11-3D-and-4D-World-Modeling-A-Survey">[논문리뷰] 3D and 4D World Modeling: A Survey</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-9-11-3D-and-4D-World-Modeling-A-Survey">Ao Liang이 arXiv에 게시한 &#x27;3D and 4D World Modeling: A Survey&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-09-11 13:02:36+0900">2025년 9월 11일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-9-8-LuxDiT-Lighting-Estimation-with-Video-Diffusion-Transformer">[논문리뷰] LuxDiT: Lighting Estimation with Video Diffusion Transformer</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-9-8-LuxDiT-Lighting-Estimation-with-Video-Diffusion-Transformer">Sanja Fidler이 arXiv에 게시한 &#x27;LuxDiT: Lighting Estimation with Video Diffusion Transformer&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-09-08 13:10:18+0900">2025년 9월 8일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-9-5-Transition-Models-Rethinking-the-Generative-Learning-Objective">[논문리뷰] Transition Models: Rethinking the Generative Learning Objective</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-9-5-Transition-Models-Rethinking-the-Generative-Learning-Objective">Yangguang Li이 arXiv에 게시한 &#x27;Transition Models: Rethinking the Generative Learning Objective&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-09-05 13:07:20+0900">2025년 9월 5일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-9-3-Towards-More-Diverse-and-Challenging-Pre-training-for-Point-Cloud-Learning-Self-Supervised-Cross-Reconstruction-with-Decoupled-Views">[논문리뷰] Towards More Diverse and Challenging Pre-training for Point Cloud Learning: Self-Supervised Cross Reconstruction with Decoupled Views</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-9-3-Towards-More-Diverse-and-Challenging-Pre-training-for-Point-Cloud-Learning-Self-Supervised-Cross-Reconstruction-with-Decoupled-Views">Junchi Yan이 arXiv에 게시한 &#x27;Towards More Diverse and Challenging Pre-training for Point Cloud Learning: Self-Supervised Cross Reconstruction with Decoupled Views&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-09-03 13:36:21+0900">2025년 9월 3일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-9-3-LLaVA-Critic-R1-Your-Critic-Model-is-Secretly-a-Strong-Policy-Model">[논문리뷰] LLaVA-Critic-R1: Your Critic Model is Secretly a Strong Policy Model</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-9-3-LLaVA-Critic-R1-Your-Critic-Model-is-Secretly-a-Strong-Policy-Model">Jianwei Yang이 arXiv에 게시한 &#x27;LLaVA-Critic-R1: Your Critic Model is Secretly a Strong Policy Model&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-09-03 13:36:21+0900">2025년 9월 3일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-9-3-GenCompositor-Generative-Video-Compositing-with-Diffusion-Transformer">[논문리뷰] GenCompositor: Generative Video Compositing with Diffusion Transformer</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-9-3-GenCompositor-Generative-Video-Compositing-with-Diffusion-Transformer">Lingen Li이 arXiv에 게시한 &#x27;GenCompositor: Generative Video Compositing with Diffusion Transformer&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-09-03 13:36:21+0900">2025년 9월 3일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-8-29-Mixture-of-Contexts-for-Long-Video-Generation">[논문리뷰] Mixture of Contexts for Long Video Generation</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-8-29-Mixture-of-Contexts-for-Long-Video-Generation">Junfei Xiao이 arXiv에 게시한 &#x27;Mixture of Contexts for Long Video Generation&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-08-29 13:14:44+0900">2025년 8월 29일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-8-29-FakeParts-a-New-Family-of-AI-Generated-DeepFakes">[논문리뷰] FakeParts: a New Family of AI-Generated DeepFakes</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-8-29-FakeParts-a-New-Family-of-AI-Generated-DeepFakes">Xi Wang이 arXiv에 게시한 &#x27;FakeParts: a New Family of AI-Generated DeepFakes&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-08-29 13:14:44+0900">2025년 8월 29일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-8-27-ObjFiller-3D-Consistent-Multi-view-3D-Inpainting-via-Video-Diffusion-Models">[논문리뷰] ObjFiller-3D: Consistent Multi-view 3D Inpainting via Video Diffusion Models</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-8-27-ObjFiller-3D-Consistent-Multi-view-3D-Inpainting-via-Video-Diffusion-Models">Beiqi Chen이 arXiv에 게시한 &#x27;ObjFiller-3D: Consistent Multi-view 3D Inpainting via Video Diffusion Models&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-08-27 13:22:18+0900">2025년 8월 27일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-8-25-Selective-Contrastive-Learning-for-Weakly-Supervised-Affordance-Grounding">[논문리뷰] Selective Contrastive Learning for Weakly Supervised Affordance Grounding</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-8-25-Selective-Contrastive-Learning-for-Weakly-Supervised-Affordance-Grounding">Jae-Pil Heo이 arXiv에 게시한 &#x27;Selective Contrastive Learning for Weakly Supervised Affordance Grounding&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-08-25 13:13:07+0900">2025년 8월 25일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-8-20-Semantic-IDs-for-Joint-Generative-Search-and-Recommendation">[논문리뷰] Semantic IDs for Joint Generative Search and Recommendation</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-8-20-Semantic-IDs-for-Joint-Generative-Search-and-Recommendation">Enrico Palumbo이 arXiv에 게시한 &#x27;Semantic IDs for Joint Generative Search and Recommendation&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-08-20 13:26:54+0900">2025년 8월 20일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-8-19-S2-Guidance-Stochastic-Self-Guidance-for-Training-Free-Enhancement-of-Diffusion-Models">[논문리뷰] S^2-Guidance: Stochastic Self Guidance for Training-Free Enhancement of Diffusion Models</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-8-19-S2-Guidance-Stochastic-Self-Guidance-for-Training-Free-Enhancement-of-Diffusion-Models">Meiqi Wu이 arXiv에 게시한 &#x27;S^2-Guidance: Stochastic Self Guidance for Training-Free Enhancement of Diffusion Models&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-08-19 13:15:01+0900">2025년 8월 19일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-8-19-Lumen-Consistent-Video-Relighting-and-Harmonious-Background-Replacement-with-Video-Generative-Models">[논문리뷰] Lumen: Consistent Video Relighting and Harmonious Background Replacement with Video Generative Models</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-8-19-Lumen-Consistent-Video-Relighting-and-Harmonious-Background-Replacement-with-Video-Generative-Models">Zixiang Gao이 arXiv에 게시한 &#x27;Lumen: Consistent Video Relighting and Harmonious Background Replacement with Video Generative Models&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-08-19 13:15:01+0900">2025년 8월 19일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-8-19-4DNeX-Feed-Forward-4D-Generative-Modeling-Made-Easy">[논문리뷰] 4DNeX: Feed-Forward 4D Generative Modeling Made Easy</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-8-19-4DNeX-Feed-Forward-4D-Generative-Modeling-Made-Easy">Zeng Tao이 arXiv에 게시한 &#x27;4DNeX: Feed-Forward 4D Generative Modeling Made Easy&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-08-19 13:15:01+0900">2025년 8월 19일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-8-12-Follow-Your-Shape-Shape-Aware-Image-Editing-via-Trajectory-Guided-Region-Control">[논문리뷰] Follow-Your-Shape: Shape-Aware Image Editing via Trajectory-Guided Region Control</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-8-12-Follow-Your-Shape-Shape-Aware-Image-Editing-via-Trajectory-Guided-Region-Control">Hongyu Liu이 arXiv에 게시한 &#x27;Follow-Your-Shape: Shape-Aware Image Editing via Trajectory-Guided Region Control&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-08-12 13:29:09+0900">2025년 8월 12일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-8-7-SonicMaster-Towards-Controllable-All-in-One-Music-Restoration-and-Mastering">[논문리뷰] SonicMaster: Towards Controllable All-in-One Music Restoration and Mastering</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-8-7-SonicMaster-Towards-Controllable-All-in-One-Music-Restoration-and-Mastering">Ambuj Mehrish이 arXiv에 게시한 &#x27;SonicMaster: Towards Controllable All-in-One Music Restoration and Mastering&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-08-07 13:38:21+0900">2025년 8월 7일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/ai/review/2025-8-4-PixNerd-Pixel-Neural-Field-Diffusion">[논문리뷰] PixNerd: Pixel Neural Field Diffusion</a></h2><div class="archive__item-excerpt"><a href="/ai/review/2025-8-4-PixNerd-Pixel-Neural-Field-Diffusion">Limin Wang이 arXiv에 게시한 &#x27;PixNerd: Pixel Neural Field Diffusion&#x27; 논문에 대한 자세한 리뷰입니다.</a></div><div class="archive__item-meta"><time dateTime="2025-08-04 12:17:01+0900">2025년 8월 4일</time><span class="text-gray-400 text-sm ml-3" role="status"><svg class="inline w-3 h-3 animate-spin" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" aria-hidden="true"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path></svg><span class="sr-only">댓글 수 로딩 중</span></span></div></article></div></div></div></div><!--/$--></main><div id="footer" class="page__footer"><footer class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8"><div class="text-center text-gray-500 text-sm"><p>© <!-- -->2026<!-- --> secrett2633. All rights reserved.</p></div></footer></div></div><script src="/_next/static/chunks/webpack-90b03762f46d1ba4.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/media/e4af272ccee01ff0-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n2:HL[\"/_next/static/css/edb8d4ad4fe2f3b0.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"3:I[5751,[],\"\"]\n5:I[9038,[\"231\",\"static/chunks/231-ee5764c1002761f9.js\",\"605\",\"static/chunks/app/tags/%5Btag%5D/page-a05565f8ea9cbb05.js\"],\"default\"]\n6:I[231,[\"231\",\"static/chunks/231-ee5764c1002761f9.js\",\"605\",\"static/chunks/app/tags/%5Btag%5D/page-a05565f8ea9cbb05.js\"],\"\"]\n7:I[227,[\"231\",\"static/chunks/231-ee5764c1002761f9.js\",\"605\",\"static/chunks/app/tags/%5Btag%5D/page-a05565f8ea9cbb05.js\"],\"default\"]\n8:I[9275,[],\"\"]\na:I[1343,[],\"\"]\nb:I[9157,[\"231\",\"static/chunks/231-ee5764c1002761f9.js\",\"132\",\"static/chunks/132-273e49420772df1e.js\",\"185\",\"static/chunks/app/layout-d443cbc354279241.js\"],\"default\"]\nc:I[4080,[\"231\",\"static/chunks/231-ee5764c1002761f9.js\",\"132\",\"static/chunks/132-273e49420772df1e.js\",\"185\",\"static/chunks/app/layout-d443cbc354279241.js\"],\"\"]\ne:I[6130,[],\"\"]\n9:[\"tag\",\"Generative%20Models\",\"d\"]\nf:[]\n"])</script><script>self.__next_f.push([1,"0:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/edb8d4ad4fe2f3b0.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L3\",null,{\"buildId\":\"mJI0q5Z-SQWBtT83kG_N7\",\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/tags/Generative%20Models\",\"initialTree\":[\"\",{\"children\":[\"tags\",{\"children\":[[\"tag\",\"Generative%20Models\",\"d\"],{\"children\":[\"__PAGE__?{\\\"tag\\\":\\\"Generative Models\\\"}\",{}]}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"tags\",{\"children\":[[\"tag\",\"Generative%20Models\",\"d\"],{\"children\":[\"__PAGE__\",{},[[\"$L4\",[\"$\",\"$L5\",null,{\"children\":[[\"$\",\"script\",null,{\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"{\\\"@context\\\":\\\"https://schema.org\\\",\\\"@type\\\":\\\"CollectionPage\\\",\\\"name\\\":\\\"#Generative Models - secrett2633's blog\\\",\\\"description\\\":\\\"Generative Models 태그가 포함된 포스트 목록\\\",\\\"url\\\":\\\"https://blog.secrett2633.cloud/tags/Generative%20Models\\\",\\\"isPartOf\\\":{\\\"@type\\\":\\\"WebSite\\\",\\\"name\\\":\\\"secrett2633's blog\\\",\\\"url\\\":\\\"https://blog.secrett2633.cloud\\\"},\\\"inLanguage\\\":\\\"ko\\\"}\"}}],[\"$\",\"script\",null,{\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"{\\\"@context\\\":\\\"https://schema.org\\\",\\\"@type\\\":\\\"BreadcrumbList\\\",\\\"itemListElement\\\":[{\\\"@type\\\":\\\"ListItem\\\",\\\"position\\\":1,\\\"name\\\":\\\"홈\\\",\\\"item\\\":\\\"https://blog.secrett2633.cloud/\\\"},{\\\"@type\\\":\\\"ListItem\\\",\\\"position\\\":2,\\\"name\\\":\\\"#Generative Models\\\",\\\"item\\\":\\\"https://blog.secrett2633.cloud/tags/Generative%20Models\\\"}]}\"}}],[\"$\",\"div\",null,{\"className\":\"space-y-6\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex flex-col lg:flex-row gap-8\",\"children\":[[\"$\",\"aside\",null,{\"className\":\"lg:w-64 xl:w-72 order-1 lg:order-none\",\"children\":[\"$\",\"div\",null,{\"className\":\"sidebar sticky\",\"children\":[\"$\",\"nav\",null,{\"className\":\"space-y-4\",\"aria-label\":\"카테고리 네비게이션\",\"children\":[[\"$\",\"div\",\"Backend\",{\"children\":[[\"$\",\"p\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"Backend\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"Django\",{\"children\":[\"$\",\"$L6\",null,{\"href\":\"/backend/django\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Django\",\" (\",6,\")\"]}]}],[\"$\",\"li\",\"Logging\",{\"children\":[\"$\",\"$L6\",null,{\"href\":\"/backend/logging\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Logging\",\" (\",1,\")\"]}]}]]}]]}],[\"$\",\"div\",\"Python\",{\"children\":[[\"$\",\"p\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"Python\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"PEP\",{\"children\":[\"$\",\"$L6\",null,{\"href\":\"/python/pep\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"PEP\",\" (\",650,\")\"]}]}]]}]]}],[\"$\",\"div\",\"AI/ML\",{\"children\":[[\"$\",\"p\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"AI/ML\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"LLM\",{\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/llm\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"LLM\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"Review\",{\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Review\",\" (\",2741,\")\"]}]}]]}]]}],[\"$\",\"div\",\"DevOps\",{\"children\":[[\"$\",\"p\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"DevOps\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"Nginx\",{\"children\":[\"$\",\"$L6\",null,{\"href\":\"/devops/nginx\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Nginx\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"Docker\",{\"children\":[\"$\",\"$L6\",null,{\"href\":\"/devops/docker\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Docker\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"SafeLine\",{\"children\":[\"$\",\"$L6\",null,{\"href\":\"/devops/safeline\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"SafeLine\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"Jenkins\",{\"children\":[\"$\",\"$L6\",null,{\"href\":\"/devops/jenkins\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Jenkins\",\" (\",3,\")\"]}]}],[\"$\",\"li\",\"GitHub Actions\",{\"children\":[\"$\",\"$L6\",null,{\"href\":\"/devops/github-actions\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"GitHub Actions\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"AWS\",{\"children\":[\"$\",\"$L6\",null,{\"href\":\"/devops/aws\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"AWS\",\" (\",1,\")\"]}]}]]}]]}],[\"$\",\"div\",\"etc\",{\"children\":[[\"$\",\"p\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"etc\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"Me\",{\"children\":[\"$\",\"$L6\",null,{\"href\":\"/etc/me\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Me\",\" (\",3,\")\"]}]}],[\"$\",\"li\",\"Chrome Extension\",{\"children\":[\"$\",\"$L6\",null,{\"href\":\"/etc/chrome-extension\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Chrome Extension\",\" (\",1,\")\"]}]}]]}]]}]]}]}]}],[\"$\",\"div\",null,{\"className\":\"flex-1\",\"children\":[[\"$\",\"nav\",null,{\"aria-label\":\"breadcrumb\",\"className\":\"text-sm text-gray-500 mb-4\",\"children\":[\"$\",\"ol\",null,{\"className\":\"flex flex-wrap items-center gap-1\",\"children\":[[\"$\",\"li\",null,{\"children\":[\"$\",\"$L6\",null,{\"href\":\"/\",\"className\":\"hover:text-gray-700\",\"children\":\"홈\"}]}],[[\"$\",\"li\",\"/tags/Generative%20Models\",{\"className\":\"flex items-center gap-1\",\"children\":[[\"$\",\"span\",null,{\"aria-hidden\":\"true\",\"children\":\"/\"}],[\"$\",\"span\",null,{\"className\":\"text-gray-900\",\"aria-current\":\"page\",\"children\":\"#Generative Models\"}]]}]]]}]}],[\"$\",\"h1\",null,{\"className\":\"page__title mb-6\",\"children\":[\"#\",\"Generative Models\"]}],[\"$\",\"p\",null,{\"className\":\"text-gray-500 mb-6\",\"children\":[83,\"개의 포스트\"]}],[\"$\",\"div\",null,{\"className\":\"entries-list\",\"children\":[[\"$\",\"article\",\"2026-02-19-Optimizing-Few-Step-Generation-with-Adaptive-Matching-Distillation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2026-02-19-Optimizing-Few-Step-Generation-with-Adaptive-Matching-Distillation\",\"children\":\"[논문리뷰] Optimizing Few-Step Generation with Adaptive Matching Distillation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2026-02-19-Optimizing-Few-Step-Generation-with-Adaptive-Matching-Distillation\",\"children\":\"arXiv에 게시된 'Optimizing Few-Step Generation with Adaptive Matching Distillation' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2026-02-19 00:00:00+0900+0900\",\"children\":\"2026년 2월 19일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2026-02-19-Optimizing-Few-Step-Generation-with-Adaptive-Matching-Distillation\"}]]}]]}],[\"$\",\"article\",\"2026-02-09-Back-to-Basics-Revisiting-Exploration-in-Reinforcement-Learning-for-LLM-Reasoning-via-Generative-Probabilities\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2026-02-09-Back-to-Basics-Revisiting-Exploration-in-Reinforcement-Learning-for-LLM-Reasoning-via-Generative-Probabilities\",\"children\":\"[논문리뷰] Back to Basics: Revisiting Exploration in Reinforcement Learning for LLM Reasoning via Generative Probabilities\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2026-02-09-Back-to-Basics-Revisiting-Exploration-in-Reinforcement-Learning-for-LLM-Reasoning-via-Generative-Probabilities\",\"children\":\"Ivan Oseledets이 arXiv에 게시한 'Back to Basics: Revisiting Exploration in Reinforcement Learning for LLM Reasoning via Generative Probabilities' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2026-02-09 00:00:00+0900+0900\",\"children\":\"2026년 2월 9일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2026-02-09-Back-to-Basics-Revisiting-Exploration-in-Reinforcement-Learning-for-LLM-Reasoning-via-Generative-Probabilities\"}]]}]]}],[\"$\",\"article\",\"2026-02-04-Research-on-World-Models-Is-Not-Merely-Injecting-World-Knowledge-into-Specific-Tasks\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2026-02-04-Research-on-World-Models-Is-Not-Merely-Injecting-World-Knowledge-into-Specific-Tasks\",\"children\":\"[논문리뷰] Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2026-02-04-Research-on-World-Models-Is-Not-Merely-Injecting-World-Knowledge-into-Specific-Tasks\",\"children\":\"arXiv에 게시된 'Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2026-02-04 00:00:00+0900+0900\",\"children\":\"2026년 2월 4일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2026-02-04-Research-on-World-Models-Is-Not-Merely-Injecting-World-Knowledge-into-Specific-Tasks\"}]]}]]}],[\"$\",\"article\",\"2026-02-03-How-Well-Do-Models-Follow-Visual-Instructions-VIBE-A-Systematic-Benchmark-for-Visual-Instruction-Driven-Image-Editing\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2026-02-03-How-Well-Do-Models-Follow-Visual-Instructions-VIBE-A-Systematic-Benchmark-for-Visual-Instruction-Driven-Image-Editing\",\"children\":\"[논문리뷰] How Well Do Models Follow Visual Instructions? VIBE: A Systematic Benchmark for Visual Instruction-Driven Image Editing\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2026-02-03-How-Well-Do-Models-Follow-Visual-Instructions-VIBE-A-Systematic-Benchmark-for-Visual-Instruction-Driven-Image-Editing\",\"children\":\"Haochen Tian이 arXiv에 게시한 'How Well Do Models Follow Visual Instructions? VIBE: A Systematic Benchmark for Visual Instruction-Driven Image Editing' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2026-02-03 00:00:00+0900+0900\",\"children\":\"2026년 2월 3일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2026-02-03-How-Well-Do-Models-Follow-Visual-Instructions-VIBE-A-Systematic-Benchmark-for-Visual-Instruction-Driven-Image-Editing\"}]]}]]}],[\"$\",\"article\",\"2026-02-02-Revisiting-Diffusion-Model-Predictions-Through-Dimensionality\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2026-02-02-Revisiting-Diffusion-Model-Predictions-Through-Dimensionality\",\"children\":\"[논문리뷰] Revisiting Diffusion Model Predictions Through Dimensionality\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2026-02-02-Revisiting-Diffusion-Model-Predictions-Through-Dimensionality\",\"children\":\"Chaoyang Wang이 arXiv에 게시한 'Revisiting Diffusion Model Predictions Through Dimensionality' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2026-02-02 00:00:00+0900+0900\",\"children\":\"2026년 2월 2일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2026-02-02-Revisiting-Diffusion-Model-Predictions-Through-Dimensionality\"}]]}]]}],[\"$\",\"article\",\"2026-01-29-Advancing-Open-source-World-Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2026-01-29-Advancing-Open-source-World-Models\",\"children\":\"[논문리뷰] Advancing Open-source World Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2026-01-29-Advancing-Open-source-World-Models\",\"children\":\"arXiv에 게시된 'Advancing Open-source World Models' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2026-01-29 00:00:00+0900+0900\",\"children\":\"2026년 1월 29일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2026-01-29-Advancing-Open-source-World-Models\"}]]}]]}],[\"$\",\"article\",\"2026-01-23-ActionMesh-Animated-3D-Mesh-Generation-with-Temporal-3D-Diffusion\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2026-01-23-ActionMesh-Animated-3D-Mesh-Generation-with-Temporal-3D-Diffusion\",\"children\":\"[논문리뷰] ActionMesh: Animated 3D Mesh Generation with Temporal 3D Diffusion\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2026-01-23-ActionMesh-Animated-3D-Mesh-Generation-with-Temporal-3D-Diffusion\",\"children\":\"arXiv에 게시된 'ActionMesh: Animated 3D Mesh Generation with Temporal 3D Diffusion' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2026-01-23 00:00:00+0900+0900\",\"children\":\"2026년 1월 23일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2026-01-23-ActionMesh-Animated-3D-Mesh-Generation-with-Temporal-3D-Diffusion\"}]]}]]}],[\"$\",\"article\",\"2026-01-13-BabyVision-Visual-Reasoning-Beyond-Language\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2026-01-13-BabyVision-Visual-Reasoning-Beyond-Language\",\"children\":\"[논문리뷰] BabyVision: Visual Reasoning Beyond Language\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2026-01-13-BabyVision-Visual-Reasoning-Beyond-Language\",\"children\":\"Yiyan Liang이 arXiv에 게시한 'BabyVision: Visual Reasoning Beyond Language' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2026-01-13 00:00:00+0900+0900\",\"children\":\"2026년 1월 13일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2026-01-13-BabyVision-Visual-Reasoning-Beyond-Language\"}]]}]]}],[\"$\",\"article\",\"2026-01-12-GenCtrl-A-Formal-Controllability-Toolkit-for-Generative-Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2026-01-12-GenCtrl-A-Formal-Controllability-Toolkit-for-Generative-Models\",\"children\":\"[논문리뷰] GenCtrl -- A Formal Controllability Toolkit for Generative Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2026-01-12-GenCtrl-A-Formal-Controllability-Toolkit-for-Generative-Models\",\"children\":\"arXiv에 게시된 'GenCtrl -- A Formal Controllability Toolkit for Generative Models' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2026-01-12 00:00:00+0900+0900\",\"children\":\"2026년 1월 12일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2026-01-12-GenCtrl-A-Formal-Controllability-Toolkit-for-Generative-Models\"}]]}]]}],[\"$\",\"article\",\"2026-01-09-Memorization-in-3D-Shape-Generation-An-Empirical-Study\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2026-01-09-Memorization-in-3D-Shape-Generation-An-Empirical-Study\",\"children\":\"[논문리뷰] Memorization in 3D Shape Generation: An Empirical Study\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2026-01-09-Memorization-in-3D-Shape-Generation-An-Empirical-Study\",\"children\":\"arXiv에 게시된 'Memorization in 3D Shape Generation: An Empirical Study' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2026-01-09 00:00:00+0900+0900\",\"children\":\"2026년 1월 9일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2026-01-09-Memorization-in-3D-Shape-Generation-An-Empirical-Study\"}]]}]]}],[\"$\",\"article\",\"2026-01-07-FFP-300K-Scaling-First-Frame-Propagation-for-Generalizable-Video-Editing\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2026-01-07-FFP-300K-Scaling-First-Frame-Propagation-for-Generalizable-Video-Editing\",\"children\":\"[논문리뷰] FFP-300K: Scaling First-Frame Propagation for Generalizable Video Editing\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2026-01-07-FFP-300K-Scaling-First-Frame-Propagation-for-Generalizable-Video-Editing\",\"children\":\"Peng Tang이 arXiv에 게시한 'FFP-300K: Scaling First-Frame Propagation for Generalizable Video Editing' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2026-01-07 00:00:00+0900+0900\",\"children\":\"2026년 1월 7일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2026-01-07-FFP-300K-Scaling-First-Frame-Propagation-for-Generalizable-Video-Editing\"}]]}]]}],[\"$\",\"article\",\"2026-01-05-MorphAny3D-Unleashing-the-Power-of-Structured-Latent-in-3D-Morphing\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2026-01-05-MorphAny3D-Unleashing-the-Power-of-Structured-Latent-in-3D-Morphing\",\"children\":\"[논문리뷰] MorphAny3D: Unleashing the Power of Structured Latent in 3D Morphing\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2026-01-05-MorphAny3D-Unleashing-the-Power-of-Structured-Latent-in-3D-Morphing\",\"children\":\"Jian Yang이 arXiv에 게시한 'MorphAny3D: Unleashing the Power of Structured Latent in 3D Morphing' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2026-01-05 00:00:00+0900+0900\",\"children\":\"2026년 1월 5일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2026-01-05-MorphAny3D-Unleashing-the-Power-of-Structured-Latent-in-3D-Morphing\"}]]}]]}],[\"$\",\"article\",\"2025-12-23-The-Prism-Hypothesis-Harmonizing-Semantic-and-Pixel-Representations-via-Unified-Autoencoding\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-12-23-The-Prism-Hypothesis-Harmonizing-Semantic-and-Pixel-Representations-via-Unified-Autoencoding\",\"children\":\"[논문리뷰] The Prism Hypothesis: Harmonizing Semantic and Pixel Representations via Unified Autoencoding\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-12-23-The-Prism-Hypothesis-Harmonizing-Semantic-and-Pixel-Representations-via-Unified-Autoencoding\",\"children\":\"Ziwei Liu이 arXiv에 게시한 'The Prism Hypothesis: Harmonizing Semantic and Pixel Representations via Unified Autoencoding' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-12-23 00:00:00+0900+0900\",\"children\":\"2025년 12월 23일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-12-23-The-Prism-Hypothesis-Harmonizing-Semantic-and-Pixel-Representations-via-Unified-Autoencoding\"}]]}]]}],[\"$\",\"article\",\"2025-12-19-Alchemist-Unlocking-Efficiency-in-Text-to-Image-Model-Training-via-Meta-Gradient-Data-Selection\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-12-19-Alchemist-Unlocking-Efficiency-in-Text-to-Image-Model-Training-via-Meta-Gradient-Data-Selection\",\"children\":\"[논문리뷰] Alchemist: Unlocking Efficiency in Text-to-Image Model Training via Meta-Gradient Data Selection\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-12-19-Alchemist-Unlocking-Efficiency-in-Text-to-Image-Model-Training-via-Meta-Gradient-Data-Selection\",\"children\":\"Jiarong Ou이 arXiv에 게시한 'Alchemist: Unlocking Efficiency in Text-to-Image Model Training via Meta-Gradient Data Selection' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-12-19 00:00:00+0900+0900\",\"children\":\"2025년 12월 19일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-12-19-Alchemist-Unlocking-Efficiency-in-Text-to-Image-Model-Training-via-Meta-Gradient-Data-Selection\"}]]}]]}],[\"$\",\"article\",\"2025-12-18-Robust-and-Calibrated-Detection-of-Authentic-Multimedia-Content\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-12-18-Robust-and-Calibrated-Detection-of-Authentic-Multimedia-Content\",\"children\":\"[논문리뷰] Robust and Calibrated Detection of Authentic Multimedia Content\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-12-18-Robust-and-Calibrated-Detection-of-Authentic-Multimedia-Content\",\"children\":\"arXiv에 게시된 'Robust and Calibrated Detection of Authentic Multimedia Content' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-12-18 00:00:00+0900+0900\",\"children\":\"2025년 12월 18일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-12-18-Robust-and-Calibrated-Detection-of-Authentic-Multimedia-Content\"}]]}]]}],[\"$\",\"article\",\"2025-12-16-Towards-Scalable-Pre-training-of-Visual-Tokenizers-for-Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-12-16-Towards-Scalable-Pre-training-of-Visual-Tokenizers-for-Generation\",\"children\":\"[논문리뷰] Towards Scalable Pre-training of Visual Tokenizers for Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-12-16-Towards-Scalable-Pre-training-of-Visual-Tokenizers-for-Generation\",\"children\":\"arXiv에 게시된 'Towards Scalable Pre-training of Visual Tokenizers for Generation' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-12-16 00:00:00+0900+0900\",\"children\":\"2025년 12월 16일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-12-16-Towards-Scalable-Pre-training-of-Visual-Tokenizers-for-Generation\"}]]}]]}],[\"$\",\"article\",\"2025-12-10-TreeGRPO-Tree-Advantage-GRPO-for-Online-RL-Post-Training-of-Diffusion-Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-12-10-TreeGRPO-Tree-Advantage-GRPO-for-Online-RL-Post-Training-of-Diffusion-Models\",\"children\":\"[논문리뷰] TreeGRPO: Tree-Advantage GRPO for Online RL Post-Training of Diffusion Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-12-10-TreeGRPO-Tree-Advantage-GRPO-for-Online-RL-Post-Training-of-Diffusion-Models\",\"children\":\"Weirui Ye이 arXiv에 게시한 'TreeGRPO: Tree-Advantage GRPO for Online RL Post-Training of Diffusion Models' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-12-10 00:00:00+0900+0900\",\"children\":\"2025년 12월 10일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-12-10-TreeGRPO-Tree-Advantage-GRPO-for-Online-RL-Post-Training-of-Diffusion-Models\"}]]}]]}],[\"$\",\"article\",\"2025-12-10-From-Next-Token-to-Next-Block-A-Principled-Adaptation-Path-for-Diffusion-LLMs\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-12-10-From-Next-Token-to-Next-Block-A-Principled-Adaptation-Path-for-Diffusion-LLMs\",\"children\":\"[논문리뷰] From Next-Token to Next-Block: A Principled Adaptation Path for Diffusion LLMs\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-12-10-From-Next-Token-to-Next-Block-A-Principled-Adaptation-Path-for-Diffusion-LLMs\",\"children\":\"arXiv에 게시된 'From Next-Token to Next-Block: A Principled Adaptation Path for Diffusion LLMs' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-12-10 00:00:00+0900+0900\",\"children\":\"2025년 12월 10일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-12-10-From-Next-Token-to-Next-Block-A-Principled-Adaptation-Path-for-Diffusion-LLMs\"}]]}]]}],[\"$\",\"article\",\"2025-12-09-Distribution-Matching-Variational-AutoEncoder\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-12-09-Distribution-Matching-Variational-AutoEncoder\",\"children\":\"[논문리뷰] Distribution Matching Variational AutoEncoder\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-12-09-Distribution-Matching-Variational-AutoEncoder\",\"children\":\"arXiv에 게시된 'Distribution Matching Variational AutoEncoder' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-12-09 00:00:00+0900+0900\",\"children\":\"2025년 12월 9일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-12-09-Distribution-Matching-Variational-AutoEncoder\"}]]}]]}],[\"$\",\"article\",\"2025-12-08-TwinFlow-Realizing-One-step-Generation-on-Large-Models-with-Self-adversarial-Flows\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-12-08-TwinFlow-Realizing-One-step-Generation-on-Large-Models-with-Self-adversarial-Flows\",\"children\":\"[논문리뷰] TwinFlow: Realizing One-step Generation on Large Models with Self-adversarial Flows\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-12-08-TwinFlow-Realizing-One-step-Generation-on-Large-Models-with-Self-adversarial-Flows\",\"children\":\"arXiv에 게시된 'TwinFlow: Realizing One-step Generation on Large Models with Self-adversarial Flows' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-12-08 00:00:00+0900+0900\",\"children\":\"2025년 12월 8일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-12-08-TwinFlow-Realizing-One-step-Generation-on-Large-Models-with-Self-adversarial-Flows\"}]]}]]}],[\"$\",\"article\",\"2025-12-05-Generative-Neural-Video-Compression-via-Video-Diffusion-Prior\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-12-05-Generative-Neural-Video-Compression-via-Video-Diffusion-Prior\",\"children\":\"[논문리뷰] Generative Neural Video Compression via Video Diffusion Prior\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-12-05-Generative-Neural-Video-Compression-via-Video-Diffusion-Prior\",\"children\":\"arXiv에 게시된 'Generative Neural Video Compression via Video Diffusion Prior' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-12-05 00:00:00+0900+0900\",\"children\":\"2025년 12월 5일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-12-05-Generative-Neural-Video-Compression-via-Video-Diffusion-Prior\"}]]}]]}],[\"$\",\"article\",\"2025-12-04-Flowing-Backwards-Improving-Normalizing-Flows-via-Reverse-Representation-Alignment\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-12-04-Flowing-Backwards-Improving-Normalizing-Flows-via-Reverse-Representation-Alignment\",\"children\":\"[논문리뷰] Flowing Backwards: Improving Normalizing Flows via Reverse Representation Alignment\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-12-04-Flowing-Backwards-Improving-Normalizing-Flows-via-Reverse-Representation-Alignment\",\"children\":\"arXiv에 게시된 'Flowing Backwards: Improving Normalizing Flows via Reverse Representation Alignment' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-12-04 00:00:00+0900+0900\",\"children\":\"2025년 12월 4일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-12-04-Flowing-Backwards-Improving-Normalizing-Flows-via-Reverse-Representation-Alignment\"}]]}]]}],[\"$\",\"article\",\"2025-12-02-Envision-Benchmarking-Unified-Understanding-Generation-for-Causal-World-Process-Insights\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-12-02-Envision-Benchmarking-Unified-Understanding-Generation-for-Causal-World-Process-Insights\",\"children\":\"[논문리뷰] Envision: Benchmarking Unified Understanding \u0026 Generation for Causal World Process Insights\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-12-02-Envision-Benchmarking-Unified-Understanding-Generation-for-Causal-World-Process-Insights\",\"children\":\"arXiv에 게시된 'Envision: Benchmarking Unified Understanding \u0026 Generation for Causal World Process Insights' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-12-02 00:00:00+0900+0900\",\"children\":\"2025년 12월 2일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-12-02-Envision-Benchmarking-Unified-Understanding-Generation-for-Causal-World-Process-Insights\"}]]}]]}],[\"$\",\"article\",\"2025-12-01-Test-time-scaling-of-diffusions-with-flow-maps\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-12-01-Test-time-scaling-of-diffusions-with-flow-maps\",\"children\":\"[논문리뷰] Test-time scaling of diffusions with flow maps\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-12-01-Test-time-scaling-of-diffusions-with-flow-maps\",\"children\":\"Sanja Fidler이 arXiv에 게시한 'Test-time scaling of diffusions with flow maps' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-12-01 00:00:00+0900+0900\",\"children\":\"2025년 12월 1일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-12-01-Test-time-scaling-of-diffusions-with-flow-maps\"}]]}]]}],[\"$\",\"article\",\"2025-12-01-Adversarial-Flow-Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-12-01-Adversarial-Flow-Models\",\"children\":\"[논문리뷰] Adversarial Flow Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-12-01-Adversarial-Flow-Models\",\"children\":\"arXiv에 게시된 'Adversarial Flow Models' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-12-01 00:00:00+0900+0900\",\"children\":\"2025년 12월 1일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-12-01-Adversarial-Flow-Models\"}]]}]]}],[\"$\",\"article\",\"2025-11-27-Terminal-Velocity-Matching\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-11-27-Terminal-Velocity-Matching\",\"children\":\"[논문리뷰] Terminal Velocity Matching\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-11-27-Terminal-Velocity-Matching\",\"children\":\"Jiaming Song이 arXiv에 게시한 'Terminal Velocity Matching' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-11-27 00:00:00+0900+0900\",\"children\":\"2025년 11월 27일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-11-27-Terminal-Velocity-Matching\"}]]}]]}],[\"$\",\"article\",\"2025-11-25-In-Video-Instructions-Visual-Signals-as-Generative-Control\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-11-25-In-Video-Instructions-Visual-Signals-as-Generative-Control\",\"children\":\"[논문리뷰] In-Video Instructions: Visual Signals as Generative Control\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-11-25-In-Video-Instructions-Visual-Signals-as-Generative-Control\",\"children\":\"arXiv에 게시된 'In-Video Instructions: Visual Signals as Generative Control' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-11-25 00:00:00+0900+0900\",\"children\":\"2025년 11월 25일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-11-25-In-Video-Instructions-Visual-Signals-as-Generative-Control\"}]]}]]}],[\"$\",\"article\",\"2025-11-25-Flow-Map-Distillation-Without-Data\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-11-25-Flow-Map-Distillation-Without-Data\",\"children\":\"[논문리뷰] Flow Map Distillation Without Data\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-11-25-Flow-Map-Distillation-Without-Data\",\"children\":\"Tommi Jaakkola이 arXiv에 게시한 'Flow Map Distillation Without Data' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-11-25 00:00:00+0900+0900\",\"children\":\"2025년 11월 25일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-11-25-Flow-Map-Distillation-Without-Data\"}]]}]]}],[\"$\",\"article\",\"2025-11-21-SAM-3D-3Dfy-Anything-in-Images\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-11-21-SAM-3D-3Dfy-Anything-in-Images\",\"children\":\"[논문리뷰] SAM 3D: 3Dfy Anything in Images\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-11-21-SAM-3D-3Dfy-Anything-in-Images\",\"children\":\"arXiv에 게시된 'SAM 3D: 3Dfy Anything in Images' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-11-21 00:00:00+0900+0900\",\"children\":\"2025년 11월 21일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-11-21-SAM-3D-3Dfy-Anything-in-Images\"}]]}]]}],[\"$\",\"article\",\"2025-11-14-SliderEdit-Continuous-Image-Editing-with-Fine-Grained-Instruction-Control\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-11-14-SliderEdit-Continuous-Image-Editing-with-Fine-Grained-Instruction-Control\",\"children\":\"[논문리뷰] SliderEdit: Continuous Image Editing with Fine-Grained Instruction Control\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-11-14-SliderEdit-Continuous-Image-Editing-with-Fine-Grained-Instruction-Control\",\"children\":\"Ryan Rossi이 arXiv에 게시한 'SliderEdit: Continuous Image Editing with Fine-Grained Instruction Control' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-11-14 00:00:00+0900+0900\",\"children\":\"2025년 11월 14일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-11-14-SliderEdit-Continuous-Image-Editing-with-Fine-Grained-Instruction-Control\"}]]}]]}],[\"$\",\"article\",\"2025-11-11-Diffusion-SDPO-Safeguarded-Direct-Preference-Optimization-for-Diffusion-Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-11-11-Diffusion-SDPO-Safeguarded-Direct-Preference-Optimization-for-Diffusion-Models\",\"children\":\"[논문리뷰] Diffusion-SDPO: Safeguarded Direct Preference Optimization for Diffusion   Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-11-11-Diffusion-SDPO-Safeguarded-Direct-Preference-Optimization-for-Diffusion-Models\",\"children\":\"Zhao Xu이 arXiv에 게시한 'Diffusion-SDPO: Safeguarded Direct Preference Optimization for Diffusion   Models' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-11-11 00:00:00+0900+0900\",\"children\":\"2025년 11월 11일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-11-11-Diffusion-SDPO-Safeguarded-Direct-Preference-Optimization-for-Diffusion-Models\"}]]}]]}],[\"$\",\"article\",\"2025-11-11-DIMO-Diverse-3D-Motion-Generation-for-Arbitrary-Objects\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-11-11-DIMO-Diverse-3D-Motion-Generation-for-Arbitrary-Objects\",\"children\":\"[논문리뷰] DIMO: Diverse 3D Motion Generation for Arbitrary Objects\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-11-11-DIMO-Diverse-3D-Motion-Generation-for-Arbitrary-Objects\",\"children\":\"Kostas Daniilidis이 arXiv에 게시한 'DIMO: Diverse 3D Motion Generation for Arbitrary Objects' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-11-11 00:00:00+0900+0900\",\"children\":\"2025년 11월 11일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-11-11-DIMO-Diverse-3D-Motion-Generation-for-Arbitrary-Objects\"}]]}]]}],[\"$\",\"article\",\"2025-11-7-Contamination-Detection-for-VLMs-using-Multi-Modal-Semantic-Perturbation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-11-7-Contamination-Detection-for-VLMs-using-Multi-Modal-Semantic-Perturbation\",\"children\":\"[논문리뷰] Contamination Detection for VLMs using Multi-Modal Semantic Perturbation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-11-7-Contamination-Detection-for-VLMs-using-Multi-Modal-Semantic-Perturbation\",\"children\":\"arXiv에 게시된 'Contamination Detection for VLMs using Multi-Modal Semantic Perturbation' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-11-09 22:08:24+0900\",\"children\":\"2025년 11월 9일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-11-7-Contamination-Detection-for-VLMs-using-Multi-Modal-Semantic-Perturbation\"}]]}]]}],[\"$\",\"article\",\"2025-11-6-UniAVGen-Unified-Audio-and-Video-Generation-with-Asymmetric-Cross-Modal-Interactions\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-11-6-UniAVGen-Unified-Audio-and-Video-Generation-with-Asymmetric-Cross-Modal-Interactions\",\"children\":\"[논문리뷰] UniAVGen: Unified Audio and Video Generation with Asymmetric Cross-Modal Interactions\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-11-6-UniAVGen-Unified-Audio-and-Video-Generation-with-Asymmetric-Cross-Modal-Interactions\",\"children\":\"arXiv에 게시된 'UniAVGen: Unified Audio and Video Generation with Asymmetric Cross-Modal Interactions' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-11-09 21:54:30+0900\",\"children\":\"2025년 11월 9일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-11-6-UniAVGen-Unified-Audio-and-Video-Generation-with-Asymmetric-Cross-Modal-Interactions\"}]]}]]}],[\"$\",\"article\",\"2025-11-4-UniREditBench-A-Unified-Reasoning-based-Image-Editing-Benchmark\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-11-4-UniREditBench-A-Unified-Reasoning-based-Image-Editing-Benchmark\",\"children\":\"[논문리뷰] UniREditBench: A Unified Reasoning-based Image Editing Benchmark\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-11-4-UniREditBench-A-Unified-Reasoning-based-Image-Editing-Benchmark\",\"children\":\"arXiv에 게시된 'UniREditBench: A Unified Reasoning-based Image Editing Benchmark' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-11-09 19:22:42+0900\",\"children\":\"2025년 11월 9일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-11-4-UniREditBench-A-Unified-Reasoning-based-Image-Editing-Benchmark\"}]]}]]}],[\"$\",\"article\",\"2025-11-3-Phased-DMD-Few-step-Distribution-Matching-Distillation-via-Score-Matching-within-Subintervals\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-11-3-Phased-DMD-Few-step-Distribution-Matching-Distillation-via-Score-Matching-within-Subintervals\",\"children\":\"[논문리뷰] Phased DMD: Few-step Distribution Matching Distillation via Score Matching within Subintervals\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-11-3-Phased-DMD-Few-step-Distribution-Matching-Distillation-via-Score-Matching-within-Subintervals\",\"children\":\"arXiv에 게시된 'Phased DMD: Few-step Distribution Matching Distillation via Score Matching within Subintervals' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-11-09 19:01:31+0900\",\"children\":\"2025년 11월 9일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-11-3-Phased-DMD-Few-step-Distribution-Matching-Distillation-via-Score-Matching-within-Subintervals\"}]]}]]}],[\"$\",\"article\",\"2025-10-31-OmniLayout-Enabling-Coarse-to-Fine-Learning-with-LLMs-for-Universal-Document-Layout-Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-31-OmniLayout-Enabling-Coarse-to-Fine-Learning-with-LLMs-for-Universal-Document-Layout-Generation\",\"children\":\"[논문리뷰] OmniLayout: Enabling Coarse-to-Fine Learning with LLMs for Universal Document Layout Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-31-OmniLayout-Enabling-Coarse-to-Fine-Learning-with-LLMs-for-Universal-Document-Layout-Generation\",\"children\":\"Bin Wang이 arXiv에 게시한 'OmniLayout: Enabling Coarse-to-Fine Learning with LLMs for Universal Document Layout Generation' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-31 18:37:31+0900\",\"children\":\"2025년 10월 31일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-10-31-OmniLayout-Enabling-Coarse-to-Fine-Learning-with-LLMs-for-Universal-Document-Layout-Generation\"}]]}]]}],[\"$\",\"article\",\"2025-10-31-EnzyControl-Adding-Functional-and-Substrate-Specific-Control-for-Enzyme-Backbone-Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-31-EnzyControl-Adding-Functional-and-Substrate-Specific-Control-for-Enzyme-Backbone-Generation\",\"children\":\"[논문리뷰] EnzyControl: Adding Functional and Substrate-Specific Control for Enzyme Backbone Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-31-EnzyControl-Adding-Functional-and-Substrate-Specific-Control-for-Enzyme-Backbone-Generation\",\"children\":\"arXiv에 게시된 'EnzyControl: Adding Functional and Substrate-Specific Control for Enzyme Backbone Generation' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-31 18:37:31+0900\",\"children\":\"2025년 10월 31일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-10-31-EnzyControl-Adding-Functional-and-Substrate-Specific-Control-for-Enzyme-Backbone-Generation\"}]]}]]}],[\"$\",\"article\",\"2025-10-30-Gaperon-A-Peppered-English-French-Generative-Language-Model-Suite\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-30-Gaperon-A-Peppered-English-French-Generative-Language-Model-Suite\",\"children\":\"[논문리뷰] Gaperon: A Peppered English-French Generative Language Model Suite\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-30-Gaperon-A-Peppered-English-French-Generative-Language-Model-Suite\",\"children\":\"Éric de la Clergerie이 arXiv에 게시한 'Gaperon: A Peppered English-French Generative Language Model Suite' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-30 13:06:06+0900\",\"children\":\"2025년 10월 30일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-10-30-Gaperon-A-Peppered-English-French-Generative-Language-Model-Suite\"}]]}]]}],[\"$\",\"article\",\"2025-10-28-Track-Inpaint-Resplat-Subject-driven-3D-and-4D-Generation-with-Progressive-Texture-Infilling\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-28-Track-Inpaint-Resplat-Subject-driven-3D-and-4D-Generation-with-Progressive-Texture-Infilling\",\"children\":\"[논문리뷰] Track, Inpaint, Resplat: Subject-driven 3D and 4D Generation with Progressive Texture Infilling\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-28-Track-Inpaint-Resplat-Subject-driven-3D-and-4D-Generation-with-Progressive-Texture-Infilling\",\"children\":\"Igor Gilitschenski이 arXiv에 게시한 'Track, Inpaint, Resplat: Subject-driven 3D and 4D Generation with Progressive Texture Infilling' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-28 13:07:54+0900\",\"children\":\"2025년 10월 28일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-10-28-Track-Inpaint-Resplat-Subject-driven-3D-and-4D-Generation-with-Progressive-Texture-Infilling\"}]]}]]}],[\"$\",\"article\",\"2025-10-28-FARMER-Flow-AutoRegressive-Transformer-over-Pixels\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-28-FARMER-Flow-AutoRegressive-Transformer-over-Pixels\",\"children\":\"[논문리뷰] FARMER: Flow AutoRegressive Transformer over Pixels\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-28-FARMER-Flow-AutoRegressive-Transformer-over-Pixels\",\"children\":\"Zhijie Lin이 arXiv에 게시한 'FARMER: Flow AutoRegressive Transformer over Pixels' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-28 13:07:54+0900\",\"children\":\"2025년 10월 28일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-10-28-FARMER-Flow-AutoRegressive-Transformer-over-Pixels\"}]]}]]}],[\"$\",\"article\",\"2025-10-28-Distilled-Decoding-2-One-step-Sampling-of-Image-Auto-regressive-Models-with-Conditional-Score-Distillation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-28-Distilled-Decoding-2-One-step-Sampling-of-Image-Auto-regressive-Models-with-Conditional-Score-Distillation\",\"children\":\"[논문리뷰] Distilled Decoding 2: One-step Sampling of Image Auto-regressive Models with Conditional Score Distillation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-28-Distilled-Decoding-2-One-step-Sampling-of-Image-Auto-regressive-Models-with-Conditional-Score-Distillation\",\"children\":\"Guohao Dai이 arXiv에 게시한 'Distilled Decoding 2: One-step Sampling of Image Auto-regressive Models with Conditional Score Distillation' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-28 13:07:54+0900\",\"children\":\"2025년 10월 28일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-10-28-Distilled-Decoding-2-One-step-Sampling-of-Image-Auto-regressive-Models-with-Conditional-Score-Distillation\"}]]}]]}],[\"$\",\"article\",\"2025-10-28-DiffusionLane-Diffusion-Model-for-Lane-Detection\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-28-DiffusionLane-Diffusion-Model-for-Lane-Detection\",\"children\":\"[논문리뷰] DiffusionLane: Diffusion Model for Lane Detection\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-28-DiffusionLane-Diffusion-Model-for-Lane-Detection\",\"children\":\"arXiv에 게시된 'DiffusionLane: Diffusion Model for Lane Detection' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-28 13:07:54+0900\",\"children\":\"2025년 10월 28일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-10-28-DiffusionLane-Diffusion-Model-for-Lane-Detection\"}]]}]]}],[\"$\",\"article\",\"2025-10-24-AlphaFlow-Understanding-and-Improving-MeanFlow-Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-24-AlphaFlow-Understanding-and-Improving-MeanFlow-Models\",\"children\":\"[논문리뷰] AlphaFlow: Understanding and Improving MeanFlow Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-24-AlphaFlow-Understanding-and-Improving-MeanFlow-Models\",\"children\":\"arXiv에 게시된 'AlphaFlow: Understanding and Improving MeanFlow Models' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-24 13:04:16+0900\",\"children\":\"2025년 10월 24일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-10-24-AlphaFlow-Understanding-and-Improving-MeanFlow-Models\"}]]}]]}],[\"$\",\"article\",\"2025-10-23-Attention-Sinks-in-Diffusion-Language-Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-23-Attention-Sinks-in-Diffusion-Language-Models\",\"children\":\"[논문리뷰] Attention Sinks in Diffusion Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-23-Attention-Sinks-in-Diffusion-Language-Models\",\"children\":\"Simone Scardapane이 arXiv에 게시한 'Attention Sinks in Diffusion Language Models' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-23 13:08:59+0900\",\"children\":\"2025년 10월 23일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-10-23-Attention-Sinks-in-Diffusion-Language-Models\"}]]}]]}],[\"$\",\"article\",\"2025-10-21-GuideFlow3D-Optimization-Guided-Rectified-Flow-For-Appearance-Transfer\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-21-GuideFlow3D-Optimization-Guided-Rectified-Flow-For-Appearance-Transfer\",\"children\":\"[논문리뷰] GuideFlow3D: Optimization-Guided Rectified Flow For Appearance Transfer\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-21-GuideFlow3D-Optimization-Guided-Rectified-Flow-For-Appearance-Transfer\",\"children\":\"arXiv에 게시된 'GuideFlow3D: Optimization-Guided Rectified Flow For Appearance Transfer' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-21 13:08:30+0900\",\"children\":\"2025년 10월 21일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-10-21-GuideFlow3D-Optimization-Guided-Rectified-Flow-For-Appearance-Transfer\"}]]}]]}],[\"$\",\"article\",\"2025-10-20-Latent-Diffusion-Model-without-Variational-Autoencoder\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-20-Latent-Diffusion-Model-without-Variational-Autoencoder\",\"children\":\"[논문리뷰] Latent Diffusion Model without Variational Autoencoder\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-20-Latent-Diffusion-Model-without-Variational-Autoencoder\",\"children\":\"arXiv에 게시된 'Latent Diffusion Model without Variational Autoencoder' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-20 13:04:24+0900\",\"children\":\"2025년 10월 20일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-10-20-Latent-Diffusion-Model-without-Variational-Autoencoder\"}]]}]]}],[\"$\",\"article\",\"2025-10-17-pi-Flow-Policy-Based-Few-Step-Generation-via-Imitation-Distillation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-17-pi-Flow-Policy-Based-Few-Step-Generation-via-Imitation-Distillation\",\"children\":\"[논문리뷰] pi-Flow: Policy-Based Few-Step Generation via Imitation Distillation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-17-pi-Flow-Policy-Based-Few-Step-Generation-via-Imitation-Distillation\",\"children\":\"arXiv에 게시된 'pi-Flow: Policy-Based Few-Step Generation via Imitation Distillation' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-17 13:09:57+0900\",\"children\":\"2025년 10월 17일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-10-17-pi-Flow-Policy-Based-Few-Step-Generation-via-Imitation-Distillation\"}]]}]]}],[\"$\",\"article\",\"2025-10-17-Beyond-Correctness-Evaluating-Subjective-Writing-Preferences-Across-Cultures\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-17-Beyond-Correctness-Evaluating-Subjective-Writing-Preferences-Across-Cultures\",\"children\":\"[논문리뷰] Beyond Correctness: Evaluating Subjective Writing Preferences Across Cultures\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-17-Beyond-Correctness-Evaluating-Subjective-Writing-Preferences-Across-Cultures\",\"children\":\"arXiv에 게시된 'Beyond Correctness: Evaluating Subjective Writing Preferences Across Cultures' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-17 13:09:57+0900\",\"children\":\"2025년 10월 17일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-10-17-Beyond-Correctness-Evaluating-Subjective-Writing-Preferences-Across-Cultures\"}]]}]]}],[\"$\",\"article\",\"2025-10-16-Generative-Universal-Verifier-as-Multimodal-Meta-Reasoner\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-16-Generative-Universal-Verifier-as-Multimodal-Meta-Reasoner\",\"children\":\"[논문리뷰] Generative Universal Verifier as Multimodal Meta-Reasoner\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-16-Generative-Universal-Verifier-as-Multimodal-Meta-Reasoner\",\"children\":\"arXiv에 게시된 'Generative Universal Verifier as Multimodal Meta-Reasoner' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-16 13:09:51+0900\",\"children\":\"2025년 10월 16일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-10-16-Generative-Universal-Verifier-as-Multimodal-Meta-Reasoner\"}]]}]]}],[\"$\",\"article\",\"2025-10-16-Attention-Illuminates-LLM-Reasoning-The-Preplan-and-Anchor-Rhythm-Enables-Fine-Grained-Policy-Optimization\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-16-Attention-Illuminates-LLM-Reasoning-The-Preplan-and-Anchor-Rhythm-Enables-Fine-Grained-Policy-Optimization\",\"children\":\"[논문리뷰] Attention Illuminates LLM Reasoning: The Preplan-and-Anchor Rhythm Enables Fine-Grained Policy Optimization\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-16-Attention-Illuminates-LLM-Reasoning-The-Preplan-and-Anchor-Rhythm-Enables-Fine-Grained-Policy-Optimization\",\"children\":\"arXiv에 게시된 'Attention Illuminates LLM Reasoning: The Preplan-and-Anchor Rhythm Enables Fine-Grained Policy Optimization' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-16 13:09:51+0900\",\"children\":\"2025년 10월 16일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-10-16-Attention-Illuminates-LLM-Reasoning-The-Preplan-and-Anchor-Rhythm-Enables-Fine-Grained-Policy-Optimization\"}]]}]]}],[\"$\",\"article\",\"2025-10-15-What-If-Understanding-Motion-Through-Sparse-Interactions\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-15-What-If-Understanding-Motion-Through-Sparse-Interactions\",\"children\":\"[논문리뷰] What If : Understanding Motion Through Sparse Interactions\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-15-What-If-Understanding-Motion-Through-Sparse-Interactions\",\"children\":\"arXiv에 게시된 'What If : Understanding Motion Through Sparse Interactions' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-15 13:01:40+0900\",\"children\":\"2025년 10월 15일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-10-15-What-If-Understanding-Motion-Through-Sparse-Interactions\"}]]}]]}],[\"$\",\"article\",\"2025-10-15-Temporal-Alignment-Guidance-On-Manifold-Sampling-in-Diffusion-Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-15-Temporal-Alignment-Guidance-On-Manifold-Sampling-in-Diffusion-Models\",\"children\":\"[논문리뷰] Temporal Alignment Guidance: On-Manifold Sampling in Diffusion Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-15-Temporal-Alignment-Guidance-On-Manifold-Sampling-in-Diffusion-Models\",\"children\":\"arXiv에 게시된 'Temporal Alignment Guidance: On-Manifold Sampling in Diffusion Models' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-15 13:01:40+0900\",\"children\":\"2025년 10월 15일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-10-15-Temporal-Alignment-Guidance-On-Manifold-Sampling-in-Diffusion-Models\"}]]}]]}],[\"$\",\"article\",\"2025-10-10-Towards-Scalable-and-Consistent-3D-Editing\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-10-Towards-Scalable-and-Consistent-3D-Editing\",\"children\":\"[논문리뷰] Towards Scalable and Consistent 3D Editing\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-10-Towards-Scalable-and-Consistent-3D-Editing\",\"children\":\"Pan Zhou이 arXiv에 게시한 'Towards Scalable and Consistent 3D Editing' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-10 13:53:45+0900\",\"children\":\"2025년 10월 10일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-10-10-Towards-Scalable-and-Consistent-3D-Editing\"}]]}]]}],[\"$\",\"article\",\"2025-10-9-Heptapod-Language-Modeling-on-Visual-Signals\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-9-Heptapod-Language-Modeling-on-Visual-Signals\",\"children\":\"[논문리뷰] Heptapod: Language Modeling on Visual Signals\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-9-Heptapod-Language-Modeling-on-Visual-Signals\",\"children\":\"arXiv에 게시된 'Heptapod: Language Modeling on Visual Signals' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-09 13:45:06+0900\",\"children\":\"2025년 10월 9일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-10-9-Heptapod-Language-Modeling-on-Visual-Signals\"}]]}]]}],[\"$\",\"article\",\"2025-10-9-G2RPO-Granular-GRPO-for-Precise-Reward-in-Flow-Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-9-G2RPO-Granular-GRPO-for-Precise-Reward-in-Flow-Models\",\"children\":\"[논문리뷰] G^2RPO: Granular GRPO for Precise Reward in Flow Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-9-G2RPO-Granular-GRPO-for-Precise-Reward-in-Flow-Models\",\"children\":\"arXiv에 게시된 'G^2RPO: Granular GRPO for Precise Reward in Flow Models' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-09 13:45:06+0900\",\"children\":\"2025년 10월 9일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-10-9-G2RPO-Granular-GRPO-for-Precise-Reward-in-Flow-Models\"}]]}]]}],[\"$\",\"article\",\"2025-10-9-Bridging-Text-and-Video-Generation-A-Survey\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-9-Bridging-Text-and-Video-Generation-A-Survey\",\"children\":\"[논문리뷰] Bridging Text and Video Generation: A Survey\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-9-Bridging-Text-and-Video-Generation-A-Survey\",\"children\":\"G. Maragatham이 arXiv에 게시한 'Bridging Text and Video Generation: A Survey' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-09 13:45:06+0900\",\"children\":\"2025년 10월 9일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-10-9-Bridging-Text-and-Video-Generation-A-Survey\"}]]}]]}],[\"$\",\"article\",\"2025-10-8-Equilibrium-Matching-Generative-Modeling-with-Implicit-Energy-Based-Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-8-Equilibrium-Matching-Generative-Modeling-with-Implicit-Energy-Based-Models\",\"children\":\"[논문리뷰] Equilibrium Matching: Generative Modeling with Implicit Energy-Based Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-8-Equilibrium-Matching-Generative-Modeling-with-Implicit-Energy-Based-Models\",\"children\":\"arXiv에 게시된 'Equilibrium Matching: Generative Modeling with Implicit Energy-Based Models' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-08 13:48:12+0900\",\"children\":\"2025년 10월 8일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-10-8-Equilibrium-Matching-Generative-Modeling-with-Implicit-Energy-Based-Models\"}]]}]]}],[\"$\",\"article\",\"2025-10-8-Drax-Speech-Recognition-with-Discrete-Flow-Matching\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-8-Drax-Speech-Recognition-with-Discrete-Flow-Matching\",\"children\":\"[논문리뷰] Drax: Speech Recognition with Discrete Flow Matching\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-8-Drax-Speech-Recognition-with-Discrete-Flow-Matching\",\"children\":\"arXiv에 게시된 'Drax: Speech Recognition with Discrete Flow Matching' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-08 13:48:12+0900\",\"children\":\"2025년 10월 8일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-10-8-Drax-Speech-Recognition-with-Discrete-Flow-Matching\"}]]}]]}],[\"$\",\"article\",\"2025-10-8-Deforming-Videos-to-Masks-Flow-Matching-for-Referring-Video-Segmentation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-8-Deforming-Videos-to-Masks-Flow-Matching-for-Referring-Video-Segmentation\",\"children\":\"[논문리뷰] Deforming Videos to Masks: Flow Matching for Referring Video Segmentation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-8-Deforming-Videos-to-Masks-Flow-Matching-for-Referring-Video-Segmentation\",\"children\":\"Chengzu Li이 arXiv에 게시한 'Deforming Videos to Masks: Flow Matching for Referring Video Segmentation' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-08 13:48:12+0900\",\"children\":\"2025년 10월 8일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-10-8-Deforming-Videos-to-Masks-Flow-Matching-for-Referring-Video-Segmentation\"}]]}]]}],[\"$\",\"article\",\"2025-10-7-ChronoEdit-Towards-Temporal-Reasoning-for-Image-Editing-and-World-Simulation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-7-ChronoEdit-Towards-Temporal-Reasoning-for-Image-Editing-and-World-Simulation\",\"children\":\"[논문리뷰] ChronoEdit: Towards Temporal Reasoning for Image Editing and World Simulation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-7-ChronoEdit-Towards-Temporal-Reasoning-for-Image-Editing-and-World-Simulation\",\"children\":\"arXiv에 게시된 'ChronoEdit: Towards Temporal Reasoning for Image Editing and World Simulation' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-07 13:36:57+0900\",\"children\":\"2025년 10월 7일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-10-7-ChronoEdit-Towards-Temporal-Reasoning-for-Image-Editing-and-World-Simulation\"}]]}]]}],[\"$\",\"article\",\"2025-10-6-Align-Your-Tangent-Training-Better-Consistency-Models-via-Manifold-Aligned-Tangents\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-6-Align-Your-Tangent-Training-Better-Consistency-Models-via-Manifold-Aligned-Tangents\",\"children\":\"[논문리뷰] Align Your Tangent: Training Better Consistency Models via Manifold-Aligned Tangents\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-10-6-Align-Your-Tangent-Training-Better-Consistency-Models-via-Manifold-Aligned-Tangents\",\"children\":\"Jong Chul Ye이 arXiv에 게시한 'Align Your Tangent: Training Better Consistency Models via Manifold-Aligned Tangents' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-06 13:29:11+0900\",\"children\":\"2025년 10월 6일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-10-6-Align-Your-Tangent-Training-Better-Consistency-Models-via-Manifold-Aligned-Tangents\"}]]}]]}],[\"$\",\"article\",\"2025-9-23-VideoFrom3D-3D-Scene-Video-Generation-via-Complementary-Image-and-Video-Diffusion-Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-9-23-VideoFrom3D-3D-Scene-Video-Generation-via-Complementary-Image-and-Video-Diffusion-Models\",\"children\":\"[논문리뷰] VideoFrom3D: 3D Scene Video Generation via Complementary Image and Video Diffusion Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-9-23-VideoFrom3D-3D-Scene-Video-Generation-via-Complementary-Image-and-Video-Diffusion-Models\",\"children\":\"Sunghyun Cho이 arXiv에 게시한 'VideoFrom3D: 3D Scene Video Generation via Complementary Image and Video Diffusion Models' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-23 13:36:03+0900\",\"children\":\"2025년 9월 23일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-9-23-VideoFrom3D-3D-Scene-Video-Generation-via-Complementary-Image-and-Video-Diffusion-Models\"}]]}]]}],[\"$\",\"article\",\"2025-9-19-AToken-A-Unified-Tokenizer-for-Vision\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-9-19-AToken-A-Unified-Tokenizer-for-Vision\",\"children\":\"[논문리뷰] AToken: A Unified Tokenizer for Vision\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-9-19-AToken-A-Unified-Tokenizer-for-Vision\",\"children\":\"Mingze Xu이 arXiv에 게시한 'AToken: A Unified Tokenizer for Vision' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-19 13:12:21+0900\",\"children\":\"2025년 9월 19일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-9-19-AToken-A-Unified-Tokenizer-for-Vision\"}]]}]]}],[\"$\",\"article\",\"2025-9-16-Locality-in-Image-Diffusion-Models-Emerges-from-Data-Statistics\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-9-16-Locality-in-Image-Diffusion-Models-Emerges-from-Data-Statistics\",\"children\":\"[논문리뷰] Locality in Image Diffusion Models Emerges from Data Statistics\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-9-16-Locality-in-Image-Diffusion-Models-Emerges-from-Data-Statistics\",\"children\":\"Vincent Sitzmann이 arXiv에 게시한 'Locality in Image Diffusion Models Emerges from Data Statistics' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-16 13:16:41+0900\",\"children\":\"2025년 9월 16일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-9-16-Locality-in-Image-Diffusion-Models-Emerges-from-Data-Statistics\"}]]}]]}],[\"$\",\"article\",\"2025-9-12-2D-Gaussian-Splatting-with-Semantic-Alignment-for-Image-Inpainting\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-9-12-2D-Gaussian-Splatting-with-Semantic-Alignment-for-Image-Inpainting\",\"children\":\"[논문리뷰] 2D Gaussian Splatting with Semantic Alignment for Image Inpainting\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-9-12-2D-Gaussian-Splatting-with-Semantic-Alignment-for-Image-Inpainting\",\"children\":\"Guangming Lu이 arXiv에 게시한 '2D Gaussian Splatting with Semantic Alignment for Image Inpainting' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-12 13:12:46+0900\",\"children\":\"2025년 9월 12일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-9-12-2D-Gaussian-Splatting-with-Semantic-Alignment-for-Image-Inpainting\"}]]}]]}],[\"$\",\"article\",\"2025-9-11-3D-and-4D-World-Modeling-A-Survey\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-9-11-3D-and-4D-World-Modeling-A-Survey\",\"children\":\"[논문리뷰] 3D and 4D World Modeling: A Survey\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-9-11-3D-and-4D-World-Modeling-A-Survey\",\"children\":\"Ao Liang이 arXiv에 게시한 '3D and 4D World Modeling: A Survey' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-11 13:02:36+0900\",\"children\":\"2025년 9월 11일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-9-11-3D-and-4D-World-Modeling-A-Survey\"}]]}]]}],[\"$\",\"article\",\"2025-9-8-LuxDiT-Lighting-Estimation-with-Video-Diffusion-Transformer\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-9-8-LuxDiT-Lighting-Estimation-with-Video-Diffusion-Transformer\",\"children\":\"[논문리뷰] LuxDiT: Lighting Estimation with Video Diffusion Transformer\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-9-8-LuxDiT-Lighting-Estimation-with-Video-Diffusion-Transformer\",\"children\":\"Sanja Fidler이 arXiv에 게시한 'LuxDiT: Lighting Estimation with Video Diffusion Transformer' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-08 13:10:18+0900\",\"children\":\"2025년 9월 8일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-9-8-LuxDiT-Lighting-Estimation-with-Video-Diffusion-Transformer\"}]]}]]}],[\"$\",\"article\",\"2025-9-5-Transition-Models-Rethinking-the-Generative-Learning-Objective\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-9-5-Transition-Models-Rethinking-the-Generative-Learning-Objective\",\"children\":\"[논문리뷰] Transition Models: Rethinking the Generative Learning Objective\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-9-5-Transition-Models-Rethinking-the-Generative-Learning-Objective\",\"children\":\"Yangguang Li이 arXiv에 게시한 'Transition Models: Rethinking the Generative Learning Objective' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-05 13:07:20+0900\",\"children\":\"2025년 9월 5일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-9-5-Transition-Models-Rethinking-the-Generative-Learning-Objective\"}]]}]]}],[\"$\",\"article\",\"2025-9-3-Towards-More-Diverse-and-Challenging-Pre-training-for-Point-Cloud-Learning-Self-Supervised-Cross-Reconstruction-with-Decoupled-Views\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-9-3-Towards-More-Diverse-and-Challenging-Pre-training-for-Point-Cloud-Learning-Self-Supervised-Cross-Reconstruction-with-Decoupled-Views\",\"children\":\"[논문리뷰] Towards More Diverse and Challenging Pre-training for Point Cloud Learning: Self-Supervised Cross Reconstruction with Decoupled Views\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-9-3-Towards-More-Diverse-and-Challenging-Pre-training-for-Point-Cloud-Learning-Self-Supervised-Cross-Reconstruction-with-Decoupled-Views\",\"children\":\"Junchi Yan이 arXiv에 게시한 'Towards More Diverse and Challenging Pre-training for Point Cloud Learning: Self-Supervised Cross Reconstruction with Decoupled Views' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-03 13:36:21+0900\",\"children\":\"2025년 9월 3일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-9-3-Towards-More-Diverse-and-Challenging-Pre-training-for-Point-Cloud-Learning-Self-Supervised-Cross-Reconstruction-with-Decoupled-Views\"}]]}]]}],[\"$\",\"article\",\"2025-9-3-LLaVA-Critic-R1-Your-Critic-Model-is-Secretly-a-Strong-Policy-Model\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-9-3-LLaVA-Critic-R1-Your-Critic-Model-is-Secretly-a-Strong-Policy-Model\",\"children\":\"[논문리뷰] LLaVA-Critic-R1: Your Critic Model is Secretly a Strong Policy Model\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-9-3-LLaVA-Critic-R1-Your-Critic-Model-is-Secretly-a-Strong-Policy-Model\",\"children\":\"Jianwei Yang이 arXiv에 게시한 'LLaVA-Critic-R1: Your Critic Model is Secretly a Strong Policy Model' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-03 13:36:21+0900\",\"children\":\"2025년 9월 3일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-9-3-LLaVA-Critic-R1-Your-Critic-Model-is-Secretly-a-Strong-Policy-Model\"}]]}]]}],[\"$\",\"article\",\"2025-9-3-GenCompositor-Generative-Video-Compositing-with-Diffusion-Transformer\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-9-3-GenCompositor-Generative-Video-Compositing-with-Diffusion-Transformer\",\"children\":\"[논문리뷰] GenCompositor: Generative Video Compositing with Diffusion Transformer\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-9-3-GenCompositor-Generative-Video-Compositing-with-Diffusion-Transformer\",\"children\":\"Lingen Li이 arXiv에 게시한 'GenCompositor: Generative Video Compositing with Diffusion Transformer' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-03 13:36:21+0900\",\"children\":\"2025년 9월 3일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-9-3-GenCompositor-Generative-Video-Compositing-with-Diffusion-Transformer\"}]]}]]}],[\"$\",\"article\",\"2025-8-29-Mixture-of-Contexts-for-Long-Video-Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-8-29-Mixture-of-Contexts-for-Long-Video-Generation\",\"children\":\"[논문리뷰] Mixture of Contexts for Long Video Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-8-29-Mixture-of-Contexts-for-Long-Video-Generation\",\"children\":\"Junfei Xiao이 arXiv에 게시한 'Mixture of Contexts for Long Video Generation' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-29 13:14:44+0900\",\"children\":\"2025년 8월 29일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-8-29-Mixture-of-Contexts-for-Long-Video-Generation\"}]]}]]}],[\"$\",\"article\",\"2025-8-29-FakeParts-a-New-Family-of-AI-Generated-DeepFakes\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-8-29-FakeParts-a-New-Family-of-AI-Generated-DeepFakes\",\"children\":\"[논문리뷰] FakeParts: a New Family of AI-Generated DeepFakes\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-8-29-FakeParts-a-New-Family-of-AI-Generated-DeepFakes\",\"children\":\"Xi Wang이 arXiv에 게시한 'FakeParts: a New Family of AI-Generated DeepFakes' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-29 13:14:44+0900\",\"children\":\"2025년 8월 29일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-8-29-FakeParts-a-New-Family-of-AI-Generated-DeepFakes\"}]]}]]}],[\"$\",\"article\",\"2025-8-27-ObjFiller-3D-Consistent-Multi-view-3D-Inpainting-via-Video-Diffusion-Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-8-27-ObjFiller-3D-Consistent-Multi-view-3D-Inpainting-via-Video-Diffusion-Models\",\"children\":\"[논문리뷰] ObjFiller-3D: Consistent Multi-view 3D Inpainting via Video Diffusion Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-8-27-ObjFiller-3D-Consistent-Multi-view-3D-Inpainting-via-Video-Diffusion-Models\",\"children\":\"Beiqi Chen이 arXiv에 게시한 'ObjFiller-3D: Consistent Multi-view 3D Inpainting via Video Diffusion Models' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-27 13:22:18+0900\",\"children\":\"2025년 8월 27일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-8-27-ObjFiller-3D-Consistent-Multi-view-3D-Inpainting-via-Video-Diffusion-Models\"}]]}]]}],[\"$\",\"article\",\"2025-8-25-Selective-Contrastive-Learning-for-Weakly-Supervised-Affordance-Grounding\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-8-25-Selective-Contrastive-Learning-for-Weakly-Supervised-Affordance-Grounding\",\"children\":\"[논문리뷰] Selective Contrastive Learning for Weakly Supervised Affordance Grounding\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-8-25-Selective-Contrastive-Learning-for-Weakly-Supervised-Affordance-Grounding\",\"children\":\"Jae-Pil Heo이 arXiv에 게시한 'Selective Contrastive Learning for Weakly Supervised Affordance Grounding' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-25 13:13:07+0900\",\"children\":\"2025년 8월 25일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-8-25-Selective-Contrastive-Learning-for-Weakly-Supervised-Affordance-Grounding\"}]]}]]}],[\"$\",\"article\",\"2025-8-20-Semantic-IDs-for-Joint-Generative-Search-and-Recommendation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-8-20-Semantic-IDs-for-Joint-Generative-Search-and-Recommendation\",\"children\":\"[논문리뷰] Semantic IDs for Joint Generative Search and Recommendation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-8-20-Semantic-IDs-for-Joint-Generative-Search-and-Recommendation\",\"children\":\"Enrico Palumbo이 arXiv에 게시한 'Semantic IDs for Joint Generative Search and Recommendation' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-20 13:26:54+0900\",\"children\":\"2025년 8월 20일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-8-20-Semantic-IDs-for-Joint-Generative-Search-and-Recommendation\"}]]}]]}],[\"$\",\"article\",\"2025-8-19-S2-Guidance-Stochastic-Self-Guidance-for-Training-Free-Enhancement-of-Diffusion-Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-8-19-S2-Guidance-Stochastic-Self-Guidance-for-Training-Free-Enhancement-of-Diffusion-Models\",\"children\":\"[논문리뷰] S^2-Guidance: Stochastic Self Guidance for Training-Free Enhancement of Diffusion Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-8-19-S2-Guidance-Stochastic-Self-Guidance-for-Training-Free-Enhancement-of-Diffusion-Models\",\"children\":\"Meiqi Wu이 arXiv에 게시한 'S^2-Guidance: Stochastic Self Guidance for Training-Free Enhancement of Diffusion Models' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-19 13:15:01+0900\",\"children\":\"2025년 8월 19일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-8-19-S2-Guidance-Stochastic-Self-Guidance-for-Training-Free-Enhancement-of-Diffusion-Models\"}]]}]]}],[\"$\",\"article\",\"2025-8-19-Lumen-Consistent-Video-Relighting-and-Harmonious-Background-Replacement-with-Video-Generative-Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-8-19-Lumen-Consistent-Video-Relighting-and-Harmonious-Background-Replacement-with-Video-Generative-Models\",\"children\":\"[논문리뷰] Lumen: Consistent Video Relighting and Harmonious Background Replacement with Video Generative Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-8-19-Lumen-Consistent-Video-Relighting-and-Harmonious-Background-Replacement-with-Video-Generative-Models\",\"children\":\"Zixiang Gao이 arXiv에 게시한 'Lumen: Consistent Video Relighting and Harmonious Background Replacement with Video Generative Models' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-19 13:15:01+0900\",\"children\":\"2025년 8월 19일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-8-19-Lumen-Consistent-Video-Relighting-and-Harmonious-Background-Replacement-with-Video-Generative-Models\"}]]}]]}],[\"$\",\"article\",\"2025-8-19-4DNeX-Feed-Forward-4D-Generative-Modeling-Made-Easy\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-8-19-4DNeX-Feed-Forward-4D-Generative-Modeling-Made-Easy\",\"children\":\"[논문리뷰] 4DNeX: Feed-Forward 4D Generative Modeling Made Easy\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-8-19-4DNeX-Feed-Forward-4D-Generative-Modeling-Made-Easy\",\"children\":\"Zeng Tao이 arXiv에 게시한 '4DNeX: Feed-Forward 4D Generative Modeling Made Easy' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-19 13:15:01+0900\",\"children\":\"2025년 8월 19일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-8-19-4DNeX-Feed-Forward-4D-Generative-Modeling-Made-Easy\"}]]}]]}],[\"$\",\"article\",\"2025-8-12-Follow-Your-Shape-Shape-Aware-Image-Editing-via-Trajectory-Guided-Region-Control\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-8-12-Follow-Your-Shape-Shape-Aware-Image-Editing-via-Trajectory-Guided-Region-Control\",\"children\":\"[논문리뷰] Follow-Your-Shape: Shape-Aware Image Editing via Trajectory-Guided Region Control\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-8-12-Follow-Your-Shape-Shape-Aware-Image-Editing-via-Trajectory-Guided-Region-Control\",\"children\":\"Hongyu Liu이 arXiv에 게시한 'Follow-Your-Shape: Shape-Aware Image Editing via Trajectory-Guided Region Control' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-12 13:29:09+0900\",\"children\":\"2025년 8월 12일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-8-12-Follow-Your-Shape-Shape-Aware-Image-Editing-via-Trajectory-Guided-Region-Control\"}]]}]]}],[\"$\",\"article\",\"2025-8-7-SonicMaster-Towards-Controllable-All-in-One-Music-Restoration-and-Mastering\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-8-7-SonicMaster-Towards-Controllable-All-in-One-Music-Restoration-and-Mastering\",\"children\":\"[논문리뷰] SonicMaster: Towards Controllable All-in-One Music Restoration and Mastering\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-8-7-SonicMaster-Towards-Controllable-All-in-One-Music-Restoration-and-Mastering\",\"children\":\"Ambuj Mehrish이 arXiv에 게시한 'SonicMaster: Towards Controllable All-in-One Music Restoration and Mastering' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-07 13:38:21+0900\",\"children\":\"2025년 8월 7일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-8-7-SonicMaster-Towards-Controllable-All-in-One-Music-Restoration-and-Mastering\"}]]}]]}],[\"$\",\"article\",\"2025-8-4-PixNerd-Pixel-Neural-Field-Diffusion\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-8-4-PixNerd-Pixel-Neural-Field-Diffusion\",\"children\":\"[논문리뷰] PixNerd: Pixel Neural Field Diffusion\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/ai/review/2025-8-4-PixNerd-Pixel-Neural-Field-Diffusion\",\"children\":\"Limin Wang이 arXiv에 게시한 'PixNerd: Pixel Neural Field Diffusion' 논문에 대한 자세한 리뷰입니다.\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-04 12:17:01+0900\",\"children\":\"2025년 8월 4일\"}],[\"$\",\"$L7\",null,{\"postPermalink\":\"/ai/review/2025-8-4-PixNerd-Pixel-Neural-Field-Diffusion\"}]]}]]}]]}]]}]]}]}]]}]],null],null]},[\"$\",\"$L8\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"tags\",\"children\",\"$9\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}],null]},[\"$\",\"$L8\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"tags\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}],null]},[[\"$\",\"html\",null,{\"lang\":\"ko\",\"className\":\"no-js\",\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"meta\",null,{\"name\":\"msapplication-TileColor\",\"content\":\"#ffc40d\"}],[\"$\",\"meta\",null,{\"name\":\"theme-color\",\"content\":\"#ffffff\"}],[\"$\",\"link\",null,{\"rel\":\"dns-prefetch\",\"href\":\"https://www.googletagmanager.com\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://www.googletagmanager.com\",\"crossOrigin\":\"anonymous\"}],[\"$\",\"link\",null,{\"rel\":\"dns-prefetch\",\"href\":\"https://giscus.app\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://giscus.app\",\"crossOrigin\":\"anonymous\"}],[\"$\",\"meta\",null,{\"httpEquiv\":\"X-Content-Type-Options\",\"content\":\"nosniff\"}],[\"$\",\"meta\",null,{\"name\":\"referrer\",\"content\":\"strict-origin-when-cross-origin\"}],[\"$\",\"script\",null,{\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"{\\\"@context\\\":\\\"https://schema.org\\\",\\\"@type\\\":\\\"WebSite\\\",\\\"name\\\":\\\"secrett2633's blog\\\",\\\"url\\\":\\\"https://blog.secrett2633.cloud\\\",\\\"description\\\":\\\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\\\",\\\"inLanguage\\\":\\\"ko\\\",\\\"publisher\\\":{\\\"@type\\\":\\\"Person\\\",\\\"name\\\":\\\"secrett2633\\\",\\\"url\\\":\\\"https://blog.secrett2633.cloud\\\"}}\"}}],[\"$\",\"script\",null,{\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"{\\\"@context\\\":\\\"https://schema.org\\\",\\\"@type\\\":\\\"Person\\\",\\\"name\\\":\\\"secrett2633\\\",\\\"url\\\":\\\"https://blog.secrett2633.cloud\\\",\\\"sameAs\\\":[\\\"https://github.com/secrett2633\\\"]}\"}}]]}],[\"$\",\"body\",null,{\"className\":\"__className_f367f3 layout--default\",\"children\":[[\"$\",\"a\",null,{\"href\":\"#main-content\",\"className\":\"sr-only focus:not-sr-only focus:absolute focus:z-50 focus:p-4 focus:bg-white focus:text-blue-600\",\"children\":\"본문으로 건너뛰기\"}],[\"$\",\"div\",null,{\"className\":\"min-h-screen bg-gray-50\",\"children\":[[\"$\",\"$Lb\",null,{}],[\"$\",\"main\",null,{\"id\":\"main-content\",\"className\":\"initial-content\",\"children\":[\"$\",\"$L8\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[\"$\",\"div\",null,{\"className\":\"min-h-screen flex items-center justify-center bg-gray-50\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-6xl font-bold text-primary-600 mb-4\",\"children\":\"404\"}],[\"$\",\"h2\",null,{\"className\":\"text-2xl font-semibold text-gray-900 mb-4\",\"children\":\"페이지를 찾을 수 없습니다\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-600 mb-8\",\"children\":\"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다.\"}],[\"$\",\"$L6\",null,{\"href\":\"/\",\"className\":\"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors\",\"children\":\"홈으로 돌아가기\"}]]}]}],\"notFoundStyles\":[],\"styles\":null}]}],[\"$\",\"div\",null,{\"id\":\"footer\",\"className\":\"page__footer\",\"children\":[\"$\",\"footer\",null,{\"className\":\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"text-center text-gray-500 text-sm\",\"children\":[\"$\",\"p\",null,{\"children\":[\"© \",2026,\" secrett2633. All rights reserved.\"]}]}]}]}]]}],[\"$\",\"$Lc\",null,{\"src\":\"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY\",\"strategy\":\"afterInteractive\"}],[\"$\",\"$Lc\",null,{\"id\":\"gtag-init\",\"strategy\":\"afterInteractive\",\"children\":\"window.dataLayer = window.dataLayer || [];\\n            function gtag(){dataLayer.push(arguments);}\\n            gtag('js', new Date());\\n            gtag('config', 'G-NE2W3CFPNY');\"}]]}]]}],null],[[\"$\",\"div\",null,{\"className\":\"flex items-center justify-center min-h-screen\",\"role\":\"status\",\"aria-label\":\"로딩 중\",\"children\":[[\"$\",\"div\",null,{\"className\":\"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600\"}],[\"$\",\"span\",null,{\"className\":\"sr-only\",\"children\":\"로딩 중...\"}]]}],[],[]]],\"couldBeIntercepted\":false,\"initialHead\":[null,\"$Ld\"],\"globalErrorComponent\":\"$e\",\"missingSlots\":\"$Wf\"}]]\n"])</script><script>self.__next_f.push([1,"d:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"#Generative Models - secrett2633's blog\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"Generative Models 태그가 포함된 포스트 목록\"}],[\"$\",\"meta\",\"4\",{\"name\":\"author\",\"content\":\"secrett2633\"}],[\"$\",\"link\",\"5\",{\"rel\":\"manifest\",\"href\":\"/manifest.json\",\"crossOrigin\":\"use-credentials\"}],[\"$\",\"meta\",\"6\",{\"name\":\"keywords\",\"content\":\"Django, Python, DevOps, AI, ML, 블로그, 기술\"}],[\"$\",\"meta\",\"7\",{\"name\":\"creator\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"8\",{\"name\":\"publisher\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"9\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"10\",{\"name\":\"googlebot\",\"content\":\"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1\"}],[\"$\",\"link\",\"11\",{\"rel\":\"canonical\",\"href\":\"https://blog.secrett2633.cloud/tags/Generative%20Models\"}],[\"$\",\"meta\",\"12\",{\"name\":\"format-detection\",\"content\":\"telephone=no, address=no, email=no\"}],[\"$\",\"meta\",\"13\",{\"property\":\"og:title\",\"content\":\"#Generative Models - secrett2633's blog\"}],[\"$\",\"meta\",\"14\",{\"property\":\"og:description\",\"content\":\"Generative Models 태그가 포함된 포스트 목록\"}],[\"$\",\"meta\",\"15\",{\"property\":\"og:url\",\"content\":\"https://blog.secrett2633.cloud/tags/Generative%20Models\"}],[\"$\",\"meta\",\"16\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"17\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"18\",{\"name\":\"twitter:title\",\"content\":\"#Generative Models - secrett2633's blog\"}],[\"$\",\"meta\",\"19\",{\"name\":\"twitter:description\",\"content\":\"Generative Models 태그가 포함된 포스트 목록\"}],[\"$\",\"link\",\"20\",{\"rel\":\"icon\",\"href\":\"/icon.ico?6d9f34d4948640b8\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}],[\"$\",\"meta\",\"21\",{\"name\":\"next-size-adjust\"}]]\n4:null\n"])</script></body></html>