2:I[9038,["231","static/chunks/231-467e37449c5a68fc.js","605","static/chunks/app/tags/%5Btag%5D/page-d13158d00abd62a4.js"],"default"]
3:I[231,["231","static/chunks/231-467e37449c5a68fc.js","605","static/chunks/app/tags/%5Btag%5D/page-d13158d00abd62a4.js"],""]
4:I[227,["231","static/chunks/231-467e37449c5a68fc.js","605","static/chunks/app/tags/%5Btag%5D/page-d13158d00abd62a4.js"],"default"]
5:I[9275,[],""]
7:I[1343,[],""]
8:I[9157,["231","static/chunks/231-467e37449c5a68fc.js","185","static/chunks/app/layout-b0a450f8e4964582.js"],"default"]
9:I[4080,["231","static/chunks/231-467e37449c5a68fc.js","185","static/chunks/app/layout-b0a450f8e4964582.js"],""]
6:["tag","Large%20Language%20Models%20(LLMs)","d"]
0:["WcxaIiCPz9cbpnkGvOjOK",[[["",{"children":["tags",{"children":[["tag","Large%20Language%20Models%20(LLMs)","d"],{"children":["__PAGE__?{\"tag\":\"Large Language Models (LLMs)\"}",{}]}]}]},"$undefined","$undefined",true],["",{"children":["tags",{"children":[["tag","Large%20Language%20Models%20(LLMs)","d"],{"children":["__PAGE__",{},[["$L1",["$","$L2",null,{"children":[["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"CollectionPage\",\"name\":\"#Large Language Models (LLMs) - secrett2633's blog\",\"description\":\"Large Language Models (LLMs) 태그가 포함된 포스트 목록\",\"url\":\"https://blog.secrett2633.cloud/tags/Large%20Language%20Models%20(LLMs)\",\"isPartOf\":{\"@type\":\"WebSite\",\"name\":\"secrett2633's blog\",\"url\":\"https://blog.secrett2633.cloud\"},\"inLanguage\":\"ko\"}"}}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"BreadcrumbList\",\"itemListElement\":[{\"@type\":\"ListItem\",\"position\":1,\"name\":\"홈\",\"item\":\"https://blog.secrett2633.cloud/\"},{\"@type\":\"ListItem\",\"position\":2,\"name\":\"#Large Language Models (LLMs)\",\"item\":\"https://blog.secrett2633.cloud/tags/Large%20Language%20Models%20(LLMs)\"}]}"}}],["$","div",null,{"className":"space-y-6","children":["$","div",null,{"className":"flex flex-col lg:flex-row gap-8","children":[["$","aside",null,{"className":"lg:w-64 xl:w-72 order-1 lg:order-none","children":["$","div",null,{"className":"sidebar sticky","children":["$","nav",null,{"className":"space-y-4","aria-label":"카테고리 네비게이션","children":[["$","div","Backend",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"Backend"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Django",{"children":["$","$L3",null,{"href":"/backend/django","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Django"," (",6,")"]}]}],["$","li","Logging",{"children":["$","$L3",null,{"href":"/backend/logging","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Logging"," (",1,")"]}]}]]}]]}],["$","div","Python",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"Python"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","PEP",{"children":["$","$L3",null,{"href":"/python/pep","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["PEP"," (",650,")"]}]}]]}]]}],["$","div","AI/ML",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"AI/ML"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","LLM",{"children":["$","$L3",null,{"href":"/ai/llm","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["LLM"," (",1,")"]}]}],["$","li","Review",{"children":["$","$L3",null,{"href":"/ai/review","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Review"," (",2728,")"]}]}]]}]]}],["$","div","DevOps",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"DevOps"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Nginx",{"children":["$","$L3",null,{"href":"/devops/nginx","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Nginx"," (",1,")"]}]}],["$","li","Docker",{"children":["$","$L3",null,{"href":"/devops/docker","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Docker"," (",1,")"]}]}],["$","li","SafeLine",{"children":["$","$L3",null,{"href":"/devops/safeline","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["SafeLine"," (",1,")"]}]}],["$","li","Jenkins",{"children":["$","$L3",null,{"href":"/devops/jenkins","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Jenkins"," (",3,")"]}]}],["$","li","GitHub Actions",{"children":["$","$L3",null,{"href":"/devops/github-actions","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["GitHub Actions"," (",1,")"]}]}],["$","li","AWS",{"children":["$","$L3",null,{"href":"/devops/aws","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["AWS"," (",1,")"]}]}]]}]]}],["$","div","etc",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"etc"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Me",{"children":["$","$L3",null,{"href":"/etc/me","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Me"," (",3,")"]}]}],["$","li","Chrome Extension",{"children":["$","$L3",null,{"href":"/etc/chrome-extension","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Chrome Extension"," (",1,")"]}]}]]}]]}]]}]}]}],["$","div",null,{"className":"flex-1","children":[["$","nav",null,{"aria-label":"breadcrumb","className":"text-sm text-gray-500 mb-4","children":["$","ol",null,{"className":"flex flex-wrap items-center gap-1","children":[["$","li",null,{"children":["$","$L3",null,{"href":"/","className":"hover:text-gray-700","children":"홈"}]}],[["$","li","/tags/Large%20Language%20Models%20(LLMs)",{"className":"flex items-center gap-1","children":[["$","span",null,{"aria-hidden":"true","children":"/"}],["$","span",null,{"className":"text-gray-900","aria-current":"page","children":"#Large Language Models (LLMs)"}]]}]]]}]}],["$","h1",null,{"className":"page__title mb-6","children":["#","Large Language Models (LLMs)"]}],["$","p",null,{"className":"text-gray-500 mb-6","children":[145,"개의 포스트"]}],["$","div",null,{"className":"entries-list","children":[["$","article","2026-02-18-Does-Socialization-Emerge-in-AI-Agent-Society-A-Case-Study-of-Moltbook",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-18-Does-Socialization-Emerge-in-AI-Agent-Society-A-Case-Study-of-Moltbook","children":"[논문리뷰] Does Socialization Emerge in AI Agent Society? A Case Study of Moltbook"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-18-Does-Socialization-Emerge-in-AI-Agent-Society-A-Case-Study-of-Moltbook","children":"Ming Li이 [arXiv]에 게시한 'Does Socialization Emerge in AI Agent Society? A Case Study of Moltbook' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-18 00:00:00+0900+0900","children":"2026년 2월 18일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-18-Does-Socialization-Emerge-in-AI-Agent-Society-A-Case-Study-of-Moltbook"}]]}]]}],["$","article","2026-02-17-InnoEval-On-Research-Idea-Evaluation-as-a-Knowledge-Grounded-Multi-Perspective-Reasoning-Problem",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-17-InnoEval-On-Research-Idea-Evaluation-as-a-Knowledge-Grounded-Multi-Perspective-Reasoning-Problem","children":"[논문리뷰] InnoEval: On Research Idea Evaluation as a Knowledge-Grounded, Multi-Perspective Reasoning Problem"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-17-InnoEval-On-Research-Idea-Evaluation-as-a-Knowledge-Grounded-Multi-Perspective-Reasoning-Problem","children":"이 [arXiv]에 게시한 'InnoEval: On Research Idea Evaluation as a Knowledge-Grounded, Multi-Perspective Reasoning Problem' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-17 00:00:00+0900+0900","children":"2026년 2월 17일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-17-InnoEval-On-Research-Idea-Evaluation-as-a-Knowledge-Grounded-Multi-Perspective-Reasoning-Problem"}]]}]]}],["$","article","2026-02-17-A-Critical-Look-at-Targeted-Instruction-Selection-Disentangling-What-Matters-and-What-Doesnt",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-17-A-Critical-Look-at-Targeted-Instruction-Selection-Disentangling-What-Matters-and-What-Doesnt","children":"[논문리뷰] A Critical Look at Targeted Instruction Selection: Disentangling What Matters (and What Doesn't)"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-17-A-Critical-Look-at-Targeted-Instruction-Selection-Disentangling-What-Matters-and-What-Doesnt","children":"이 [arXiv]에 게시한 'A Critical Look at Targeted Instruction Selection: Disentangling What Matters (and What Doesn't)' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-17 00:00:00+0900+0900","children":"2026년 2월 17일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-17-A-Critical-Look-at-Targeted-Instruction-Selection-Disentangling-What-Matters-and-What-Doesnt"}]]}]]}],["$","article","2026-02-13-Pretraining-A-Large-Language-Model-using-Distributed-GPUs-A-Memory-Efficient-Decentralized-Paradigm",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-13-Pretraining-A-Large-Language-Model-using-Distributed-GPUs-A-Memory-Efficient-Decentralized-Paradigm","children":"[논문리뷰] Pretraining A Large Language Model using Distributed GPUs: A Memory-Efficient Decentralized Paradigm"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-13-Pretraining-A-Large-Language-Model-using-Distributed-GPUs-A-Memory-Efficient-Decentralized-Paradigm","children":"이 [arXiv]에 게시한 'Pretraining A Large Language Model using Distributed GPUs: A Memory-Efficient Decentralized Paradigm' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-13 00:00:00+0900+0900","children":"2026년 2월 13일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-13-Pretraining-A-Large-Language-Model-using-Distributed-GPUs-A-Memory-Efficient-Decentralized-Paradigm"}]]}]]}],["$","article","2026-02-13-Learning-beyond-Teacher-Generalized-On-Policy-Distillation-with-Reward-Extrapolation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-13-Learning-beyond-Teacher-Generalized-On-Policy-Distillation-with-Reward-Extrapolation","children":"[논문리뷰] Learning beyond Teacher: Generalized On-Policy Distillation with Reward Extrapolation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-13-Learning-beyond-Teacher-Generalized-On-Policy-Distillation-with-Reward-Extrapolation","children":"이 [arXiv]에 게시한 'Learning beyond Teacher: Generalized On-Policy Distillation with Reward Extrapolation' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-13 00:00:00+0900+0900","children":"2026년 2월 13일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-13-Learning-beyond-Teacher-Generalized-On-Policy-Distillation-with-Reward-Extrapolation"}]]}]]}],["$","article","2026-02-12-When-to-Memorize-and-When-to-Stop-Gated-Recurrent-Memory-for-Long-Context-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-12-When-to-Memorize-and-When-to-Stop-Gated-Recurrent-Memory-for-Long-Context-Reasoning","children":"[논문리뷰] When to Memorize and When to Stop: Gated Recurrent Memory for Long-Context Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-12-When-to-Memorize-and-When-to-Stop-Gated-Recurrent-Memory-for-Long-Context-Reasoning","children":"이 [arXiv]에 게시한 'When to Memorize and When to Stop: Gated Recurrent Memory for Long-Context Reasoning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-12 00:00:00+0900+0900","children":"2026년 2월 12일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-12-When-to-Memorize-and-When-to-Stop-Gated-Recurrent-Memory-for-Long-Context-Reasoning"}]]}]]}],["$","article","2026-02-12-QP-OneModel-A-Unified-Generative-LLM-for-Multi-Task-Query-Understanding-in-Xiaohongshu-Search",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-12-QP-OneModel-A-Unified-Generative-LLM-for-Multi-Task-Query-Understanding-in-Xiaohongshu-Search","children":"[논문리뷰] QP-OneModel: A Unified Generative LLM for Multi-Task Query Understanding in Xiaohongshu Search"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-12-QP-OneModel-A-Unified-Generative-LLM-for-Multi-Task-Query-Understanding-in-Xiaohongshu-Search","children":"Hui Zhang이 [arXiv]에 게시한 'QP-OneModel: A Unified Generative LLM for Multi-Task Query Understanding in Xiaohongshu Search' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-12 00:00:00+0900+0900","children":"2026년 2월 12일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-12-QP-OneModel-A-Unified-Generative-LLM-for-Multi-Task-Query-Understanding-in-Xiaohongshu-Search"}]]}]]}],["$","article","2026-02-12-Online-Causal-Kalman-Filtering-for-Stable-and-Effective-Policy-Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-12-Online-Causal-Kalman-Filtering-for-Stable-and-Effective-Policy-Optimization","children":"[논문리뷰] Online Causal Kalman Filtering for Stable and Effective Policy Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-12-Online-Causal-Kalman-Filtering-for-Stable-and-Effective-Policy-Optimization","children":"이 [arXiv]에 게시한 'Online Causal Kalman Filtering for Stable and Effective Policy Optimization' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-12 00:00:00+0900+0900","children":"2026년 2월 12일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-12-Online-Causal-Kalman-Filtering-for-Stable-and-Effective-Policy-Optimization"}]]}]]}],["$","article","2026-02-12-G-LNS-Generative-Large-Neighborhood-Search-for-LLM-Based-Automatic-Heuristic-Design",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-12-G-LNS-Generative-Large-Neighborhood-Search-for-LLM-Based-Automatic-Heuristic-Design","children":"[논문리뷰] G-LNS: Generative Large Neighborhood Search for LLM-Based Automatic Heuristic Design"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-12-G-LNS-Generative-Large-Neighborhood-Search-for-LLM-Based-Automatic-Heuristic-Design","children":"Liang Zeng이 [arXiv]에 게시한 'G-LNS: Generative Large Neighborhood Search for LLM-Based Automatic Heuristic Design' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-12 00:00:00+0900+0900","children":"2026년 2월 12일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-12-G-LNS-Generative-Large-Neighborhood-Search-for-LLM-Based-Automatic-Heuristic-Design"}]]}]]}],["$","article","2026-02-12-CLI-Gym-Scalable-CLI-Task-Generation-via-Agentic-Environment-Inversion",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-12-CLI-Gym-Scalable-CLI-Task-Generation-via-Agentic-Environment-Inversion","children":"[논문리뷰] CLI-Gym: Scalable CLI Task Generation via Agentic Environment Inversion"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-12-CLI-Gym-Scalable-CLI-Task-Generation-via-Agentic-Environment-Inversion","children":"Feiyang Pan이 [arXiv]에 게시한 'CLI-Gym: Scalable CLI Task Generation via Agentic Environment Inversion' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-12 00:00:00+0900+0900","children":"2026년 2월 12일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-12-CLI-Gym-Scalable-CLI-Task-Generation-via-Agentic-Environment-Inversion"}]]}]]}],["$","article","2026-02-11-Dynamic-Long-Context-Reasoning-over-Compressed-Memory-via-End-to-End-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-11-Dynamic-Long-Context-Reasoning-over-Compressed-Memory-via-End-to-End-Reinforcement-Learning","children":"[논문리뷰] Dynamic Long Context Reasoning over Compressed Memory via End-to-End Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-11-Dynamic-Long-Context-Reasoning-over-Compressed-Memory-via-End-to-End-Reinforcement-Learning","children":"이 [arXiv]에 게시한 'Dynamic Long Context Reasoning over Compressed Memory via End-to-End Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-11 00:00:00+0900+0900","children":"2026년 2월 11일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-11-Dynamic-Long-Context-Reasoning-over-Compressed-Memory-via-End-to-End-Reinforcement-Learning"}]]}]]}],["$","article","2026-02-11-Chain-of-Mindset-Reasoning-with-Adaptive-Cognitive-Modes",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-11-Chain-of-Mindset-Reasoning-with-Adaptive-Cognitive-Modes","children":"[논문리뷰] Chain of Mindset: Reasoning with Adaptive Cognitive Modes"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-11-Chain-of-Mindset-Reasoning-with-Adaptive-Cognitive-Modes","children":"이 [arXiv]에 게시한 'Chain of Mindset: Reasoning with Adaptive Cognitive Modes' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-11 00:00:00+0900+0900","children":"2026년 2월 11일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-11-Chain-of-Mindset-Reasoning-with-Adaptive-Cognitive-Modes"}]]}]]}],["$","article","2026-02-10-LatentChem-From-Textual-CoT-to-Latent-Thinking-in-Chemical-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-10-LatentChem-From-Textual-CoT-to-Latent-Thinking-in-Chemical-Reasoning","children":"[논문리뷰] LatentChem: From Textual CoT to Latent Thinking in Chemical Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-10-LatentChem-From-Textual-CoT-to-Latent-Thinking-in-Chemical-Reasoning","children":"Jia Zhang이 [arXiv]에 게시한 'LatentChem: From Textual CoT to Latent Thinking in Chemical Reasoning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-10 00:00:00+0900+0900","children":"2026년 2월 10일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-10-LatentChem-From-Textual-CoT-to-Latent-Thinking-in-Chemical-Reasoning"}]]}]]}],["$","article","2026-02-09-On-the-Entropy-Dynamics-in-Reinforcement-Fine-Tuning-of-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-09-On-the-Entropy-Dynamics-in-Reinforcement-Fine-Tuning-of-Large-Language-Models","children":"[논문리뷰] On the Entropy Dynamics in Reinforcement Fine-Tuning of Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-09-On-the-Entropy-Dynamics-in-Reinforcement-Fine-Tuning-of-Large-Language-Models","children":"Yanxi Chen이 [arXiv]에 게시한 'On the Entropy Dynamics in Reinforcement Fine-Tuning of Large Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-09 00:00:00+0900+0900","children":"2026년 2월 9일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-09-On-the-Entropy-Dynamics-in-Reinforcement-Fine-Tuning-of-Large-Language-Models"}]]}]]}],["$","article","2026-02-06-V-Retrver-Evidence-Driven-Agentic-Reasoning-for-Universal-Multimodal-Retrieval",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-06-V-Retrver-Evidence-Driven-Agentic-Reasoning-for-Universal-Multimodal-Retrieval","children":"[논문리뷰] V-Retrver: Evidence-Driven Agentic Reasoning for Universal Multimodal Retrieval"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-06-V-Retrver-Evidence-Driven-Agentic-Reasoning-for-Universal-Multimodal-Retrieval","children":"Zeyu Zhang이 [arXiv]에 게시한 'V-Retrver: Evidence-Driven Agentic Reasoning for Universal Multimodal Retrieval' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-06 00:00:00+0900+0900","children":"2026년 2월 6일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-06-V-Retrver-Evidence-Driven-Agentic-Reasoning-for-Universal-Multimodal-Retrieval"}]]}]]}],["$","article","2026-02-06-Multi-Task-GRPO-Reliable-LLM-Reasoning-Across-Tasks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-06-Multi-Task-GRPO-Reliable-LLM-Reasoning-Across-Tasks","children":"[논문리뷰] Multi-Task GRPO: Reliable LLM Reasoning Across Tasks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-06-Multi-Task-GRPO-Reliable-LLM-Reasoning-Across-Tasks","children":"Zhiyong Wang이 [arXiv]에 게시한 'Multi-Task GRPO: Reliable LLM Reasoning Across Tasks' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-06 00:00:00+0900+0900","children":"2026년 2월 6일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-06-Multi-Task-GRPO-Reliable-LLM-Reasoning-Across-Tasks"}]]}]]}],["$","article","2026-02-05-BatCoder-Self-Supervised-Bidirectional-Code-Documentation-Learning-via-Back-Translation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-05-BatCoder-Self-Supervised-Bidirectional-Code-Documentation-Learning-via-Back-Translation","children":"[논문리뷰] BatCoder: Self-Supervised Bidirectional Code-Documentation Learning via Back-Translation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-05-BatCoder-Self-Supervised-Bidirectional-Code-Documentation-Learning-via-Back-Translation","children":"Xiaohua Wang이 [arXiv]에 게시한 'BatCoder: Self-Supervised Bidirectional Code-Documentation Learning via Back-Translation' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-05 00:00:00+0900+0900","children":"2026년 2월 5일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-05-BatCoder-Self-Supervised-Bidirectional-Code-Documentation-Learning-via-Back-Translation"}]]}]]}],["$","article","2026-02-02-Latent-Chain-of-Thought-as-Planning-Decoupling-Reasoning-from-Verbalization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-02-Latent-Chain-of-Thought-as-Planning-Decoupling-Reasoning-from-Verbalization","children":"[논문리뷰] Latent Chain-of-Thought as Planning: Decoupling Reasoning from Verbalization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-02-Latent-Chain-of-Thought-as-Planning-Decoupling-Reasoning-from-Verbalization","children":"이 [arXiv]에 게시한 'Latent Chain-of-Thought as Planning: Decoupling Reasoning from Verbalization' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-02 00:00:00+0900+0900","children":"2026년 2월 2일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-02-Latent-Chain-of-Thought-as-Planning-Decoupling-Reasoning-from-Verbalization"}]]}]]}],["$","article","2026-01-30-Self-Improving-Pretraining-using-post-trained-models-to-pretrain-better-models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-30-Self-Improving-Pretraining-using-post-trained-models-to-pretrain-better-models","children":"[논문리뷰] Self-Improving Pretraining: using post-trained models to pretrain better models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-30-Self-Improving-Pretraining-using-post-trained-models-to-pretrain-better-models","children":"이 [arXiv]에 게시한 'Self-Improving Pretraining: using post-trained models to pretrain better models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-30 00:00:00+0900+0900","children":"2026년 1월 30일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-30-Self-Improving-Pretraining-using-post-trained-models-to-pretrain-better-models"}]]}]]}],["$","article","2026-01-30-Scaling-Embeddings-Outperforms-Scaling-Experts-in-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-30-Scaling-Embeddings-Outperforms-Scaling-Experts-in-Language-Models","children":"[논문리뷰] Scaling Embeddings Outperforms Scaling Experts in Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-30-Scaling-Embeddings-Outperforms-Scaling-Experts-in-Language-Models","children":"이 [arXiv]에 게시한 'Scaling Embeddings Outperforms Scaling Experts in Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-30 00:00:00+0900+0900","children":"2026년 1월 30일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-30-Scaling-Embeddings-Outperforms-Scaling-Experts-in-Language-Models"}]]}]]}],["$","article","2026-01-30-Exploring-Reasoning-Reward-Model-for-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-30-Exploring-Reasoning-Reward-Model-for-Agents","children":"[논문리뷰] Exploring Reasoning Reward Model for Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-30-Exploring-Reasoning-Reward-Model-for-Agents","children":"Zhixun Li이 [arXiv]에 게시한 'Exploring Reasoning Reward Model for Agents' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-30 00:00:00+0900+0900","children":"2026년 1월 30일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-30-Exploring-Reasoning-Reward-Model-for-Agents"}]]}]]}],["$","article","2026-01-30-Beyond-Imitation-Reinforcement-Learning-for-Active-Latent-Planning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-30-Beyond-Imitation-Reinforcement-Learning-for-Active-Latent-Planning","children":"[논문리뷰] Beyond Imitation: Reinforcement Learning for Active Latent Planning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-30-Beyond-Imitation-Reinforcement-Learning-for-Active-Latent-Planning","children":"Wee Sun Lee이 [arXiv]에 게시한 'Beyond Imitation: Reinforcement Learning for Active Latent Planning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-30 00:00:00+0900+0900","children":"2026년 1월 30일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-30-Beyond-Imitation-Reinforcement-Learning-for-Active-Latent-Planning"}]]}]]}],["$","article","2026-01-29-Reinforcement-Learning-via-Self-Distillation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-29-Reinforcement-Learning-via-Self-Distillation","children":"[논문리뷰] Reinforcement Learning via Self-Distillation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-29-Reinforcement-Learning-via-Self-Distillation","children":"이 [arXiv]에 게시한 'Reinforcement Learning via Self-Distillation' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-29 00:00:00+0900+0900","children":"2026년 1월 29일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-29-Reinforcement-Learning-via-Self-Distillation"}]]}]]}],["$","article","2026-01-28-Selective-Steering-Norm-Preserving-Control-Through-Discriminative-Layer-Selection",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-28-Selective-Steering-Norm-Preserving-Control-Through-Discriminative-Layer-Selection","children":"[논문리뷰] Selective Steering: Norm-Preserving Control Through Discriminative Layer Selection"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-28-Selective-Steering-Norm-Preserving-Control-Through-Discriminative-Layer-Selection","children":"이 [arXiv]에 게시한 'Selective Steering: Norm-Preserving Control Through Discriminative Layer Selection' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-28 00:00:00+0900+0900","children":"2026년 1월 28일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-28-Selective-Steering-Norm-Preserving-Control-Through-Discriminative-Layer-Selection"}]]}]]}],["$","article","2026-01-28-HalluCitation-Matters-Revealing-the-Impact-of-Hallucinated-References-with-300-Hallucinated-Papers-in-ACL-Conferences",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-28-HalluCitation-Matters-Revealing-the-Impact-of-Hallucinated-References-with-300-Hallucinated-Papers-in-ACL-Conferences","children":"[논문리뷰] HalluCitation Matters: Revealing the Impact of Hallucinated References with 300 Hallucinated Papers in ACL Conferences"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-28-HalluCitation-Matters-Revealing-the-Impact-of-Hallucinated-References-with-300-Hallucinated-Papers-in-ACL-Conferences","children":"Taro Watanabe이 [arXiv]에 게시한 'HalluCitation Matters: Revealing the Impact of Hallucinated References with 300 Hallucinated Papers in ACL Conferences' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-28 00:00:00+0900+0900","children":"2026년 1월 28일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-28-HalluCitation-Matters-Revealing-the-Impact-of-Hallucinated-References-with-300-Hallucinated-Papers-in-ACL-Conferences"}]]}]]}],["$","article","2026-01-26-SWE-Pruner-Self-Adaptive-Context-Pruning-for-Coding-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-26-SWE-Pruner-Self-Adaptive-Context-Pruning-for-Coding-Agents","children":"[논문리뷰] SWE-Pruner: Self-Adaptive Context Pruning for Coding Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-26-SWE-Pruner-Self-Adaptive-Context-Pruning-for-Coding-Agents","children":"이 [arXiv]에 게시한 'SWE-Pruner: Self-Adaptive Context Pruning for Coding Agents' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-26 00:00:00+0900+0900","children":"2026년 1월 26일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-26-SWE-Pruner-Self-Adaptive-Context-Pruning-for-Coding-Agents"}]]}]]}],["$","article","2026-01-26-LongCat-Flash-Thinking-2601-Technical-Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-26-LongCat-Flash-Thinking-2601-Technical-Report","children":"[논문리뷰] LongCat-Flash-Thinking-2601 Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-26-LongCat-Flash-Thinking-2601-Technical-Report","children":"이 [arXiv]에 게시한 'LongCat-Flash-Thinking-2601 Technical Report' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-26 00:00:00+0900+0900","children":"2026년 1월 26일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-26-LongCat-Flash-Thinking-2601-Technical-Report"}]]}]]}],["$","article","2026-01-22-Render-of-Thought-Rendering-Textual-Chain-of-Thought-as-Images-for-Visual-Latent-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-22-Render-of-Thought-Rendering-Textual-Chain-of-Thought-as-Images-for-Visual-Latent-Reasoning","children":"[논문리뷰] Render-of-Thought: Rendering Textual Chain-of-Thought as Images for Visual Latent Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-22-Render-of-Thought-Rendering-Textual-Chain-of-Thought-as-Images-for-Visual-Latent-Reasoning","children":"이 [arXiv]에 게시한 'Render-of-Thought: Rendering Textual Chain-of-Thought as Images for Visual Latent Reasoning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-22 00:00:00+0900+0900","children":"2026년 1월 22일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-22-Render-of-Thought-Rendering-Textual-Chain-of-Thought-as-Images-for-Visual-Latent-Reasoning"}]]}]]}],["$","article","2026-01-22-Numina-Lean-Agent-An-Open-and-General-Agentic-Reasoning-System-for-Formal-Mathematics",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-22-Numina-Lean-Agent-An-Open-and-General-Agentic-Reasoning-System-for-Formal-Mathematics","children":"[논문리뷰] Numina-Lean-Agent: An Open and General Agentic Reasoning System for Formal Mathematics"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-22-Numina-Lean-Agent-An-Open-and-General-Agentic-Reasoning-System-for-Formal-Mathematics","children":"이 [arXiv]에 게시한 'Numina-Lean-Agent: An Open and General Agentic Reasoning System for Formal Mathematics' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-22 00:00:00+0900+0900","children":"2026년 1월 22일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-22-Numina-Lean-Agent-An-Open-and-General-Agentic-Reasoning-System-for-Formal-Mathematics"}]]}]]}],["$","article","2026-01-22-Facilitating-Proactive-and-Reactive-Guidance-for-Decision-Making-on-the-Web-A-Design-Probe-with-WebSeek",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-22-Facilitating-Proactive-and-Reactive-Guidance-for-Decision-Making-on-the-Web-A-Design-Probe-with-WebSeek","children":"[논문리뷰] Facilitating Proactive and Reactive Guidance for Decision Making on the Web: A Design Probe with WebSeek"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-22-Facilitating-Proactive-and-Reactive-Guidance-for-Decision-Making-on-the-Web-A-Design-Probe-with-WebSeek","children":"Arpit Narechania이 [arXiv]에 게시한 'Facilitating Proactive and Reactive Guidance for Decision Making on the Web: A Design Probe with WebSeek' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-22 00:00:00+0900+0900","children":"2026년 1월 22일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-22-Facilitating-Proactive-and-Reactive-Guidance-for-Decision-Making-on-the-Web-A-Design-Probe-with-WebSeek"}]]}]]}],["$","article","2026-01-20-YaPO-Learnable-Sparse-Activation-Steering-Vectors-for-Domain-Adaptation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-20-YaPO-Learnable-Sparse-Activation-Steering-Vectors-for-Domain-Adaptation","children":"[논문리뷰] YaPO: Learnable Sparse Activation Steering Vectors for Domain Adaptation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-20-YaPO-Learnable-Sparse-Activation-Steering-Vectors-for-Domain-Adaptation","children":"이 [arXiv]에 게시한 'YaPO: Learnable Sparse Activation Steering Vectors for Domain Adaptation' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-20 00:00:00+0900+0900","children":"2026년 1월 20일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-20-YaPO-Learnable-Sparse-Activation-Steering-Vectors-for-Domain-Adaptation"}]]}]]}],["$","article","2026-01-19-Reasoning-Models-Generate-Societies-of-Thought",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-19-Reasoning-Models-Generate-Societies-of-Thought","children":"[논문리뷰] Reasoning Models Generate Societies of Thought"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-19-Reasoning-Models-Generate-Societies-of-Thought","children":"James Evans이 [arXiv]에 게시한 'Reasoning Models Generate Societies of Thought' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-19 00:00:00+0900+0900","children":"2026년 1월 19일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-19-Reasoning-Models-Generate-Societies-of-Thought"}]]}]]}],["$","article","2026-01-16-Rewarding-the-Rare-Uniqueness-Aware-RL-for-Creative-Problem-Solving-in-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-16-Rewarding-the-Rare-Uniqueness-Aware-RL-for-Creative-Problem-Solving-in-LLMs","children":"[논문리뷰] Rewarding the Rare: Uniqueness-Aware RL for Creative Problem Solving in LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-16-Rewarding-the-Rare-Uniqueness-Aware-RL-for-Creative-Problem-Solving-in-LLMs","children":"이 [arXiv]에 게시한 'Rewarding the Rare: Uniqueness-Aware RL for Creative Problem Solving in LLMs' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-16 00:00:00+0900+0900","children":"2026년 1월 16일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-16-Rewarding-the-Rare-Uniqueness-Aware-RL-for-Creative-Problem-Solving-in-LLMs"}]]}]]}],["$","article","2026-01-16-EvasionBench-Detecting-Evasive-Answers-in-Financial-QA-via-Multi-Model-Consensus-and-LLM-as-Judge",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-16-EvasionBench-Detecting-Evasive-Answers-in-Financial-QA-via-Multi-Model-Consensus-and-LLM-as-Judge","children":"[논문리뷰] EvasionBench: Detecting Evasive Answers in Financial Q&A via Multi-Model Consensus and LLM-as-Judge"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-16-EvasionBench-Detecting-Evasive-Answers-in-Financial-QA-via-Multi-Model-Consensus-and-LLM-as-Judge","children":"Yi Yang이 [arXiv]에 게시한 'EvasionBench: Detecting Evasive Answers in Financial Q&A via Multi-Model Consensus and LLM-as-Judge' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-16 00:00:00+0900+0900","children":"2026년 1월 16일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-16-EvasionBench-Detecting-Evasive-Answers-in-Financial-QA-via-Multi-Model-Consensus-and-LLM-as-Judge"}]]}]]}],["$","article","2026-01-15-The-AI-Hippocampus-How-Far-are-We-From-Human-Memory",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-15-The-AI-Hippocampus-How-Far-are-We-From-Human-Memory","children":"[논문리뷰] The AI Hippocampus: How Far are We From Human Memory?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-15-The-AI-Hippocampus-How-Far-are-We-From-Human-Memory","children":"Tong Wu이 [arXiv]에 게시한 'The AI Hippocampus: How Far are We From Human Memory?' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-15 00:00:00+0900+0900","children":"2026년 1월 15일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-15-The-AI-Hippocampus-How-Far-are-We-From-Human-Memory"}]]}]]}],["$","article","2026-01-15-Distribution-Aligned-Sequence-Distillation-for-Superior-Long-CoT-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-15-Distribution-Aligned-Sequence-Distillation-for-Superior-Long-CoT-Reasoning","children":"[논문리뷰] Distribution-Aligned Sequence Distillation for Superior Long-CoT Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-15-Distribution-Aligned-Sequence-Distillation-for-Superior-Long-CoT-Reasoning","children":"이 [arXiv]에 게시한 'Distribution-Aligned Sequence Distillation for Superior Long-CoT Reasoning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-15 00:00:00+0900+0900","children":"2026년 1월 15일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-15-Distribution-Aligned-Sequence-Distillation-for-Superior-Long-CoT-Reasoning"}]]}]]}],["$","article","2026-01-15-A3-Bench-Benchmarking-Memory-Driven-Scientific-Reasoning-via-Anchor-and-Attractor-Activation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-15-A3-Bench-Benchmarking-Memory-Driven-Scientific-Reasoning-via-Anchor-and-Attractor-Activation","children":"[논문리뷰] A^3-Bench: Benchmarking Memory-Driven Scientific Reasoning via Anchor and Attractor Activation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-15-A3-Bench-Benchmarking-Memory-Driven-Scientific-Reasoning-via-Anchor-and-Attractor-Activation","children":"Kai He이 [arXiv]에 게시한 'A^3-Bench: Benchmarking Memory-Driven Scientific Reasoning via Anchor and Attractor Activation' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-15 00:00:00+0900+0900","children":"2026년 1월 15일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-15-A3-Bench-Benchmarking-Memory-Driven-Scientific-Reasoning-via-Anchor-and-Attractor-Activation"}]]}]]}],["$","article","2026-01-14-Towards-Comprehensive-Stage-wise-Benchmarking-of-Large-Language-Models-in-Fact-Checking",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-14-Towards-Comprehensive-Stage-wise-Benchmarking-of-Large-Language-Models-in-Fact-Checking","children":"[논문리뷰] Towards Comprehensive Stage-wise Benchmarking of Large Language Models in Fact-Checking"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-14-Towards-Comprehensive-Stage-wise-Benchmarking-of-Large-Language-Models-in-Fact-Checking","children":"Zhen Ye이 [arXiv]에 게시한 'Towards Comprehensive Stage-wise Benchmarking of Large Language Models in Fact-Checking' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-14 00:00:00+0900+0900","children":"2026년 1월 14일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-14-Towards-Comprehensive-Stage-wise-Benchmarking-of-Large-Language-Models-in-Fact-Checking"}]]}]]}],["$","article","2026-01-13-ET-Agent-Incentivizing-Effective-Tool-Integrated-Reasoning-Agent-via-Behavior-Calibration",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-13-ET-Agent-Incentivizing-Effective-Tool-Integrated-Reasoning-Agent-via-Behavior-Calibration","children":"[논문리뷰] ET-Agent: Incentivizing Effective Tool-Integrated Reasoning Agent via Behavior Calibration"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-13-ET-Agent-Incentivizing-Effective-Tool-Integrated-Reasoning-Agent-via-Behavior-Calibration","children":"이 [arXiv]에 게시한 'ET-Agent: Incentivizing Effective Tool-Integrated Reasoning Agent via Behavior Calibration' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-13 00:00:00+0900+0900","children":"2026년 1월 13일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-13-ET-Agent-Incentivizing-Effective-Tool-Integrated-Reasoning-Agent-via-Behavior-Calibration"}]]}]]}],["$","article","2026-01-13-Dr-Zero-Self-Evolving-Search-Agents-without-Training-Data",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-13-Dr-Zero-Self-Evolving-Search-Agents-without-Training-Data","children":"[논문리뷰] Dr. Zero: Self-Evolving Search Agents without Training Data"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-13-Dr-Zero-Self-Evolving-Search-Agents-without-Training-Data","children":"Shaoliang Nie이 [arXiv]에 게시한 'Dr. Zero: Self-Evolving Search Agents without Training Data' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-13 00:00:00+0900+0900","children":"2026년 1월 13일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-13-Dr-Zero-Self-Evolving-Search-Agents-without-Training-Data"}]]}]]}],["$","article","2026-01-13-Controllable-Memory-Usage-Balancing-Anchoring-and-Innovation-in-Long-Term-Human-Agent-Interaction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-13-Controllable-Memory-Usage-Balancing-Anchoring-and-Innovation-in-Long-Term-Human-Agent-Interaction","children":"[논문리뷰] Controllable Memory Usage: Balancing Anchoring and Innovation in Long-Term Human-Agent Interaction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-13-Controllable-Memory-Usage-Balancing-Anchoring-and-Innovation-in-Long-Term-Human-Agent-Interaction","children":"Zhengkang Guo이 [arXiv]에 게시한 'Controllable Memory Usage: Balancing Anchoring and Innovation in Long-Term Human-Agent Interaction' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-13 00:00:00+0900+0900","children":"2026년 1월 13일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-13-Controllable-Memory-Usage-Balancing-Anchoring-and-Innovation-in-Long-Term-Human-Agent-Interaction"}]]}]]}],["$","article","2026-01-08-Entropy-Adaptive-Fine-Tuning-Resolving-Confident-Conflicts-to-Mitigate-Forgetting",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-08-Entropy-Adaptive-Fine-Tuning-Resolving-Confident-Conflicts-to-Mitigate-Forgetting","children":"[논문리뷰] Entropy-Adaptive Fine-Tuning: Resolving Confident Conflicts to Mitigate Forgetting"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-08-Entropy-Adaptive-Fine-Tuning-Resolving-Confident-Conflicts-to-Mitigate-Forgetting","children":"이 [arXiv]에 게시한 'Entropy-Adaptive Fine-Tuning: Resolving Confident Conflicts to Mitigate Forgetting' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-08 00:00:00+0900+0900","children":"2026년 1월 8일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-08-Entropy-Adaptive-Fine-Tuning-Resolving-Confident-Conflicts-to-Mitigate-Forgetting"}]]}]]}],["$","article","2026-01-07-X-MuTeST-A-Multilingual-Benchmark-for-Explainable-Hate-Speech-Detection-and-A-Novel-LLM-consulted-Explanation-Framework",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-07-X-MuTeST-A-Multilingual-Benchmark-for-Explainable-Hate-Speech-Detection-and-A-Novel-LLM-consulted-Explanation-Framework","children":"[논문리뷰] X-MuTeST: A Multilingual Benchmark for Explainable Hate Speech Detection and A Novel LLM-consulted Explanation Framework"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-07-X-MuTeST-A-Multilingual-Benchmark-for-Explainable-Hate-Speech-Detection-and-A-Novel-LLM-consulted-Explanation-Framework","children":"Shwetank Shekhar Singh이 [arXiv]에 게시한 'X-MuTeST: A Multilingual Benchmark for Explainable Hate Speech Detection and A Novel LLM-consulted Explanation Framework' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-07 00:00:00+0900+0900","children":"2026년 1월 7일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-07-X-MuTeST-A-Multilingual-Benchmark-for-Explainable-Hate-Speech-Detection-and-A-Novel-LLM-consulted-Explanation-Framework"}]]}]]}],["$","article","2026-01-06-SWE-Lego-Pushing-the-Limits-of-Supervised-Fine-tuning-for-Software-Issue-Resolving",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-06-SWE-Lego-Pushing-the-Limits-of-Supervised-Fine-tuning-for-Software-Issue-Resolving","children":"[논문리뷰] SWE-Lego: Pushing the Limits of Supervised Fine-tuning for Software Issue Resolving"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-06-SWE-Lego-Pushing-the-Limits-of-Supervised-Fine-tuning-for-Software-Issue-Resolving","children":"이 [arXiv]에 게시한 'SWE-Lego: Pushing the Limits of Supervised Fine-tuning for Software Issue Resolving' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-06 00:00:00+0900+0900","children":"2026년 1월 6일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-06-SWE-Lego-Pushing-the-Limits-of-Supervised-Fine-tuning-for-Software-Issue-Resolving"}]]}]]}],["$","article","2026-01-01-AI-Meets-Brain-Memory-Systems-from-Cognitive-Neuroscience-to-Autonomous-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-01-AI-Meets-Brain-Memory-Systems-from-Cognitive-Neuroscience-to-Autonomous-Agents","children":"[논문리뷰] AI Meets Brain: Memory Systems from Cognitive Neuroscience to Autonomous Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-01-AI-Meets-Brain-Memory-Systems-from-Cognitive-Neuroscience-to-Autonomous-Agents","children":"Shixin Jiang이 [arXiv]에 게시한 'AI Meets Brain: Memory Systems from Cognitive Neuroscience to Autonomous Agents' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-01 00:00:00+0900+0900","children":"2026년 1월 1일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-01-AI-Meets-Brain-Memory-Systems-from-Cognitive-Neuroscience-to-Autonomous-Agents"}]]}]]}],["$","article","2025-12-30-VL-LN-Bench-Towards-Long-horizon-Goal-oriented-Navigation-with-Active-Dialogs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-30-VL-LN-Bench-Towards-Long-horizon-Goal-oriented-Navigation-with-Active-Dialogs","children":"[논문리뷰] VL-LN Bench: Towards Long-horizon Goal-oriented Navigation with Active Dialogs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-30-VL-LN-Bench-Towards-Long-horizon-Goal-oriented-Navigation-with-Active-Dialogs","children":"Xihui Liu이 [arXiv]에 게시한 'VL-LN Bench: Towards Long-horizon Goal-oriented Navigation with Active Dialogs' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-30 00:00:00+0900+0900","children":"2025년 12월 30일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-30-VL-LN-Bench-Towards-Long-horizon-Goal-oriented-Navigation-with-Active-Dialogs"}]]}]]}],["$","article","2025-12-30-Coupling-Experts-and-Routers-in-Mixture-of-Experts-via-an-Auxiliary-Loss",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-30-Coupling-Experts-and-Routers-in-Mixture-of-Experts-via-an-Auxiliary-Loss","children":"[논문리뷰] Coupling Experts and Routers in Mixture-of-Experts via an Auxiliary Loss"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-30-Coupling-Experts-and-Routers-in-Mixture-of-Experts-via-an-Auxiliary-Loss","children":"이 [arXiv]에 게시한 'Coupling Experts and Routers in Mixture-of-Experts via an Auxiliary Loss' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-30 00:00:00+0900+0900","children":"2025년 12월 30일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-30-Coupling-Experts-and-Routers-in-Mixture-of-Experts-via-an-Auxiliary-Loss"}]]}]]}],["$","article","2025-12-25-Streaming-Video-Instruction-Tuning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-25-Streaming-Video-Instruction-Tuning","children":"[논문리뷰] Streaming Video Instruction Tuning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-25-Streaming-Video-Instruction-Tuning","children":"Kaiyang Zhou이 [arXiv]에 게시한 'Streaming Video Instruction Tuning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-25 00:00:00+0900+0900","children":"2025년 12월 25일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-25-Streaming-Video-Instruction-Tuning"}]]}]]}],["$","article","2025-12-25-SWE-EVO-Benchmarking-Coding-Agents-in-Long-Horizon-Software-Evolution-Scenarios",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-25-SWE-EVO-Benchmarking-Coding-Agents-in-Long-Horizon-Software-Evolution-Scenarios","children":"[논문리뷰] SWE-EVO: Benchmarking Coding Agents in Long-Horizon Software Evolution Scenarios"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-25-SWE-EVO-Benchmarking-Coding-Agents-in-Long-Horizon-Software-Evolution-Scenarios","children":"Nghi D. Q. Bui이 [arXiv]에 게시한 'SWE-EVO: Benchmarking Coding Agents in Long-Horizon Software Evolution Scenarios' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-25 00:00:00+0900+0900","children":"2025년 12월 25일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-25-SWE-EVO-Benchmarking-Coding-Agents-in-Long-Horizon-Software-Evolution-Scenarios"}]]}]]}],["$","article","2025-12-23-Understanding-Syllogistic-Reasoning-in-LLMs-from-Formal-and-Natural-Language-Perspectives",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-23-Understanding-Syllogistic-Reasoning-in-LLMs-from-Formal-and-Natural-Language-Perspectives","children":"[논문리뷰] Understanding Syllogistic Reasoning in LLMs from Formal and Natural Language Perspectives"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-23-Understanding-Syllogistic-Reasoning-in-LLMs-from-Formal-and-Natural-Language-Perspectives","children":"Sujata Ghosh이 [arXiv]에 게시한 'Understanding Syllogistic Reasoning in LLMs from Formal and Natural Language Perspectives' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-23 00:00:00+0900+0900","children":"2025년 12월 23일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-23-Understanding-Syllogistic-Reasoning-in-LLMs-from-Formal-and-Natural-Language-Perspectives"}]]}]]}],["$","article","2025-12-23-UCoder-Unsupervised-Code-Generation-by-Internal-Probing-of-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-23-UCoder-Unsupervised-Code-Generation-by-Internal-Probing-of-Large-Language-Models","children":"[논문리뷰] UCoder: Unsupervised Code Generation by Internal Probing of Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-23-UCoder-Unsupervised-Code-Generation-by-Internal-Probing-of-Large-Language-Models","children":"Yuqing Ma이 [arXiv]에 게시한 'UCoder: Unsupervised Code Generation by Internal Probing of Large Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-23 00:00:00+0900+0900","children":"2025년 12월 23일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-23-UCoder-Unsupervised-Code-Generation-by-Internal-Probing-of-Large-Language-Models"}]]}]]}],["$","article","2025-12-23-Reasoning-Palette-Modulating-Reasoning-via-Latent-Contextualization-for-Controllable-Exploration-for-VLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-23-Reasoning-Palette-Modulating-Reasoning-via-Latent-Contextualization-for-Controllable-Exploration-for-VLMs","children":"[논문리뷰] Reasoning Palette: Modulating Reasoning via Latent Contextualization for Controllable Exploration for (V)LMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-23-Reasoning-Palette-Modulating-Reasoning-via-Latent-Contextualization-for-Controllable-Exploration-for-VLMs","children":"이 [arXiv]에 게시한 'Reasoning Palette: Modulating Reasoning via Latent Contextualization for Controllable Exploration for (V)LMs' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-23 00:00:00+0900+0900","children":"2025년 12월 23일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-23-Reasoning-Palette-Modulating-Reasoning-via-Latent-Contextualization-for-Controllable-Exploration-for-VLMs"}]]}]]}],["$","article","2025-12-22-SWE-Bench-A-Framework-for-the-Scalable-Generation-of-Software-Engineering-Benchmarks-from-Open-Source-Repositories",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-22-SWE-Bench-A-Framework-for-the-Scalable-Generation-of-Software-Engineering-Benchmarks-from-Open-Source-Repositories","children":"[논문리뷰] SWE-Bench++: A Framework for the Scalable Generation of Software Engineering Benchmarks from Open-Source Repositories"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-22-SWE-Bench-A-Framework-for-the-Scalable-Generation-of-Software-Engineering-Benchmarks-from-Open-Source-Repositories","children":"이 [arXiv]에 게시한 'SWE-Bench++: A Framework for the Scalable Generation of Software Engineering Benchmarks from Open-Source Repositories' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-22 00:00:00+0900+0900","children":"2025년 12월 22일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-22-SWE-Bench-A-Framework-for-the-Scalable-Generation-of-Software-Engineering-Benchmarks-from-Open-Source-Repositories"}]]}]]}],["$","article","2025-12-15-LEO-RobotAgent-A-General-purpose-Robotic-Agent-for-Language-driven-Embodied-Operator",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-15-LEO-RobotAgent-A-General-purpose-Robotic-Agent-for-Language-driven-Embodied-Operator","children":"[논문리뷰] LEO-RobotAgent: A General-purpose Robotic Agent for Language-driven Embodied Operator"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-15-LEO-RobotAgent-A-General-purpose-Robotic-Agent-for-Language-driven-Embodied-Operator","children":"이 [arXiv]에 게시한 'LEO-RobotAgent: A General-purpose Robotic Agent for Language-driven Embodied Operator' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-15 00:00:00+0900+0900","children":"2025년 12월 15일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-15-LEO-RobotAgent-A-General-purpose-Robotic-Agent-for-Language-driven-Embodied-Operator"}]]}]]}],["$","article","2025-12-09-Native-Parallel-Reasoner-Reasoning-in-Parallelism-via-Self-Distilled-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-09-Native-Parallel-Reasoner-Reasoning-in-Parallelism-via-Self-Distilled-Reinforcement-Learning","children":"[논문리뷰] Native Parallel Reasoner: Reasoning in Parallelism via Self-Distilled Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-09-Native-Parallel-Reasoner-Reasoning-in-Parallelism-via-Self-Distilled-Reinforcement-Learning","children":"이 [arXiv]에 게시한 'Native Parallel Reasoner: Reasoning in Parallelism via Self-Distilled Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-09 00:00:00+0900+0900","children":"2025년 12월 9일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-09-Native-Parallel-Reasoner-Reasoning-in-Parallelism-via-Self-Distilled-Reinforcement-Learning"}]]}]]}],["$","article","2025-12-05-SignRoundV2-Closing-the-Performance-Gap-in-Extremely-Low-Bit-Post-Training-Quantization-for-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-05-SignRoundV2-Closing-the-Performance-Gap-in-Extremely-Low-Bit-Post-Training-Quantization-for-LLMs","children":"[논문리뷰] SignRoundV2: Closing the Performance Gap in Extremely Low-Bit Post-Training Quantization for LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-05-SignRoundV2-Closing-the-Performance-Gap-in-Extremely-Low-Bit-Post-Training-Quantization-for-LLMs","children":"이 [arXiv]에 게시한 'SignRoundV2: Closing the Performance Gap in Extremely Low-Bit Post-Training Quantization for LLMs' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-05 00:00:00+0900+0900","children":"2025년 12월 5일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-05-SignRoundV2-Closing-the-Performance-Gap-in-Extremely-Low-Bit-Post-Training-Quantization-for-LLMs"}]]}]]}],["$","article","2025-12-05-REFLEX-Self-Refining-Explainable-Fact-Checking-via-Disentangling-Truth-into-Style-and-Substance",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-05-REFLEX-Self-Refining-Explainable-Fact-Checking-via-Disentangling-Truth-into-Style-and-Substance","children":"[논문리뷰] REFLEX: Self-Refining Explainable Fact-Checking via Disentangling Truth into Style and Substance"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-05-REFLEX-Self-Refining-Explainable-Fact-Checking-via-Disentangling-Truth-into-Style-and-Substance","children":"Yaxin Fan이 [arXiv]에 게시한 'REFLEX: Self-Refining Explainable Fact-Checking via Disentangling Truth into Style and Substance' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-05 00:00:00+0900+0900","children":"2025년 12월 5일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-05-REFLEX-Self-Refining-Explainable-Fact-Checking-via-Disentangling-Truth-into-Style-and-Substance"}]]}]]}],["$","article","2025-12-05-On-GRPO-Collapse-in-Search-R1-The-Lazy-Likelihood-Displacement-Death-Spiral",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-05-On-GRPO-Collapse-in-Search-R1-The-Lazy-Likelihood-Displacement-Death-Spiral","children":"[논문리뷰] On GRPO Collapse in Search-R1: The Lazy Likelihood-Displacement Death Spiral"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-05-On-GRPO-Collapse-in-Search-R1-The-Lazy-Likelihood-Displacement-Death-Spiral","children":"Christos Thrampoulidis이 [arXiv]에 게시한 'On GRPO Collapse in Search-R1: The Lazy Likelihood-Displacement Death Spiral' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-05 00:00:00+0900+0900","children":"2025년 12월 5일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-05-On-GRPO-Collapse-in-Search-R1-The-Lazy-Likelihood-Displacement-Death-Spiral"}]]}]]}],["$","article","2025-12-05-Nex-N1-Agentic-Models-Trained-via-a-Unified-Ecosystem-for-Large-Scale-Environment-Construction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-05-Nex-N1-Agentic-Models-Trained-via-a-Unified-Ecosystem-for-Large-Scale-Environment-Construction","children":"[논문리뷰] Nex-N1: Agentic Models Trained via a Unified Ecosystem for Large-Scale Environment Construction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-05-Nex-N1-Agentic-Models-Trained-via-a-Unified-Ecosystem-for-Large-Scale-Environment-Construction","children":"이 [arXiv]에 게시한 'Nex-N1: Agentic Models Trained via a Unified Ecosystem for Large-Scale Environment Construction' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-05 00:00:00+0900+0900","children":"2025년 12월 5일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-05-Nex-N1-Agentic-Models-Trained-via-a-Unified-Ecosystem-for-Large-Scale-Environment-Construction"}]]}]]}],["$","article","2025-12-05-Mitigating-Catastrophic-Forgetting-in-Target-Language-Adaptation-of-LLMs-via-Source-Shielded-Updates",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-05-Mitigating-Catastrophic-Forgetting-in-Target-Language-Adaptation-of-LLMs-via-Source-Shielded-Updates","children":"[논문리뷰] Mitigating Catastrophic Forgetting in Target Language Adaptation of LLMs via Source-Shielded Updates"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-05-Mitigating-Catastrophic-Forgetting-in-Target-Language-Adaptation-of-LLMs-via-Source-Shielded-Updates","children":"Nikolaos Aletras이 [arXiv]에 게시한 'Mitigating Catastrophic Forgetting in Target Language Adaptation of LLMs via Source-Shielded Updates' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-05 00:00:00+0900+0900","children":"2025년 12월 5일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-05-Mitigating-Catastrophic-Forgetting-in-Target-Language-Adaptation-of-LLMs-via-Source-Shielded-Updates"}]]}]]}],["$","article","2025-12-02-Stabilizing-Reinforcement-Learning-with-LLMs-Formulation-and-Practices",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-02-Stabilizing-Reinforcement-Learning-with-LLMs-Formulation-and-Practices","children":"[논문리뷰] Stabilizing Reinforcement Learning with LLMs: Formulation and Practices"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-02-Stabilizing-Reinforcement-Learning-with-LLMs-Formulation-and-Practices","children":"이 [arXiv]에 게시한 'Stabilizing Reinforcement Learning with LLMs: Formulation and Practices' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-02 00:00:00+0900+0900","children":"2025년 12월 2일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-02-Stabilizing-Reinforcement-Learning-with-LLMs-Formulation-and-Practices"}]]}]]}],["$","article","2025-12-01-DeepSeekMath-V2-Towards-Self-Verifiable-Mathematical-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-01-DeepSeekMath-V2-Towards-Self-Verifiable-Mathematical-Reasoning","children":"[논문리뷰] DeepSeekMath-V2: Towards Self-Verifiable Mathematical Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-01-DeepSeekMath-V2-Towards-Self-Verifiable-Mathematical-Reasoning","children":"이 [arXiv]에 게시한 'DeepSeekMath-V2: Towards Self-Verifiable Mathematical Reasoning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-01 00:00:00+0900+0900","children":"2025년 12월 1일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-01-DeepSeekMath-V2-Towards-Self-Verifiable-Mathematical-Reasoning"}]]}]]}],["$","article","2025-11-26-SSA-Sparse-Sparse-Attention-by-Aligning-Full-and-Sparse-Attention-Outputs-in-Feature-Space",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-26-SSA-Sparse-Sparse-Attention-by-Aligning-Full-and-Sparse-Attention-Outputs-in-Feature-Space","children":"[논문리뷰] SSA: Sparse Sparse Attention by Aligning Full and Sparse Attention Outputs in Feature Space"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-26-SSA-Sparse-Sparse-Attention-by-Aligning-Full-and-Sparse-Attention-Outputs-in-Feature-Space","children":"Yulan He이 [arXiv]에 게시한 'SSA: Sparse Sparse Attention by Aligning Full and Sparse Attention Outputs in Feature Space' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-26 00:00:00+0900+0900","children":"2025년 11월 26일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-26-SSA-Sparse-Sparse-Attention-by-Aligning-Full-and-Sparse-Attention-Outputs-in-Feature-Space"}]]}]]}],["$","article","2025-11-25-General-Agentic-Memory-Via-Deep-Research",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-25-General-Agentic-Memory-Via-Deep-Research","children":"[논문리뷰] General Agentic Memory Via Deep Research"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-25-General-Agentic-Memory-Via-Deep-Research","children":"이 [arXiv]에 게시한 'General Agentic Memory Via Deep Research' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-25 00:00:00+0900+0900","children":"2025년 11월 25일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-25-General-Agentic-Memory-Via-Deep-Research"}]]}]]}],["$","article","2025-11-24-OmniScientist-Toward-a-Co-evolving-Ecosystem-of-Human-and-AI-Scientists",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-24-OmniScientist-Toward-a-Co-evolving-Ecosystem-of-Human-and-AI-Scientists","children":"[논문리뷰] OmniScientist: Toward a Co-evolving Ecosystem of Human and AI Scientists"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-24-OmniScientist-Toward-a-Co-evolving-Ecosystem-of-Human-and-AI-Scientists","children":"Weiquan Lin이 [arXiv]에 게시한 'OmniScientist: Toward a Co-evolving Ecosystem of Human and AI Scientists' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-24 00:00:00+0900+0900","children":"2025년 11월 24일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-24-OmniScientist-Toward-a-Co-evolving-Ecosystem-of-Human-and-AI-Scientists"}]]}]]}],["$","article","2025-11-19-Large-Language-Models-Meet-Extreme-Multi-label-Classification-Scaling-and-Multi-modal-Framework",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-19-Large-Language-Models-Meet-Extreme-Multi-label-Classification-Scaling-and-Multi-modal-Framework","children":"[논문리뷰] Large Language Models Meet Extreme Multi-label Classification: Scaling and Multi-modal Framework"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-19-Large-Language-Models-Meet-Extreme-Multi-label-Classification-Scaling-and-Multi-modal-Framework","children":"이 [arXiv]에 게시한 'Large Language Models Meet Extreme Multi-label Classification: Scaling and Multi-modal Framework' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-19 00:00:00+0900+0900","children":"2025년 11월 19일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-19-Large-Language-Models-Meet-Extreme-Multi-label-Classification-Scaling-and-Multi-modal-Framework"}]]}]]}],["$","article","2025-11-18-Genomic-Next-Token-Predictors-are-In-Context-Learners",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-18-Genomic-Next-Token-Predictors-are-In-Context-Learners","children":"[논문리뷰] Genomic Next-Token Predictors are In-Context Learners"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-18-Genomic-Next-Token-Predictors-are-In-Context-Learners","children":"이 [arXiv]에 게시한 'Genomic Next-Token Predictors are In-Context Learners' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-18 00:00:00+0900+0900","children":"2025년 11월 18일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-18-Genomic-Next-Token-Predictors-are-In-Context-Learners"}]]}]]}],["$","article","2025-11-14-Black-Box-On-Policy-Distillation-of-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-14-Black-Box-On-Policy-Distillation-of-Large-Language-Models","children":"[논문리뷰] Black-Box On-Policy Distillation of Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-14-Black-Box-On-Policy-Distillation-of-Large-Language-Models","children":"이 [arXiv]에 게시한 'Black-Box On-Policy Distillation of Large Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-14 00:00:00+0900+0900","children":"2025년 11월 14일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-14-Black-Box-On-Policy-Distillation-of-Large-Language-Models"}]]}]]}],["$","article","2025-11-13-MathSE-Improving-Multimodal-Mathematical-Reasoning-via-Self-Evolving-Iterative-Reflection-and-Reward-Guided-Fine-Tuning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-13-MathSE-Improving-Multimodal-Mathematical-Reasoning-via-Self-Evolving-Iterative-Reflection-and-Reward-Guided-Fine-Tuning","children":"[논문리뷰] MathSE: Improving Multimodal Mathematical Reasoning via Self-Evolving Iterative Reflection and Reward-Guided Fine-Tuning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-13-MathSE-Improving-Multimodal-Mathematical-Reasoning-via-Self-Evolving-Iterative-Reflection-and-Reward-Guided-Fine-Tuning","children":"이 [arXiv]에 게시한 'MathSE: Improving Multimodal Mathematical Reasoning via Self-Evolving Iterative Reflection and Reward-Guided Fine-Tuning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-13 00:00:00+0900+0900","children":"2025년 11월 13일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-13-MathSE-Improving-Multimodal-Mathematical-Reasoning-via-Self-Evolving-Iterative-Reflection-and-Reward-Guided-Fine-Tuning"}]]}]]}],["$","article","2025-11-13-LoopTool-Closing-the-Data-Training-Loop-for-Robust-LLM-Tool-Calls",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-13-LoopTool-Closing-the-Data-Training-Loop-for-Robust-LLM-Tool-Calls","children":"[논문리뷰] LoopTool: Closing the Data-Training Loop for Robust LLM Tool Calls"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-13-LoopTool-Closing-the-Data-Training-Loop-for-Robust-LLM-Tool-Calls","children":"이 [arXiv]에 게시한 'LoopTool: Closing the Data-Training Loop for Robust LLM Tool Calls' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-13 00:00:00+0900+0900","children":"2025년 11월 13일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-13-LoopTool-Closing-the-Data-Training-Loop-for-Robust-LLM-Tool-Calls"}]]}]]}],["$","article","2025-11-12-Beyond-Fact-Retrieval-Episodic-Memory-for-RAG-with-Generative-Semantic-Workspaces",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-12-Beyond-Fact-Retrieval-Episodic-Memory-for-RAG-with-Generative-Semantic-Workspaces","children":"[논문리뷰] Beyond Fact Retrieval: Episodic Memory for RAG with Generative Semantic Workspaces"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-12-Beyond-Fact-Retrieval-Episodic-Memory-for-RAG-with-Generative-Semantic-Workspaces","children":"Vwani Roychowdhury이 [arXiv]에 게시한 'Beyond Fact Retrieval: Episodic Memory for RAG with Generative Semantic Workspaces' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-12 00:00:00+0900+0900","children":"2025년 11월 12일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-12-Beyond-Fact-Retrieval-Episodic-Memory-for-RAG-with-Generative-Semantic-Workspaces"}]]}]]}],["$","article","2025-11-11-Routing-Manifold-Alignment-Improves-Generalization-of-Mixture-of-Experts-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-Routing-Manifold-Alignment-Improves-Generalization-of-Mixture-of-Experts-LLMs","children":"[논문리뷰] Routing Manifold Alignment Improves Generalization of Mixture-of-Experts   LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-Routing-Manifold-Alignment-Improves-Generalization-of-Mixture-of-Experts-LLMs","children":"Ziyue Li이 [arXiv]에 게시한 'Routing Manifold Alignment Improves Generalization of Mixture-of-Experts   LLMs' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-11 00:00:00+0900+0900","children":"2025년 11월 11일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-11-Routing-Manifold-Alignment-Improves-Generalization-of-Mixture-of-Experts-LLMs"}]]}]]}],["$","article","2025-11-5-The-Collaboration-Gap",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-5-The-Collaboration-Gap","children":"[논문리뷰] The Collaboration Gap"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-5-The-Collaboration-Gap","children":"이 [arXiv]에 게시한 'The Collaboration Gap' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:35:02+0900","children":"2025년 11월 9일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-5-The-Collaboration-Gap"}]]}]]}],["$","article","2025-11-5-TabDSR-Decompose-Sanitize-and-Reason-for-Complex-Numerical-Reasoning-in-Tabular-Data",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-5-TabDSR-Decompose-Sanitize-and-Reason-for-Complex-Numerical-Reasoning-in-Tabular-Data","children":"[논문리뷰] TabDSR: Decompose, Sanitize, and Reason for Complex Numerical Reasoning in Tabular Data"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-5-TabDSR-Decompose-Sanitize-and-Reason-for-Complex-Numerical-Reasoning-in-Tabular-Data","children":"Jin Zeng이 [arXiv]에 게시한 'TabDSR: Decompose, Sanitize, and Reason for Complex Numerical Reasoning in Tabular Data' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:35:02+0900","children":"2025년 11월 9일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-5-TabDSR-Decompose-Sanitize-and-Reason-for-Complex-Numerical-Reasoning-in-Tabular-Data"}]]}]]}],["$","article","2025-11-5-BRAINS-A-Retrieval-Augmented-System-for-Alzheimers-Detection-and-Monitoring",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-5-BRAINS-A-Retrieval-Augmented-System-for-Alzheimers-Detection-and-Monitoring","children":"[논문리뷰] BRAINS: A Retrieval-Augmented System for Alzheimer's Detection and Monitoring"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-5-BRAINS-A-Retrieval-Augmented-System-for-Alzheimers-Detection-and-Monitoring","children":"이 [arXiv]에 게시한 'BRAINS: A Retrieval-Augmented System for Alzheimer's Detection and Monitoring' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:35:02+0900","children":"2025년 11월 9일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-5-BRAINS-A-Retrieval-Augmented-System-for-Alzheimers-Detection-and-Monitoring"}]]}]]}],["$","article","2025-11-4-Towards-Robust-Mathematical-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-Towards-Robust-Mathematical-Reasoning","children":"[논문리뷰] Towards Robust Mathematical Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-Towards-Robust-Mathematical-Reasoning","children":"Yuri Chervonyi이 [arXiv]에 게시한 'Towards Robust Mathematical Reasoning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:22:42+0900","children":"2025년 11월 9일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-4-Towards-Robust-Mathematical-Reasoning"}]]}]]}],["$","article","2025-11-4-Data-Efficient-RLVR-via-Off-Policy-Influence-Guidance",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-Data-Efficient-RLVR-via-Off-Policy-Influence-Guidance","children":"[논문리뷰] Data-Efficient RLVR via Off-Policy Influence Guidance"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-Data-Efficient-RLVR-via-Off-Policy-Influence-Guidance","children":"Jiale Cheng이 [arXiv]에 게시한 'Data-Efficient RLVR via Off-Policy Influence Guidance' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:22:42+0900","children":"2025년 11월 9일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-4-Data-Efficient-RLVR-via-Off-Policy-Influence-Guidance"}]]}]]}],["$","article","2025-11-3-MisSynth-Improving-MISSCI-Logical-Fallacies-Classification-with-Synthetic-Data",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-3-MisSynth-Improving-MISSCI-Logical-Fallacies-Classification-with-Synthetic-Data","children":"[논문리뷰] MisSynth: Improving MISSCI Logical Fallacies Classification with Synthetic Data"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-3-MisSynth-Improving-MISSCI-Logical-Fallacies-Classification-with-Synthetic-Data","children":"Nadiya Shvai이 [arXiv]에 게시한 'MisSynth: Improving MISSCI Logical Fallacies Classification with Synthetic Data' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:01:31+0900","children":"2025년 11월 9일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-3-MisSynth-Improving-MISSCI-Logical-Fallacies-Classification-with-Synthetic-Data"}]]}]]}],["$","article","2025-11-3-Limits-of-Generalization-in-RLVR-Two-Case-Studies-in-Mathematical-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-3-Limits-of-Generalization-in-RLVR-Two-Case-Studies-in-Mathematical-Reasoning","children":"[논문리뷰] Limits of Generalization in RLVR: Two Case Studies in Mathematical Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-3-Limits-of-Generalization-in-RLVR-Two-Case-Studies-in-Mathematical-Reasoning","children":"Nidhi Rastogi이 [arXiv]에 게시한 'Limits of Generalization in RLVR: Two Case Studies in Mathematical Reasoning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:01:31+0900","children":"2025년 11월 9일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-3-Limits-of-Generalization-in-RLVR-Two-Case-Studies-in-Mathematical-Reasoning"}]]}]]}],["$","article","2025-11-3-INT-v-s-FP-A-Comprehensive-Study-of-Fine-Grained-Low-bit-Quantization-Formats",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-3-INT-v-s-FP-A-Comprehensive-Study-of-Fine-Grained-Low-bit-Quantization-Formats","children":"[논문리뷰] INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-3-INT-v-s-FP-A-Comprehensive-Study-of-Fine-Grained-Low-bit-Quantization-Formats","children":"이 [arXiv]에 게시한 'INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:01:31+0900","children":"2025년 11월 9일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-3-INT-v-s-FP-A-Comprehensive-Study-of-Fine-Grained-Low-bit-Quantization-Formats"}]]}]]}],["$","article","2025-11-3-Continuous-Autoregressive-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-3-Continuous-Autoregressive-Language-Models","children":"[논문리뷰] Continuous Autoregressive Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-3-Continuous-Autoregressive-Language-Models","children":"이 [arXiv]에 게시한 'Continuous Autoregressive Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:01:31+0900","children":"2025년 11월 9일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-3-Continuous-Autoregressive-Language-Models"}]]}]]}],["$","article","2025-10-31-The-End-of-Manual-Decoding-Towards-Truly-End-to-End-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-The-End-of-Manual-Decoding-Towards-Truly-End-to-End-Language-Models","children":"[논문리뷰] The End of Manual Decoding: Towards Truly End-to-End Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-The-End-of-Manual-Decoding-Towards-Truly-End-to-End-Language-Models","children":"이 [arXiv]에 게시한 'The End of Manual Decoding: Towards Truly End-to-End Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-31 18:37:31+0900","children":"2025년 10월 31일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-31-The-End-of-Manual-Decoding-Towards-Truly-End-to-End-Language-Models"}]]}]]}],["$","article","2025-10-31-OmniLayout-Enabling-Coarse-to-Fine-Learning-with-LLMs-for-Universal-Document-Layout-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-OmniLayout-Enabling-Coarse-to-Fine-Learning-with-LLMs-for-Universal-Document-Layout-Generation","children":"[논문리뷰] OmniLayout: Enabling Coarse-to-Fine Learning with LLMs for Universal Document Layout Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-OmniLayout-Enabling-Coarse-to-Fine-Learning-with-LLMs-for-Universal-Document-Layout-Generation","children":"Bin Wang이 [arXiv]에 게시한 'OmniLayout: Enabling Coarse-to-Fine Learning with LLMs for Universal Document Layout Generation' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-31 18:37:31+0900","children":"2025년 10월 31일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-31-OmniLayout-Enabling-Coarse-to-Fine-Learning-with-LLMs-for-Universal-Document-Layout-Generation"}]]}]]}],["$","article","2025-10-31-Magentic-Marketplace-An-Open-Source-Environment-for-Studying-Agentic-Markets",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-Magentic-Marketplace-An-Open-Source-Environment-for-Studying-Agentic-Markets","children":"[논문리뷰] Magentic Marketplace: An Open-Source Environment for Studying Agentic Markets"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-Magentic-Marketplace-An-Open-Source-Environment-for-Studying-Agentic-Markets","children":"이 [arXiv]에 게시한 'Magentic Marketplace: An Open-Source Environment for Studying Agentic Markets' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-31 18:37:31+0900","children":"2025년 10월 31일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-31-Magentic-Marketplace-An-Open-Source-Environment-for-Studying-Agentic-Markets"}]]}]]}],["$","article","2025-10-30-Evolving-Diagnostic-Agents-in-a-Virtual-Clinical-Environment",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-Evolving-Diagnostic-Agents-in-a-Virtual-Clinical-Environment","children":"[논문리뷰] Evolving Diagnostic Agents in a Virtual Clinical Environment"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-Evolving-Diagnostic-Agents-in-a-Virtual-Clinical-Environment","children":"이 [arXiv]에 게시한 'Evolving Diagnostic Agents in a Virtual Clinical Environment' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-30 13:06:06+0900","children":"2025년 10월 30일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-30-Evolving-Diagnostic-Agents-in-a-Virtual-Clinical-Environment"}]]}]]}],["$","article","2025-10-30-ChronoPlay-A-Framework-for-Modeling-Dual-Dynamics-and-Authenticity-in-Game-RAG-Benchmarks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-ChronoPlay-A-Framework-for-Modeling-Dual-Dynamics-and-Authenticity-in-Game-RAG-Benchmarks","children":"[논문리뷰] ChronoPlay: A Framework for Modeling Dual Dynamics and Authenticity in Game RAG Benchmarks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-ChronoPlay-A-Framework-for-Modeling-Dual-Dynamics-and-Authenticity-in-Game-RAG-Benchmarks","children":"이 [arXiv]에 게시한 'ChronoPlay: A Framework for Modeling Dual Dynamics and Authenticity in Game RAG Benchmarks' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-30 13:06:06+0900","children":"2025년 10월 30일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-30-ChronoPlay-A-Framework-for-Modeling-Dual-Dynamics-and-Authenticity-in-Game-RAG-Benchmarks"}]]}]]}],["$","article","2025-10-30-BhashaBench-V1-A-Comprehensive-Benchmark-for-the-Quadrant-of-Indic-Domains",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-BhashaBench-V1-A-Comprehensive-Benchmark-for-the-Quadrant-of-Indic-Domains","children":"[논문리뷰] BhashaBench V1: A Comprehensive Benchmark for the Quadrant of Indic Domains"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-BhashaBench-V1-A-Comprehensive-Benchmark-for-the-Quadrant-of-Indic-Domains","children":"이 [arXiv]에 게시한 'BhashaBench V1: A Comprehensive Benchmark for the Quadrant of Indic Domains' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-30 13:06:06+0900","children":"2025년 10월 30일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-30-BhashaBench-V1-A-Comprehensive-Benchmark-for-the-Quadrant-of-Indic-Domains"}]]}]]}],["$","article","2025-10-29-Generalization-or-Memorization-Dynamic-Decoding-for-Mode-Steering",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-29-Generalization-or-Memorization-Dynamic-Decoding-for-Mode-Steering","children":"[논문리뷰] Generalization or Memorization: Dynamic Decoding for Mode Steering"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-29-Generalization-or-Memorization-Dynamic-Decoding-for-Mode-Steering","children":"이 [arXiv]에 게시한 'Generalization or Memorization: Dynamic Decoding for Mode Steering' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-29 13:11:02+0900","children":"2025년 10월 29일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-29-Generalization-or-Memorization-Dynamic-Decoding-for-Mode-Steering"}]]}]]}],["$","article","2025-10-29-FunReason-MT-Technical-Report-Overcoming-the-Complexity-Barrier-in-Multi-Turn-Function-Calling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-29-FunReason-MT-Technical-Report-Overcoming-the-Complexity-Barrier-in-Multi-Turn-Function-Calling","children":"[논문리뷰] FunReason-MT Technical Report: Overcoming the Complexity Barrier in Multi-Turn Function Calling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-29-FunReason-MT-Technical-Report-Overcoming-the-Complexity-Barrier-in-Multi-Turn-Function-Calling","children":"이 [arXiv]에 게시한 'FunReason-MT Technical Report: Overcoming the Complexity Barrier in Multi-Turn Function Calling' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-29 13:11:02+0900","children":"2025년 10월 29일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-29-FunReason-MT-Technical-Report-Overcoming-the-Complexity-Barrier-in-Multi-Turn-Function-Calling"}]]}]]}],["$","article","2025-10-27-Sparser-Block-Sparse-Attention-via-Token-Permutation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-27-Sparser-Block-Sparse-Attention-via-Token-Permutation","children":"[논문리뷰] Sparser Block-Sparse Attention via Token Permutation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-27-Sparser-Block-Sparse-Attention-via-Token-Permutation","children":"이 [arXiv]에 게시한 'Sparser Block-Sparse Attention via Token Permutation' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-27 13:07:36+0900","children":"2025년 10월 27일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-27-Sparser-Block-Sparse-Attention-via-Token-Permutation"}]]}]]}],["$","article","2025-10-24-ComProScanner-A-multi-agent-based-framework-for-composition-property-structured-data-extraction-from-scientific-literature",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-ComProScanner-A-multi-agent-based-framework-for-composition-property-structured-data-extraction-from-scientific-literature","children":"[논문리뷰] ComProScanner: A multi-agent based framework for composition-property structured data extraction from scientific literature"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-ComProScanner-A-multi-agent-based-framework-for-composition-property-structured-data-extraction-from-scientific-literature","children":"이 [arXiv]에 게시한 'ComProScanner: A multi-agent based framework for composition-property structured data extraction from scientific literature' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-24-ComProScanner-A-multi-agent-based-framework-for-composition-property-structured-data-extraction-from-scientific-literature"}]]}]]}],["$","article","2025-10-23-Learning-from-the-Best-Differently-A-Diversity-Driven-Rethinking-on-Data-Selection",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-Learning-from-the-Best-Differently-A-Diversity-Driven-Rethinking-on-Data-Selection","children":"[논문리뷰] Learning from the Best, Differently: A Diversity-Driven Rethinking on Data Selection"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-Learning-from-the-Best-Differently-A-Diversity-Driven-Rethinking-on-Data-Selection","children":"Yi Cheng이 [arXiv]에 게시한 'Learning from the Best, Differently: A Diversity-Driven Rethinking on Data Selection' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-23-Learning-from-the-Best-Differently-A-Diversity-Driven-Rethinking-on-Data-Selection"}]]}]]}],["$","article","2025-10-23-AlphaOPT-Formulating-Optimization-Programs-with-Self-Improving-LLM-Experience-Library",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-AlphaOPT-Formulating-Optimization-Programs-with-Self-Improving-LLM-Experience-Library","children":"[논문리뷰] AlphaOPT: Formulating Optimization Programs with Self-Improving LLM Experience Library"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-AlphaOPT-Formulating-Optimization-Programs-with-Self-Improving-LLM-Experience-Library","children":"Chonghe Jiang이 [arXiv]에 게시한 'AlphaOPT: Formulating Optimization Programs with Self-Improving LLM Experience Library' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-23-AlphaOPT-Formulating-Optimization-Programs-with-Self-Improving-LLM-Experience-Library"}]]}]]}],["$","article","2025-10-21-Executable-Knowledge-Graphs-for-Replicating-AI-Research",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-Executable-Knowledge-Graphs-for-Replicating-AI-Research","children":"[논문리뷰] Executable Knowledge Graphs for Replicating AI Research"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-Executable-Knowledge-Graphs-for-Replicating-AI-Research","children":"이 [arXiv]에 게시한 'Executable Knowledge Graphs for Replicating AI Research' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-21-Executable-Knowledge-Graphs-for-Replicating-AI-Research"}]]}]]}],["$","article","2025-10-20-Rewiring-Experts-on-the-FlyContinuous-Rerouting-for-Better-Online-Adaptation-in-Mixture-of-Expert-models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-Rewiring-Experts-on-the-FlyContinuous-Rerouting-for-Better-Online-Adaptation-in-Mixture-of-Expert-models","children":"[논문리뷰] Rewiring Experts on the Fly:Continuous Rerouting for Better Online Adaptation in Mixture-of-Expert models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-Rewiring-Experts-on-the-FlyContinuous-Rerouting-for-Better-Online-Adaptation-in-Mixture-of-Expert-models","children":"Shiwei Liu이 [arXiv]에 게시한 'Rewiring Experts on the Fly:Continuous Rerouting for Better Online Adaptation in Mixture-of-Expert models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-20-Rewiring-Experts-on-the-FlyContinuous-Rerouting-for-Better-Online-Adaptation-in-Mixture-of-Expert-models"}]]}]]}],["$","article","2025-10-20-ERGO-Entropy-guided-Resetting-for-Generation-Optimization-in-Multi-turn-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-ERGO-Entropy-guided-Resetting-for-Generation-Optimization-in-Multi-turn-Language-Models","children":"[논문리뷰] ERGO: Entropy-guided Resetting for Generation Optimization in Multi-turn Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-ERGO-Entropy-guided-Resetting-for-Generation-Optimization-in-Multi-turn-Language-Models","children":"Sean O'Brien이 [arXiv]에 게시한 'ERGO: Entropy-guided Resetting for Generation Optimization in Multi-turn Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-20-ERGO-Entropy-guided-Resetting-for-Generation-Optimization-in-Multi-turn-Language-Models"}]]}]]}],["$","article","2025-10-17-MoM-Mixtures-of-Scenario-Aware-Document-Memories-for-Retrieval-Augmented-Generation-Systems",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-MoM-Mixtures-of-Scenario-Aware-Document-Memories-for-Retrieval-Augmented-Generation-Systems","children":"[논문리뷰] MoM: Mixtures of Scenario-Aware Document Memories for Retrieval-Augmented Generation Systems"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-MoM-Mixtures-of-Scenario-Aware-Document-Memories-for-Retrieval-Augmented-Generation-Systems","children":"Feiyu Xiong이 [arXiv]에 게시한 'MoM: Mixtures of Scenario-Aware Document Memories for Retrieval-Augmented Generation Systems' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-17-MoM-Mixtures-of-Scenario-Aware-Document-Memories-for-Retrieval-Augmented-Generation-Systems"}]]}]]}],["$","article","2025-10-16-Stronger-Together-On-Policy-Reinforcement-Learning-for-Collaborative-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-Stronger-Together-On-Policy-Reinforcement-Learning-for-Collaborative-LLMs","children":"[논문리뷰] Stronger Together: On-Policy Reinforcement Learning for Collaborative LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-Stronger-Together-On-Policy-Reinforcement-Learning-for-Collaborative-LLMs","children":"Hao Zhang이 [arXiv]에 게시한 'Stronger Together: On-Policy Reinforcement Learning for Collaborative LLMs' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-16-Stronger-Together-On-Policy-Reinforcement-Learning-for-Collaborative-LLMs"}]]}]]}],["$","article","2025-10-16-Reasoning-in-Space-via-Grounding-in-the-World",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-Reasoning-in-Space-via-Grounding-in-the-World","children":"[논문리뷰] Reasoning in Space via Grounding in the World"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-Reasoning-in-Space-via-Grounding-in-the-World","children":"Li Zhang이 [arXiv]에 게시한 'Reasoning in Space via Grounding in the World' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-16-Reasoning-in-Space-via-Grounding-in-the-World"}]]}]]}],["$","article","2025-10-16-MATH-Beyond-A-Benchmark-for-RL-to-Expand-Beyond-the-Base-Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-MATH-Beyond-A-Benchmark-for-RL-to-Expand-Beyond-the-Base-Model","children":"[논문리뷰] MATH-Beyond: A Benchmark for RL to Expand Beyond the Base Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-MATH-Beyond-A-Benchmark-for-RL-to-Expand-Beyond-the-Base-Model","children":"Wieland Brendel이 [arXiv]에 게시한 'MATH-Beyond: A Benchmark for RL to Expand Beyond the Base Model' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-16-MATH-Beyond-A-Benchmark-for-RL-to-Expand-Beyond-the-Base-Model"}]]}]]}],["$","article","2025-10-15-SAIL-Embedding-Technical-Report-Omni-modal-Embedding-Foundation-Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-SAIL-Embedding-Technical-Report-Omni-modal-Embedding-Foundation-Model","children":"[논문리뷰] SAIL-Embedding Technical Report: Omni-modal Embedding Foundation Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-SAIL-Embedding-Technical-Report-Omni-modal-Embedding-Foundation-Model","children":"이 [arXiv]에 게시한 'SAIL-Embedding Technical Report: Omni-modal Embedding Foundation Model' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-15-SAIL-Embedding-Technical-Report-Omni-modal-Embedding-Foundation-Model"}]]}]]}],["$","article","2025-10-15-LLM-Reasoning-for-Machine-Translation-Synthetic-Data-Generation-over-Thinking-Tokens",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-LLM-Reasoning-for-Machine-Translation-Synthetic-Data-Generation-over-Thinking-Tokens","children":"[논문리뷰] LLM Reasoning for Machine Translation: Synthetic Data Generation over Thinking Tokens"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-LLM-Reasoning-for-Machine-Translation-Synthetic-Data-Generation-over-Thinking-Tokens","children":"이 [arXiv]에 게시한 'LLM Reasoning for Machine Translation: Synthetic Data Generation over Thinking Tokens' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-15-LLM-Reasoning-for-Machine-Translation-Synthetic-Data-Generation-over-Thinking-Tokens"}]]}]]}],["$","article","2025-10-15-DITING-A-Multi-Agent-Evaluation-Framework-for-Benchmarking-Web-Novel-Translation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-DITING-A-Multi-Agent-Evaluation-Framework-for-Benchmarking-Web-Novel-Translation","children":"[논문리뷰] DITING: A Multi-Agent Evaluation Framework for Benchmarking Web Novel Translation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-DITING-A-Multi-Agent-Evaluation-Framework-for-Benchmarking-Web-Novel-Translation","children":"이 [arXiv]에 게시한 'DITING: A Multi-Agent Evaluation Framework for Benchmarking Web Novel Translation' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-15-DITING-A-Multi-Agent-Evaluation-Framework-for-Benchmarking-Web-Novel-Translation"}]]}]]}],["$","article","2025-10-13-Which-Heads-Matter-for-Reasoning-RL-Guided-KV-Cache-Compression",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Which-Heads-Matter-for-Reasoning-RL-Guided-KV-Cache-Compression","children":"[논문리뷰] Which Heads Matter for Reasoning? RL-Guided KV Cache Compression"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Which-Heads-Matter-for-Reasoning-RL-Guided-KV-Cache-Compression","children":"Huan Wang이 [arXiv]에 게시한 'Which Heads Matter for Reasoning? RL-Guided KV Cache Compression' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-13-Which-Heads-Matter-for-Reasoning-RL-Guided-KV-Cache-Compression"}]]}]]}],["$","article","2025-10-13-Webscale-RL-Automated-Data-Pipeline-for-Scaling-RL-Data-to-Pretraining-Levels",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Webscale-RL-Automated-Data-Pipeline-for-Scaling-RL-Data-to-Pretraining-Levels","children":"[논문리뷰] Webscale-RL: Automated Data Pipeline for Scaling RL Data to Pretraining Levels"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Webscale-RL-Automated-Data-Pipeline-for-Scaling-RL-Data-to-Pretraining-Levels","children":"이 [arXiv]에 게시한 'Webscale-RL: Automated Data Pipeline for Scaling RL Data to Pretraining Levels' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-13-Webscale-RL-Automated-Data-Pipeline-for-Scaling-RL-Data-to-Pretraining-Levels"}]]}]]}],["$","article","2025-10-13-Bridging-Reasoning-to-Learning-Unmasking-Illusions-using-Complexity-Out-of-Distribution-Generalization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Bridging-Reasoning-to-Learning-Unmasking-Illusions-using-Complexity-Out-of-Distribution-Generalization","children":"[논문리뷰] Bridging Reasoning to Learning: Unmasking Illusions using Complexity Out of Distribution Generalization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Bridging-Reasoning-to-Learning-Unmasking-Illusions-using-Complexity-Out-of-Distribution-Generalization","children":"Mahdi Ghaznavai이 [arXiv]에 게시한 'Bridging Reasoning to Learning: Unmasking Illusions using Complexity Out of Distribution Generalization' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-13-Bridging-Reasoning-to-Learning-Unmasking-Illusions-using-Complexity-Out-of-Distribution-Generalization"}]]}]]}],["$","article","2025-10-10-Hybrid-Reinforcement-When-Reward-Is-Sparse-Its-Better-to-Be-Dense",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Hybrid-Reinforcement-When-Reward-Is-Sparse-Its-Better-to-Be-Dense","children":"[논문리뷰] Hybrid Reinforcement: When Reward Is Sparse, It's Better to Be Dense"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Hybrid-Reinforcement-When-Reward-Is-Sparse-Its-Better-to-Be-Dense","children":"이 [arXiv]에 게시한 'Hybrid Reinforcement: When Reward Is Sparse, It's Better to Be Dense' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-10-Hybrid-Reinforcement-When-Reward-Is-Sparse-Its-Better-to-Be-Dense"}]]}]]}],["$","article","2025-10-10-First-Try-Matters-Revisiting-the-Role-of-Reflection-in-Reasoning-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-First-Try-Matters-Revisiting-the-Role-of-Reflection-in-Reasoning-Models","children":"[논문리뷰] First Try Matters: Revisiting the Role of Reflection in Reasoning Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-First-Try-Matters-Revisiting-the-Role-of-Reflection-in-Reasoning-Models","children":"Wee Sun Lee이 [arXiv]에 게시한 'First Try Matters: Revisiting the Role of Reflection in Reasoning Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-10-First-Try-Matters-Revisiting-the-Role-of-Reflection-in-Reasoning-Models"}]]}]]}],["$","article","2025-10-9-Native-Hybrid-Attention-for-Efficient-Sequence-Modeling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Native-Hybrid-Attention-for-Efficient-Sequence-Modeling","children":"[논문리뷰] Native Hybrid Attention for Efficient Sequence Modeling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Native-Hybrid-Attention-for-Efficient-Sequence-Modeling","children":"Yu Cheng이 [arXiv]에 게시한 'Native Hybrid Attention for Efficient Sequence Modeling' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-9-Native-Hybrid-Attention-for-Efficient-Sequence-Modeling"}]]}]]}],["$","article","2025-10-9-Multi-Agent-Tool-Integrated-Policy-Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Multi-Agent-Tool-Integrated-Policy-Optimization","children":"[논문리뷰] Multi-Agent Tool-Integrated Policy Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Multi-Agent-Tool-Integrated-Policy-Optimization","children":"Lidong Bing이 [arXiv]에 게시한 'Multi-Agent Tool-Integrated Policy Optimization' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-9-Multi-Agent-Tool-Integrated-Policy-Optimization"}]]}]]}],["$","article","2025-10-9-Cache-to-Cache-Direct-Semantic-Communication-Between-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Cache-to-Cache-Direct-Semantic-Communication-Between-Large-Language-Models","children":"[논문리뷰] Cache-to-Cache: Direct Semantic Communication Between Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Cache-to-Cache-Direct-Semantic-Communication-Between-Large-Language-Models","children":"이 [arXiv]에 게시한 'Cache-to-Cache: Direct Semantic Communication Between Large Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-9-Cache-to-Cache-Direct-Semantic-Communication-Between-Large-Language-Models"}]]}]]}],["$","article","2025-10-8-In-the-Flow-Agentic-System-Optimization-for-Effective-Planning-and-Tool-Use",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-In-the-Flow-Agentic-System-Optimization-for-Effective-Planning-and-Tool-Use","children":"[논문리뷰] In-the-Flow Agentic System Optimization for Effective Planning and Tool Use"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-In-the-Flow-Agentic-System-Optimization-for-Effective-Planning-and-Tool-Use","children":"이 [arXiv]에 게시한 'In-the-Flow Agentic System Optimization for Effective Planning and Tool Use' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-8-In-the-Flow-Agentic-System-Optimization-for-Effective-Planning-and-Tool-Use"}]]}]]}],["$","article","2025-10-7-Reinforce-Ada-An-Adaptive-Sampling-Framework-for-Reinforce-Style-LLM-Training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Reinforce-Ada-An-Adaptive-Sampling-Framework-for-Reinforce-Style-LLM-Training","children":"[논문리뷰] Reinforce-Ada: An Adaptive Sampling Framework for Reinforce-Style LLM Training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Reinforce-Ada-An-Adaptive-Sampling-Framework-for-Reinforce-Style-LLM-Training","children":"이 [arXiv]에 게시한 'Reinforce-Ada: An Adaptive Sampling Framework for Reinforce-Style LLM Training' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-7-Reinforce-Ada-An-Adaptive-Sampling-Framework-for-Reinforce-Style-LLM-Training"}]]}]]}],["$","article","2025-10-6-Scaling-Policy-Compliance-Assessment-in-Language-Models-with-Policy-Reasoning-Traces",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-Scaling-Policy-Compliance-Assessment-in-Language-Models-with-Policy-Reasoning-Traces","children":"[논문리뷰] Scaling Policy Compliance Assessment in Language Models with Policy Reasoning Traces"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-Scaling-Policy-Compliance-Assessment-in-Language-Models-with-Policy-Reasoning-Traces","children":"이 [arXiv]에 게시한 'Scaling Policy Compliance Assessment in Language Models with Policy Reasoning Traces' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-6-Scaling-Policy-Compliance-Assessment-in-Language-Models-with-Policy-Reasoning-Traces"}]]}]]}],["$","article","2025-10-2-Knapsack-RL-Unlocking-Exploration-of-LLMs-via-Optimizing-Budget-Allocation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-Knapsack-RL-Unlocking-Exploration-of-LLMs-via-Optimizing-Budget-Allocation","children":"[논문리뷰] Knapsack RL: Unlocking Exploration of LLMs via Optimizing Budget Allocation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-Knapsack-RL-Unlocking-Exploration-of-LLMs-via-Optimizing-Budget-Allocation","children":"이 [arXiv]에 게시한 'Knapsack RL: Unlocking Exploration of LLMs via Optimizing Budget Allocation' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-2-Knapsack-RL-Unlocking-Exploration-of-LLMs-via-Optimizing-Budget-Allocation"}]]}]]}],["$","article","2025-10-2-DeepSearch-Overcome-the-Bottleneck-of-Reinforcement-Learning-with-Verifiable-Rewards-via-Monte-Carlo-Tree-Search",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-DeepSearch-Overcome-the-Bottleneck-of-Reinforcement-Learning-with-Verifiable-Rewards-via-Monte-Carlo-Tree-Search","children":"[논문리뷰] DeepSearch: Overcome the Bottleneck of Reinforcement Learning with Verifiable Rewards via Monte Carlo Tree Search"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-DeepSearch-Overcome-the-Bottleneck-of-Reinforcement-Learning-with-Verifiable-Rewards-via-Monte-Carlo-Tree-Search","children":"이 [arXiv]에 게시한 'DeepSearch: Overcome the Bottleneck of Reinforcement Learning with Verifiable Rewards via Monte Carlo Tree Search' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-2-DeepSearch-Overcome-the-Bottleneck-of-Reinforcement-Learning-with-Verifiable-Rewards-via-Monte-Carlo-Tree-Search"}]]}]]}],["$","article","2025-10-2-Beyond-Log-Likelihood-Probability-Based-Objectives-for-Supervised-Fine-Tuning-across-the-Model-Capability-Continuum",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-Beyond-Log-Likelihood-Probability-Based-Objectives-for-Supervised-Fine-Tuning-across-the-Model-Capability-Continuum","children":"[논문리뷰] Beyond Log Likelihood: Probability-Based Objectives for Supervised Fine-Tuning across the Model Capability Continuum"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-Beyond-Log-Likelihood-Probability-Based-Objectives-for-Supervised-Fine-Tuning-across-the-Model-Capability-Continuum","children":"Hanghang Tong이 [arXiv]에 게시한 'Beyond Log Likelihood: Probability-Based Objectives for Supervised Fine-Tuning across the Model Capability Continuum' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-2-Beyond-Log-Likelihood-Probability-Based-Objectives-for-Supervised-Fine-Tuning-across-the-Model-Capability-Continuum"}]]}]]}],["$","article","2025-10-1-d2Cache-Accelerating-Diffusion-Based-LLMs-via-Dual-Adaptive-Caching",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-d2Cache-Accelerating-Diffusion-Based-LLMs-via-Dual-Adaptive-Caching","children":"[논문리뷰] d^2Cache: Accelerating Diffusion-Based LLMs via Dual Adaptive Caching"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-d2Cache-Accelerating-Diffusion-Based-LLMs-via-Dual-Adaptive-Caching","children":"Jiarui Wang이 [arXiv]에 게시한 'd^2Cache: Accelerating Diffusion-Based LLMs via Dual Adaptive Caching' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-1-d2Cache-Accelerating-Diffusion-Based-LLMs-via-Dual-Adaptive-Caching"}]]}]]}],["$","article","2025-10-1-OffTopicEval-When-Large-Language-Models-Enter-the-Wrong-Chat-Almost-Always",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-OffTopicEval-When-Large-Language-Models-Enter-the-Wrong-Chat-Almost-Always","children":"[논문리뷰] OffTopicEval: When Large Language Models Enter the Wrong Chat, Almost Always!"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-OffTopicEval-When-Large-Language-Models-Enter-the-Wrong-Chat-Almost-Always","children":"이 [arXiv]에 게시한 'OffTopicEval: When Large Language Models Enter the Wrong Chat, Almost Always!' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-1-OffTopicEval-When-Large-Language-Models-Enter-the-Wrong-Chat-Almost-Always"}]]}]]}],["$","article","2025-9-29-ReviewScore-Misinformed-Peer-Review-Detection-with-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-ReviewScore-Misinformed-Peer-Review-Detection-with-Large-Language-Models","children":"[논문리뷰] ReviewScore: Misinformed Peer Review Detection with Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-ReviewScore-Misinformed-Peer-Review-Detection-with-Large-Language-Models","children":"이 [arXiv]에 게시한 'ReviewScore: Misinformed Peer Review Detection with Large Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-29-ReviewScore-Misinformed-Peer-Review-Detection-with-Large-Language-Models"}]]}]]}],["$","article","2025-9-26-Thinking-While-Listening-Simple-Test-Time-Scaling-For-Audio-Classification",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-Thinking-While-Listening-Simple-Test-Time-Scaling-For-Audio-Classification","children":"[논문리뷰] Thinking While Listening: Simple Test Time Scaling For Audio Classification"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-Thinking-While-Listening-Simple-Test-Time-Scaling-For-Audio-Classification","children":"Mert Pilanci이 [arXiv]에 게시한 'Thinking While Listening: Simple Test Time Scaling For Audio Classification' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-26-Thinking-While-Listening-Simple-Test-Time-Scaling-For-Audio-Classification"}]]}]]}],["$","article","2025-9-26-Thinking-Augmented-Pre-training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-Thinking-Augmented-Pre-training","children":"[논문리뷰] Thinking Augmented Pre-training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-Thinking-Augmented-Pre-training","children":"Furu Wei이 [arXiv]에 게시한 'Thinking Augmented Pre-training' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-26-Thinking-Augmented-Pre-training"}]]}]]}],["$","article","2025-9-23-Analyzing-the-Effects-of-Supervised-Fine-Tuning-on-Model-Knowledge-from-Token-and-Parameter-Levels",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-Analyzing-the-Effects-of-Supervised-Fine-Tuning-on-Model-Knowledge-from-Token-and-Parameter-Levels","children":"[논문리뷰] Analyzing the Effects of Supervised Fine-Tuning on Model Knowledge from Token and Parameter Levels"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-Analyzing-the-Effects-of-Supervised-Fine-Tuning-on-Model-Knowledge-from-Token-and-Parameter-Levels","children":"Qi Zhang이 [arXiv]에 게시한 'Analyzing the Effects of Supervised Fine-Tuning on Model Knowledge from Token and Parameter Levels' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-23-Analyzing-the-Effects-of-Supervised-Fine-Tuning-on-Model-Knowledge-from-Token-and-Parameter-Levels"}]]}]]}],["$","article","2025-9-22-Video2Roleplay-A-Multimodal-Dataset-and-Framework-for-Video-Guided-Role-playing-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-22-Video2Roleplay-A-Multimodal-Dataset-and-Framework-for-Video-Guided-Role-playing-Agents","children":"[논문리뷰] Video2Roleplay: A Multimodal Dataset and Framework for Video-Guided Role-playing Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-22-Video2Roleplay-A-Multimodal-Dataset-and-Framework-for-Video-Guided-Role-playing-Agents","children":"Chao Zhang이 [arXiv]에 게시한 'Video2Roleplay: A Multimodal Dataset and Framework for Video-Guided Role-playing Agents' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-22 13:11:29+0900","children":"2025년 9월 22일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-22-Video2Roleplay-A-Multimodal-Dataset-and-Framework-for-Video-Guided-Role-playing-Agents"}]]}]]}],["$","article","2025-9-18-MARS2-2025-Challenge-on-Multimodal-Reasoning-Datasets-Methods-Results-Discussion-and-Outlook",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-18-MARS2-2025-Challenge-on-Multimodal-Reasoning-Datasets-Methods-Results-Discussion-and-Outlook","children":"[논문리뷰] MARS2 2025 Challenge on Multimodal Reasoning: Datasets, Methods, Results, Discussion, and Outlook"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-18-MARS2-2025-Challenge-on-Multimodal-Reasoning-Datasets-Methods-Results-Discussion-and-Outlook","children":"Bowen Zhou이 [arXiv]에 게시한 'MARS2 2025 Challenge on Multimodal Reasoning: Datasets, Methods, Results, Discussion, and Outlook' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-18 13:07:00+0900","children":"2025년 9월 18일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-18-MARS2-2025-Challenge-on-Multimodal-Reasoning-Datasets-Methods-Results-Discussion-and-Outlook"}]]}]]}],["$","article","2025-9-18-Improving-Context-Fidelity-via-Native-Retrieval-Augmented-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-18-Improving-Context-Fidelity-via-Native-Retrieval-Augmented-Reasoning","children":"[논문리뷰] Improving Context Fidelity via Native Retrieval-Augmented Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-18-Improving-Context-Fidelity-via-Native-Retrieval-Augmented-Reasoning","children":"Xiangru Tang이 [arXiv]에 게시한 'Improving Context Fidelity via Native Retrieval-Augmented Reasoning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-18 13:07:00+0900","children":"2025년 9월 18일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-18-Improving-Context-Fidelity-via-Native-Retrieval-Augmented-Reasoning"}]]}]]}],["$","article","2025-9-12-The-Choice-of-Divergence-A-Neglected-Key-to-Mitigating-Diversity-Collapse-in-Reinforcement-Learning-with-Verifiable-Reward",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-12-The-Choice-of-Divergence-A-Neglected-Key-to-Mitigating-Diversity-Collapse-in-Reinforcement-Learning-with-Verifiable-Reward","children":"[논문리뷰] The Choice of Divergence: A Neglected Key to Mitigating Diversity Collapse in Reinforcement Learning with Verifiable Reward"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-12-The-Choice-of-Divergence-A-Neglected-Key-to-Mitigating-Diversity-Collapse-in-Reinforcement-Learning-with-Verifiable-Reward","children":"Xiaoyu Tan이 [arXiv]에 게시한 'The Choice of Divergence: A Neglected Key to Mitigating Diversity Collapse in Reinforcement Learning with Verifiable Reward' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-12 13:12:46+0900","children":"2025년 9월 12일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-12-The-Choice-of-Divergence-A-Neglected-Key-to-Mitigating-Diversity-Collapse-in-Reinforcement-Learning-with-Verifiable-Reward"}]]}]]}],["$","article","2025-9-9-WebExplorer-Explore-and-Evolve-for-Training-Long-Horizon-Web-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-WebExplorer-Explore-and-Evolve-for-Training-Long-Horizon-Web-Agents","children":"[논문리뷰] WebExplorer: Explore and Evolve for Training Long-Horizon Web Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-WebExplorer-Explore-and-Evolve-for-Training-Long-Horizon-Web-Agents","children":"Aili Chen이 [arXiv]에 게시한 'WebExplorer: Explore and Evolve for Training Long-Horizon Web Agents' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-9-WebExplorer-Explore-and-Evolve-for-Training-Long-Horizon-Web-Agents"}]]}]]}],["$","article","2025-9-8-Bootstrapping-Task-Spaces-for-Self-Improvement",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-8-Bootstrapping-Task-Spaces-for-Self-Improvement","children":"[논문리뷰] Bootstrapping Task Spaces for Self-Improvement"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-8-Bootstrapping-Task-Spaces-for-Self-Improvement","children":"Yoram Bachrach이 [arXiv]에 게시한 'Bootstrapping Task Spaces for Self-Improvement' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-08 13:10:18+0900","children":"2025년 9월 8일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-8-Bootstrapping-Task-Spaces-for-Self-Improvement"}]]}]]}],["$","article","2025-9-5-Towards-a-Unified-View-of-Large-Language-Model-Post-Training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-5-Towards-a-Unified-View-of-Large-Language-Model-Post-Training","children":"[논문리뷰] Towards a Unified View of Large Language Model Post-Training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-5-Towards-a-Unified-View-of-Large-Language-Model-Post-Training","children":"Hongyi Liu이 [arXiv]에 게시한 'Towards a Unified View of Large Language Model Post-Training' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-05 13:07:20+0900","children":"2025년 9월 5일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-5-Towards-a-Unified-View-of-Large-Language-Model-Post-Training"}]]}]]}],["$","article","2025-9-5-NER-Retriever-Zero-Shot-Named-Entity-Retrieval-with-Type-Aware-Embeddings",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-5-NER-Retriever-Zero-Shot-Named-Entity-Retrieval-with-Type-Aware-Embeddings","children":"[논문리뷰] NER Retriever: Zero-Shot Named Entity Retrieval with Type-Aware Embeddings"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-5-NER-Retriever-Zero-Shot-Named-Entity-Retrieval-with-Type-Aware-Embeddings","children":"Oren Glickman이 [arXiv]에 게시한 'NER Retriever: Zero-Shot Named Entity Retrieval with Type-Aware Embeddings' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-05 13:07:20+0900","children":"2025년 9월 5일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-5-NER-Retriever-Zero-Shot-Named-Entity-Retrieval-with-Type-Aware-Embeddings"}]]}]]}],["$","article","2025-9-3-Attributes-as-Textual-Genes-Leveraging-LLMs-as-Genetic-Algorithm-Simulators-for-Conditional-Synthetic-Data-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-Attributes-as-Textual-Genes-Leveraging-LLMs-as-Genetic-Algorithm-Simulators-for-Conditional-Synthetic-Data-Generation","children":"[논문리뷰] Attributes as Textual Genes: Leveraging LLMs as Genetic Algorithm Simulators for Conditional Synthetic Data Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-Attributes-as-Textual-Genes-Leveraging-LLMs-as-Genetic-Algorithm-Simulators-for-Conditional-Synthetic-Data-Generation","children":"Xiaolei Huang이 [arXiv]에 게시한 'Attributes as Textual Genes: Leveraging LLMs as Genetic Algorithm Simulators for Conditional Synthetic Data Generation' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-3-Attributes-as-Textual-Genes-Leveraging-LLMs-as-Genetic-Algorithm-Simulators-for-Conditional-Synthetic-Data-Generation"}]]}]]}],["$","article","2025-9-2-T2R-bench-A-Benchmark-for-Generating-Article-Level-Reports-from-Real-World-Industrial-Tables",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-2-T2R-bench-A-Benchmark-for-Generating-Article-Level-Reports-from-Real-World-Industrial-Tables","children":"[논문리뷰] T2R-bench: A Benchmark for Generating Article-Level Reports from Real World Industrial Tables"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-2-T2R-bench-A-Benchmark-for-Generating-Article-Level-Reports-from-Real-World-Industrial-Tables","children":"Yu Zhao이 [arXiv]에 게시한 'T2R-bench: A Benchmark for Generating Article-Level Reports from Real World Industrial Tables' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-02 13:01:41+0900","children":"2025년 9월 2일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-2-T2R-bench-A-Benchmark-for-Generating-Article-Level-Reports-from-Real-World-Industrial-Tables"}]]}]]}],["$","article","2025-9-2-PVPO-Pre-Estimated-Value-Based-Policy-Optimization-for-Agentic-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-2-PVPO-Pre-Estimated-Value-Based-Policy-Optimization-for-Agentic-Reasoning","children":"[논문리뷰] PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-2-PVPO-Pre-Estimated-Value-Based-Policy-Optimization-for-Agentic-Reasoning","children":"Yuewei Zhang이 [arXiv]에 게시한 'PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic Reasoning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-02 13:01:41+0900","children":"2025년 9월 2일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-2-PVPO-Pre-Estimated-Value-Based-Policy-Optimization-for-Agentic-Reasoning"}]]}]]}],["$","article","2025-8-29-Persuasion-Dynamics-in-LLMs-Investigating-Robustness-and-Adaptability-in-Knowledge-and-Safety-with-DuET-PD",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-Persuasion-Dynamics-in-LLMs-Investigating-Robustness-and-Adaptability-in-Knowledge-and-Safety-with-DuET-PD","children":"[논문리뷰] Persuasion Dynamics in LLMs: Investigating Robustness and Adaptability in Knowledge and Safety with DuET-PD"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-Persuasion-Dynamics-in-LLMs-Investigating-Robustness-and-Adaptability-in-Knowledge-and-Safety-with-DuET-PD","children":"Roy Ka-Wei Lee이 [arXiv]에 게시한 'Persuasion Dynamics in LLMs: Investigating Robustness and Adaptability in Knowledge and Safety with DuET-PD' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-29-Persuasion-Dynamics-in-LLMs-Investigating-Robustness-and-Adaptability-in-Knowledge-and-Safety-with-DuET-PD"}]]}]]}],["$","article","2025-8-29-OnGoal-Tracking-and-Visualizing-Conversational-Goals-in-Multi-Turn-Dialogue-with-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-OnGoal-Tracking-and-Visualizing-Conversational-Goals-in-Multi-Turn-Dialogue-with-Large-Language-Models","children":"[논문리뷰] OnGoal: Tracking and Visualizing Conversational Goals in Multi-Turn Dialogue with Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-OnGoal-Tracking-and-Visualizing-Conversational-Goals-in-Multi-Turn-Dialogue-with-Large-Language-Models","children":"Alex Endert이 [arXiv]에 게시한 'OnGoal: Tracking and Visualizing Conversational Goals in Multi-Turn Dialogue with Large Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-29-OnGoal-Tracking-and-Visualizing-Conversational-Goals-in-Multi-Turn-Dialogue-with-Large-Language-Models"}]]}]]}],["$","article","2025-8-27-Spacer-Towards-Engineered-Scientific-Inspiration",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-Spacer-Towards-Engineered-Scientific-Inspiration","children":"[논문리뷰] Spacer: Towards Engineered Scientific Inspiration"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-Spacer-Towards-Engineered-Scientific-Inspiration","children":"zerojun48이 [arXiv]에 게시한 'Spacer: Towards Engineered Scientific Inspiration' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-27-Spacer-Towards-Engineered-Scientific-Inspiration"}]]}]]}],["$","article","2025-8-22-LiveMCP-101-Stress-Testing-and-Diagnosing-MCP-enabled-Agents-on-Challenging-Queries",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-22-LiveMCP-101-Stress-Testing-and-Diagnosing-MCP-enabled-Agents-on-Challenging-Queries","children":"[논문리뷰] LiveMCP-101: Stress Testing and Diagnosing MCP-enabled Agents on Challenging Queries"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-22-LiveMCP-101-Stress-Testing-and-Diagnosing-MCP-enabled-Agents-on-Challenging-Queries","children":"huuuyeah이 [arXiv]에 게시한 'LiveMCP-101: Stress Testing and Diagnosing MCP-enabled Agents on Challenging Queries' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-22 13:10:52+0900","children":"2025년 8월 22일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-22-LiveMCP-101-Stress-Testing-and-Diagnosing-MCP-enabled-Agents-on-Challenging-Queries"}]]}]]}],["$","article","2025-8-20-Leveraging-Large-Language-Models-for-Predictive-Analysis-of-Human-Misery",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-Leveraging-Large-Language-Models-for-Predictive-Analysis-of-Human-Misery","children":"[논문리뷰] Leveraging Large Language Models for Predictive Analysis of Human Misery"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-Leveraging-Large-Language-Models-for-Predictive-Analysis-of-Human-Misery","children":"Abhilash Nandy이 [arXiv]에 게시한 'Leveraging Large Language Models for Predictive Analysis of Human Misery' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-20-Leveraging-Large-Language-Models-for-Predictive-Analysis-of-Human-Misery"}]]}]]}],["$","article","2025-8-13-TopXGen-Topic-Diverse-Parallel-Data-Generation-for-Low-Resource-Machine-Translation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-TopXGen-Topic-Diverse-Parallel-Data-Generation-for-Low-Resource-Machine-Translation","children":"[논문리뷰] TopXGen: Topic-Diverse Parallel Data Generation for Low-Resource Machine Translation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-TopXGen-Topic-Diverse-Parallel-Data-Generation-for-Low-Resource-Machine-Translation","children":"Rachel Bawden이 [arXiv]에 게시한 'TopXGen: Topic-Diverse Parallel Data Generation for Low-Resource Machine Translation' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-13-TopXGen-Topic-Diverse-Parallel-Data-Generation-for-Low-Resource-Machine-Translation"}]]}]]}],["$","article","2025-8-13-GeRe-Towards-Efficient-Anti-Forgetting-in-Continual-Learning-of-LLM-via-General-Samples-Replay",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-GeRe-Towards-Efficient-Anti-Forgetting-in-Continual-Learning-of-LLM-via-General-Samples-Replay","children":"[논문리뷰] GeRe: Towards Efficient Anti-Forgetting in Continual Learning of LLM via General Samples Replay"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-GeRe-Towards-Efficient-Anti-Forgetting-in-Continual-Learning-of-LLM-via-General-Samples-Replay","children":"Yang Fan이 [arXiv]에 게시한 'GeRe: Towards Efficient Anti-Forgetting in Continual Learning of LLM via General Samples Replay' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-13-GeRe-Towards-Efficient-Anti-Forgetting-in-Continual-Learning-of-LLM-via-General-Samples-Replay"}]]}]]}],["$","article","2025-8-13-Feedback-Driven-Tool-Use-Improvements-in-Large-Language-Models-via-Automated-Build-Environments",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-Feedback-Driven-Tool-Use-Improvements-in-Large-Language-Models-via-Automated-Build-Environments","children":"[논문리뷰] Feedback-Driven Tool-Use Improvements in Large Language Models via Automated Build Environments"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-Feedback-Driven-Tool-Use-Improvements-in-Large-Language-Models-via-Automated-Build-Environments","children":"Xuesong Yao이 [arXiv]에 게시한 'Feedback-Driven Tool-Use Improvements in Large Language Models via Automated Build Environments' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-13-Feedback-Driven-Tool-Use-Improvements-in-Large-Language-Models-via-Automated-Build-Environments"}]]}]]}],["$","article","2025-8-6-Tool-integrated-Reinforcement-Learning-for-Repo-Deep-Search",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-6-Tool-integrated-Reinforcement-Learning-for-Repo-Deep-Search","children":"[논문리뷰] Tool-integrated Reinforcement Learning for Repo Deep Search"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-6-Tool-integrated-Reinforcement-Learning-for-Repo-Deep-Search","children":"Yanzhen Zou이 [arXiv]에 게시한 'Tool-integrated Reinforcement Learning for Repo Deep Search' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-06 13:46:36+0900","children":"2025년 8월 6일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-6-Tool-integrated-Reinforcement-Learning-for-Repo-Deep-Search"}]]}]]}],["$","article","2025-8-3-RecGPT-Technical-Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-RecGPT-Technical-Report","children":"[논문리뷰] RecGPT Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-RecGPT-Technical-Report","children":"Jian Wu이 [arXiv]에 게시한 'RecGPT Technical Report' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-03 07:35:17+0900","children":"2025년 8월 3일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-3-RecGPT-Technical-Report"}]]}]]}],["$","article","2025-8-3-Persona-Vectors-Monitoring-and-Controlling-Character-Traits-in-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-Persona-Vectors-Monitoring-and-Controlling-Character-Traits-in-Language-Models","children":"[논문리뷰] Persona Vectors: Monitoring and Controlling Character Traits in Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-Persona-Vectors-Monitoring-and-Controlling-Character-Traits-in-Language-Models","children":"Jack Lindsey이 [arXiv]에 게시한 'Persona Vectors: Monitoring and Controlling Character Traits in Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-03 07:35:17+0900","children":"2025년 8월 3일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-3-Persona-Vectors-Monitoring-and-Controlling-Character-Traits-in-Language-Models"}]]}]]}]]}]]}]]}]}]]}]],null],null]},["$","$L5",null,{"parallelRouterKey":"children","segmentPath":["children","tags","children","$6","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L7",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},["$","$L5",null,{"parallelRouterKey":"children","segmentPath":["children","tags","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L7",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},[["$","html",null,{"lang":"ko","className":"no-js","children":[["$","head",null,{"children":[["$","meta",null,{"name":"msapplication-TileColor","content":"#ffc40d"}],["$","meta",null,{"name":"theme-color","content":"#ffffff"}],["$","link",null,{"rel":"dns-prefetch","href":"https://www.googletagmanager.com"}],["$","link",null,{"rel":"preconnect","href":"https://www.googletagmanager.com","crossOrigin":"anonymous"}],["$","link",null,{"rel":"dns-prefetch","href":"https://giscus.app"}],["$","link",null,{"rel":"preconnect","href":"https://giscus.app","crossOrigin":"anonymous"}],["$","meta",null,{"httpEquiv":"X-Content-Type-Options","content":"nosniff"}],["$","meta",null,{"name":"referrer","content":"strict-origin-when-cross-origin"}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"WebSite\",\"name\":\"secrett2633's blog\",\"url\":\"https://blog.secrett2633.cloud\",\"description\":\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\",\"inLanguage\":\"ko\",\"publisher\":{\"@type\":\"Person\",\"name\":\"secrett2633\",\"url\":\"https://blog.secrett2633.cloud\"}}"}}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"Person\",\"name\":\"secrett2633\",\"url\":\"https://blog.secrett2633.cloud\",\"sameAs\":[\"https://github.com/secrett2633\"]}"}}]]}],["$","body",null,{"className":"__className_f367f3 layout--default","children":[["$","a",null,{"href":"#main-content","className":"sr-only focus:not-sr-only focus:absolute focus:z-50 focus:p-4 focus:bg-white focus:text-blue-600","children":"본문으로 건너뛰기"}],["$","div",null,{"className":"min-h-screen bg-gray-50","children":[["$","$L8",null,{}],["$","main",null,{"id":"main-content","className":"initial-content","children":["$","$L5",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L7",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","div",null,{"className":"min-h-screen flex items-center justify-center bg-gray-50","children":["$","div",null,{"className":"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center","children":[["$","h1",null,{"className":"text-6xl font-bold text-primary-600 mb-4","children":"404"}],["$","h2",null,{"className":"text-2xl font-semibold text-gray-900 mb-4","children":"페이지를 찾을 수 없습니다"}],["$","p",null,{"className":"text-gray-600 mb-8","children":"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다."}],["$","$L3",null,{"href":"/","className":"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors","children":"홈으로 돌아가기"}]]}]}],"notFoundStyles":[],"styles":null}]}],["$","div",null,{"id":"footer","className":"page__footer","children":["$","footer",null,{"className":"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8","children":["$","div",null,{"className":"text-center text-gray-500 text-sm","children":["$","p",null,{"children":["© ",2026," secrett2633. All rights reserved."]}]}]}]}]]}],["$","$L9",null,{"src":"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY","strategy":"afterInteractive"}],["$","$L9",null,{"id":"gtag-init","strategy":"afterInteractive","children":"window.dataLayer = window.dataLayer || [];\n            function gtag(){dataLayer.push(arguments);}\n            gtag('js', new Date());\n            gtag('config', 'G-NE2W3CFPNY');"}]]}]]}],null],[["$","div",null,{"className":"flex items-center justify-center min-h-screen","role":"status","aria-label":"로딩 중","children":[["$","div",null,{"className":"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600"}],["$","span",null,{"className":"sr-only","children":"로딩 중..."}]]}],[],[]]],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/ddc331716d5e47a2.css","precedence":"next","crossOrigin":"$undefined"}]],[null,"$La"]]]]]
a:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"#Large Language Models (LLMs) - secrett2633's blog"}],["$","meta","3",{"name":"description","content":"Large Language Models (LLMs) 태그가 포함된 포스트 목록"}],["$","meta","4",{"name":"author","content":"secrett2633"}],["$","link","5",{"rel":"manifest","href":"/manifest.json","crossOrigin":"use-credentials"}],["$","meta","6",{"name":"keywords","content":"Django, Python, DevOps, AI, ML, 블로그, 기술"}],["$","meta","7",{"name":"creator","content":"secrett2633"}],["$","meta","8",{"name":"publisher","content":"secrett2633"}],["$","meta","9",{"name":"robots","content":"index, follow"}],["$","meta","10",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","11",{"rel":"canonical","href":"https://blog.secrett2633.cloud/tags/Large%20Language%20Models%20(LLMs)"}],["$","meta","12",{"name":"format-detection","content":"telephone=no, address=no, email=no"}],["$","meta","13",{"property":"og:title","content":"#Large Language Models (LLMs) - secrett2633's blog"}],["$","meta","14",{"property":"og:description","content":"Large Language Models (LLMs) 태그가 포함된 포스트 목록"}],["$","meta","15",{"property":"og:url","content":"https://blog.secrett2633.cloud/tags/Large%20Language%20Models%20(LLMs)"}],["$","meta","16",{"property":"og:type","content":"website"}],["$","meta","17",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","18",{"name":"twitter:title","content":"#Large Language Models (LLMs) - secrett2633's blog"}],["$","meta","19",{"name":"twitter:description","content":"Large Language Models (LLMs) 태그가 포함된 포스트 목록"}],["$","link","20",{"rel":"icon","href":"/icon.ico?6d9f34d4948640b8","type":"image/x-icon","sizes":"16x16"}],["$","meta","21",{"name":"next-size-adjust"}]]
1:null
