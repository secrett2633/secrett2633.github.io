2:I[9038,["231","static/chunks/231-467e37449c5a68fc.js","605","static/chunks/app/tags/%5Btag%5D/page-d13158d00abd62a4.js"],"default"]
3:I[231,["231","static/chunks/231-467e37449c5a68fc.js","605","static/chunks/app/tags/%5Btag%5D/page-d13158d00abd62a4.js"],""]
4:I[227,["231","static/chunks/231-467e37449c5a68fc.js","605","static/chunks/app/tags/%5Btag%5D/page-d13158d00abd62a4.js"],"default"]
5:I[9275,[],""]
7:I[1343,[],""]
8:I[9157,["231","static/chunks/231-467e37449c5a68fc.js","185","static/chunks/app/layout-b0a450f8e4964582.js"],"default"]
9:I[4080,["231","static/chunks/231-467e37449c5a68fc.js","185","static/chunks/app/layout-b0a450f8e4964582.js"],""]
6:["tag","Large%20Language%20Models","d"]
0:["WcxaIiCPz9cbpnkGvOjOK",[[["",{"children":["tags",{"children":[["tag","Large%20Language%20Models","d"],{"children":["__PAGE__?{\"tag\":\"Large Language Models\"}",{}]}]}]},"$undefined","$undefined",true],["",{"children":["tags",{"children":[["tag","Large%20Language%20Models","d"],{"children":["__PAGE__",{},[["$L1",["$","$L2",null,{"children":[["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"CollectionPage\",\"name\":\"#Large Language Models - secrett2633's blog\",\"description\":\"Large Language Models 태그가 포함된 포스트 목록\",\"url\":\"https://blog.secrett2633.cloud/tags/Large%20Language%20Models\",\"isPartOf\":{\"@type\":\"WebSite\",\"name\":\"secrett2633's blog\",\"url\":\"https://blog.secrett2633.cloud\"},\"inLanguage\":\"ko\"}"}}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"BreadcrumbList\",\"itemListElement\":[{\"@type\":\"ListItem\",\"position\":1,\"name\":\"홈\",\"item\":\"https://blog.secrett2633.cloud/\"},{\"@type\":\"ListItem\",\"position\":2,\"name\":\"#Large Language Models\",\"item\":\"https://blog.secrett2633.cloud/tags/Large%20Language%20Models\"}]}"}}],["$","div",null,{"className":"space-y-6","children":["$","div",null,{"className":"flex flex-col lg:flex-row gap-8","children":[["$","aside",null,{"className":"lg:w-64 xl:w-72 order-1 lg:order-none","children":["$","div",null,{"className":"sidebar sticky","children":["$","nav",null,{"className":"space-y-4","aria-label":"카테고리 네비게이션","children":[["$","div","Backend",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"Backend"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Django",{"children":["$","$L3",null,{"href":"/backend/django","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Django"," (",6,")"]}]}],["$","li","Logging",{"children":["$","$L3",null,{"href":"/backend/logging","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Logging"," (",1,")"]}]}]]}]]}],["$","div","Python",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"Python"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","PEP",{"children":["$","$L3",null,{"href":"/python/pep","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["PEP"," (",650,")"]}]}]]}]]}],["$","div","AI/ML",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"AI/ML"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","LLM",{"children":["$","$L3",null,{"href":"/ai/llm","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["LLM"," (",1,")"]}]}],["$","li","Review",{"children":["$","$L3",null,{"href":"/ai/review","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Review"," (",2728,")"]}]}]]}]]}],["$","div","DevOps",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"DevOps"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Nginx",{"children":["$","$L3",null,{"href":"/devops/nginx","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Nginx"," (",1,")"]}]}],["$","li","Docker",{"children":["$","$L3",null,{"href":"/devops/docker","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Docker"," (",1,")"]}]}],["$","li","SafeLine",{"children":["$","$L3",null,{"href":"/devops/safeline","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["SafeLine"," (",1,")"]}]}],["$","li","Jenkins",{"children":["$","$L3",null,{"href":"/devops/jenkins","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Jenkins"," (",3,")"]}]}],["$","li","GitHub Actions",{"children":["$","$L3",null,{"href":"/devops/github-actions","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["GitHub Actions"," (",1,")"]}]}],["$","li","AWS",{"children":["$","$L3",null,{"href":"/devops/aws","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["AWS"," (",1,")"]}]}]]}]]}],["$","div","etc",{"children":[["$","p",null,{"className":"font-medium text-gray-900 mb-2","children":"etc"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Me",{"children":["$","$L3",null,{"href":"/etc/me","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Me"," (",3,")"]}]}],["$","li","Chrome Extension",{"children":["$","$L3",null,{"href":"/etc/chrome-extension","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Chrome Extension"," (",1,")"]}]}]]}]]}]]}]}]}],["$","div",null,{"className":"flex-1","children":[["$","nav",null,{"aria-label":"breadcrumb","className":"text-sm text-gray-500 mb-4","children":["$","ol",null,{"className":"flex flex-wrap items-center gap-1","children":[["$","li",null,{"children":["$","$L3",null,{"href":"/","className":"hover:text-gray-700","children":"홈"}]}],[["$","li","/tags/Large%20Language%20Models",{"className":"flex items-center gap-1","children":[["$","span",null,{"aria-hidden":"true","children":"/"}],["$","span",null,{"className":"text-gray-900","aria-current":"page","children":"#Large Language Models"}]]}]]]}]}],["$","h1",null,{"className":"page__title mb-6","children":["#","Large Language Models"]}],["$","p",null,{"className":"text-gray-500 mb-6","children":[319,"개의 포스트"]}],["$","div",null,{"className":"entries-list","children":[["$","article","2026-02-18-STAPO-Stabilizing-Reinforcement-Learning-for-LLMs-by-Silencing-Rare-Spurious-Tokens",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-18-STAPO-Stabilizing-Reinforcement-Learning-for-LLMs-by-Silencing-Rare-Spurious-Tokens","children":"[논문리뷰] STAPO: Stabilizing Reinforcement Learning for LLMs by Silencing Rare Spurious Tokens"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-18-STAPO-Stabilizing-Reinforcement-Learning-for-LLMs-by-Silencing-Rare-Spurious-Tokens","children":"Zhilong Zheng이 [arXiv]에 게시한 'STAPO: Stabilizing Reinforcement Learning for LLMs by Silencing Rare Spurious Tokens' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-18 00:00:00+0900+0900","children":"2026년 2월 18일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-18-STAPO-Stabilizing-Reinforcement-Learning-for-LLMs-by-Silencing-Rare-Spurious-Tokens"}]]}]]}],["$","article","2026-02-17-Query-as-Anchor-Scenario-Adaptive-User-Representation-via-Large-Language-Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-17-Query-as-Anchor-Scenario-Adaptive-User-Representation-via-Large-Language-Model","children":"[논문리뷰] Query as Anchor: Scenario-Adaptive User Representation via Large Language Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-17-Query-as-Anchor-Scenario-Adaptive-User-Representation-via-Large-Language-Model","children":"이 [arXiv]에 게시한 'Query as Anchor: Scenario-Adaptive User Representation via Large Language Model' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-17 00:00:00+0900+0900","children":"2026년 2월 17일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-17-Query-as-Anchor-Scenario-Adaptive-User-Representation-via-Large-Language-Model"}]]}]]}],["$","article","2026-02-17-Exposing-the-Systematic-Vulnerability-of-Open-Weight-Models-to-Prefill-Attacks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-17-Exposing-the-Systematic-Vulnerability-of-Open-Weight-Models-to-Prefill-Attacks","children":"[논문리뷰] Exposing the Systematic Vulnerability of Open-Weight Models to Prefill Attacks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-17-Exposing-the-Systematic-Vulnerability-of-Open-Weight-Models-to-Prefill-Attacks","children":"이 [arXiv]에 게시한 'Exposing the Systematic Vulnerability of Open-Weight Models to Prefill Attacks' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-17 00:00:00+0900+0900","children":"2026년 2월 17일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-17-Exposing-the-Systematic-Vulnerability-of-Open-Weight-Models-to-Prefill-Attacks"}]]}]]}],["$","article","2026-02-17-Benchmarking-Knowledge-Extraction-Attack-and-Defense-on-Retrieval-Augmented-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-17-Benchmarking-Knowledge-Extraction-Attack-and-Defense-on-Retrieval-Augmented-Generation","children":"[논문리뷰] Benchmarking Knowledge-Extraction Attack and Defense on Retrieval-Augmented Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-17-Benchmarking-Knowledge-Extraction-Attack-and-Defense-on-Retrieval-Augmented-Generation","children":"Ryan Rossi이 [arXiv]에 게시한 'Benchmarking Knowledge-Extraction Attack and Defense on Retrieval-Augmented Generation' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-17 00:00:00+0900+0900","children":"2026년 2월 17일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-17-Benchmarking-Knowledge-Extraction-Attack-and-Defense-on-Retrieval-Augmented-Generation"}]]}]]}],["$","article","2026-02-17-AIDev-Studying-AI-Coding-Agents-on-GitHub",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-17-AIDev-Studying-AI-Coding-Agents-on-GitHub","children":"[논문리뷰] AIDev: Studying AI Coding Agents on GitHub"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-17-AIDev-Studying-AI-Coding-Agents-on-GitHub","children":"Ahmed E. Hassan이 [arXiv]에 게시한 'AIDev: Studying AI Coding Agents on GitHub' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-17 00:00:00+0900+0900","children":"2026년 2월 17일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-17-AIDev-Studying-AI-Coding-Agents-on-GitHub"}]]}]]}],["$","article","2026-02-16-BPDQ-Bit-Plane-Decomposition-Quantization-on-a-Variable-Grid-for-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-16-BPDQ-Bit-Plane-Decomposition-Quantization-on-a-Variable-Grid-for-Large-Language-Models","children":"[논문리뷰] BPDQ: Bit-Plane Decomposition Quantization on a Variable Grid for Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-16-BPDQ-Bit-Plane-Decomposition-Quantization-on-a-Variable-Grid-for-Large-Language-Models","children":"이 [arXiv]에 게시한 'BPDQ: Bit-Plane Decomposition Quantization on a Variable Grid for Large Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-16 00:00:00+0900+0900","children":"2026년 2월 16일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-16-BPDQ-Bit-Plane-Decomposition-Quantization-on-a-Variable-Grid-for-Large-Language-Models"}]]}]]}],["$","article","2026-02-13-Think-Longer-to-Explore-Deeper-Learn-to-Explore-In-Context-via-Length-Incentivized-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-13-Think-Longer-to-Explore-Deeper-Learn-to-Explore-In-Context-via-Length-Incentivized-Reinforcement-Learning","children":"[논문리뷰] Think Longer to Explore Deeper: Learn to Explore In-Context via Length-Incentivized Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-13-Think-Longer-to-Explore-Deeper-Learn-to-Explore-In-Context-via-Length-Incentivized-Reinforcement-Learning","children":"이 [arXiv]에 게시한 'Think Longer to Explore Deeper: Learn to Explore In-Context via Length-Incentivized Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-13 00:00:00+0900+0900","children":"2026년 2월 13일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-13-Think-Longer-to-Explore-Deeper-Learn-to-Explore-In-Context-via-Length-Incentivized-Reinforcement-Learning"}]]}]]}],["$","article","2026-02-13-LawThinker-A-Deep-Research-Legal-Agent-in-Dynamic-Environments",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-13-LawThinker-A-Deep-Research-Legal-Agent-in-Dynamic-Environments","children":"[논문리뷰] LawThinker: A Deep Research Legal Agent in Dynamic Environments"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-13-LawThinker-A-Deep-Research-Legal-Agent-in-Dynamic-Environments","children":"이 [arXiv]에 게시한 'LawThinker: A Deep Research Legal Agent in Dynamic Environments' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-13 00:00:00+0900+0900","children":"2026년 2월 13일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-13-LawThinker-A-Deep-Research-Legal-Agent-in-Dynamic-Environments"}]]}]]}],["$","article","2026-02-13-Composition-RL-Compose-Your-Verifiable-Prompts-for-Reinforcement-Learning-of-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-13-Composition-RL-Compose-Your-Verifiable-Prompts-for-Reinforcement-Learning-of-Large-Language-Models","children":"[논문리뷰] Composition-RL: Compose Your Verifiable Prompts for Reinforcement Learning of Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-13-Composition-RL-Compose-Your-Verifiable-Prompts-for-Reinforcement-Learning-of-Large-Language-Models","children":"이 [arXiv]에 게시한 'Composition-RL: Compose Your Verifiable Prompts for Reinforcement Learning of Large Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-13 00:00:00+0900+0900","children":"2026년 2월 13일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-13-Composition-RL-Compose-Your-Verifiable-Prompts-for-Reinforcement-Learning-of-Large-Language-Models"}]]}]]}],["$","article","2026-02-12-Towards-Autonomous-Mathematics-Research",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-12-Towards-Autonomous-Mathematics-Research","children":"[논문리뷰] Towards Autonomous Mathematics Research"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-12-Towards-Autonomous-Mathematics-Research","children":"이 [arXiv]에 게시한 'Towards Autonomous Mathematics Research' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-12 00:00:00+0900+0900","children":"2026년 2월 12일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-12-Towards-Autonomous-Mathematics-Research"}]]}]]}],["$","article","2026-02-12-TimeChat-Captioner-Scripting-Multi-Scene-Videos-with-Time-Aware-and-Structural-Audio-Visual-Captions",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-12-TimeChat-Captioner-Scripting-Multi-Scene-Videos-with-Time-Aware-and-Structural-Audio-Visual-Captions","children":"[논문리뷰] TimeChat-Captioner: Scripting Multi-Scene Videos with Time-Aware and Structural Audio-Visual Captions"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-12-TimeChat-Captioner-Scripting-Multi-Scene-Videos-with-Time-Aware-and-Structural-Audio-Visual-Captions","children":"이 [arXiv]에 게시한 'TimeChat-Captioner: Scripting Multi-Scene Videos with Time-Aware and Structural Audio-Visual Captions' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-12 00:00:00+0900+0900","children":"2026년 2월 12일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-12-TimeChat-Captioner-Scripting-Multi-Scene-Videos-with-Time-Aware-and-Structural-Audio-Visual-Captions"}]]}]]}],["$","article","2026-02-12-Internalizing-Meta-Experience-into-Memory-for-Guided-Reinforcement-Learning-in-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-12-Internalizing-Meta-Experience-into-Memory-for-Guided-Reinforcement-Learning-in-Large-Language-Models","children":"[논문리뷰] Internalizing Meta-Experience into Memory for Guided Reinforcement Learning in Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-12-Internalizing-Meta-Experience-into-Memory-for-Guided-Reinforcement-Learning-in-Large-Language-Models","children":"Zhen Fang이 [arXiv]에 게시한 'Internalizing Meta-Experience into Memory for Guided Reinforcement Learning in Large Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-12 00:00:00+0900+0900","children":"2026년 2월 12일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-12-Internalizing-Meta-Experience-into-Memory-for-Guided-Reinforcement-Learning-in-Large-Language-Models"}]]}]]}],["$","article","2026-02-12-Free-Learning-to-Forget-in-Malloc-Only-Reasoning-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-12-Free-Learning-to-Forget-in-Malloc-Only-Reasoning-Models","children":"[논문리뷰] Free(): Learning to Forget in Malloc-Only Reasoning Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-12-Free-Learning-to-Forget-in-Malloc-Only-Reasoning-Models","children":"이 [arXiv]에 게시한 'Free(): Learning to Forget in Malloc-Only Reasoning Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-12 00:00:00+0900+0900","children":"2026년 2월 12일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-12-Free-Learning-to-Forget-in-Malloc-Only-Reasoning-Models"}]]}]]}],["$","article","2026-02-10-LOCA-bench-Benchmarking-Language-Agents-Under-Controllable-and-Extreme-Context-Growth",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-10-LOCA-bench-Benchmarking-Language-Agents-Under-Controllable-and-Extreme-Context-Growth","children":"[논문리뷰] LOCA-bench: Benchmarking Language Agents Under Controllable and Extreme Context Growth"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-10-LOCA-bench-Benchmarking-Language-Agents-Under-Controllable-and-Extreme-Context-Growth","children":"이 [arXiv]에 게시한 'LOCA-bench: Benchmarking Language Agents Under Controllable and Extreme Context Growth' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-10 00:00:00+0900+0900","children":"2026년 2월 10일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-10-LOCA-bench-Benchmarking-Language-Agents-Under-Controllable-and-Extreme-Context-Growth"}]]}]]}],["$","article","2026-02-09-InftyThink-Effective-and-Efficient-Infinite-Horizon-Reasoning-via-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-09-InftyThink-Effective-and-Efficient-Infinite-Horizon-Reasoning-via-Reinforcement-Learning","children":"[논문리뷰] InftyThink+: Effective and Efficient Infinite-Horizon Reasoning via Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-09-InftyThink-Effective-and-Efficient-Infinite-Horizon-Reasoning-via-Reinforcement-Learning","children":"이 [arXiv]에 게시한 'InftyThink+: Effective and Efficient Infinite-Horizon Reasoning via Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-09 00:00:00+0900+0900","children":"2026년 2월 9일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-09-InftyThink-Effective-and-Efficient-Infinite-Horizon-Reasoning-via-Reinforcement-Learning"}]]}]]}],["$","article","2026-02-06-Steering-LLMs-via-Scalable-Interactive-Oversight",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-06-Steering-LLMs-via-Scalable-Interactive-Oversight","children":"[논문리뷰] Steering LLMs via Scalable Interactive Oversight"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-06-Steering-LLMs-via-Scalable-Interactive-Oversight","children":"이 [arXiv]에 게시한 'Steering LLMs via Scalable Interactive Oversight' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-06 00:00:00+0900+0900","children":"2026년 2월 6일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-06-Steering-LLMs-via-Scalable-Interactive-Oversight"}]]}]]}],["$","article","2026-02-06-Retrieval-Infused-Reasoning-Sandbox-A-Benchmark-for-Decoupling-Retrieval-and-Reasoning-Capabilities",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-06-Retrieval-Infused-Reasoning-Sandbox-A-Benchmark-for-Decoupling-Retrieval-and-Reasoning-Capabilities","children":"[논문리뷰] Retrieval-Infused Reasoning Sandbox: A Benchmark for Decoupling Retrieval and Reasoning Capabilities"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-06-Retrieval-Infused-Reasoning-Sandbox-A-Benchmark-for-Decoupling-Retrieval-and-Reasoning-Capabilities","children":"이 [arXiv]에 게시한 'Retrieval-Infused Reasoning Sandbox: A Benchmark for Decoupling Retrieval and Reasoning Capabilities' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-06 00:00:00+0900+0900","children":"2026년 2월 6일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-06-Retrieval-Infused-Reasoning-Sandbox-A-Benchmark-for-Decoupling-Retrieval-and-Reasoning-Capabilities"}]]}]]}],["$","article","2026-02-06-ProAct-Agentic-Lookahead-in-Interactive-Environments",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-06-ProAct-Agentic-Lookahead-in-Interactive-Environments","children":"[논문리뷰] ProAct: Agentic Lookahead in Interactive Environments"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-06-ProAct-Agentic-Lookahead-in-Interactive-Environments","children":"이 [arXiv]에 게시한 'ProAct: Agentic Lookahead in Interactive Environments' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-06 00:00:00+0900+0900","children":"2026년 2월 6일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-06-ProAct-Agentic-Lookahead-in-Interactive-Environments"}]]}]]}],["$","article","2026-02-06-BABE-Biology-Arena-BEnchmark",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-06-BABE-Biology-Arena-BEnchmark","children":"[논문리뷰] BABE: Biology Arena BEnchmark"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-06-BABE-Biology-Arena-BEnchmark","children":"이 [arXiv]에 게시한 'BABE: Biology Arena BEnchmark' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-06 00:00:00+0900+0900","children":"2026년 2월 6일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-06-BABE-Biology-Arena-BEnchmark"}]]}]]}],["$","article","2026-02-05-WideSeek-R1-Exploring-Width-Scaling-for-Broad-Information-Seeking-via-Multi-Agent-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-05-WideSeek-R1-Exploring-Width-Scaling-for-Broad-Information-Seeking-via-Multi-Agent-Reinforcement-Learning","children":"[논문리뷰] WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-05-WideSeek-R1-Exploring-Width-Scaling-for-Broad-Information-Seeking-via-Multi-Agent-Reinforcement-Learning","children":"이 [arXiv]에 게시한 'WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-05 00:00:00+0900+0900","children":"2026년 2월 5일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-05-WideSeek-R1-Exploring-Width-Scaling-for-Broad-Information-Seeking-via-Multi-Agent-Reinforcement-Learning"}]]}]]}],["$","article","2026-02-05-Self-Hinting-Language-Models-Enhance-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-05-Self-Hinting-Language-Models-Enhance-Reinforcement-Learning","children":"[논문리뷰] Self-Hinting Language Models Enhance Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-05-Self-Hinting-Language-Models-Enhance-Reinforcement-Learning","children":"이 [arXiv]에 게시한 'Self-Hinting Language Models Enhance Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-05 00:00:00+0900+0900","children":"2026년 2월 5일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-05-Self-Hinting-Language-Models-Enhance-Reinforcement-Learning"}]]}]]}],["$","article","2026-02-05-PaperSearchQA-Learning-to-Search-and-Reason-over-Scientific-Papers-with-RLVR",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-05-PaperSearchQA-Learning-to-Search-and-Reason-over-Scientific-Papers-with-RLVR","children":"[논문리뷰] PaperSearchQA: Learning to Search and Reason over Scientific Papers with RLVR"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-05-PaperSearchQA-Learning-to-Search-and-Reason-over-Scientific-Papers-with-RLVR","children":"Alejandro Lozano이 [arXiv]에 게시한 'PaperSearchQA: Learning to Search and Reason over Scientific Papers with RLVR' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-05 00:00:00+0900+0900","children":"2026년 2월 5일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-05-PaperSearchQA-Learning-to-Search-and-Reason-over-Scientific-Papers-with-RLVR"}]]}]]}],["$","article","2026-02-05-OmniSIFT-Modality-Asymmetric-Token-Compression-for-Efficient-Omni-modal-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-05-OmniSIFT-Modality-Asymmetric-Token-Compression-for-Efficient-Omni-modal-Large-Language-Models","children":"[논문리뷰] OmniSIFT: Modality-Asymmetric Token Compression for Efficient Omni-modal Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-05-OmniSIFT-Modality-Asymmetric-Token-Compression-for-Efficient-Omni-modal-Large-Language-Models","children":"Yiyan Ji이 [arXiv]에 게시한 'OmniSIFT: Modality-Asymmetric Token Compression for Efficient Omni-modal Large Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-05 00:00:00+0900+0900","children":"2026년 2월 5일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-05-OmniSIFT-Modality-Asymmetric-Token-Compression-for-Efficient-Omni-modal-Large-Language-Models"}]]}]]}],["$","article","2026-02-04-SimpleGPT-Improving-GPT-via-A-Simple-Normalization-Strategy",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-04-SimpleGPT-Improving-GPT-via-A-Simple-Normalization-Strategy","children":"[논문리뷰] SimpleGPT: Improving GPT via A Simple Normalization Strategy"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-04-SimpleGPT-Improving-GPT-via-A-Simple-Normalization-Strategy","children":"Rong Xiao이 [arXiv]에 게시한 'SimpleGPT: Improving GPT via A Simple Normalization Strategy' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-04 00:00:00+0900+0900","children":"2026년 2월 4일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-04-SimpleGPT-Improving-GPT-via-A-Simple-Normalization-Strategy"}]]}]]}],["$","article","2026-02-04-AOrchestra-Automating-Sub-Agent-Creation-for-Agentic-Orchestration",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-04-AOrchestra-Automating-Sub-Agent-Creation-for-Agentic-Orchestration","children":"[논문리뷰] AOrchestra: Automating Sub-Agent Creation for Agentic Orchestration"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-04-AOrchestra-Automating-Sub-Agent-Creation-for-Agentic-Orchestration","children":"Zhaoyang Yu이 [arXiv]에 게시한 'AOrchestra: Automating Sub-Agent Creation for Agentic Orchestration' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-04 00:00:00+0900+0900","children":"2026년 2월 4일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-04-AOrchestra-Automating-Sub-Agent-Creation-for-Agentic-Orchestration"}]]}]]}],["$","article","2026-02-03-RLAnything-Forge-Environment-Policy-and-Reward-Model-in-Completely-Dynamic-RL-System",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-03-RLAnything-Forge-Environment-Policy-and-Reward-Model-in-Completely-Dynamic-RL-System","children":"[논문리뷰] RLAnything: Forge Environment, Policy, and Reward Model in Completely Dynamic RL System"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-03-RLAnything-Forge-Environment-Policy-and-Reward-Model-in-Completely-Dynamic-RL-System","children":"이 [arXiv]에 게시한 'RLAnything: Forge Environment, Policy, and Reward Model in Completely Dynamic RL System' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-03 00:00:00+0900+0900","children":"2026년 2월 3일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-03-RLAnything-Forge-Environment-Policy-and-Reward-Model-in-Completely-Dynamic-RL-System"}]]}]]}],["$","article","2026-02-02-RM-RF-Reward-Model-for-Run-Free-Unit-Test-Evaluation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-02-RM-RF-Reward-Model-for-Run-Free-Unit-Test-Evaluation","children":"[논문리뷰] RM -RF: Reward Model for Run-Free Unit Test Evaluation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-02-RM-RF-Reward-Model-for-Run-Free-Unit-Test-Evaluation","children":"Vadim Alperovich이 [arXiv]에 게시한 'RM -RF: Reward Model for Run-Free Unit Test Evaluation' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-02 00:00:00+0900+0900","children":"2026년 2월 2일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-02-RM-RF-Reward-Model-for-Run-Free-Unit-Test-Evaluation"}]]}]]}],["$","article","2026-02-02-MemOCR-Layout-Aware-Visual-Memory-for-Efficient-Long-Horizon-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-02-MemOCR-Layout-Aware-Visual-Memory-for-Efficient-Long-Horizon-Reasoning","children":"[논문리뷰] MemOCR: Layout-Aware Visual Memory for Efficient Long-Horizon Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-02-MemOCR-Layout-Aware-Visual-Memory-for-Efficient-Long-Horizon-Reasoning","children":"Yuxin Chen이 [arXiv]에 게시한 'MemOCR: Layout-Aware Visual Memory for Efficient Long-Horizon Reasoning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-02 00:00:00+0900+0900","children":"2026년 2월 2일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-02-MemOCR-Layout-Aware-Visual-Memory-for-Efficient-Long-Horizon-Reasoning"}]]}]]}],["$","article","2026-02-02-Deep-Search-with-Hierarchical-Meta-Cognitive-Monitoring-Inspired-by-Cognitive-Neuroscience",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-02-02-Deep-Search-with-Hierarchical-Meta-Cognitive-Monitoring-Inspired-by-Cognitive-Neuroscience","children":"[논문리뷰] Deep Search with Hierarchical Meta-Cognitive Monitoring Inspired by Cognitive Neuroscience"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-02-02-Deep-Search-with-Hierarchical-Meta-Cognitive-Monitoring-Inspired-by-Cognitive-Neuroscience","children":"이 [arXiv]에 게시한 'Deep Search with Hierarchical Meta-Cognitive Monitoring Inspired by Cognitive Neuroscience' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-02-02 00:00:00+0900+0900","children":"2026년 2월 2일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-02-02-Deep-Search-with-Hierarchical-Meta-Cognitive-Monitoring-Inspired-by-Cognitive-Neuroscience"}]]}]]}],["$","article","2026-01-30-MMFineReason-Closing-the-Multimodal-Reasoning-Gap-via-Open-Data-Centric-Methods",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-30-MMFineReason-Closing-the-Multimodal-Reasoning-Gap-via-Open-Data-Centric-Methods","children":"[논문리뷰] MMFineReason: Closing the Multimodal Reasoning Gap via Open Data-Centric Methods"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-30-MMFineReason-Closing-the-Multimodal-Reasoning-Gap-via-Open-Data-Centric-Methods","children":"이 [arXiv]에 게시한 'MMFineReason: Closing the Multimodal Reasoning Gap via Open Data-Centric Methods' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-30 00:00:00+0900+0900","children":"2026년 1월 30일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-30-MMFineReason-Closing-the-Multimodal-Reasoning-Gap-via-Open-Data-Centric-Methods"}]]}]]}],["$","article","2026-01-30-Language-based-Trial-and-Error-Falls-Behind-in-the-Era-of-Experience",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-30-Language-based-Trial-and-Error-Falls-Behind-in-the-Era-of-Experience","children":"[논문리뷰] Language-based Trial and Error Falls Behind in the Era of Experience"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-30-Language-based-Trial-and-Error-Falls-Behind-in-the-Era-of-Experience","children":"이 [arXiv]에 게시한 'Language-based Trial and Error Falls Behind in the Era of Experience' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-30 00:00:00+0900+0900","children":"2026년 1월 30일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-30-Language-based-Trial-and-Error-Falls-Behind-in-the-Era-of-Experience"}]]}]]}],["$","article","2026-01-30-Discovering-Hidden-Gems-in-Model-Repositories",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-30-Discovering-Hidden-Gems-in-Model-Repositories","children":"[논문리뷰] Discovering Hidden Gems in Model Repositories"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-30-Discovering-Hidden-Gems-in-Model-Repositories","children":"Yedid Hoshen이 [arXiv]에 게시한 'Discovering Hidden Gems in Model Repositories' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-30 00:00:00+0900+0900","children":"2026년 1월 30일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-30-Discovering-Hidden-Gems-in-Model-Repositories"}]]}]]}],["$","article","2026-01-29-GDCNet-Generative-Discrepancy-Comparison-Network-for-Multimodal-Sarcasm-Detection",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-29-GDCNet-Generative-Discrepancy-Comparison-Network-for-Multimodal-Sarcasm-Detection","children":"[논문리뷰] GDCNet: Generative Discrepancy Comparison Network for Multimodal Sarcasm Detection"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-29-GDCNet-Generative-Discrepancy-Comparison-Network-for-Multimodal-Sarcasm-Detection","children":"이 [arXiv]에 게시한 'GDCNet: Generative Discrepancy Comparison Network for Multimodal Sarcasm Detection' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-29 00:00:00+0900+0900","children":"2026년 1월 29일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-29-GDCNet-Generative-Discrepancy-Comparison-Network-for-Multimodal-Sarcasm-Detection"}]]}]]}],["$","article","2026-01-28-Post-LayerNorm-Is-Back-Stable-ExpressivE-and-Deep",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-28-Post-LayerNorm-Is-Back-Stable-ExpressivE-and-Deep","children":"[논문리뷰] Post-LayerNorm Is Back: Stable, ExpressivE, and Deep"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-28-Post-LayerNorm-Is-Back-Stable-ExpressivE-and-Deep","children":"이 [arXiv]에 게시한 'Post-LayerNorm Is Back: Stable, ExpressivE, and Deep' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-28 00:00:00+0900+0900","children":"2026년 1월 28일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-28-Post-LayerNorm-Is-Back-Stable-ExpressivE-and-Deep"}]]}]]}],["$","article","2026-01-27-daVinci-Dev-Agent-native-Mid-training-for-Software-Engineering",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-27-daVinci-Dev-Agent-native-Mid-training-for-Software-Engineering","children":"[논문리뷰] daVinci-Dev: Agent-native Mid-training for Software Engineering"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-27-daVinci-Dev-Agent-native-Mid-training-for-Software-Engineering","children":"이 [arXiv]에 게시한 'daVinci-Dev: Agent-native Mid-training for Software Engineering' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-27 00:00:00+0900+0900","children":"2026년 1월 27일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-27-daVinci-Dev-Agent-native-Mid-training-for-Software-Engineering"}]]}]]}],["$","article","2026-01-27-VIBEVOICE-ASR-Technical-Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-27-VIBEVOICE-ASR-Technical-Report","children":"[논문리뷰] VIBEVOICE-ASR Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-27-VIBEVOICE-ASR-Technical-Report","children":"이 [arXiv]에 게시한 'VIBEVOICE-ASR Technical Report' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-27 00:00:00+0900+0900","children":"2026년 1월 27일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-27-VIBEVOICE-ASR-Technical-Report"}]]}]]}],["$","article","2026-01-27-STAR-Semantic-Table-Representation-with-Header-Aware-Clustering-and-Adaptive-Weighted-Fusion",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-27-STAR-Semantic-Table-Representation-with-Header-Aware-Clustering-and-Adaptive-Weighted-Fusion","children":"[논문리뷰] STAR: Semantic Table Representation with Header-Aware Clustering and Adaptive Weighted Fusion"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-27-STAR-Semantic-Table-Representation-with-Header-Aware-Clustering-and-Adaptive-Weighted-Fusion","children":"이 [arXiv]에 게시한 'STAR: Semantic Table Representation with Header-Aware Clustering and Adaptive Weighted Fusion' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-27 00:00:00+0900+0900","children":"2026년 1월 27일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-27-STAR-Semantic-Table-Representation-with-Header-Aware-Clustering-and-Adaptive-Weighted-Fusion"}]]}]]}],["$","article","2026-01-26-MeepleLM-A-Virtual-Playtester-Simulating-Diverse-Subjective-Experiences",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-26-MeepleLM-A-Virtual-Playtester-Simulating-Diverse-Subjective-Experiences","children":"[논문리뷰] MeepleLM: A Virtual Playtester Simulating Diverse Subjective Experiences"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-26-MeepleLM-A-Virtual-Playtester-Simulating-Diverse-Subjective-Experiences","children":"Jianwen Sun이 [arXiv]에 게시한 'MeepleLM: A Virtual Playtester Simulating Diverse Subjective Experiences' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-26 00:00:00+0900+0900","children":"2026년 1월 26일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-26-MeepleLM-A-Virtual-Playtester-Simulating-Diverse-Subjective-Experiences"}]]}]]}],["$","article","2026-01-26-Guidelines-to-Prompt-Large-Language-Models-for-Code-Generation-An-Empirical-Characterization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-26-Guidelines-to-Prompt-Large-Language-Models-for-Code-Generation-An-Empirical-Characterization","children":"[논문리뷰] Guidelines to Prompt Large Language Models for Code Generation: An Empirical Characterization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-26-Guidelines-to-Prompt-Large-Language-Models-for-Code-Generation-An-Empirical-Characterization","children":"Gabriele Bavota이 [arXiv]에 게시한 'Guidelines to Prompt Large Language Models for Code Generation: An Empirical Characterization' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-26 00:00:00+0900+0900","children":"2026년 1월 26일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-26-Guidelines-to-Prompt-Large-Language-Models-for-Code-Generation-An-Empirical-Characterization"}]]}]]}],["$","article","2026-01-26-Dancing-in-Chains-Strategic-Persuasion-in-Academic-Rebuttal-via-Theory-of-Mind",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-26-Dancing-in-Chains-Strategic-Persuasion-in-Academic-Rebuttal-via-Theory-of-Mind","children":"[논문리뷰] Dancing in Chains: Strategic Persuasion in Academic Rebuttal via Theory of Mind"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-26-Dancing-in-Chains-Strategic-Persuasion-in-Academic-Rebuttal-via-Theory-of-Mind","children":"Yi R Fung이 [arXiv]에 게시한 'Dancing in Chains: Strategic Persuasion in Academic Rebuttal via Theory of Mind' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-26 00:00:00+0900+0900","children":"2026년 1월 26일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-26-Dancing-in-Chains-Strategic-Persuasion-in-Academic-Rebuttal-via-Theory-of-Mind"}]]}]]}],["$","article","2026-01-23-Towards-Automated-Kernel-Generation-in-the-Era-of-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-23-Towards-Automated-Kernel-Generation-in-the-Era-of-LLMs","children":"[논문리뷰] Towards Automated Kernel Generation in the Era of LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-23-Towards-Automated-Kernel-Generation-in-the-Era-of-LLMs","children":"Yixin Shen이 [arXiv]에 게시한 'Towards Automated Kernel Generation in the Era of LLMs' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-23 00:00:00+0900+0900","children":"2026년 1월 23일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-23-Towards-Automated-Kernel-Generation-in-the-Era-of-LLMs"}]]}]]}],["$","article","2026-01-23-Stable-DiffCoder-Pushing-the-Frontier-of-Code-Diffusion-Large-Language-Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-23-Stable-DiffCoder-Pushing-the-Frontier-of-Code-Diffusion-Large-Language-Model","children":"[논문리뷰] Stable-DiffCoder: Pushing the Frontier of Code Diffusion Large Language Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-23-Stable-DiffCoder-Pushing-the-Frontier-of-Code-Diffusion-Large-Language-Model","children":"이 [arXiv]에 게시한 'Stable-DiffCoder: Pushing the Frontier of Code Diffusion Large Language Model' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-23 00:00:00+0900+0900","children":"2026년 1월 23일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-23-Stable-DiffCoder-Pushing-the-Frontier-of-Code-Diffusion-Large-Language-Model"}]]}]]}],["$","article","2026-01-22-Lost-in-the-Prompt-Order-Revealing-the-Limitations-of-Causal-Attention-in-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-22-Lost-in-the-Prompt-Order-Revealing-the-Limitations-of-Causal-Attention-in-Language-Models","children":"[논문리뷰] Lost in the Prompt Order: Revealing the Limitations of Causal Attention in Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-22-Lost-in-the-Prompt-Order-Revealing-the-Limitations-of-Causal-Attention-in-Language-Models","children":"이 [arXiv]에 게시한 'Lost in the Prompt Order: Revealing the Limitations of Causal Attention in Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-22 00:00:00+0900+0900","children":"2026년 1월 22일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-22-Lost-in-the-Prompt-Order-Revealing-the-Limitations-of-Causal-Attention-in-Language-Models"}]]}]]}],["$","article","2026-01-21-ToolPRMBench-Evaluating-and-Advancing-Process-Reward-Models-for-Tool-using-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-21-ToolPRMBench-Evaluating-and-Advancing-Process-Reward-Models-for-Tool-using-Agents","children":"[논문리뷰] ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-21-ToolPRMBench-Evaluating-and-Advancing-Process-Reward-Models-for-Tool-using-Agents","children":"이 [arXiv]에 게시한 'ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-21 00:00:00+0900+0900","children":"2026년 1월 21일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-21-ToolPRMBench-Evaluating-and-Advancing-Process-Reward-Models-for-Tool-using-Agents"}]]}]]}],["$","article","2026-01-21-On-the-Evidentiary-Limits-of-Membership-Inference-for-Copyright-Auditing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-21-On-the-Evidentiary-Limits-of-Membership-Inference-for-Copyright-Auditing","children":"[논문리뷰] On the Evidentiary Limits of Membership Inference for Copyright Auditing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-21-On-the-Evidentiary-Limits-of-Membership-Inference-for-Copyright-Auditing","children":"Marten van Dijk이 [arXiv]에 게시한 'On the Evidentiary Limits of Membership Inference for Copyright Auditing' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-21 00:00:00+0900+0900","children":"2026년 1월 21일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-21-On-the-Evidentiary-Limits-of-Membership-Inference-for-Copyright-Auditing"}]]}]]}],["$","article","2026-01-21-Agentic-R-Learning-to-Retrieve-for-Agentic-Search",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-21-Agentic-R-Learning-to-Retrieve-for-Agentic-Search","children":"[논문리뷰] Agentic-R: Learning to Retrieve for Agentic Search"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-21-Agentic-R-Learning-to-Retrieve-for-Agentic-Search","children":"Daiting Shi이 [arXiv]에 게시한 'Agentic-R: Learning to Retrieve for Agentic Search' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-21 00:00:00+0900+0900","children":"2026년 1월 21일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-21-Agentic-R-Learning-to-Retrieve-for-Agentic-Search"}]]}]]}],["$","article","2026-01-20-Multiplex-Thinking-Reasoning-via-Token-wise-Branch-and-Merge",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-20-Multiplex-Thinking-Reasoning-via-Token-wise-Branch-and-Merge","children":"[논문리뷰] Multiplex Thinking: Reasoning via Token-wise Branch-and-Merge"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-20-Multiplex-Thinking-Reasoning-via-Token-wise-Branch-and-Merge","children":"이 [arXiv]에 게시한 'Multiplex Thinking: Reasoning via Token-wise Branch-and-Merge' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-20 00:00:00+0900+0900","children":"2026년 1월 20일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-20-Multiplex-Thinking-Reasoning-via-Token-wise-Branch-and-Merge"}]]}]]}],["$","article","2026-01-19-Language-of-Thought-Shapes-Output-Diversity-in-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-19-Language-of-Thought-Shapes-Output-Diversity-in-Large-Language-Models","children":"[논문리뷰] Language of Thought Shapes Output Diversity in Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-19-Language-of-Thought-Shapes-Output-Diversity-in-Large-Language-Models","children":"이 [arXiv]에 게시한 'Language of Thought Shapes Output Diversity in Large Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-19 00:00:00+0900+0900","children":"2026년 1월 19일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-19-Language-of-Thought-Shapes-Output-Diversity-in-Large-Language-Models"}]]}]]}],["$","article","2026-01-16-Collaborative-Multi-Agent-Test-Time-Reinforcement-Learning-for-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-16-Collaborative-Multi-Agent-Test-Time-Reinforcement-Learning-for-Reasoning","children":"[논문리뷰] Collaborative Multi-Agent Test-Time Reinforcement Learning for Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-16-Collaborative-Multi-Agent-Test-Time-Reinforcement-Learning-for-Reasoning","children":"이 [arXiv]에 게시한 'Collaborative Multi-Agent Test-Time Reinforcement Learning for Reasoning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-16 00:00:00+0900+0900","children":"2026년 1월 16일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-16-Collaborative-Multi-Agent-Test-Time-Reinforcement-Learning-for-Reasoning"}]]}]]}],["$","article","2026-01-16-Beyond-Static-Tools-Test-Time-Tool-Evolution-for-Scientific-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-16-Beyond-Static-Tools-Test-Time-Tool-Evolution-for-Scientific-Reasoning","children":"[논문리뷰] Beyond Static Tools: Test-Time Tool Evolution for Scientific Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-16-Beyond-Static-Tools-Test-Time-Tool-Evolution-for-Scientific-Reasoning","children":"이 [arXiv]에 게시한 'Beyond Static Tools: Test-Time Tool Evolution for Scientific Reasoning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-16 00:00:00+0900+0900","children":"2026년 1월 16일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-16-Beyond-Static-Tools-Test-Time-Tool-Evolution-for-Scientific-Reasoning"}]]}]]}],["$","article","2026-01-16-A-Safety-Report-on-GPT-5-2-Gemini-3-Pro-Qwen3-VL-Doubao-1-8-Grok-4-1-Fast-Nano-Banana-Pro-and-Seedream-4-5",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-16-A-Safety-Report-on-GPT-5-2-Gemini-3-Pro-Qwen3-VL-Doubao-1-8-Grok-4-1-Fast-Nano-Banana-Pro-and-Seedream-4-5","children":"[논문리뷰] A Safety Report on GPT-5.2, Gemini 3 Pro, Qwen3-VL, Doubao 1.8, Grok 4.1 Fast, Nano Banana Pro, and Seedream 4.5"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-16-A-Safety-Report-on-GPT-5-2-Gemini-3-Pro-Qwen3-VL-Doubao-1-8-Grok-4-1-Fast-Nano-Banana-Pro-and-Seedream-4-5","children":"Yutao Wu이 [arXiv]에 게시한 'A Safety Report on GPT-5.2, Gemini 3 Pro, Qwen3-VL, Doubao 1.8, Grok 4.1 Fast, Nano Banana Pro, and Seedream 4.5' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-16 00:00:00+0900+0900","children":"2026년 1월 16일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-16-A-Safety-Report-on-GPT-5-2-Gemini-3-Pro-Qwen3-VL-Doubao-1-8-Grok-4-1-Fast-Nano-Banana-Pro-and-Seedream-4-5"}]]}]]}],["$","article","2026-01-15-TranslateGemma-Technical-Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-15-TranslateGemma-Technical-Report","children":"[논문리뷰] TranslateGemma Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-15-TranslateGemma-Technical-Report","children":"이 [arXiv]에 게시한 'TranslateGemma Technical Report' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-15 00:00:00+0900+0900","children":"2026년 1월 15일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-15-TranslateGemma-Technical-Report"}]]}]]}],["$","article","2026-01-15-Controlled-Self-Evolution-for-Algorithmic-Code-Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-15-Controlled-Self-Evolution-for-Algorithmic-Code-Optimization","children":"[논문리뷰] Controlled Self-Evolution for Algorithmic Code Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-15-Controlled-Self-Evolution-for-Algorithmic-Code-Optimization","children":"이 [arXiv]에 게시한 'Controlled Self-Evolution for Algorithmic Code Optimization' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-15 00:00:00+0900+0900","children":"2026년 1월 15일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-15-Controlled-Self-Evolution-for-Algorithmic-Code-Optimization"}]]}]]}],["$","article","2026-01-15-Are-LLMs-Vulnerable-to-Preference-Undermining-Attacks-PUA-A-Factorial-Analysis-Methodology-for-Diagnosing-the-Trade-off-between-Preference-Alignment-and-Real-World-Validity",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-15-Are-LLMs-Vulnerable-to-Preference-Undermining-Attacks-PUA-A-Factorial-Analysis-Methodology-for-Diagnosing-the-Trade-off-between-Preference-Alignment-and-Real-World-Validity","children":"[논문리뷰] Are LLMs Vulnerable to Preference-Undermining Attacks (PUA)? A Factorial Analysis Methodology for Diagnosing the Trade-off between Preference Alignment and Real-World Validity"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-15-Are-LLMs-Vulnerable-to-Preference-Undermining-Attacks-PUA-A-Factorial-Analysis-Methodology-for-Diagnosing-the-Trade-off-between-Preference-Alignment-and-Real-World-Validity","children":"Chi Zhang이 [arXiv]에 게시한 'Are LLMs Vulnerable to Preference-Undermining Attacks (PUA)? A Factorial Analysis Methodology for Diagnosing the Trade-off between Preference Alignment and Real-World Validity' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-15 00:00:00+0900+0900","children":"2026년 1월 15일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-15-Are-LLMs-Vulnerable-to-Preference-Undermining-Attacks-PUA-A-Factorial-Analysis-Methodology-for-Diagnosing-the-Trade-off-between-Preference-Alignment-and-Real-World-Validity"}]]}]]}],["$","article","2026-01-14-Solar-Open-Technical-Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-14-Solar-Open-Technical-Report","children":"[논문리뷰] Solar Open Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-14-Solar-Open-Technical-Report","children":"이 [arXiv]에 게시한 'Solar Open Technical Report' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-14 00:00:00+0900+0900","children":"2026년 1월 14일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-14-Solar-Open-Technical-Report"}]]}]]}],["$","article","2026-01-14-Ministral-3",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-14-Ministral-3","children":"[논문리뷰] Ministral 3"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-14-Ministral-3","children":"이 [arXiv]에 게시한 'Ministral 3' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-14 00:00:00+0900+0900","children":"2026년 1월 14일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-14-Ministral-3"}]]}]]}],["$","article","2026-01-12-SmartSearch-Process-Reward-Guided-Query-Refinement-for-Search-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-12-SmartSearch-Process-Reward-Guided-Query-Refinement-for-Search-Agents","children":"[논문리뷰] SmartSearch: Process Reward-Guided Query Refinement for Search Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-12-SmartSearch-Process-Reward-Guided-Query-Refinement-for-Search-Agents","children":"Guanting Dong이 [arXiv]에 게시한 'SmartSearch: Process Reward-Guided Query Refinement for Search Agents' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-12 00:00:00+0900+0900","children":"2026년 1월 12일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-12-SmartSearch-Process-Reward-Guided-Query-Refinement-for-Search-Agents"}]]}]]}],["$","article","2026-01-09-Learnable-Multipliers-Freeing-the-Scale-of-Language-Model-Matrix-Layers",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-09-Learnable-Multipliers-Freeing-the-Scale-of-Language-Model-Matrix-Layers","children":"[논문리뷰] Learnable Multipliers: Freeing the Scale of Language Model Matrix Layers"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-09-Learnable-Multipliers-Freeing-the-Scale-of-Language-Model-Matrix-Layers","children":"이 [arXiv]에 게시한 'Learnable Multipliers: Freeing the Scale of Language Model Matrix Layers' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-09 00:00:00+0900+0900","children":"2026년 1월 9일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-09-Learnable-Multipliers-Freeing-the-Scale-of-Language-Model-Matrix-Layers"}]]}]]}],["$","article","2026-01-09-DiffCoT-Diffusion-styled-Chain-of-Thought-Reasoning-in-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-09-DiffCoT-Diffusion-styled-Chain-of-Thought-Reasoning-in-LLMs","children":"[논문리뷰] DiffCoT: Diffusion-styled Chain-of-Thought Reasoning in LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-09-DiffCoT-Diffusion-styled-Chain-of-Thought-Reasoning-in-LLMs","children":"Jing Ma이 [arXiv]에 게시한 'DiffCoT: Diffusion-styled Chain-of-Thought Reasoning in LLMs' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-09 00:00:00+0900+0900","children":"2026년 1월 9일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-09-DiffCoT-Diffusion-styled-Chain-of-Thought-Reasoning-in-LLMs"}]]}]]}],["$","article","2026-01-08-MDAgent2-Large-Language-Model-for-Code-Generation-and-Knowledge-QA-in-Molecular-Dynamics",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-08-MDAgent2-Large-Language-Model-for-Code-Generation-and-Knowledge-QA-in-Molecular-Dynamics","children":"[논문리뷰] MDAgent2: Large Language Model for Code Generation and Knowledge Q&A in Molecular Dynamics"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-08-MDAgent2-Large-Language-Model-for-Code-Generation-and-Knowledge-QA-in-Molecular-Dynamics","children":"이 [arXiv]에 게시한 'MDAgent2: Large Language Model for Code Generation and Knowledge Q&A in Molecular Dynamics' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-08 00:00:00+0900+0900","children":"2026년 1월 8일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-08-MDAgent2-Large-Language-Model-for-Code-Generation-and-Knowledge-QA-in-Molecular-Dynamics"}]]}]]}],["$","article","2026-01-08-MAGMA-A-Multi-Graph-based-Agentic-Memory-Architecture-for-AI-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-08-MAGMA-A-Multi-Graph-based-Agentic-Memory-Architecture-for-AI-Agents","children":"[논문리뷰] MAGMA: A Multi-Graph based Agentic Memory Architecture for AI Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-08-MAGMA-A-Multi-Graph-based-Agentic-Memory-Architecture-for-AI-Agents","children":"Bingzhe Li이 [arXiv]에 게시한 'MAGMA: A Multi-Graph based Agentic Memory Architecture for AI Agents' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-08 00:00:00+0900+0900","children":"2026년 1월 8일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-08-MAGMA-A-Multi-Graph-based-Agentic-Memory-Architecture-for-AI-Agents"}]]}]]}],["$","article","2026-01-08-EpiQAL-Benchmarking-Large-Language-Models-in-Epidemiological-Question-Answering-for-Enhanced-Alignment-and-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-08-EpiQAL-Benchmarking-Large-Language-Models-in-Epidemiological-Question-Answering-for-Enhanced-Alignment-and-Reasoning","children":"[논문리뷰] EpiQAL: Benchmarking Large Language Models in Epidemiological Question Answering for Enhanced Alignment and Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-08-EpiQAL-Benchmarking-Large-Language-Models-in-Epidemiological-Question-Answering-for-Enhanced-Alignment-and-Reasoning","children":"Guanchen Wu이 [arXiv]에 게시한 'EpiQAL: Benchmarking Large Language Models in Epidemiological Question Answering for Enhanced Alignment and Reasoning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-08 00:00:00+0900+0900","children":"2026년 1월 8일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-08-EpiQAL-Benchmarking-Large-Language-Models-in-Epidemiological-Question-Answering-for-Enhanced-Alignment-and-Reasoning"}]]}]]}],["$","article","2026-01-06-Recursive-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-06-Recursive-Language-Models","children":"[논문리뷰] Recursive Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-06-Recursive-Language-Models","children":"이 [arXiv]에 게시한 'Recursive Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-06 00:00:00+0900+0900","children":"2026년 1월 6일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-06-Recursive-Language-Models"}]]}]]}],["$","article","2026-01-05-Diversity-or-Precision-A-Deep-Dive-into-Next-Token-Prediction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-05-Diversity-or-Precision-A-Deep-Dive-into-Next-Token-Prediction","children":"[논문리뷰] Diversity or Precision? A Deep Dive into Next Token Prediction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-05-Diversity-or-Precision-A-Deep-Dive-into-Next-Token-Prediction","children":"이 [arXiv]에 게시한 'Diversity or Precision? A Deep Dive into Next Token Prediction' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-05 00:00:00+0900+0900","children":"2026년 1월 5일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-05-Diversity-or-Precision-A-Deep-Dive-into-Next-Token-Prediction"}]]}]]}],["$","article","2026-01-01-mHC-Manifold-Constrained-Hyper-Connections",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-01-mHC-Manifold-Constrained-Hyper-Connections","children":"[논문리뷰] mHC: Manifold-Constrained Hyper-Connections"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-01-mHC-Manifold-Constrained-Hyper-Connections","children":"이 [arXiv]에 게시한 'mHC: Manifold-Constrained Hyper-Connections' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-01 00:00:00+0900+0900","children":"2026년 1월 1일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-01-mHC-Manifold-Constrained-Hyper-Connections"}]]}]]}],["$","article","2026-01-01-Let-It-Flow-Agentic-Crafting-on-Rock-and-Roll-Building-the-ROME-Model-within-an-Open-Agentic-Learning-Ecosystem",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2026-01-01-Let-It-Flow-Agentic-Crafting-on-Rock-and-Roll-Building-the-ROME-Model-within-an-Open-Agentic-Learning-Ecosystem","children":"[논문리뷰] Let It Flow: Agentic Crafting on Rock and Roll, Building the ROME Model within an Open Agentic Learning Ecosystem"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2026-01-01-Let-It-Flow-Agentic-Crafting-on-Rock-and-Roll-Building-the-ROME-Model-within-an-Open-Agentic-Learning-Ecosystem","children":"Wei Gao이 [arXiv]에 게시한 'Let It Flow: Agentic Crafting on Rock and Roll, Building the ROME Model within an Open Agentic Learning Ecosystem' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2026-01-01 00:00:00+0900+0900","children":"2026년 1월 1일"}],["$","$L4",null,{"postPermalink":"/ai/review/2026-01-01-Let-It-Flow-Agentic-Crafting-on-Rock-and-Roll-Building-the-ROME-Model-within-an-Open-Agentic-Learning-Ecosystem"}]]}]]}],["$","article","2025-12-31-GraphLocator-Graph-guided-Causal-Reasoning-for-Issue-Localization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-31-GraphLocator-Graph-guided-Causal-Reasoning-for-Issue-Localization","children":"[논문리뷰] GraphLocator: Graph-guided Causal Reasoning for Issue Localization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-31-GraphLocator-Graph-guided-Causal-Reasoning-for-Issue-Localization","children":"Wei Zhang이 [arXiv]에 게시한 'GraphLocator: Graph-guided Causal Reasoning for Issue Localization' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-31 00:00:00+0900+0900","children":"2025년 12월 31일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-31-GraphLocator-Graph-guided-Causal-Reasoning-for-Issue-Localization"}]]}]]}],["$","article","2025-12-29-SlideTailor-Personalized-Presentation-Slide-Generation-for-Scientific-Papers",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-29-SlideTailor-Personalized-Presentation-Slide-Generation-for-Scientific-Papers","children":"[논문리뷰] SlideTailor: Personalized Presentation Slide Generation for Scientific Papers"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-29-SlideTailor-Personalized-Presentation-Slide-Generation-for-Scientific-Papers","children":"이 [arXiv]에 게시한 'SlideTailor: Personalized Presentation Slide Generation for Scientific Papers' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-29 00:00:00+0900+0900","children":"2025년 12월 29일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-29-SlideTailor-Personalized-Presentation-Slide-Generation-for-Scientific-Papers"}]]}]]}],["$","article","2025-12-24-Multi-LLM-Thematic-Analysis-with-Dual-Reliability-Metrics-Combining-Cohens-Kappa-and-Semantic-Similarity-for-Qualitative-Research-Validation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-24-Multi-LLM-Thematic-Analysis-with-Dual-Reliability-Metrics-Combining-Cohens-Kappa-and-Semantic-Similarity-for-Qualitative-Research-Validation","children":"[논문리뷰] Multi-LLM Thematic Analysis with Dual Reliability Metrics: Combining Cohen's Kappa and Semantic Similarity for Qualitative Research Validation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-24-Multi-LLM-Thematic-Analysis-with-Dual-Reliability-Metrics-Combining-Cohens-Kappa-and-Semantic-Similarity-for-Qualitative-Research-Validation","children":"이 [arXiv]에 게시한 'Multi-LLM Thematic Analysis with Dual Reliability Metrics: Combining Cohen's Kappa and Semantic Similarity for Qualitative Research Validation' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-24 00:00:00+0900+0900","children":"2025년 12월 24일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-24-Multi-LLM-Thematic-Analysis-with-Dual-Reliability-Metrics-Combining-Cohens-Kappa-and-Semantic-Similarity-for-Qualitative-Research-Validation"}]]}]]}],["$","article","2025-12-24-LongVideoAgent-Multi-Agent-Reasoning-with-Long-Videos",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-24-LongVideoAgent-Multi-Agent-Reasoning-with-Long-Videos","children":"[논문리뷰] LongVideoAgent: Multi-Agent Reasoning with Long Videos"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-24-LongVideoAgent-Multi-Agent-Reasoning-with-Long-Videos","children":"Renjie Pi이 [arXiv]에 게시한 'LongVideoAgent: Multi-Agent Reasoning with Long Videos' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-24 00:00:00+0900+0900","children":"2025년 12월 24일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-24-LongVideoAgent-Multi-Agent-Reasoning-with-Long-Videos"}]]}]]}],["$","article","2025-12-24-INTELLECT-3-Technical-Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-24-INTELLECT-3-Technical-Report","children":"[논문리뷰] INTELLECT-3: Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-24-INTELLECT-3-Technical-Report","children":"이 [arXiv]에 게시한 'INTELLECT-3: Technical Report' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-24 00:00:00+0900+0900","children":"2025년 12월 24일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-24-INTELLECT-3-Technical-Report"}]]}]]}],["$","article","2025-12-24-Bottom-up-Policy-Optimization-Your-Language-Model-Policy-Secretly-Contains-Internal-Policies",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-24-Bottom-up-Policy-Optimization-Your-Language-Model-Policy-Secretly-Contains-Internal-Policies","children":"[논문리뷰] Bottom-up Policy Optimization: Your Language Model Policy Secretly Contains Internal Policies"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-24-Bottom-up-Policy-Optimization-Your-Language-Model-Policy-Secretly-Contains-Internal-Policies","children":"이 [arXiv]에 게시한 'Bottom-up Policy Optimization: Your Language Model Policy Secretly Contains Internal Policies' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-24 00:00:00+0900+0900","children":"2025년 12월 24일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-24-Bottom-up-Policy-Optimization-Your-Language-Model-Policy-Secretly-Contains-Internal-Policies"}]]}]]}],["$","article","2025-12-23-Can-LLMs-Estimate-Student-Struggles-Human-AI-Difficulty-Alignment-with-Proficiency-Simulation-for-Item-Difficulty-Prediction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-23-Can-LLMs-Estimate-Student-Struggles-Human-AI-Difficulty-Alignment-with-Proficiency-Simulation-for-Item-Difficulty-Prediction","children":"[논문리뷰] Can LLMs Estimate Student Struggles? Human-AI Difficulty Alignment with Proficiency Simulation for Item Difficulty Prediction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-23-Can-LLMs-Estimate-Student-Struggles-Human-AI-Difficulty-Alignment-with-Proficiency-Simulation-for-Item-Difficulty-Prediction","children":"Hong Jiao이 [arXiv]에 게시한 'Can LLMs Estimate Student Struggles? Human-AI Difficulty Alignment with Proficiency Simulation for Item Difficulty Prediction' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-23 00:00:00+0900+0900","children":"2025년 12월 23일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-23-Can-LLMs-Estimate-Student-Struggles-Human-AI-Difficulty-Alignment-with-Proficiency-Simulation-for-Item-Difficulty-Prediction"}]]}]]}],["$","article","2025-12-22-Seed-Prover-1-5-Mastering-Undergraduate-Level-Theorem-Proving-via-Learning-from-Experience",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-22-Seed-Prover-1-5-Mastering-Undergraduate-Level-Theorem-Proving-via-Learning-from-Experience","children":"[논문리뷰] Seed-Prover 1.5: Mastering Undergraduate-Level Theorem Proving via Learning from Experience"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-22-Seed-Prover-1-5-Mastering-Undergraduate-Level-Theorem-Proving-via-Learning-from-Experience","children":"이 [arXiv]에 게시한 'Seed-Prover 1.5: Mastering Undergraduate-Level Theorem Proving via Learning from Experience' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-22 00:00:00+0900+0900","children":"2025년 12월 22일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-22-Seed-Prover-1-5-Mastering-Undergraduate-Level-Theorem-Proving-via-Learning-from-Experience"}]]}]]}],["$","article","2025-12-19-Exploration-v-s-Exploitation-Rethinking-RLVR-through-Clipping-Entropy-and-Spurious-Reward",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-19-Exploration-v-s-Exploitation-Rethinking-RLVR-through-Clipping-Entropy-and-Spurious-Reward","children":"[논문리뷰] Exploration v.s. Exploitation: Rethinking RLVR through Clipping, Entropy, and Spurious Reward"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-19-Exploration-v-s-Exploitation-Rethinking-RLVR-through-Clipping-Entropy-and-Spurious-Reward","children":"이 [arXiv]에 게시한 'Exploration v.s. Exploitation: Rethinking RLVR through Clipping, Entropy, and Spurious Reward' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-19 00:00:00+0900+0900","children":"2025년 12월 19일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-19-Exploration-v-s-Exploitation-Rethinking-RLVR-through-Clipping-Entropy-and-Spurious-Reward"}]]}]]}],["$","article","2025-12-18-SAGE-Training-Smart-Any-Horizon-Agents-for-Long-Video-Reasoning-with-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-18-SAGE-Training-Smart-Any-Horizon-Agents-for-Long-Video-Reasoning-with-Reinforcement-Learning","children":"[논문리뷰] SAGE: Training Smart Any-Horizon Agents for Long Video Reasoning with Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-18-SAGE-Training-Smart-Any-Horizon-Agents-for-Long-Video-Reasoning-with-Reinforcement-Learning","children":"이 [arXiv]에 게시한 'SAGE: Training Smart Any-Horizon Agents for Long Video Reasoning with Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-18 00:00:00+0900+0900","children":"2025년 12월 18일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-18-SAGE-Training-Smart-Any-Horizon-Agents-for-Long-Video-Reasoning-with-Reinforcement-Learning"}]]}]]}],["$","article","2025-12-18-Can-LLMs-Guide-Their-Own-Exploration-Gradient-Guided-Reinforcement-Learning-for-LLM-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-18-Can-LLMs-Guide-Their-Own-Exploration-Gradient-Guided-Reinforcement-Learning-for-LLM-Reasoning","children":"[논문리뷰] Can LLMs Guide Their Own Exploration? Gradient-Guided Reinforcement Learning for LLM Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-18-Can-LLMs-Guide-Their-Own-Exploration-Gradient-Guided-Reinforcement-Learning-for-LLM-Reasoning","children":"이 [arXiv]에 게시한 'Can LLMs Guide Their Own Exploration? Gradient-Guided Reinforcement Learning for LLM Reasoning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-18 00:00:00+0900+0900","children":"2025년 12월 18일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-18-Can-LLMs-Guide-Their-Own-Exploration-Gradient-Guided-Reinforcement-Learning-for-LLM-Reasoning"}]]}]]}],["$","article","2025-12-17-RecGPT-V2-Technical-Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-17-RecGPT-V2-Technical-Report","children":"[논문리뷰] RecGPT-V2 Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-17-RecGPT-V2-Technical-Report","children":"Dian Chen이 [arXiv]에 게시한 'RecGPT-V2 Technical Report' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-17 00:00:00+0900+0900","children":"2025년 12월 17일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-17-RecGPT-V2-Technical-Report"}]]}]]}],["$","article","2025-12-17-Olmo-3",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-17-Olmo-3","children":"[논문리뷰] Olmo 3"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-17-Olmo-3","children":"이 [arXiv]에 게시한 'Olmo 3' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-17 00:00:00+0900+0900","children":"2025년 12월 17일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-17-Olmo-3"}]]}]]}],["$","article","2025-12-15-Sliding-Window-Attention-Adaptation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-15-Sliding-Window-Attention-Adaptation","children":"[논문리뷰] Sliding Window Attention Adaptation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-15-Sliding-Window-Attention-Adaptation","children":"이 [arXiv]에 게시한 'Sliding Window Attention Adaptation' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-15 00:00:00+0900+0900","children":"2025년 12월 15일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-15-Sliding-Window-Attention-Adaptation"}]]}]]}],["$","article","2025-12-11-EtCon-Edit-then-Consolidate-for-Reliable-Knowledge-Editing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-11-EtCon-Edit-then-Consolidate-for-Reliable-Knowledge-Editing","children":"[논문리뷰] EtCon: Edit-then-Consolidate for Reliable Knowledge Editing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-11-EtCon-Edit-then-Consolidate-for-Reliable-Knowledge-Editing","children":"Chenglin Li이 [arXiv]에 게시한 'EtCon: Edit-then-Consolidate for Reliable Knowledge Editing' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-11 00:00:00+0900+0900","children":"2025년 12월 11일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-11-EtCon-Edit-then-Consolidate-for-Reliable-Knowledge-Editing"}]]}]]}],["$","article","2025-12-09-Beyond-Token-level-Supervision-Unlocking-the-Potential-of-Decoding-based-Regression-via-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-09-Beyond-Token-level-Supervision-Unlocking-the-Potential-of-Decoding-based-Regression-via-Reinforcement-Learning","children":"[논문리뷰] Beyond Token-level Supervision: Unlocking the Potential of Decoding-based Regression via Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-09-Beyond-Token-level-Supervision-Unlocking-the-Potential-of-Decoding-based-Regression-via-Reinforcement-Learning","children":"Jiacheng Chen이 [arXiv]에 게시한 'Beyond Token-level Supervision: Unlocking the Potential of Decoding-based Regression via Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-09 00:00:00+0900+0900","children":"2025년 12월 9일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-09-Beyond-Token-level-Supervision-Unlocking-the-Potential-of-Decoding-based-Regression-via-Reinforcement-Learning"}]]}]]}],["$","article","2025-12-08-TwinFlow-Realizing-One-step-Generation-on-Large-Models-with-Self-adversarial-Flows",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-08-TwinFlow-Realizing-One-step-Generation-on-Large-Models-with-Self-adversarial-Flows","children":"[논문리뷰] TwinFlow: Realizing One-step Generation on Large Models with Self-adversarial Flows"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-08-TwinFlow-Realizing-One-step-Generation-on-Large-Models-with-Self-adversarial-Flows","children":"이 [arXiv]에 게시한 'TwinFlow: Realizing One-step Generation on Large Models with Self-adversarial Flows' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-08 00:00:00+0900+0900","children":"2025년 12월 8일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-08-TwinFlow-Realizing-One-step-Generation-on-Large-Models-with-Self-adversarial-Flows"}]]}]]}],["$","article","2025-12-08-From-Imitation-to-Discrimination-Toward-A-Generalized-Curriculum-Advantage-Mechanism-Enhancing-Cross-Domain-Reasoning-Tasks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-08-From-Imitation-to-Discrimination-Toward-A-Generalized-Curriculum-Advantage-Mechanism-Enhancing-Cross-Domain-Reasoning-Tasks","children":"[논문리뷰] From Imitation to Discrimination: Toward A Generalized Curriculum Advantage Mechanism Enhancing Cross-Domain Reasoning Tasks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-08-From-Imitation-to-Discrimination-Toward-A-Generalized-Curriculum-Advantage-Mechanism-Enhancing-Cross-Domain-Reasoning-Tasks","children":"Yang Li이 [arXiv]에 게시한 'From Imitation to Discrimination: Toward A Generalized Curriculum Advantage Mechanism Enhancing Cross-Domain Reasoning Tasks' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-08 00:00:00+0900+0900","children":"2025년 12월 8일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-08-From-Imitation-to-Discrimination-Toward-A-Generalized-Curriculum-Advantage-Mechanism-Enhancing-Cross-Domain-Reasoning-Tasks"}]]}]]}],["$","article","2025-12-08-Entropy-Ratio-Clipping-as-a-Soft-Global-Constraint-for-Stable-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-08-Entropy-Ratio-Clipping-as-a-Soft-Global-Constraint-for-Stable-Reinforcement-Learning","children":"[논문리뷰] Entropy Ratio Clipping as a Soft Global Constraint for Stable Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-08-Entropy-Ratio-Clipping-as-a-Soft-Global-Constraint-for-Stable-Reinforcement-Learning","children":"Zijia Lin이 [arXiv]에 게시한 'Entropy Ratio Clipping as a Soft Global Constraint for Stable Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-08 00:00:00+0900+0900","children":"2025년 12월 8일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-08-Entropy-Ratio-Clipping-as-a-Soft-Global-Constraint-for-Stable-Reinforcement-Learning"}]]}]]}],["$","article","2025-12-04-PretrainZero-Reinforcement-Active-Pretraining",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-04-PretrainZero-Reinforcement-Active-Pretraining","children":"[논문리뷰] PretrainZero: Reinforcement Active Pretraining"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-04-PretrainZero-Reinforcement-Active-Pretraining","children":"Guoqi Li이 [arXiv]에 게시한 'PretrainZero: Reinforcement Active Pretraining' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-04 00:00:00+0900+0900","children":"2025년 12월 4일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-04-PretrainZero-Reinforcement-Active-Pretraining"}]]}]]}],["$","article","2025-12-03-The-Curious-Case-of-Analogies-Investigating-Analogical-Reasoning-in-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-03-The-Curious-Case-of-Analogies-Investigating-Analogical-Reasoning-in-Large-Language-Models","children":"[논문리뷰] The Curious Case of Analogies: Investigating Analogical Reasoning in Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-03-The-Curious-Case-of-Analogies-Investigating-Analogical-Reasoning-in-Large-Language-Models","children":"이 [arXiv]에 게시한 'The Curious Case of Analogies: Investigating Analogical Reasoning in Large Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-03 00:00:00+0900+0900","children":"2025년 12월 3일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-03-The-Curious-Case-of-Analogies-Investigating-Analogical-Reasoning-in-Large-Language-Models"}]]}]]}],["$","article","2025-12-03-DeepSeek-V3-2-Pushing-the-Frontier-of-Open-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-03-DeepSeek-V3-2-Pushing-the-Frontier-of-Open-Large-Language-Models","children":"[논문리뷰] DeepSeek-V3.2: Pushing the Frontier of Open Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-03-DeepSeek-V3-2-Pushing-the-Frontier-of-Open-Large-Language-Models","children":"이 [arXiv]에 게시한 'DeepSeek-V3.2: Pushing the Frontier of Open Large Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-03 00:00:00+0900+0900","children":"2025년 12월 3일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-03-DeepSeek-V3-2-Pushing-the-Frontier-of-Open-Large-Language-Models"}]]}]]}],["$","article","2025-12-03-C2DLM-Causal-Concept-Guided-Diffusion-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-03-C2DLM-Causal-Concept-Guided-Diffusion-Large-Language-Models","children":"[논문리뷰] C^2DLM: Causal Concept-Guided Diffusion Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-03-C2DLM-Causal-Concept-Guided-Diffusion-Large-Language-Models","children":"Xinpeng Dong이 [arXiv]에 게시한 'C^2DLM: Causal Concept-Guided Diffusion Large Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-03 00:00:00+0900+0900","children":"2025년 12월 3일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-03-C2DLM-Causal-Concept-Guided-Diffusion-Large-Language-Models"}]]}]]}],["$","article","2025-12-02-Wikontic-Constructing-Wikidata-Aligned-Ontology-Aware-Knowledge-Graphs-with-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-02-Wikontic-Constructing-Wikidata-Aligned-Ontology-Aware-Knowledge-Graphs-with-Large-Language-Models","children":"[논문리뷰] Wikontic: Constructing Wikidata-Aligned, Ontology-Aware Knowledge Graphs with Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-02-Wikontic-Constructing-Wikidata-Aligned-Ontology-Aware-Knowledge-Graphs-with-Large-Language-Models","children":"Mikhail Burtsev이 [arXiv]에 게시한 'Wikontic: Constructing Wikidata-Aligned, Ontology-Aware Knowledge Graphs with Large Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-02 00:00:00+0900+0900","children":"2025년 12월 2일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-02-Wikontic-Constructing-Wikidata-Aligned-Ontology-Aware-Knowledge-Graphs-with-Large-Language-Models"}]]}]]}],["$","article","2025-12-02-PromptBridge-Cross-Model-Prompt-Transfer-for-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-02-PromptBridge-Cross-Model-Prompt-Transfer-for-Large-Language-Models","children":"[논문리뷰] PromptBridge: Cross-Model Prompt Transfer for Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-02-PromptBridge-Cross-Model-Prompt-Transfer-for-Large-Language-Models","children":"Wei Wei이 [arXiv]에 게시한 'PromptBridge: Cross-Model Prompt Transfer for Large Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-02 00:00:00+0900+0900","children":"2025년 12월 2일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-02-PromptBridge-Cross-Model-Prompt-Transfer-for-Large-Language-Models"}]]}]]}],["$","article","2025-12-02-OmniFusion-Simultaneous-Multilingual-Multimodal-Translations-via-Modular-Fusion",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-02-OmniFusion-Simultaneous-Multilingual-Multimodal-Translations-via-Modular-Fusion","children":"[논문리뷰] OmniFusion: Simultaneous Multilingual Multimodal Translations via Modular Fusion"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-02-OmniFusion-Simultaneous-Multilingual-Multimodal-Translations-via-Modular-Fusion","children":"이 [arXiv]에 게시한 'OmniFusion: Simultaneous Multilingual Multimodal Translations via Modular Fusion' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-02 00:00:00+0900+0900","children":"2025년 12월 2일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-02-OmniFusion-Simultaneous-Multilingual-Multimodal-Translations-via-Modular-Fusion"}]]}]]}],["$","article","2025-12-02-Generalist-Large-Language-Models-Outperform-Clinical-Tools-on-Medical-Benchmarks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-02-Generalist-Large-Language-Models-Outperform-Clinical-Tools-on-Medical-Benchmarks","children":"[논문리뷰] Generalist Large Language Models Outperform Clinical Tools on Medical Benchmarks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-02-Generalist-Large-Language-Models-Outperform-Clinical-Tools-on-Medical-Benchmarks","children":"이 [arXiv]에 게시한 'Generalist Large Language Models Outperform Clinical Tools on Medical Benchmarks' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-02 00:00:00+0900+0900","children":"2025년 12월 2일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-02-Generalist-Large-Language-Models-Outperform-Clinical-Tools-on-Medical-Benchmarks"}]]}]]}],["$","article","2025-12-02-Agentic-Policy-Optimization-via-Instruction-Policy-Co-Evolution",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-02-Agentic-Policy-Optimization-via-Instruction-Policy-Co-Evolution","children":"[논문리뷰] Agentic Policy Optimization via Instruction-Policy Co-Evolution"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-02-Agentic-Policy-Optimization-via-Instruction-Policy-Co-Evolution","children":"이 [arXiv]에 게시한 'Agentic Policy Optimization via Instruction-Policy Co-Evolution' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-02 00:00:00+0900+0900","children":"2025년 12월 2일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-02-Agentic-Policy-Optimization-via-Instruction-Policy-Co-Evolution"}]]}]]}],["$","article","2025-12-01-Every-Token-Counts-Generalizing-16M-Ultra-Long-Context-in-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-12-01-Every-Token-Counts-Generalizing-16M-Ultra-Long-Context-in-Large-Language-Models","children":"[논문리뷰] Every Token Counts: Generalizing 16M Ultra-Long Context in Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-12-01-Every-Token-Counts-Generalizing-16M-Ultra-Long-Context-in-Large-Language-Models","children":"Wei Wu이 [arXiv]에 게시한 'Every Token Counts: Generalizing 16M Ultra-Long Context in Large Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-12-01 00:00:00+0900+0900","children":"2025년 12월 1일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-12-01-Every-Token-Counts-Generalizing-16M-Ultra-Long-Context-in-Large-Language-Models"}]]}]]}],["$","article","2025-11-28-What-does-it-mean-to-understand-language",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-28-What-does-it-mean-to-understand-language","children":"[논문리뷰] What does it mean to understand language?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-28-What-does-it-mean-to-understand-language","children":"이 [arXiv]에 게시한 'What does it mean to understand language?' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-28 00:00:00+0900+0900","children":"2025년 11월 28일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-28-What-does-it-mean-to-understand-language"}]]}]]}],["$","article","2025-11-27-Latent-Collaboration-in-Multi-Agent-Systems",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-27-Latent-Collaboration-in-Multi-Agent-Systems","children":"[논문리뷰] Latent Collaboration in Multi-Agent Systems"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-27-Latent-Collaboration-in-Multi-Agent-Systems","children":"이 [arXiv]에 게시한 'Latent Collaboration in Multi-Agent Systems' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-27 00:00:00+0900+0900","children":"2025년 11월 27일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-27-Latent-Collaboration-in-Multi-Agent-Systems"}]]}]]}],["$","article","2025-11-26-YoCity-Personalized-and-Boundless-3D-Realistic-City-Scene-Generation-via-Self-Critic-Expansion",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-26-YoCity-Personalized-and-Boundless-3D-Realistic-City-Scene-Generation-via-Self-Critic-Expansion","children":"[논문리뷰] Yo'City: Personalized and Boundless 3D Realistic City Scene Generation via Self-Critic Expansion"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-26-YoCity-Personalized-and-Boundless-3D-Realistic-City-Scene-Generation-via-Self-Critic-Expansion","children":"Zhifei Yang이 [arXiv]에 게시한 'Yo'City: Personalized and Boundless 3D Realistic City Scene Generation via Self-Critic Expansion' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-26 00:00:00+0900+0900","children":"2025년 11월 26일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-26-YoCity-Personalized-and-Boundless-3D-Realistic-City-Scene-Generation-via-Self-Critic-Expansion"}]]}]]}],["$","article","2025-11-26-Soft-Adaptive-Policy-Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-26-Soft-Adaptive-Policy-Optimization","children":"[논문리뷰] Soft Adaptive Policy Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-26-Soft-Adaptive-Policy-Optimization","children":"이 [arXiv]에 게시한 'Soft Adaptive Policy Optimization' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-26 00:00:00+0900+0900","children":"2025년 11월 26일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-26-Soft-Adaptive-Policy-Optimization"}]]}]]}],["$","article","2025-11-26-SciEducator-Scientific-Video-Understanding-and-Educating-via-Deming-Cycle-Multi-Agent-System",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-26-SciEducator-Scientific-Video-Understanding-and-Educating-via-Deming-Cycle-Multi-Agent-System","children":"[논문리뷰] SciEducator: Scientific Video Understanding and Educating via Deming-Cycle Multi-Agent System"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-26-SciEducator-Scientific-Video-Understanding-and-Educating-via-Deming-Cycle-Multi-Agent-System","children":"이 [arXiv]에 게시한 'SciEducator: Scientific Video Understanding and Educating via Deming-Cycle Multi-Agent System' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-26 00:00:00+0900+0900","children":"2025년 11월 26일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-26-SciEducator-Scientific-Video-Understanding-and-Educating-via-Deming-Cycle-Multi-Agent-System"}]]}]]}],["$","article","2025-11-25-PRInTS-Reward-Modeling-for-Long-Horizon-Information-Seeking",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-25-PRInTS-Reward-Modeling-for-Long-Horizon-Information-Seeking","children":"[논문리뷰] PRInTS: Reward Modeling for Long-Horizon Information Seeking"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-25-PRInTS-Reward-Modeling-for-Long-Horizon-Information-Seeking","children":"Elias Stengel-Eskin이 [arXiv]에 게시한 'PRInTS: Reward Modeling for Long-Horizon Information Seeking' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-25 00:00:00+0900+0900","children":"2025년 11월 25일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-25-PRInTS-Reward-Modeling-for-Long-Horizon-Information-Seeking"}]]}]]}],["$","article","2025-11-25-AICC-Parse-HTML-Finer-Make-Models-Better-A-7-3T-AI-Ready-Corpus-Built-by-a-Model-Based-HTML-Parser",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-25-AICC-Parse-HTML-Finer-Make-Models-Better-A-7-3T-AI-Ready-Corpus-Built-by-a-Model-Based-HTML-Parser","children":"[논문리뷰] AICC: Parse HTML Finer, Make Models Better -- A 7.3T AI-Ready Corpus Built by a Model-Based HTML Parser"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-25-AICC-Parse-HTML-Finer-Make-Models-Better-A-7-3T-AI-Ready-Corpus-Built-by-a-Model-Based-HTML-Parser","children":"이 [arXiv]에 게시한 'AICC: Parse HTML Finer, Make Models Better -- A 7.3T AI-Ready Corpus Built by a Model-Based HTML Parser' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-25 00:00:00+0900+0900","children":"2025년 11월 25일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-25-AICC-Parse-HTML-Finer-Make-Models-Better-A-7-3T-AI-Ready-Corpus-Built-by-a-Model-Based-HTML-Parser"}]]}]]}],["$","article","2025-11-20-ARC-Chapter-Structuring-Hour-Long-Videos-into-Navigable-Chapters-and-Hierarchical-Summaries",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-20-ARC-Chapter-Structuring-Hour-Long-Videos-into-Navigable-Chapters-and-Hierarchical-Summaries","children":"[논문리뷰] ARC-Chapter: Structuring Hour-Long Videos into Navigable Chapters and Hierarchical Summaries"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-20-ARC-Chapter-Structuring-Hour-Long-Videos-into-Navigable-Chapters-and-Hierarchical-Summaries","children":"이 [arXiv]에 게시한 'ARC-Chapter: Structuring Hour-Long Videos into Navigable Chapters and Hierarchical Summaries' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-20 00:00:00+0900+0900","children":"2025년 11월 20일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-20-ARC-Chapter-Structuring-Hour-Long-Videos-into-Navigable-Chapters-and-Hierarchical-Summaries"}]]}]]}],["$","article","2025-11-19-OmniZip-Audio-Guided-Dynamic-Token-Compression-for-Fast-Omnimodal-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-19-OmniZip-Audio-Guided-Dynamic-Token-Compression-for-Fast-Omnimodal-Large-Language-Models","children":"[논문리뷰] OmniZip: Audio-Guided Dynamic Token Compression for Fast Omnimodal Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-19-OmniZip-Audio-Guided-Dynamic-Token-Compression-for-Fast-Omnimodal-Large-Language-Models","children":"Jian liu이 [arXiv]에 게시한 'OmniZip: Audio-Guided Dynamic Token Compression for Fast Omnimodal Large Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-19 00:00:00+0900+0900","children":"2025년 11월 19일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-19-OmniZip-Audio-Guided-Dynamic-Token-Compression-for-Fast-Omnimodal-Large-Language-Models"}]]}]]}],["$","article","2025-11-19-Mitigating-Label-Length-Bias-in-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-19-Mitigating-Label-Length-Bias-in-Large-Language-Models","children":"[논문리뷰] Mitigating Label Length Bias in Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-19-Mitigating-Label-Length-Bias-in-Large-Language-Models","children":"Katharina von der Wense이 [arXiv]에 게시한 'Mitigating Label Length Bias in Large Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-19 00:00:00+0900+0900","children":"2025년 11월 19일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-19-Mitigating-Label-Length-Bias-in-Large-Language-Models"}]]}]]}],["$","article","2025-11-19-LLM-Powered-Fully-Automated-Chaos-Engineering-Towards-Enabling-Anyone-to-Build-Resilient-Software-Systems-at-Low-Cost",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-19-LLM-Powered-Fully-Automated-Chaos-Engineering-Towards-Enabling-Anyone-to-Build-Resilient-Software-Systems-at-Low-Cost","children":"[논문리뷰] LLM-Powered Fully Automated Chaos Engineering: Towards Enabling Anyone to Build Resilient Software Systems at Low Cost"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-19-LLM-Powered-Fully-Automated-Chaos-Engineering-Towards-Enabling-Anyone-to-Build-Resilient-Software-Systems-at-Low-Cost","children":"Kengo Tajiri이 [arXiv]에 게시한 'LLM-Powered Fully Automated Chaos Engineering: Towards Enabling Anyone to Build Resilient Software Systems at Low Cost' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-19 00:00:00+0900+0900","children":"2025년 11월 19일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-19-LLM-Powered-Fully-Automated-Chaos-Engineering-Towards-Enabling-Anyone-to-Build-Resilient-Software-Systems-at-Low-Cost"}]]}]]}],["$","article","2025-11-18-Souper-Model-How-Simple-Arithmetic-Unlocks-State-of-the-Art-LLM-Performance",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-18-Souper-Model-How-Simple-Arithmetic-Unlocks-State-of-the-Art-LLM-Performance","children":"[논문리뷰] Souper-Model: How Simple Arithmetic Unlocks State-of-the-Art LLM Performance"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-18-Souper-Model-How-Simple-Arithmetic-Unlocks-State-of-the-Art-LLM-Performance","children":"이 [arXiv]에 게시한 'Souper-Model: How Simple Arithmetic Unlocks State-of-the-Art LLM Performance' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-18 00:00:00+0900+0900","children":"2025년 11월 18일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-18-Souper-Model-How-Simple-Arithmetic-Unlocks-State-of-the-Art-LLM-Performance"}]]}]]}],["$","article","2025-11-18-P1-Mastering-Physics-Olympiads-with-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-18-P1-Mastering-Physics-Olympiads-with-Reinforcement-Learning","children":"[논문리뷰] P1: Mastering Physics Olympiads with Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-18-P1-Mastering-Physics-Olympiads-with-Reinforcement-Learning","children":"Haiyuan Wan이 [arXiv]에 게시한 'P1: Mastering Physics Olympiads with Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-18 00:00:00+0900+0900","children":"2025년 11월 18일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-18-P1-Mastering-Physics-Olympiads-with-Reinforcement-Learning"}]]}]]}],["$","article","2025-11-18-MiroThinker-Pushing-the-Performance-Boundaries-of-Open-Source-Research-Agents-via-Model-Context-and-Interactive-Scaling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-18-MiroThinker-Pushing-the-Performance-Boundaries-of-Open-Source-Research-Agents-via-Model-Context-and-Interactive-Scaling","children":"[논문리뷰] MiroThinker: Pushing the Performance Boundaries of Open-Source Research Agents via Model, Context, and Interactive Scaling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-18-MiroThinker-Pushing-the-Performance-Boundaries-of-Open-Source-Research-Agents-via-Model-Context-and-Interactive-Scaling","children":"cyyang822이 [arXiv]에 게시한 'MiroThinker: Pushing the Performance Boundaries of Open-Source Research Agents via Model, Context, and Interactive Scaling' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-18 00:00:00+0900+0900","children":"2025년 11월 18일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-18-MiroThinker-Pushing-the-Performance-Boundaries-of-Open-Source-Research-Agents-via-Model-Context-and-Interactive-Scaling"}]]}]]}],["$","article","2025-11-18-AI-Salesman-Towards-Reliable-Large-Language-Model-Driven-Telemarketing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-18-AI-Salesman-Towards-Reliable-Large-Language-Model-Driven-Telemarketing","children":"[논문리뷰] AI-Salesman: Towards Reliable Large Language Model Driven Telemarketing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-18-AI-Salesman-Towards-Reliable-Large-Language-Model-Driven-Telemarketing","children":"Hongyu Lin이 [arXiv]에 게시한 'AI-Salesman: Towards Reliable Large Language Model Driven Telemarketing' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-18 00:00:00+0900+0900","children":"2025년 11월 18일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-18-AI-Salesman-Towards-Reliable-Large-Language-Model-Driven-Telemarketing"}]]}]]}],["$","article","2025-11-18-A-Decentralized-Retrieval-Augmented-Generation-System-with-Source-Reliabilities-Secured-on-Blockchain",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-18-A-Decentralized-Retrieval-Augmented-Generation-System-with-Source-Reliabilities-Secured-on-Blockchain","children":"[논문리뷰] A Decentralized Retrieval Augmented Generation System with Source Reliabilities Secured on Blockchain"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-18-A-Decentralized-Retrieval-Augmented-Generation-System-with-Source-Reliabilities-Secured-on-Blockchain","children":"Meng Jiang이 [arXiv]에 게시한 'A Decentralized Retrieval Augmented Generation System with Source Reliabilities Secured on Blockchain' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-18 00:00:00+0900+0900","children":"2025년 11월 18일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-18-A-Decentralized-Retrieval-Augmented-Generation-System-with-Source-Reliabilities-Secured-on-Blockchain"}]]}]]}],["$","article","2025-11-17-miniF2F-Lean-Revisited-Reviewing-Limitations-and-Charting-a-Path-Forward",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-17-miniF2F-Lean-Revisited-Reviewing-Limitations-and-Charting-a-Path-Forward","children":"[논문리뷰] miniF2F-Lean Revisited: Reviewing Limitations and Charting a Path Forward"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-17-miniF2F-Lean-Revisited-Reviewing-Limitations-and-Charting-a-Path-Forward","children":"Farzan Farnia이 [arXiv]에 게시한 'miniF2F-Lean Revisited: Reviewing Limitations and Charting a Path Forward' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-17 00:00:00+0900+0900","children":"2025년 11월 17일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-17-miniF2F-Lean-Revisited-Reviewing-Limitations-and-Charting-a-Path-Forward"}]]}]]}],["$","article","2025-11-17-Large-Language-Models-for-Scientific-Idea-Generation-A-Creativity-Centered-Survey",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-17-Large-Language-Models-for-Scientific-Idea-Generation-A-Creativity-Centered-Survey","children":"[논문리뷰] Large Language Models for Scientific Idea Generation: A Creativity-Centered Survey"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-17-Large-Language-Models-for-Scientific-Idea-Generation-A-Creativity-Centered-Survey","children":"Mohammad Hossein Rohban이 [arXiv]에 게시한 'Large Language Models for Scientific Idea Generation: A Creativity-Centered Survey' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-17 00:00:00+0900+0900","children":"2025년 11월 17일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-17-Large-Language-Models-for-Scientific-Idea-Generation-A-Creativity-Centered-Survey"}]]}]]}],["$","article","2025-11-17-DoPE-Denoising-Rotary-Position-Embedding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-17-DoPE-Denoising-Rotary-Position-Embedding","children":"[논문리뷰] DoPE: Denoising Rotary Position Embedding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-17-DoPE-Denoising-Rotary-Position-Embedding","children":"Min Yang이 [arXiv]에 게시한 'DoPE: Denoising Rotary Position Embedding' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-17 00:00:00+0900+0900","children":"2025년 11월 17일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-17-DoPE-Denoising-Rotary-Position-Embedding"}]]}]]}],["$","article","2025-11-14-Superpositional-Gradient-Descent-Harnessing-Quantum-Principles-for-Model-Training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-14-Superpositional-Gradient-Descent-Harnessing-Quantum-Principles-for-Model-Training","children":"[논문리뷰] Superpositional Gradient Descent: Harnessing Quantum Principles for   Model Training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-14-Superpositional-Gradient-Descent-Harnessing-Quantum-Principles-for-Model-Training","children":"suayptalha이 [arXiv]에 게시한 'Superpositional Gradient Descent: Harnessing Quantum Principles for   Model Training' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-14 00:00:00+0900+0900","children":"2025년 11월 14일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-14-Superpositional-Gradient-Descent-Harnessing-Quantum-Principles-for-Model-Training"}]]}]]}],["$","article","2025-11-14-CC30k-A-Citation-Contexts-Dataset-for-Reproducibility-Oriented-Sentiment-Analysis",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-14-CC30k-A-Citation-Contexts-Dataset-for-Reproducibility-Oriented-Sentiment-Analysis","children":"[논문리뷰] CC30k: A Citation Contexts Dataset for Reproducibility-Oriented Sentiment Analysis"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-14-CC30k-A-Citation-Contexts-Dataset-for-Reproducibility-Oriented-Sentiment-Analysis","children":"Jian Wu이 [arXiv]에 게시한 'CC30k: A Citation Contexts Dataset for Reproducibility-Oriented Sentiment Analysis' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-14 00:00:00+0900+0900","children":"2025년 11월 14일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-14-CC30k-A-Citation-Contexts-Dataset-for-Reproducibility-Oriented-Sentiment-Analysis"}]]}]]}],["$","article","2025-11-13-Agentic-Refactoring-An-Empirical-Study-of-AI-Coding-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-13-Agentic-Refactoring-An-Empirical-Study-of-AI-Coding-Agents","children":"[논문리뷰] Agentic Refactoring: An Empirical Study of AI Coding Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-13-Agentic-Refactoring-An-Empirical-Study-of-AI-Coding-Agents","children":"Hajimu Iida이 [arXiv]에 게시한 'Agentic Refactoring: An Empirical Study of AI Coding Agents' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-13 00:00:00+0900+0900","children":"2025년 11월 13일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-13-Agentic-Refactoring-An-Empirical-Study-of-AI-Coding-Agents"}]]}]]}],["$","article","2025-11-12-Wasm-A-Pipeline-for-Constructing-Structured-Arabic-Interleaved-Multimodal-Corpora",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-12-Wasm-A-Pipeline-for-Constructing-Structured-Arabic-Interleaved-Multimodal-Corpora","children":"[논문리뷰] Wasm: A Pipeline for Constructing Structured Arabic Interleaved   Multimodal Corpora"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-12-Wasm-A-Pipeline-for-Constructing-Structured-Arabic-Interleaved-Multimodal-Corpora","children":"Mohamed Motasim Hamed이 [arXiv]에 게시한 'Wasm: A Pipeline for Constructing Structured Arabic Interleaved   Multimodal Corpora' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-12 00:00:00+0900+0900","children":"2025년 11월 12일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-12-Wasm-A-Pipeline-for-Constructing-Structured-Arabic-Interleaved-Multimodal-Corpora"}]]}]]}],["$","article","2025-11-12-Walking-the-Tightrope-of-LLMs-for-Software-Development-A-Practitioners-Perspective",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-12-Walking-the-Tightrope-of-LLMs-for-Software-Development-A-Practitioners-Perspective","children":"[논문리뷰] Walking the Tightrope of LLMs for Software Development: A Practitioners' Perspective"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-12-Walking-the-Tightrope-of-LLMs-for-Software-Development-A-Practitioners-Perspective","children":"Christoph Treude이 [arXiv]에 게시한 'Walking the Tightrope of LLMs for Software Development: A Practitioners' Perspective' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-12 00:00:00+0900+0900","children":"2025년 11월 12일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-12-Walking-the-Tightrope-of-LLMs-for-Software-Development-A-Practitioners-Perspective"}]]}]]}],["$","article","2025-11-12-The-Path-Not-Taken-RLVR-Provably-Learns-Off-the-Principals",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-12-The-Path-Not-Taken-RLVR-Provably-Learns-Off-the-Principals","children":"[논문리뷰] The Path Not Taken: RLVR Provably Learns Off the Principals"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-12-The-Path-Not-Taken-RLVR-Provably-Learns-Off-the-Principals","children":"이 [arXiv]에 게시한 'The Path Not Taken: RLVR Provably Learns Off the Principals' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-12 00:00:00+0900+0900","children":"2025년 11월 12일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-12-The-Path-Not-Taken-RLVR-Provably-Learns-Off-the-Principals"}]]}]]}],["$","article","2025-11-12-Optimizing-Diversity-and-Quality-through-Base-Aligned-Model-Collaboration",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-12-Optimizing-Diversity-and-Quality-through-Base-Aligned-Model-Collaboration","children":"[논문리뷰] Optimizing Diversity and Quality through Base-Aligned Model Collaboration"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-12-Optimizing-Diversity-and-Quality-through-Base-Aligned-Model-Collaboration","children":"Jonathan May이 [arXiv]에 게시한 'Optimizing Diversity and Quality through Base-Aligned Model Collaboration' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-12 00:00:00+0900+0900","children":"2025년 11월 12일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-12-Optimizing-Diversity-and-Quality-through-Base-Aligned-Model-Collaboration"}]]}]]}],["$","article","2025-11-12-DynaAct-Large-Language-Model-Reasoning-with-Dynamic-Action-Spaces",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-12-DynaAct-Large-Language-Model-Reasoning-with-Dynamic-Action-Spaces","children":"[논문리뷰] DynaAct: Large Language Model Reasoning with Dynamic Action Spaces"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-12-DynaAct-Large-Language-Model-Reasoning-with-Dynamic-Action-Spaces","children":"Lingpeng Kong이 [arXiv]에 게시한 'DynaAct: Large Language Model Reasoning with Dynamic Action Spaces' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-12 00:00:00+0900+0900","children":"2025년 11월 12일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-12-DynaAct-Large-Language-Model-Reasoning-with-Dynamic-Action-Spaces"}]]}]]}],["$","article","2025-11-12-Beyond-English-Toward-Inclusive-and-Scalable-Multilingual-Machine-Translation-with-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-12-Beyond-English-Toward-Inclusive-and-Scalable-Multilingual-Machine-Translation-with-LLMs","children":"[논문리뷰] Beyond English: Toward Inclusive and Scalable Multilingual Machine Translation with LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-12-Beyond-English-Toward-Inclusive-and-Scalable-Multilingual-Machine-Translation-with-LLMs","children":"이 [arXiv]에 게시한 'Beyond English: Toward Inclusive and Scalable Multilingual Machine Translation with LLMs' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-12 00:00:00+0900+0900","children":"2025년 11월 12일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-12-Beyond-English-Toward-Inclusive-and-Scalable-Multilingual-Machine-Translation-with-LLMs"}]]}]]}],["$","article","2025-11-12-Adaptive-Multi-Agent-Response-Refinement-in-Conversational-Systems",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-12-Adaptive-Multi-Agent-Response-Refinement-in-Conversational-Systems","children":"[논문리뷰] Adaptive Multi-Agent Response Refinement in Conversational Systems"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-12-Adaptive-Multi-Agent-Response-Refinement-in-Conversational-Systems","children":"이 [arXiv]에 게시한 'Adaptive Multi-Agent Response Refinement in Conversational Systems' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-12 00:00:00+0900+0900","children":"2025년 11월 12일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-12-Adaptive-Multi-Agent-Response-Refinement-in-Conversational-Systems"}]]}]]}],["$","article","2025-11-11-VADER-Towards-Causal-Video-Anomaly-Understanding-with-Relation-Aware-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-VADER-Towards-Causal-Video-Anomaly-Understanding-with-Relation-Aware-Large-Language-Models","children":"[논문리뷰] VADER: Towards Causal Video Anomaly Understanding with Relation-Aware   Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-VADER-Towards-Causal-Video-Anomaly-Understanding-with-Relation-Aware-Large-Language-Models","children":"이 [arXiv]에 게시한 'VADER: Towards Causal Video Anomaly Understanding with Relation-Aware   Large Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-11 00:00:00+0900+0900","children":"2025년 11월 11일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-11-VADER-Towards-Causal-Video-Anomaly-Understanding-with-Relation-Aware-Large-Language-Models"}]]}]]}],["$","article","2025-11-11-The-Station-An-Open-World-Environment-for-AI-Driven-Discovery",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-The-Station-An-Open-World-Environment-for-AI-Driven-Discovery","children":"[논문리뷰] The Station: An Open-World Environment for AI-Driven Discovery"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-The-Station-An-Open-World-Environment-for-AI-Driven-Discovery","children":"wydu이 [arXiv]에 게시한 'The Station: An Open-World Environment for AI-Driven Discovery' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-11 00:00:00+0900+0900","children":"2025년 11월 11일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-11-The-Station-An-Open-World-Environment-for-AI-Driven-Discovery"}]]}]]}],["$","article","2025-11-11-Reinforcement-Learning-Improves-Traversal-of-Hierarchical-Knowledge-in-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-Reinforcement-Learning-Improves-Traversal-of-Hierarchical-Knowledge-in-LLMs","children":"[논문리뷰] Reinforcement Learning Improves Traversal of Hierarchical Knowledge in LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-Reinforcement-Learning-Improves-Traversal-of-Hierarchical-Knowledge-in-LLMs","children":"이 [arXiv]에 게시한 'Reinforcement Learning Improves Traversal of Hierarchical Knowledge in LLMs' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-11 00:00:00+0900+0900","children":"2025년 11월 11일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-11-Reinforcement-Learning-Improves-Traversal-of-Hierarchical-Knowledge-in-LLMs"}]]}]]}],["$","article","2025-11-11-Omni-AVSR-Towards-Unified-Multimodal-Speech-Recognition-with-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-Omni-AVSR-Towards-Unified-Multimodal-Speech-Recognition-with-Large-Language-Models","children":"[논문리뷰] Omni-AVSR: Towards Unified Multimodal Speech Recognition with Large   Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-Omni-AVSR-Towards-Unified-Multimodal-Speech-Recognition-with-Large-Language-Models","children":"이 [arXiv]에 게시한 'Omni-AVSR: Towards Unified Multimodal Speech Recognition with Large   Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-11 00:00:00+0900+0900","children":"2025년 11월 11일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-11-Omni-AVSR-Towards-Unified-Multimodal-Speech-Recognition-with-Large-Language-Models"}]]}]]}],["$","article","2025-11-11-NURBGen-High-Fidelity-Text-to-CAD-Generation-through-LLM-Driven-NURBS-Modeling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-NURBGen-High-Fidelity-Text-to-CAD-Generation-through-LLM-Driven-NURBS-Modeling","children":"[논문리뷰] NURBGen: High-Fidelity Text-to-CAD Generation through LLM-Driven NURBS   Modeling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-NURBGen-High-Fidelity-Text-to-CAD-Generation-through-LLM-Driven-NURBS-Modeling","children":"이 [arXiv]에 게시한 'NURBGen: High-Fidelity Text-to-CAD Generation through LLM-Driven NURBS   Modeling' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-11 00:00:00+0900+0900","children":"2025년 11월 11일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-11-NURBGen-High-Fidelity-Text-to-CAD-Generation-through-LLM-Driven-NURBS-Modeling"}]]}]]}],["$","article","2025-11-11-Do-LLMs-Feel-Teaching-Emotion-Recognition-with-Prompts-Retrieval-and-Curriculum-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-Do-LLMs-Feel-Teaching-Emotion-Recognition-with-Prompts-Retrieval-and-Curriculum-Learning","children":"[논문리뷰] Do LLMs Feel? Teaching Emotion Recognition with Prompts, Retrieval, and   Curriculum Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-Do-LLMs-Feel-Teaching-Emotion-Recognition-with-Prompts-Retrieval-and-Curriculum-Learning","children":"이 [arXiv]에 게시한 'Do LLMs Feel? Teaching Emotion Recognition with Prompts, Retrieval, and   Curriculum Learning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-11 00:00:00+0900+0900","children":"2025년 11월 11일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-11-Do-LLMs-Feel-Teaching-Emotion-Recognition-with-Prompts-Retrieval-and-Curriculum-Learning"}]]}]]}],["$","article","2025-11-10-VeriCoT-Neuro-symbolic-Chain-of-Thought-Validation-via-Logical-Consistency-Checks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-10-VeriCoT-Neuro-symbolic-Chain-of-Thought-Validation-via-Logical-Consistency-Checks","children":"[논문리뷰] VeriCoT: Neuro-symbolic Chain-of-Thought Validation via Logical Consistency Checks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-10-VeriCoT-Neuro-symbolic-Chain-of-Thought-Validation-via-Logical-Consistency-Checks","children":"이 [arXiv]에 게시한 'VeriCoT: Neuro-symbolic Chain-of-Thought Validation via Logical Consistency Checks' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-10 00:00:00+0900+0900","children":"2025년 11월 10일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-10-VeriCoT-Neuro-symbolic-Chain-of-Thought-Validation-via-Logical-Consistency-Checks"}]]}]]}],["$","article","2025-11-10-HAFixAgent-History-Aware-Automated-Program-Repair-Agent",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-10-HAFixAgent-History-Aware-Automated-Program-Repair-Agent","children":"[논문리뷰] HAFixAgent: History-Aware Automated Program Repair Agent"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-10-HAFixAgent-History-Aware-Automated-Program-Repair-Agent","children":"Ahmed E. Hassan이 [arXiv]에 게시한 'HAFixAgent: History-Aware Automated Program Repair Agent' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-10 00:00:00+0900+0900","children":"2025년 11월 10일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-10-HAFixAgent-History-Aware-Automated-Program-Repair-Agent"}]]}]]}],["$","article","2025-11-10-Dense-Motion-Captioning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-10-Dense-Motion-Captioning","children":"[논문리뷰] Dense Motion Captioning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-10-Dense-Motion-Captioning","children":"Paolo Rota이 [arXiv]에 게시한 'Dense Motion Captioning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-10 00:00:00+0900+0900","children":"2025년 11월 10일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-10-Dense-Motion-Captioning"}]]}]]}],["$","article","2025-11-6-Grounded-Misunderstandings-in-Asymmetric-Dialogue-A-Perspectivist-Annotation-Scheme-for-MapTask",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-6-Grounded-Misunderstandings-in-Asymmetric-Dialogue-A-Perspectivist-Annotation-Scheme-for-MapTask","children":"[논문리뷰] Grounded Misunderstandings in Asymmetric Dialogue: A Perspectivist Annotation Scheme for MapTask"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-6-Grounded-Misunderstandings-in-Asymmetric-Dialogue-A-Perspectivist-Annotation-Scheme-for-MapTask","children":"이 [arXiv]에 게시한 'Grounded Misunderstandings in Asymmetric Dialogue: A Perspectivist Annotation Scheme for MapTask' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 21:54:30+0900","children":"2025년 11월 9일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-6-Grounded-Misunderstandings-in-Asymmetric-Dialogue-A-Perspectivist-Annotation-Scheme-for-MapTask"}]]}]]}],["$","article","2025-11-5-Forget-BIT-It-is-All-about-TOKEN-Towards-Semantic-Information-Theory-for-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-5-Forget-BIT-It-is-All-about-TOKEN-Towards-Semantic-Information-Theory-for-LLMs","children":"[논문리뷰] Forget BIT, It is All about TOKEN: Towards Semantic Information Theory for LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-5-Forget-BIT-It-is-All-about-TOKEN-Towards-Semantic-Information-Theory-for-LLMs","children":"Bo Bai이 [arXiv]에 게시한 'Forget BIT, It is All about TOKEN: Towards Semantic Information Theory for LLMs' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:35:02+0900","children":"2025년 11월 9일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-5-Forget-BIT-It-is-All-about-TOKEN-Towards-Semantic-Information-Theory-for-LLMs"}]]}]]}],["$","article","2025-11-4-OpenSIR-Open-Ended-Self-Improving-Reasoner",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-OpenSIR-Open-Ended-Self-Improving-Reasoner","children":"[논문리뷰] OpenSIR: Open-Ended Self-Improving Reasoner"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-OpenSIR-Open-Ended-Self-Improving-Reasoner","children":"이 [arXiv]에 게시한 'OpenSIR: Open-Ended Self-Improving Reasoner' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:22:42+0900","children":"2025년 11월 9일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-4-OpenSIR-Open-Ended-Self-Improving-Reasoner"}]]}]]}],["$","article","2025-11-4-Every-Activation-Boosted-Scaling-General-Reasoner-to-1-Trillion-Open-Language-Foundation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-Every-Activation-Boosted-Scaling-General-Reasoner-to-1-Trillion-Open-Language-Foundation","children":"[논문리뷰] Every Activation Boosted: Scaling General Reasoner to 1 Trillion Open Language Foundation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-Every-Activation-Boosted-Scaling-General-Reasoner-to-1-Trillion-Open-Language-Foundation","children":"이 [arXiv]에 게시한 'Every Activation Boosted: Scaling General Reasoner to 1 Trillion Open Language Foundation' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:22:42+0900","children":"2025년 11월 9일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-4-Every-Activation-Boosted-Scaling-General-Reasoner-to-1-Trillion-Open-Language-Foundation"}]]}]]}],["$","article","2025-11-3-Rank-GRPO-Training-LLM-based-Conversational-Recommender-Systems-with-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-3-Rank-GRPO-Training-LLM-based-Conversational-Recommender-Systems-with-Reinforcement-Learning","children":"[논문리뷰] Rank-GRPO: Training LLM-based Conversational Recommender Systems with Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-11-3-Rank-GRPO-Training-LLM-based-Conversational-Recommender-Systems-with-Reinforcement-Learning","children":"이 [arXiv]에 게시한 'Rank-GRPO: Training LLM-based Conversational Recommender Systems with Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:01:31+0900","children":"2025년 11월 9일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-11-3-Rank-GRPO-Training-LLM-based-Conversational-Recommender-Systems-with-Reinforcement-Learning"}]]}]]}],["$","article","2025-10-31-EHR-R1-A-Reasoning-Enhanced-Foundational-Language-Model-for-Electronic-Health-Record-Analysis",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-EHR-R1-A-Reasoning-Enhanced-Foundational-Language-Model-for-Electronic-Health-Record-Analysis","children":"[논문리뷰] EHR-R1: A Reasoning-Enhanced Foundational Language Model for Electronic Health Record Analysis"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-EHR-R1-A-Reasoning-Enhanced-Foundational-Language-Model-for-Electronic-Health-Record-Analysis","children":"이 [arXiv]에 게시한 'EHR-R1: A Reasoning-Enhanced Foundational Language Model for Electronic Health Record Analysis' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-31 18:37:31+0900","children":"2025년 10월 31일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-31-EHR-R1-A-Reasoning-Enhanced-Foundational-Language-Model-for-Electronic-Health-Record-Analysis"}]]}]]}],["$","article","2025-10-31-Can-Agent-Conquer-Web-Exploring-the-Frontiers-of-ChatGPT-Atlas-Agent-in-Web-Games",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-Can-Agent-Conquer-Web-Exploring-the-Frontiers-of-ChatGPT-Atlas-Agent-in-Web-Games","children":"[논문리뷰] Can Agent Conquer Web? Exploring the Frontiers of ChatGPT Atlas Agent in Web Games"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-Can-Agent-Conquer-Web-Exploring-the-Frontiers-of-ChatGPT-Atlas-Agent-in-Web-Games","children":"Justin Cui이 [arXiv]에 게시한 'Can Agent Conquer Web? Exploring the Frontiers of ChatGPT Atlas Agent in Web Games' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-31 18:37:31+0900","children":"2025년 10월 31일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-31-Can-Agent-Conquer-Web-Exploring-the-Frontiers-of-ChatGPT-Atlas-Agent-in-Web-Games"}]]}]]}],["$","article","2025-10-30-TheraMind-A-Strategic-and-Adaptive-Agent-for-Longitudinal-Psychological-Counseling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-TheraMind-A-Strategic-and-Adaptive-Agent-for-Longitudinal-Psychological-Counseling","children":"[논문리뷰] TheraMind: A Strategic and Adaptive Agent for Longitudinal Psychological Counseling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-TheraMind-A-Strategic-and-Adaptive-Agent-for-Longitudinal-Psychological-Counseling","children":"Zheng Zhang이 [arXiv]에 게시한 'TheraMind: A Strategic and Adaptive Agent for Longitudinal Psychological Counseling' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-30 13:06:06+0900","children":"2025년 10월 30일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-30-TheraMind-A-Strategic-and-Adaptive-Agent-for-Longitudinal-Psychological-Counseling"}]]}]]}],["$","article","2025-10-30-Reasoning-Aware-GRPO-using-Process-Mining",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-Reasoning-Aware-GRPO-using-Process-Mining","children":"[논문리뷰] Reasoning-Aware GRPO using Process Mining"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-Reasoning-Aware-GRPO-using-Process-Mining","children":"이 [arXiv]에 게시한 'Reasoning-Aware GRPO using Process Mining' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-30 13:06:06+0900","children":"2025년 10월 30일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-30-Reasoning-Aware-GRPO-using-Process-Mining"}]]}]]}],["$","article","2025-10-30-ReForm-Reflective-Autoformalization-with-Prospective-Bounded-Sequence-Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-ReForm-Reflective-Autoformalization-with-Prospective-Bounded-Sequence-Optimization","children":"[논문리뷰] ReForm: Reflective Autoformalization with Prospective Bounded Sequence Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-ReForm-Reflective-Autoformalization-with-Prospective-Bounded-Sequence-Optimization","children":"Ruihua Song이 [arXiv]에 게시한 'ReForm: Reflective Autoformalization with Prospective Bounded Sequence Optimization' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-30 13:06:06+0900","children":"2025년 10월 30일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-30-ReForm-Reflective-Autoformalization-with-Prospective-Bounded-Sequence-Optimization"}]]}]]}],["$","article","2025-10-30-Parallel-Loop-Transformer-for-Efficient-Test-Time-Computation-Scaling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-Parallel-Loop-Transformer-for-Efficient-Test-Time-Computation-Scaling","children":"[논문리뷰] Parallel Loop Transformer for Efficient Test-Time Computation Scaling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-Parallel-Loop-Transformer-for-Efficient-Test-Time-Computation-Scaling","children":"이 [arXiv]에 게시한 'Parallel Loop Transformer for Efficient Test-Time Computation Scaling' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-30 13:06:06+0900","children":"2025년 10월 30일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-30-Parallel-Loop-Transformer-for-Efficient-Test-Time-Computation-Scaling"}]]}]]}],["$","article","2025-10-30-JanusCoder-Towards-a-Foundational-Visual-Programmatic-Interface-for-Code-Intelligence",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-JanusCoder-Towards-a-Foundational-Visual-Programmatic-Interface-for-Code-Intelligence","children":"[논문리뷰] JanusCoder: Towards a Foundational Visual-Programmatic Interface for Code Intelligence"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-JanusCoder-Towards-a-Foundational-Visual-Programmatic-Interface-for-Code-Intelligence","children":"이 [arXiv]에 게시한 'JanusCoder: Towards a Foundational Visual-Programmatic Interface for Code Intelligence' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-30 13:06:06+0900","children":"2025년 10월 30일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-30-JanusCoder-Towards-a-Foundational-Visual-Programmatic-Interface-for-Code-Intelligence"}]]}]]}],["$","article","2025-10-30-FAPO-Flawed-Aware-Policy-Optimization-for-Efficient-and-Reliable-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-FAPO-Flawed-Aware-Policy-Optimization-for-Efficient-and-Reliable-Reasoning","children":"[논문리뷰] FAPO: Flawed-Aware Policy Optimization for Efficient and Reliable Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-FAPO-Flawed-Aware-Policy-Optimization-for-Efficient-and-Reliable-Reasoning","children":"Xin Liu이 [arXiv]에 게시한 'FAPO: Flawed-Aware Policy Optimization for Efficient and Reliable Reasoning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-30 13:06:06+0900","children":"2025년 10월 30일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-30-FAPO-Flawed-Aware-Policy-Optimization-for-Efficient-and-Reliable-Reasoning"}]]}]]}],["$","article","2025-10-29-VisCoder2-Building-Multi-Language-Visualization-Coding-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-29-VisCoder2-Building-Multi-Language-Visualization-Coding-Agents","children":"[논문리뷰] VisCoder2: Building Multi-Language Visualization Coding Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-29-VisCoder2-Building-Multi-Language-Visualization-Coding-Agents","children":"이 [arXiv]에 게시한 'VisCoder2: Building Multi-Language Visualization Coding Agents' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-29 13:11:02+0900","children":"2025년 10월 29일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-29-VisCoder2-Building-Multi-Language-Visualization-Coding-Agents"}]]}]]}],["$","article","2025-10-29-ReplicationBench-Can-AI-Agents-Replicate-Astrophysics-Research-Papers",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-29-ReplicationBench-Can-AI-Agents-Replicate-Astrophysics-Research-Papers","children":"[논문리뷰] ReplicationBench: Can AI Agents Replicate Astrophysics Research Papers?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-29-ReplicationBench-Can-AI-Agents-Replicate-Astrophysics-Research-Papers","children":"Ian L. V. Roque이 [arXiv]에 게시한 'ReplicationBench: Can AI Agents Replicate Astrophysics Research Papers?' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-29 13:11:02+0900","children":"2025년 10월 29일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-29-ReplicationBench-Can-AI-Agents-Replicate-Astrophysics-Research-Papers"}]]}]]}],["$","article","2025-10-28-The-Best-of-N-Worlds-Aligning-Reinforcement-Learning-with-Best-of-N-Sampling-via-maxk-Optimisation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-28-The-Best-of-N-Worlds-Aligning-Reinforcement-Learning-with-Best-of-N-Sampling-via-maxk-Optimisation","children":"[논문리뷰] The Best of N Worlds: Aligning Reinforcement Learning with Best-of-N Sampling via max@k Optimisation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-28-The-Best-of-N-Worlds-Aligning-Reinforcement-Learning-with-Best-of-N-Sampling-via-maxk-Optimisation","children":"이 [arXiv]에 게시한 'The Best of N Worlds: Aligning Reinforcement Learning with Best-of-N Sampling via max@k Optimisation' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-28 13:07:54+0900","children":"2025년 10월 28일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-28-The-Best-of-N-Worlds-Aligning-Reinforcement-Learning-with-Best-of-N-Sampling-via-maxk-Optimisation"}]]}]]}],["$","article","2025-10-28-Mitigating-Attention-Sinks-and-Massive-Activations-in-Audio-Visual-Speech-Recognition-with-LLMS",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-28-Mitigating-Attention-Sinks-and-Massive-Activations-in-Audio-Visual-Speech-Recognition-with-LLMS","children":"[논문리뷰] Mitigating Attention Sinks and Massive Activations in Audio-Visual Speech Recognition with LLMS"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-28-Mitigating-Attention-Sinks-and-Massive-Activations-in-Audio-Visual-Speech-Recognition-with-LLMS","children":"이 [arXiv]에 게시한 'Mitigating Attention Sinks and Massive Activations in Audio-Visual Speech Recognition with LLMS' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-28 13:07:54+0900","children":"2025년 10월 28일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-28-Mitigating-Attention-Sinks-and-Massive-Activations-in-Audio-Visual-Speech-Recognition-with-LLMS"}]]}]]}],["$","article","2025-10-28-LimRank-Less-is-More-for-Reasoning-Intensive-Information-Reranking",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-28-LimRank-Less-is-More-for-Reasoning-Intensive-Information-Reranking","children":"[논문리뷰] LimRank: Less is More for Reasoning-Intensive Information Reranking"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-28-LimRank-Less-is-More-for-Reasoning-Intensive-Information-Reranking","children":"Arman Cohan이 [arXiv]에 게시한 'LimRank: Less is More for Reasoning-Intensive Information Reranking' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-28 13:07:54+0900","children":"2025년 10월 28일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-28-LimRank-Less-is-More-for-Reasoning-Intensive-Information-Reranking"}]]}]]}],["$","article","2025-10-28-Knocking-Heads-Attention",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-28-Knocking-Heads-Attention","children":"[논문리뷰] Knocking-Heads Attention"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-28-Knocking-Heads-Attention","children":"Jianguo Li이 [arXiv]에 게시한 'Knocking-Heads Attention' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-28 13:07:54+0900","children":"2025년 10월 28일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-28-Knocking-Heads-Attention"}]]}]]}],["$","article","2025-10-28-Code-Aesthetics-with-Agentic-Reward-Feedback",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-28-Code-Aesthetics-with-Agentic-Reward-Feedback","children":"[논문리뷰] Code Aesthetics with Agentic Reward Feedback"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-28-Code-Aesthetics-with-Agentic-Reward-Feedback","children":"Yupan Huang이 [arXiv]에 게시한 'Code Aesthetics with Agentic Reward Feedback' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-28 13:07:54+0900","children":"2025년 10월 28일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-28-Code-Aesthetics-with-Agentic-Reward-Feedback"}]]}]]}],["$","article","2025-10-27-Soft-Instruction-De-escalation-Defense",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-27-Soft-Instruction-De-escalation-Defense","children":"[논문리뷰] Soft Instruction De-escalation Defense"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-27-Soft-Instruction-De-escalation-Defense","children":"이 [arXiv]에 게시한 'Soft Instruction De-escalation Defense' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-27 13:07:36+0900","children":"2025년 10월 27일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-27-Soft-Instruction-De-escalation-Defense"}]]}]]}],["$","article","2025-10-27-Document-Understanding-Measurement-and-Manipulation-Using-Category-Theory",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-27-Document-Understanding-Measurement-and-Manipulation-Using-Category-Theory","children":"[논문리뷰] Document Understanding, Measurement, and Manipulation Using Category Theory"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-27-Document-Understanding-Measurement-and-Manipulation-Using-Category-Theory","children":"이 [arXiv]에 게시한 'Document Understanding, Measurement, and Manipulation Using Category Theory' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-27 13:07:36+0900","children":"2025년 10월 27일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-27-Document-Understanding-Measurement-and-Manipulation-Using-Category-Theory"}]]}]]}],["$","article","2025-10-27-DeepAgent-A-General-Reasoning-Agent-with-Scalable-Toolsets",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-27-DeepAgent-A-General-Reasoning-Agent-with-Scalable-Toolsets","children":"[논문리뷰] DeepAgent: A General Reasoning Agent with Scalable Toolsets"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-27-DeepAgent-A-General-Reasoning-Agent-with-Scalable-Toolsets","children":"Jiajie Jin이 [arXiv]에 게시한 'DeepAgent: A General Reasoning Agent with Scalable Toolsets' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-27 13:07:36+0900","children":"2025년 10월 27일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-27-DeepAgent-A-General-Reasoning-Agent-with-Scalable-Toolsets"}]]}]]}],["$","article","2025-10-27-ARC-Encoder-learning-compressed-text-representations-for-large-language-models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-27-ARC-Encoder-learning-compressed-text-representations-for-large-language-models","children":"[논문리뷰] ARC-Encoder: learning compressed text representations for large language models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-27-ARC-Encoder-learning-compressed-text-representations-for-large-language-models","children":"이 [arXiv]에 게시한 'ARC-Encoder: learning compressed text representations for large language models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-27 13:07:36+0900","children":"2025년 10월 27일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-27-ARC-Encoder-learning-compressed-text-representations-for-large-language-models"}]]}]]}],["$","article","2025-10-23-Machine-Text-Detectors-are-Membership-Inference-Attacks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-Machine-Text-Detectors-are-Membership-Inference-Attacks","children":"[논문리뷰] Machine Text Detectors are Membership Inference Attacks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-Machine-Text-Detectors-are-Membership-Inference-Attacks","children":"Naoaki Okazaki이 [arXiv]에 게시한 'Machine Text Detectors are Membership Inference Attacks' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-23-Machine-Text-Detectors-are-Membership-Inference-Attacks"}]]}]]}],["$","article","2025-10-23-LoongRLReinforcement-Learning-for-Advanced-Reasoning-over-Long-Contexts",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-LoongRLReinforcement-Learning-for-Advanced-Reasoning-over-Long-Contexts","children":"[논문리뷰] LoongRL:Reinforcement Learning for Advanced Reasoning over Long Contexts"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-LoongRLReinforcement-Learning-for-Advanced-Reasoning-over-Long-Contexts","children":"이 [arXiv]에 게시한 'LoongRL:Reinforcement Learning for Advanced Reasoning over Long Contexts' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-23-LoongRLReinforcement-Learning-for-Advanced-Reasoning-over-Long-Contexts"}]]}]]}],["$","article","2025-10-23-BAPO-Stabilizing-Off-Policy-Reinforcement-Learning-for-LLMs-via-Balanced-Policy-Optimization-with-Adaptive-Clipping",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-BAPO-Stabilizing-Off-Policy-Reinforcement-Learning-for-LLMs-via-Balanced-Policy-Optimization-with-Adaptive-Clipping","children":"[논문리뷰] BAPO: Stabilizing Off-Policy Reinforcement Learning for LLMs via Balanced Policy Optimization with Adaptive Clipping"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-BAPO-Stabilizing-Off-Policy-Reinforcement-Learning-for-LLMs-via-Balanced-Policy-Optimization-with-Adaptive-Clipping","children":"Junrui Shen이 [arXiv]에 게시한 'BAPO: Stabilizing Off-Policy Reinforcement Learning for LLMs via Balanced Policy Optimization with Adaptive Clipping' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-23-BAPO-Stabilizing-Off-Policy-Reinforcement-Learning-for-LLMs-via-Balanced-Policy-Optimization-with-Adaptive-Clipping"}]]}]]}],["$","article","2025-10-22-UniGenBench-A-Unified-Semantic-Evaluation-Benchmark-for-Text-to-Image-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-UniGenBench-A-Unified-Semantic-Evaluation-Benchmark-for-Text-to-Image-Generation","children":"[논문리뷰] UniGenBench++: A Unified Semantic Evaluation Benchmark for Text-to-Image Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-UniGenBench-A-Unified-Semantic-Evaluation-Benchmark-for-Text-to-Image-Generation","children":"Yujie Zhou이 [arXiv]에 게시한 'UniGenBench++: A Unified Semantic Evaluation Benchmark for Text-to-Image Generation' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-22-UniGenBench-A-Unified-Semantic-Evaluation-Benchmark-for-Text-to-Image-Generation"}]]}]]}],["$","article","2025-10-22-PokeeResearch-Effective-Deep-Research-via-Reinforcement-Learning-from-AI-Feedback-and-Robust-Reasoning-Scaffold",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-PokeeResearch-Effective-Deep-Research-via-Reinforcement-Learning-from-AI-Feedback-and-Robust-Reasoning-Scaffold","children":"[논문리뷰] PokeeResearch: Effective Deep Research via Reinforcement Learning from AI Feedback and Robust Reasoning Scaffold"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-PokeeResearch-Effective-Deep-Research-via-Reinforcement-Learning-from-AI-Feedback-and-Robust-Reasoning-Scaffold","children":"이 [arXiv]에 게시한 'PokeeResearch: Effective Deep Research via Reinforcement Learning from AI Feedback and Robust Reasoning Scaffold' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-22-PokeeResearch-Effective-Deep-Research-via-Reinforcement-Learning-from-AI-Feedback-and-Robust-Reasoning-Scaffold"}]]}]]}],["$","article","2025-10-22-Extracting-alignment-data-in-open-models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-Extracting-alignment-data-in-open-models","children":"[논문리뷰] Extracting alignment data in open models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-Extracting-alignment-data-in-open-models","children":"이 [arXiv]에 게시한 'Extracting alignment data in open models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-22-Extracting-alignment-data-in-open-models"}]]}]]}],["$","article","2025-10-22-EvoSyn-Generalizable-Evolutionary-Data-Synthesis-for-Verifiable-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-EvoSyn-Generalizable-Evolutionary-Data-Synthesis-for-Verifiable-Learning","children":"[논문리뷰] EvoSyn: Generalizable Evolutionary Data Synthesis for Verifiable Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-EvoSyn-Generalizable-Evolutionary-Data-Synthesis-for-Verifiable-Learning","children":"Qipeng Guo이 [arXiv]에 게시한 'EvoSyn: Generalizable Evolutionary Data Synthesis for Verifiable Learning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-22-EvoSyn-Generalizable-Evolutionary-Data-Synthesis-for-Verifiable-Learning"}]]}]]}],["$","article","2025-10-22-Chem-R-Learning-to-Reason-as-a-Chemist",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-Chem-R-Learning-to-Reason-as-a-Chemist","children":"[논문리뷰] Chem-R: Learning to Reason as a Chemist"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-Chem-R-Learning-to-Reason-as-a-Chemist","children":"이 [arXiv]에 게시한 'Chem-R: Learning to Reason as a Chemist' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-22-Chem-R-Learning-to-Reason-as-a-Chemist"}]]}]]}],["$","article","2025-10-20-Paper2Web-Lets-Make-Your-Paper-Alive",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-Paper2Web-Lets-Make-Your-Paper-Alive","children":"[논문리뷰] Paper2Web: Let's Make Your Paper Alive!"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-Paper2Web-Lets-Make-Your-Paper-Alive","children":"Yao Wan이 [arXiv]에 게시한 'Paper2Web: Let's Make Your Paper Alive!' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-20-Paper2Web-Lets-Make-Your-Paper-Alive"}]]}]]}],["$","article","2025-10-20-Language-Models-Model-Language",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-Language-Models-Model-Language","children":"[논문리뷰] Language Models Model Language"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-Language-Models-Model-Language","children":"이 [arXiv]에 게시한 'Language Models Model Language' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-20-Language-Models-Model-Language"}]]}]]}],["$","article","2025-10-20-DLER-Doing-Length-pEnalty-Right-Incentivizing-More-Intelligence-per-Token-via-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-DLER-Doing-Length-pEnalty-Right-Incentivizing-More-Intelligence-per-Token-via-Reinforcement-Learning","children":"[논문리뷰] DLER: Doing Length pEnalty Right - Incentivizing More Intelligence per Token via Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-DLER-Doing-Length-pEnalty-Right-Incentivizing-More-Intelligence-per-Token-via-Reinforcement-Learning","children":"이 [arXiv]에 게시한 'DLER: Doing Length pEnalty Right - Incentivizing More Intelligence per Token via Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-20-DLER-Doing-Length-pEnalty-Right-Incentivizing-More-Intelligence-per-Token-via-Reinforcement-Learning"}]]}]]}],["$","article","2025-10-17-VLA-0-Building-State-of-the-Art-VLAs-with-Zero-Modification",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-VLA-0-Building-State-of-the-Art-VLAs-with-Zero-Modification","children":"[논문리뷰] VLA-0: Building State-of-the-Art VLAs with Zero Modification"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-VLA-0-Building-State-of-the-Art-VLAs-with-Zero-Modification","children":"이 [arXiv]에 게시한 'VLA-0: Building State-of-the-Art VLAs with Zero Modification' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-17-VLA-0-Building-State-of-the-Art-VLAs-with-Zero-Modification"}]]}]]}],["$","article","2025-10-17-The-German-Commons-154-Billion-Tokens-of-Openly-Licensed-Text-for-German-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-The-German-Commons-154-Billion-Tokens-of-Openly-Licensed-Text-for-German-Language-Models","children":"[논문리뷰] The German Commons - 154 Billion Tokens of Openly Licensed Text for German Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-The-German-Commons-154-Billion-Tokens-of-Openly-Licensed-Text-for-German-Language-Models","children":"이 [arXiv]에 게시한 'The German Commons - 154 Billion Tokens of Openly Licensed Text for German Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-17-The-German-Commons-154-Billion-Tokens-of-Openly-Licensed-Text-for-German-Language-Models"}]]}]]}],["$","article","2025-10-17-RAGCap-Bench-Benchmarking-Capabilities-of-LLMs-in-Agentic-Retrieval-Augmented-Generation-Systems",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-RAGCap-Bench-Benchmarking-Capabilities-of-LLMs-in-Agentic-Retrieval-Augmented-Generation-Systems","children":"[논문리뷰] RAGCap-Bench: Benchmarking Capabilities of LLMs in Agentic Retrieval Augmented Generation Systems"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-RAGCap-Bench-Benchmarking-Capabilities-of-LLMs-in-Agentic-Retrieval-Augmented-Generation-Systems","children":"이 [arXiv]에 게시한 'RAGCap-Bench: Benchmarking Capabilities of LLMs in Agentic Retrieval Augmented Generation Systems' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-17-RAGCap-Bench-Benchmarking-Capabilities-of-LLMs-in-Agentic-Retrieval-Augmented-Generation-Systems"}]]}]]}],["$","article","2025-10-17-LLM-guided-Hierarchical-Retrieval",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-LLM-guided-Hierarchical-Retrieval","children":"[논문리뷰] LLM-guided Hierarchical Retrieval"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-LLM-guided-Hierarchical-Retrieval","children":"이 [arXiv]에 게시한 'LLM-guided Hierarchical Retrieval' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-17-LLM-guided-Hierarchical-Retrieval"}]]}]]}],["$","article","2025-10-17-Agentic-Entropy-Balanced-Policy-Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-Agentic-Entropy-Balanced-Policy-Optimization","children":"[논문리뷰] Agentic Entropy-Balanced Policy Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-Agentic-Entropy-Balanced-Policy-Optimization","children":"이 [arXiv]에 게시한 'Agentic Entropy-Balanced Policy Optimization' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-17-Agentic-Entropy-Balanced-Policy-Optimization"}]]}]]}],["$","article","2025-10-16-Revisiting-Model-Interpolation-for-Efficient-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-Revisiting-Model-Interpolation-for-Efficient-Reasoning","children":"[논문리뷰] Revisiting Model Interpolation for Efficient Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-Revisiting-Model-Interpolation-for-Efficient-Reasoning","children":"이 [arXiv]에 게시한 'Revisiting Model Interpolation for Efficient Reasoning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-16-Revisiting-Model-Interpolation-for-Efficient-Reasoning"}]]}]]}],["$","article","2025-10-16-MTSQL-R1-Towards-Long-Horizon-Multi-Turn-Text-to-SQL-via-Agentic-Training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-MTSQL-R1-Towards-Long-Horizon-Multi-Turn-Text-to-SQL-via-Agentic-Training","children":"[논문리뷰] MTSQL-R1: Towards Long-Horizon Multi-Turn Text-to-SQL via Agentic Training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-MTSQL-R1-Towards-Long-Horizon-Multi-Turn-Text-to-SQL-via-Agentic-Training","children":"이 [arXiv]에 게시한 'MTSQL-R1: Towards Long-Horizon Multi-Turn Text-to-SQL via Agentic Training' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-16-MTSQL-R1-Towards-Long-Horizon-Multi-Turn-Text-to-SQL-via-Agentic-Training"}]]}]]}],["$","article","2025-10-16-Hierarchical-Frequency-Tagging-Probe-HFTP-A-Unified-Approach-to-Investigate-Syntactic-Structure-Representations-in-Large-Language-Models-and-the-Human-Brain",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-Hierarchical-Frequency-Tagging-Probe-HFTP-A-Unified-Approach-to-Investigate-Syntactic-Structure-Representations-in-Large-Language-Models-and-the-Human-Brain","children":"[논문리뷰] Hierarchical Frequency Tagging Probe (HFTP): A Unified Approach to Investigate Syntactic Structure Representations in Large Language Models and the Human Brain"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-Hierarchical-Frequency-Tagging-Probe-HFTP-A-Unified-Approach-to-Investigate-Syntactic-Structure-Representations-in-Large-Language-Models-and-the-Human-Brain","children":"Lingxi Lu이 [arXiv]에 게시한 'Hierarchical Frequency Tagging Probe (HFTP): A Unified Approach to Investigate Syntactic Structure Representations in Large Language Models and the Human Brain' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-16-Hierarchical-Frequency-Tagging-Probe-HFTP-A-Unified-Approach-to-Investigate-Syntactic-Structure-Representations-in-Large-Language-Models-and-the-Human-Brain"}]]}]]}],["$","article","2025-10-15-Memory-as-Action-Autonomous-Context-Curation-for-Long-Horizon-Agentic-Tasks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-Memory-as-Action-Autonomous-Context-Curation-for-Long-Horizon-Agentic-Tasks","children":"[논문리뷰] Memory as Action: Autonomous Context Curation for Long-Horizon Agentic Tasks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-Memory-as-Action-Autonomous-Context-Curation-for-Long-Horizon-Agentic-Tasks","children":"Xueyuan Lin이 [arXiv]에 게시한 'Memory as Action: Autonomous Context Curation for Long-Horizon Agentic Tasks' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-15-Memory-as-Action-Autonomous-Context-Curation-for-Long-Horizon-Agentic-Tasks"}]]}]]}],["$","article","2025-10-15-Information-Preserving-Reformulation-of-Reasoning-Traces-for-Antidistillation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-Information-Preserving-Reformulation-of-Reasoning-Traces-for-Antidistillation","children":"[논문리뷰] Information-Preserving Reformulation of Reasoning Traces for Antidistillation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-Information-Preserving-Reformulation-of-Reasoning-Traces-for-Antidistillation","children":"이 [arXiv]에 게시한 'Information-Preserving Reformulation of Reasoning Traces for Antidistillation' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-15-Information-Preserving-Reformulation-of-Reasoning-Traces-for-Antidistillation"}]]}]]}],["$","article","2025-10-15-A-Survey-of-Vibe-Coding-with-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-A-Survey-of-Vibe-Coding-with-Large-Language-Models","children":"[논문리뷰] A Survey of Vibe Coding with Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-A-Survey-of-Vibe-Coding-with-Large-Language-Models","children":"이 [arXiv]에 게시한 'A Survey of Vibe Coding with Large Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-15-A-Survey-of-Vibe-Coding-with-Large-Language-Models"}]]}]]}],["$","article","2025-10-13-ReviewerToo-Should-AI-Join-The-Program-Committee-A-Look-At-The-Future-of-Peer-Review",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-ReviewerToo-Should-AI-Join-The-Program-Committee-A-Look-At-The-Future-of-Peer-Review","children":"[논문리뷰] ReviewerToo: Should AI Join The Program Committee? A Look At The Future of Peer Review"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-ReviewerToo-Should-AI-Join-The-Program-Committee-A-Look-At-The-Future-of-Peer-Review","children":"Christopher Pal이 [arXiv]에 게시한 'ReviewerToo: Should AI Join The Program Committee? A Look At The Future of Peer Review' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-13-ReviewerToo-Should-AI-Join-The-Program-Committee-A-Look-At-The-Future-of-Peer-Review"}]]}]]}],["$","article","2025-10-13-GTAlign-Game-Theoretic-Alignment-of-LLM-Assistants-for-Mutual-Welfare",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-GTAlign-Game-Theoretic-Alignment-of-LLM-Assistants-for-Mutual-Welfare","children":"[논문리뷰] GTAlign: Game-Theoretic Alignment of LLM Assistants for Mutual Welfare"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-GTAlign-Game-Theoretic-Alignment-of-LLM-Assistants-for-Mutual-Welfare","children":"이 [arXiv]에 게시한 'GTAlign: Game-Theoretic Alignment of LLM Assistants for Mutual Welfare' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-13-GTAlign-Game-Theoretic-Alignment-of-LLM-Assistants-for-Mutual-Welfare"}]]}]]}],["$","article","2025-10-13-Dont-Waste-Mistakes-Leveraging-Negative-RL-Groups-via-Confidence-Reweighting",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Dont-Waste-Mistakes-Leveraging-Negative-RL-Groups-via-Confidence-Reweighting","children":"[논문리뷰] Don't Waste Mistakes: Leveraging Negative RL-Groups via Confidence Reweighting"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Dont-Waste-Mistakes-Leveraging-Negative-RL-Groups-via-Confidence-Reweighting","children":"Julia Kempe이 [arXiv]에 게시한 'Don't Waste Mistakes: Leveraging Negative RL-Groups via Confidence Reweighting' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-13-Dont-Waste-Mistakes-Leveraging-Negative-RL-Groups-via-Confidence-Reweighting"}]]}]]}],["$","article","2025-10-13-DISCO-Diversifying-Sample-Condensation-for-Efficient-Model-Evaluation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-DISCO-Diversifying-Sample-Condensation-for-Efficient-Model-Evaluation","children":"[논문리뷰] DISCO: Diversifying Sample Condensation for Efficient Model Evaluation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-DISCO-Diversifying-Sample-Condensation-for-Efficient-Model-Evaluation","children":"이 [arXiv]에 게시한 'DISCO: Diversifying Sample Condensation for Efficient Model Evaluation' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-13-DISCO-Diversifying-Sample-Condensation-for-Efficient-Model-Evaluation"}]]}]]}],["$","article","2025-10-13-BigCodeArena-Unveiling-More-Reliable-Human-Preferences-in-Code-Generation-via-Execution",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-BigCodeArena-Unveiling-More-Reliable-Human-Preferences-in-Code-Generation-via-Execution","children":"[논문리뷰] BigCodeArena: Unveiling More Reliable Human Preferences in Code Generation via Execution"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-BigCodeArena-Unveiling-More-Reliable-Human-Preferences-in-Code-Generation-via-Execution","children":"Hange Liu이 [arXiv]에 게시한 'BigCodeArena: Unveiling More Reliable Human Preferences in Code Generation via Execution' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-13-BigCodeArena-Unveiling-More-Reliable-Human-Preferences-in-Code-Generation-via-Execution"}]]}]]}],["$","article","2025-10-13-AutoPR-Lets-Automate-Your-Academic-Promotion",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-AutoPR-Lets-Automate-Your-Academic-Promotion","children":"[논문리뷰] AutoPR: Let's Automate Your Academic Promotion!"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-AutoPR-Lets-Automate-Your-Academic-Promotion","children":"Yixin Yuan이 [arXiv]에 게시한 'AutoPR: Let's Automate Your Academic Promotion!' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-13-AutoPR-Lets-Automate-Your-Academic-Promotion"}]]}]]}],["$","article","2025-10-10-UNIDOC-BENCH-A-Unified-Benchmark-for-Document-Centric-Multimodal-RAG",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-UNIDOC-BENCH-A-Unified-Benchmark-for-Document-Centric-Multimodal-RAG","children":"[논문리뷰] UNIDOC-BENCH: A Unified Benchmark for Document-Centric Multimodal RAG"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-UNIDOC-BENCH-A-Unified-Benchmark-for-Document-Centric-Multimodal-RAG","children":"이 [arXiv]에 게시한 'UNIDOC-BENCH: A Unified Benchmark for Document-Centric Multimodal RAG' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-10-UNIDOC-BENCH-A-Unified-Benchmark-for-Document-Centric-Multimodal-RAG"}]]}]]}],["$","article","2025-10-10-Search-R3-Unifying-Reasoning-and-Embedding-Generation-in-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Search-R3-Unifying-Reasoning-and-Embedding-Generation-in-Large-Language-Models","children":"[논문리뷰] Search-R3: Unifying Reasoning and Embedding Generation in Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Search-R3-Unifying-Reasoning-and-Embedding-Generation-in-Large-Language-Models","children":"James Cheng이 [arXiv]에 게시한 'Search-R3: Unifying Reasoning and Embedding Generation in Large Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-10-Search-R3-Unifying-Reasoning-and-Embedding-Generation-in-Large-Language-Models"}]]}]]}],["$","article","2025-10-10-Recycling-Pretrained-Checkpoints-Orthogonal-Growth-of-Mixture-of-Experts-for-Efficient-Large-Language-Model-Pre-Training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Recycling-Pretrained-Checkpoints-Orthogonal-Growth-of-Mixture-of-Experts-for-Efficient-Large-Language-Model-Pre-Training","children":"[논문리뷰] Recycling Pretrained Checkpoints: Orthogonal Growth of Mixture-of-Experts for Efficient Large Language Model Pre-Training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Recycling-Pretrained-Checkpoints-Orthogonal-Growth-of-Mixture-of-Experts-for-Efficient-Large-Language-Model-Pre-Training","children":"Peng Cheng이 [arXiv]에 게시한 'Recycling Pretrained Checkpoints: Orthogonal Growth of Mixture-of-Experts for Efficient Large Language Model Pre-Training' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-10-Recycling-Pretrained-Checkpoints-Orthogonal-Growth-of-Mixture-of-Experts-for-Efficient-Large-Language-Model-Pre-Training"}]]}]]}],["$","article","2025-10-10-Memory-Retrieval-and-Consolidation-in-Large-Language-Models-through-Function-Tokens",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Memory-Retrieval-and-Consolidation-in-Large-Language-Models-through-Function-Tokens","children":"[논문리뷰] Memory Retrieval and Consolidation in Large Language Models through Function Tokens"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Memory-Retrieval-and-Consolidation-in-Large-Language-Models-through-Function-Tokens","children":"이 [arXiv]에 게시한 'Memory Retrieval and Consolidation in Large Language Models through Function Tokens' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-10-Memory-Retrieval-and-Consolidation-in-Large-Language-Models-through-Function-Tokens"}]]}]]}],["$","article","2025-10-10-From-What-to-Why-A-Multi-Agent-System-for-Evidence-based-Chemical-Reaction-Condition-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-From-What-to-Why-A-Multi-Agent-System-for-Evidence-based-Chemical-Reaction-Condition-Reasoning","children":"[논문리뷰] From What to Why: A Multi-Agent System for Evidence-based Chemical Reaction Condition Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-From-What-to-Why-A-Multi-Agent-System-for-Evidence-based-Chemical-Reaction-Condition-Reasoning","children":"Feiwei Qin이 [arXiv]에 게시한 'From What to Why: A Multi-Agent System for Evidence-based Chemical Reaction Condition Reasoning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-10-From-What-to-Why-A-Multi-Agent-System-for-Evidence-based-Chemical-Reaction-Condition-Reasoning"}]]}]]}],["$","article","2025-10-10-Entropy-Regularizing-Activation-Boosting-Continuous-Control-Large-Language-Models-and-Image-Classification-with-Activation-as-Entropy-Constraints",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Entropy-Regularizing-Activation-Boosting-Continuous-Control-Large-Language-Models-and-Image-Classification-with-Activation-as-Entropy-Constraints","children":"[논문리뷰] Entropy Regularizing Activation: Boosting Continuous Control, Large Language Models, and Image Classification with Activation as Entropy Constraints"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Entropy-Regularizing-Activation-Boosting-Continuous-Control-Large-Language-Models-and-Image-Classification-with-Activation-as-Entropy-Constraints","children":"Huazhe Xu이 [arXiv]에 게시한 'Entropy Regularizing Activation: Boosting Continuous Control, Large Language Models, and Image Classification with Activation as Entropy Constraints' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-10-Entropy-Regularizing-Activation-Boosting-Continuous-Control-Large-Language-Models-and-Image-Classification-with-Activation-as-Entropy-Constraints"}]]}]]}],["$","article","2025-10-10-A2Search-Ambiguity-Aware-Question-Answering-with-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-A2Search-Ambiguity-Aware-Question-Answering-with-Reinforcement-Learning","children":"[논문리뷰] A^2Search: Ambiguity-Aware Question Answering with Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-A2Search-Ambiguity-Aware-Question-Answering-with-Reinforcement-Learning","children":"이 [arXiv]에 게시한 'A^2Search: Ambiguity-Aware Question Answering with Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-10-A2Search-Ambiguity-Aware-Question-Answering-with-Reinforcement-Learning"}]]}]]}],["$","article","2025-10-9-Vibe-Checker-Aligning-Code-Evaluation-with-Human-Preference",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Vibe-Checker-Aligning-Code-Evaluation-with-Human-Preference","children":"[논문리뷰] Vibe Checker: Aligning Code Evaluation with Human Preference"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Vibe-Checker-Aligning-Code-Evaluation-with-Human-Preference","children":"이 [arXiv]에 게시한 'Vibe Checker: Aligning Code Evaluation with Human Preference' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-9-Vibe-Checker-Aligning-Code-Evaluation-with-Human-Preference"}]]}]]}],["$","article","2025-10-9-The-Markovian-Thinker",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-The-Markovian-Thinker","children":"[논문리뷰] The Markovian Thinker"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-The-Markovian-Thinker","children":"이 [arXiv]에 게시한 'The Markovian Thinker' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-9-The-Markovian-Thinker"}]]}]]}],["$","article","2025-10-9-DeepTravel-An-End-to-End-Agentic-Reinforcement-Learning-Framework-for-Autonomous-Travel-Planning-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-DeepTravel-An-End-to-End-Agentic-Reinforcement-Learning-Framework-for-Autonomous-Travel-Planning-Agents","children":"[논문리뷰] DeepTravel: An End-to-End Agentic Reinforcement Learning Framework for Autonomous Travel Planning Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-DeepTravel-An-End-to-End-Agentic-Reinforcement-Learning-Framework-for-Autonomous-Travel-Planning-Agents","children":"이 [arXiv]에 게시한 'DeepTravel: An End-to-End Agentic Reinforcement Learning Framework for Autonomous Travel Planning Agents' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-9-DeepTravel-An-End-to-End-Agentic-Reinforcement-Learning-Framework-for-Autonomous-Travel-Planning-Agents"}]]}]]}],["$","article","2025-10-9-Beyond-Monolingual-Assumptions-A-Survey-of-Code-Switched-NLP-in-the-Era-of-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Beyond-Monolingual-Assumptions-A-Survey-of-Code-Switched-NLP-in-the-Era-of-Large-Language-Models","children":"[논문리뷰] Beyond Monolingual Assumptions: A Survey of Code-Switched NLP in the Era of Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Beyond-Monolingual-Assumptions-A-Survey-of-Code-Switched-NLP-in-the-Era-of-Large-Language-Models","children":"이 [arXiv]에 게시한 'Beyond Monolingual Assumptions: A Survey of Code-Switched NLP in the Era of Large Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-9-Beyond-Monolingual-Assumptions-A-Survey-of-Code-Switched-NLP-in-the-Era-of-Large-Language-Models"}]]}]]}],["$","article","2025-10-8-Training-Dynamics-Impact-Post-Training-Quantization-Robustness",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Training-Dynamics-Impact-Post-Training-Quantization-Robustness","children":"[논문리뷰] Training Dynamics Impact Post-Training Quantization Robustness"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Training-Dynamics-Impact-Post-Training-Quantization-Robustness","children":"Jonas Geiping이 [arXiv]에 게시한 'Training Dynamics Impact Post-Training Quantization Robustness' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-8-Training-Dynamics-Impact-Post-Training-Quantization-Robustness"}]]}]]}],["$","article","2025-10-8-TaTToo-Tool-Grounded-Thinking-PRM-for-Test-Time-Scaling-in-Tabular-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-TaTToo-Tool-Grounded-Thinking-PRM-for-Test-Time-Scaling-in-Tabular-Reasoning","children":"[논문리뷰] TaTToo: Tool-Grounded Thinking PRM for Test-Time Scaling in Tabular Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-TaTToo-Tool-Grounded-Thinking-PRM-for-Test-Time-Scaling-in-Tabular-Reasoning","children":"이 [arXiv]에 게시한 'TaTToo: Tool-Grounded Thinking PRM for Test-Time Scaling in Tabular Reasoning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-8-TaTToo-Tool-Grounded-Thinking-PRM-for-Test-Time-Scaling-in-Tabular-Reasoning"}]]}]]}],["$","article","2025-10-8-Margin-Adaptive-DPO-Leveraging-Reward-Model-for-Granular-Control-in-Preference-Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Margin-Adaptive-DPO-Leveraging-Reward-Model-for-Granular-Control-in-Preference-Optimization","children":"[논문리뷰] Margin Adaptive DPO: Leveraging Reward Model for Granular Control in Preference Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Margin-Adaptive-DPO-Leveraging-Reward-Model-for-Granular-Control-in-Preference-Optimization","children":"sirano1004이 [arXiv]에 게시한 'Margin Adaptive DPO: Leveraging Reward Model for Granular Control in Preference Optimization' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-8-Margin-Adaptive-DPO-Leveraging-Reward-Model-for-Granular-Control-in-Preference-Optimization"}]]}]]}],["$","article","2025-10-8-CARE-Cognitive-reasoning-Augmented-Reinforcement-for-Emotional-Support-Conversation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-CARE-Cognitive-reasoning-Augmented-Reinforcement-for-Emotional-Support-Conversation","children":"[논문리뷰] CARE: Cognitive-reasoning Augmented Reinforcement for Emotional Support Conversation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-CARE-Cognitive-reasoning-Augmented-Reinforcement-for-Emotional-Support-Conversation","children":"이 [arXiv]에 게시한 'CARE: Cognitive-reasoning Augmented Reinforcement for Emotional Support Conversation' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-8-CARE-Cognitive-reasoning-Augmented-Reinforcement-for-Emotional-Support-Conversation"}]]}]]}],["$","article","2025-10-8-ASPO-Asymmetric-Importance-Sampling-Policy-Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-ASPO-Asymmetric-Importance-Sampling-Policy-Optimization","children":"[논문리뷰] ASPO: Asymmetric Importance Sampling Policy Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-ASPO-Asymmetric-Importance-Sampling-Policy-Optimization","children":"Xiu Li이 [arXiv]에 게시한 'ASPO: Asymmetric Importance Sampling Policy Optimization' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-8-ASPO-Asymmetric-Importance-Sampling-Policy-Optimization"}]]}]]}],["$","article","2025-10-7-Watch-and-Learn-Learning-to-Use-Computers-from-Online-Videos",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Watch-and-Learn-Learning-to-Use-Computers-from-Online-Videos","children":"[논문리뷰] Watch and Learn: Learning to Use Computers from Online Videos"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Watch-and-Learn-Learning-to-Use-Computers-from-Online-Videos","children":"Oriana Riva이 [arXiv]에 게시한 'Watch and Learn: Learning to Use Computers from Online Videos' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-7-Watch-and-Learn-Learning-to-Use-Computers-from-Online-Videos"}]]}]]}],["$","article","2025-10-7-Self-Reflective-Generation-at-Test-Time",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Self-Reflective-Generation-at-Test-Time","children":"[논문리뷰] Self-Reflective Generation at Test Time"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Self-Reflective-Generation-at-Test-Time","children":"Shuang Qiu이 [arXiv]에 게시한 'Self-Reflective Generation at Test Time' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-7-Self-Reflective-Generation-at-Test-Time"}]]}]]}],["$","article","2025-10-7-Optimal-Scaling-Needs-Optimal-Norm",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Optimal-Scaling-Needs-Optimal-Norm","children":"[논문리뷰] Optimal Scaling Needs Optimal Norm"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Optimal-Scaling-Needs-Optimal-Norm","children":"Stefan Kesselheim이 [arXiv]에 게시한 'Optimal Scaling Needs Optimal Norm' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-7-Optimal-Scaling-Needs-Optimal-Norm"}]]}]]}],["$","article","2025-10-7-MoME-Mixture-of-Matryoshka-Experts-for-Audio-Visual-Speech-Recognition",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-MoME-Mixture-of-Matryoshka-Experts-for-Audio-Visual-Speech-Recognition","children":"[논문리뷰] MoME: Mixture of Matryoshka Experts for Audio-Visual Speech Recognition"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-MoME-Mixture-of-Matryoshka-Experts-for-Audio-Visual-Speech-Recognition","children":"이 [arXiv]에 게시한 'MoME: Mixture of Matryoshka Experts for Audio-Visual Speech Recognition' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-7-MoME-Mixture-of-Matryoshka-Experts-for-Audio-Visual-Speech-Recognition"}]]}]]}],["$","article","2025-10-7-Learning-on-the-Job-Test-Time-Curricula-for-Targeted-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Learning-on-the-Job-Test-Time-Curricula-for-Targeted-Reinforcement-Learning","children":"[논문리뷰] Learning on the Job: Test-Time Curricula for Targeted Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Learning-on-the-Job-Test-Time-Curricula-for-Targeted-Reinforcement-Learning","children":"이 [arXiv]에 게시한 'Learning on the Job: Test-Time Curricula for Targeted Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-7-Learning-on-the-Job-Test-Time-Curricula-for-Targeted-Reinforcement-Learning"}]]}]]}],["$","article","2025-10-7-Judging-with-Confidence-Calibrating-Autoraters-to-Preference-Distributions",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Judging-with-Confidence-Calibrating-Autoraters-to-Preference-Distributions","children":"[논문리뷰] Judging with Confidence: Calibrating Autoraters to Preference Distributions"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Judging-with-Confidence-Calibrating-Autoraters-to-Preference-Distributions","children":"이 [arXiv]에 게시한 'Judging with Confidence: Calibrating Autoraters to Preference Distributions' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-7-Judging-with-Confidence-Calibrating-Autoraters-to-Preference-Distributions"}]]}]]}],["$","article","2025-10-7-Imperceptible-Jailbreaking-against-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Imperceptible-Jailbreaking-against-Large-Language-Models","children":"[논문리뷰] Imperceptible Jailbreaking against Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Imperceptible-Jailbreaking-against-Large-Language-Models","children":"이 [arXiv]에 게시한 'Imperceptible Jailbreaking against Large Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-7-Imperceptible-Jailbreaking-against-Large-Language-Models"}]]}]]}],["$","article","2025-10-7-Front-Loading-Reasoning-The-Synergy-between-Pretraining-and-Post-Training-Data",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Front-Loading-Reasoning-The-Synergy-between-Pretraining-and-Post-Training-Data","children":"[논문리뷰] Front-Loading Reasoning: The Synergy between Pretraining and Post-Training Data"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Front-Loading-Reasoning-The-Synergy-between-Pretraining-and-Post-Training-Data","children":"이 [arXiv]에 게시한 'Front-Loading Reasoning: The Synergy between Pretraining and Post-Training Data' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-7-Front-Loading-Reasoning-The-Synergy-between-Pretraining-and-Post-Training-Data"}]]}]]}],["$","article","2025-10-7-EvolProver-Advancing-Automated-Theorem-Proving-by-Evolving-Formalized-Problems-via-Symmetry-and-Difficulty",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-EvolProver-Advancing-Automated-Theorem-Proving-by-Evolving-Formalized-Problems-via-Symmetry-and-Difficulty","children":"[논문리뷰] EvolProver: Advancing Automated Theorem Proving by Evolving Formalized Problems via Symmetry and Difficulty"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-EvolProver-Advancing-Automated-Theorem-Proving-by-Evolving-Formalized-Problems-via-Symmetry-and-Difficulty","children":"Xuanwu Wang이 [arXiv]에 게시한 'EvolProver: Advancing Automated Theorem Proving by Evolving Formalized Problems via Symmetry and Difficulty' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-7-EvolProver-Advancing-Automated-Theorem-Proving-by-Evolving-Formalized-Problems-via-Symmetry-and-Difficulty"}]]}]]}],["$","article","2025-10-7-Epistemic-Diversity-and-Knowledge-Collapse-in-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Epistemic-Diversity-and-Knowledge-Collapse-in-Large-Language-Models","children":"[논문리뷰] Epistemic Diversity and Knowledge Collapse in Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Epistemic-Diversity-and-Knowledge-Collapse-in-Large-Language-Models","children":"이 [arXiv]에 게시한 'Epistemic Diversity and Knowledge Collapse in Large Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-7-Epistemic-Diversity-and-Knowledge-Collapse-in-Large-Language-Models"}]]}]]}],["$","article","2025-10-6-WAInjectBench-Benchmarking-Prompt-Injection-Detections-for-Web-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-WAInjectBench-Benchmarking-Prompt-Injection-Detections-for-Web-Agents","children":"[논문리뷰] WAInjectBench: Benchmarking Prompt Injection Detections for Web Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-WAInjectBench-Benchmarking-Prompt-Injection-Detections-for-Web-Agents","children":"Neil Zhenqiang Gong이 [arXiv]에 게시한 'WAInjectBench: Benchmarking Prompt Injection Detections for Web Agents' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-6-WAInjectBench-Benchmarking-Prompt-Injection-Detections-for-Web-Agents"}]]}]]}],["$","article","2025-10-2-On-Predictability-of-Reinforcement-Learning-Dynamics-for-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-On-Predictability-of-Reinforcement-Learning-Dynamics-for-Large-Language-Models","children":"[논문리뷰] On Predictability of Reinforcement Learning Dynamics for Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-On-Predictability-of-Reinforcement-Learning-Dynamics-for-Large-Language-Models","children":"Yuqing Huang이 [arXiv]에 게시한 'On Predictability of Reinforcement Learning Dynamics for Large Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-2-On-Predictability-of-Reinforcement-Learning-Dynamics-for-Large-Language-Models"}]]}]]}],["$","article","2025-10-2-Infusing-Theory-of-Mind-into-Socially-Intelligent-LLM-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-Infusing-Theory-of-Mind-into-Socially-Intelligent-LLM-Agents","children":"[논문리뷰] Infusing Theory of Mind into Socially Intelligent LLM Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-Infusing-Theory-of-Mind-into-Socially-Intelligent-LLM-Agents","children":"이 [arXiv]에 게시한 'Infusing Theory of Mind into Socially Intelligent LLM Agents' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-2-Infusing-Theory-of-Mind-into-Socially-Intelligent-LLM-Agents"}]]}]]}],["$","article","2025-10-1-The-Dragon-Hatchling-The-Missing-Link-between-the-Transformer-and-Models-of-the-Brain",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-The-Dragon-Hatchling-The-Missing-Link-between-the-Transformer-and-Models-of-the-Brain","children":"[논문리뷰] The Dragon Hatchling: The Missing Link between the Transformer and Models of the Brain"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-The-Dragon-Hatchling-The-Missing-Link-between-the-Transformer-and-Models-of-the-Brain","children":"이 [arXiv]에 게시한 'The Dragon Hatchling: The Missing Link between the Transformer and Models of the Brain' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-1-The-Dragon-Hatchling-The-Missing-Link-between-the-Transformer-and-Models-of-the-Brain"}]]}]]}],["$","article","2025-10-1-Test-Time-Policy-Adaptation-for-Enhanced-Multi-Turn-Interactions-with-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Test-Time-Policy-Adaptation-for-Enhanced-Multi-Turn-Interactions-with-LLMs","children":"[논문리뷰] Test-Time Policy Adaptation for Enhanced Multi-Turn Interactions with LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Test-Time-Policy-Adaptation-for-Enhanced-Multi-Turn-Interactions-with-LLMs","children":"Yao Shu이 [arXiv]에 게시한 'Test-Time Policy Adaptation for Enhanced Multi-Turn Interactions with LLMs' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-1-Test-Time-Policy-Adaptation-for-Enhanced-Multi-Turn-Interactions-with-LLMs"}]]}]]}],["$","article","2025-10-1-Context-Is-What-You-Need-The-Maximum-Effective-Context-Window-for-Real-World-Limits-of-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Context-Is-What-You-Need-The-Maximum-Effective-Context-Window-for-Real-World-Limits-of-LLMs","children":"[논문리뷰] Context Is What You Need: The Maximum Effective Context Window for Real World Limits of LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Context-Is-What-You-Need-The-Maximum-Effective-Context-Window-for-Real-World-Limits-of-LLMs","children":"normanpaulsen이 [arXiv]에 게시한 'Context Is What You Need: The Maximum Effective Context Window for Real World Limits of LLMs' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-1-Context-Is-What-You-Need-The-Maximum-Effective-Context-Window-for-Real-World-Limits-of-LLMs"}]]}]]}],["$","article","2025-10-1-Benefits-and-Pitfalls-of-Reinforcement-Learning-for-Language-Model-Planning-A-Theoretical-Perspective",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Benefits-and-Pitfalls-of-Reinforcement-Learning-for-Language-Model-Planning-A-Theoretical-Perspective","children":"[논문리뷰] Benefits and Pitfalls of Reinforcement Learning for Language Model Planning: A Theoretical Perspective"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Benefits-and-Pitfalls-of-Reinforcement-Learning-for-Language-Model-Planning-A-Theoretical-Perspective","children":"이 [arXiv]에 게시한 'Benefits and Pitfalls of Reinforcement Learning for Language Model Planning: A Theoretical Perspective' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-1-Benefits-and-Pitfalls-of-Reinforcement-Learning-for-Language-Model-Planning-A-Theoretical-Perspective"}]]}]]}],["$","article","2025-10-1-Attention-as-a-Compass-Efficient-Exploration-for-Process-Supervised-RL-in-Reasoning-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Attention-as-a-Compass-Efficient-Exploration-for-Process-Supervised-RL-in-Reasoning-Models","children":"[논문리뷰] Attention as a Compass: Efficient Exploration for Process-Supervised RL in Reasoning Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Attention-as-a-Compass-Efficient-Exploration-for-Process-Supervised-RL-in-Reasoning-Models","children":"이 [arXiv]에 게시한 'Attention as a Compass: Efficient Exploration for Process-Supervised RL in Reasoning Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-10-1-Attention-as-a-Compass-Efficient-Exploration-for-Process-Supervised-RL-in-Reasoning-Models"}]]}]]}],["$","article","2025-9-29-PromptCoT-2-0-Scaling-Prompt-Synthesis-for-Large-Language-Model-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-PromptCoT-2-0-Scaling-Prompt-Synthesis-for-Large-Language-Model-Reasoning","children":"[논문리뷰] PromptCoT 2.0: Scaling Prompt Synthesis for Large Language Model Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-PromptCoT-2-0-Scaling-Prompt-Synthesis-for-Large-Language-Model-Reasoning","children":"Lingpeng Kong이 [arXiv]에 게시한 'PromptCoT 2.0: Scaling Prompt Synthesis for Large Language Model Reasoning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-29-PromptCoT-2-0-Scaling-Prompt-Synthesis-for-Large-Language-Model-Reasoning"}]]}]]}],["$","article","2025-9-29-MesaTask-Towards-Task-Driven-Tabletop-Scene-Generation-via-3D-Spatial-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-MesaTask-Towards-Task-Driven-Tabletop-Scene-Generation-via-3D-Spatial-Reasoning","children":"[논문리뷰] MesaTask: Towards Task-Driven Tabletop Scene Generation via 3D Spatial Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-MesaTask-Towards-Task-Driven-Tabletop-Scene-Generation-via-3D-Spatial-Reasoning","children":"Weipeng Zhong이 [arXiv]에 게시한 'MesaTask: Towards Task-Driven Tabletop Scene Generation via 3D Spatial Reasoning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-29-MesaTask-Towards-Task-Driven-Tabletop-Scene-Generation-via-3D-Spatial-Reasoning"}]]}]]}],["$","article","2025-9-29-Language-Models-Can-Learn-from-Verbal-Feedback-Without-Scalar-Rewards",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-Language-Models-Can-Learn-from-Verbal-Feedback-Without-Scalar-Rewards","children":"[논문리뷰] Language Models Can Learn from Verbal Feedback Without Scalar Rewards"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-Language-Models-Can-Learn-from-Verbal-Feedback-Without-Scalar-Rewards","children":"이 [arXiv]에 게시한 'Language Models Can Learn from Verbal Feedback Without Scalar Rewards' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-29-Language-Models-Can-Learn-from-Verbal-Feedback-Without-Scalar-Rewards"}]]}]]}],["$","article","2025-9-29-Fine-tuning-Done-Right-in-Model-Editing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-Fine-tuning-Done-Right-in-Model-Editing","children":"[논문리뷰] Fine-tuning Done Right in Model Editing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-Fine-tuning-Done-Right-in-Model-Editing","children":"Du Su이 [arXiv]에 게시한 'Fine-tuning Done Right in Model Editing' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-29-Fine-tuning-Done-Right-in-Model-Editing"}]]}]]}],["$","article","2025-9-26-VCRL-Variance-based-Curriculum-Reinforcement-Learning-for-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-VCRL-Variance-based-Curriculum-Reinforcement-Learning-for-Large-Language-Models","children":"[논문리뷰] VCRL: Variance-based Curriculum Reinforcement Learning for Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-VCRL-Variance-based-Curriculum-Reinforcement-Learning-for-Large-Language-Models","children":"Yuewei Zhang이 [arXiv]에 게시한 'VCRL: Variance-based Curriculum Reinforcement Learning for Large Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-26-VCRL-Variance-based-Curriculum-Reinforcement-Learning-for-Large-Language-Models"}]]}]]}],["$","article","2025-9-26-TrustJudge-Inconsistencies-of-LLM-as-a-Judge-and-How-to-Alleviate-Them",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-TrustJudge-Inconsistencies-of-LLM-as-a-Judge-and-How-to-Alleviate-Them","children":"[논문리뷰] TrustJudge: Inconsistencies of LLM-as-a-Judge and How to Alleviate Them"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-TrustJudge-Inconsistencies-of-LLM-as-a-Judge-and-How-to-Alleviate-Them","children":"Zhuohao Yu이 [arXiv]에 게시한 'TrustJudge: Inconsistencies of LLM-as-a-Judge and How to Alleviate Them' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-26-TrustJudge-Inconsistencies-of-LLM-as-a-Judge-and-How-to-Alleviate-Them"}]]}]]}],["$","article","2025-9-26-StyleBench-Evaluating-thinking-styles-in-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-StyleBench-Evaluating-thinking-styles-in-Large-Language-Models","children":"[논문리뷰] StyleBench: Evaluating thinking styles in Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-StyleBench-Evaluating-thinking-styles-in-Large-Language-Models","children":"Javad Lavaei이 [arXiv]에 게시한 'StyleBench: Evaluating thinking styles in Large Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-26-StyleBench-Evaluating-thinking-styles-in-Large-Language-Models"}]]}]]}],["$","article","2025-9-26-Interactive-Recommendation-Agent-with-Active-User-Commands",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-Interactive-Recommendation-Agent-with-Active-User-Commands","children":"[논문리뷰] Interactive Recommendation Agent with Active User Commands"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-Interactive-Recommendation-Agent-with-Active-User-Commands","children":"Xueyang Feng이 [arXiv]에 게시한 'Interactive Recommendation Agent with Active User Commands' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-26-Interactive-Recommendation-Agent-with-Active-User-Commands"}]]}]]}],["$","article","2025-9-26-CE-GPPO-Controlling-Entropy-via-Gradient-Preserving-Clipping-Policy-Optimization-in-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-CE-GPPO-Controlling-Entropy-via-Gradient-Preserving-Clipping-Policy-Optimization-in-Reinforcement-Learning","children":"[논문리뷰] CE-GPPO: Controlling Entropy via Gradient-Preserving Clipping Policy Optimization in Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-CE-GPPO-Controlling-Entropy-via-Gradient-Preserving-Clipping-Policy-Optimization-in-Reinforcement-Learning","children":"Wenping Hu이 [arXiv]에 게시한 'CE-GPPO: Controlling Entropy via Gradient-Preserving Clipping Policy Optimization in Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-26-CE-GPPO-Controlling-Entropy-via-Gradient-Preserving-Clipping-Policy-Optimization-in-Reinforcement-Learning"}]]}]]}],["$","article","2025-9-26-Behind-RoPE-How-Does-Causal-Mask-Encode-Positional-Information",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-Behind-RoPE-How-Does-Causal-Mask-Encode-Positional-Information","children":"[논문리뷰] Behind RoPE: How Does Causal Mask Encode Positional Information?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-Behind-RoPE-How-Does-Causal-Mask-Encode-Positional-Information","children":"Yeyun Gong이 [arXiv]에 게시한 'Behind RoPE: How Does Causal Mask Encode Positional Information?' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-26-Behind-RoPE-How-Does-Causal-Mask-Encode-Positional-Information"}]]}]]}],["$","article","2025-9-25-On-the-Use-of-Agentic-Coding-An-Empirical-Study-of-Pull-Requests-on-GitHub",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-25-On-the-Use-of-Agentic-Coding-An-Empirical-Study-of-Pull-Requests-on-GitHub","children":"[논문리뷰] On the Use of Agentic Coding: An Empirical Study of Pull Requests on GitHub"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-25-On-the-Use-of-Agentic-Coding-An-Empirical-Study-of-Pull-Requests-on-GitHub","children":"Hajimu Iida이 [arXiv]에 게시한 'On the Use of Agentic Coding: An Empirical Study of Pull Requests on GitHub' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-25 13:08:16+0900","children":"2025년 9월 25일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-25-On-the-Use-of-Agentic-Coding-An-Empirical-Study-of-Pull-Requests-on-GitHub"}]]}]]}],["$","article","2025-9-25-LLMs4All-A-Review-on-Large-Language-Models-for-Research-and-Applications-in-Academic-Disciplines",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-25-LLMs4All-A-Review-on-Large-Language-Models-for-Research-and-Applications-in-Academic-Disciplines","children":"[논문리뷰] LLMs4All: A Review on Large Language Models for Research and Applications in Academic Disciplines"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-25-LLMs4All-A-Review-on-Large-Language-Models-for-Research-and-Applications-in-Academic-Disciplines","children":"Yanfang이 [arXiv]에 게시한 'LLMs4All: A Review on Large Language Models for Research and Applications in Academic Disciplines' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-25 13:08:16+0900","children":"2025년 9월 25일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-25-LLMs4All-A-Review-on-Large-Language-Models-for-Research-and-Applications-in-Academic-Disciplines"}]]}]]}],["$","article","2025-9-24-Reinforcement-Learning-on-Pre-Training-Data",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-24-Reinforcement-Learning-on-Pre-Training-Data","children":"[논문리뷰] Reinforcement Learning on Pre-Training Data"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-24-Reinforcement-Learning-on-Pre-Training-Data","children":"Evander Yang이 [arXiv]에 게시한 'Reinforcement Learning on Pre-Training Data' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-24 13:14:19+0900","children":"2025년 9월 24일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-24-Reinforcement-Learning-on-Pre-Training-Data"}]]}]]}],["$","article","2025-9-24-Large-Language-Models-Discriminate-Against-Speakers-of-German-Dialects",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-24-Large-Language-Models-Discriminate-Against-Speakers-of-German-Dialects","children":"[논문리뷰] Large Language Models Discriminate Against Speakers of German Dialects"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-24-Large-Language-Models-Discriminate-Against-Speakers-of-German-Dialects","children":"Katharina von der Wense이 [arXiv]에 게시한 'Large Language Models Discriminate Against Speakers of German Dialects' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-24 13:14:19+0900","children":"2025년 9월 24일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-24-Large-Language-Models-Discriminate-Against-Speakers-of-German-Dialects"}]]}]]}],["$","article","2025-9-23-Turk-LettuceDetect-A-Hallucination-Detection-Models-for-Turkish-RAG-Applications",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-Turk-LettuceDetect-A-Hallucination-Detection-Models-for-Turkish-RAG-Applications","children":"[논문리뷰] Turk-LettuceDetect: A Hallucination Detection Models for Turkish RAG Applications"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-Turk-LettuceDetect-A-Hallucination-Detection-Models-for-Turkish-RAG-Applications","children":"Fatma Betül Terzioğlu이 [arXiv]에 게시한 'Turk-LettuceDetect: A Hallucination Detection Models for Turkish RAG Applications' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-23-Turk-LettuceDetect-A-Hallucination-Detection-Models-for-Turkish-RAG-Applications"}]]}]]}],["$","article","2025-9-23-SCAN-Self-Denoising-Monte-Carlo-Annotation-for-Robust-Process-Reward-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-SCAN-Self-Denoising-Monte-Carlo-Annotation-for-Robust-Process-Reward-Learning","children":"[논문리뷰] SCAN: Self-Denoising Monte Carlo Annotation for Robust Process Reward Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-SCAN-Self-Denoising-Monte-Carlo-Annotation-for-Robust-Process-Reward-Learning","children":"Zhaopeng Tu이 [arXiv]에 게시한 'SCAN: Self-Denoising Monte Carlo Annotation for Robust Process Reward Learning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-23-SCAN-Self-Denoising-Monte-Carlo-Annotation-for-Robust-Process-Reward-Learning"}]]}]]}],["$","article","2025-9-23-LIMI-Less-is-More-for-Agency",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-LIMI-Less-is-More-for-Agency","children":"[논문리뷰] LIMI: Less is More for Agency"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-LIMI-Less-is-More-for-Agency","children":"happyZYM이 [arXiv]에 게시한 'LIMI: Less is More for Agency' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-23-LIMI-Less-is-More-for-Agency"}]]}]]}],["$","article","2025-9-23-DIWALI-Diversity-and-Inclusivity-aWare-cuLture-specific-Items-for-India-Dataset-and-Assessment-of-LLMs-for-Cultural-Text-Adaptation-in-Indian-Context",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-DIWALI-Diversity-and-Inclusivity-aWare-cuLture-specific-Items-for-India-Dataset-and-Assessment-of-LLMs-for-Cultural-Text-Adaptation-in-Indian-Context","children":"[논문리뷰] DIWALI - Diversity and Inclusivity aWare cuLture specific Items for India: Dataset and Assessment of LLMs for Cultural Text Adaptation in Indian Context"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-DIWALI-Diversity-and-Inclusivity-aWare-cuLture-specific-Items-for-India-Dataset-and-Assessment-of-LLMs-for-Cultural-Text-Adaptation-in-Indian-Context","children":"Maunendra Sankar Desarkar이 [arXiv]에 게시한 'DIWALI - Diversity and Inclusivity aWare cuLture specific Items for India: Dataset and Assessment of LLMs for Cultural Text Adaptation in Indian Context' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-23-DIWALI-Diversity-and-Inclusivity-aWare-cuLture-specific-Items-for-India-Dataset-and-Assessment-of-LLMs-for-Cultural-Text-Adaptation-in-Indian-Context"}]]}]]}],["$","article","2025-9-23-AuditoryBench-Can-Language-Models-Understand-Auditory-Knowledge-without-Hearing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-AuditoryBench-Can-Language-Models-Understand-Auditory-Knowledge-without-Hearing","children":"[논문리뷰] AuditoryBench++: Can Language Models Understand Auditory Knowledge without Hearing?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-AuditoryBench-Can-Language-Models-Understand-Auditory-Knowledge-without-Hearing","children":"Jaeho Lee이 [arXiv]에 게시한 'AuditoryBench++: Can Language Models Understand Auditory Knowledge without Hearing?' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-23-AuditoryBench-Can-Language-Models-Understand-Auditory-Knowledge-without-Hearing"}]]}]]}],["$","article","2025-9-19-FlowRL-Matching-Reward-Distributions-for-LLM-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-19-FlowRL-Matching-Reward-Distributions-for-LLM-Reasoning","children":"[논문리뷰] FlowRL: Matching Reward Distributions for LLM Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-19-FlowRL-Matching-Reward-Distributions-for-LLM-Reasoning","children":"Hengli Li이 [arXiv]에 게시한 'FlowRL: Matching Reward Distributions for LLM Reasoning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-19 13:12:21+0900","children":"2025년 9월 19일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-19-FlowRL-Matching-Reward-Distributions-for-LLM-Reasoning"}]]}]]}],["$","article","2025-9-18-THOR-Tool-Integrated-Hierarchical-Optimization-via-RL-for-Mathematical-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-18-THOR-Tool-Integrated-Hierarchical-Optimization-via-RL-for-Mathematical-Reasoning","children":"[논문리뷰] THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-18-THOR-Tool-Integrated-Hierarchical-Optimization-via-RL-for-Mathematical-Reasoning","children":"Yicheng Pan이 [arXiv]에 게시한 'THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-18 13:07:00+0900","children":"2025년 9월 18일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-18-THOR-Tool-Integrated-Hierarchical-Optimization-via-RL-for-Mathematical-Reasoning"}]]}]]}],["$","article","2025-9-18-Hala-Technical-Report-Building-Arabic-Centric-Instruction-Translation-Models-at-Scale",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-18-Hala-Technical-Report-Building-Arabic-Centric-Instruction-Translation-Models-at-Scale","children":"[논문리뷰] Hala Technical Report: Building Arabic-Centric Instruction & Translation Models at Scale"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-18-Hala-Technical-Report-Building-Arabic-Centric-Instruction-Translation-Models-at-Scale","children":"Bernard Ghanem이 [arXiv]에 게시한 'Hala Technical Report: Building Arabic-Centric Instruction & Translation Models at Scale' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-18 13:07:00+0900","children":"2025년 9월 18일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-18-Hala-Technical-Report-Building-Arabic-Centric-Instruction-Translation-Models-at-Scale"}]]}]]}],["$","article","2025-9-17-Towards-General-Agentic-Intelligence-via-Environment-Scaling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-17-Towards-General-Agentic-Intelligence-via-Environment-Scaling","children":"[논문리뷰] Towards General Agentic Intelligence via Environment Scaling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-17-Towards-General-Agentic-Intelligence-via-Environment-Scaling","children":"Guangyu Li이 [arXiv]에 게시한 'Towards General Agentic Intelligence via Environment Scaling' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-17 13:16:01+0900","children":"2025년 9월 17일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-17-Towards-General-Agentic-Intelligence-via-Environment-Scaling"}]]}]]}],["$","article","2025-9-17-Multimodal-Reasoning-for-Science-Technical-Report-and-1st-Place-Solution-to-the-ICML-2025-SeePhys-Challenge",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-17-Multimodal-Reasoning-for-Science-Technical-Report-and-1st-Place-Solution-to-the-ICML-2025-SeePhys-Challenge","children":"[논문리뷰] Multimodal Reasoning for Science: Technical Report and 1st Place Solution to the ICML 2025 SeePhys Challenge"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-17-Multimodal-Reasoning-for-Science-Technical-Report-and-1st-Place-Solution-to-the-ICML-2025-SeePhys-Challenge","children":"Wentao Zhang이 [arXiv]에 게시한 'Multimodal Reasoning for Science: Technical Report and 1st Place Solution to the ICML 2025 SeePhys Challenge' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-17 13:16:01+0900","children":"2025년 9월 17일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-17-Multimodal-Reasoning-for-Science-Technical-Report-and-1st-Place-Solution-to-the-ICML-2025-SeePhys-Challenge"}]]}]]}],["$","article","2025-9-16-UI-S1-Advancing-GUI-Automation-via-Semi-online-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-16-UI-S1-Advancing-GUI-Automation-via-Semi-online-Reinforcement-Learning","children":"[논문리뷰] UI-S1: Advancing GUI Automation via Semi-online Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-16-UI-S1-Advancing-GUI-Automation-via-Semi-online-Reinforcement-Learning","children":"Yongliang Shen이 [arXiv]에 게시한 'UI-S1: Advancing GUI Automation via Semi-online Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-16 13:16:41+0900","children":"2025년 9월 16일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-16-UI-S1-Advancing-GUI-Automation-via-Semi-online-Reinforcement-Learning"}]]}]]}],["$","article","2025-9-16-EthicsMH-A-Pilot-Benchmark-for-Ethical-Reasoning-in-Mental-Health-AI",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-16-EthicsMH-A-Pilot-Benchmark-for-Ethical-Reasoning-in-Mental-Health-AI","children":"[논문리뷰] EthicsMH: A Pilot Benchmark for Ethical Reasoning in Mental Health AI"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-16-EthicsMH-A-Pilot-Benchmark-for-Ethical-Reasoning-in-Mental-Health-AI","children":"UVSKKR이 [arXiv]에 게시한 'EthicsMH: A Pilot Benchmark for Ethical Reasoning in Mental Health AI' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-16 13:16:41+0900","children":"2025년 9월 16일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-16-EthicsMH-A-Pilot-Benchmark-for-Ethical-Reasoning-in-Mental-Health-AI"}]]}]]}],["$","article","2025-9-15-The-Illusion-of-Diminishing-Returns-Measuring-Long-Horizon-Execution-in-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-15-The-Illusion-of-Diminishing-Returns-Measuring-Long-Horizon-Execution-in-LLMs","children":"[논문리뷰] The Illusion of Diminishing Returns: Measuring Long Horizon Execution in LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-15-The-Illusion-of-Diminishing-Returns-Measuring-Long-Horizon-Execution-in-LLMs","children":"Jonas Geiping이 [arXiv]에 게시한 'The Illusion of Diminishing Returns: Measuring Long Horizon Execution in LLMs' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-15 13:12:08+0900","children":"2025년 9월 15일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-15-The-Illusion-of-Diminishing-Returns-Measuring-Long-Horizon-Execution-in-LLMs"}]]}]]}],["$","article","2025-9-15-QuantAgent-Price-Driven-Multi-Agent-LLMs-for-High-Frequency-Trading",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-15-QuantAgent-Price-Driven-Multi-Agent-LLMs-for-High-Frequency-Trading","children":"[논문리뷰] QuantAgent: Price-Driven Multi-Agent LLMs for High-Frequency Trading"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-15-QuantAgent-Price-Driven-Multi-Agent-LLMs-for-High-Frequency-Trading","children":"Chenyu You이 [arXiv]에 게시한 'QuantAgent: Price-Driven Multi-Agent LLMs for High-Frequency Trading' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-15 13:12:08+0900","children":"2025년 9월 15일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-15-QuantAgent-Price-Driven-Multi-Agent-LLMs-for-High-Frequency-Trading"}]]}]]}],["$","article","2025-9-10-SimpleQA-Verified-A-Reliable-Factuality-Benchmark-to-Measure-Parametric-Knowledge",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-10-SimpleQA-Verified-A-Reliable-Factuality-Benchmark-to-Measure-Parametric-Knowledge","children":"[논문리뷰] SimpleQA Verified: A Reliable Factuality Benchmark to Measure Parametric Knowledge"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-10-SimpleQA-Verified-A-Reliable-Factuality-Benchmark-to-Measure-Parametric-Knowledge","children":"Dipanjan Das이 [arXiv]에 게시한 'SimpleQA Verified: A Reliable Factuality Benchmark to Measure Parametric Knowledge' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-10 13:11:01+0900","children":"2025년 9월 10일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-10-SimpleQA-Verified-A-Reliable-Factuality-Benchmark-to-Measure-Parametric-Knowledge"}]]}]]}],["$","article","2025-9-10-Parallel-R1-Towards-Parallel-Thinking-via-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-10-Parallel-R1-Towards-Parallel-Thinking-via-Reinforcement-Learning","children":"[논문리뷰] Parallel-R1: Towards Parallel Thinking via Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-10-Parallel-R1-Towards-Parallel-Thinking-via-Reinforcement-Learning","children":"Xinyu Yang이 [arXiv]에 게시한 'Parallel-R1: Towards Parallel Thinking via Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-10 13:11:01+0900","children":"2025년 9월 10일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-10-Parallel-R1-Towards-Parallel-Thinking-via-Reinforcement-Learning"}]]}]]}],["$","article","2025-9-10-Language-Self-Play-For-Data-Free-Training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-10-Language-Self-Play-For-Data-Free-Training","children":"[논문리뷰] Language Self-Play For Data-Free Training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-10-Language-Self-Play-For-Data-Free-Training","children":"Vijai Mohan이 [arXiv]에 게시한 'Language Self-Play For Data-Free Training' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-10 13:11:01+0900","children":"2025년 9월 10일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-10-Language-Self-Play-For-Data-Free-Training"}]]}]]}],["$","article","2025-9-9-Test-Time-Scaling-in-Reasoning-Models-Is-Not-Effective-for-Knowledge-Intensive-Tasks-Yet",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-Test-Time-Scaling-in-Reasoning-Models-Is-Not-Effective-for-Knowledge-Intensive-Tasks-Yet","children":"[논문리뷰] Test-Time Scaling in Reasoning Models Is Not Effective for Knowledge-Intensive Tasks Yet"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-Test-Time-Scaling-in-Reasoning-Models-Is-Not-Effective-for-Knowledge-Intensive-Tasks-Yet","children":"See-Kiong Ng이 [arXiv]에 게시한 'Test-Time Scaling in Reasoning Models Is Not Effective for Knowledge-Intensive Tasks Yet' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-9-Test-Time-Scaling-in-Reasoning-Models-Is-Not-Effective-for-Knowledge-Intensive-Tasks-Yet"}]]}]]}],["$","article","2025-9-9-Revolutionizing-Reinforcement-Learning-Framework-for-Diffusion-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-Revolutionizing-Reinforcement-Learning-Framework-for-Diffusion-Large-Language-Models","children":"[논문리뷰] Revolutionizing Reinforcement Learning Framework for Diffusion Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-Revolutionizing-Reinforcement-Learning-Framework-for-Diffusion-Large-Language-Models","children":"Ke Shen이 [arXiv]에 게시한 'Revolutionizing Reinforcement Learning Framework for Diffusion Large Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-9-Revolutionizing-Reinforcement-Learning-Framework-for-Diffusion-Large-Language-Models"}]]}]]}],["$","article","2025-9-8-Symbolic-Graphics-Programming-with-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-8-Symbolic-Graphics-Programming-with-Large-Language-Models","children":"[논문리뷰] Symbolic Graphics Programming with Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-8-Symbolic-Graphics-Programming-with-Large-Language-Models","children":"Kaipeng Zhang이 [arXiv]에 게시한 'Symbolic Graphics Programming with Large Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-08 13:10:18+0900","children":"2025년 9월 8일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-8-Symbolic-Graphics-Programming-with-Large-Language-Models"}]]}]]}],["$","article","2025-9-8-Behavioral-Fingerprinting-of-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-8-Behavioral-Fingerprinting-of-Large-Language-Models","children":"[논문리뷰] Behavioral Fingerprinting of Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-8-Behavioral-Fingerprinting-of-Large-Language-Models","children":"Xing Li이 [arXiv]에 게시한 'Behavioral Fingerprinting of Large Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-08 13:10:18+0900","children":"2025년 9월 8일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-8-Behavioral-Fingerprinting-of-Large-Language-Models"}]]}]]}],["$","article","2025-9-5-Drivel-ology-Challenging-LLMs-with-Interpreting-Nonsense-with-Depth",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-5-Drivel-ology-Challenging-LLMs-with-Interpreting-Nonsense-with-Depth","children":"[논문리뷰] Drivel-ology: Challenging LLMs with Interpreting Nonsense with Depth"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-5-Drivel-ology-Challenging-LLMs-with-Interpreting-Nonsense-with-Depth","children":"Chi-Li Chen이 [arXiv]에 게시한 'Drivel-ology: Challenging LLMs with Interpreting Nonsense with Depth' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-05 13:07:20+0900","children":"2025년 9월 5일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-5-Drivel-ology-Challenging-LLMs-with-Interpreting-Nonsense-with-Depth"}]]}]]}],["$","article","2025-9-4-Open-Data-Synthesis-For-Deep-Research",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-4-Open-Data-Synthesis-For-Deep-Research","children":"[논문리뷰] Open Data Synthesis For Deep Research"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-4-Open-Data-Synthesis-For-Deep-Research","children":"Zheng Liu이 [arXiv]에 게시한 'Open Data Synthesis For Deep Research' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-04 12:56:15+0900","children":"2025년 9월 4일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-4-Open-Data-Synthesis-For-Deep-Research"}]]}]]}],["$","article","2025-9-3-VerlTool-Towards-Holistic-Agentic-Reinforcement-Learning-with-Tool-Use",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-VerlTool-Towards-Holistic-Agentic-Reinforcement-Learning-with-Tool-Use","children":"[논문리뷰] VerlTool: Towards Holistic Agentic Reinforcement Learning with Tool Use"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-VerlTool-Towards-Holistic-Agentic-Reinforcement-Learning-with-Tool-Use","children":"Zhiheng Lyu이 [arXiv]에 게시한 'VerlTool: Towards Holistic Agentic Reinforcement Learning with Tool Use' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-3-VerlTool-Towards-Holistic-Agentic-Reinforcement-Learning-with-Tool-Use"}]]}]]}],["$","article","2025-9-3-The-Landscape-of-Agentic-Reinforcement-Learning-for-LLMs-A-Survey",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-The-Landscape-of-Agentic-Reinforcement-Learning-for-LLMs-A-Survey","children":"[논문리뷰] The Landscape of Agentic Reinforcement Learning for LLMs: A Survey"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-The-Landscape-of-Agentic-Reinforcement-Learning-for-LLMs-A-Survey","children":"Hejia Geng이 [arXiv]에 게시한 'The Landscape of Agentic Reinforcement Learning for LLMs: A Survey' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-3-The-Landscape-of-Agentic-Reinforcement-Learning-for-LLMs-A-Survey"}]]}]]}],["$","article","2025-9-3-SimpleTIR-End-to-End-Reinforcement-Learning-for-Multi-Turn-Tool-Integrated-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-SimpleTIR-End-to-End-Reinforcement-Learning-for-Multi-Turn-Tool-Integrated-Reasoning","children":"[논문리뷰] SimpleTIR: End-to-End Reinforcement Learning for Multi-Turn Tool-Integrated Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-SimpleTIR-End-to-End-Reinforcement-Learning-for-Multi-Turn-Tool-Integrated-Reasoning","children":"Qian Liu이 [arXiv]에 게시한 'SimpleTIR: End-to-End Reinforcement Learning for Multi-Turn Tool-Integrated Reasoning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-3-SimpleTIR-End-to-End-Reinforcement-Learning-for-Multi-Turn-Tool-Integrated-Reasoning"}]]}]]}],["$","article","2025-9-3-SQL-of-Thought-Multi-agentic-Text-to-SQL-with-Guided-Error-Correction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-SQL-of-Thought-Multi-agentic-Text-to-SQL-with-Guided-Error-Correction","children":"[논문리뷰] SQL-of-Thought: Multi-agentic Text-to-SQL with Guided Error Correction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-SQL-of-Thought-Multi-agentic-Text-to-SQL-with-Guided-Error-Correction","children":"bindsch이 [arXiv]에 게시한 'SQL-of-Thought: Multi-agentic Text-to-SQL with Guided Error Correction' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-3-SQL-of-Thought-Multi-agentic-Text-to-SQL-with-Guided-Error-Correction"}]]}]]}],["$","article","2025-9-3-OpenVision-2-A-Family-of-Generative-Pretrained-Visual-Encoders-for-Multimodal-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-OpenVision-2-A-Family-of-Generative-Pretrained-Visual-Encoders-for-Multimodal-Learning","children":"[논문리뷰] OpenVision 2: A Family of Generative Pretrained Visual Encoders for Multimodal Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-OpenVision-2-A-Family-of-Generative-Pretrained-Visual-Encoders-for-Multimodal-Learning","children":"Zirui Wang이 [arXiv]에 게시한 'OpenVision 2: A Family of Generative Pretrained Visual Encoders for Multimodal Learning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-3-OpenVision-2-A-Family-of-Generative-Pretrained-Visual-Encoders-for-Multimodal-Learning"}]]}]]}],["$","article","2025-9-3-Implicit-Actor-Critic-Coupling-via-a-Supervised-Learning-Framework-for-RLVR",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-Implicit-Actor-Critic-Coupling-via-a-Supervised-Learning-Framework-for-RLVR","children":"[논문리뷰] Implicit Actor Critic Coupling via a Supervised Learning Framework for RLVR"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-Implicit-Actor-Critic-Coupling-via-a-Supervised-Learning-Framework-for-RLVR","children":"Lu Wang이 [arXiv]에 게시한 'Implicit Actor Critic Coupling via a Supervised Learning Framework for RLVR' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-3-Implicit-Actor-Critic-Coupling-via-a-Supervised-Learning-Framework-for-RLVR"}]]}]]}],["$","article","2025-9-3-Fantastic-Pretraining-Optimizers-and-Where-to-Find-Them",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-Fantastic-Pretraining-Optimizers-and-Where-to-Find-Them","children":"[논문리뷰] Fantastic Pretraining Optimizers and Where to Find Them"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-Fantastic-Pretraining-Optimizers-and-Where-to-Find-Them","children":"Percy Liang이 [arXiv]에 게시한 'Fantastic Pretraining Optimizers and Where to Find Them' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-3-Fantastic-Pretraining-Optimizers-and-Where-to-Find-Them"}]]}]]}],["$","article","2025-9-3-AMBEDKAR-A-Multi-level-Bias-Elimination-through-a-Decoding-Approach-with-Knowledge-Augmentation-for-Robust-Constitutional-Alignment-of-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-AMBEDKAR-A-Multi-level-Bias-Elimination-through-a-Decoding-Approach-with-Knowledge-Augmentation-for-Robust-Constitutional-Alignment-of-Language-Models","children":"[논문리뷰] AMBEDKAR-A Multi-level Bias Elimination through a Decoding Approach with Knowledge Augmentation for Robust Constitutional Alignment of Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-AMBEDKAR-A-Multi-level-Bias-Elimination-through-a-Decoding-Approach-with-Knowledge-Augmentation-for-Robust-Constitutional-Alignment-of-Language-Models","children":"Rahul Karthikeyan이 [arXiv]에 게시한 'AMBEDKAR-A Multi-level Bias Elimination through a Decoding Approach with Knowledge Augmentation for Robust Constitutional Alignment of Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-3-AMBEDKAR-A-Multi-level-Bias-Elimination-through-a-Decoding-Approach-with-Knowledge-Augmentation-for-Robust-Constitutional-Alignment-of-Language-Models"}]]}]]}],["$","article","2025-9-1-Think-in-Games-Learning-to-Reason-in-Games-via-Reinforcement-Learning-with-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-1-Think-in-Games-Learning-to-Reason-in-Games-via-Reinforcement-Learning-with-Large-Language-Models","children":"[논문리뷰] Think in Games: Learning to Reason in Games via Reinforcement Learning with Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-9-1-Think-in-Games-Learning-to-Reason-in-Games-via-Reinforcement-Learning-with-Large-Language-Models","children":"Yifan Lu이 [arXiv]에 게시한 'Think in Games: Learning to Reason in Games via Reinforcement Learning with Large Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-01 13:14:34+0900","children":"2025년 9월 1일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-9-1-Think-in-Games-Learning-to-Reason-in-Games-via-Reinforcement-Learning-with-Large-Language-Models"}]]}]]}],["$","article","2025-8-29-TCIA-A-Task-Centric-Instruction-Augmentation-Method-for-Instruction-Finetuning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-TCIA-A-Task-Centric-Instruction-Augmentation-Method-for-Instruction-Finetuning","children":"[논문리뷰] TCIA: A Task-Centric Instruction Augmentation Method for Instruction Finetuning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-TCIA-A-Task-Centric-Instruction-Augmentation-Method-for-Instruction-Finetuning","children":"Simin Ma이 [arXiv]에 게시한 'TCIA: A Task-Centric Instruction Augmentation Method for Instruction Finetuning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-29-TCIA-A-Task-Centric-Instruction-Augmentation-Method-for-Instruction-Finetuning"}]]}]]}],["$","article","2025-8-29-Provable-Benefits-of-In-Tool-Learning-for-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-Provable-Benefits-of-In-Tool-Learning-for-Large-Language-Models","children":"[논문리뷰] Provable Benefits of In-Tool Learning for Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-Provable-Benefits-of-In-Tool-Learning-for-Large-Language-Models","children":"Vivien Cabannes이 [arXiv]에 게시한 'Provable Benefits of In-Tool Learning for Large Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-29-Provable-Benefits-of-In-Tool-Learning-for-Large-Language-Models"}]]}]]}],["$","article","2025-8-28-Predicting-the-Order-of-Upcoming-Tokens-Improves-Language-Modeling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-28-Predicting-the-Order-of-Upcoming-Tokens-Improves-Language-Modeling","children":"[논문리뷰] Predicting the Order of Upcoming Tokens Improves Language Modeling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-28-Predicting-the-Order-of-Upcoming-Tokens-Improves-Language-Modeling","children":"Alham Fikri Aji이 [arXiv]에 게시한 'Predicting the Order of Upcoming Tokens Improves Language Modeling' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-28 13:10:39+0900","children":"2025년 8월 28일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-28-Predicting-the-Order-of-Upcoming-Tokens-Improves-Language-Modeling"}]]}]]}],["$","article","2025-8-28-AudioStory-Generating-Long-Form-Narrative-Audio-with-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-28-AudioStory-Generating-Long-Form-Narrative-Audio-with-Large-Language-Models","children":"[논문리뷰] AudioStory: Generating Long-Form Narrative Audio with Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-28-AudioStory-Generating-Long-Form-Narrative-Audio-with-Large-Language-Models","children":"Yixiao Ge이 [arXiv]에 게시한 'AudioStory: Generating Long-Form Narrative Audio with Large Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-28 13:10:39+0900","children":"2025년 8월 28일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-28-AudioStory-Generating-Long-Form-Narrative-Audio-with-Large-Language-Models"}]]}]]}],["$","article","2025-8-27-Unraveling-the-cognitive-patterns-of-Large-Language-Models-through-module-communities",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-Unraveling-the-cognitive-patterns-of-Large-Language-Models-through-module-communities","children":"[논문리뷰] Unraveling the cognitive patterns of Large Language Models through module communities"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-Unraveling-the-cognitive-patterns-of-Large-Language-Models-through-module-communities","children":"Jianxi Gao이 [arXiv]에 게시한 'Unraveling the cognitive patterns of Large Language Models through module communities' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-27-Unraveling-the-cognitive-patterns-of-Large-Language-Models-through-module-communities"}]]}]]}],["$","article","2025-8-27-TreePO-Bridging-the-Gap-of-Policy-Optimization-and-Efficacy-and-Inference-Efficiency-with-Heuristic-Tree-based-Modeling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-TreePO-Bridging-the-Gap-of-Policy-Optimization-and-Efficacy-and-Inference-Efficiency-with-Heuristic-Tree-based-Modeling","children":"[논문리뷰] TreePO: Bridging the Gap of Policy Optimization and Efficacy and Inference Efficiency with Heuristic Tree-based Modeling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-TreePO-Bridging-the-Gap-of-Policy-Optimization-and-Efficacy-and-Inference-Efficiency-with-Heuristic-Tree-based-Modeling","children":"Zhoufutu Wen이 [arXiv]에 게시한 'TreePO: Bridging the Gap of Policy Optimization and Efficacy and Inference Efficiency with Heuristic Tree-based Modeling' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-27-TreePO-Bridging-the-Gap-of-Policy-Optimization-and-Efficacy-and-Inference-Efficiency-with-Heuristic-Tree-based-Modeling"}]]}]]}],["$","article","2025-8-27-QueryBandits-for-Hallucination-Mitigation-Exploiting-Semantic-Features-for-No-Regret-Rewriting",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-QueryBandits-for-Hallucination-Mitigation-Exploiting-Semantic-Features-for-No-Regret-Rewriting","children":"[논문리뷰] QueryBandits for Hallucination Mitigation: Exploiting Semantic Features for No-Regret Rewriting"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-QueryBandits-for-Hallucination-Mitigation-Exploiting-Semantic-Features-for-No-Regret-Rewriting","children":"Manuela Veloso이 [arXiv]에 게시한 'QueryBandits for Hallucination Mitigation: Exploiting Semantic Features for No-Regret Rewriting' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-27-QueryBandits-for-Hallucination-Mitigation-Exploiting-Semantic-Features-for-No-Regret-Rewriting"}]]}]]}],["$","article","2025-8-27-Optimal-Sparsity-of-Mixture-of-Experts-Language-Models-for-Reasoning-Tasks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-Optimal-Sparsity-of-Mixture-of-Experts-Language-Models-for-Reasoning-Tasks","children":"[논문리뷰] Optimal Sparsity of Mixture-of-Experts Language Models for Reasoning Tasks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-Optimal-Sparsity-of-Mixture-of-Experts-Language-Models-for-Reasoning-Tasks","children":"Daisuke Nohara이 [arXiv]에 게시한 'Optimal Sparsity of Mixture-of-Experts Language Models for Reasoning Tasks' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-27-Optimal-Sparsity-of-Mixture-of-Experts-Language-Models-for-Reasoning-Tasks"}]]}]]}],["$","article","2025-8-27-Demystifying-Scientific-Problem-Solving-in-LLMs-by-Probing-Knowledge-and-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-Demystifying-Scientific-Problem-Solving-in-LLMs-by-Probing-Knowledge-and-Reasoning","children":"[논문리뷰] Demystifying Scientific Problem-Solving in LLMs by Probing Knowledge and Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-Demystifying-Scientific-Problem-Solving-in-LLMs-by-Probing-Knowledge-and-Reasoning","children":"Arman Cohan이 [arXiv]에 게시한 'Demystifying Scientific Problem-Solving in LLMs by Probing Knowledge and Reasoning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-27-Demystifying-Scientific-Problem-Solving-in-LLMs-by-Probing-Knowledge-and-Reasoning"}]]}]]}],["$","article","2025-8-27-ClaimGen-CN-A-Large-scale-Chinese-Dataset-for-Legal-Claim-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-ClaimGen-CN-A-Large-scale-Chinese-Dataset-for-Legal-Claim-Generation","children":"[논문리뷰] ClaimGen-CN: A Large-scale Chinese Dataset for Legal Claim Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-ClaimGen-CN-A-Large-scale-Chinese-Dataset-for-Legal-Claim-Generation","children":"Kun Kuang이 [arXiv]에 게시한 'ClaimGen-CN: A Large-scale Chinese Dataset for Legal Claim Generation' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-27-ClaimGen-CN-A-Large-scale-Chinese-Dataset-for-Legal-Claim-Generation"}]]}]]}],["$","article","2025-8-27-CMPhysBench-A-Benchmark-for-Evaluating-Large-Language-Models-in-Condensed-Matter-Physics",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-CMPhysBench-A-Benchmark-for-Evaluating-Large-Language-Models-in-Condensed-Matter-Physics","children":"[논문리뷰] CMPhysBench: A Benchmark for Evaluating Large Language Models in Condensed Matter Physics"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-CMPhysBench-A-Benchmark-for-Evaluating-Large-Language-Models-in-Condensed-Matter-Physics","children":"Dongchen Huang이 [arXiv]에 게시한 'CMPhysBench: A Benchmark for Evaluating Large Language Models in Condensed Matter Physics' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-27-CMPhysBench-A-Benchmark-for-Evaluating-Large-Language-Models-in-Condensed-Matter-Physics"}]]}]]}],["$","article","2025-8-26-Explain-Before-You-Answer-A-Survey-on-Compositional-Visual-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-Explain-Before-You-Answer-A-Survey-on-Compositional-Visual-Reasoning","children":"[논문리뷰] Explain Before You Answer: A Survey on Compositional Visual Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-Explain-Before-You-Answer-A-Survey-on-Compositional-Visual-Reasoning","children":"Xin Zheng이 [arXiv]에 게시한 'Explain Before You Answer: A Survey on Compositional Visual Reasoning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-26 13:21:57+0900","children":"2025년 8월 26일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-26-Explain-Before-You-Answer-A-Survey-on-Compositional-Visual-Reasoning"}]]}]]}],["$","article","2025-8-26-Breaking-the-Exploration-Bottleneck-Rubric-Scaffolded-Reinforcement-Learning-for-General-LLM-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-Breaking-the-Exploration-Bottleneck-Rubric-Scaffolded-Reinforcement-Learning-for-General-LLM-Reasoning","children":"[논문리뷰] Breaking the Exploration Bottleneck: Rubric-Scaffolded Reinforcement Learning for General LLM Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-Breaking-the-Exploration-Bottleneck-Rubric-Scaffolded-Reinforcement-Learning-for-General-LLM-Reasoning","children":"Jiale Zhao이 [arXiv]에 게시한 'Breaking the Exploration Bottleneck: Rubric-Scaffolded Reinforcement Learning for General LLM Reasoning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-26 13:21:57+0900","children":"2025년 8월 26일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-26-Breaking-the-Exploration-Bottleneck-Rubric-Scaffolded-Reinforcement-Learning-for-General-LLM-Reasoning"}]]}]]}],["$","article","2025-8-25-End-to-End-Agentic-RAG-System-Training-for-Traceable-Diagnostic-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-25-End-to-End-Agentic-RAG-System-Training-for-Traceable-Diagnostic-Reasoning","children":"[논문리뷰] End-to-End Agentic RAG System Training for Traceable Diagnostic Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-25-End-to-End-Agentic-RAG-System-Training-for-Traceable-Diagnostic-Reasoning","children":"Pengcheng Qiu이 [arXiv]에 게시한 'End-to-End Agentic RAG System Training for Traceable Diagnostic Reasoning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-25 13:13:07+0900","children":"2025년 8월 25일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-25-End-to-End-Agentic-RAG-System-Training-for-Traceable-Diagnostic-Reasoning"}]]}]]}],["$","article","2025-8-25-Beyond-Pass1-Self-Play-with-Variational-Problem-Synthesis-Sustains-RLVR",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-25-Beyond-Pass1-Self-Play-with-Variational-Problem-Synthesis-Sustains-RLVR","children":"[논문리뷰] Beyond Pass@1: Self-Play with Variational Problem Synthesis Sustains RLVR"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-25-Beyond-Pass1-Self-Play-with-Variational-Problem-Synthesis-Sustains-RLVR","children":"Ying Nian Wu이 [arXiv]에 게시한 'Beyond Pass@1: Self-Play with Variational Problem Synthesis Sustains RLVR' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-25 13:13:07+0900","children":"2025년 8월 25일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-25-Beyond-Pass1-Self-Play-with-Variational-Problem-Synthesis-Sustains-RLVR"}]]}]]}],["$","article","2025-8-22-Mobile-Agent-v3-Foundamental-Agents-for-GUI-Automation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-22-Mobile-Agent-v3-Foundamental-Agents-for-GUI-Automation","children":"[논문리뷰] Mobile-Agent-v3: Foundamental Agents for GUI Automation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-22-Mobile-Agent-v3-Foundamental-Agents-for-GUI-Automation","children":"Haowei Liu이 [arXiv]에 게시한 'Mobile-Agent-v3: Foundamental Agents for GUI Automation' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-22 13:10:52+0900","children":"2025년 8월 22일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-22-Mobile-Agent-v3-Foundamental-Agents-for-GUI-Automation"}]]}]]}],["$","article","2025-8-22-Fin-PRM-A-Domain-Specialized-Process-Reward-Model-for-Financial-Reasoning-in-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-22-Fin-PRM-A-Domain-Specialized-Process-Reward-Model-for-Financial-Reasoning-in-Large-Language-Models","children":"[논문리뷰] Fin-PRM: A Domain-Specialized Process Reward Model for Financial Reasoning in Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-22-Fin-PRM-A-Domain-Specialized-Process-Reward-Model-for-Financial-Reasoning-in-Large-Language-Models","children":"Lifan Guo이 [arXiv]에 게시한 'Fin-PRM: A Domain-Specialized Process Reward Model for Financial Reasoning in Large Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-22 13:10:52+0900","children":"2025년 8월 22일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-22-Fin-PRM-A-Domain-Specialized-Process-Reward-Model-for-Financial-Reasoning-in-Large-Language-Models"}]]}]]}],["$","article","2025-8-21-Quantization-Meets-dLLMs-A-Systematic-Study-of-Post-training-Quantization-for-Diffusion-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-Quantization-Meets-dLLMs-A-Systematic-Study-of-Post-training-Quantization-for-Diffusion-LLMs","children":"[논문리뷰] Quantization Meets dLLMs: A Systematic Study of Post-training Quantization for Diffusion LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-Quantization-Meets-dLLMs-A-Systematic-Study-of-Post-training-Quantization-for-Diffusion-LLMs","children":"Haobo Xu이 [arXiv]에 게시한 'Quantization Meets dLLMs: A Systematic Study of Post-training Quantization for Diffusion LLMs' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-21 13:15:28+0900","children":"2025년 8월 21일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-21-Quantization-Meets-dLLMs-A-Systematic-Study-of-Post-training-Quantization-for-Diffusion-LLMs"}]]}]]}],["$","article","2025-8-21-On-Policy-RL-Meets-Off-Policy-Experts-Harmonizing-Supervised-Fine-Tuning-and-Reinforcement-Learning-via-Dynamic-Weighting",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-On-Policy-RL-Meets-Off-Policy-Experts-Harmonizing-Supervised-Fine-Tuning-and-Reinforcement-Learning-via-Dynamic-Weighting","children":"[논문리뷰] On-Policy RL Meets Off-Policy Experts: Harmonizing Supervised Fine-Tuning and Reinforcement Learning via Dynamic Weighting"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-On-Policy-RL-Meets-Off-Policy-Experts-Harmonizing-Supervised-Fine-Tuning-and-Reinforcement-Learning-via-Dynamic-Weighting","children":"Guoyin Wang이 [arXiv]에 게시한 'On-Policy RL Meets Off-Policy Experts: Harmonizing Supervised Fine-Tuning and Reinforcement Learning via Dynamic Weighting' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-21 13:15:28+0900","children":"2025년 8월 21일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-21-On-Policy-RL-Meets-Off-Policy-Experts-Harmonizing-Supervised-Fine-Tuning-and-Reinforcement-Learning-via-Dynamic-Weighting"}]]}]]}],["$","article","2025-8-21-MCP-Universe-Benchmarking-Large-Language-Models-with-Real-World-Model-Context-Protocol-Servers",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-MCP-Universe-Benchmarking-Large-Language-Models-with-Real-World-Model-Context-Protocol-Servers","children":"[논문리뷰] MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-MCP-Universe-Benchmarking-Large-Language-Models-with-Real-World-Model-Context-Protocol-Servers","children":"Prathyusha Jwalapuram이 [arXiv]에 게시한 'MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-21 13:15:28+0900","children":"2025년 8월 21일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-21-MCP-Universe-Benchmarking-Large-Language-Models-with-Real-World-Model-Context-Protocol-Servers"}]]}]]}],["$","article","2025-8-21-From-AI-for-Science-to-Agentic-Science-A-Survey-on-Autonomous-Scientific-Discovery",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-From-AI-for-Science-to-Agentic-Science-A-Survey-on-Autonomous-Scientific-Discovery","children":"[논문리뷰] From AI for Science to Agentic Science: A Survey on Autonomous Scientific Discovery"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-From-AI-for-Science-to-Agentic-Science-A-Survey-on-Autonomous-Scientific-Discovery","children":"zijieqiu이 [arXiv]에 게시한 'From AI for Science to Agentic Science: A Survey on Autonomous Scientific Discovery' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-21 13:15:28+0900","children":"2025년 8월 21일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-21-From-AI-for-Science-to-Agentic-Science-A-Survey-on-Autonomous-Scientific-Discovery"}]]}]]}],["$","article","2025-8-20-Prompt-Orchestration-Markup-Language",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-Prompt-Orchestration-Markup-Language","children":"[논문리뷰] Prompt Orchestration Markup Language"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-Prompt-Orchestration-Markup-Language","children":"Yuqing Yang이 [arXiv]에 게시한 'Prompt Orchestration Markup Language' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-20-Prompt-Orchestration-Markup-Language"}]]}]]}],["$","article","2025-8-20-Beyond-Human-Judgment-A-Bayesian-Evaluation-of-LLMs-Moral-Values-Understanding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-Beyond-Human-Judgment-A-Bayesian-Evaluation-of-LLMs-Moral-Values-Understanding","children":"[논문리뷰] Beyond Human Judgment: A Bayesian Evaluation of LLMs' Moral Values Understanding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-Beyond-Human-Judgment-A-Bayesian-Evaluation-of-LLMs-Moral-Values-Understanding","children":"Alina Landowska이 [arXiv]에 게시한 'Beyond Human Judgment: A Bayesian Evaluation of LLMs' Moral Values Understanding' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-20-Beyond-Human-Judgment-A-Bayesian-Evaluation-of-LLMs-Moral-Values-Understanding"}]]}]]}],["$","article","2025-8-19-Speed-Always-Wins-A-Survey-on-Efficient-Architectures-for-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-Speed-Always-Wins-A-Survey-on-Efficient-Architectures-for-Large-Language-Models","children":"[논문리뷰] Speed Always Wins: A Survey on Efficient Architectures for Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-Speed-Always-Wins-A-Survey-on-Efficient-Architectures-for-Large-Language-Models","children":"Jusen Du이 [arXiv]에 게시한 'Speed Always Wins: A Survey on Efficient Architectures for Large Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-19 13:15:01+0900","children":"2025년 8월 19일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-19-Speed-Always-Wins-A-Survey-on-Efficient-Architectures-for-Large-Language-Models"}]]}]]}],["$","article","2025-8-19-Reinforcement-Learning-with-Rubric-Anchors",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-Reinforcement-Learning-with-Rubric-Anchors","children":"[논문리뷰] Reinforcement Learning with Rubric Anchors"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-Reinforcement-Learning-with-Rubric-Anchors","children":"Haokai Xu이 [arXiv]에 게시한 'Reinforcement Learning with Rubric Anchors' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-19 13:15:01+0900","children":"2025년 8월 19일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-19-Reinforcement-Learning-with-Rubric-Anchors"}]]}]]}],["$","article","2025-8-18-SSRL-Self-Search-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-18-SSRL-Self-Search-Reinforcement-Learning","children":"[논문리뷰] SSRL: Self-Search Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-18-SSRL-Self-Search-Reinforcement-Learning","children":"Yanxu Chen이 [arXiv]에 게시한 'SSRL: Self-Search Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-18 13:14:38+0900","children":"2025년 8월 18일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-18-SSRL-Self-Search-Reinforcement-Learning"}]]}]]}],["$","article","2025-8-15-Passk-Training-for-Adaptively-Balancing-Exploration-and-Exploitation-of-Large-Reasoning-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-15-Passk-Training-for-Adaptively-Balancing-Exploration-and-Exploitation-of-Large-Reasoning-Models","children":"[논문리뷰] Pass@k Training for Adaptively Balancing Exploration and Exploitation of Large Reasoning Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-15-Passk-Training-for-Adaptively-Balancing-Exploration-and-Exploitation-of-Large-Reasoning-Models","children":"Qinghao Ye이 [arXiv]에 게시한 'Pass@k Training for Adaptively Balancing Exploration and Exploitation of Large Reasoning Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-15 13:09:31+0900","children":"2025년 8월 15일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-15-Passk-Training-for-Adaptively-Balancing-Exploration-and-Exploitation-of-Large-Reasoning-Models"}]]}]]}],["$","article","2025-8-14-Mol-R1-Towards-Explicit-Long-CoT-Reasoning-in-Molecule-Discovery",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-Mol-R1-Towards-Explicit-Long-CoT-Reasoning-in-Molecule-Discovery","children":"[논문리뷰] Mol-R1: Towards Explicit Long-CoT Reasoning in Molecule Discovery"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-Mol-R1-Towards-Explicit-Long-CoT-Reasoning-in-Molecule-Discovery","children":"Di Zhang이 [arXiv]에 게시한 'Mol-R1: Towards Explicit Long-CoT Reasoning in Molecule Discovery' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-14 13:19:02+0900","children":"2025년 8월 14일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-14-Mol-R1-Towards-Explicit-Long-CoT-Reasoning-in-Molecule-Discovery"}]]}]]}],["$","article","2025-8-14-Cooper-Co-Optimizing-Policy-and-Reward-Models-in-Reinforcement-Learning-for-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-Cooper-Co-Optimizing-Policy-and-Reward-Models-in-Reinforcement-Learning-for-Large-Language-Models","children":"[논문리뷰] Cooper: Co-Optimizing Policy and Reward Models in Reinforcement Learning for Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-Cooper-Co-Optimizing-Policy-and-Reward-Models-in-Reinforcement-Learning-for-Large-Language-Models","children":"Guiyang Hou이 [arXiv]에 게시한 'Cooper: Co-Optimizing Policy and Reward Models in Reinforcement Learning for Large Language Models' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-14 13:19:02+0900","children":"2025년 8월 14일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-14-Cooper-Co-Optimizing-Policy-and-Reward-Models-in-Reinforcement-Learning-for-Large-Language-Models"}]]}]]}],["$","article","2025-8-14-Can-LLM-Generated-Textual-Explanations-Enhance-Model-Classification-Performance-An-Empirical-Study",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-Can-LLM-Generated-Textual-Explanations-Enhance-Model-Classification-Performance-An-Empirical-Study","children":"[논문리뷰] Can LLM-Generated Textual Explanations Enhance Model Classification Performance? An Empirical Study"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-Can-LLM-Generated-Textual-Explanations-Enhance-Model-Classification-Performance-An-Empirical-Study","children":"Gjergji Kasneci이 [arXiv]에 게시한 'Can LLM-Generated Textual Explanations Enhance Model Classification Performance? An Empirical Study' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-14 13:19:02+0900","children":"2025년 8월 14일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-14-Can-LLM-Generated-Textual-Explanations-Enhance-Model-Classification-Performance-An-Empirical-Study"}]]}]]}],["$","article","2025-8-14-AMFT-Aligning-LLM-Reasoners-by-Meta-Learning-the-Optimal-Imitation-Exploration-Balance",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-AMFT-Aligning-LLM-Reasoners-by-Meta-Learning-the-Optimal-Imitation-Exploration-Balance","children":"[논문리뷰] AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-AMFT-Aligning-LLM-Reasoners-by-Meta-Learning-the-Optimal-Imitation-Exploration-Balance","children":"Yong Li이 [arXiv]에 게시한 'AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-14 13:19:02+0900","children":"2025년 8월 14일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-14-AMFT-Aligning-LLM-Reasoners-by-Meta-Learning-the-Optimal-Imitation-Exploration-Balance"}]]}]]}],["$","article","2025-8-13-Train-Long-Think-Short-Curriculum-Learning-for-Efficient-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-Train-Long-Think-Short-Curriculum-Learning-for-Efficient-Reasoning","children":"[논문리뷰] Train Long, Think Short: Curriculum Learning for Efficient Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-Train-Long-Think-Short-Curriculum-Learning-for-Efficient-Reasoning","children":"Marzyeh Ghassemi이 [arXiv]에 게시한 'Train Long, Think Short: Curriculum Learning for Efficient Reasoning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-13-Train-Long-Think-Short-Curriculum-Learning-for-Efficient-Reasoning"}]]}]]}],["$","article","2025-8-13-Democratizing-Diplomacy-A-Harness-for-Evaluating-Any-Large-Language-Model-on-Full-Press-Diplomacy",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-Democratizing-Diplomacy-A-Harness-for-Evaluating-Any-Large-Language-Model-on-Full-Press-Diplomacy","children":"[논문리뷰] Democratizing Diplomacy: A Harness for Evaluating Any Large Language Model on Full-Press Diplomacy"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-Democratizing-Diplomacy-A-Harness-for-Evaluating-Any-Large-Language-Model-on-Full-Press-Diplomacy","children":"Elizabeth Karpinski이 [arXiv]에 게시한 'Democratizing Diplomacy: A Harness for Evaluating Any Large Language Model on Full-Press Diplomacy' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-13-Democratizing-Diplomacy-A-Harness-for-Evaluating-Any-Large-Language-Model-on-Full-Press-Diplomacy"}]]}]]}],["$","article","2025-8-12-ReasonRank-Empowering-Passage-Ranking-with-Strong-Reasoning-Ability",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-ReasonRank-Empowering-Passage-Ranking-with-Strong-Reasoning-Ability","children":"[논문리뷰] ReasonRank: Empowering Passage Ranking with Strong Reasoning Ability"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-ReasonRank-Empowering-Passage-Ranking-with-Strong-Reasoning-Ability","children":"Yuchen Li이 [arXiv]에 게시한 'ReasonRank: Empowering Passage Ranking with Strong Reasoning Ability' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-12-ReasonRank-Empowering-Passage-Ranking-with-Strong-Reasoning-Ability"}]]}]]}],["$","article","2025-8-12-Part-I-Tricks-or-Traps-A-Deep-Dive-into-RL-for-LLM-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-Part-I-Tricks-or-Traps-A-Deep-Dive-into-RL-for-LLM-Reasoning","children":"[논문리뷰] Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-Part-I-Tricks-or-Traps-A-Deep-Dive-into-RL-for-LLM-Reasoning","children":"Jiaheng Liu이 [arXiv]에 게시한 'Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-12-Part-I-Tricks-or-Traps-A-Deep-Dive-into-RL-for-LLM-Reasoning"}]]}]]}],["$","article","2025-8-8-Visual-Document-Understanding-and-Question-Answering-A-Multi-Agent-Collaboration-Framework-with-Test-Time-Scaling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-Visual-Document-Understanding-and-Question-Answering-A-Multi-Agent-Collaboration-Framework-with-Test-Time-Scaling","children":"[논문리뷰] Visual Document Understanding and Question Answering: A Multi-Agent Collaboration Framework with Test-Time Scaling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-Visual-Document-Understanding-and-Question-Answering-A-Multi-Agent-Collaboration-Framework-with-Test-Time-Scaling","children":"Ruolin Shen이 [arXiv]에 게시한 'Visual Document Understanding and Question Answering: A Multi-Agent Collaboration Framework with Test-Time Scaling' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-8-Visual-Document-Understanding-and-Question-Answering-A-Multi-Agent-Collaboration-Framework-with-Test-Time-Scaling"}]]}]]}],["$","article","2025-8-8-R-Zero-Self-Evolving-Reasoning-LLM-from-Zero-Data",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-R-Zero-Self-Evolving-Reasoning-LLM-from-Zero-Data","children":"[논문리뷰] R-Zero: Self-Evolving Reasoning LLM from Zero Data"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-R-Zero-Self-Evolving-Reasoning-LLM-from-Zero-Data","children":"Zongxia Li이 [arXiv]에 게시한 'R-Zero: Self-Evolving Reasoning LLM from Zero Data' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-8-R-Zero-Self-Evolving-Reasoning-LLM-from-Zero-Data"}]]}]]}],["$","article","2025-8-8-PRvL-Quantifying-the-Capabilities-and-Risks-of-Large-Language-Models-for-PII-Redaction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-PRvL-Quantifying-the-Capabilities-and-Risks-of-Large-Language-Models-for-PII-Redaction","children":"[논문리뷰] PRvL: Quantifying the Capabilities and Risks of Large Language Models for PII Redaction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-PRvL-Quantifying-the-Capabilities-and-Risks-of-Large-Language-Models-for-PII-Redaction","children":"Prajit Das이 [arXiv]에 게시한 'PRvL: Quantifying the Capabilities and Risks of Large Language Models for PII Redaction' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-8-PRvL-Quantifying-the-Capabilities-and-Risks-of-Large-Language-Models-for-PII-Redaction"}]]}]]}],["$","article","2025-8-8-I2CR-Intra-and-Inter-modal-Collaborative-Reflections-for-Multimodal-Entity-Linking",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-I2CR-Intra-and-Inter-modal-Collaborative-Reflections-for-Multimodal-Entity-Linking","children":"[논문리뷰] I2CR: Intra- and Inter-modal Collaborative Reflections for Multimodal Entity Linking"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-I2CR-Intra-and-Inter-modal-Collaborative-Reflections-for-Multimodal-Entity-Linking","children":"Chao Wang이 [arXiv]에 게시한 'I2CR: Intra- and Inter-modal Collaborative Reflections for Multimodal Entity Linking' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-8-I2CR-Intra-and-Inter-modal-Collaborative-Reflections-for-Multimodal-Entity-Linking"}]]}]]}],["$","article","2025-8-8-Hop-Skip-and-Overthink-Diagnosing-Why-Reasoning-Models-Fumble-during-Multi-Hop-Analysis",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-Hop-Skip-and-Overthink-Diagnosing-Why-Reasoning-Models-Fumble-during-Multi-Hop-Analysis","children":"[논문리뷰] Hop, Skip, and Overthink: Diagnosing Why Reasoning Models Fumble during Multi-Hop Analysis"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-Hop-Skip-and-Overthink-Diagnosing-Why-Reasoning-Models-Fumble-during-Multi-Hop-Analysis","children":"Reshmi Ghosh이 [arXiv]에 게시한 'Hop, Skip, and Overthink: Diagnosing Why Reasoning Models Fumble during Multi-Hop Analysis' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-8-Hop-Skip-and-Overthink-Diagnosing-Why-Reasoning-Models-Fumble-during-Multi-Hop-Analysis"}]]}]]}],["$","article","2025-8-8-Evaluating-Synthesizing-and-Enhancing-for-Customer-Support-Conversation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-Evaluating-Synthesizing-and-Enhancing-for-Customer-Support-Conversation","children":"[논문리뷰] Evaluating, Synthesizing, and Enhancing for Customer Support Conversation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-Evaluating-Synthesizing-and-Enhancing-for-Customer-Support-Conversation","children":"Feng Chen이 [arXiv]에 게시한 'Evaluating, Synthesizing, and Enhancing for Customer Support Conversation' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-8-Evaluating-Synthesizing-and-Enhancing-for-Customer-Support-Conversation"}]]}]]}],["$","article","2025-8-8-Are-Todays-LLMs-Ready-to-Explain-Well-Being-Concepts",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-Are-Todays-LLMs-Ready-to-Explain-Well-Being-Concepts","children":"[논문리뷰] Are Today's LLMs Ready to Explain Well-Being Concepts?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-Are-Todays-LLMs-Ready-to-Explain-Well-Being-Concepts","children":"Huan Liu이 [arXiv]에 게시한 'Are Today's LLMs Ready to Explain Well-Being Concepts?' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-8-Are-Todays-LLMs-Ready-to-Explain-Well-Being-Concepts"}]]}]]}],["$","article","2025-8-7-Training-Long-Context-Multi-Turn-Software-Engineering-Agents-with-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-Training-Long-Context-Multi-Turn-Software-Engineering-Agents-with-Reinforcement-Learning","children":"[논문리뷰] Training Long-Context, Multi-Turn Software Engineering Agents with Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-Training-Long-Context-Multi-Turn-Software-Engineering-Agents-with-Reinforcement-Learning","children":"Maksim Nekrashevich이 [arXiv]에 게시한 'Training Long-Context, Multi-Turn Software Engineering Agents with Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-7-Training-Long-Context-Multi-Turn-Software-Engineering-Agents-with-Reinforcement-Learning"}]]}]]}],["$","article","2025-8-7-Sotopia-RL-Reward-Design-for-Social-Intelligence",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-Sotopia-RL-Reward-Design-for-Social-Intelligence","children":"[논문리뷰] Sotopia-RL: Reward Design for Social Intelligence"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-Sotopia-RL-Reward-Design-for-Social-Intelligence","children":"Keyang Xuan이 [arXiv]에 게시한 'Sotopia-RL: Reward Design for Social Intelligence' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-7-Sotopia-RL-Reward-Design-for-Social-Intelligence"}]]}]]}],["$","article","2025-8-7-Sculptor-Empowering-LLMs-with-Cognitive-Agency-via-Active-Context-Management",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-Sculptor-Empowering-LLMs-with-Cognitive-Agency-via-Active-Context-Management","children":"[논문리뷰] Sculptor: Empowering LLMs with Cognitive Agency via Active Context Management"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-Sculptor-Empowering-LLMs-with-Cognitive-Agency-via-Active-Context-Management","children":"Yunxin Liu이 [arXiv]에 게시한 'Sculptor: Empowering LLMs with Cognitive Agency via Active Context Management' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-7-Sculptor-Empowering-LLMs-with-Cognitive-Agency-via-Active-Context-Management"}]]}]]}],["$","article","2025-8-7-Reasoning-Language-Models-for-Root-Cause-Analysis-in-5G-Wireless-Networks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-Reasoning-Language-Models-for-Root-Cause-Analysis-in-5G-Wireless-Networks","children":"[논문리뷰] Reasoning Language Models for Root Cause Analysis in 5G Wireless Networks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-Reasoning-Language-Models-for-Root-Cause-Analysis-in-5G-Wireless-Networks","children":"Haozhe Zhang이 [arXiv]에 게시한 'Reasoning Language Models for Root Cause Analysis in 5G Wireless Networks' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-7-Reasoning-Language-Models-for-Root-Cause-Analysis-in-5G-Wireless-Networks"}]]}]]}],["$","article","2025-8-7-RL-PLUS-Countering-Capability-Boundary-Collapse-of-LLMs-in-Reinforcement-Learning-with-Hybrid-policy-Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-RL-PLUS-Countering-Capability-Boundary-Collapse-of-LLMs-in-Reinforcement-Learning-with-Hybrid-policy-Optimization","children":"[논문리뷰] RL-PLUS: Countering Capability Boundary Collapse of LLMs in Reinforcement Learning with Hybrid-policy Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-RL-PLUS-Countering-Capability-Boundary-Collapse-of-LLMs-in-Reinforcement-Learning-with-Hybrid-policy-Optimization","children":"Kechi Zhang이 [arXiv]에 게시한 'RL-PLUS: Countering Capability Boundary Collapse of LLMs in Reinforcement Learning with Hybrid-policy Optimization' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-7-RL-PLUS-Countering-Capability-Boundary-Collapse-of-LLMs-in-Reinforcement-Learning-with-Hybrid-policy-Optimization"}]]}]]}],["$","article","2025-8-7-EVOC2RUST-A-Skeleton-guided-Framework-for-Project-Level-C-to-Rust-Translation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-EVOC2RUST-A-Skeleton-guided-Framework-for-Project-Level-C-to-Rust-Translation","children":"[논문리뷰] EVOC2RUST: A Skeleton-guided Framework for Project-Level C-to-Rust Translation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-EVOC2RUST-A-Skeleton-guided-Framework-for-Project-Level-C-to-Rust-Translation","children":"Dong Chen이 [arXiv]에 게시한 'EVOC2RUST: A Skeleton-guided Framework for Project-Level C-to-Rust Translation' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-7-EVOC2RUST-A-Skeleton-guided-Framework-for-Project-Level-C-to-Rust-Translation"}]]}]]}],["$","article","2025-8-7-Agent-Lightning-Train-ANY-AI-Agents-with-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-Agent-Lightning-Train-ANY-AI-Agents-with-Reinforcement-Learning","children":"[논문리뷰] Agent Lightning: Train ANY AI Agents with Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-Agent-Lightning-Train-ANY-AI-Agents-with-Reinforcement-Learning","children":"Zilong Wang이 [arXiv]에 게시한 'Agent Lightning: Train ANY AI Agents with Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-7-Agent-Lightning-Train-ANY-AI-Agents-with-Reinforcement-Learning"}]]}]]}],["$","article","2025-8-6-CRINN-Contrastive-Reinforcement-Learning-for-Approximate-Nearest-Neighbor-Search",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-6-CRINN-Contrastive-Reinforcement-Learning-for-Approximate-Nearest-Neighbor-Search","children":"[논문리뷰] CRINN: Contrastive Reinforcement Learning for Approximate Nearest Neighbor Search"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-6-CRINN-Contrastive-Reinforcement-Learning-for-Approximate-Nearest-Neighbor-Search","children":"Jiwei Li이 [arXiv]에 게시한 'CRINN: Contrastive Reinforcement Learning for Approximate Nearest Neighbor Search' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-06 13:46:36+0900","children":"2025년 8월 6일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-6-CRINN-Contrastive-Reinforcement-Learning-for-Approximate-Nearest-Neighbor-Search"}]]}]]}],["$","article","2025-8-5-Beyond-the-Trade-off-Self-Supervised-Reinforcement-Learning-for-Reasoning-Models-Instruction-Following",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-5-Beyond-the-Trade-off-Self-Supervised-Reinforcement-Learning-for-Reasoning-Models-Instruction-Following","children":"[논문리뷰] Beyond the Trade-off: Self-Supervised Reinforcement Learning for Reasoning Models' Instruction Following"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-5-Beyond-the-Trade-off-Self-Supervised-Reinforcement-Learning-for-Reasoning-Models-Instruction-Following","children":"Jiaqing Liang이 [arXiv]에 게시한 'Beyond the Trade-off: Self-Supervised Reinforcement Learning for Reasoning Models' Instruction Following' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-05 11:40:52+0900","children":"2025년 8월 5일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-5-Beyond-the-Trade-off-Self-Supervised-Reinforcement-Learning-for-Reasoning-Models-Instruction-Following"}]]}]]}],["$","article","2025-8-5-AgentTTS-Large-Language-Model-Agent-for-Test-time-Compute-optimal-Scaling-Strategy-in-Complex-Tasks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-5-AgentTTS-Large-Language-Model-Agent-for-Test-time-Compute-optimal-Scaling-Strategy-in-Complex-Tasks","children":"[논문리뷰] AgentTTS: Large Language Model Agent for Test-time Compute-optimal Scaling Strategy in Complex Tasks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-5-AgentTTS-Large-Language-Model-Agent-for-Test-time-Compute-optimal-Scaling-Strategy-in-Complex-Tasks","children":"Zhiwei Zhang이 [arXiv]에 게시한 'AgentTTS: Large Language Model Agent for Test-time Compute-optimal Scaling Strategy in Complex Tasks' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-05 11:40:52+0900","children":"2025년 8월 5일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-5-AgentTTS-Large-Language-Model-Agent-for-Test-time-Compute-optimal-Scaling-Strategy-in-Complex-Tasks"}]]}]]}],["$","article","2025-8-4-SWE-Debate-Competitive-Multi-Agent-Debate-for-Software-Issue-Resolution",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-4-SWE-Debate-Competitive-Multi-Agent-Debate-for-Software-Issue-Resolution","children":"[논문리뷰] SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-4-SWE-Debate-Competitive-Multi-Agent-Debate-for-Software-Issue-Resolution","children":"Heng Lian이 [arXiv]에 게시한 'SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-04 12:17:01+0900","children":"2025년 8월 4일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-4-SWE-Debate-Competitive-Multi-Agent-Debate-for-Software-Issue-Resolution"}]]}]]}],["$","article","2025-8-3-Seed-Prover-Deep-and-Broad-Reasoning-for-Automated-Theorem-Proving",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-Seed-Prover-Deep-and-Broad-Reasoning-for-Automated-Theorem-Proving","children":"[논문리뷰] Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving"}]}],["$","div",null,{"className":"archive__item-excerpt","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-Seed-Prover-Deep-and-Broad-Reasoning-for-Automated-Theorem-Proving","children":"Zhicheng Jiang이 [arXiv]에 게시한 'Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving' 논문에 대한 자세한 리뷰입니다."}]}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-03 07:35:17+0900","children":"2025년 8월 3일"}],["$","$L4",null,{"postPermalink":"/ai/review/2025-8-3-Seed-Prover-Deep-and-Broad-Reasoning-for-Automated-Theorem-Proving"}]]}]]}]]}]]}]]}]}]]}]],null],null]},["$","$L5",null,{"parallelRouterKey":"children","segmentPath":["children","tags","children","$6","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L7",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},["$","$L5",null,{"parallelRouterKey":"children","segmentPath":["children","tags","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L7",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},[["$","html",null,{"lang":"ko","className":"no-js","children":[["$","head",null,{"children":[["$","meta",null,{"name":"msapplication-TileColor","content":"#ffc40d"}],["$","meta",null,{"name":"theme-color","content":"#ffffff"}],["$","link",null,{"rel":"dns-prefetch","href":"https://www.googletagmanager.com"}],["$","link",null,{"rel":"preconnect","href":"https://www.googletagmanager.com","crossOrigin":"anonymous"}],["$","link",null,{"rel":"dns-prefetch","href":"https://giscus.app"}],["$","link",null,{"rel":"preconnect","href":"https://giscus.app","crossOrigin":"anonymous"}],["$","meta",null,{"httpEquiv":"X-Content-Type-Options","content":"nosniff"}],["$","meta",null,{"name":"referrer","content":"strict-origin-when-cross-origin"}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"WebSite\",\"name\":\"secrett2633's blog\",\"url\":\"https://blog.secrett2633.cloud\",\"description\":\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\",\"inLanguage\":\"ko\",\"publisher\":{\"@type\":\"Person\",\"name\":\"secrett2633\",\"url\":\"https://blog.secrett2633.cloud\"}}"}}],["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"Person\",\"name\":\"secrett2633\",\"url\":\"https://blog.secrett2633.cloud\",\"sameAs\":[\"https://github.com/secrett2633\"]}"}}]]}],["$","body",null,{"className":"__className_f367f3 layout--default","children":[["$","a",null,{"href":"#main-content","className":"sr-only focus:not-sr-only focus:absolute focus:z-50 focus:p-4 focus:bg-white focus:text-blue-600","children":"본문으로 건너뛰기"}],["$","div",null,{"className":"min-h-screen bg-gray-50","children":[["$","$L8",null,{}],["$","main",null,{"id":"main-content","className":"initial-content","children":["$","$L5",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L7",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","div",null,{"className":"min-h-screen flex items-center justify-center bg-gray-50","children":["$","div",null,{"className":"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center","children":[["$","h1",null,{"className":"text-6xl font-bold text-primary-600 mb-4","children":"404"}],["$","h2",null,{"className":"text-2xl font-semibold text-gray-900 mb-4","children":"페이지를 찾을 수 없습니다"}],["$","p",null,{"className":"text-gray-600 mb-8","children":"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다."}],["$","$L3",null,{"href":"/","className":"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors","children":"홈으로 돌아가기"}]]}]}],"notFoundStyles":[],"styles":null}]}],["$","div",null,{"id":"footer","className":"page__footer","children":["$","footer",null,{"className":"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8","children":["$","div",null,{"className":"text-center text-gray-500 text-sm","children":["$","p",null,{"children":["© ",2026," secrett2633. All rights reserved."]}]}]}]}]]}],["$","$L9",null,{"src":"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY","strategy":"afterInteractive"}],["$","$L9",null,{"id":"gtag-init","strategy":"afterInteractive","children":"window.dataLayer = window.dataLayer || [];\n            function gtag(){dataLayer.push(arguments);}\n            gtag('js', new Date());\n            gtag('config', 'G-NE2W3CFPNY');"}]]}]]}],null],[["$","div",null,{"className":"flex items-center justify-center min-h-screen","role":"status","aria-label":"로딩 중","children":[["$","div",null,{"className":"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600"}],["$","span",null,{"className":"sr-only","children":"로딩 중..."}]]}],[],[]]],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/ddc331716d5e47a2.css","precedence":"next","crossOrigin":"$undefined"}]],[null,"$La"]]]]]
a:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"#Large Language Models - secrett2633's blog"}],["$","meta","3",{"name":"description","content":"Large Language Models 태그가 포함된 포스트 목록"}],["$","meta","4",{"name":"author","content":"secrett2633"}],["$","link","5",{"rel":"manifest","href":"/manifest.json","crossOrigin":"use-credentials"}],["$","meta","6",{"name":"keywords","content":"Django, Python, DevOps, AI, ML, 블로그, 기술"}],["$","meta","7",{"name":"creator","content":"secrett2633"}],["$","meta","8",{"name":"publisher","content":"secrett2633"}],["$","meta","9",{"name":"robots","content":"index, follow"}],["$","meta","10",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","11",{"rel":"canonical","href":"https://blog.secrett2633.cloud/tags/Large%20Language%20Models"}],["$","meta","12",{"name":"format-detection","content":"telephone=no, address=no, email=no"}],["$","meta","13",{"property":"og:title","content":"#Large Language Models - secrett2633's blog"}],["$","meta","14",{"property":"og:description","content":"Large Language Models 태그가 포함된 포스트 목록"}],["$","meta","15",{"property":"og:url","content":"https://blog.secrett2633.cloud/tags/Large%20Language%20Models"}],["$","meta","16",{"property":"og:type","content":"website"}],["$","meta","17",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","18",{"name":"twitter:title","content":"#Large Language Models - secrett2633's blog"}],["$","meta","19",{"name":"twitter:description","content":"Large Language Models 태그가 포함된 포스트 목록"}],["$","link","20",{"rel":"icon","href":"/icon.ico?6d9f34d4948640b8","type":"image/x-icon","sizes":"16x16"}],["$","meta","21",{"name":"next-size-adjust"}]]
1:null
