<!DOCTYPE html><html lang="ko" class="no-js"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/_next/static/css/d6cea809dcbae606.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-61c2b369a48bb953.js"/><script src="/_next/static/chunks/fd9d1056-0395f68b8cc78a20.js" async=""></script><script src="/_next/static/chunks/23-706b53707bbf0661.js" async=""></script><script src="/_next/static/chunks/main-app-cf4c503f60a850f8.js" async=""></script><script src="/_next/static/chunks/231-467e37449c5a68fc.js" async=""></script><script src="/_next/static/chunks/app/layout-135ad156a55a8fe5.js" async=""></script><script src="/_next/static/chunks/app/%5B...slug%5D/page-a0fe0cc578429896.js" async=""></script><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY"></script><title>secrett2633&#x27;s blog</title><meta name="description" content="기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"/><meta name="author" content="secrett2633"/><meta name="keywords" content="Django, Python, DevOps, AI, ML, 블로그, 기술"/><meta name="creator" content="secrett2633"/><meta name="publisher" content="secrett2633"/><meta name="robots" content="index, follow"/><meta name="googlebot" content="index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"/><link rel="canonical" href="https://blog.secrett2633.cloud/"/><meta name="format-detection" content="telephone=no, address=no, email=no"/><meta property="og:title" content="secrett2633&#x27;s blog"/><meta property="og:description" content="기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"/><meta property="og:url" content="https://blog.secrett2633.cloud/"/><meta property="og:site_name" content="secrett2633&#x27;s blog"/><meta property="og:locale" content="ko_KR"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="secrett2633&#x27;s blog"/><meta name="twitter:description" content="기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"/><link rel="icon" href="/icon.ico?6d9f34d4948640b8" type="image/x-icon" sizes="16x16"/><meta name="msapplication-TileColor" content="#ffc40d"/><meta name="theme-color" content="#ffffff"/><script>
              window.dataLayer = window.dataLayer || [];
              function gtag(){dataLayer.push(arguments);}
              gtag('js', new Date());
              gtag('config', 'G-NE2W3CFPNY');
            </script><script src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body class="__className_f367f3 layout--default"><div class="min-h-screen bg-gray-50"><div class="masthead"><div class="masthead__inner-wrap"><div class="masthead__menu"><nav id="site-nav" class="greedy-nav"><a class="site-title" href="/">secrett2633&#x27;s blog</a><div class="flex items-center space-x-4"><ul class="visible-links"><li class="masthead__menu-item"><a href="https://github.com/secrett2633" target="_blank" rel="noopener noreferrer">GitHub</a></li></ul><button class="search__toggle" type="button"><svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16"><path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path></svg></button></div></nav></div></div></div><main class="initial-content"><!--$--><div class="flex flex-col lg:flex-row gap-8"><aside class="lg:w-64 xl:w-72 order-1 lg:order-none"><div class="sidebar sticky"><nav class="space-y-4"><div><h4 class="font-medium text-gray-900 mb-2">Backend</h4><ul class="space-y-1 ml-4"><li><a href="/backend/django/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Django<!-- --> (<!-- -->6<!-- -->)</a></li><li><a href="/backend/logging/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Logging<!-- --> (<!-- -->1<!-- -->)</a></li></ul></div><div><h4 class="font-medium text-gray-900 mb-2">Python</h4><ul class="space-y-1 ml-4"><li><a href="/python/pep/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">PEP<!-- --> (<!-- -->650<!-- -->)</a></li></ul></div><div><h4 class="font-medium text-gray-900 mb-2">AI/ML</h4><ul class="space-y-1 ml-4"><li><a href="/ai/llm/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">LLM<!-- --> (<!-- -->1<!-- -->)</a></li><li><a href="/ai/review/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Review<!-- --> (<!-- -->2672<!-- -->)</a></li></ul></div><div><h4 class="font-medium text-gray-900 mb-2">DevOps</h4><ul class="space-y-1 ml-4"><li><a href="/devops/nginx/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Nginx<!-- --> (<!-- -->1<!-- -->)</a></li><li><a href="/devops/docker/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Docker<!-- --> (<!-- -->1<!-- -->)</a></li><li><a href="/devops/safeline/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">SafeLine<!-- --> (<!-- -->1<!-- -->)</a></li><li><a href="/devops/jenkins/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Jenkins<!-- --> (<!-- -->3<!-- -->)</a></li><li><a href="/devops/github-actions/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">GitHub Actions<!-- --> (<!-- -->1<!-- -->)</a></li><li><a href="/devops/aws/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">AWS<!-- --> (<!-- -->1<!-- -->)</a></li></ul></div><div><h4 class="font-medium text-gray-900 mb-2">etc</h4><ul class="space-y-1 ml-4"><li><a href="/etc/me/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Me<!-- --> (<!-- -->3<!-- -->)</a></li><li><a href="/etc/chrome-extension/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Chrome Extension<!-- --> (<!-- -->1<!-- -->)</a></li></ul></div></nav></div></aside><main class="flex-1"><article class="page"><header class="mb-8"><h1 class="page__title">[Final] PEP 371 - Addition of the multiprocessing package to the standard library</h1><div class="page__meta"><time dateTime="2025-09-26 20:55:33+0900">2025년 9월 26일</time><span class="ml-4">수정: <!-- -->2025년 9월 26일</span></div></header><div class="page__content"><div><blockquote>
<p><strong>원문 링크:</strong> <a href="https://peps.python.org/pep-0371/">PEP 371 - Addition of the multiprocessing package to the standard library</a></p>
<p><strong>상태:</strong> Final | <strong>유형:</strong> Standards Track | <strong>작성일:</strong> 06-May-2008</p>
</blockquote>
<h1>PEP 371 – 표준 라이브러리에 <code>multiprocessing</code> 패키지 추가</h1>
<h2>개요 (Abstract)</h2>
<p>이 PEP는 <code>pyProcessing</code> 패키지를 "multiprocessing"으로 이름을 변경하여 Python 표준 라이브러리에 포함할 것을 제안합니다.</p>
<p><code>processing</code> 패키지는 표준 라이브러리의 <code>threading</code> 모듈과 유사한 기능을 제공하여 스레드 기반 프로그래밍에 프로세스 기반 접근 방식을 도입합니다. 이는 최종 사용자가 Global Interpreter Lock (GIL)을 효과적으로 우회하는 여러 작업을 디스패치(dispatch)할 수 있도록 합니다.</p>
<p>이 패키지는 또한 <code>processing.Manager</code>를 통해 서버 및 클라이언트 기능을 제공하여 객체와 작업을 원격으로 공유하고 관리할 수 있도록 합니다. 이를 통해 애플리케이션은 로컬 머신의 여러 코어를 활용할 수 있을 뿐만 아니라, 네트워크로 연결된 머신 클러스터에 객체와 작업을 분산할 수 있습니다.</p>
<p>이 패키지의 분산 기능은 유용하지만, 이 PEP의 주된 초점은 패키지의 핵심적인 스레드와 유사한 API 및 기능입니다.</p>
<h2>도입 배경 (Rationale)</h2>
<p>현재 CPython 인터프리터는 Global Interpreter Lock (GIL)을 구현하고 있으며, Python 3000 또는 현재 계획된 다른 버전에서의 작업을 제외하고는 예측 가능한 미래에도 GIL은 CPython 인터프리터 내에 현재 상태로 유지될 것입니다. GIL 자체는 인터프리터와 확장 기반을 위한 C 코드를 깔끔하고 쉽게 유지 보수할 수 있게 해주지만, 멀티코어 머신을 활용하는 Python 프로그래머들에게는 종종 문제가 됩니다.</p>
<p>GIL은 어떤 시점에도 인터프리터 내에서 단 하나의 스레드만 실행되도록 하여, Python이 멀티프로세서 시스템을 활용하는 능력을 효과적으로 제거합니다.</p>
<p><code>pyprocessing</code> 패키지는 GIL을 우회하는 방법을 제공하여 CPython 내의 애플리케이션이 프로그래밍 패러다임을 완전히 변경하지 않고도(예: <code>Twisted</code>, <code>Actors</code>와 같은 다른 "동시성" 접근 방식을 위해 스레드 프로그래밍을 포기하는 것) 멀티코어 아키텍처를 활용할 수 있도록 합니다.</p>
<p><code>Processing</code> 패키지는 <code>threading</code> API와 유사한 "알려진 API"를 CPython에 제공하며, 이는 PEP 8을 준수하는 방식으로 알려진 시맨틱(semantics)과 쉬운 확장성을 제공합니다.</p>
<p>미래에 CPython 인터프리터가 "진정한" 스레딩을 가능하게 한다면 이 패키지는 덜 중요해질 수도 있습니다. 그러나 일부 애플리케이션의 경우, 특히 프로세스 생성이 빠르고 최적화된 플랫폼에서는 경량 스레드(lightweight threads)를 사용하는 것보다 OS 프로세스를 포크(fork)하는 것이 더 바람직할 수 있습니다.</p>
<p>예를 들어, 간단한 스레드 애플리케이션:</p>
<pre><code class="language-python">from threading import Thread as worker
def afunc(number):
    print number * 3
t = worker(target=afunc, args=(4,))
t.start()
t.join()
</code></pre>
<p><code>pyprocessing</code> 패키지는 API를 너무 잘 미러링(mirroring)하여, 임포트 문을 다음과 같이 간단히 변경하는 것만으로도:</p>
<pre><code class="language-python">from processing import process as worker
</code></pre>
<p>코드가 <code>processing.process</code> 클래스를 통해 실행될 것입니다. 물론 API를 PEP 8 준수 방식으로 이름을 변경하면 사용자 애플리케이션 내에서도 추가적인 이름 변경이 필요하겠지만, 그 정도는 사소합니다.</p>
<p>이러한 종류의 호환성은 (대부분의 경우) 코드의 사소한 변경만으로 사용자의 애플리케이션이 병렬 실행을 위해 주어진 머신의 모든 코어와 프로세서를 활용할 수 있게 된다는 것을 의미합니다. 많은 경우 <code>pyprocessing</code> 패키지는 I/O 바운드(I/O-bound) 프로그램의 경우 일반적인 스레딩 접근 방식보다도 더 빠릅니다. 물론 이것은 <code>pyprocessing</code> 패키지가 최적화된 C 코드로 되어 있고, <code>threading</code> 모듈은 그렇지 않다는 점을 고려한 것입니다.</p>
<h2>"분산(Distributed)" 문제</h2>
<p>이 패키지 포함에 대한 Python-Dev 토론에서는 이 PEP가 "분산" 문제를 해결하려는 의도에 대한 혼란이 있었고, 이 패키지의 기능을 MPI 기반 통신, CORBA 또는 다른 분산 객체 접근 방식과 같은 다른 솔루션과 자주 비교했습니다.</p>
<p>"분산" 문제는 크고 다양합니다. 이 분야에서 작업하는 각 프로그래머는 자신이 좋아하는 모듈/메서드에 대한 매우 강력한 의견을 가지고 있거나, 기존 솔루션으로는 해결되지 않는 고도로 맞춤화된 문제를 가지고 있습니다.</p>
<p>이 패키지의 채택은 "분산" 문제에 대해 작업하는 프로그래머들이 자신의 문제 영역에 대한 다른 솔루션을 검토하지 못하게 하거나 권장하지 않습니다. 이 패키지를 포함하는 목적은 로컬 동시성(local concurrency)을 위한 초기 수준의 기능과 그 동시성을 머신 네트워크에 분산하기 위한 기본적인 지원을 제공하는 것입니다. 이 둘이 긴밀하게 연결되어 있지는 않지만, <code>pyprocessing</code> 패키지는 실제로는 MPI/etc를 포함한 다른 어떤 솔루션과도 함께 사용될 수 있습니다.</p>
<p>필요한 경우, 패키지의 로컬 동시성 기능을 네트워크 기능/공유 측면과 완전히 분리할 수 있습니다. 그러나 심각한 우려나 원인 없이는 이 PEP의 작성자는 그러한 접근 방식을 권장하지 않습니다.</p>
<h2>성능 비교 (Performance Comparison)</h2>
<p>우리 모두 알다시피, "거짓말, 빌어먹을 거짓말, 그리고 벤치마크"가 있습니다. 이 속도 비교는 <code>pyprocessing</code> 패키지의 성능을 보여주기 위한 것이지만, 모든 가능한 사용 사례나 환경에 포괄적으로 적용될 수는 없습니다. 특히 프로세스 포크 타이밍이 느린 플랫폼에서는 더욱 그렇습니다.</p>
<p>모든 벤치마크는 다음 환경에서 실행되었습니다.</p>
<ul>
<li>4 코어 Intel Xeon CPU @ 3.00GHz</li>
<li>16 GB RAM</li>
<li>Gentoo Linux (kernel 2.6.18.6)에 컴파일된 Python 2.5.2</li>
<li>pyProcessing 0.52</li>
</ul>
<p>이 모든 코드는 <code>http://jessenoller.com/code/bench-src.tgz</code>에서 다운로드할 수 있습니다.</p>
<p>이 벤치마크의 기본 실행 방법은 <code>run_benchmarks.py</code> 스크립트에 있습니다. 이 스크립트는 단순히 단일 스레드(선형), 멀티 스레드(<code>threading</code> 모듈 사용), 멀티 프로세스(<code>pyprocessing</code> 사용) 방식으로 대상 함수를 실행하기 위한 래퍼(wrapper)이며, 증가하는 실행 루프 수 및/또는 스레드 수에 따라 고정된 반복 횟수로 실행됩니다.</p>
<p><code>run_benchmarks.py</code> 스크립트는 각 함수를 100번 실행하며, <code>timeit</code> 모듈을 통해 이 100번의 반복 중 가장 좋은 실행 결과를 선택합니다.</p>
<p>첫째, 워커(worker) 생성의 오버헤드를 식별하기 위해, 단순히 <code>pass</code> 문(빈 함수)만 있는 함수를 실행했습니다.</p>
<pre><code>cmd: python run_benchmarks.py empty_func.py
Importing empty_func
Starting tests ...
non_threaded (1 iters) 0.000001 seconds
threaded (1 threads) 0.000796 seconds
processes (1 procs) 0.000714 seconds
non_threaded (2 iters) 0.000002 seconds
threaded (2 threads) 0.001963 seconds
processes (2 procs) 0.001466 seconds
non_threaded (4 iters) 0.000002 seconds
threaded (4 threads) 0.003986 seconds
processes (4 procs) 0.002701 seconds
non_threaded (8 iters) 0.000003 seconds
threaded (8 threads) 0.007990 seconds
processes (8 procs) 0.005512 seconds
</code></pre>
<p>보시다시피, <code>pyprocessing</code> 패키지를 통한 프로세스 포크는 스레드 버전 코드를 빌드하고 실행하는 속도보다 빠릅니다.</p>
<p>두 번째 테스트는 각 스레드 내에서(격리되어 아무것도 공유하지 않음) 50000개의 피보나치 수를 계산합니다.</p>
<pre><code>cmd: python run_benchmarks.py fibonacci.py
Importing fibonacci
Starting tests ...
non_threaded (1 iters) 0.195548 seconds
threaded (1 threads) 0.197909 seconds
processes (1 procs) 0.201175 seconds
non_threaded (2 iters) 0.397540 seconds
threaded (2 threads) 0.397637 seconds
processes (2 procs) 0.204265 seconds
non_threaded (4 iters) 0.795333 seconds
threaded (4 threads) 0.797262 seconds
processes (4 procs) 0.206990 seconds
non_threaded (8 iters) 1.591680 seconds
threaded (8 threads) 1.596824 seconds
processes (8 procs) 0.417899 seconds
</code></pre>
<p>세 번째 테스트는 100000 미만의 모든 소수의 합계를 계산하며, 역시 아무것도 공유하지 않습니다.</p>
<pre><code>cmd: run_benchmarks.py crunch_primes.py
Importing crunch_primes
Starting tests ...
non_threaded (1 iters) 0.495157 seconds
threaded (1 threads) 0.522320 seconds
processes (1 procs) 0.523757 seconds
non_threaded (2 iters) 1.052048 seconds
threaded (2 threads) 1.154726 seconds
processes (2 procs) 0.524603 seconds
non_threaded (4 iters) 2.104733 seconds
threaded (4 threads) 2.455215 seconds
processes (4 procs) 0.530688 seconds
non_threaded (8 iters) 4.217455 seconds
threaded (8 threads) 5.109192 seconds
processes (8 procs) 1.077939 seconds
</code></pre>
<p>두 번째와 세 번째 테스트가 순수 수치 계산에 중점을 둔 이유는 현재의 스레딩 구현이 비-I/O 애플리케이션에 어떻게 방해가 되는지를 보여주기 위함입니다. 물론, 이러한 테스트는 결과 및 작업 청크(chunk) 조정을 위해 큐(queue)를 사용하도록 개선될 수 있지만, 이는 패키지와 핵심 <code>processing.process</code> 모듈의 성능을 보여주는 데 필요하지 않습니다.</p>
<p>다음 테스트는 I/O 바운드 테스트입니다. 일반적으로 여기서 우리는 단일 스레드 접근 방식에 비해 스레딩 모듈 접근 방식에서 큰 개선을 볼 수 있습니다. 이 경우, 각 워커는 <code>lorem.txt</code>에 대한 디스크립터(descriptor)를 열고, 그 안에서 무작위로 탐색(seek)하여 <code>/dev/null</code>에 라인들을 작성합니다.</p>
<pre><code>cmd: python run_benchmarks.py file_io.py
Importing file_io
Starting tests ...
non_threaded (1 iters) 0.057750 seconds
threaded (1 threads) 0.089992 seconds
processes (1 procs) 0.090817 seconds
non_threaded (2 iters) 0.180256 seconds
threaded (2 threads) 0.329961 seconds
processes (2 procs) 0.096683 seconds
non_threaded (4 iters) 0.370841 seconds
threaded (4 threads) 1.103678 seconds
processes (4 procs) 0.101535 seconds
non_threaded (8 iters) 0.749571 seconds
threaded (8 threads) 2.437204 seconds
processes (8 procs) 0.203438 seconds
</code></pre>
<p>보시다시피, <code>pyprocessing</code>은 이 I/O 작업에서도 여러 스레드를 사용하는 것보다 여전히 빠릅니다. 그리고 여러 스레드를 사용하는 것은 단일 스레드 실행 자체보다 느립니다.</p>
<p>마지막으로, 네트워크 I/O 성능을 보여주기 위해 소켓 기반 테스트를 실행할 것입니다. 이 함수는 LAN 상의 서버에서 간단한 톰캣 오류 페이지인 URL을 100번 가져옵니다. 네트워크는 조용하고, 10G 연결입니다.</p>
<pre><code>cmd: python run_benchmarks.py url_get.py
Importing url_get
Starting tests ...
non_threaded (1 iters) 0.124774 seconds
threaded (1 threads) 0.120478 seconds
processes (1 procs) 0.121404 seconds
non_threaded (2 iters) 0.239574 seconds
threaded (2 threads) 0.146138 seconds
processes (2 procs) 0.138366 seconds
non_threaded (4 iters) 0.479159 seconds
threaded (4 threads) 0.200985 seconds
processes (4 procs) 0.188847 seconds
non_threaded (8 iters) 0.960621 seconds
threaded (8 threads) 0.659298 seconds
processes (8 procs) 0.298625 seconds
</code></pre>
<p>마침내 스레드 성능이 단일 스레드 실행을 능가하는 것을 볼 수 있지만, 워커 수를 늘릴 때는 <code>pyprocessing</code> 패키지가 여전히 더 빠릅니다. 한두 개의 스레드/워커를 유지한다면, 스레드와 <code>pyprocessing</code> 간의 시간 차이는 상당히 비슷합니다.</p>
<p>하지만 주목할 점은, <code>pyprocessing</code> 패키지의 Queue 구현에는 객체 직렬화(serialization)로 인한 암묵적인 오버헤드(overhead)가 있다는 것입니다.</p>
<p>Alec Thomas는 <code>run_benchmarks.py</code> 스크립트를 기반으로 한 짧은 예제를 제공하여 기본 Queue 구현 대비 이러한 오버헤드를 보여주었습니다.</p>
<pre><code>cmd: run_bench_queue.py
non_threaded (1 iters) 0.010546 seconds
threaded (1 threads) 0.015164 seconds
processes (1 procs) 0.066167 seconds
non_threaded (2 iters) 0.020768 seconds
threaded (2 threads) 0.041635 seconds
processes (2 procs) 0.084270 seconds
non_threaded (4 iters) 0.041718 seconds
threaded (4 threads) 0.086394 seconds
processes (4 procs) 0.144176 seconds
non_threaded (8 iters) 0.083488 seconds
threaded (8 threads) 0.184254 seconds
processes (8 procs) 0.302999 seconds
</code></pre>
<p>추가 벤치마크는 <code>pyprocessing</code> 패키지의 소스 배포판 <code>examples/</code> 디렉토리에서 찾을 수 있습니다. 이 예제들은 패키지 문서에 포함될 것입니다.</p>
<h2>유지 보수 (Maintenance)</h2>
<p><code>pyprocessing</code> 패키지의 저자인 Richard M. Oudkerk는 Python SVN 내에서 패키지를 유지 보수하는 데 동의했습니다. Jesse Noller는 또한 패키지 유지 보수/문서화 및 테스트를 돕기로 자원했습니다.</p>
<h2>API 명명 (API Naming)</h2>
<p>패키지 API의 목표는 Python 2.x의 <code>threading</code> 및 <code>Queue</code> 모듈의 API를 면밀히 모방하도록 설계되었지만, 해당 모듈들은 PEP 8을 준수하지 않습니다. 따라서 패키지를 "있는 그대로" 추가하여 비-PEP 8 준수 명명을 영속화하는 대신, 모든 API, 클래스 등의 이름을 완전히 PEP 8을 준수하도록 변경하기로 결정했습니다.</p>
<p>이러한 변경은 <code>threading</code> 모듈을 사용하는 사람들에게는 교체 용이성(ease-of-drop in replacement)에 영향을 미치지만, 작성자들의 관점에서는 이는 수용 가능한 부작용입니다. 특히 <code>threading</code> 모듈 자체의 API도 변경될 예정이라는 점을 고려하면 더욱 그렇습니다.</p>
<p>트래커의 Issue 3042는 Python 2.6에 <code>threading</code> 모듈을 위한 두 가지 API, 즉 현재 API와 PEP 8 준수 API가 있을 것을 제안합니다. <code>-3</code>이 호출될 때 원래의 Java 스타일 API의 향후 제거에 대한 경고가 발행될 것입니다.</p>
<p>Python 3000에서는 <code>threading</code> API가 PEP 8을 준수하게 될 것이며, 이는 <code>multiprocessing</code> 모듈과 <code>threading</code> 모듈이 다시 일치하는 API를 갖게 될 것임을 의미합니다.</p>
<h2>타이밍/일정 (Timing/Schedule)</h2>
<p>올해 2.6 및 3.0 릴리스를 위한 이 PEP의 타이밍/늦음(lateness)에 대한 일부 우려가 제기되었지만, 작성자들과 다른 사람들은 이 패키지가 제공하는 기능이 포함 위험을 능가한다고 생각합니다.</p>
<p>그러나 Python 코어(core)를 불안정하게 만들지 않으려는 바람을 고려하여, <code>pyprocessing</code> 코드의 일부 리팩토링(refactoring)을 다음 2.x/3.x 릴리스까지 보류할 수 있습니다. 이는 Python 코어에 대한 실제 위험이 최소화되며, 주로 실제 패키지 자체에 한정된다는 것을 의미합니다.</p>
<h2>열린 문제 (Open Issues)</h2>
<ul>
<li>"기본" 원격 연결 기능이 없는지 확인하고, 필요한 경우 원격 기능을 제공하는 클래스에 대해 원격 보안 메커니즘을 기본적으로 활성화해야 합니다.</li>
<li>일부 API(<code>Queue</code> 메서드 <code>qsize()</code>, <code>task_done()</code>, <code>join()</code>)는 추가되어야 하거나, 제외 이유가 명확히 식별되고 문서화되어야 합니다.</li>
</ul>
<h2>해결된 문제 (Closed Issues)</h2>
<ul>
<li><code>roudkerk</code>가 issue 1683에 제출한 <code>PyGILState</code> 버그 패치는 패키지 단위 테스트가 작동하도록 적용되어야 합니다.</li>
<li>기존 문서는 ReST 형식으로 이동되어야 합니다.</li>
<li><code>ctypes</code>에 대한 의존성: <code>pyprocessing</code> 패키지의 <code>ctypes</code> 의존성은 <code>ctypes</code>가 지원되지 않는 플랫폼에서 패키지가 작동하지 못하게 합니다. 이는 이 패키지의 제한 사항이 아니라 <code>ctypes</code>의 제한 사항입니다.</li>
<li><strong>완료:</strong> 최상위 패키지 이름을 "pyprocessing"에서 "multiprocessing"으로 변경했습니다.</li>
<li><strong>완료:</strong> 또한 프로세스 생성의 기본 동작이 <code>IDLE</code> 내에서 그대로 사용하기에 호환되지 않으므로, 이는 버그 수정 또는 "setExecutable" 개선 사항으로 검토될 것입니다.</li>
<li><strong>완료:</strong> Python 인터프리터 대신 현재 실행 파일 이름을 사용하여 프로세스를 생성하는 패키지의 기본 동작을 재정의하기 위해 "multiprocessing.setExecutable()" 메서드를 추가했습니다. Mark Hammond는 이를 위한 팩토리 스타일(factory-style) 인터페이스를 제안했습니다.</li>
</ul>
<h2>참고 자료 (References)</h2>
<ul>
<li>[1] 2008년 당시의 PyProcessing 프로젝트 (<code>pyprocessing</code> 이름은 이후 재사용됨) <a href="https://web.archive.org/web/20080914113946/https://pyprocessing.berlios.de/">https://web.archive.org/web/20080914113946/https://pyprocessing.berlios.de/</a></li>
<li>[2] Adam Olsen의 "safe threading" 프로젝트 참조 <a href="https://code.google.com/archive/p/python-safethread/">https://code.google.com/archive/p/python-safethread/</a></li>
<li>[3] 참조: 표준 라이브러리에 "pyprocessing" 모듈 추가 <a href="https://mail.python.org/pipermail/python-dev/2008-May/079417.html">https://mail.python.org/pipermail/python-dev/2008-May/079417.html</a></li>
<li>[4] <a href="https://mpi4py.readthedocs.io/">https://mpi4py.readthedocs.io/</a></li>
<li>[5] "클러스터 컴퓨팅(Cluster Computing)" 참조 <a href="https://wiki.python.org/moin/ParallelProcessing#Cluster_Computing">https://wiki.python.org/moin/ParallelProcessing#Cluster_Computing</a></li>
<li>[6] 원본 <code>run_benchmark.py</code> 코드는 2007년 12월 Python Magazine에 Jesse Noller의 "Python Threads and the Global Interpreter Lock"이라는 제목으로 출판되었습니다. 이 PEP를 위해 수정되었습니다.</li>
<li>[7] <a href="http://groups.google.com/group/python-dev2/msg/54cf06d15cbcbc34">http://groups.google.com/group/python-dev2/msg/54cf06d15cbcbc34</a></li>
</ul>
<h2>저작권 (Copyright)</h2>
<p>이 문서는 퍼블릭 도메인(public domain)으로 지정되었습니다.</p>
<p>The translation is complete and follows all the guidelines.# PEP 371 – 표준 라이브러리에 <code>multiprocessing</code> 패키지 추가</p>
<h2>개요 (Abstract)</h2>
<p>이 PEP는 <code>pyProcessing</code> 패키지를 "multiprocessing"으로 이름을 변경하여 Python 표준 라이브러리에 포함할 것을 제안합니다.</p>
<p><code>processing</code> 패키지는 표준 라이브러리의 <code>threading</code> 모듈과 유사한 기능을 제공하여 스레드 기반 프로그래밍에 프로세스 기반 접근 방식을 도입합니다. 이는 최종 사용자가 Global Interpreter Lock (GIL)을 효과적으로 우회하는 여러 작업을 디스패치(dispatch)할 수 있도록 합니다.</p>
<p>이 패키지는 또한 <code>processing.Manager</code>를 통해 서버 및 클라이언트 기능을 제공하여 객체와 작업을 원격으로 공유하고 관리할 수 있도록 합니다. 이를 통해 애플리케이션은 로컬 머신의 여러 코어를 활용할 수 있을 뿐만 아니라, 네트워크로 연결된 머신 클러스터에 객체와 작업을 분산할 수 있습니다.</p>
<p>이 패키지의 분산 기능은 유용하지만, 이 PEP의 주된 초점은 패키지의 핵심적인 스레드와 유사한 API 및 기능입니다.</p>
<h2>도입 배경 (Rationale)</h2>
<p>현재 CPython 인터프리터는 Global Interpreter Lock (GIL)을 구현하고 있으며, Python 3000 또는 현재 계획된 다른 버전에서의 작업을 제외하고는 예측 가능한 미래에도 GIL은 CPython 인터프리터 내에 현재 상태로 유지될 것입니다. GIL 자체는 인터프리터와 확장 기반을 위한 C 코드를 깔끔하고 쉽게 유지 보수할 수 있게 해주지만, 멀티코어 머신을 활용하는 Python 프로그래머들에게는 종종 문제가 됩니다.</p>
<p>GIL은 어떤 시점에도 인터프리터 내에서 단 하나의 스레드만 실행되도록 하여, Python이 멀티프로세서 시스템을 활용하는 능력을 효과적으로 제거합니다.</p>
<p><code>pyprocessing</code> 패키지는 GIL을 우회하는 방법을 제공하여 CPython 내의 애플리케이션이 프로그래밍 패러다임을 완전히 변경하지 않고도(예: <code>Twisted</code>, <code>Actors</code>와 같은 다른 "동시성" 접근 방식을 위해 스레드 프로그래밍을 포기하는 것) 멀티코어 아키텍처를 활용할 수 있도록 합니다.</p>
<p><code>Processing</code> 패키지는 <code>threading</code> API와 유사한 "알려진 API"를 CPython에 제공하며, 이는 PEP 8을 준수하는 방식으로 알려진 시맨틱(semantics)과 쉬운 확장성을 제공합니다.</p>
<p>미래에 CPython 인터프리터가 "진정한" 스레딩을 가능하게 한다면 이 패키지는 덜 중요해질 수도 있습니다. 그러나 일부 애플리케이션의 경우, 특히 프로세스 생성이 빠르고 최적화된 플랫폼에서는 경량 스레드(lightweight threads)를 사용하는 것보다 OS 프로세스를 포크(fork)하는 것이 더 바람직할 수 있습니다.</p>
<p>예를 들어, 간단한 스레드 애플리케이션:</p>
<pre><code class="language-python">from threading import Thread as worker
def afunc(number):
    print number * 3
t = worker(target=afunc, args=(4,))
t.start()
t.join()
</code></pre>
<p><code>pyprocessing</code> 패키지는 API를 너무 잘 미러링(mirroring)하여, 임포트 문을 다음과 같이 간단히 변경하는 것만으로도:</p>
<pre><code class="language-python">from processing import process as worker
</code></pre>
<p>코드가 <code>processing.process</code> 클래스를 통해 실행될 것입니다. 물론 API를 PEP 8 준수 방식으로 이름을 변경하면 사용자 애플리케이션 내에서도 추가적인 이름 변경이 필요하겠지만, 그 정도는 사소합니다.</p>
<p>이러한 종류의 호환성은 (대부분의 경우) 코드의 사소한 변경만으로 사용자의 애플리케이션이 병렬 실행을 위해 주어진 머신의 모든 코어와 프로세서를 활용할 수 있게 된다는 것을 의미합니다. 많은 경우 <code>pyprocessing</code> 패키지는 I/O 바운드(I/O-bound) 프로그램의 경우 일반적인 스레딩 접근 방식보다도 더 빠릅니다. 물론 이것은 <code>pyprocessing</code> 패키지가 최적화된 C 코드로 되어 있고, <code>threading</code> 모듈은 그렇지 않다는 점을 고려한 것입니다.</p>
<h2>"분산(Distributed)" 문제</h2>
<p>이 패키지 포함에 대한 Python-Dev 토론에서는 이 PEP가 "분산" 문제를 해결하려는 의도에 대한 혼란이 있었고, 이 패키지의 기능을 MPI 기반 통신, CORBA 또는 다른 분산 객체 접근 방식과 같은 다른 솔루션과 자주 비교했습니다.</p>
<p>"분산" 문제는 크고 다양합니다. 이 분야에서 작업하는 각 프로그래머는 자신이 좋아하는 모듈/메서드에 대한 매우 강력한 의견을 가지고 있거나, 기존 솔루션으로는 해결되지 않는 고도로 맞춤화된 문제를 가지고 있습니다.</p>
<p>이 패키지의 채택은 "분산" 문제에 대해 작업하는 프로그래머들이 자신의 문제 영역에 대한 다른 솔루션을 검토하지 못하게 하거나 권장하지 않습니다. 이 패키지를 포함하는 목적은 로컬 동시성(local concurrency)을 위한 초기 수준의 기능과 그 동시성을 머신 네트워크에 분산하기 위한 기본적인 지원을 제공하는 것입니다. 이 둘이 긴밀하게 연결되어 있지는 않지만, <code>pyprocessing</code> 패키지는 실제로는 MPI/etc를 포함한 다른 어떤 솔루션과도 함께 사용될 수 있습니다.</p>
<p>필요한 경우, 패키지의 로컬 동시성 기능을 네트워크 기능/공유 측면과 완전히 분리할 수 있습니다. 그러나 심각한 우려나 원인 없이는 이 PEP의 작성자는 그러한 접근 방식을 권장하지 않습니다.</p>
<h2>성능 비교 (Performance Comparison)</h2>
<p>우리 모두 알다시피, "거짓말, 빌어먹을 거짓말, 그리고 벤치마크"가 있습니다. 이 속도 비교는 <code>pyprocessing</code> 패키지의 성능을 보여주기 위한 것이지만, 모든 가능한 사용 사례나 환경에 포괄적으로 적용될 수는 없습니다. 특히 프로세스 포크 타이밍이 느린 플랫폼에서는 더욱 그렇습니다.</p>
<p>모든 벤치마크는 다음 환경에서 실행되었습니다.</p>
<ul>
<li>4 코어 Intel Xeon CPU @ 3.00GHz</li>
<li>16 GB RAM</li>
<li>Gentoo Linux (kernel 2.6.18.6)에 컴파일된 Python 2.5.2</li>
<li>pyProcessing 0.52</li>
</ul>
<p>이 모든 코드는 <code>http://jessenoller.com/code/bench-src.tgz</code>에서 다운로드할 수 있습니다.</p>
<p>이 벤치마크의 기본 실행 방법은 <code>run_benchmarks.py</code> 스크립트에 있습니다. 이 스크립트는 단순히 단일 스레드(선형), 멀티 스레드(<code>threading</code> 모듈 사용), 멀티 프로세스(<code>pyprocessing</code> 사용) 방식으로 대상 함수를 실행하기 위한 래퍼(wrapper)이며, 증가하는 실행 루프 수 및/또는 스레드 수에 따라 고정된 반복 횟수로 실행됩니다.</p>
<p><code>run_benchmarks.py</code> 스크립트는 각 함수를 100번 실행하며, <code>timeit</code> 모듈을 통해 이 100번의 반복 중 가장 좋은 실행 결과를 선택합니다.</p>
<p>첫째, 워커(worker) 생성의 오버헤드를 식별하기 위해, 단순히 <code>pass</code> 문(빈 함수)만 있는 함수를 실행했습니다.</p>
<pre><code>cmd: python run_benchmarks.py empty_func.py
Importing empty_func
Starting tests ...
non_threaded (1 iters) 0.000001 seconds
threaded (1 threads) 0.000796 seconds
processes (1 procs) 0.000714 seconds
non_threaded (2 iters) 0.000002 seconds
threaded (2 threads) 0.001963 seconds
processes (2 procs) 0.001466 seconds
non_threaded (4 iters) 0.000002 seconds
threaded (4 threads) 0.003986 seconds
processes (4 procs) 0.002701 seconds
non_threaded (8 iters) 0.000003 seconds
threaded (8 threads) 0.007990 seconds
processes (8 procs) 0.005512 seconds
</code></pre>
<p>보시다시피, <code>pyprocessing</code> 패키지를 통한 프로세스 포크는 스레드 버전 코드를 빌드하고 실행하는 속도보다 빠릅니다.</p>
<p>두 번째 테스트는 각 스레드 내에서(격리되어 아무것도 공유하지 않음) 50000개의 피보나치 수를 계산합니다.</p>
<pre><code>cmd: python run_benchmarks.py fibonacci.py
Importing fibonacci
Starting tests ...
non_threaded (1 iters) 0.195548 seconds
threaded (1 threads) 0.197909 seconds
processes (1 procs) 0.201175 seconds
non_threaded (2 iters) 0.397540 seconds
threaded (2 threads) 0.397637 seconds
processes (2 procs) 0.204265 seconds
non_threaded (4 iters) 0.795333 seconds
threaded (4 threads) 0.797262 seconds
processes (4 procs) 0.206990 seconds
non_threaded (8 iters) 1.591680 seconds
threaded (8 threads) 1.596824 seconds
processes (8 procs) 0.417899 seconds
</code></pre>
<p>세 번째 테스트는 100000 미만의 모든 소수의 합계를 계산하며, 역시 아무것도 공유하지 않습니다.</p>
<pre><code>cmd: run_benchmarks.py crunch_primes.py
Importing crunch_primes
Starting tests ...
non_threaded (1 iters) 0.495157 seconds
threaded (1 threads) 0.522320 seconds
processes (1 procs) 0.523757 seconds
non_threaded (2 iters) 1.052048 seconds
threaded (2 threads) 1.154726 seconds
processes (2 procs) 0.524603 seconds
non_threaded (4 iters) 2.104733 seconds
threaded (4 threads) 2.455215 seconds
processes (4 procs) 0.530688 seconds
non_threaded (8 iters) 4.217455 seconds
threaded (8 threads) 5.109192 seconds
processes (8 procs) 1.077939 seconds
</code></pre>
<p>두 번째와 세 번째 테스트가 순수 수치 계산에 중점을 둔 이유는 현재의 스레딩 구현이 비-I/O 애플리케이션에 어떻게 방해가 되는지를 보여주기 위함입니다. 물론, 이러한 테스트는 결과 및 작업 청크(chunk) 조정을 위해 큐(queue)를 사용하도록 개선될 수 있지만, 이는 패키지와 핵심 <code>processing.process</code> 모듈의 성능을 보여주는 데 필요하지 않습니다.</p>
<p>다음 테스트는 I/O 바운드 테스트입니다. 일반적으로 여기서 우리는 단일 스레드 접근 방식에 비해 스레딩 모듈 접근 방식에서 큰 개선을 볼 수 있습니다. 이 경우, 각 워커는 <code>lorem.txt</code>에 대한 디스크립터(descriptor)를 열고, 그 안에서 무작위로 탐색(seek)하여 <code>/dev/null</code>에 라인들을 작성합니다.</p>
<pre><code>cmd: python run_benchmarks.py file_io.py
Importing file_io
Starting tests ...
non_threaded (1 iters) 0.057750 seconds
threaded (1 threads) 0.089992 seconds
processes (1 procs) 0.090817 seconds
non_threaded (2 iters) 0.180256 seconds
threaded (2 threads) 0.329961 seconds
processes (2 procs) 0.096683 seconds
non_threaded (4 iters) 0.370841 seconds
threaded (4 threads) 1.103678 seconds
processes (4 procs) 0.101535 seconds
non_threaded (8 iters) 0.749571 seconds
threaded (8 threads) 2.437204 seconds
processes (8 procs) 0.203438 seconds
</code></pre>
<p>보시다시피, <code>pyprocessing</code>은 이 I/O 작업에서도 여러 스레드를 사용하는 것보다 여전히 빠릅니다. 그리고 여러 스레드를 사용하는 것은 단일 스레드 실행 자체보다 느립니다.</p>
<p>마지막으로, 네트워크 I/O 성능을 보여주기 위해 소켓 기반 테스트를 실행할 것입니다. 이 함수는 LAN 상의 서버에서 간단한 톰캣 오류 페이지인 URL을 100번 가져옵니다. 네트워크는 조용하고, 10G 연결입니다.</p>
<pre><code>cmd: python run_benchmarks.py url_get.py
Importing url_get
Starting tests ...
non_threaded (1 iters) 0.124774 seconds
threaded (1 threads) 0.120478 seconds
processes (1 procs) 0.121404 seconds
non_threaded (2 iters) 0.239574 seconds
threaded (2 threads) 0.146138 seconds
processes (2 procs) 0.138366 seconds
non_threaded (4 iters) 0.479159 seconds
threaded (4 threads) 0.200985 seconds
processes (4 procs) 0.188847 seconds
non_threaded (8 iters) 0.960621 seconds
threaded (8 threads) 0.659298 seconds
processes (8 procs) 0.298625 seconds
</code></pre>
<p>마침내 스레드 성능이 단일 스레드 실행을 능가하는 것을 볼 수 있지만, 워커 수를 늘릴 때는 <code>pyprocessing</code> 패키지가 여전히 더 빠릅니다. 한두 개의 스레드/워커를 유지한다면, 스레드와 <code>pyprocessing</code> 간의 시간 차이는 상당히 비슷합니다.</p>
<p>하지만 주목할 점은, <code>pyprocessing</code> 패키지의 Queue 구현에는 객체 직렬화(serialization)로 인한 암묵적인 오버헤드(overhead)가 있다는 것입니다.</p>
<p>Alec Thomas는 <code>run_benchmarks.py</code> 스크립트를 기반으로 한 짧은 예제를 제공하여 기본 Queue 구현 대비 이러한 오버헤드를 보여주었습니다.</p>
<pre><code>cmd: run_bench_queue.py
non_threaded (1 iters) 0.010546 seconds
threaded (1 threads) 0.015164 seconds
processes (1 procs) 0.066167 seconds
non_threaded (2 iters) 0.020768 seconds
threaded (2 threads) 0.041635 seconds
processes (2 procs) 0.084270 seconds
non_threaded (4 iters) 0.041718 seconds
threaded (4 threads) 0.086394 seconds
processes (4 procs) 0.144176 seconds
non_threaded (8 iters) 0.083488 seconds
threaded (8 threads) 0.184254 seconds
processes (8 procs) 0.302999 seconds
</code></pre>
<p>추가 벤치마크는 <code>pyprocessing</code> 패키지의 소스 배포판 <code>examples/</code> 디렉토리에서 찾을 수 있습니다. 이 예제들은 패키지 문서에 포함될 것입니다.</p>
<h2>유지 보수 (Maintenance)</h2>
<p><code>pyprocessing</code> 패키지의 저자인 Richard M. Oudkerk는 Python SVN 내에서 패키지를 유지 보수하는 데 동의했습니다. Jesse Noller는 또한 패키지 유지 보수/문서화 및 테스트를 돕기로 자원했습니다.</p>
<h2>API 명명 (API Naming)</h2>
<p>패키지 API의 목표는 Python 2.x의 <code>threading</code> 및 <code>Queue</code> 모듈의 API를 면밀히 모방하도록 설계되었지만, 해당 모듈들은 PEP 8을 준수하지 않습니다. 따라서 패키지를 "있는 그대로" 추가하여 비-PEP 8 준수 명명을 영속화하는 대신, 모든 API, 클래스 등의 이름을 완전히 PEP 8을 준수하도록 변경하기로 결정했습니다.</p>
<p>이러한 변경은 <code>threading</code> 모듈을 사용하는 사람들에게는 교체 용이성(ease-of-drop in replacement)에 영향을 미치지만, 작성자들의 관점에서는 이는 수용 가능한 부작용입니다. 특히 <code>threading</code> 모듈 자체의 API도 변경될 예정이라는 점을 고려하면 더욱 그렇습니다.</p>
<p>트래커의 Issue 3042는 Python 2.6에 <code>threading</code> 모듈을 위한 두 가지 API, 즉 현재 API와 PEP 8 준수 API가 있을 것을 제안합니다. <code>-3</code>이 호출될 때 원래의 Java 스타일 API의 향후 제거에 대한 경고가 발행될 것입니다.</p>
<p>Python 3000에서는 <code>threading</code> API가 PEP 8을 준수하게 될 것이며, 이는 <code>multiprocessing</code> 모듈과 <code>threading</code> 모듈이 다시 일치하는 API를 갖게 될 것임을 의미합니다.</p>
<h2>타이밍/일정 (Timing/Schedule)</h2>
<p>올해 2.6 및 3.0 릴리스를 위한 이 PEP의 타이밍/늦음(lateness)에 대한 일부 우려가 제기되었지만, 작성자들과 다른 사람들은 이 패키지가 제공하는 기능이 포함 위험을 능가한다고 생각합니다.</p>
<p>그러나 Python 코어(core)를 불안정하게 만들지 않으려는 바람을 고려하여, <code>pyprocessing</code> 코드의 일부 리팩토링(refactoring)을 다음 2.x/3.x 릴리스까지 보류할 수 있습니다. 이는 Python 코어에 대한 실제 위험이 최소화되며, 주로 실제 패키지 자체에 한정된다는 것을 의미합니다.</p>
<h2>열린 문제 (Open Issues)</h2>
<ul>
<li>"기본" 원격 연결 기능이 없는지 확인하고, 필요한 경우 원격 기능을 제공하는 클래스에 대해 원격 보안 메커니즘을 기본적으로 활성화해야 합니다.</li>
<li>일부 API(<code>Queue</code> 메서드 <code>qsize()</code>, <code>task_done()</code>, <code>join()</code>)는 추가되어야 하거나, 제외 이유가 명확히 식별되고 문서화되어야 합니다.</li>
</ul>
<h2>해결된 문제 (Closed Issues)</h2>
<ul>
<li><code>roudkerk</code>가 issue 1683에 제출한 <code>PyGILState</code> 버그 패치는 패키지 단위 테스트가 작동하도록 적용되어야 합니다.</li>
<li>기존 문서는 ReST 형식으로 이동되어야 합니다.</li>
<li><code>ctypes</code>에 대한 의존성: <code>pyprocessing</code> 패키지의 <code>ctypes</code> 의존성은 <code>ctypes</code>가 지원되지 않는 플랫폼에서 패키지가 작동하지 못하게 합니다. 이는 이 패키지의 제한 사항이 아니라 <code>ctypes</code>의 제한 사항입니다.</li>
<li><strong>완료:</strong> 최상위 패키지 이름을 "pyprocessing"에서 "multiprocessing"으로 변경했습니다.</li>
<li><strong>완료:</strong> 또한 프로세스 생성의 기본 동작이 <code>IDLE</code> 내에서 그대로 사용하기에 호환되지 않으므로, 이는 버그 수정 또는 "setExecutable" 개선 사항으로 검토될 것입니다.</li>
<li><strong>완료:</strong> Python 인터프리터 대신 현재 실행 파일 이름을 사용하여 프로세스를 생성하는 패키지의 기본 동작을 재정의하기 위해 "multiprocessing.setExecutable()" 메서드를 추가했습니다. Mark Hammond는 이를 위한 팩토리 스타일(factory-style) 인터페이스를 제안했습니다.</li>
</ul>
<h2>참고 자료 (References)</h2>
<ul>
<li>2008년 당시의 PyProcessing 프로젝트 (<code>pyprocessing</code> 이름은 이후 재사용됨) <a href="https://web.archive.org/web/20080914113946/https://pyprocessing.berlios.de/">https://web.archive.org/web/20080914113946/https://pyprocessing.berlios.de/</a></li>
<li>Adam Olsen의 "safe threading" 프로젝트 참조 <a href="https://code.google.com/archive/p/python-safethread/">https://code.google.com/archive/p/python-safethread/</a></li>
<li>참조: 표준 라이브러리에 "pyprocessing" 모듈 추가 <a href="https://mail.python.org/pipermail/python-dev/2008-May/079417.html">https://mail.python.org/pipermail/python-dev/2008-May/079417.html</a></li>
<li><a href="https://mpi4py.readthedocs.io/">https://mpi4py.readthedocs.io/</a></li>
<li>"클러스터 컴퓨팅(Cluster Computing)" 참조 <a href="https://wiki.python.org/moin/ParallelProcessing#Cluster_Computing">https://wiki.python.org/moin/ParallelProcessing#Cluster_Computing</a></li>
<li>원본 <code>run_benchmark.py</code> 코드는 2007년 12월 Python Magazine에 Jesse Noller의 "Python Threads and the Global Interpreter Lock"이라는 제목으로 출판되었습니다. 이 PEP를 위해 수정되었습니다.</li>
<li><a href="http://groups.google.com/group/python-dev2/msg/54cf06d15cbcbc34">http://groups.google.com/group/python-dev2/msg/54cf06d15cbcbc34</a></li>
</ul>
<h2>저작권 (Copyright)</h2>
<p>이 문서는 퍼블릭 도메인(public domain)으로 지정되었습니다.</p>
<blockquote>
<p>⚠️ <strong>알림:</strong> 이 문서는 AI를 활용하여 번역되었으며, 기술적 정확성을 보장하지 않습니다. 정확한 내용은 반드시 원문을 확인하시기 바랍니다.</p>
</blockquote>
</div></div><footer class="page__meta mt-8"><div class="page__taxonomy"><h4 class="text-sm font-medium text-gray-900 mb-2">태그</h4><span class="page__taxonomy-item">#<!-- -->Python</span><span class="page__taxonomy-item">#<!-- -->PEP</span><span class="page__taxonomy-item">#<!-- -->Translation</span></div></footer><section class="comments-section mt-12 pt-8 border-t border-gray-200"></section><section class="mt-12 border-t border-gray-200 pt-8"><h3 class="text-base font-semibold text-gray-900 mb-4">Python<!-- --> 의 다른글</h3><ul class="space-y-2 text-sm"><li class="text-gray-500">이전글<!-- --> <a class="text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4" href="/python/pep/370/">[Final] PEP 370 - Per user site-packages directory</a></li><li class="text-gray-900 font-semibold">현재글 : <!-- -->[Final] PEP 371 - Addition of the multiprocessing package to the standard library</li><li class="text-gray-500">다음글<!-- --> <a class="text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4" href="/python/pep/372/">[Final] PEP 372 - Adding an ordered dictionary to collections</a></li></ul></section></article></main></div><!--/$--></main><div id="footer" class="page__footer"><footer class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8"><div class="text-center text-gray-500 text-sm"><p>© 2025 secrett2633. All rights reserved.</p></div></footer></div></div><script src="/_next/static/chunks/webpack-61c2b369a48bb953.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/css/d6cea809dcbae606.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"2:I[5751,[],\"\"]\n5:I[9275,[],\"\"]\n7:I[1343,[],\"\"]\n8:I[9157,[\"231\",\"static/chunks/231-467e37449c5a68fc.js\",\"185\",\"static/chunks/app/layout-135ad156a55a8fe5.js\"],\"default\"]\n9:I[231,[\"231\",\"static/chunks/231-467e37449c5a68fc.js\",\"877\",\"static/chunks/app/%5B...slug%5D/page-a0fe0cc578429896.js\"],\"\"]\nb:I[6130,[],\"\"]\n6:[\"slug\",\"python/pep/371\",\"c\"]\nc:[]\n"])</script><script>self.__next_f.push([1,"0:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/d6cea809dcbae606.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L2\",null,{\"buildId\":\"Z3C0dl-eqDisnYDXzkst9\",\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/python/pep/371/\",\"initialTree\":[\"\",{\"children\":[[\"slug\",\"python/pep/371\",\"c\"],{\"children\":[\"__PAGE__?{\\\"slug\\\":[\\\"python\\\",\\\"pep\\\",\\\"371\\\"]}\",{}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[[\"slug\",\"python/pep/371\",\"c\"],{\"children\":[\"__PAGE__\",{},[[\"$L3\",\"$L4\"],null],null]},[\"$\",\"$L5\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"$6\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L7\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}],null]},[[\"$\",\"html\",null,{\"lang\":\"ko\",\"className\":\"no-js\",\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"meta\",null,{\"name\":\"msapplication-TileColor\",\"content\":\"#ffc40d\"}],[\"$\",\"meta\",null,{\"name\":\"theme-color\",\"content\":\"#ffffff\"}],[\"$\",\"script\",null,{\"async\":true,\"src\":\"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY\"}],[\"$\",\"script\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\\n              window.dataLayer = window.dataLayer || [];\\n              function gtag(){dataLayer.push(arguments);}\\n              gtag('js', new Date());\\n              gtag('config', 'G-NE2W3CFPNY');\\n            \"}}]]}],[\"$\",\"body\",null,{\"className\":\"__className_f367f3 layout--default\",\"children\":[\"$\",\"div\",null,{\"className\":\"min-h-screen bg-gray-50\",\"children\":[[\"$\",\"$L8\",null,{}],[\"$\",\"main\",null,{\"className\":\"initial-content\",\"children\":[\"$\",\"$L5\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L7\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[\"$\",\"div\",null,{\"className\":\"min-h-screen flex items-center justify-center bg-gray-50\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-6xl font-bold text-primary-600 mb-4\",\"children\":\"404\"}],[\"$\",\"h2\",null,{\"className\":\"text-2xl font-semibold text-gray-900 mb-4\",\"children\":\"페이지를 찾을 수 없습니다\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-600 mb-8\",\"children\":\"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다.\"}],[\"$\",\"$L9\",null,{\"href\":\"/\",\"className\":\"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors\",\"children\":\"홈으로 돌아가기\"}]]}]}],\"notFoundStyles\":[],\"styles\":null}]}],[\"$\",\"div\",null,{\"id\":\"footer\",\"className\":\"page__footer\",\"children\":[\"$\",\"footer\",null,{\"className\":\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"text-center text-gray-500 text-sm\",\"children\":[\"$\",\"p\",null,{\"children\":\"© 2025 secrett2633. All rights reserved.\"}]}]}]}]]}]}]]}],null],[[\"$\",\"div\",null,{\"className\":\"flex items-center justify-center min-h-screen\",\"children\":[\"$\",\"div\",null,{\"className\":\"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600\"}]}],[],[]]],\"couldBeIntercepted\":false,\"initialHead\":[null,\"$La\"],\"globalErrorComponent\":\"$b\",\"missingSlots\":\"$Wc\"}]]\n"])</script><script>self.__next_f.push([1,"e:I[646,[\"231\",\"static/chunks/231-467e37449c5a68fc.js\",\"877\",\"static/chunks/app/%5B...slug%5D/page-a0fe0cc578429896.js\"],\"default\"]\nd:T9b2d,"])</script><script>self.__next_f.push([1,"\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e원문 링크:\u003c/strong\u003e \u003ca href=\"https://peps.python.org/pep-0371/\"\u003ePEP 371 - Addition of the multiprocessing package to the standard library\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e상태:\u003c/strong\u003e Final | \u003cstrong\u003e유형:\u003c/strong\u003e Standards Track | \u003cstrong\u003e작성일:\u003c/strong\u003e 06-May-2008\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch1\u003ePEP 371 – 표준 라이브러리에 \u003ccode\u003emultiprocessing\u003c/code\u003e 패키지 추가\u003c/h1\u003e\n\u003ch2\u003e개요 (Abstract)\u003c/h2\u003e\n\u003cp\u003e이 PEP는 \u003ccode\u003epyProcessing\u003c/code\u003e 패키지를 \"multiprocessing\"으로 이름을 변경하여 Python 표준 라이브러리에 포함할 것을 제안합니다.\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eprocessing\u003c/code\u003e 패키지는 표준 라이브러리의 \u003ccode\u003ethreading\u003c/code\u003e 모듈과 유사한 기능을 제공하여 스레드 기반 프로그래밍에 프로세스 기반 접근 방식을 도입합니다. 이는 최종 사용자가 Global Interpreter Lock (GIL)을 효과적으로 우회하는 여러 작업을 디스패치(dispatch)할 수 있도록 합니다.\u003c/p\u003e\n\u003cp\u003e이 패키지는 또한 \u003ccode\u003eprocessing.Manager\u003c/code\u003e를 통해 서버 및 클라이언트 기능을 제공하여 객체와 작업을 원격으로 공유하고 관리할 수 있도록 합니다. 이를 통해 애플리케이션은 로컬 머신의 여러 코어를 활용할 수 있을 뿐만 아니라, 네트워크로 연결된 머신 클러스터에 객체와 작업을 분산할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e이 패키지의 분산 기능은 유용하지만, 이 PEP의 주된 초점은 패키지의 핵심적인 스레드와 유사한 API 및 기능입니다.\u003c/p\u003e\n\u003ch2\u003e도입 배경 (Rationale)\u003c/h2\u003e\n\u003cp\u003e현재 CPython 인터프리터는 Global Interpreter Lock (GIL)을 구현하고 있으며, Python 3000 또는 현재 계획된 다른 버전에서의 작업을 제외하고는 예측 가능한 미래에도 GIL은 CPython 인터프리터 내에 현재 상태로 유지될 것입니다. GIL 자체는 인터프리터와 확장 기반을 위한 C 코드를 깔끔하고 쉽게 유지 보수할 수 있게 해주지만, 멀티코어 머신을 활용하는 Python 프로그래머들에게는 종종 문제가 됩니다.\u003c/p\u003e\n\u003cp\u003eGIL은 어떤 시점에도 인터프리터 내에서 단 하나의 스레드만 실행되도록 하여, Python이 멀티프로세서 시스템을 활용하는 능력을 효과적으로 제거합니다.\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003epyprocessing\u003c/code\u003e 패키지는 GIL을 우회하는 방법을 제공하여 CPython 내의 애플리케이션이 프로그래밍 패러다임을 완전히 변경하지 않고도(예: \u003ccode\u003eTwisted\u003c/code\u003e, \u003ccode\u003eActors\u003c/code\u003e와 같은 다른 \"동시성\" 접근 방식을 위해 스레드 프로그래밍을 포기하는 것) 멀티코어 아키텍처를 활용할 수 있도록 합니다.\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eProcessing\u003c/code\u003e 패키지는 \u003ccode\u003ethreading\u003c/code\u003e API와 유사한 \"알려진 API\"를 CPython에 제공하며, 이는 PEP 8을 준수하는 방식으로 알려진 시맨틱(semantics)과 쉬운 확장성을 제공합니다.\u003c/p\u003e\n\u003cp\u003e미래에 CPython 인터프리터가 \"진정한\" 스레딩을 가능하게 한다면 이 패키지는 덜 중요해질 수도 있습니다. 그러나 일부 애플리케이션의 경우, 특히 프로세스 생성이 빠르고 최적화된 플랫폼에서는 경량 스레드(lightweight threads)를 사용하는 것보다 OS 프로세스를 포크(fork)하는 것이 더 바람직할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e예를 들어, 간단한 스레드 애플리케이션:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom threading import Thread as worker\r\ndef afunc(number):\r\n    print number * 3\r\nt = worker(target=afunc, args=(4,))\r\nt.start()\r\nt.join()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003ccode\u003epyprocessing\u003c/code\u003e 패키지는 API를 너무 잘 미러링(mirroring)하여, 임포트 문을 다음과 같이 간단히 변경하는 것만으로도:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom processing import process as worker\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e코드가 \u003ccode\u003eprocessing.process\u003c/code\u003e 클래스를 통해 실행될 것입니다. 물론 API를 PEP 8 준수 방식으로 이름을 변경하면 사용자 애플리케이션 내에서도 추가적인 이름 변경이 필요하겠지만, 그 정도는 사소합니다.\u003c/p\u003e\n\u003cp\u003e이러한 종류의 호환성은 (대부분의 경우) 코드의 사소한 변경만으로 사용자의 애플리케이션이 병렬 실행을 위해 주어진 머신의 모든 코어와 프로세서를 활용할 수 있게 된다는 것을 의미합니다. 많은 경우 \u003ccode\u003epyprocessing\u003c/code\u003e 패키지는 I/O 바운드(I/O-bound) 프로그램의 경우 일반적인 스레딩 접근 방식보다도 더 빠릅니다. 물론 이것은 \u003ccode\u003epyprocessing\u003c/code\u003e 패키지가 최적화된 C 코드로 되어 있고, \u003ccode\u003ethreading\u003c/code\u003e 모듈은 그렇지 않다는 점을 고려한 것입니다.\u003c/p\u003e\n\u003ch2\u003e\"분산(Distributed)\" 문제\u003c/h2\u003e\n\u003cp\u003e이 패키지 포함에 대한 Python-Dev 토론에서는 이 PEP가 \"분산\" 문제를 해결하려는 의도에 대한 혼란이 있었고, 이 패키지의 기능을 MPI 기반 통신, CORBA 또는 다른 분산 객체 접근 방식과 같은 다른 솔루션과 자주 비교했습니다.\u003c/p\u003e\n\u003cp\u003e\"분산\" 문제는 크고 다양합니다. 이 분야에서 작업하는 각 프로그래머는 자신이 좋아하는 모듈/메서드에 대한 매우 강력한 의견을 가지고 있거나, 기존 솔루션으로는 해결되지 않는 고도로 맞춤화된 문제를 가지고 있습니다.\u003c/p\u003e\n\u003cp\u003e이 패키지의 채택은 \"분산\" 문제에 대해 작업하는 프로그래머들이 자신의 문제 영역에 대한 다른 솔루션을 검토하지 못하게 하거나 권장하지 않습니다. 이 패키지를 포함하는 목적은 로컬 동시성(local concurrency)을 위한 초기 수준의 기능과 그 동시성을 머신 네트워크에 분산하기 위한 기본적인 지원을 제공하는 것입니다. 이 둘이 긴밀하게 연결되어 있지는 않지만, \u003ccode\u003epyprocessing\u003c/code\u003e 패키지는 실제로는 MPI/etc를 포함한 다른 어떤 솔루션과도 함께 사용될 수 있습니다.\u003c/p\u003e\n\u003cp\u003e필요한 경우, 패키지의 로컬 동시성 기능을 네트워크 기능/공유 측면과 완전히 분리할 수 있습니다. 그러나 심각한 우려나 원인 없이는 이 PEP의 작성자는 그러한 접근 방식을 권장하지 않습니다.\u003c/p\u003e\n\u003ch2\u003e성능 비교 (Performance Comparison)\u003c/h2\u003e\n\u003cp\u003e우리 모두 알다시피, \"거짓말, 빌어먹을 거짓말, 그리고 벤치마크\"가 있습니다. 이 속도 비교는 \u003ccode\u003epyprocessing\u003c/code\u003e 패키지의 성능을 보여주기 위한 것이지만, 모든 가능한 사용 사례나 환경에 포괄적으로 적용될 수는 없습니다. 특히 프로세스 포크 타이밍이 느린 플랫폼에서는 더욱 그렇습니다.\u003c/p\u003e\n\u003cp\u003e모든 벤치마크는 다음 환경에서 실행되었습니다.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e4 코어 Intel Xeon CPU @ 3.00GHz\u003c/li\u003e\n\u003cli\u003e16 GB RAM\u003c/li\u003e\n\u003cli\u003eGentoo Linux (kernel 2.6.18.6)에 컴파일된 Python 2.5.2\u003c/li\u003e\n\u003cli\u003epyProcessing 0.52\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e이 모든 코드는 \u003ccode\u003ehttp://jessenoller.com/code/bench-src.tgz\u003c/code\u003e에서 다운로드할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e이 벤치마크의 기본 실행 방법은 \u003ccode\u003erun_benchmarks.py\u003c/code\u003e 스크립트에 있습니다. 이 스크립트는 단순히 단일 스레드(선형), 멀티 스레드(\u003ccode\u003ethreading\u003c/code\u003e 모듈 사용), 멀티 프로세스(\u003ccode\u003epyprocessing\u003c/code\u003e 사용) 방식으로 대상 함수를 실행하기 위한 래퍼(wrapper)이며, 증가하는 실행 루프 수 및/또는 스레드 수에 따라 고정된 반복 횟수로 실행됩니다.\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003erun_benchmarks.py\u003c/code\u003e 스크립트는 각 함수를 100번 실행하며, \u003ccode\u003etimeit\u003c/code\u003e 모듈을 통해 이 100번의 반복 중 가장 좋은 실행 결과를 선택합니다.\u003c/p\u003e\n\u003cp\u003e첫째, 워커(worker) 생성의 오버헤드를 식별하기 위해, 단순히 \u003ccode\u003epass\u003c/code\u003e 문(빈 함수)만 있는 함수를 실행했습니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecmd: python run_benchmarks.py empty_func.py\r\nImporting empty_func\r\nStarting tests ...\r\nnon_threaded (1 iters) 0.000001 seconds\r\nthreaded (1 threads) 0.000796 seconds\r\nprocesses (1 procs) 0.000714 seconds\r\nnon_threaded (2 iters) 0.000002 seconds\r\nthreaded (2 threads) 0.001963 seconds\r\nprocesses (2 procs) 0.001466 seconds\r\nnon_threaded (4 iters) 0.000002 seconds\r\nthreaded (4 threads) 0.003986 seconds\r\nprocesses (4 procs) 0.002701 seconds\r\nnon_threaded (8 iters) 0.000003 seconds\r\nthreaded (8 threads) 0.007990 seconds\r\nprocesses (8 procs) 0.005512 seconds\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e보시다시피, \u003ccode\u003epyprocessing\u003c/code\u003e 패키지를 통한 프로세스 포크는 스레드 버전 코드를 빌드하고 실행하는 속도보다 빠릅니다.\u003c/p\u003e\n\u003cp\u003e두 번째 테스트는 각 스레드 내에서(격리되어 아무것도 공유하지 않음) 50000개의 피보나치 수를 계산합니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecmd: python run_benchmarks.py fibonacci.py\r\nImporting fibonacci\r\nStarting tests ...\r\nnon_threaded (1 iters) 0.195548 seconds\r\nthreaded (1 threads) 0.197909 seconds\r\nprocesses (1 procs) 0.201175 seconds\r\nnon_threaded (2 iters) 0.397540 seconds\r\nthreaded (2 threads) 0.397637 seconds\r\nprocesses (2 procs) 0.204265 seconds\r\nnon_threaded (4 iters) 0.795333 seconds\r\nthreaded (4 threads) 0.797262 seconds\r\nprocesses (4 procs) 0.206990 seconds\r\nnon_threaded (8 iters) 1.591680 seconds\r\nthreaded (8 threads) 1.596824 seconds\r\nprocesses (8 procs) 0.417899 seconds\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e세 번째 테스트는 100000 미만의 모든 소수의 합계를 계산하며, 역시 아무것도 공유하지 않습니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecmd: run_benchmarks.py crunch_primes.py\r\nImporting crunch_primes\r\nStarting tests ...\r\nnon_threaded (1 iters) 0.495157 seconds\r\nthreaded (1 threads) 0.522320 seconds\r\nprocesses (1 procs) 0.523757 seconds\r\nnon_threaded (2 iters) 1.052048 seconds\r\nthreaded (2 threads) 1.154726 seconds\r\nprocesses (2 procs) 0.524603 seconds\r\nnon_threaded (4 iters) 2.104733 seconds\r\nthreaded (4 threads) 2.455215 seconds\r\nprocesses (4 procs) 0.530688 seconds\r\nnon_threaded (8 iters) 4.217455 seconds\r\nthreaded (8 threads) 5.109192 seconds\r\nprocesses (8 procs) 1.077939 seconds\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e두 번째와 세 번째 테스트가 순수 수치 계산에 중점을 둔 이유는 현재의 스레딩 구현이 비-I/O 애플리케이션에 어떻게 방해가 되는지를 보여주기 위함입니다. 물론, 이러한 테스트는 결과 및 작업 청크(chunk) 조정을 위해 큐(queue)를 사용하도록 개선될 수 있지만, 이는 패키지와 핵심 \u003ccode\u003eprocessing.process\u003c/code\u003e 모듈의 성능을 보여주는 데 필요하지 않습니다.\u003c/p\u003e\n\u003cp\u003e다음 테스트는 I/O 바운드 테스트입니다. 일반적으로 여기서 우리는 단일 스레드 접근 방식에 비해 스레딩 모듈 접근 방식에서 큰 개선을 볼 수 있습니다. 이 경우, 각 워커는 \u003ccode\u003elorem.txt\u003c/code\u003e에 대한 디스크립터(descriptor)를 열고, 그 안에서 무작위로 탐색(seek)하여 \u003ccode\u003e/dev/null\u003c/code\u003e에 라인들을 작성합니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecmd: python run_benchmarks.py file_io.py\r\nImporting file_io\r\nStarting tests ...\r\nnon_threaded (1 iters) 0.057750 seconds\r\nthreaded (1 threads) 0.089992 seconds\r\nprocesses (1 procs) 0.090817 seconds\r\nnon_threaded (2 iters) 0.180256 seconds\r\nthreaded (2 threads) 0.329961 seconds\r\nprocesses (2 procs) 0.096683 seconds\r\nnon_threaded (4 iters) 0.370841 seconds\r\nthreaded (4 threads) 1.103678 seconds\r\nprocesses (4 procs) 0.101535 seconds\r\nnon_threaded (8 iters) 0.749571 seconds\r\nthreaded (8 threads) 2.437204 seconds\r\nprocesses (8 procs) 0.203438 seconds\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e보시다시피, \u003ccode\u003epyprocessing\u003c/code\u003e은 이 I/O 작업에서도 여러 스레드를 사용하는 것보다 여전히 빠릅니다. 그리고 여러 스레드를 사용하는 것은 단일 스레드 실행 자체보다 느립니다.\u003c/p\u003e\n\u003cp\u003e마지막으로, 네트워크 I/O 성능을 보여주기 위해 소켓 기반 테스트를 실행할 것입니다. 이 함수는 LAN 상의 서버에서 간단한 톰캣 오류 페이지인 URL을 100번 가져옵니다. 네트워크는 조용하고, 10G 연결입니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecmd: python run_benchmarks.py url_get.py\r\nImporting url_get\r\nStarting tests ...\r\nnon_threaded (1 iters) 0.124774 seconds\r\nthreaded (1 threads) 0.120478 seconds\r\nprocesses (1 procs) 0.121404 seconds\r\nnon_threaded (2 iters) 0.239574 seconds\r\nthreaded (2 threads) 0.146138 seconds\r\nprocesses (2 procs) 0.138366 seconds\r\nnon_threaded (4 iters) 0.479159 seconds\r\nthreaded (4 threads) 0.200985 seconds\r\nprocesses (4 procs) 0.188847 seconds\r\nnon_threaded (8 iters) 0.960621 seconds\r\nthreaded (8 threads) 0.659298 seconds\r\nprocesses (8 procs) 0.298625 seconds\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e마침내 스레드 성능이 단일 스레드 실행을 능가하는 것을 볼 수 있지만, 워커 수를 늘릴 때는 \u003ccode\u003epyprocessing\u003c/code\u003e 패키지가 여전히 더 빠릅니다. 한두 개의 스레드/워커를 유지한다면, 스레드와 \u003ccode\u003epyprocessing\u003c/code\u003e 간의 시간 차이는 상당히 비슷합니다.\u003c/p\u003e\n\u003cp\u003e하지만 주목할 점은, \u003ccode\u003epyprocessing\u003c/code\u003e 패키지의 Queue 구현에는 객체 직렬화(serialization)로 인한 암묵적인 오버헤드(overhead)가 있다는 것입니다.\u003c/p\u003e\n\u003cp\u003eAlec Thomas는 \u003ccode\u003erun_benchmarks.py\u003c/code\u003e 스크립트를 기반으로 한 짧은 예제를 제공하여 기본 Queue 구현 대비 이러한 오버헤드를 보여주었습니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecmd: run_bench_queue.py\r\nnon_threaded (1 iters) 0.010546 seconds\r\nthreaded (1 threads) 0.015164 seconds\r\nprocesses (1 procs) 0.066167 seconds\r\nnon_threaded (2 iters) 0.020768 seconds\r\nthreaded (2 threads) 0.041635 seconds\r\nprocesses (2 procs) 0.084270 seconds\r\nnon_threaded (4 iters) 0.041718 seconds\r\nthreaded (4 threads) 0.086394 seconds\r\nprocesses (4 procs) 0.144176 seconds\r\nnon_threaded (8 iters) 0.083488 seconds\r\nthreaded (8 threads) 0.184254 seconds\r\nprocesses (8 procs) 0.302999 seconds\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e추가 벤치마크는 \u003ccode\u003epyprocessing\u003c/code\u003e 패키지의 소스 배포판 \u003ccode\u003eexamples/\u003c/code\u003e 디렉토리에서 찾을 수 있습니다. 이 예제들은 패키지 문서에 포함될 것입니다.\u003c/p\u003e\n\u003ch2\u003e유지 보수 (Maintenance)\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003epyprocessing\u003c/code\u003e 패키지의 저자인 Richard M. Oudkerk는 Python SVN 내에서 패키지를 유지 보수하는 데 동의했습니다. Jesse Noller는 또한 패키지 유지 보수/문서화 및 테스트를 돕기로 자원했습니다.\u003c/p\u003e\n\u003ch2\u003eAPI 명명 (API Naming)\u003c/h2\u003e\n\u003cp\u003e패키지 API의 목표는 Python 2.x의 \u003ccode\u003ethreading\u003c/code\u003e 및 \u003ccode\u003eQueue\u003c/code\u003e 모듈의 API를 면밀히 모방하도록 설계되었지만, 해당 모듈들은 PEP 8을 준수하지 않습니다. 따라서 패키지를 \"있는 그대로\" 추가하여 비-PEP 8 준수 명명을 영속화하는 대신, 모든 API, 클래스 등의 이름을 완전히 PEP 8을 준수하도록 변경하기로 결정했습니다.\u003c/p\u003e\n\u003cp\u003e이러한 변경은 \u003ccode\u003ethreading\u003c/code\u003e 모듈을 사용하는 사람들에게는 교체 용이성(ease-of-drop in replacement)에 영향을 미치지만, 작성자들의 관점에서는 이는 수용 가능한 부작용입니다. 특히 \u003ccode\u003ethreading\u003c/code\u003e 모듈 자체의 API도 변경될 예정이라는 점을 고려하면 더욱 그렇습니다.\u003c/p\u003e\n\u003cp\u003e트래커의 Issue 3042는 Python 2.6에 \u003ccode\u003ethreading\u003c/code\u003e 모듈을 위한 두 가지 API, 즉 현재 API와 PEP 8 준수 API가 있을 것을 제안합니다. \u003ccode\u003e-3\u003c/code\u003e이 호출될 때 원래의 Java 스타일 API의 향후 제거에 대한 경고가 발행될 것입니다.\u003c/p\u003e\n\u003cp\u003ePython 3000에서는 \u003ccode\u003ethreading\u003c/code\u003e API가 PEP 8을 준수하게 될 것이며, 이는 \u003ccode\u003emultiprocessing\u003c/code\u003e 모듈과 \u003ccode\u003ethreading\u003c/code\u003e 모듈이 다시 일치하는 API를 갖게 될 것임을 의미합니다.\u003c/p\u003e\n\u003ch2\u003e타이밍/일정 (Timing/Schedule)\u003c/h2\u003e\n\u003cp\u003e올해 2.6 및 3.0 릴리스를 위한 이 PEP의 타이밍/늦음(lateness)에 대한 일부 우려가 제기되었지만, 작성자들과 다른 사람들은 이 패키지가 제공하는 기능이 포함 위험을 능가한다고 생각합니다.\u003c/p\u003e\n\u003cp\u003e그러나 Python 코어(core)를 불안정하게 만들지 않으려는 바람을 고려하여, \u003ccode\u003epyprocessing\u003c/code\u003e 코드의 일부 리팩토링(refactoring)을 다음 2.x/3.x 릴리스까지 보류할 수 있습니다. 이는 Python 코어에 대한 실제 위험이 최소화되며, 주로 실제 패키지 자체에 한정된다는 것을 의미합니다.\u003c/p\u003e\n\u003ch2\u003e열린 문제 (Open Issues)\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\"기본\" 원격 연결 기능이 없는지 확인하고, 필요한 경우 원격 기능을 제공하는 클래스에 대해 원격 보안 메커니즘을 기본적으로 활성화해야 합니다.\u003c/li\u003e\n\u003cli\u003e일부 API(\u003ccode\u003eQueue\u003c/code\u003e 메서드 \u003ccode\u003eqsize()\u003c/code\u003e, \u003ccode\u003etask_done()\u003c/code\u003e, \u003ccode\u003ejoin()\u003c/code\u003e)는 추가되어야 하거나, 제외 이유가 명확히 식별되고 문서화되어야 합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e해결된 문제 (Closed Issues)\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eroudkerk\u003c/code\u003e가 issue 1683에 제출한 \u003ccode\u003ePyGILState\u003c/code\u003e 버그 패치는 패키지 단위 테스트가 작동하도록 적용되어야 합니다.\u003c/li\u003e\n\u003cli\u003e기존 문서는 ReST 형식으로 이동되어야 합니다.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ectypes\u003c/code\u003e에 대한 의존성: \u003ccode\u003epyprocessing\u003c/code\u003e 패키지의 \u003ccode\u003ectypes\u003c/code\u003e 의존성은 \u003ccode\u003ectypes\u003c/code\u003e가 지원되지 않는 플랫폼에서 패키지가 작동하지 못하게 합니다. 이는 이 패키지의 제한 사항이 아니라 \u003ccode\u003ectypes\u003c/code\u003e의 제한 사항입니다.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e완료:\u003c/strong\u003e 최상위 패키지 이름을 \"pyprocessing\"에서 \"multiprocessing\"으로 변경했습니다.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e완료:\u003c/strong\u003e 또한 프로세스 생성의 기본 동작이 \u003ccode\u003eIDLE\u003c/code\u003e 내에서 그대로 사용하기에 호환되지 않으므로, 이는 버그 수정 또는 \"setExecutable\" 개선 사항으로 검토될 것입니다.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e완료:\u003c/strong\u003e Python 인터프리터 대신 현재 실행 파일 이름을 사용하여 프로세스를 생성하는 패키지의 기본 동작을 재정의하기 위해 \"multiprocessing.setExecutable()\" 메서드를 추가했습니다. Mark Hammond는 이를 위한 팩토리 스타일(factory-style) 인터페이스를 제안했습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e참고 자료 (References)\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e[1] 2008년 당시의 PyProcessing 프로젝트 (\u003ccode\u003epyprocessing\u003c/code\u003e 이름은 이후 재사용됨) \u003ca href=\"https://web.archive.org/web/20080914113946/https://pyprocessing.berlios.de/\"\u003ehttps://web.archive.org/web/20080914113946/https://pyprocessing.berlios.de/\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e[2] Adam Olsen의 \"safe threading\" 프로젝트 참조 \u003ca href=\"https://code.google.com/archive/p/python-safethread/\"\u003ehttps://code.google.com/archive/p/python-safethread/\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e[3] 참조: 표준 라이브러리에 \"pyprocessing\" 모듈 추가 \u003ca href=\"https://mail.python.org/pipermail/python-dev/2008-May/079417.html\"\u003ehttps://mail.python.org/pipermail/python-dev/2008-May/079417.html\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e[4] \u003ca href=\"https://mpi4py.readthedocs.io/\"\u003ehttps://mpi4py.readthedocs.io/\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e[5] \"클러스터 컴퓨팅(Cluster Computing)\" 참조 \u003ca href=\"https://wiki.python.org/moin/ParallelProcessing#Cluster_Computing\"\u003ehttps://wiki.python.org/moin/ParallelProcessing#Cluster_Computing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e[6] 원본 \u003ccode\u003erun_benchmark.py\u003c/code\u003e 코드는 2007년 12월 Python Magazine에 Jesse Noller의 \"Python Threads and the Global Interpreter Lock\"이라는 제목으로 출판되었습니다. 이 PEP를 위해 수정되었습니다.\u003c/li\u003e\n\u003cli\u003e[7] \u003ca href=\"http://groups.google.com/group/python-dev2/msg/54cf06d15cbcbc34\"\u003ehttp://groups.google.com/group/python-dev2/msg/54cf06d15cbcbc34\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e저작권 (Copyright)\u003c/h2\u003e\n\u003cp\u003e이 문서는 퍼블릭 도메인(public domain)으로 지정되었습니다.\u003c/p\u003e\n\u003cp\u003eThe translation is complete and follows all the guidelines.# PEP 371 – 표준 라이브러리에 \u003ccode\u003emultiprocessing\u003c/code\u003e 패키지 추가\u003c/p\u003e\n\u003ch2\u003e개요 (Abstract)\u003c/h2\u003e\n\u003cp\u003e이 PEP는 \u003ccode\u003epyProcessing\u003c/code\u003e 패키지를 \"multiprocessing\"으로 이름을 변경하여 Python 표준 라이브러리에 포함할 것을 제안합니다.\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eprocessing\u003c/code\u003e 패키지는 표준 라이브러리의 \u003ccode\u003ethreading\u003c/code\u003e 모듈과 유사한 기능을 제공하여 스레드 기반 프로그래밍에 프로세스 기반 접근 방식을 도입합니다. 이는 최종 사용자가 Global Interpreter Lock (GIL)을 효과적으로 우회하는 여러 작업을 디스패치(dispatch)할 수 있도록 합니다.\u003c/p\u003e\n\u003cp\u003e이 패키지는 또한 \u003ccode\u003eprocessing.Manager\u003c/code\u003e를 통해 서버 및 클라이언트 기능을 제공하여 객체와 작업을 원격으로 공유하고 관리할 수 있도록 합니다. 이를 통해 애플리케이션은 로컬 머신의 여러 코어를 활용할 수 있을 뿐만 아니라, 네트워크로 연결된 머신 클러스터에 객체와 작업을 분산할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e이 패키지의 분산 기능은 유용하지만, 이 PEP의 주된 초점은 패키지의 핵심적인 스레드와 유사한 API 및 기능입니다.\u003c/p\u003e\n\u003ch2\u003e도입 배경 (Rationale)\u003c/h2\u003e\n\u003cp\u003e현재 CPython 인터프리터는 Global Interpreter Lock (GIL)을 구현하고 있으며, Python 3000 또는 현재 계획된 다른 버전에서의 작업을 제외하고는 예측 가능한 미래에도 GIL은 CPython 인터프리터 내에 현재 상태로 유지될 것입니다. GIL 자체는 인터프리터와 확장 기반을 위한 C 코드를 깔끔하고 쉽게 유지 보수할 수 있게 해주지만, 멀티코어 머신을 활용하는 Python 프로그래머들에게는 종종 문제가 됩니다.\u003c/p\u003e\n\u003cp\u003eGIL은 어떤 시점에도 인터프리터 내에서 단 하나의 스레드만 실행되도록 하여, Python이 멀티프로세서 시스템을 활용하는 능력을 효과적으로 제거합니다.\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003epyprocessing\u003c/code\u003e 패키지는 GIL을 우회하는 방법을 제공하여 CPython 내의 애플리케이션이 프로그래밍 패러다임을 완전히 변경하지 않고도(예: \u003ccode\u003eTwisted\u003c/code\u003e, \u003ccode\u003eActors\u003c/code\u003e와 같은 다른 \"동시성\" 접근 방식을 위해 스레드 프로그래밍을 포기하는 것) 멀티코어 아키텍처를 활용할 수 있도록 합니다.\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eProcessing\u003c/code\u003e 패키지는 \u003ccode\u003ethreading\u003c/code\u003e API와 유사한 \"알려진 API\"를 CPython에 제공하며, 이는 PEP 8을 준수하는 방식으로 알려진 시맨틱(semantics)과 쉬운 확장성을 제공합니다.\u003c/p\u003e\n\u003cp\u003e미래에 CPython 인터프리터가 \"진정한\" 스레딩을 가능하게 한다면 이 패키지는 덜 중요해질 수도 있습니다. 그러나 일부 애플리케이션의 경우, 특히 프로세스 생성이 빠르고 최적화된 플랫폼에서는 경량 스레드(lightweight threads)를 사용하는 것보다 OS 프로세스를 포크(fork)하는 것이 더 바람직할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e예를 들어, 간단한 스레드 애플리케이션:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom threading import Thread as worker\r\ndef afunc(number):\r\n    print number * 3\r\nt = worker(target=afunc, args=(4,))\r\nt.start()\r\nt.join()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003ccode\u003epyprocessing\u003c/code\u003e 패키지는 API를 너무 잘 미러링(mirroring)하여, 임포트 문을 다음과 같이 간단히 변경하는 것만으로도:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom processing import process as worker\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e코드가 \u003ccode\u003eprocessing.process\u003c/code\u003e 클래스를 통해 실행될 것입니다. 물론 API를 PEP 8 준수 방식으로 이름을 변경하면 사용자 애플리케이션 내에서도 추가적인 이름 변경이 필요하겠지만, 그 정도는 사소합니다.\u003c/p\u003e\n\u003cp\u003e이러한 종류의 호환성은 (대부분의 경우) 코드의 사소한 변경만으로 사용자의 애플리케이션이 병렬 실행을 위해 주어진 머신의 모든 코어와 프로세서를 활용할 수 있게 된다는 것을 의미합니다. 많은 경우 \u003ccode\u003epyprocessing\u003c/code\u003e 패키지는 I/O 바운드(I/O-bound) 프로그램의 경우 일반적인 스레딩 접근 방식보다도 더 빠릅니다. 물론 이것은 \u003ccode\u003epyprocessing\u003c/code\u003e 패키지가 최적화된 C 코드로 되어 있고, \u003ccode\u003ethreading\u003c/code\u003e 모듈은 그렇지 않다는 점을 고려한 것입니다.\u003c/p\u003e\n\u003ch2\u003e\"분산(Distributed)\" 문제\u003c/h2\u003e\n\u003cp\u003e이 패키지 포함에 대한 Python-Dev 토론에서는 이 PEP가 \"분산\" 문제를 해결하려는 의도에 대한 혼란이 있었고, 이 패키지의 기능을 MPI 기반 통신, CORBA 또는 다른 분산 객체 접근 방식과 같은 다른 솔루션과 자주 비교했습니다.\u003c/p\u003e\n\u003cp\u003e\"분산\" 문제는 크고 다양합니다. 이 분야에서 작업하는 각 프로그래머는 자신이 좋아하는 모듈/메서드에 대한 매우 강력한 의견을 가지고 있거나, 기존 솔루션으로는 해결되지 않는 고도로 맞춤화된 문제를 가지고 있습니다.\u003c/p\u003e\n\u003cp\u003e이 패키지의 채택은 \"분산\" 문제에 대해 작업하는 프로그래머들이 자신의 문제 영역에 대한 다른 솔루션을 검토하지 못하게 하거나 권장하지 않습니다. 이 패키지를 포함하는 목적은 로컬 동시성(local concurrency)을 위한 초기 수준의 기능과 그 동시성을 머신 네트워크에 분산하기 위한 기본적인 지원을 제공하는 것입니다. 이 둘이 긴밀하게 연결되어 있지는 않지만, \u003ccode\u003epyprocessing\u003c/code\u003e 패키지는 실제로는 MPI/etc를 포함한 다른 어떤 솔루션과도 함께 사용될 수 있습니다.\u003c/p\u003e\n\u003cp\u003e필요한 경우, 패키지의 로컬 동시성 기능을 네트워크 기능/공유 측면과 완전히 분리할 수 있습니다. 그러나 심각한 우려나 원인 없이는 이 PEP의 작성자는 그러한 접근 방식을 권장하지 않습니다.\u003c/p\u003e\n\u003ch2\u003e성능 비교 (Performance Comparison)\u003c/h2\u003e\n\u003cp\u003e우리 모두 알다시피, \"거짓말, 빌어먹을 거짓말, 그리고 벤치마크\"가 있습니다. 이 속도 비교는 \u003ccode\u003epyprocessing\u003c/code\u003e 패키지의 성능을 보여주기 위한 것이지만, 모든 가능한 사용 사례나 환경에 포괄적으로 적용될 수는 없습니다. 특히 프로세스 포크 타이밍이 느린 플랫폼에서는 더욱 그렇습니다.\u003c/p\u003e\n\u003cp\u003e모든 벤치마크는 다음 환경에서 실행되었습니다.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e4 코어 Intel Xeon CPU @ 3.00GHz\u003c/li\u003e\n\u003cli\u003e16 GB RAM\u003c/li\u003e\n\u003cli\u003eGentoo Linux (kernel 2.6.18.6)에 컴파일된 Python 2.5.2\u003c/li\u003e\n\u003cli\u003epyProcessing 0.52\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e이 모든 코드는 \u003ccode\u003ehttp://jessenoller.com/code/bench-src.tgz\u003c/code\u003e에서 다운로드할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e이 벤치마크의 기본 실행 방법은 \u003ccode\u003erun_benchmarks.py\u003c/code\u003e 스크립트에 있습니다. 이 스크립트는 단순히 단일 스레드(선형), 멀티 스레드(\u003ccode\u003ethreading\u003c/code\u003e 모듈 사용), 멀티 프로세스(\u003ccode\u003epyprocessing\u003c/code\u003e 사용) 방식으로 대상 함수를 실행하기 위한 래퍼(wrapper)이며, 증가하는 실행 루프 수 및/또는 스레드 수에 따라 고정된 반복 횟수로 실행됩니다.\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003erun_benchmarks.py\u003c/code\u003e 스크립트는 각 함수를 100번 실행하며, \u003ccode\u003etimeit\u003c/code\u003e 모듈을 통해 이 100번의 반복 중 가장 좋은 실행 결과를 선택합니다.\u003c/p\u003e\n\u003cp\u003e첫째, 워커(worker) 생성의 오버헤드를 식별하기 위해, 단순히 \u003ccode\u003epass\u003c/code\u003e 문(빈 함수)만 있는 함수를 실행했습니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecmd: python run_benchmarks.py empty_func.py\r\nImporting empty_func\r\nStarting tests ...\r\nnon_threaded (1 iters) 0.000001 seconds\r\nthreaded (1 threads) 0.000796 seconds\r\nprocesses (1 procs) 0.000714 seconds\r\nnon_threaded (2 iters) 0.000002 seconds\r\nthreaded (2 threads) 0.001963 seconds\r\nprocesses (2 procs) 0.001466 seconds\r\nnon_threaded (4 iters) 0.000002 seconds\r\nthreaded (4 threads) 0.003986 seconds\r\nprocesses (4 procs) 0.002701 seconds\r\nnon_threaded (8 iters) 0.000003 seconds\r\nthreaded (8 threads) 0.007990 seconds\r\nprocesses (8 procs) 0.005512 seconds\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e보시다시피, \u003ccode\u003epyprocessing\u003c/code\u003e 패키지를 통한 프로세스 포크는 스레드 버전 코드를 빌드하고 실행하는 속도보다 빠릅니다.\u003c/p\u003e\n\u003cp\u003e두 번째 테스트는 각 스레드 내에서(격리되어 아무것도 공유하지 않음) 50000개의 피보나치 수를 계산합니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecmd: python run_benchmarks.py fibonacci.py\r\nImporting fibonacci\r\nStarting tests ...\r\nnon_threaded (1 iters) 0.195548 seconds\r\nthreaded (1 threads) 0.197909 seconds\r\nprocesses (1 procs) 0.201175 seconds\r\nnon_threaded (2 iters) 0.397540 seconds\r\nthreaded (2 threads) 0.397637 seconds\r\nprocesses (2 procs) 0.204265 seconds\r\nnon_threaded (4 iters) 0.795333 seconds\r\nthreaded (4 threads) 0.797262 seconds\r\nprocesses (4 procs) 0.206990 seconds\r\nnon_threaded (8 iters) 1.591680 seconds\r\nthreaded (8 threads) 1.596824 seconds\r\nprocesses (8 procs) 0.417899 seconds\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e세 번째 테스트는 100000 미만의 모든 소수의 합계를 계산하며, 역시 아무것도 공유하지 않습니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecmd: run_benchmarks.py crunch_primes.py\r\nImporting crunch_primes\r\nStarting tests ...\r\nnon_threaded (1 iters) 0.495157 seconds\r\nthreaded (1 threads) 0.522320 seconds\r\nprocesses (1 procs) 0.523757 seconds\r\nnon_threaded (2 iters) 1.052048 seconds\r\nthreaded (2 threads) 1.154726 seconds\r\nprocesses (2 procs) 0.524603 seconds\r\nnon_threaded (4 iters) 2.104733 seconds\r\nthreaded (4 threads) 2.455215 seconds\r\nprocesses (4 procs) 0.530688 seconds\r\nnon_threaded (8 iters) 4.217455 seconds\r\nthreaded (8 threads) 5.109192 seconds\r\nprocesses (8 procs) 1.077939 seconds\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e두 번째와 세 번째 테스트가 순수 수치 계산에 중점을 둔 이유는 현재의 스레딩 구현이 비-I/O 애플리케이션에 어떻게 방해가 되는지를 보여주기 위함입니다. 물론, 이러한 테스트는 결과 및 작업 청크(chunk) 조정을 위해 큐(queue)를 사용하도록 개선될 수 있지만, 이는 패키지와 핵심 \u003ccode\u003eprocessing.process\u003c/code\u003e 모듈의 성능을 보여주는 데 필요하지 않습니다.\u003c/p\u003e\n\u003cp\u003e다음 테스트는 I/O 바운드 테스트입니다. 일반적으로 여기서 우리는 단일 스레드 접근 방식에 비해 스레딩 모듈 접근 방식에서 큰 개선을 볼 수 있습니다. 이 경우, 각 워커는 \u003ccode\u003elorem.txt\u003c/code\u003e에 대한 디스크립터(descriptor)를 열고, 그 안에서 무작위로 탐색(seek)하여 \u003ccode\u003e/dev/null\u003c/code\u003e에 라인들을 작성합니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecmd: python run_benchmarks.py file_io.py\r\nImporting file_io\r\nStarting tests ...\r\nnon_threaded (1 iters) 0.057750 seconds\r\nthreaded (1 threads) 0.089992 seconds\r\nprocesses (1 procs) 0.090817 seconds\r\nnon_threaded (2 iters) 0.180256 seconds\r\nthreaded (2 threads) 0.329961 seconds\r\nprocesses (2 procs) 0.096683 seconds\r\nnon_threaded (4 iters) 0.370841 seconds\r\nthreaded (4 threads) 1.103678 seconds\r\nprocesses (4 procs) 0.101535 seconds\r\nnon_threaded (8 iters) 0.749571 seconds\r\nthreaded (8 threads) 2.437204 seconds\r\nprocesses (8 procs) 0.203438 seconds\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e보시다시피, \u003ccode\u003epyprocessing\u003c/code\u003e은 이 I/O 작업에서도 여러 스레드를 사용하는 것보다 여전히 빠릅니다. 그리고 여러 스레드를 사용하는 것은 단일 스레드 실행 자체보다 느립니다.\u003c/p\u003e\n\u003cp\u003e마지막으로, 네트워크 I/O 성능을 보여주기 위해 소켓 기반 테스트를 실행할 것입니다. 이 함수는 LAN 상의 서버에서 간단한 톰캣 오류 페이지인 URL을 100번 가져옵니다. 네트워크는 조용하고, 10G 연결입니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecmd: python run_benchmarks.py url_get.py\r\nImporting url_get\r\nStarting tests ...\r\nnon_threaded (1 iters) 0.124774 seconds\r\nthreaded (1 threads) 0.120478 seconds\r\nprocesses (1 procs) 0.121404 seconds\r\nnon_threaded (2 iters) 0.239574 seconds\r\nthreaded (2 threads) 0.146138 seconds\r\nprocesses (2 procs) 0.138366 seconds\r\nnon_threaded (4 iters) 0.479159 seconds\r\nthreaded (4 threads) 0.200985 seconds\r\nprocesses (4 procs) 0.188847 seconds\r\nnon_threaded (8 iters) 0.960621 seconds\r\nthreaded (8 threads) 0.659298 seconds\r\nprocesses (8 procs) 0.298625 seconds\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e마침내 스레드 성능이 단일 스레드 실행을 능가하는 것을 볼 수 있지만, 워커 수를 늘릴 때는 \u003ccode\u003epyprocessing\u003c/code\u003e 패키지가 여전히 더 빠릅니다. 한두 개의 스레드/워커를 유지한다면, 스레드와 \u003ccode\u003epyprocessing\u003c/code\u003e 간의 시간 차이는 상당히 비슷합니다.\u003c/p\u003e\n\u003cp\u003e하지만 주목할 점은, \u003ccode\u003epyprocessing\u003c/code\u003e 패키지의 Queue 구현에는 객체 직렬화(serialization)로 인한 암묵적인 오버헤드(overhead)가 있다는 것입니다.\u003c/p\u003e\n\u003cp\u003eAlec Thomas는 \u003ccode\u003erun_benchmarks.py\u003c/code\u003e 스크립트를 기반으로 한 짧은 예제를 제공하여 기본 Queue 구현 대비 이러한 오버헤드를 보여주었습니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecmd: run_bench_queue.py\r\nnon_threaded (1 iters) 0.010546 seconds\r\nthreaded (1 threads) 0.015164 seconds\r\nprocesses (1 procs) 0.066167 seconds\r\nnon_threaded (2 iters) 0.020768 seconds\r\nthreaded (2 threads) 0.041635 seconds\r\nprocesses (2 procs) 0.084270 seconds\r\nnon_threaded (4 iters) 0.041718 seconds\r\nthreaded (4 threads) 0.086394 seconds\r\nprocesses (4 procs) 0.144176 seconds\r\nnon_threaded (8 iters) 0.083488 seconds\r\nthreaded (8 threads) 0.184254 seconds\r\nprocesses (8 procs) 0.302999 seconds\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e추가 벤치마크는 \u003ccode\u003epyprocessing\u003c/code\u003e 패키지의 소스 배포판 \u003ccode\u003eexamples/\u003c/code\u003e 디렉토리에서 찾을 수 있습니다. 이 예제들은 패키지 문서에 포함될 것입니다.\u003c/p\u003e\n\u003ch2\u003e유지 보수 (Maintenance)\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003epyprocessing\u003c/code\u003e 패키지의 저자인 Richard M. Oudkerk는 Python SVN 내에서 패키지를 유지 보수하는 데 동의했습니다. Jesse Noller는 또한 패키지 유지 보수/문서화 및 테스트를 돕기로 자원했습니다.\u003c/p\u003e\n\u003ch2\u003eAPI 명명 (API Naming)\u003c/h2\u003e\n\u003cp\u003e패키지 API의 목표는 Python 2.x의 \u003ccode\u003ethreading\u003c/code\u003e 및 \u003ccode\u003eQueue\u003c/code\u003e 모듈의 API를 면밀히 모방하도록 설계되었지만, 해당 모듈들은 PEP 8을 준수하지 않습니다. 따라서 패키지를 \"있는 그대로\" 추가하여 비-PEP 8 준수 명명을 영속화하는 대신, 모든 API, 클래스 등의 이름을 완전히 PEP 8을 준수하도록 변경하기로 결정했습니다.\u003c/p\u003e\n\u003cp\u003e이러한 변경은 \u003ccode\u003ethreading\u003c/code\u003e 모듈을 사용하는 사람들에게는 교체 용이성(ease-of-drop in replacement)에 영향을 미치지만, 작성자들의 관점에서는 이는 수용 가능한 부작용입니다. 특히 \u003ccode\u003ethreading\u003c/code\u003e 모듈 자체의 API도 변경될 예정이라는 점을 고려하면 더욱 그렇습니다.\u003c/p\u003e\n\u003cp\u003e트래커의 Issue 3042는 Python 2.6에 \u003ccode\u003ethreading\u003c/code\u003e 모듈을 위한 두 가지 API, 즉 현재 API와 PEP 8 준수 API가 있을 것을 제안합니다. \u003ccode\u003e-3\u003c/code\u003e이 호출될 때 원래의 Java 스타일 API의 향후 제거에 대한 경고가 발행될 것입니다.\u003c/p\u003e\n\u003cp\u003ePython 3000에서는 \u003ccode\u003ethreading\u003c/code\u003e API가 PEP 8을 준수하게 될 것이며, 이는 \u003ccode\u003emultiprocessing\u003c/code\u003e 모듈과 \u003ccode\u003ethreading\u003c/code\u003e 모듈이 다시 일치하는 API를 갖게 될 것임을 의미합니다.\u003c/p\u003e\n\u003ch2\u003e타이밍/일정 (Timing/Schedule)\u003c/h2\u003e\n\u003cp\u003e올해 2.6 및 3.0 릴리스를 위한 이 PEP의 타이밍/늦음(lateness)에 대한 일부 우려가 제기되었지만, 작성자들과 다른 사람들은 이 패키지가 제공하는 기능이 포함 위험을 능가한다고 생각합니다.\u003c/p\u003e\n\u003cp\u003e그러나 Python 코어(core)를 불안정하게 만들지 않으려는 바람을 고려하여, \u003ccode\u003epyprocessing\u003c/code\u003e 코드의 일부 리팩토링(refactoring)을 다음 2.x/3.x 릴리스까지 보류할 수 있습니다. 이는 Python 코어에 대한 실제 위험이 최소화되며, 주로 실제 패키지 자체에 한정된다는 것을 의미합니다.\u003c/p\u003e\n\u003ch2\u003e열린 문제 (Open Issues)\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\"기본\" 원격 연결 기능이 없는지 확인하고, 필요한 경우 원격 기능을 제공하는 클래스에 대해 원격 보안 메커니즘을 기본적으로 활성화해야 합니다.\u003c/li\u003e\n\u003cli\u003e일부 API(\u003ccode\u003eQueue\u003c/code\u003e 메서드 \u003ccode\u003eqsize()\u003c/code\u003e, \u003ccode\u003etask_done()\u003c/code\u003e, \u003ccode\u003ejoin()\u003c/code\u003e)는 추가되어야 하거나, 제외 이유가 명확히 식별되고 문서화되어야 합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e해결된 문제 (Closed Issues)\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eroudkerk\u003c/code\u003e가 issue 1683에 제출한 \u003ccode\u003ePyGILState\u003c/code\u003e 버그 패치는 패키지 단위 테스트가 작동하도록 적용되어야 합니다.\u003c/li\u003e\n\u003cli\u003e기존 문서는 ReST 형식으로 이동되어야 합니다.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ectypes\u003c/code\u003e에 대한 의존성: \u003ccode\u003epyprocessing\u003c/code\u003e 패키지의 \u003ccode\u003ectypes\u003c/code\u003e 의존성은 \u003ccode\u003ectypes\u003c/code\u003e가 지원되지 않는 플랫폼에서 패키지가 작동하지 못하게 합니다. 이는 이 패키지의 제한 사항이 아니라 \u003ccode\u003ectypes\u003c/code\u003e의 제한 사항입니다.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e완료:\u003c/strong\u003e 최상위 패키지 이름을 \"pyprocessing\"에서 \"multiprocessing\"으로 변경했습니다.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e완료:\u003c/strong\u003e 또한 프로세스 생성의 기본 동작이 \u003ccode\u003eIDLE\u003c/code\u003e 내에서 그대로 사용하기에 호환되지 않으므로, 이는 버그 수정 또는 \"setExecutable\" 개선 사항으로 검토될 것입니다.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e완료:\u003c/strong\u003e Python 인터프리터 대신 현재 실행 파일 이름을 사용하여 프로세스를 생성하는 패키지의 기본 동작을 재정의하기 위해 \"multiprocessing.setExecutable()\" 메서드를 추가했습니다. Mark Hammond는 이를 위한 팩토리 스타일(factory-style) 인터페이스를 제안했습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e참고 자료 (References)\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e2008년 당시의 PyProcessing 프로젝트 (\u003ccode\u003epyprocessing\u003c/code\u003e 이름은 이후 재사용됨) \u003ca href=\"https://web.archive.org/web/20080914113946/https://pyprocessing.berlios.de/\"\u003ehttps://web.archive.org/web/20080914113946/https://pyprocessing.berlios.de/\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eAdam Olsen의 \"safe threading\" 프로젝트 참조 \u003ca href=\"https://code.google.com/archive/p/python-safethread/\"\u003ehttps://code.google.com/archive/p/python-safethread/\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e참조: 표준 라이브러리에 \"pyprocessing\" 모듈 추가 \u003ca href=\"https://mail.python.org/pipermail/python-dev/2008-May/079417.html\"\u003ehttps://mail.python.org/pipermail/python-dev/2008-May/079417.html\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mpi4py.readthedocs.io/\"\u003ehttps://mpi4py.readthedocs.io/\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\"클러스터 컴퓨팅(Cluster Computing)\" 참조 \u003ca href=\"https://wiki.python.org/moin/ParallelProcessing#Cluster_Computing\"\u003ehttps://wiki.python.org/moin/ParallelProcessing#Cluster_Computing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e원본 \u003ccode\u003erun_benchmark.py\u003c/code\u003e 코드는 2007년 12월 Python Magazine에 Jesse Noller의 \"Python Threads and the Global Interpreter Lock\"이라는 제목으로 출판되었습니다. 이 PEP를 위해 수정되었습니다.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://groups.google.com/group/python-dev2/msg/54cf06d15cbcbc34\"\u003ehttp://groups.google.com/group/python-dev2/msg/54cf06d15cbcbc34\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e저작권 (Copyright)\u003c/h2\u003e\n\u003cp\u003e이 문서는 퍼블릭 도메인(public domain)으로 지정되었습니다.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e⚠️ \u003cstrong\u003e알림:\u003c/strong\u003e 이 문서는 AI를 활용하여 번역되었으며, 기술적 정확성을 보장하지 않습니다. 정확한 내용은 반드시 원문을 확인하시기 바랍니다.\u003c/p\u003e\n\u003c/blockquote\u003e\n"])</script><script>self.__next_f.push([1,"4:[\"$\",\"div\",null,{\"className\":\"flex flex-col lg:flex-row gap-8\",\"children\":[[\"$\",\"aside\",null,{\"className\":\"lg:w-64 xl:w-72 order-1 lg:order-none\",\"children\":[\"$\",\"div\",null,{\"className\":\"sidebar sticky\",\"children\":[\"$\",\"nav\",null,{\"className\":\"space-y-4\",\"children\":[[\"$\",\"div\",\"Backend\",{\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"Backend\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"Django\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/backend/django/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Django\",\" (\",6,\")\"]}]}],[\"$\",\"li\",\"Logging\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/backend/logging/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Logging\",\" (\",1,\")\"]}]}]]}]]}],[\"$\",\"div\",\"Python\",{\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"Python\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"PEP\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/python/pep/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"PEP\",\" (\",650,\")\"]}]}]]}]]}],[\"$\",\"div\",\"AI/ML\",{\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"AI/ML\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"LLM\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/ai/llm/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"LLM\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"Review\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/ai/review/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Review\",\" (\",2672,\")\"]}]}]]}]]}],[\"$\",\"div\",\"DevOps\",{\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"DevOps\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"Nginx\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/devops/nginx/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Nginx\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"Docker\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/devops/docker/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Docker\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"SafeLine\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/devops/safeline/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"SafeLine\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"Jenkins\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/devops/jenkins/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Jenkins\",\" (\",3,\")\"]}]}],[\"$\",\"li\",\"GitHub Actions\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/devops/github-actions/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"GitHub Actions\",\" (\",1,\")\"]}]}],[\"$\",\"li\",\"AWS\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/devops/aws/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"AWS\",\" (\",1,\")\"]}]}]]}]]}],[\"$\",\"div\",\"etc\",{\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"etc\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 ml-4\",\"children\":[[\"$\",\"li\",\"Me\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/etc/me/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Me\",\" (\",3,\")\"]}]}],[\"$\",\"li\",\"Chrome Extension\",{\"children\":[\"$\",\"a\",null,{\"href\":\"/etc/chrome-extension/\",\"className\":\"text-sm text-gray-600 hover:text-primary-600 block py-1\",\"children\":[\"Chrome Extension\",\" (\",1,\")\"]}]}]]}]]}]]}]}]}],[\"$\",\"main\",null,{\"className\":\"flex-1\",\"children\":[\"$\",\"article\",null,{\"className\":\"page\",\"children\":[[\"$\",\"header\",null,{\"className\":\"mb-8\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"page__title\",\"children\":\"[Final] PEP 371 - Addition of the multiprocessing package to the standard library\"}],[\"$\",\"div\",null,{\"className\":\"page__meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-26 20:55:33+0900\",\"children\":\"2025년 9월 26일\"}],[\"$\",\"span\",null,{\"className\":\"ml-4\",\"children\":[\"수정: \",\"2025년 9월 26일\"]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"page__content\",\"children\":[\"$\",\"div\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$d\"}}]}],[\"$\",\"footer\",null,{\"className\":\"page__meta mt-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"page__taxonomy\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"text-sm font-medium text-gray-900 mb-2\",\"children\":\"태그\"}],[[\"$\",\"span\",\"Python\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Python\"]}],[\"$\",\"span\",\"PEP\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"PEP\"]}],[\"$\",\"span\",\"Translation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Translation\"]}]]]}]}],[\"$\",\"$Le\",null,{\"postPermalink\":\"/python/pep/371/\",\"postId\":\"2025-09-26-pep-0371-addition-of-the-multiprocessing-package-to-the-standard-library\"}],[\"$\",\"section\",null,{\"className\":\"mt-12 border-t border-gray-200 pt-8\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-base font-semibold text-gray-900 mb-4\",\"children\":[\"Python\",\" 의 다른글\"]}],[\"$\",\"ul\",null,{\"className\":\"space-y-2 text-sm\",\"children\":[[\"$\",\"li\",null,{\"className\":\"text-gray-500\",\"children\":[\"이전글\",\" \",[\"$\",\"$L9\",null,{\"href\":\"/python/pep/370/\",\"className\":\"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4\",\"children\":\"[Final] PEP 370 - Per user site-packages directory\"}]]}],[\"$\",\"li\",null,{\"className\":\"text-gray-900 font-semibold\",\"children\":[\"현재글 : \",\"[Final] PEP 371 - Addition of the multiprocessing package to the standard library\"]}],[\"$\",\"li\",null,{\"className\":\"text-gray-500\",\"children\":[\"다음글\",\" \",[\"$\",\"$L9\",null,{\"href\":\"/python/pep/372/\",\"className\":\"text-gray-500 hover:text-gray-700 underline decoration-dotted underline-offset-4\",\"children\":\"[Final] PEP 372 - Adding an ordered dictionary to collections\"}]]}]]}]]}]]}]}]]}]\n"])</script><script>self.__next_f.push([1,"a:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"secrett2633's blog\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\"}],[\"$\",\"meta\",\"4\",{\"name\":\"author\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"5\",{\"name\":\"keywords\",\"content\":\"Django, Python, DevOps, AI, ML, 블로그, 기술\"}],[\"$\",\"meta\",\"6\",{\"name\":\"creator\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"7\",{\"name\":\"publisher\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"8\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"9\",{\"name\":\"googlebot\",\"content\":\"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1\"}],[\"$\",\"link\",\"10\",{\"rel\":\"canonical\",\"href\":\"https://blog.secrett2633.cloud/\"}],[\"$\",\"meta\",\"11\",{\"name\":\"format-detection\",\"content\":\"telephone=no, address=no, email=no\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:title\",\"content\":\"secrett2633's blog\"}],[\"$\",\"meta\",\"13\",{\"property\":\"og:description\",\"content\":\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\"}],[\"$\",\"meta\",\"14\",{\"property\":\"og:url\",\"content\":\"https://blog.secrett2633.cloud/\"}],[\"$\",\"meta\",\"15\",{\"property\":\"og:site_name\",\"content\":\"secrett2633's blog\"}],[\"$\",\"meta\",\"16\",{\"property\":\"og:locale\",\"content\":\"ko_KR\"}],[\"$\",\"meta\",\"17\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"18\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"19\",{\"name\":\"twitter:title\",\"content\":\"secrett2633's blog\"}],[\"$\",\"meta\",\"20\",{\"name\":\"twitter:description\",\"content\":\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\"}],[\"$\",\"link\",\"21\",{\"rel\":\"icon\",\"href\":\"/icon.ico?6d9f34d4948640b8\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}]]\n3:null\n"])</script></body></html>