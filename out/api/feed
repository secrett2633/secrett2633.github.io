<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>secrett2633's blog</title>
    <description>기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트</description>
    <link>https://blog.secrett2633.cloud</link>
    <atom:link href="https://blog.secrett2633.cloud/api/feed" rel="self" type="application/rss+xml" />
    <language>ko-KR</language>
    <lastBuildDate>Thu, 19 Feb 2026 07:15:48 GMT</lastBuildDate>
    <pubDate>Thu, 19 Feb 2026 07:15:48 GMT</pubDate>
    <ttl>60</ttl>
    <generator>Next.js RSS Generator</generator>
    <managingEditor>secrett2633@example.com (secrett2633)</managingEditor>
    <webMaster>secrett2633@example.com (secrett2633)</webMaster>
    <category>Technology</category>
    <category>Programming</category>
    <category>Django</category>
    <category>Python</category>
    <category>DevOps</category>
    <category>AI/ML</category>
    
        <item>
      <title>[논문리뷰] Visual Persuasion: What Influences Decisions of Vision-Language Models?</title>
      <description>Nikhil Singh이 [arXiv]에 게시한 &#39;Visual Persuasion: What Influences Decisions of Vision-Language Models?&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-18-Visual-Persuasion-What-Influences-Decisions-of-Vision-Language-Models</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-18-Visual-Persuasion-What-Influences-Decisions-of-Vision-Language-Models</guid>
      <pubDate>Wed, 18 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Vision-Language Models</category><category>Visual Persuasion</category><category>Prompt Optimization</category><category>Image Generation</category><category>AI Agent Behavior</category><category>Interpretability</category><category>Behavioral Evaluation</category>
    </item>
    <item>
      <title>[논문리뷰] UniT: Unified Multimodal Chain-of-Thought Test-time Scaling</title>
      <description>Animesh Sinha이 [arXiv]에 게시한 &#39;UniT: Unified Multimodal Chain-of-Thought Test-time Scaling&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-18-UniT-Unified-Multimodal-Chain-of-Thought-Test-time-Scaling</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-18-UniT-Unified-Multimodal-Chain-of-Thought-Test-time-Scaling</guid>
      <pubDate>Wed, 18 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Multimodal AI</category><category>Chain-of-Thought</category><category>Test-time Scaling</category><category>Unified Models</category><category>Iterative Reasoning</category><category>Image Generation</category><category>Visual Reasoning</category><category>Self-Correction</category>
    </item>
    <item>
      <title>[논문리뷰] Understanding vs. Generation: Navigating Optimization Dilemma in Multimodal Models</title>
      <description>Liwei Wang이 [arXiv]에 게시한 &#39;Understanding vs. Generation: Navigating Optimization Dilemma in Multimodal Models&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-18-Understanding-vs-Generation-Navigating-Optimization-Dilemma-in-Multimodal-Models</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-18-Understanding-vs-Generation-Navigating-Optimization-Dilemma-in-Multimodal-Models</guid>
      <pubDate>Wed, 18 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Multimodal Models</category><category>Generative AI</category><category>Understanding</category><category>Reason-Reflect-Refine (R3)</category><category>Reinforcement Learning (RL)</category><category>Text-to-Image Generation</category><category>Optimization Dilemma</category><category>Image Editing</category>
    </item>
    <item>
      <title>[논문리뷰] STAPO: Stabilizing Reinforcement Learning for LLMs by Silencing Rare Spurious Tokens</title>
      <description>Zhilong Zheng이 [arXiv]에 게시한 &#39;STAPO: Stabilizing Reinforcement Learning for LLMs by Silencing Rare Spurious Tokens&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-18-STAPO-Stabilizing-Reinforcement-Learning-for-LLMs-by-Silencing-Rare-Spurious-Tokens</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-18-STAPO-Stabilizing-Reinforcement-Learning-for-LLMs-by-Silencing-Rare-Spurious-Tokens</guid>
      <pubDate>Wed, 18 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Reinforcement Learning</category><category>Large Language Models</category><category>Training Stability</category><category>Policy Optimization</category><category>Spurious Tokens</category><category>Entropy Regularization</category><category>Gradient Modulation</category>
    </item>
    <item>
      <title>[논문리뷰] Sanity Checks for Sparse Autoencoders: Do SAEs Beat Random Baselines?</title>
      <description>Ivan Oseledets이 [arXiv]에 게시한 &#39;Sanity Checks for Sparse Autoencoders: Do SAEs Beat Random Baselines?&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-18-Sanity-Checks-for-Sparse-Autoencoders-Do-SAEs-Beat-Random-Baselines</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-18-Sanity-Checks-for-Sparse-Autoencoders-Do-SAEs-Beat-Random-Baselines</guid>
      <pubDate>Wed, 18 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Sparse Autoencoders</category><category>Interpretability</category><category>Neural Network Internals</category><category>Evaluation Baselines</category><category>Feature Decomposition</category><category>LLMs</category><category>Mechanistic Interpretability</category>
    </item>
    <item>
      <title>[논문리뷰] Revisiting the Platonic Representation Hypothesis: An Aristotelian View</title>
      <description>Maria Brbić이 [arXiv]에 게시한 &#39;Revisiting the Platonic Representation Hypothesis: An Aristotelian View&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-18-Revisiting-the-Platonic-Representation-Hypothesis-An-Aristotelian-View</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-18-Revisiting-the-Platonic-Representation-Hypothesis-An-Aristotelian-View</guid>
      <pubDate>Wed, 18 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Representational Similarity</category><category>Null Calibration</category><category>Permutation Testing</category><category>Confounder</category><category>Neural Network Representation</category><category>Platonic Representation Hypothesis</category><category>Aristotelian Representation Hypothesis</category>
    </item>
    <item>
      <title>[논문리뷰] ResearchGym: Evaluating Language Model Agents on Real-World AI Research</title>
      <description>Arman Cohan이 [arXiv]에 게시한 &#39;ResearchGym: Evaluating Language Model Agents on Real-World AI Research&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-18-ResearchGym-Evaluating-Language-Model-Agents-on-Real-World-AI-Research</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-18-ResearchGym-Evaluating-Language-Model-Agents-on-Real-World-AI-Research</guid>
      <pubDate>Wed, 18 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>LLM Agents</category><category>AI Research</category><category>Benchmark</category><category>Closed-loop Research</category><category>Agent Evaluation</category><category>Reproducibility</category><category>Real-world Tasks</category>
    </item>
    <item>
      <title>[논문리뷰] Prescriptive Scaling Reveals the Evolution of Language Model Capabilities</title>
      <description>Sham Kakade이 [arXiv]에 게시한 &#39;Prescriptive Scaling Reveals the Evolution of Language Model Capabilities&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-18-Prescriptive-Scaling-Reveals-the-Evolution-of-Language-Model-Capabilities</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-18-Prescriptive-Scaling-Reveals-the-Evolution-of-Language-Model-Capabilities</guid>
      <pubDate>Wed, 18 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Prescriptive Scaling</category><category>Language Models</category><category>Capability Boundaries</category><category>Quantile Regression</category><category>Scaling Laws</category><category>Temporal Stability</category><category>I-Optimal Design</category><category>Benchmark Saturation</category>
    </item>
    <item>
      <title>[논문리뷰] On Surprising Effectiveness of Masking Updates in Adaptive Optimizers</title>
      <description>이 [arXiv]에 게시한 &#39;On Surprising Effectiveness of Masking Updates in Adaptive Optimizers&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-18-On-Surprising-Effectiveness-of-Masking-Updates-in-Adaptive-Optimizers</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-18-On-Surprising-Effectiveness-of-Masking-Updates-in-Adaptive-Optimizers</guid>
      <pubDate>Wed, 18 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Adaptive Optimizers</category><category>Gradient Masking</category><category>LLM Training</category><category>Geometric Regularization</category><category>Momentum Alignment</category><category>RMSProp</category><category>Perplexity</category><category>Deep Learning</category>
    </item>
    <item>
      <title>[논문리뷰] Learning Native Continuation for Action Chunking Flow Policies</title>
      <description>Di Zhang이 [arXiv]에 게시한 &#39;Learning Native Continuation for Action Chunking Flow Policies&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-18-Learning-Native-Continuation-for-Action-Chunking-Flow-Policies</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-18-Learning-Native-Continuation-for-Action-Chunking-Flow-Policies</guid>
      <pubDate>Wed, 18 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Action Chunking</category><category>Flow-based Policies</category><category>Trajectory Continuation</category><category>Robotics</category><category>Vision-Language-Action (VLA)</category><category>Denoising Dynamics</category><category>Schedule-shaped Guidance</category><category>Real-time Control</category>
    </item>
    <item>
      <title>[논문리뷰] GLM-5: from Vibe Coding to Agentic Engineering</title>
      <description>GLM-5 Team이 [arXiv]에 게시한 &#39;GLM-5: from Vibe Coding to Agentic Engineering&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-18-GLM-5-from-Vibe-Coding-to-Agentic-Engineering</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-18-GLM-5-from-Vibe-Coding-to-Agentic-Engineering</guid>
      <pubDate>Wed, 18 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Foundation Model</category><category>Agentic AI</category><category>Reinforcement Learning</category><category>Sparse Attention</category><category>Software Engineering</category><category>Long-Context Models</category><category>GPU Optimization</category>
    </item>
    <item>
      <title>[논문리뷰] Geometry-Aware Rotary Position Embedding for Consistent Video World Model</title>
      <description>이 [arXiv]에 게시한 &#39;Geometry-Aware Rotary Position Embedding for Consistent Video World Model&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-18-Geometry-Aware-Rotary-Position-Embedding-for-Consistent-Video-World-Model</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-18-Geometry-Aware-Rotary-Position-Embedding-for-Consistent-Video-World-Model</guid>
      <pubDate>Wed, 18 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Video World Model</category><category>Generative AI</category><category>Transformer</category><category>Positional Encoding</category><category>3D Consistency</category><category>View Synthesis</category><category>Sparse Attention</category><category>Loop Closure</category>
    </item>
    <item>
      <title>[논문리뷰] Does Socialization Emerge in AI Agent Society? A Case Study of Moltbook</title>
      <description>Ming Li이 [arXiv]에 게시한 &#39;Does Socialization Emerge in AI Agent Society? A Case Study of Moltbook&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-18-Does-Socialization-Emerge-in-AI-Agent-Society-A-Case-Study-of-Moltbook</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-18-Does-Socialization-Emerge-in-AI-Agent-Society-A-Case-Study-of-Moltbook</guid>
      <pubDate>Wed, 18 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>AI Agent Societies</category><category>Socialization</category><category>Large Language Models (LLMs)</category><category>Collective Dynamics</category><category>Semantic Analysis</category><category>Network Analysis</category><category>Moltbook</category>
    </item>
    <item>
      <title>[논문리뷰] COMPOT: Calibration-Optimized Matrix Procrustes Orthogonalization for Transformers Compression</title>
      <description>이 [arXiv]에 게시한 &#39;COMPOT: Calibration-Optimized Matrix Procrustes Orthogonalization for Transformers Compression&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-18-COMPOT-Calibration-Optimized-Matrix-Procrustes-Orthogonalization-for-Transformers-Compression</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-18-COMPOT-Calibration-Optimized-Matrix-Procrustes-Orthogonalization-for-Transformers-Compression</guid>
      <pubDate>Wed, 18 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Transformer Compression</category><category>Matrix Factorization</category><category>Sparse Dictionary Learning</category><category>Post-Training Quantization</category><category>Procrustes Analysis</category><category>Orthogonal Dictionary</category><category>Dynamic Allocation</category>
    </item>
    <item>
      <title>[논문리뷰] ClinAlign: Scaling Healthcare Alignment from Clinician Preference</title>
      <description>Chaohe Zhang이 [arXiv]에 게시한 &#39;ClinAlign: Scaling Healthcare Alignment from Clinician Preference&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-18-ClinAlign-Scaling-Healthcare-Alignment-from-Clinician-Preference</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-18-ClinAlign-Scaling-Healthcare-Alignment-from-Clinician-Preference</guid>
      <pubDate>Wed, 18 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Healthcare AI</category><category>LLM Alignment</category><category>Clinician Preference</category><category>Rubric-based RLHF</category><category>Medical LLMs</category><category>Data Curation</category><category>HealthBench</category><category>Principle-based Supervision</category>
    </item>
    <item>
      <title>[논문리뷰] Causal-JEPA: Learning World Models through Object-Level Latent Interventions</title>
      <description>이 [arXiv]에 게시한 &#39;Causal-JEPA: Learning World Models through Object-Level Latent Interventions&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-18-Causal-JEPA-Learning-World-Models-through-Object-Level-Latent-Interventions</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-18-Causal-JEPA-Learning-World-Models-through-Object-Level-Latent-Interventions</guid>
      <pubDate>Wed, 18 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>World Models</category><category>Object-Centric Representations</category><category>Latent Interventions</category><category>Masked Prediction</category><category>Causal Inductive Bias</category><category>Joint Embedding Predictive Architecture (JEPA)</category><category>Visual Question Answering (VQA)</category><category>Model Predictive Control (MPC)</category>
    </item>
    <item>
      <title>[논문리뷰] UniWeTok: An Unified Binary Tokenizer with Codebook Size 2^{128} for Unified Multimodal Large Language Model</title>
      <description>이 [arXiv]에 게시한 &#39;UniWeTok: An Unified Binary Tokenizer with Codebook Size 2^{128} for Unified Multimodal Large Language Model&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-17-UniWeTok-An-Unified-Binary-Tokenizer-with-Codebook-Size-2128-for-Unified-Multimodal-Large-Language-Model</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-17-UniWeTok-An-Unified-Binary-Tokenizer-with-Codebook-Size-2128-for-Unified-Multimodal-Large-Language-Model</guid>
      <pubDate>Tue, 17 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Multimodal LLM</category><category>Visual Tokenizer</category><category>Binary Codebook</category><category>Image Generation</category><category>Semantic Extraction</category><category>Pre-Post Distillation</category><category>Hybrid Architecture</category>
    </item>
    <item>
      <title>[논문리뷰] REDSearcher: A Scalable and Cost-Efficient Framework for Long-Horizon Search Agents</title>
      <description>이 [arXiv]에 게시한 &#39;REDSearcher: A Scalable and Cost-Efficient Framework for Long-Horizon Search Agents&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-17-REDSearcher-A-Scalable-and-Cost-Efficient-Framework-for-Long-Horizon-Search-Agents</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-17-REDSearcher-A-Scalable-and-Cost-Efficient-Framework-for-Long-Horizon-Search-Agents</guid>
      <pubDate>Tue, 17 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Long-Horizon Search</category><category>Multimodal LLM</category><category>Task Synthesis</category><category>Agentic Mid-Training</category><category>Reinforcement Learning</category><category>Tool-Augmented Agents</category><category>Web Search</category>
    </item>
    <item>
      <title>[논문리뷰] Qute: Towards Quantum-Native Database</title>
      <description>Surui Tang이 [arXiv]에 게시한 &#39;Qute: Towards Quantum-Native Database&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-17-Qute-Towards-Quantum-Native-Database</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-17-Qute-Towards-Quantum-Native-Database</guid>
      <pubDate>Tue, 17 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Quantum Database</category><category>Quantum Computing</category><category>SQL Compilation</category><category>Hybrid Optimizer</category><category>Quantum Indexing</category><category>Fidelity-Preserving Storage</category><category>Grover&#39;s Algorithm</category>
    </item>
    <item>
      <title>[논문리뷰] Query as Anchor: Scenario-Adaptive User Representation via Large Language Model</title>
      <description>이 [arXiv]에 게시한 &#39;Query as Anchor: Scenario-Adaptive User Representation via Large Language Model&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-17-Query-as-Anchor-Scenario-Adaptive-User-Representation-via-Large-Language-Model</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-17-Query-as-Anchor-Scenario-Adaptive-User-Representation-via-Large-Language-Model</guid>
      <pubDate>Tue, 17 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>User Representation Learning</category><category>Large Language Models</category><category>Scenario-Adaptive</category><category>Query-Conditioned</category><category>Multi-modal</category><category>Prompt Tuning</category><category>KV-Cache</category><category>Industrial AI</category>
    </item>
    
  </channel>
</rss>