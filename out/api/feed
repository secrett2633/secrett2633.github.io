<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>secrett2633's blog</title>
    <description>기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트</description>
    <link>https://blog.secrett2633.cloud</link>
    <atom:link href="https://blog.secrett2633.cloud/api/feed" rel="self" type="application/rss+xml" />
    <language>ko-KR</language>
    <lastBuildDate>Sat, 14 Feb 2026 19:27:03 GMT</lastBuildDate>
    <pubDate>Sat, 14 Feb 2026 19:27:03 GMT</pubDate>
    <ttl>60</ttl>
    <generator>Next.js RSS Generator</generator>
    <managingEditor>secrett2633@example.com (secrett2633)</managingEditor>
    <webMaster>secrett2633@example.com (secrett2633)</webMaster>
    <category>Technology</category>
    <category>Programming</category>
    <category>Django</category>
    <category>Python</category>
    <category>DevOps</category>
    <category>AI/ML</category>
    
        <item>
      <title>[논문리뷰] χ_{0}: Resource-Aware Robust Manipulation via Taming Distributional Inconsistencies</title>
      <description>이 [arXiv]에 게시한 &#39;χ_{0}: Resource-Aware Robust Manipulation via Taming Distributional Inconsistencies&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-13-χ_0-Resource-Aware-Robust-Manipulation-via-Taming-Distributional-Inconsistencies/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-13-χ_0-Resource-Aware-Robust-Manipulation-via-Taming-Distributional-Inconsistencies/</guid>
      <pubDate>Fri, 13 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Robotic Manipulation</category><category>Distributional Shift</category><category>Imitation Learning</category><category>Model Arithmetic</category><category>Stage Advantage</category><category>Train-Deploy Alignment</category><category>Resource-Efficient AI</category><category>Long-Horizon Tasks</category>
    </item>
    <item>
      <title>[논문리뷰] Unveiling Implicit Advantage Symmetry: Why GRPO Struggles with Exploration and Difficulty Adaptation</title>
      <description>이 [arXiv]에 게시한 &#39;Unveiling Implicit Advantage Symmetry: Why GRPO Struggles with Exploration and Difficulty Adaptation&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-13-Unveiling-Implicit-Advantage-Symmetry-Why-GRPO-Struggles-with-Exploration-and-Difficulty-Adaptation/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-13-Unveiling-Implicit-Advantage-Symmetry-Why-GRPO-Struggles-with-Exploration-and-Difficulty-Adaptation/</guid>
      <pubDate>Fri, 13 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Reinforcement Learning</category><category>LLM Reasoning</category><category>Group Relative Policy Optimization</category><category>Advantage Estimation</category><category>Exploration-Exploitation</category><category>Curriculum Learning</category><category>Multi-modal LLMs</category>
    </item>
    <item>
      <title>[논문리뷰] ThinkRouter: Efficient Reasoning via Routing Thinking between Latent and Discrete Spaces</title>
      <description>Julian McAuley이 [arXiv]에 게시한 &#39;ThinkRouter: Efficient Reasoning via Routing Thinking between Latent and Discrete Spaces&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-13-ThinkRouter-Efficient-Reasoning-via-Routing-Thinking-between-Latent-and-Discrete-Spaces/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-13-ThinkRouter-Efficient-Reasoning-via-Routing-Thinking-between-Latent-and-Discrete-Spaces/</guid>
      <pubDate>Fri, 13 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Efficient Reasoning</category><category>Latent Space Reasoning</category><category>Discrete Space Reasoning</category><category>LLM Confidence</category><category>Routing Mechanism</category><category>Inference-Time Optimization</category><category>Chain-of-Thought</category>
    </item>
    <item>
      <title>[논문리뷰] Thinking with Drafting: Optical Decompression via Logical Reconstruction</title>
      <description>이 [arXiv]에 게시한 &#39;Thinking with Drafting: Optical Decompression via Logical Reconstruction&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-13-Thinking-with-Drafting-Optical-Decompression-via-Logical-Reconstruction/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-13-Thinking-with-Drafting-Optical-Decompression-via-Logical-Reconstruction/</guid>
      <pubDate>Fri, 13 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Multimodal Reasoning</category><category>Visual Algebra</category><category>Domain-Specific Language</category><category>Optical Decompression</category><category>Logical Reconstruction</category><category>Bar Model</category><category>MLLMs</category><category>Verification</category>
    </item>
    <item>
      <title>[논문리뷰] Think Longer to Explore Deeper: Learn to Explore In-Context via Length-Incentivized Reinforcement Learning</title>
      <description>이 [arXiv]에 게시한 &#39;Think Longer to Explore Deeper: Learn to Explore In-Context via Length-Incentivized Reinforcement Learning&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-13-Think-Longer-to-Explore-Deeper-Learn-to-Explore-In-Context-via-Length-Incentivized-Reinforcement-Learning/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-13-Think-Longer-to-Explore-Deeper-Learn-to-Explore-In-Context-via-Length-Incentivized-Reinforcement-Learning/</guid>
      <pubDate>Fri, 13 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Large Language Models</category><category>In-Context Learning</category><category>Reinforcement Learning</category><category>Test-Time Scaling</category><category>Exploration-Exploitation</category><category>State Coverage</category><category>Reward Shaping</category><category>Chain-of-Thought</category>
    </item>
    <item>
      <title>[논문리뷰] The Devil Behind Moltbook: Anthropic Safety is Always Vanishing in Self-Evolving AI Societies</title>
      <description>Jinyu Hou이 [arXiv]에 게시한 &#39;The Devil Behind Moltbook: Anthropic Safety is Always Vanishing in Self-Evolving AI Societies&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-13-The-Devil-Behind-Moltbook-Anthropic-Safety-is-Always-Vanishing-in-Self-Evolving-AI-Societies/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-13-The-Devil-Behind-Moltbook-Anthropic-Safety-is-Always-Vanishing-in-Self-Evolving-AI-Societies/</guid>
      <pubDate>Fri, 13 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Multi-agent Systems</category><category>Self-evolution</category><category>AI Safety</category><category>Alignment Drift</category><category>Information Theory</category><category>Thermodynamics</category><category>Entropy Accumulation</category><category>Moltbook</category>
    </item>
    <item>
      <title>[논문리뷰] Stroke of Surprise: Progressive Semantic Illusions in Vector Sketching</title>
      <description>이 [arXiv]에 게시한 &#39;Stroke of Surprise: Progressive Semantic Illusions in Vector Sketching&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-13-Stroke-of-Surprise-Progressive-Semantic-Illusions-in-Vector-Sketching/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-13-Stroke-of-Surprise-Progressive-Semantic-Illusions-in-Vector-Sketching/</guid>
      <pubDate>Fri, 13 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Vector Sketching</category><category>Progressive Semantic Illusions</category><category>Score Distillation Sampling</category><category>Joint Optimization</category><category>Visual Anagrams</category><category>Bézier Strokes</category><category>CLIP-guided Generation</category><category>Diffusion Models</category>
    </item>
    <item>
      <title>[논문리뷰] Sparse Video Generation Propels Real-World Beyond-the-View Vision-Language Navigation</title>
      <description>Yukuan Xu이 [arXiv]에 게시한 &#39;Sparse Video Generation Propels Real-World Beyond-the-View Vision-Language Navigation&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-13-Sparse-Video-Generation-Propels-Real-World-Beyond-the-View-Vision-Language-Navigation/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-13-Sparse-Video-Generation-Propels-Real-World-Beyond-the-View-Vision-Language-Navigation/</guid>
      <pubDate>Fri, 13 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Vision-Language Navigation</category><category>Beyond-the-View Navigation</category><category>Video Generation Models</category><category>Sparse Video Generation</category><category>Diffusion Models</category><category>Embodied AI</category><category>Real-world Navigation</category><category>Long-horizon Planning</category>
    </item>
    <item>
      <title>[논문리뷰] Sci-CoE: Co-evolving Scientific Reasoning LLMs via Geometric Consensus with Sparse Supervision</title>
      <description>이 [arXiv]에 게시한 &#39;Sci-CoE: Co-evolving Scientific Reasoning LLMs via Geometric Consensus with Sparse Supervision&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-13-Sci-CoE-Co-evolving-Scientific-Reasoning-LLMs-via-Geometric-Consensus-with-Sparse-Supervision/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-13-Sci-CoE-Co-evolving-Scientific-Reasoning-LLMs-via-Geometric-Consensus-with-Sparse-Supervision/</guid>
      <pubDate>Fri, 13 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>LLM</category><category>Scientific Reasoning</category><category>Co-evolution</category><category>Reinforcement Learning</category><category>Sparse Supervision</category><category>Geometric Consensus</category><category>Self-Play</category><category>Verifier</category>
    </item>
    <item>
      <title>[논문리뷰] ScalSelect: Scalable Training-Free Multimodal Data Selection for Efficient Visual Instruction Tuning</title>
      <description>이 [arXiv]에 게시한 &#39;ScalSelect: Scalable Training-Free Multimodal Data Selection for Efficient Visual Instruction Tuning&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-13-ScalSelect-Scalable-Training-Free-Multimodal-Data-Selection-for-Efficient-Visual-Instruction-Tuning/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-13-ScalSelect-Scalable-Training-Free-Multimodal-Data-Selection-for-Efficient-Visual-Instruction-Tuning/</guid>
      <pubDate>Fri, 13 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Multimodal Data Selection</category><category>Visual Instruction Tuning</category><category>Training-Free</category><category>Scalability</category><category>Subspace Learning</category><category>Vision-Language Models</category><category>Attention Mechanism</category>
    </item>
    <item>
      <title>[논문리뷰] RISE: Self-Improving Robot Policy with Compositional World Model</title>
      <description>이 [arXiv]에 게시한 &#39;RISE: Self-Improving Robot Policy with Compositional World Model&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-13-RISE-Self-Improving-Robot-Policy-with-Compositional-World-Model/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-13-RISE-Self-Improving-Robot-Policy-with-Compositional-World-Model/</guid>
      <pubDate>Fri, 13 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Robot Learning</category><category>Reinforcement Learning</category><category>World Models</category><category>Compositional Models</category><category>Robotic Manipulation</category><category>Self-Improving</category><category>Vision-Language-Action (VLA)</category>
    </item>
    <item>
      <title>[논문리뷰] Pretraining A Large Language Model using Distributed GPUs: A Memory-Efficient Decentralized Paradigm</title>
      <description>이 [arXiv]에 게시한 &#39;Pretraining A Large Language Model using Distributed GPUs: A Memory-Efficient Decentralized Paradigm&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-13-Pretraining-A-Large-Language-Model-using-Distributed-GPUs-A-Memory-Efficient-Decentralized-Paradigm/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-13-Pretraining-A-Large-Language-Model-using-Distributed-GPUs-A-Memory-Efficient-Decentralized-Paradigm/</guid>
      <pubDate>Fri, 13 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Decentralized Training</category><category>Mixture-of-Experts (MoE)</category><category>Large Language Models (LLMs)</category><category>Memory Efficiency</category><category>Sparse Expert Synchronization</category><category>Federated Learning</category><category>Distributed GPUs</category>
    </item>
    <item>
      <title>[논문리뷰] NarraScore: Bridging Visual Narrative and Musical Dynamics via Hierarchical Affective Control</title>
      <description>이 [arXiv]에 게시한 &#39;NarraScore: Bridging Visual Narrative and Musical Dynamics via Hierarchical Affective Control&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-13-NarraScore-Bridging-Visual-Narrative-and-Musical-Dynamics-via-Hierarchical-Affective-Control/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-13-NarraScore-Bridging-Visual-Narrative-and-Musical-Dynamics-via-Hierarchical-Affective-Control/</guid>
      <pubDate>Fri, 13 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Video-to-Music Generation</category><category>Affective Computing</category><category>Vision-Language Models (VLMs)</category><category>Hierarchical Control</category><category>Soundtrack Generation</category><category>Temporal Coherence</category><category>Emotion-Driven Music</category>
    </item>
    <item>
      <title>[논문리뷰] MOSS-Audio-Tokenizer: Scaling Audio Tokenizers for Future Audio Foundation Models</title>
      <description>이 [arXiv]에 게시한 &#39;MOSS-Audio-Tokenizer: Scaling Audio Tokenizers for Future Audio Foundation Models&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-13-MOSS-Audio-Tokenizer-Scaling-Audio-Tokenizers-for-Future-Audio-Foundation-Models/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-13-MOSS-Audio-Tokenizer-Scaling-Audio-Tokenizers-for-Future-Audio-Foundation-Models/</guid>
      <pubDate>Fri, 13 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Audio Tokenizer</category><category>Transformer Architecture</category><category>End-to-End Learning</category><category>Residual Vector Quantization</category><category>Speech Synthesis</category><category>Audio Foundation Models</category><category>Scalability</category><category>Autoregressive Models</category>
    </item>
    <item>
      <title>[논문리뷰] MetaphorStar: Image Metaphor Understanding and Reasoning with End-to-End Visual Reinforcement Learning</title>
      <description>Hongsheng Li이 [arXiv]에 게시한 &#39;MetaphorStar: Image Metaphor Understanding and Reasoning with End-to-End Visual Reinforcement Learning&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-13-MetaphorStar-Image-Metaphor-Understanding-and-Reasoning-with-End-to-End-Visual-Reinforcement-Learning/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-13-MetaphorStar-Image-Metaphor-Understanding-and-Reasoning-with-End-to-End-Visual-Reinforcement-Learning/</guid>
      <pubDate>Fri, 13 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Image Metaphor Understanding</category><category>Visual Reasoning</category><category>Reinforcement Learning</category><category>MLLMs</category><category>TFQ-GRPO</category><category>End-to-End Learning</category><category>Cognitive AI</category>
    </item>
    <item>
      <title>[논문리뷰] Learning beyond Teacher: Generalized On-Policy Distillation with Reward Extrapolation</title>
      <description>이 [arXiv]에 게시한 &#39;Learning beyond Teacher: Generalized On-Policy Distillation with Reward Extrapolation&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-13-Learning-beyond-Teacher-Generalized-On-Policy-Distillation-with-Reward-Extrapolation/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-13-Learning-beyond-Teacher-Generalized-On-Policy-Distillation-with-Reward-Extrapolation/</guid>
      <pubDate>Fri, 13 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>On-Policy Distillation</category><category>Reward Extrapolation</category><category>Large Language Models (LLMs)</category><category>Knowledge Distillation</category><category>Reinforcement Learning</category><category>Math Reasoning</category><category>Code Generation</category><category>Multi-teacher Distillation</category>
    </item>
    <item>
      <title>[논문리뷰] LawThinker: A Deep Research Legal Agent in Dynamic Environments</title>
      <description>이 [arXiv]에 게시한 &#39;LawThinker: A Deep Research Legal Agent in Dynamic Environments&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-13-LawThinker-A-Deep-Research-Legal-Agent-in-Dynamic-Environments/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-13-LawThinker-A-Deep-Research-Legal-Agent-in-Dynamic-Environments/</guid>
      <pubDate>Fri, 13 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Legal Reasoning</category><category>AI Agent</category><category>Large Language Models</category><category>Verification</category><category>Knowledge Management</category><category>Dynamic Environments</category><category>Procedural Compliance</category><category>Tool Use</category>
    </item>
    <item>
      <title>[논문리뷰] GigaBrain-0.5M*: a VLA That Learns From World Model-Based Reinforcement Learning</title>
      <description>이 [arXiv]에 게시한 &#39;GigaBrain-0.5M*: a VLA That Learns From World Model-Based Reinforcement Learning&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-13-GigaBrain-0-5M-a-VLA-That-Learns-From-World-Model-Based-Reinforcement-Learning/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-13-GigaBrain-0-5M-a-VLA-That-Learns-From-World-Model-Based-Reinforcement-Learning/</guid>
      <pubDate>Fri, 13 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>VLA Models</category><category>World Models</category><category>Reinforcement Learning</category><category>Robotic Manipulation</category><category>Long-Horizon Control</category><category>Human-in-the-Loop</category><category>Continual Learning</category>
    </item>
    <item>
      <title>[논문리뷰] EgoHumanoid: Unlocking In-the-Wild Loco-Manipulation with Robot-Free Egocentric Demonstration</title>
      <description>Yinghui Li이 [arXiv]에 게시한 &#39;EgoHumanoid: Unlocking In-the-Wild Loco-Manipulation with Robot-Free Egocentric Demonstration&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-13-EgoHumanoid-Unlocking-In-the-Wild-Loco-Manipulation-with-Robot-Free-Egocentric-Demonstration/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-13-EgoHumanoid-Unlocking-In-the-Wild-Loco-Manipulation-with-Robot-Free-Egocentric-Demonstration/</guid>
      <pubDate>Fri, 13 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Humanoid Robotics</category><category>Loco-Manipulation</category><category>Egocentric Demonstration</category><category>Robot-Free Learning</category><category>Cross-Embodiment Transfer</category><category>View Alignment</category><category>Action Alignment</category><category>VLA Co-training</category>
    </item>
    <item>
      <title>[논문리뷰] dVoting: Fast Voting for dLLMs</title>
      <description>이 [arXiv]에 게시한 &#39;dVoting: Fast Voting for dLLMs&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-02-13-dVoting-Fast-Voting-for-dLLMs/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-02-13-dVoting-Fast-Voting-for-dLLMs/</guid>
      <pubDate>Fri, 13 Feb 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>dLLMs</category><category>Diffusion Models</category><category>Test-Time Scaling</category><category>Voting</category><category>Reasoning</category><category>Masked Language Models</category><category>Parallel Decoding</category><category>Remasking</category>
    </item>
    
  </channel>
</rss>