<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>secrett2633's blog</title>
    <description>기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트</description>
    <link>https://blog.secrett2633.cloud</link>
    <atom:link href="https://blog.secrett2633.cloud/api/feed" rel="self" type="application/rss+xml" />
    <language>ko-KR</language>
    <lastBuildDate>Mon, 12 Jan 2026 23:41:32 GMT</lastBuildDate>
    <pubDate>Mon, 12 Jan 2026 23:41:32 GMT</pubDate>
    <ttl>60</ttl>
    <generator>Next.js RSS Generator</generator>
    <managingEditor>secrett2633@example.com (secrett2633)</managingEditor>
    <webMaster>secrett2633@example.com (secrett2633)</webMaster>
    <category>Technology</category>
    <category>Programming</category>
    <category>Django</category>
    <category>Python</category>
    <category>DevOps</category>
    <category>AI/ML</category>
    
        <item>
      <title>[논문리뷰] VideoAR: Autoregressive Video Generation via Next-Frame &amp; Scale Prediction</title>
      <description>Yu Sun이 [arXiv]에 게시한 &#39;VideoAR: Autoregressive Video Generation via Next-Frame &amp; Scale Prediction&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-12-VideoAR-Autoregressive-Video-Generation-via-Next-Frame-Scale-Prediction/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-12-VideoAR-Autoregressive-Video-Generation-via-Next-Frame-Scale-Prediction/</guid>
      <pubDate>Mon, 12 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Video Generation</category><category>Autoregressive Models</category><category>Next-Frame Prediction</category><category>Multi-scale Prediction</category><category>Temporal Consistency</category><category>Visual Autoregressive</category><category>Error Propagation</category>
    </item>
    <item>
      <title>[논문리뷰] Thinking with Map: Reinforced Parallel Map-Augmented Agent for Geolocalization</title>
      <description>이 [arXiv]에 게시한 &#39;Thinking with Map: Reinforced Parallel Map-Augmented Agent for Geolocalization&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-12-Thinking-with-Map-Reinforced-Parallel-Map-Augmented-Agent-for-Geolocalization/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-12-Thinking-with-Map-Reinforced-Parallel-Map-Augmented-Agent-for-Geolocalization/</guid>
      <pubDate>Mon, 12 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Geolocalization</category><category>LVLM</category><category>Map-Augmented Agent</category><category>Reinforcement Learning</category><category>Parallel Test-Time Scaling</category><category>Tool Use</category><category>MAPBench</category>
    </item>
    <item>
      <title>[논문리뷰] SmartSearch: Process Reward-Guided Query Refinement for Search Agents</title>
      <description>Guanting Dong이 [arXiv]에 게시한 &#39;SmartSearch: Process Reward-Guided Query Refinement for Search Agents&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-12-SmartSearch-Process-Reward-Guided-Query-Refinement-for-Search-Agents/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-12-SmartSearch-Process-Reward-Guided-Query-Refinement-for-Search-Agents/</guid>
      <pubDate>Mon, 12 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Search Agent</category><category>Information Retrieval</category><category>Large Language Models</category><category>Process Reward</category><category>Query Refinement</category><category>Reinforcement Learning</category><category>Curriculum Learning</category>
    </item>
    <item>
      <title>[논문리뷰] Qwen3-VL-Embedding and Qwen3-VL-Reranker: A Unified Framework for State-of-the-Art Multimodal Retrieval and Ranking</title>
      <description>이 [arXiv]에 게시한 &#39;Qwen3-VL-Embedding and Qwen3-VL-Reranker: A Unified Framework for State-of-the-Art Multimodal Retrieval and Ranking&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-12-Qwen3-VL-Embedding-and-Qwen3-VL-Reranker-A-Unified-Framework-for-State-of-the-Art-Multimodal-Retrieval-and-Ranking/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-12-Qwen3-VL-Embedding-and-Qwen3-VL-Reranker-A-Unified-Framework-for-State-of-the-Art-Multimodal-Retrieval-and-Ranking/</guid>
      <pubDate>Mon, 12 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Multimodal Retrieval</category><category>Multimodal Ranking</category><category>Foundation Models</category><category>Embedding Models</category><category>Reranking Models</category><category>Contrastive Learning</category><category>Knowledge Distillation</category><category>Matryoshka Representation Learning</category><category>Quantization-Aware Training</category>
    </item>
    <item>
      <title>[논문리뷰] Memory Matters More: Event-Centric Memory as a Logic Map for Agent Searching and Reasoning</title>
      <description>Zhicheng Dou이 [arXiv]에 게시한 &#39;Memory Matters More: Event-Centric Memory as a Logic Map for Agent Searching and Reasoning&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-12-Memory-Matters-More-Event-Centric-Memory-as-a-Logic-Map-for-Agent-Searching-and-Reasoning/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-12-Memory-Matters-More-Event-Centric-Memory-as-a-Logic-Map-for-Agent-Searching-and-Reasoning/</guid>
      <pubDate>Mon, 12 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>LLM Agents</category><category>Agent Memory</category><category>Event Graph</category><category>Long-term Reasoning</category><category>Knowledge Graph</category><category>Active Retrieval</category><category>Event Segmentation</category><category>Multi-hop QA</category>
    </item>
    <item>
      <title>[논문리뷰] Goal Force: Teaching Video Models To Accomplish Physics-Conditioned Goals</title>
      <description>Arjan Chakravarthy이 [arXiv]에 게시한 &#39;Goal Force: Teaching Video Models To Accomplish Physics-Conditioned Goals&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-12-Goal-Force-Teaching-Video-Models-To-Accomplish-Physics-Conditioned-Goals/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-12-Goal-Force-Teaching-Video-Models-To-Accomplish-Physics-Conditioned-Goals/</guid>
      <pubDate>Mon, 12 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Video Generation</category><category>World Models</category><category>Physics-Conditioned Goals</category><category>Causal Planning</category><category>Force Vectors</category><category>Zero-Shot Generalization</category><category>Diffusion Models</category><category>Robotics Planning</category>
    </item>
    <item>
      <title>[논문리뷰] GenCtrl -- A Formal Controllability Toolkit for Generative Models</title>
      <description>이 [arXiv]에 게시한 &#39;GenCtrl -- A Formal Controllability Toolkit for Generative Models&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-12-GenCtrl-A-Formal-Controllability-Toolkit-for-Generative-Models/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-12-GenCtrl-A-Formal-Controllability-Toolkit-for-Generative-Models/</guid>
      <pubDate>Mon, 12 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Generative Models</category><category>Controllability</category><category>Reachability</category><category>Control Theory</category><category>Dialogue Systems</category><category>LLMs</category><category>T2IMs</category><category>PAC Bounds</category><category>Formal Verification</category>
    </item>
    <item>
      <title>[논문리뷰] Distilling Feedback into Memory-as-a-Tool</title>
      <description>vicgalle이 [arXiv]에 게시한 &#39;Distilling Feedback into Memory-as-a-Tool&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-12-Distilling-Feedback-into-Memory-as-a-Tool/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-12-Distilling-Feedback-into-Memory-as-a-Tool/</guid>
      <pubDate>Mon, 12 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>LLM</category><category>Continual Learning</category><category>Memory-Augmented Agents</category><category>Self-Correction</category><category>Feedback Distillation</category><category>Tool Use</category><category>Inference Cost Amortization</category><category>Rubric-based Learning</category>
    </item>
    <item>
      <title>[논문리뷰] CaricatureGS: Exaggerating 3D Gaussian Splatting Faces With Gaussian Curvature</title>
      <description>이 [arXiv]에 게시한 &#39;CaricatureGS: Exaggerating 3D Gaussian Splatting Faces With Gaussian Curvature&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-12-CaricatureGS-Exaggerating-3D-Gaussian-Splatting-Faces-With-Gaussian-Curvature/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-12-CaricatureGS-Exaggerating-3D-Gaussian-Splatting-Faces-With-Gaussian-Curvature/</guid>
      <pubDate>Mon, 12 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>3D Gaussian Splatting</category><category>Facial Caricaturization</category><category>Gaussian Curvature</category><category>Mesh Deformation</category><category>Photorealistic Rendering</category><category>Human Avatars</category><category>Local Affine Transformations</category>
    </item>
    <item>
      <title>[논문리뷰] VideoAuto-R1: Video Auto Reasoning via Thinking Once, Answering Twice</title>
      <description>이 [arXiv]에 게시한 &#39;VideoAuto-R1: Video Auto Reasoning via Thinking Once, Answering Twice&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-09-VideoAuto-R1-Video-Auto-Reasoning-via-Thinking-Once-Answering-Twice/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-09-VideoAuto-R1-Video-Auto-Reasoning-via-Thinking-Once-Answering-Twice/</guid>
      <pubDate>Fri, 09 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Video Understanding</category><category>Chain-of-Thought (CoT)</category><category>Reinforcement Learning (RL)</category><category>Adaptive Reasoning</category><category>Early Exit</category><category>Multimodal LLM</category><category>Video QA</category><category>Temporal Grounding</category>
    </item>
    <item>
      <title>[논문리뷰] VerseCrafter: Dynamic Realistic Video World Model with 4D Geometric Control</title>
      <description>Ying Shan이 [arXiv]에 게시한 &#39;VerseCrafter: Dynamic Realistic Video World Model with 4D Geometric Control&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-09-VerseCrafter-Dynamic-Realistic-Video-World-Model-with-4D-Geometric-Control/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-09-VerseCrafter-Dynamic-Realistic-Video-World-Model-with-4D-Geometric-Control/</guid>
      <pubDate>Fri, 09 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Video World Model</category><category>4D Geometric Control</category><category>Gaussian Trajectories</category><category>Video Generation</category><category>Diffusion Models</category><category>Camera Control</category><category>Object Motion Control</category><category>Data Engine</category>
    </item>
    <item>
      <title>[논문리뷰] Towards Open-Vocabulary Industrial Defect Understanding with a Large-Scale Multimodal Dataset</title>
      <description>YuanFu Yang이 [arXiv]에 게시한 &#39;Towards Open-Vocabulary Industrial Defect Understanding with a Large-Scale Multimodal Dataset&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-09-Towards-Open-Vocabulary-Industrial-Defect-Understanding-with-a-Large-Scale-Multimodal-Dataset/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-09-Towards-Open-Vocabulary-Industrial-Defect-Understanding-with-a-Large-Scale-Multimodal-Dataset/</guid>
      <pubDate>Fri, 09 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Industrial Defect Detection</category><category>Multimodal Dataset</category><category>Vision-Language Model</category><category>Diffusion Model</category><category>Open-Vocabulary Learning</category><category>Quality Inspection</category><category>Data Efficiency</category><category>Foundation Model</category>
    </item>
    <item>
      <title>[논문리뷰] Token-Level LLM Collaboration via FusionRoute</title>
      <description>Furong Huang이 [arXiv]에 게시한 &#39;Token-Level LLM Collaboration via FusionRoute&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-09-Token-Level-LLM-Collaboration-via-FusionRoute/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-09-Token-Level-LLM-Collaboration-via-FusionRoute/</guid>
      <pubDate>Fri, 09 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>LLM Collaboration</category><category>Token-level Routing</category><category>Mixture-of-Experts</category><category>Complementary Logits</category><category>Preference Optimization</category><category>FusionRoute</category><category>Domain Adaptation</category>
    </item>
    <item>
      <title>[논문리뷰] The Illusion of Specialization: Unveiling the Domain-Invariant &#39;Standing Committee&#39; in Mixture-of-Experts Models</title>
      <description>이 [arXiv]에 게시한 &#39;The Illusion of Specialization: Unveiling the Domain-Invariant &#39;Standing Committee&#39; in Mixture-of-Experts Models&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-09-The-Illusion-of-Specialization-Unveiling-the-Domain-Invariant-Standing-Committee-in-Mixture-of-Experts-Models/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-09-The-Illusion-of-Specialization-Unveiling-the-Domain-Invariant-Standing-Committee-in-Mixture-of-Experts-Models/</guid>
      <pubDate>Fri, 09 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Mixture-of-Experts (MoE)</category><category>Sparse Routing</category><category>Domain Specialization</category><category>Load Balancing</category><category>Interpretability</category><category>Standing Committee</category><category>LLM</category>
    </item>
    <item>
      <title>[논문리뷰] RoboVIP: Multi-View Video Generation with Visual Identity Prompting Augments Robot Manipulation</title>
      <description>Mingda Jia이 [arXiv]에 게시한 &#39;RoboVIP: Multi-View Video Generation with Visual Identity Prompting Augments Robot Manipulation&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-09-RoboVIP-Multi-View-Video-Generation-with-Visual-Identity-Prompting-Augments-Robot-Manipulation/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-09-RoboVIP-Multi-View-Video-Generation-with-Visual-Identity-Prompting-Augments-Robot-Manipulation/</guid>
      <pubDate>Fri, 09 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Robot Manipulation</category><category>Data Augmentation</category><category>Video Generation</category><category>Diffusion Models</category><category>Multi-View</category><category>Visual Identity Prompting</category><category>Action-Guided Segmentation</category><category>Visuomotor Policy</category>
    </item>
    <item>
      <title>[논문리뷰] RL-AWB: Deep Reinforcement Learning for Auto White Balance Correction in Low-Light Night-time Scenes</title>
      <description>Yu-Lun Liu이 [arXiv]에 게시한 &#39;RL-AWB: Deep Reinforcement Learning for Auto White Balance Correction in Low-Light Night-time Scenes&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-09-RL-AWB-Deep-Reinforcement-Learning-for-Auto-White-Balance-Correction-in-Low-Light-Night-time-Scenes/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-09-RL-AWB-Deep-Reinforcement-Learning-for-Auto-White-Balance-Correction-in-Low-Light-Night-time-Scenes/</guid>
      <pubDate>Fri, 09 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Auto White Balance (AWB)</category><category>Deep Reinforcement Learning (DRL)</category><category>Low-Light Imaging</category><category>Night-time Scenes</category><category>Color Constancy</category><category>Cross-Sensor Generalization</category><category>Statistical Methods</category><category>Curriculum Learning</category>
    </item>
    <item>
      <title>[논문리뷰] RelayLLM: Efficient Reasoning via Collaborative Decoding</title>
      <description>Haolin Liu이 [arXiv]에 게시한 &#39;RelayLLM: Efficient Reasoning via Collaborative Decoding&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-09-RelayLLM-Efficient-Reasoning-via-Collaborative-Decoding/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-09-RelayLLM-Efficient-Reasoning-via-Collaborative-Decoding/</guid>
      <pubDate>Fri, 09 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>LLM</category><category>SLM</category><category>Collaborative Decoding</category><category>Token-level Intervention</category><category>Reinforcement Learning</category><category>GRPO</category><category>Efficient Reasoning</category><category>Resource Efficiency</category>
    </item>
    <item>
      <title>[논문리뷰] Re-Align: Structured Reasoning-guided Alignment for In-Context Image Generation and Editing</title>
      <description>Yu Xu이 [arXiv]에 게시한 &#39;Re-Align: Structured Reasoning-guided Alignment for In-Context Image Generation and Editing&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-09-Re-Align-Structured-Reasoning-guided-Alignment-for-In-Context-Image-Generation-and-Editing/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-09-Re-Align-Structured-Reasoning-guided-Alignment-for-In-Context-Image-Generation-and-Editing/</guid>
      <pubDate>Fri, 09 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>In-Context Image Generation</category><category>Image Editing</category><category>Multimodal Models</category><category>Chain-of-Thought</category><category>Structured Reasoning</category><category>Reinforcement Learning</category><category>Alignment</category><category>Diffusion Models</category>
    </item>
    <item>
      <title>[논문리뷰] Plenoptic Video Generation</title>
      <description>이 [arXiv]에 게시한 &#39;Plenoptic Video Generation&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-09-Plenoptic-Video-Generation/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-09-Plenoptic-Video-Generation/</guid>
      <pubDate>Fri, 09 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Generative Video</category><category>Camera Control</category><category>Plenoptic Function</category><category>Autoregressive Model</category><category>Diffusion Transformer</category><category>3D FOV Retrieval</category><category>Spatio-Temporal Consistency</category>
    </item>
    <item>
      <title>[논문리뷰] Memorization in 3D Shape Generation: An Empirical Study</title>
      <description>이 [arXiv]에 게시한 &#39;Memorization in 3D Shape Generation: An Empirical Study&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-09-Memorization-in-3D-Shape-Generation-An-Empirical-Study/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-09-Memorization-in-3D-Shape-Generation-An-Empirical-Study/</guid>
      <pubDate>Fri, 09 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>3D Shape Generation</category><category>Memorization</category><category>Generative Models</category><category>Diffusion Models</category><category>Evaluation Framework</category><category>Generalization</category><category>Data Augmentation</category>
    </item>
    
  </channel>
</rss>