<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>secrett2633's blog</title>
    <description>기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트</description>
    <link>https://blog.secrett2633.site</link>
    <atom:link href="https://blog.secrett2633.site/api/feed" rel="self" type="application/rss+xml" />
    <language>ko-KR</language>
    <lastBuildDate>Mon, 08 Dec 2025 15:45:23 GMT</lastBuildDate>
    <pubDate>Mon, 08 Dec 2025 15:45:23 GMT</pubDate>
    <ttl>60</ttl>
    <generator>Next.js RSS Generator</generator>
    <managingEditor>secrett2633@example.com (secrett2633)</managingEditor>
    <webMaster>secrett2633@example.com (secrett2633)</webMaster>
    <category>Technology</category>
    <category>Programming</category>
    <category>Django</category>
    <category>Python</category>
    <category>DevOps</category>
    <category>AI/ML</category>
    
        <item>
      <title>[논문리뷰] UltraImage: Rethinking Resolution Extrapolation in Image Diffusion Transformers</title>
      <description>이 [arXiv]에 게시한 &#39;UltraImage: Rethinking Resolution Extrapolation in Image Diffusion Transformers&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-UltraImage-Rethinking-Resolution-Extrapolation-in-Image-Diffusion-Transformers/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-UltraImage-Rethinking-Resolution-Extrapolation-in-Image-Diffusion-Transformers/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Diffusion Transformers</category><category>Resolution Extrapolation</category><category>Positional Encoding</category><category>Frequency Analysis</category><category>Adaptive Attention</category><category>High-Resolution Image Generation</category><category>Image Quality</category><category>Content Repetition</category>
    </item>
    <item>
      <title>[논문리뷰] TV2TV: A Unified Framework for Interleaved Language and Video Generation</title>
      <description>이 [arXiv]에 게시한 &#39;TV2TV: A Unified Framework for Interleaved Language and Video Generation&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-TV2TV-A-Unified-Framework-for-Interleaved-Language-and-Video-Generation/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-TV2TV-A-Unified-Framework-for-Interleaved-Language-and-Video-Generation/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Video Generation</category><category>Language Modeling</category><category>Multimodal AI</category><category>Interleaved Generation</category><category>Flow Matching</category><category>Transformer</category><category>Controllability</category><category>World Models</category>
    </item>
    <item>
      <title>[논문리뷰] Splannequin: Freezing Monocular Mannequin-Challenge Footage with Dual-Detection Splatting</title>
      <description>Yu-Lun Liu이 [arXiv]에 게시한 &#39;Splannequin: Freezing Monocular Mannequin-Challenge Footage with Dual-Detection Splatting&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-Splannequin-Freezing-Monocular-Mannequin-Challenge-Footage-with-Dual-Detection-Splatting/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-Splannequin-Freezing-Monocular-Mannequin-Challenge-Footage-with-Dual-Detection-Splatting/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Monocular 3D Reconstruction</category><category>Mannequin Challenge</category><category>Dynamic Gaussian Splatting</category><category>Freeze-Time Video</category><category>Temporal Consistency</category><category>Artifact Suppression</category><category>Regularization</category>
    </item>
    <item>
      <title>[논문리뷰] SignRoundV2: Closing the Performance Gap in Extremely Low-Bit Post-Training Quantization for LLMs</title>
      <description>이 [arXiv]에 게시한 &#39;SignRoundV2: Closing the Performance Gap in Extremely Low-Bit Post-Training Quantization for LLMs&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-SignRoundV2-Closing-the-Performance-Gap-in-Extremely-Low-Bit-Post-Training-Quantization-for-LLMs/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-SignRoundV2-Closing-the-Performance-Gap-in-Extremely-Low-Bit-Post-Training-Quantization-for-LLMs/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Post-Training Quantization (PTQ)</category><category>Large Language Models (LLMs)</category><category>Low-Bit Quantization</category><category>Mixed-Precision Quantization</category><category>Sensitivity Metric</category><category>Quantization Scale Initialization</category><category>Accuracy Preservation</category>
    </item>
    <item>
      <title>[논문리뷰] Semantics Lead the Way: Harmonizing Semantic and Texture Modeling with Asynchronous Latent Diffusion</title>
      <description>이 [arXiv]에 게시한 &#39;Semantics Lead the Way: Harmonizing Semantic and Texture Modeling with Asynchronous Latent Diffusion&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-Semantics-Lead-the-Way-Harmonizing-Semantic-and-Texture-Modeling-with-Asynchronous-Latent-Diffusion/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-Semantics-Lead-the-Way-Harmonizing-Semantic-and-Texture-Modeling-with-Asynchronous-Latent-Diffusion/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Latent Diffusion Models</category><category>Asynchronous Denoising</category><category>Semantic Modeling</category><category>Texture Modeling</category><category>Image Generation</category><category>Vision Transformer</category><category>VAE</category><category>Fast Convergence</category>
    </item>
    <item>
      <title>[논문리뷰] SeeNav-Agent: Enhancing Vision-Language Navigation with Visual Prompt and Step-Level Policy Optimization</title>
      <description>이 [arXiv]에 게시한 &#39;SeeNav-Agent: Enhancing Vision-Language Navigation with Visual Prompt and Step-Level Policy Optimization&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-SeeNav-Agent-Enhancing-Vision-Language-Navigation-with-Visual-Prompt-and-Step-Level-Policy-Optimization/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-SeeNav-Agent-Enhancing-Vision-Language-Navigation-with-Visual-Prompt-and-Step-Level-Policy-Optimization/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Vision-Language Navigation</category><category>Large Vision-Language Models</category><category>Visual Prompt</category><category>Reinforcement Fine-Tuning</category><category>Policy Optimization</category><category>Embodied AI</category><category>Spatial Reasoning</category><category>Perception Errors</category>
    </item>
    <item>
      <title>[논문리뷰] SIMA 2: A Generalist Embodied Agent for Virtual Worlds</title>
      <description>이 [arXiv]에 게시한 &#39;SIMA 2: A Generalist Embodied Agent for Virtual Worlds&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-SIMA-2-A-Generalist-Embodied-Agent-for-Virtual-Worlds/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-SIMA-2-A-Generalist-Embodied-Agent-for-Virtual-Worlds/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Embodied AI</category><category>Generalist Agent</category><category>Virtual Worlds</category><category>Foundation Models</category><category>Gemini</category><category>Self-Improvement</category><category>Dialogue</category><category>Reasoning</category><category>Reinforcement Learning</category>
    </item>
    <item>
      <title>[논문리뷰] Reward Forcing: Efficient Streaming Video Generation with Rewarded Distribution Matching Distillation</title>
      <description>Hao Ouyang이 [arXiv]에 게시한 &#39;Reward Forcing: Efficient Streaming Video Generation with Rewarded Distribution Matching Distillation&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-Reward-Forcing-Efficient-Streaming-Video-Generation-with-Rewarded-Distribution-Matching-Distillation/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-Reward-Forcing-Efficient-Streaming-Video-Generation-with-Rewarded-Distribution-Matching-Distillation/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Streaming Video Generation</category><category>Video Diffusion Models</category><category>Distribution Matching Distillation</category><category>Reinforcement Learning</category><category>Autoregressive Models</category><category>Attention Sink</category><category>Real-time</category>
    </item>
    <item>
      <title>[논문리뷰] REFLEX: Self-Refining Explainable Fact-Checking via Disentangling Truth into Style and Substance</title>
      <description>Yaxin Fan이 [arXiv]에 게시한 &#39;REFLEX: Self-Refining Explainable Fact-Checking via Disentangling Truth into Style and Substance&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-REFLEX-Self-Refining-Explainable-Fact-Checking-via-Disentangling-Truth-into-Style-and-Substance/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-REFLEX-Self-Refining-Explainable-Fact-Checking-via-Disentangling-Truth-into-Style-and-Substance/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Fact-Checking</category><category>Explainable AI (XAI)</category><category>Large Language Models (LLMs)</category><category>Self-Refinement</category><category>Latent Space</category><category>Disentanglement</category><category>Steering Vectors</category><category>Misinformation</category>
    </item>
    <item>
      <title>[논문리뷰] QKAN-LSTM: Quantum-inspired Kolmogorov-Arnold Long Short-term Memory</title>
      <description>Nan-Yow Chen이 [arXiv]에 게시한 &#39;QKAN-LSTM: Quantum-inspired Kolmogorov-Arnold Long Short-term Memory&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-QKAN-LSTM-Quantum-inspired-Kolmogorov-Arnold-Long-Short-term-Memory/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-QKAN-LSTM-Quantum-inspired-Kolmogorov-Arnold-Long-Short-term-Memory/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Quantum Machine Learning</category><category>Kolmogorov-Arnold Networks</category><category>Long Short-Term Memory (LSTM)</category><category>Time Series Forecasting</category><category>Hybrid Quantum-Classical Learning</category><category>Quantum-inspired</category><category>Recurrent Neural Networks</category>
    </item>
    <item>
      <title>[논문리뷰] PaperDebugger: A Plugin-Based Multi-Agent System for In-Editor Academic Writing, Review, and Editing</title>
      <description>이 [arXiv]에 게시한 &#39;PaperDebugger: A Plugin-Based Multi-Agent System for In-Editor Academic Writing, Review, and Editing&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-PaperDebugger-A-Plugin-Based-Multi-Agent-System-for-In-Editor-Academic-Writing-Review-and-Editing/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-PaperDebugger-A-Plugin-Based-Multi-Agent-System-for-In-Editor-Academic-Writing-Review-and-Editing/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>LLM Agents</category><category>Academic Writing</category><category>In-editor Assistant</category><category>Multi-agent System</category><category>Overleaf Integration</category><category>Chrome Extension</category><category>Kubernetes</category><category>XtraMCP</category>
    </item>
    <item>
      <title>[논문리뷰] On GRPO Collapse in Search-R1: The Lazy Likelihood-Displacement Death Spiral</title>
      <description>Christos Thrampoulidis이 [arXiv]에 게시한 &#39;On GRPO Collapse in Search-R1: The Lazy Likelihood-Displacement Death Spiral&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-On-GRPO-Collapse-in-Search-R1-The-Lazy-Likelihood-Displacement-Death-Spiral/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-On-GRPO-Collapse-in-Search-R1-The-Lazy-Likelihood-Displacement-Death-Spiral/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Reinforcement Learning (RL)</category><category>Large Language Models (LLMs)</category><category>Tool-Integrated Reasoning (TIR)</category><category>GRPO</category><category>Training Stability</category><category>Lazy Likelihood Displacement (LLD)</category><category>Regularization</category><category>Search-R1</category>
    </item>
    <item>
      <title>[논문리뷰] Nex-N1: Agentic Models Trained via a Unified Ecosystem for Large-Scale Environment Construction</title>
      <description>이 [arXiv]에 게시한 &#39;Nex-N1: Agentic Models Trained via a Unified Ecosystem for Large-Scale Environment Construction&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-Nex-N1-Agentic-Models-Trained-via-a-Unified-Ecosystem-for-Large-Scale-Environment-Construction/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-Nex-N1-Agentic-Models-Trained-via-a-Unified-Ecosystem-for-Large-Scale-Environment-Construction/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Agentic Models</category><category>Large Language Models (LLMs)</category><category>Agentic Scaling</category><category>Environment Construction</category><category>NexAU</category><category>NexA4A</category><category>NexGAP</category><category>Interactive Environments</category>
    </item>
    <item>
      <title>[논문리뷰] NeuralRemaster: Phase-Preserving Diffusion for Structure-Aligned Generation</title>
      <description>Vitor Guizilini이 [arXiv]에 게시한 &#39;NeuralRemaster: Phase-Preserving Diffusion for Structure-Aligned Generation&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-NeuralRemaster-Phase-Preserving-Diffusion-for-Structure-Aligned-Generation/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-NeuralRemaster-Phase-Preserving-Diffusion-for-Structure-Aligned-Generation/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Diffusion Models</category><category>Phase Preservation</category><category>Frequency Domain</category><category>Structure-Aligned Generation</category><category>Image-to-Image Translation</category><category>Sim-to-Real</category><category>Generative AI</category>
    </item>
    <item>
      <title>[논문리뷰] Model-Based and Sample-Efficient AI-Assisted Math Discovery in Sphere Packing</title>
      <description>Jun Wang이 [arXiv]에 게시한 &#39;Model-Based and Sample-Efficient AI-Assisted Math Discovery in Sphere Packing&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-Model-Based-and-Sample-Efficient-AI-Assisted-Math-Discovery-in-Sphere-Packing/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-Model-Based-and-Sample-Efficient-AI-Assisted-Math-Discovery-in-Sphere-Packing/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Sphere Packing</category><category>Mathematical Discovery</category><category>Semidefinite Programming (SDP)</category><category>Bayesian Optimization (BO)</category><category>Monte Carlo Tree Search (MCTS)</category><category>Sample-Efficient AI</category><category>Model-Based Learning</category><category>Geometric Constraints</category>
    </item>
    <item>
      <title>[논문리뷰] Mitigating Object and Action Hallucinations in Multimodal LLMs via Self-Augmented Contrastive Alignment</title>
      <description>이 [arXiv]에 게시한 &#39;Mitigating Object and Action Hallucinations in Multimodal LLMs via Self-Augmented Contrastive Alignment&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-Mitigating-Object-and-Action-Hallucinations-in-Multimodal-LLMs-via-Self-Augmented-Contrastive-Alignment/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-Mitigating-Object-and-Action-Hallucinations-in-Multimodal-LLMs-via-Self-Augmented-Contrastive-Alignment/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Multimodal LLMs</category><category>Video Understanding</category><category>Hallucination Mitigation</category><category>Object Hallucination</category><category>Action Hallucination</category><category>Contrastive Learning</category><category>Self-Augmentation</category><category>Tracklet-Phrase Alignment</category>
    </item>
    <item>
      <title>[논문리뷰] Mitigating Catastrophic Forgetting in Target Language Adaptation of LLMs via Source-Shielded Updates</title>
      <description>Nikolaos Aletras이 [arXiv]에 게시한 &#39;Mitigating Catastrophic Forgetting in Target Language Adaptation of LLMs via Source-Shielded Updates&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-Mitigating-Catastrophic-Forgetting-in-Target-Language-Adaptation-of-LLMs-via-Source-Shielded-Updates/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-Mitigating-Catastrophic-Forgetting-in-Target-Language-Adaptation-of-LLMs-via-Source-Shielded-Updates/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Large Language Models (LLMs)</category><category>Catastrophic Forgetting</category><category>Language Adaptation</category><category>Continual Pre-training</category><category>Parameter Freezing</category><category>Low-Resource Languages</category><category>Source Knowledge Preservation</category>
    </item>
    <item>
      <title>[논문리뷰] Live Avatar: Streaming Real-time Audio-Driven Avatar Generation with Infinite Length</title>
      <description>Shifeng Zhang이 [arXiv]에 게시한 &#39;Live Avatar: Streaming Real-time Audio-Driven Avatar Generation with Infinite Length&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-Live-Avatar-Streaming-Real-time-Audio-Driven-Avatar-Generation-with-Infinite-Length/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-Live-Avatar-Streaming-Real-time-Audio-Driven-Avatar-Generation-with-Infinite-Length/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Audio-Driven Avatar Generation</category><category>Real-time Streaming</category><category>Diffusion Models</category><category>Infinite Length</category><category>Pipeline Parallelism</category><category>Temporal Consistency</category><category>Model Distillation</category>
    </item>
    <item>
      <title>[논문리뷰] LATTICE: Democratize High-Fidelity 3D Generation at Scale</title>
      <description>Qingxiang Lin이 [arXiv]에 게시한 &#39;LATTICE: Democratize High-Fidelity 3D Generation at Scale&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-LATTICE-Democratize-High-Fidelity-3D-Generation-at-Scale/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-LATTICE-Democratize-High-Fidelity-3D-Generation-at-Scale/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>3D Generation</category><category>High-Fidelity</category><category>Latent Representation</category><category>Voxel Grid</category><category>Diffusion Models</category><category>Transformer</category><category>Scalable AI</category><category>Asset Creation</category>
    </item>
    <item>
      <title>[논문리뷰] Generative Neural Video Compression via Video Diffusion Prior</title>
      <description>이 [arXiv]에 게시한 &#39;Generative Neural Video Compression via Video Diffusion Prior&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-Generative-Neural-Video-Compression-via-Video-Diffusion-Prior/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-Generative-Neural-Video-Compression-via-Video-Diffusion-Prior/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Neural Video Compression</category><category>Diffusion Models</category><category>Generative Models</category><category>Video Compression</category><category>Temporal Coherence</category><category>Perceptual Quality</category><category>Flow Matching</category><category>Video Diffusion Transformer (VideoDiT)</category>
    </item>
    
  </channel>
</rss>