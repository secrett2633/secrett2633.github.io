<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>secrett2633's blog</title>
    <description>기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트</description>
    <link>https://blog.secrett2633.site</link>
    <atom:link href="https://blog.secrett2633.site/api/feed" rel="self" type="application/rss+xml" />
    <language>ko-KR</language>
    <lastBuildDate>Thu, 11 Dec 2025 18:32:13 GMT</lastBuildDate>
    <pubDate>Thu, 11 Dec 2025 18:32:13 GMT</pubDate>
    <ttl>60</ttl>
    <generator>Next.js RSS Generator</generator>
    <managingEditor>secrett2633@example.com (secrett2633)</managingEditor>
    <webMaster>secrett2633@example.com (secrett2633)</webMaster>
    <category>Technology</category>
    <category>Programming</category>
    <category>Django</category>
    <category>Python</category>
    <category>DevOps</category>
    <category>AI/ML</category>
    
        <item>
      <title>[논문리뷰] Wan-Move: Motion-controllable Video Generation via Latent Trajectory Guidance</title>
      <description>이 [arXiv]에 게시한 &#39;Wan-Move: Motion-controllable Video Generation via Latent Trajectory Guidance&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-10-Wan-Move-Motion-controllable-Video-Generation-via-Latent-Trajectory-Guidance/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-10-Wan-Move-Motion-controllable-Video-Generation-via-Latent-Trajectory-Guidance/</guid>
      <pubDate>Wed, 10 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Video Generation</category><category>Motion Control</category><category>Latent Trajectory Guidance</category><category>Image-to-Video</category><category>Diffusion Models</category><category>Neural Networks</category><category>MoveBench</category>
    </item>
    <item>
      <title>[논문리뷰] Visionary: The World Model Carrier Built on WebGPU-Powered Gaussian Splatting Platform</title>
      <description>Muyao Niu이 [arXiv]에 게시한 &#39;Visionary: The World Model Carrier Built on WebGPU-Powered Gaussian Splatting Platform&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-10-Visionary-The-World-Model-Carrier-Built-on-WebGPU-Powered-Gaussian-Splatting-Platform/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-10-Visionary-The-World-Model-Carrier-Built-on-WebGPU-Powered-Gaussian-Splatting-Platform/</guid>
      <pubDate>Wed, 10 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Neural Rendering</category><category>3D Gaussian Splatting</category><category>WebGPU</category><category>ONNX Inference</category><category>World Models</category><category>Real-time Rendering</category><category>Browser-based</category><category>Dynamic Scenes</category>
    </item>
    <item>
      <title>[논문리뷰] TreeGRPO: Tree-Advantage GRPO for Online RL Post-Training of Diffusion Models</title>
      <description>Weirui Ye이 [arXiv]에 게시한 &#39;TreeGRPO: Tree-Advantage GRPO for Online RL Post-Training of Diffusion Models&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-10-TreeGRPO-Tree-Advantage-GRPO-for-Online-RL-Post-Training-of-Diffusion-Models/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-10-TreeGRPO-Tree-Advantage-GRPO-for-Online-RL-Post-Training-of-Diffusion-Models/</guid>
      <pubDate>Wed, 10 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Reinforcement Learning</category><category>Diffusion Models</category><category>Generative Models</category><category>Tree Search</category><category>Sample Efficiency</category><category>Credit Assignment</category><category>GRPO</category><category>Visual Generative Models</category>
    </item>
    <item>
      <title>[논문리뷰] TrackingWorld: World-centric Monocular 3D Tracking of Almost All Pixels</title>
      <description>Tianyu Huang이 [arXiv]에 게시한 &#39;TrackingWorld: World-centric Monocular 3D Tracking of Almost All Pixels&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-10-TrackingWorld-World-centric-Monocular-3D-Tracking-of-Almost-All-Pixels/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-10-TrackingWorld-World-centric-Monocular-3D-Tracking-of-Almost-All-Pixels/</guid>
      <pubDate>Wed, 10 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Monocular 3D Tracking</category><category>World-centric Coordinates</category><category>Dense Tracking</category><category>Camera Pose Estimation</category><category>Dynamic Object Tracking</category><category>Optimization</category><category>2D Track Upsampling</category>
    </item>
    <item>
      <title>[논문리뷰] ThreadWeaver: Adaptive Threading for Efficient Parallel Reasoning in Language Models</title>
      <description>Xiuyu Li이 [arXiv]에 게시한 &#39;ThreadWeaver: Adaptive Threading for Efficient Parallel Reasoning in Language Models&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-10-ThreadWeaver-Adaptive-Threading-for-Efficient-Parallel-Reasoning-in-Language-Models/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-10-ThreadWeaver-Adaptive-Threading-for-Efficient-Parallel-Reasoning-in-Language-Models/</guid>
      <pubDate>Wed, 10 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>LLM</category><category>Parallel Reasoning</category><category>Inference Latency</category><category>Chain-of-Thought</category><category>Reinforcement Learning</category><category>Adaptive Threading</category><category>Mathematical Reasoning</category><category>Speedup</category>
    </item>
    <item>
      <title>[논문리뷰] Same Content, Different Answers: Cross-Modal Inconsistency in MLLMs</title>
      <description>이 [arXiv]에 게시한 &#39;Same Content, Different Answers: Cross-Modal Inconsistency in MLLMs&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-10-Same-Content-Different-Answers-Cross-Modal-Inconsistency-in-MLLMs/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-10-Same-Content-Different-Answers-Cross-Modal-Inconsistency-in-MLLMs/</guid>
      <pubDate>Wed, 10 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Multimodal Large Language Models (MLLMs)</category><category>Cross-Modal Consistency</category><category>Reasoning Inconsistency</category><category>OCR Performance</category><category>Modality Gap</category><category>Benchmarking</category><category>Render Equivalence</category>
    </item>
    <item>
      <title>[논문리뷰] SUCCESS-GS: Survey of Compactness and Compression for Efficient Static and Dynamic Gaussian Splatting</title>
      <description>Sung-Ho Bae이 [arXiv]에 게시한 &#39;SUCCESS-GS: Survey of Compactness and Compression for Efficient Static and Dynamic Gaussian Splatting&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-10-SUCCESS-GS-Survey-of-Compactness-and-Compression-for-Efficient-Static-and-Dynamic-Gaussian-Splatting/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-10-SUCCESS-GS-Survey-of-Compactness-and-Compression-for-Efficient-Static-and-Dynamic-Gaussian-Splatting/</guid>
      <pubDate>Wed, 10 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>3D Gaussian Splatting (3DGS)</category><category>Gaussian Compression</category><category>Model Efficiency</category><category>Novel View Synthesis</category><category>Dynamic Scenes</category><category>Parameter Compression</category><category>Restructuring Compression</category><category>Real-time Rendering</category>
    </item>
    <item>
      <title>[논문리뷰] Preserving Source Video Realism: High-Fidelity Face Swapping for Cinematic Quality</title>
      <description>이 [arXiv]에 게시한 &#39;Preserving Source Video Realism: High-Fidelity Face Swapping for Cinematic Quality&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-10-Preserving-Source-Video-Realism-High-Fidelity-Face-Swapping-for-Cinematic-Quality/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-10-Preserving-Source-Video-Realism-High-Fidelity-Face-Swapping-for-Cinematic-Quality/</guid>
      <pubDate>Wed, 10 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Face Swapping</category><category>Video Editing</category><category>Diffusion Models</category><category>Reference-guided Generation</category><category>Temporal Consistency</category><category>Keyframe Conditioning</category><category>Cinematic Quality</category><category>Dataset Construction</category>
    </item>
    <item>
      <title>[논문리뷰] Predicting Time-Dependent Flow Over Complex Geometries Using Operator Networks</title>
      <description>이 [arXiv]에 게시한 &#39;Predicting Time-Dependent Flow Over Complex Geometries Using Operator Networks&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-10-Predicting-Time-Dependent-Flow-Over-Complex-Geometries-Using-Operator-Networks/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-10-Predicting-Time-Dependent-Flow-Over-Complex-Geometries-Using-Operator-Networks/</guid>
      <pubDate>Wed, 10 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Neural Operators</category><category>Time-Dependent Flow</category><category>Complex Geometries</category><category>DeepONet</category><category>Signed Distance Field</category><category>Autoregressive Prediction</category><category>Computational Fluid Dynamics</category><category>FlowBench</category>
    </item>
    <item>
      <title>[논문리뷰] OneStory: Coherent Multi-Shot Video Generation with Adaptive Memory</title>
      <description>이 [arXiv]에 게시한 &#39;OneStory: Coherent Multi-Shot Video Generation with Adaptive Memory&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-10-OneStory-Coherent-Multi-Shot-Video-Generation-with-Adaptive-Memory/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-10-OneStory-Coherent-Multi-Shot-Video-Generation-with-Adaptive-Memory/</guid>
      <pubDate>Wed, 10 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Multi-Shot Video Generation</category><category>Adaptive Memory</category><category>Long-Range Context</category><category>Frame Selection</category><category>Diffusion Models</category><category>Image-to-Video</category><category>Autoregressive Generation</category><category>Narrative Coherence</category>
    </item>
    <item>
      <title>[논문리뷰] Modular Neural Image Signal Processing</title>
      <description>Michael S. Brown이 [arXiv]에 게시한 &#39;Modular Neural Image Signal Processing&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-10-Modular-Neural-Image-Signal-Processing/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-10-Modular-Neural-Image-Signal-Processing/</guid>
      <pubDate>Wed, 10 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Neural ISP</category><category>Modular Architecture</category><category>Raw Image Processing</category><category>Photo-Editing</category><category>Camera Agnostic</category><category>Generalization</category><category>Deep Learning</category><category>Image Enhancement</category>
    </item>
    <item>
      <title>[논문리뷰] MIND-V: Hierarchical Video Generation for Long-Horizon Robotic Manipulation with RL-based Physical Alignment</title>
      <description>이 [arXiv]에 게시한 &#39;MIND-V: Hierarchical Video Generation for Long-Horizon Robotic Manipulation with RL-based Physical Alignment&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-10-MIND-V-Hierarchical-Video-Generation-for-Long-Horizon-Robotic-Manipulation-with-RL-based-Physical-Alignment/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-10-MIND-V-Hierarchical-Video-Generation-for-Long-Horizon-Robotic-Manipulation-with-RL-based-Physical-Alignment/</guid>
      <pubDate>Wed, 10 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Video Generation</category><category>Robotic Manipulation</category><category>Hierarchical Framework</category><category>Reinforcement Learning</category><category>Diffusion Models</category><category>World Models</category><category>Cognitive Science</category><category>Physical Alignment</category>
    </item>
    <item>
      <title>[논문리뷰] LYNX: Learning Dynamic Exits for Confidence-Controlled Reasoning</title>
      <description>이 [arXiv]에 게시한 &#39;LYNX: Learning Dynamic Exits for Confidence-Controlled Reasoning&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-10-LYNX-Learning-Dynamic-Exits-for-Confidence-Controlled-Reasoning/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-10-LYNX-Learning-Dynamic-Exits-for-Confidence-Controlled-Reasoning/</guid>
      <pubDate>Wed, 10 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Early Exit</category><category>Confidence Control</category><category>Reasoning Models</category><category>Conformal Prediction</category><category>LLM Optimization</category><category>Dynamic Exits</category><category>Hidden States</category><category>Chain-of-Thought</category>
    </item>
    <item>
      <title>[논문리뷰] Ground Slow, Move Fast: A Dual-System Foundation Model for Generalizable Vision-and-Language Navigation</title>
      <description>이 [arXiv]에 게시한 &#39;Ground Slow, Move Fast: A Dual-System Foundation Model for Generalizable Vision-and-Language Navigation&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-10-Ground-Slow-Move-Fast-A-Dual-System-Foundation-Model-for-Generalizable-Vision-and-Language-Navigation/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-10-Ground-Slow-Move-Fast-A-Dual-System-Foundation-Model-for-Generalizable-Vision-and-Language-Navigation/</guid>
      <pubDate>Wed, 10 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Vision-Language Navigation</category><category>Dual-System Architecture</category><category>Foundation Models</category><category>Diffusion Policies</category><category>Robotics</category><category>Real-time Control</category><category>Generalization</category><category>Autonomous Navigation</category>
    </item>
    <item>
      <title>[논문리뷰] From Next-Token to Next-Block: A Principled Adaptation Path for Diffusion LLMs</title>
      <description>이 [arXiv]에 게시한 &#39;From Next-Token to Next-Block: A Principled Adaptation Path for Diffusion LLMs&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-10-From-Next-Token-to-Next-Block-A-Principled-Adaptation-Path-for-Diffusion-LLMs/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-10-From-Next-Token-to-Next-Block-A-Principled-Adaptation-Path-for-Diffusion-LLMs/</guid>
      <pubDate>Wed, 10 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Diffusion Language Models</category><category>LLM Adaptation</category><category>Block-Diffusion</category><category>Autoregressive Models</category><category>Attention Masks</category><category>Parallel Generation</category><category>Transfer Learning</category><category>Generative Models</category>
    </item>
    <item>
      <title>[논문리뷰] Efficiently Reconstructing Dynamic Scenes One D4RT at a Time</title>
      <description>이 [arXiv]에 게시한 &#39;Efficiently Reconstructing Dynamic Scenes One D4RT at a Time&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-10-Efficiently-Reconstructing-Dynamic-Scenes-One-D4RT-at-a-Time/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-10-Efficiently-Reconstructing-Dynamic-Scenes-One-D4RT-at-a-Time/</guid>
      <pubDate>Wed, 10 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Dynamic Scene Reconstruction</category><category>4D Reconstruction</category><category>Point Tracking</category><category>Transformer Architecture</category><category>Feedforward Model</category><category>Query-based Inference</category><category>Computer Vision</category><category>Geometric Consistency</category>
    </item>
    <item>
      <title>[논문리뷰] EcomBench: Towards Holistic Evaluation of Foundation Agents in E-commerce</title>
      <description>이 [arXiv]에 게시한 &#39;EcomBench: Towards Holistic Evaluation of Foundation Agents in E-commerce&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-10-EcomBench-Towards-Holistic-Evaluation-of-Foundation-Agents-in-E-commerce/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-10-EcomBench-Towards-Holistic-Evaluation-of-Foundation-Agents-in-E-commerce/</guid>
      <pubDate>Wed, 10 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>E-commerce</category><category>Foundation Agents</category><category>LLM Agents</category><category>Benchmark</category><category>Agent Evaluation</category><category>Tool Use</category><category>Multi-step Reasoning</category><category>Real-world Scenarios</category>
    </item>
    <item>
      <title>[논문리뷰] DeepCode: Open Agentic Coding</title>
      <description>Chao Huang이 [arXiv]에 게시한 &#39;DeepCode: Open Agentic Coding&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-10-DeepCode-Open-Agentic-Coding/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-10-DeepCode-Open-Agentic-Coding/</guid>
      <pubDate>Wed, 10 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Agentic Coding</category><category>LLM</category><category>Code Generation</category><category>Repository Synthesis</category><category>Information Flow Management</category><category>Code Memory</category><category>CodeRAG</category><category>Automated Verification</category><category>Scientific Reproduction</category>
    </item>
    <item>
      <title>[논문리뷰] Boosting Unsupervised Video Instance Segmentation with Automatic Quality-Guided Self-Training</title>
      <description>Dim P. Papadopoulos이 [arXiv]에 게시한 &#39;Boosting Unsupervised Video Instance Segmentation with Automatic Quality-Guided Self-Training&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-10-Boosting-Unsupervised-Video-Instance-Segmentation-with-Automatic-Quality-Guided-Self-Training/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-10-Boosting-Unsupervised-Video-Instance-Segmentation-with-Automatic-Quality-Guided-Self-Training/</guid>
      <pubDate>Wed, 10 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Unsupervised Video Instance Segmentation</category><category>Self-Training</category><category>Quality Assessment</category><category>Pseudo-labeling</category><category>Domain Adaptation</category><category>VideoMask2Former</category><category>YouTubeVIS</category>
    </item>
    <item>
      <title>[논문리뷰] Voxify3D: Pixel Art Meets Volumetric Rendering</title>
      <description>Yu-Lun Liu이 [arXiv]에 게시한 &#39;Voxify3D: Pixel Art Meets Volumetric Rendering&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-09-Voxify3D-Pixel-Art-Meets-Volumetric-Rendering/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-09-Voxify3D-Pixel-Art-Meets-Volumetric-Rendering/</guid>
      <pubDate>Tue, 09 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Voxel Art</category><category>Volumetric Rendering</category><category>3D Stylization</category><category>Neural Radiance Fields</category><category>Discrete Optimization</category><category>Gumbel-Softmax</category><category>CLIP Loss</category>
    </item>
    
  </channel>
</rss>