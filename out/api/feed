<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>secrett2633's blog</title>
    <description>기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트</description>
    <link>https://blog.secrett2633.cloud</link>
    <atom:link href="https://blog.secrett2633.cloud/api/feed" rel="self" type="application/rss+xml" />
    <language>ko-KR</language>
    <lastBuildDate>Thu, 22 Jan 2026 12:29:13 GMT</lastBuildDate>
    <pubDate>Thu, 22 Jan 2026 12:29:13 GMT</pubDate>
    <ttl>60</ttl>
    <generator>Next.js RSS Generator</generator>
    <managingEditor>secrett2633@example.com (secrett2633)</managingEditor>
    <webMaster>secrett2633@example.com (secrett2633)</webMaster>
    <category>Technology</category>
    <category>Programming</category>
    <category>Django</category>
    <category>Python</category>
    <category>DevOps</category>
    <category>AI/ML</category>
    
        <item>
      <title>[논문리뷰] UniX: Unifying Autoregression and Diffusion for Chest X-Ray Understanding and Generation</title>
      <description>이 [arXiv]에 게시한 &#39;UniX: Unifying Autoregression and Diffusion for Chest X-Ray Understanding and Generation&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-21-UniX-Unifying-Autoregression-and-Diffusion-for-Chest-X-Ray-Understanding-and-Generation/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-21-UniX-Unifying-Autoregression-and-Diffusion-for-Chest-X-Ray-Understanding-and-Generation/</guid>
      <pubDate>Wed, 21 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Chest X-Ray</category><category>Medical Foundation Model</category><category>Autoregressive Model</category><category>Diffusion Model</category><category>Multimodal Learning</category><category>Image Understanding</category><category>Image Generation</category><category>Cross-Modal Attention</category>
    </item>
    <item>
      <title>[논문리뷰] Toward Efficient Agents: Memory, Tool learning, and Planning</title>
      <description>이 [arXiv]에 게시한 &#39;Toward Efficient Agents: Memory, Tool learning, and Planning&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-21-Toward-Efficient-Agents-Memory-Tool-learning-and-Planning/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-21-Toward-Efficient-Agents-Memory-Tool-learning-and-Planning/</guid>
      <pubDate>Wed, 21 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>LLM Agents</category><category>Agent Efficiency</category><category>Memory Management</category><category>Tool Learning</category><category>AI Planning</category><category>Resource Optimization</category><category>Cost-Performance Trade-off</category>
    </item>
    <item>
      <title>[논문리뷰] ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents</title>
      <description>이 [arXiv]에 게시한 &#39;ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-21-ToolPRMBench-Evaluating-and-Advancing-Process-Reward-Models-for-Tool-using-Agents/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-21-ToolPRMBench-Evaluating-and-Advancing-Process-Reward-Models-for-Tool-using-Agents/</guid>
      <pubDate>Wed, 21 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Process Reward Models</category><category>Tool-using Agents</category><category>Benchmark</category><category>Reinforcement Learning</category><category>Large Language Models</category><category>Reward-guided Search</category><category>Agent Evaluation</category><category>Step-level Rewards</category>
    </item>
    <item>
      <title>[논문리뷰] Think3D: Thinking with Space for Spatial Reasoning</title>
      <description>Yuhan Wu이 [arXiv]에 게시한 &#39;Think3D: Thinking with Space for Spatial Reasoning&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-21-Think3D-Thinking-with-Space-for-Spatial-Reasoning/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-21-Think3D-Thinking-with-Space-for-Spatial-Reasoning/</guid>
      <pubDate>Wed, 21 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Spatial Reasoning</category><category>3D Reconstruction</category><category>VLM Agents</category><category>Tool Calling</category><category>Reinforcement Learning</category><category>Novel View Synthesis</category><category>Iterative Exploration</category>
    </item>
    <item>
      <title>[논문리뷰] SciCoQA: Quality Assurance for Scientific Paper--Code Alignment</title>
      <description>이 [arXiv]에 게시한 &#39;SciCoQA: Quality Assurance for Scientific Paper--Code Alignment&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-21-SciCoQA-Quality-Assurance-for-Scientific-Paper-Code-Alignment/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-21-SciCoQA-Quality-Assurance-for-Scientific-Paper-Code-Alignment/</guid>
      <pubDate>Wed, 21 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Reproducibility</category><category>Paper-Code Discrepancy</category><category>Code Alignment</category><category>LLM Evaluation</category><category>Synthetic Data Generation</category><category>Quality Assurance</category><category>Scientific Automation</category>
    </item>
    <item>
      <title>[논문리뷰] PRiSM: Benchmarking Phone Realization in Speech Models</title>
      <description>이 [arXiv]에 게시한 &#39;PRiSM: Benchmarking Phone Realization in Speech Models&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-21-PRiSM-Benchmarking-Phone-Realization-in-Speech-Models/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-21-PRiSM-Benchmarking-Phone-Realization-in-Speech-Models/</guid>
      <pubDate>Wed, 21 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Phone Recognition</category><category>Speech Models</category><category>Benchmarking</category><category>Phonetic Analysis</category><category>Cross-lingual Speech</category><category>LALMs</category><category>Intrinsic Evaluation</category><category>Extrinsic Evaluation</category>
    </item>
    <item>
      <title>[논문리뷰] On the Evidentiary Limits of Membership Inference for Copyright Auditing</title>
      <description>Marten van Dijk이 [arXiv]에 게시한 &#39;On the Evidentiary Limits of Membership Inference for Copyright Auditing&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-21-On-the-Evidentiary-Limits-of-Membership-Inference-for-Copyright-Auditing/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-21-On-the-Evidentiary-Limits-of-Membership-Inference-for-Copyright-Auditing/</guid>
      <pubDate>Wed, 21 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Membership Inference Attacks</category><category>Copyright Auditing</category><category>Large Language Models</category><category>Adversarial Robustness</category><category>Paraphrasing</category><category>Sparse Autoencoders</category><category>Semantic Preservation</category><category>LLM Security</category>
    </item>
    <item>
      <title>[논문리뷰] OmniTransfer: All-in-one Framework for Spatio-temporal Video Transfer</title>
      <description>이 [arXiv]에 게시한 &#39;OmniTransfer: All-in-one Framework for Spatio-temporal Video Transfer&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-21-OmniTransfer-All-in-one-Framework-for-Spatio-temporal-Video-Transfer/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-21-OmniTransfer-All-in-one-Framework-for-Spatio-temporal-Video-Transfer/</guid>
      <pubDate>Wed, 21 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Video Transfer</category><category>Diffusion Models</category><category>Spatio-temporal Learning</category><category>Multimodal Alignment</category><category>Appearance Consistency</category><category>Temporal Control</category><category>Video Generation</category>
    </item>
    <item>
      <title>[논문리뷰] MemoryRewardBench: Benchmarking Reward Models for Long-Term Memory Management in Large Language Models</title>
      <description>이 [arXiv]에 게시한 &#39;MemoryRewardBench: Benchmarking Reward Models for Long-Term Memory Management in Large Language Models&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-21-MemoryRewardBench-Benchmarking-Reward-Models-for-Long-Term-Memory-Management-in-Large-Language-Models/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-21-MemoryRewardBench-Benchmarking-Reward-Models-for-Long-Term-Memory-Management-in-Large-Language-Models/</guid>
      <pubDate>Wed, 21 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Reward Models</category><category>LLM Memory Management</category><category>Benchmarking</category><category>Long Context</category><category>Evaluation Metrics</category><category>Generative RMs</category><category>Memory Management Patterns</category>
    </item>
    <item>
      <title>[논문리뷰] LightOnOCR: A 1B End-to-End Multilingual Vision-Language Model for State-of-the-Art OCR</title>
      <description>이 [arXiv]에 게시한 &#39;LightOnOCR: A 1B End-to-End Multilingual Vision-Language Model for State-of-the-Art OCR&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-21-LightOnOCR-A-1B-End-to-End-Multilingual-Vision-Language-Model-for-State-of-the-Art-OCR/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-21-LightOnOCR-A-1B-End-to-End-Multilingual-Vision-Language-Model-for-State-of-the-Art-OCR/</guid>
      <pubDate>Wed, 21 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>OCR</category><category>Vision-Language Model</category><category>End-to-End Learning</category><category>Multilingual</category><category>Reinforcement Learning</category><category>Document Understanding</category><category>Bounding Box Prediction</category><category>Task Arithmetic Merging</category>
    </item>
    <item>
      <title>[논문리뷰] LIBERTy: A Causal Framework for Benchmarking Concept-Based Explanations of LLMs with Structural Counterfactuals</title>
      <description>이 [arXiv]에 게시한 &#39;LIBERTy: A Causal Framework for Benchmarking Concept-Based Explanations of LLMs with Structural Counterfactuals&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-21-LIBERTy-A-Causal-Framework-for-Benchmarking-Concept-Based-Explanations-of-LLMs-with-Structural-Counterfactuals/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-21-LIBERTy-A-Causal-Framework-for-Benchmarking-Concept-Based-Explanations-of-LLMs-with-Structural-Counterfactuals/</guid>
      <pubDate>Wed, 21 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>LLM Explainability</category><category>Causal Inference</category><category>Structural Counterfactuals</category><category>Concept-Based Explanations</category><category>Evaluation Benchmark</category><category>Faithfulness</category><category>SCM</category>
    </item>
    <item>
      <title>[논문리뷰] KAGE-Bench: Fast Known-Axis Visual Generalization Evaluation for Reinforcement Learning</title>
      <description>Aleksandr I. Panov이 [arXiv]에 게시한 &#39;KAGE-Bench: Fast Known-Axis Visual Generalization Evaluation for Reinforcement Learning&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-21-KAGE-Bench-Fast-Known-Axis-Visual-Generalization-Evaluation-for-Reinforcement-Learning/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-21-KAGE-Bench-Fast-Known-Axis-Visual-Generalization-Evaluation-for-Reinforcement-Learning/</guid>
      <pubDate>Wed, 21 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Reinforcement Learning</category><category>Visual Generalization</category><category>Distribution Shift</category><category>Benchmarking</category><category>JAX</category><category>Controlled Environments</category><category>PPO</category>
    </item>
    <item>
      <title>[논문리뷰] FutureOmni: Evaluating Future Forecasting from Omni-Modal Context for Multimodal LLMs</title>
      <description>이 [arXiv]에 게시한 &#39;FutureOmni: Evaluating Future Forecasting from Omni-Modal Context for Multimodal LLMs&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-21-FutureOmni-Evaluating-Future-Forecasting-from-Omni-Modal-Context-for-Multimodal-LLMs/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-21-FutureOmni-Evaluating-Future-Forecasting-from-Omni-Modal-Context-for-Multimodal-LLMs/</guid>
      <pubDate>Wed, 21 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Multimodal LLMs</category><category>Future Forecasting</category><category>Audio-Visual Reasoning</category><category>Benchmark</category><category>Instruction Tuning</category><category>Omni-Modal</category><category>Causal Reasoning</category>
    </item>
    <item>
      <title>[논문리뷰] Fundamental Limitations of Favorable Privacy-Utility Guarantees for DP-SGD</title>
      <description>이 [arXiv]에 게시한 &#39;Fundamental Limitations of Favorable Privacy-Utility Guarantees for DP-SGD&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-21-Fundamental-Limitations-of-Favorable-Privacy-Utility-Guarantees-for-DP-SGD/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-21-Fundamental-Limitations-of-Favorable-Privacy-Utility-Guarantees-for-DP-SGD/</guid>
      <pubDate>Wed, 21 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Differential Privacy (DP)</category><category>DP-SGD</category><category>f-differential privacy</category><category>Privacy-Utility Trade-off</category><category>Shuffled Sampling</category><category>Poisson Subsampling</category><category>Gaussian Noise</category><category>Worst-Case Adversary</category>
    </item>
    <item>
      <title>[논문리뷰] FantasyVLN: Unified Multimodal Chain-of-Thought Reasoning for Vision-Language Navigation</title>
      <description>이 [arXiv]에 게시한 &#39;FantasyVLN: Unified Multimodal Chain-of-Thought Reasoning for Vision-Language Navigation&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-21-FantasyVLN-Unified-Multimodal-Chain-of-Thought-Reasoning-for-Vision-Language-Navigation/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-21-FantasyVLN-Unified-Multimodal-Chain-of-Thought-Reasoning-for-Vision-Language-Navigation/</guid>
      <pubDate>Wed, 21 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Vision-Language Navigation</category><category>Chain-of-Thought Reasoning</category><category>Multimodal AI</category><category>Implicit Reasoning</category><category>Visual AutoRegressor</category><category>Embodied AI</category><category>Long-Horizon Planning</category>
    </item>
    <item>
      <title>[논문리뷰] Being-H0.5: Scaling Human-Centric Robot Learning for Cross-Embodiment Generalization</title>
      <description>이 [arXiv]에 게시한 &#39;Being-H0.5: Scaling Human-Centric Robot Learning for Cross-Embodiment Generalization&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-21-Being-H0-5-Scaling-Human-Centric-Robot-Learning-for-Cross-Embodiment-Generalization/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-21-Being-H0-5-Scaling-Human-Centric-Robot-Learning-for-Cross-Embodiment-Generalization/</guid>
      <pubDate>Wed, 21 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Robot Learning</category><category>Cross-Embodiment Generalization</category><category>Vision-Language-Action Models</category><category>Human-Centric Learning</category><category>Unified Action Space</category><category>Mixture-of-Flow</category><category>Real-Time Deployment</category><category>Large-Scale Datasets</category>
    </item>
    <item>
      <title>[논문리뷰] Aligning Agentic World Models via Knowledgeable Experience Learning</title>
      <description>이 [arXiv]에 게시한 &#39;Aligning Agentic World Models via Knowledgeable Experience Learning&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-21-Aligning-Agentic-World-Models-via-Knowledgeable-Experience-Learning/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-21-Aligning-Agentic-World-Models-via-Knowledgeable-Experience-Learning/</guid>
      <pubDate>Wed, 21 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Agentic AI</category><category>World Models</category><category>Experience Learning</category><category>LLMs</category><category>Physical Hallucinations</category><category>Embodied AI</category><category>Predictive Coding</category><category>Knowledge Repository</category>
    </item>
    <item>
      <title>[논문리뷰] Agentic-R: Learning to Retrieve for Agentic Search</title>
      <description>Daiting Shi이 [arXiv]에 게시한 &#39;Agentic-R: Learning to Retrieve for Agentic Search&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-21-Agentic-R-Learning-to-Retrieve-for-Agentic-Search/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-21-Agentic-R-Learning-to-Retrieve-for-Agentic-Search/</guid>
      <pubDate>Wed, 21 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Agentic Search</category><category>Retrieval-Augmented Generation</category><category>Retriever Training</category><category>Passage Utility Modeling</category><category>Iterative Optimization</category><category>Reinforcement Learning</category><category>Large Language Models</category>
    </item>
    <item>
      <title>[논문리뷰] Advances and Frontiers of LLM-based Issue Resolution in Software Engineering: A Comprehensive Survey</title>
      <description>이 [arXiv]에 게시한 &#39;Advances and Frontiers of LLM-based Issue Resolution in Software Engineering: A Comprehensive Survey&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-21-Advances-and-Frontiers-of-LLM-based-Issue-Resolution-in-Software-Engineering-A-Comprehensive-Survey/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-21-Advances-and-Frontiers-of-LLM-based-Issue-Resolution-in-Software-Engineering-A-Comprehensive-Survey/</guid>
      <pubDate>Wed, 21 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>LLM-based Issue Resolution</category><category>Software Engineering</category><category>Autonomous Agents</category><category>Code Generation</category><category>Benchmarking</category><category>Reinforcement Learning</category><category>Supervised Fine-tuning</category><category>Multimodal LLMs</category>
    </item>
    <item>
      <title>[논문리뷰] A Hybrid Protocol for Large-Scale Semantic Dataset Generation in Low-Resource Languages: The Turkish Semantic Relations Corpus</title>
      <description>Özay Ezerceli이 [arXiv]에 게시한 &#39;A Hybrid Protocol for Large-Scale Semantic Dataset Generation in Low-Resource Languages: The Turkish Semantic Relations Corpus&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-21-A-Hybrid-Protocol-for-Large-Scale-Semantic-Dataset-Generation-in-Low-Resource-Languages-The-Turkish-Semantic-Relations-Corpus/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-21-A-Hybrid-Protocol-for-Large-Scale-Semantic-Dataset-Generation-in-Low-Resource-Languages-The-Turkish-Semantic-Relations-Corpus/</guid>
      <pubDate>Wed, 21 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Low-Resource NLP</category><category>Semantic Relations</category><category>Dataset Generation</category><category>Turkish Language</category><category>LLM</category><category>FastText Embeddings</category><category>Agglomerative Clustering</category><category>Synonyms</category><category>Antonyms</category><category>Co-hyponyms</category>
    </item>
    
  </channel>
</rss>