<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>secrett2633's blog</title>
    <description>기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트</description>
    <link>https://blog.secrett2633.site</link>
    <atom:link href="https://blog.secrett2633.site/api/feed" rel="self" type="application/rss+xml" />
    <language>ko-KR</language>
    <lastBuildDate>Mon, 01 Dec 2025 11:07:51 GMT</lastBuildDate>
    <pubDate>Mon, 01 Dec 2025 11:07:51 GMT</pubDate>
    <ttl>60</ttl>
    <generator>Next.js RSS Generator</generator>
    <managingEditor>secrett2633@example.com (secrett2633)</managingEditor>
    <webMaster>secrett2633@example.com (secrett2633)</webMaster>
    <category>Technology</category>
    <category>Programming</category>
    <category>Django</category>
    <category>Python</category>
    <category>DevOps</category>
    <category>AI/ML</category>
    
        <item>
      <title>[논문리뷰] What does it mean to understand language?</title>
      <description>이 [arXiv]에 게시한 &#39;What does it mean to understand language?&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-11-28-What-does-it-mean-to-understand-language/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-11-28-What-does-it-mean-to-understand-language/</guid>
      <pubDate>Fri, 28 Nov 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Language Understanding</category><category>Cognitive Neuroscience</category><category>Situation Models</category><category>World Knowledge</category><category>Embodiment</category><category>fMRI</category><category>Large Language Models</category><category>Brain Networks</category>
    </item>
    <item>
      <title>[논문리뷰] Video Generation Models Are Good Latent Reward Models</title>
      <description>이 [arXiv]에 게시한 &#39;Video Generation Models Are Good Latent Reward Models&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-11-28-Video-Generation-Models-Are-Good-Latent-Reward-Models/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-11-28-Video-Generation-Models-Are-Good-Latent-Reward-Models/</guid>
      <pubDate>Fri, 28 Nov 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Video Generation</category><category>Reward Feedback Learning</category><category>Latent Space</category><category>Diffusion Models</category><category>Human Preferences</category><category>Motion Quality</category><category>Process-aware</category>
    </item>
    <item>
      <title>[논문리뷰] Multi-Crit: Benchmarking Multimodal Judges on Pluralistic Criteria-Following</title>
      <description>이 [arXiv]에 게시한 &#39;Multi-Crit: Benchmarking Multimodal Judges on Pluralistic Criteria-Following&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-11-28-Multi-Crit-Benchmarking-Multimodal-Judges-on-Pluralistic-Criteria-Following/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-11-28-Multi-Crit-Benchmarking-Multimodal-Judges-on-Pluralistic-Criteria-Following/</guid>
      <pubDate>Fri, 28 Nov 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Multimodal Judges</category><category>LMM Evaluation</category><category>Pluralistic Criteria</category><category>Criteria-Following</category><category>Trade-off Sensitivity</category><category>Conflict Resolution</category><category>Reward Models</category><category>Benchmark</category>
    </item>
    <item>
      <title>[논문리뷰] MIRA: Multimodal Iterative Reasoning Agent for Image Editing</title>
      <description>Jiebo Luo이 [arXiv]에 게시한 &#39;MIRA: Multimodal Iterative Reasoning Agent for Image Editing&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-11-28-MIRA-Multimodal-Iterative-Reasoning-Agent-for-Image-Editing/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-11-28-MIRA-Multimodal-Iterative-Reasoning-Agent-for-Image-Editing/</guid>
      <pubDate>Fri, 28 Nov 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Image Editing</category><category>Multimodal AI</category><category>Iterative Reasoning</category><category>Agentic AI</category><category>Reinforcement Learning</category><category>Diffusion Models</category><category>Vision-Language Models</category><category>Instruction Following</category>
    </item>
    <item>
      <title>[논문리뷰] Canvas-to-Image: Compositional Image Generation with Multimodal Controls</title>
      <description>Kfir Aberman이 [arXiv]에 게시한 &#39;Canvas-to-Image: Compositional Image Generation with Multimodal Controls&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-11-28-Canvas-to-Image-Compositional-Image-Generation-with-Multimodal-Controls/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-11-28-Canvas-to-Image-Compositional-Image-Generation-with-Multimodal-Controls/</guid>
      <pubDate>Fri, 28 Nov 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Image Generation</category><category>Diffusion Models</category><category>Compositional Control</category><category>Multimodal Control</category><category>Unified Canvas</category><category>Multi-Task Learning</category><category>Personalization</category>
    </item>
    <item>
      <title>[논문리뷰] Agentic Learner with Grow-and-Refine Multimodal Semantic Memory</title>
      <description>Qunyi Xie이 [arXiv]에 게시한 &#39;Agentic Learner with Grow-and-Refine Multimodal Semantic Memory&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-11-28-Agentic-Learner-with-Grow-and-Refine-Multimodal-Semantic-Memory/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-11-28-Agentic-Learner-with-Grow-and-Refine-Multimodal-Semantic-Memory/</guid>
      <pubDate>Fri, 28 Nov 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Multimodal LLMs</category><category>Semantic Memory</category><category>Agentic Learning</category><category>Error Attribution</category><category>Visual Reasoning</category><category>Long-term Memory</category><category>Grow-and-Refine</category><category>Multimodal Reasoning</category>
    </item>
    <item>
      <title>[논문리뷰] Terminal Velocity Matching</title>
      <description>Jiaming Song이 [arXiv]에 게시한 &#39;Terminal Velocity Matching&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-11-27-Terminal-Velocity-Matching/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-11-27-Terminal-Velocity-Matching/</guid>
      <pubDate>Thu, 27 Nov 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Generative Models</category><category>Flow Matching</category><category>Diffusion Models</category><category>One-Step Generation</category><category>Few-Step Generation</category><category>Wasserstein Distance</category><category>Transformer Architecture</category><category>Lipschitz Continuity</category>
    </item>
    <item>
      <title>[논문리뷰] SPHINX: A Synthetic Environment for Visual Perception and Reasoning</title>
      <description>Nidhi Rastogi이 [arXiv]에 게시한 &#39;SPHINX: A Synthetic Environment for Visual Perception and Reasoning&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-11-27-SPHINX-A-Synthetic-Environment-for-Visual-Perception-and-Reasoning/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-11-27-SPHINX-A-Synthetic-Environment-for-Visual-Perception-and-Reasoning/</guid>
      <pubDate>Thu, 27 Nov 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Visual Reasoning</category><category>Synthetic Environment</category><category>LVLM Evaluation</category><category>Reinforcement Learning</category><category>Cognitive Primitives</category><category>Procedural Generation</category><category>Multimodal AI</category>
    </item>
    <item>
      <title>[논문리뷰] Revisiting Generalization Across Difficulty Levels: It&#39;s Not So Easy</title>
      <description>이 [arXiv]에 게시한 &#39;Revisiting Generalization Across Difficulty Levels: It&#39;s Not So Easy&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-11-27-Revisiting-Generalization-Across-Difficulty-Levels-Its-Not-So-Easy/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-11-27-Revisiting-Generalization-Across-Difficulty-Levels-Its-Not-So-Easy/</guid>
      <pubDate>Thu, 27 Nov 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>LLM Generalization</category><category>Task Difficulty</category><category>Item Response Theory</category><category>Cross-Difficulty</category><category>Data Curation</category><category>Model Evaluation</category><category>Supervised Fine-Tuning</category>
    </item>
    <item>
      <title>[논문리뷰] RAISECity: A Multimodal Agent Framework for Reality-Aligned 3D World Generation at City-Scale</title>
      <description>Yangcheng Yu이 [arXiv]에 게시한 &#39;RAISECity: A Multimodal Agent Framework for Reality-Aligned 3D World Generation at City-Scale&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-11-27-RAISECity-A-Multimodal-Agent-Framework-for-Reality-Aligned-3D-World-Generation-at-City-Scale/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-11-27-RAISECity-A-Multimodal-Agent-Framework-for-Reality-Aligned-3D-World-Generation-at-City-Scale/</guid>
      <pubDate>Thu, 27 Nov 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>3D World Generation</category><category>City-Scale</category><category>Multimodal Agents</category><category>Reality Alignment</category><category>Urban Simulation</category><category>Foundation Models</category><category>Geospatial Data</category>
    </item>
    <item>
      <title>[논문리뷰] NVIDIA Nemotron Parse 1.1</title>
      <description>이 [arXiv]에 게시한 &#39;NVIDIA Nemotron Parse 1.1&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-11-27-NVIDIA-Nemotron-Parse-1-1/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-11-27-NVIDIA-Nemotron-Parse-1-1/</guid>
      <pubDate>Thu, 27 Nov 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>OCR</category><category>Document Parsing</category><category>Vision-Language Model</category><category>Encoder-Decoder</category><category>Transformer</category><category>Table Extraction</category><category>Multilingual OCR</category><category>Layout Analysis</category>
    </item>
    <item>
      <title>[논문리뷰] Monet: Reasoning in Latent Visual Space Beyond Images and Language</title>
      <description>Pengfei Wan이 [arXiv]에 게시한 &#39;Monet: Reasoning in Latent Visual Space Beyond Images and Language&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-11-27-Monet-Reasoning-in-Latent-Visual-Space-Beyond-Images-and-Language/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-11-27-Monet-Reasoning-in-Latent-Visual-Space-Beyond-Images-and-Language/</guid>
      <pubDate>Thu, 27 Nov 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Latent Visual Reasoning</category><category>Multimodal Large Language Models (MLLMs)</category><category>Supervised Fine-tuning (SFT)</category><category>Reinforcement Learning (RL)</category><category>Visual-latent Policy Optimization (VLPO)</category><category>Chain-of-Thought (CoT)</category><category>Abstract Visual Thinking</category>
    </item>
    <item>
      <title>[논문리뷰] MobileVLA-R1: Reinforcing Vision-Language-Action for Mobile Robots</title>
      <description>Rui Yang이 [arXiv]에 게시한 &#39;MobileVLA-R1: Reinforcing Vision-Language-Action for Mobile Robots&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-11-27-MobileVLA-R1-Reinforcing-Vision-Language-Action-for-Mobile-Robots/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-11-27-MobileVLA-R1-Reinforcing-Vision-Language-Action-for-Mobile-Robots/</guid>
      <pubDate>Thu, 27 Nov 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Vision-Language-Action (VLA)</category><category>Mobile Robotics</category><category>Quadruped Robots</category><category>Chain-of-Thought (CoT)</category><category>Reinforcement Learning (RL)</category><category>Embodied AI</category><category>Multimodal Perception</category>
    </item>
    <item>
      <title>[논문리뷰] Latent Collaboration in Multi-Agent Systems</title>
      <description>이 [arXiv]에 게시한 &#39;Latent Collaboration in Multi-Agent Systems&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-11-27-Latent-Collaboration-in-Multi-Agent-Systems/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-11-27-Latent-Collaboration-in-Multi-Agent-Systems/</guid>
      <pubDate>Thu, 27 Nov 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Multi-Agent Systems</category><category>Large Language Models</category><category>Latent Space</category><category>Latent Reasoning</category><category>Latent Communication</category><category>KV Cache</category><category>Computational Efficiency</category><category>Training-Free</category>
    </item>
    <item>
      <title>[논문리뷰] Inferix: A Block-Diffusion based Next-Generation Inference Engine for World Simulation</title>
      <description>Jiahao He이 [arXiv]에 게시한 &#39;Inferix: A Block-Diffusion based Next-Generation Inference Engine for World Simulation&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-11-27-Inferix-A-Block-Diffusion-based-Next-Generation-Inference-Engine-for-World-Simulation/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-11-27-Inferix-A-Block-Diffusion-based-Next-Generation-Inference-Engine-for-World-Simulation/</guid>
      <pubDate>Thu, 27 Nov 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>World Simulation</category><category>Video Generation</category><category>Block Diffusion</category><category>Semi-Autoregressive</category><category>KV Cache Management</category><category>Inference Engine</category><category>Long Video Generation</category><category>Performance Optimization</category>
    </item>
    <item>
      <title>[논문리뷰] Image-Free Timestep Distillation via Continuous-Time Consistency with Trajectory-Sampled Pairs</title>
      <description>Xin Yang이 [arXiv]에 게시한 &#39;Image-Free Timestep Distillation via Continuous-Time Consistency with Trajectory-Sampled Pairs&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-11-27-Image-Free-Timestep-Distillation-via-Continuous-Time-Consistency-with-Trajectory-Sampled-Pairs/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-11-27-Image-Free-Timestep-Distillation-via-Continuous-Time-Consistency-with-Trajectory-Sampled-Pairs/</guid>
      <pubDate>Thu, 27 Nov 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Diffusion Models</category><category>Timestep Distillation</category><category>Consistency Models</category><category>Latent Space</category><category>Image-Free Training</category><category>Efficiency Optimization</category><category>Trajectory Sampling</category><category>Continuous-Time Learning</category>
    </item>
    <item>
      <title>[논문리뷰] I-GLIDE: Input Groups for Latent Health Indicators in Degradation Estimation</title>
      <description>이 [arXiv]에 게시한 &#39;I-GLIDE: Input Groups for Latent Health Indicators in Degradation Estimation&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-11-27-I-GLIDE-Input-Groups-for-Latent-Health-Indicators-in-Degradation-Estimation/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-11-27-I-GLIDE-Input-Groups-for-Latent-Health-Indicators-in-Degradation-Estimation/</guid>
      <pubDate>Thu, 27 Nov 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Health Indicator (HI)</category><category>Remaining Useful Life (RUL)</category><category>Uncertainty Quantification (UQ)</category><category>Autoencoder (AE)</category><category>Latent Space</category><category>Degradation Modeling</category><category>Prognostics</category><category>Condition-Based Maintenance</category>
    </item>
    <item>
      <title>[논문리뷰] Harmony: Harmonizing Audio and Video Generation through Cross-Task Synergy</title>
      <description>이 [arXiv]에 게시한 &#39;Harmony: Harmonizing Audio and Video Generation through Cross-Task Synergy&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-11-27-Harmony-Harmonizing-Audio-and-Video-Generation-through-Cross-Task-Synergy/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-11-27-Harmony-Harmonizing-Audio-and-Video-Generation-through-Cross-Task-Synergy/</guid>
      <pubDate>Thu, 27 Nov 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Audio-Visual Generation</category><category>Cross-Modal Synchronization</category><category>Diffusion Models</category><category>Cross-Task Synergy</category><category>Classifier-Free Guidance</category><category>Multimodal AI</category><category>Generative AI</category>
    </item>
    <item>
      <title>[논문리뷰] Frequency-Adaptive Sharpness Regularization for Improving 3D Gaussian Splatting Generalization</title>
      <description>Youngjung Uh이 [arXiv]에 게시한 &#39;Frequency-Adaptive Sharpness Regularization for Improving 3D Gaussian Splatting Generalization&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-11-27-Frequency-Adaptive-Sharpness-Regularization-for-Improving-3D-Gaussian-Splatting-Generalization/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-11-27-Frequency-Adaptive-Sharpness-Regularization-for-Improving-3D-Gaussian-Splatting-Generalization/</guid>
      <pubDate>Thu, 27 Nov 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>3D Gaussian Splatting</category><category>Generalization</category><category>Sharpness-Aware Minimization</category><category>Regularization</category><category>Novel View Synthesis</category><category>Sparse View Reconstruction</category><category>Loss Landscape</category><category>Frequency-Adaptive</category>
    </item>
    <item>
      <title>[논문리뷰] Block Cascading: Training Free Acceleration of Block-Causal Video Models</title>
      <description>이 [arXiv]에 게시한 &#39;Block Cascading: Training Free Acceleration of Block-Causal Video Models&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-11-27-Block-Cascading-Training-Free-Acceleration-of-Block-Causal-Video-Models/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-11-27-Block-Cascading-Training-Free-Acceleration-of-Block-Causal-Video-Models/</guid>
      <pubDate>Thu, 27 Nov 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Video Generation</category><category>Diffusion Models</category><category>Block-Causal Models</category><category>Inference Acceleration</category><category>Multi-GPU Parallelism</category><category>Training-Free</category><category>KV Caching</category><category>Interactive AI</category>
    </item>
    
  </channel>
</rss>