[{"id":"2025-10-15-What_If_Understanding_Motion_Through_Sparse_Interactions","title":"[논문리뷰] What If : Understanding Motion Through Sparse Interactions","excerpt":"이 [arXiv]에 게시한 'What If : Understanding Motion Through Sparse Interactions' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-15 13:01:40+0900","lastModifiedAt":"2025-10-15 13:01:40+0900","categories":["Review"],"tags":["Review","Motion Understanding","Sparse Interactions","Multimodal Prediction","Flow Poke Transformer","Physical Scene Dynamics","Uncertainty Quantification","Generative Models","Computer Vision"],"permalink":"/ai/review/2025-10-15-What_If_Understanding_Motion_Through_Sparse_Interactions/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-15-ViCO_A_Training_Strategy_towards_Semantic_Aware_Dynamic_High-Resolution","title":"[논문리뷰] ViCO: A Training Strategy towards Semantic Aware Dynamic High-Resolution","excerpt":"이 [arXiv]에 게시한 'ViCO: A Training Strategy towards Semantic Aware Dynamic High-Resolution' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-15 13:01:40+0900","lastModifiedAt":"2025-10-15 13:01:40+0900","categories":["Review"],"tags":["Review","Multimodal Large Language Models (MLLMs)","Dynamic Resolution","Token Compression","Semantic Awareness","Visual Consistency Learning (ViCO)","Visual Resolution Router (ViR)","Inference Optimization"],"permalink":"/ai/review/2025-10-15-ViCO_A_Training_Strategy_towards_Semantic_Aware_Dynamic_High-Resolution/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-15-UniFusion_Vision-Language_Model_as_Unified_Encoder_in_Image_Generation","title":"[논문리뷰] UniFusion: Vision-Language Model as Unified Encoder in Image Generation","excerpt":"이 [arXiv]에 게시한 'UniFusion: Vision-Language Model as Unified Encoder in Image Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-15 13:01:40+0900","lastModifiedAt":"2025-10-15 13:01:40+0900","categories":["Review"],"tags":["Review","Vision-Language Model","Unified Encoder","Image Generation","Diffusion Models","Multimodal Learning","Text-to-Image","Image Editing","Zero-shot Learning"],"permalink":"/ai/review/2025-10-15-UniFusion_Vision-Language_Model_as_Unified_Encoder_in_Image_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-15-Tensor_Logic_The_Language_of_AI","title":"[논문리뷰] Tensor Logic: The Language of AI","excerpt":"Pedro Domingos이 [arXiv]에 게시한 'Tensor Logic: The Language of AI' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-15 13:01:40+0900","lastModifiedAt":"2025-10-15 13:01:40+0900","categories":["Review"],"tags":["Review","Tensor Logic","Neurosymbolic AI","Logic Programming","Tensor Algebra","Deep Learning","Automated Reasoning","Embedding Space"],"permalink":"/ai/review/2025-10-15-Tensor_Logic_The_Language_of_AI/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-15-Temporal_Alignment_Guidance_On-Manifold_Sampling_in_Diffusion_Models","title":"[논문리뷰] Temporal Alignment Guidance: On-Manifold Sampling in Diffusion Models","excerpt":"이 [arXiv]에 게시한 'Temporal Alignment Guidance: On-Manifold Sampling in Diffusion Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-15 13:01:40+0900","lastModifiedAt":"2025-10-15 13:01:40+0900","categories":["Review"],"tags":["Review","Diffusion Models","Generative Models","Guidance","On-Manifold Sampling","Temporal Alignment","Score Approximation Error","Training-Free Guidance"],"permalink":"/ai/review/2025-10-15-Temporal_Alignment_Guidance_On-Manifold_Sampling_in_Diffusion_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-15-SynthID-Image_Image_watermarking_at_internet_scale","title":"[논문리뷰] SynthID-Image: Image watermarking at internet scale","excerpt":"이 [arXiv]에 게시한 'SynthID-Image: Image watermarking at internet scale' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-15 13:01:40+0900","lastModifiedAt":"2025-10-15 13:01:40+0900","categories":["Review"],"tags":["Review","Image Watermarking","AI-Generated Content","Provenance","Robustness","Security","Deep Learning","Internet Scale","Post-hoc"],"permalink":"/ai/review/2025-10-15-SynthID-Image_Image_watermarking_at_internet_scale/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-15-SRUM_Fine-Grained_Self-Rewarding_for_Unified_Multimodal_Models","title":"[논문리뷰] SRUM: Fine-Grained Self-Rewarding for Unified Multimodal Models","excerpt":"이 [arXiv]에 게시한 'SRUM: Fine-Grained Self-Rewarding for Unified Multimodal Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-15 13:01:40+0900","lastModifiedAt":"2025-10-15 13:01:40+0900","categories":["Review"],"tags":["Review","Unified Multimodal Models","Self-Rewarding","Text-to-Image Generation","Image Understanding","Post-Training","Global-Local Reward","Compositional Reasoning"],"permalink":"/ai/review/2025-10-15-SRUM_Fine-Grained_Self-Rewarding_for_Unified_Multimodal_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-15-Spatial_Forcing_Implicit_Spatial_Representation_Alignment_for_Vision-language-action_Model","title":"[논문리뷰] Spatial Forcing: Implicit Spatial Representation Alignment for Vision-language-action Model","excerpt":"이 [arXiv]에 게시한 'Spatial Forcing: Implicit Spatial Representation Alignment for Vision-language-action Model' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-15 13:01:40+0900","lastModifiedAt":"2025-10-15 13:01:40+0900","categories":["Review"],"tags":["Review","Vision-Language-Action Models","Spatial Perception","Implicit Representation Alignment","3D Foundation Models","Robotics","Data Efficiency","Representation Learning"],"permalink":"/ai/review/2025-10-15-Spatial_Forcing_Implicit_Spatial_Representation_Alignment_for_Vision-language-action_Model/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-15-Scaling_Language-Centric_Omnimodal_Representation_Learning","title":"[논문리뷰] Scaling Language-Centric Omnimodal Representation Learning","excerpt":"이 [arXiv]에 게시한 'Scaling Language-Centric Omnimodal Representation Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-15 13:01:40+0900","lastModifiedAt":"2025-10-15 13:01:40+0900","categories":["Review"],"tags":["Review","Multimodal Embeddings","MLLMs","Contrastive Learning","Cross-modal Alignment","Generative Pretraining","Representation Learning","Scaling Laws"],"permalink":"/ai/review/2025-10-15-Scaling_Language-Centric_Omnimodal_Representation_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-15-SAIL-Embedding_Technical_Report_Omni-modal_Embedding_Foundation_Model","title":"[논문리뷰] SAIL-Embedding Technical Report: Omni-modal Embedding Foundation Model","excerpt":"이 [arXiv]에 게시한 'SAIL-Embedding Technical Report: Omni-modal Embedding Foundation Model' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-15 13:01:40+0900","lastModifiedAt":"2025-10-15 13:01:40+0900","categories":["Review"],"tags":["Review","Omni-modal Embedding","Multimodal Learning","Recommendation Systems","Hard Negative Mining","Contrastive Learning","Large Language Models (LLMs)","Data Balancing","Multitask Learning"],"permalink":"/ai/review/2025-10-15-SAIL-Embedding_Technical_Report_Omni-modal_Embedding_Foundation_Model/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-15-Robot_Learning_A_Tutorial","title":"[논문리뷰] Robot Learning: A Tutorial","excerpt":"이 [arXiv]에 게시한 'Robot Learning: A Tutorial' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-15 13:01:40+0900","lastModifiedAt":"2025-10-15 13:01:40+0900","categories":["Review"],"tags":["Review","Robot Learning","Reinforcement Learning","Imitation Learning","Behavioral Cloning","Vision-Language-Action Models","Diffusion Models","Transformers","LeRobot"],"permalink":"/ai/review/2025-10-15-Robot_Learning_A_Tutorial/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-15-ReFIne_A_Framework_for_Trustworthy_Large_Reasoning_Models_with_Reliability_Faithfulness_and_Interpretability","title":"[논문리뷰] ReFIne: A Framework for Trustworthy Large Reasoning Models with Reliability, Faithfulness, and Interpretability","excerpt":"Tsui-Wei Weng이 [arXiv]에 게시한 'ReFIne: A Framework for Trustworthy Large Reasoning Models with Reliability, Faithfulness, and Interpretability' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-15 13:01:40+0900","lastModifiedAt":"2025-10-15 13:01:40+0900","categories":["Review"],"tags":["Review","Trustworthy AI","Large Reasoning Models (LRMs)","Interpretability","Faithfulness","Reliability","Chain-of-Thought (CoT)","Supervised Fine-tuning (SFT)","GRPO"],"permalink":"/ai/review/2025-10-15-ReFIne_A_Framework_for_Trustworthy_Large_Reasoning_Models_with_Reliability_Faithfulness_and_Interpretability/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-15-One_Life_to_Learn_Inferring_Symbolic_World_Models_for_Stochastic_Environments_from_Unguided_Exploration","title":"[논문리뷰] One Life to Learn: Inferring Symbolic World Models for Stochastic Environments from Unguided Exploration","excerpt":"Mohit Bansal이 [arXiv]에 게시한 'One Life to Learn: Inferring Symbolic World Models for Stochastic Environments from Unguided Exploration' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-15 13:01:40+0900","lastModifiedAt":"2025-10-15 13:01:40+0900","categories":["Review"],"tags":["Review","Symbolic World Models","Stochastic Environments","Unguided Exploration","Probabilistic Programming","Law Synthesis","Crafter-OO","Program Synthesis"],"permalink":"/ai/review/2025-10-15-One_Life_to_Learn_Inferring_Symbolic_World_Models_for_Stochastic_Environments_from_Unguided_Exploration/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-15-MLLM_as_a_UI_Judge_Benchmarking_Multimodal_LLMs_for_Predicting_Human_Perception_of_User_Interfaces","title":"[논문리뷰] MLLM as a UI Judge: Benchmarking Multimodal LLMs for Predicting Human Perception of User Interfaces","excerpt":"Sungchul Kim이 [arXiv]에 게시한 'MLLM as a UI Judge: Benchmarking Multimodal LLMs for Predicting Human Perception of User Interfaces' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-15 13:01:40+0900","lastModifiedAt":"2025-10-15 13:01:40+0900","categories":["Review"],"tags":["Review","Multimodal LLMs","UI Evaluation","Human Perception","Benchmarking","UX Research","MLLM-as-a-Judge","Cognitive Factors","Pairwise Comparison"],"permalink":"/ai/review/2025-10-15-MLLM_as_a_UI_Judge_Benchmarking_Multimodal_LLMs_for_Predicting_Human_Perception_of_User_Interfaces/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-15-Memory_as_Action_Autonomous_Context_Curation_for_Long-Horizon_Agentic_Tasks","title":"[논문리뷰] Memory as Action: Autonomous Context Curation for Long-Horizon Agentic Tasks","excerpt":"Xueyuan Lin이 [arXiv]에 게시한 'Memory as Action: Autonomous Context Curation for Long-Horizon Agentic Tasks' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-15 13:01:40+0900","lastModifiedAt":"2025-10-15 13:01:40+0900","categories":["Review"],"tags":["Review","Long-Horizon Tasks","Agentic AI","Context Curation","Working Memory","Reinforcement Learning","Policy Optimization","Large Language Models","Memory-as-Action"],"permalink":"/ai/review/2025-10-15-Memory_as_Action_Autonomous_Context_Curation_for_Long-Horizon_Agentic_Tasks/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-15-LLM_Reasoning_for_Machine_Translation_Synthetic_Data_Generation_over_Thinking_Tokens","title":"[논문리뷰] LLM Reasoning for Machine Translation: Synthetic Data Generation over Thinking Tokens","excerpt":"이 [arXiv]에 게시한 'LLM Reasoning for Machine Translation: Synthetic Data Generation over Thinking Tokens' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-15 13:01:40+0900","lastModifiedAt":"2025-10-15 13:01:40+0900","categories":["Review"],"tags":["Review","Large Language Models (LLMs)","Machine Translation (MT)","Chain-of-Thought (CoT)","Knowledge Distillation","Fine-tuning","Prompt Engineering","Synthetic Data"],"permalink":"/ai/review/2025-10-15-LLM_Reasoning_for_Machine_Translation_Synthetic_Data_Generation_over_Thinking_Tokens/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-15-Information-Preserving_Reformulation_of_Reasoning_Traces_for_Antidistillation","title":"[논문리뷰] Information-Preserving Reformulation of Reasoning Traces for Antidistillation","excerpt":"이 [arXiv]에 게시한 'Information-Preserving Reformulation of Reasoning Traces for Antidistillation' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-15 13:01:40+0900","lastModifiedAt":"2025-10-15 13:01:40+0900","categories":["Review"],"tags":["Review","Antidistillation","Reasoning Traces","Large Language Models","Knowledge Distillation","Information Preservation","Trace Reformulation","Supervised Fine-Tuning"],"permalink":"/ai/review/2025-10-15-Information-Preserving_Reformulation_of_Reasoning_Traces_for_Antidistillation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-15-HoneyBee_Data_Recipes_for_Vision-Language_Reasoners","title":"[논문리뷰] HoneyBee: Data Recipes for Vision-Language Reasoners","excerpt":"이 [arXiv]에 게시한 'HoneyBee: Data Recipes for Vision-Language Reasoners' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-15 13:01:40+0900","lastModifiedAt":"2025-10-15 13:01:40+0900","categories":["Review"],"tags":["Review","Vision-Language Models","Data Curation","Chain-of-Thought","VL Reasoning","Dataset Scaling","Supervised Finetuning","HONEYBEE","Test-Time Scaling"],"permalink":"/ai/review/2025-10-15-HoneyBee_Data_Recipes_for_Vision-Language_Reasoners/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-15-FlashVSR_Towards_Real-Time_Diffusion-Based_Streaming_Video_Super-Resolution","title":"[논문리뷰] FlashVSR: Towards Real-Time Diffusion-Based Streaming Video Super-Resolution","excerpt":"Yihao Liu이 [arXiv]에 게시한 'FlashVSR: Towards Real-Time Diffusion-Based Streaming Video Super-Resolution' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-15 13:01:40+0900","lastModifiedAt":"2025-10-15 13:01:40+0900","categories":["Review"],"tags":["Review","Video Super-Resolution (VSR)","Diffusion Models","Real-time VSR","Streaming VSR","Sparse Attention","Distillation","Conditional Decoder","High-resolution"],"permalink":"/ai/review/2025-10-15-FlashVSR_Towards_Real-Time_Diffusion-Based_Streaming_Video_Super-Resolution/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-15-ExpVid_A_Benchmark_for_Experiment_Video_Understanding_Reasoning","title":"[논문리뷰] ExpVid: A Benchmark for Experiment Video Understanding & Reasoning","excerpt":"이 [arXiv]에 게시한 'ExpVid: A Benchmark for Experiment Video Understanding & Reasoning' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-15 13:01:40+0900","lastModifiedAt":"2025-10-15 13:01:40+0900","categories":["Review"],"tags":["Review","Experiment Video Understanding","Multimodal Large Language Models (MLLMs)","Scientific Reasoning","Benchmark","Wet-Lab Experiments","Procedural Understanding","Fine-grained Perception","Video QA"],"permalink":"/ai/review/2025-10-15-ExpVid_A_Benchmark_for_Experiment_Video_Understanding_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-15-ERA_Transforming_VLMs_into_Embodied_Agents_via_Embodied_Prior_Learning_and_Online_Reinforcement_Learning","title":"[논문리뷰] ERA: Transforming VLMs into Embodied Agents via Embodied Prior Learning and Online Reinforcement Learning","excerpt":"이 [arXiv]에 게시한 'ERA: Transforming VLMs into Embodied Agents via Embodied Prior Learning and Online Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-15 13:01:40+0900","lastModifiedAt":"2025-10-15 13:01:40+0900","categories":["Review"],"tags":["Review","Embodied AI","Vision Language Models (VLMs)","Reinforcement Learning (RL)","Prior Learning","Supervised Fine-tuning (SFT)","Embodied Agents"],"permalink":"/ai/review/2025-10-15-ERA_Transforming_VLMs_into_Embodied_Agents_via_Embodied_Prior_Learning_and_Online_Reinforcement_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-15-Dr.LLM_Dynamic_Layer_Routing_in_LLMs","title":"[논문리뷰] Dr.LLM: Dynamic Layer Routing in LLMs","excerpt":"이 [arXiv]에 게시한 'Dr.LLM: Dynamic Layer Routing in LLMs' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-15 13:01:40+0900","lastModifiedAt":"2025-10-15 13:01:40+0900","categories":["Review"],"tags":["Review","Dynamic Routing","LLMs","Adaptive Depth","Computational Efficiency","Monte Carlo Tree Search (MCTS)","Retrofittable Framework","Supervised Learning","Accuracy Improvement"],"permalink":"/ai/review/2025-10-15-Dr.LLM_Dynamic_Layer_Routing_in_LLMs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-15-DITING_A_Multi-Agent_Evaluation_Framework_for_Benchmarking_Web_Novel_Translation","title":"[논문리뷰] DITING: A Multi-Agent Evaluation Framework for Benchmarking Web Novel Translation","excerpt":"이 [arXiv]에 게시한 'DITING: A Multi-Agent Evaluation Framework for Benchmarking Web Novel Translation' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-15 13:01:40+0900","lastModifiedAt":"2025-10-15 13:01:40+0900","categories":["Review"],"tags":["Review","Machine Translation Evaluation","Large Language Models (LLMs)","Web Novel Translation","Multi-Agent Systems","Cultural Nuance","Benchmark Dataset","Natural Language Generation"],"permalink":"/ai/review/2025-10-15-DITING_A_Multi-Agent_Evaluation_Framework_for_Benchmarking_Web_Novel_Translation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-15-Detect_Anything_via_Next_Point_Prediction","title":"[논문리뷰] Detect Anything via Next Point Prediction","excerpt":"이 [arXiv]에 게시한 'Detect Anything via Next Point Prediction' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-15 13:01:40+0900","lastModifiedAt":"2025-10-15 13:01:40+0900","categories":["Review"],"tags":["Review","Multimodal Large Language Models","Object Detection","Coordinate Prediction","Reinforcement Learning","Supervised Fine-tuning","Visual Perception","Zero-shot Learning","Spatial Reasoning"],"permalink":"/ai/review/2025-10-15-Detect_Anything_via_Next_Point_Prediction/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-15-DeepMMSearch-R1_Empowering_Multimodal_LLMs_in_Multimodal_Web_Search","title":"[논문리뷰] DeepMMSearch-R1: Empowering Multimodal LLMs in Multimodal Web Search","excerpt":"이 [arXiv]에 게시한 'DeepMMSearch-R1: Empowering Multimodal LLMs in Multimodal Web Search' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-15 13:01:40+0900","lastModifiedAt":"2025-10-15 13:01:40+0900","categories":["Review"],"tags":["Review","Multimodal LLM","Web Search","Visual Question Answering","Reinforcement Learning","Image Cropping","Self-Correction","Tool Use"],"permalink":"/ai/review/2025-10-15-DeepMMSearch-R1_Empowering_Multimodal_LLMs_in_Multimodal_Web_Search/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-15-Boundary-Guided_Policy_Optimization_for_Memory-efficient_RL_of_Diffusion_Large_Language_Models","title":"[논문리뷰] Boundary-Guided Policy Optimization for Memory-efficient RL of Diffusion Large Language Models","excerpt":"이 [arXiv]에 게시한 'Boundary-Guided Policy Optimization for Memory-efficient RL of Diffusion Large Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-15 13:01:40+0900","lastModifiedAt":"2025-10-15 13:01:40+0900","categories":["Review"],"tags":["Review","Diffusion Large Language Models","Reinforcement Learning","Memory Efficiency","Monte Carlo Sampling","Log-Likelihood Approximation","Policy Optimization","ELBO"],"permalink":"/ai/review/2025-10-15-Boundary-Guided_Policy_Optimization_for_Memory-efficient_RL_of_Diffusion_Large_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-15-A_Survey_of_Vibe_Coding_with_Large_Language_Models","title":"[논문리뷰] A Survey of Vibe Coding with Large Language Models","excerpt":"이 [arXiv]에 게시한 'A Survey of Vibe Coding with Large Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-15 13:01:40+0900","lastModifiedAt":"2025-10-15 13:01:40+0900","categories":["Review"],"tags":["Review","Vibe Coding","Large Language Models","Coding Agents","Human-AI Collaboration","Software Engineering","Development Models","Context Engineering"],"permalink":"/ai/review/2025-10-15-A_Survey_of_Vibe_Coding_with_Large_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-15-Advancing_End-to-End_Pixel_Space_Generative_Modeling_via_Self-supervised_Pre-training","title":"[논문리뷰] Advancing End-to-End Pixel Space Generative Modeling via Self-supervised Pre-training","excerpt":"이 [arXiv]에 게시한 'Advancing End-to-End Pixel Space Generative Modeling via Self-supervised Pre-training' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-15 13:01:40+0900","lastModifiedAt":"2025-10-15 13:01:40+0900","categories":["Review"],"tags":["Review","Pixel-space Generative Models","Diffusion Models","Consistency Models","Self-supervised Pre-training","End-to-end Training","Image Generation","FID","Representation Learning"],"permalink":"/ai/review/2025-10-15-Advancing_End-to-End_Pixel_Space_Generative_Modeling_via_Self-supervised_Pre-training/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-13-Which_Heads_Matter_for_Reasoning_RL-Guided_KV_Cache_Compression","title":"[논문리뷰] Which Heads Matter for Reasoning? RL-Guided KV Cache Compression","excerpt":"Huan Wang이 [arXiv]에 게시한 'Which Heads Matter for Reasoning? RL-Guided KV Cache Compression' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-13 13:44:18+0900","lastModifiedAt":"2025-10-13 13:44:18+0900","categories":["Review"],"tags":["Review","KV Cache Compression","Large Language Models (LLMs)","Reinforcement Learning (RL)","Reasoning Models","Attention Heads","Chain-of-Thought (CoT)","Memory Efficiency"],"permalink":"/ai/review/2025-10-13-Which_Heads_Matter_for_Reasoning_RL-Guided_KV_Cache_Compression/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-13-Webscale-RL_Automated_Data_Pipeline_for_Scaling_RL_Data_to_Pretraining_Levels","title":"[논문리뷰] Webscale-RL: Automated Data Pipeline for Scaling RL Data to Pretraining Levels","excerpt":"이 [arXiv]에 게시한 'Webscale-RL: Automated Data Pipeline for Scaling RL Data to Pretraining Levels' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-13 13:44:18+0900","lastModifiedAt":"2025-10-13 13:44:18+0900","categories":["Review"],"tags":["Review","Reinforcement Learning (RL)","Large Language Models (LLMs)","Data Pipeline","Web-scale Data","Question-Answering (QA)","Data Generation","Data Diversity","Data Efficiency"],"permalink":"/ai/review/2025-10-13-Webscale-RL_Automated_Data_Pipeline_for_Scaling_RL_Data_to_Pretraining_Levels/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-13-Understanding_DeepResearch_via_Reports","title":"[논문리뷰] Understanding DeepResearch via Reports","excerpt":"Chengen Huang이 [arXiv]에 게시한 'Understanding DeepResearch via Reports' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-13 13:44:18+0900","lastModifiedAt":"2025-10-13 13:44:18+0900","categories":["Review"],"tags":["Review","DeepResearch Agents","LLM-as-a-Judge","Report Evaluation","Agentic AI","Factuality","Redundancy","Research Automation","Benchmark"],"permalink":"/ai/review/2025-10-13-Understanding_DeepResearch_via_Reports/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-13-Thinking_with_Camera_A_Unified_Multimodal_Model_for_Camera-Centric_Understanding_and_Generation","title":"[논문리뷰] Thinking with Camera: A Unified Multimodal Model for Camera-Centric Understanding and Generation","excerpt":"Linyi Jin이 [arXiv]에 게시한 'Thinking with Camera: A Unified Multimodal Model for Camera-Centric Understanding and Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-13 13:44:18+0900","lastModifiedAt":"2025-10-13 13:44:18+0900","categories":["Review"],"tags":["Review","Unified Multimodal Model","Camera-Centric","Image Understanding","Image Generation","Spatial Reasoning","Camera Parameters","Instruction Tuning","Multimodal Spatial Intelligence"],"permalink":"/ai/review/2025-10-13-Thinking_with_Camera_A_Unified_Multimodal_Model_for_Camera-Centric_Understanding_and_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-13-Temporal_Prompting_Matters_Rethinking_Referring_Video_Object_Segmentation","title":"[논문리뷰] Temporal Prompting Matters: Rethinking Referring Video Object Segmentation","excerpt":"Sifei Liu이 [arXiv]에 게시한 'Temporal Prompting Matters: Rethinking Referring Video Object Segmentation' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-13 13:44:18+0900","lastModifiedAt":"2025-10-13 13:44:18+0900","categories":["Review"],"tags":["Review","Referring Video Object Segmentation","Foundation Models","Prompt Engineering","Object Tracking","SAM","Video Analysis","Prompt Preference Learning"],"permalink":"/ai/review/2025-10-13-Temporal_Prompting_Matters_Rethinking_Referring_Video_Object_Segmentation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-13-TC-LoRA_Temporally_Modulated_Conditional_LoRA_for_Adaptive_Diffusion_Control","title":"[논문리뷰] TC-LoRA: Temporally Modulated Conditional LoRA for Adaptive Diffusion Control","excerpt":"Adityan Jothi이 [arXiv]에 게시한 'TC-LoRA: Temporally Modulated Conditional LoRA for Adaptive Diffusion Control' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-13 13:44:18+0900","lastModifiedAt":"2025-10-13 13:44:18+0900","categories":["Review"],"tags":["Review","Diffusion Models","Conditional Generation","LoRA","Hypernetwork","Dynamic Weight Adaptation","Generative AI","Controllable Generation"],"permalink":"/ai/review/2025-10-13-TC-LoRA_Temporally_Modulated_Conditional_LoRA_for_Adaptive_Diffusion_Control/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-13-StreamingVLM_Real-Time_Understanding_for_Infinite_Video_Streams","title":"[논문리뷰] StreamingVLM: Real-Time Understanding for Infinite Video Streams","excerpt":"Kelly Peng이 [arXiv]에 게시한 'StreamingVLM: Real-Time Understanding for Infinite Video Streams' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-13 13:44:18+0900","lastModifiedAt":"2025-10-13 13:44:18+0900","categories":["Review"],"tags":["Review","Video Stream Understanding","Real-Time VLM","Attention Sink","KV Cache Management","Contiguous RoPE","Supervised Fine-tuning","Long-Context Video"],"permalink":"/ai/review/2025-10-13-StreamingVLM_Real-Time_Understanding_for_Infinite_Video_Streams/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-13-StatEval_A_Comprehensive_Benchmark_for_Large_Language_Models_in_Statistics","title":"[논문리뷰] StatEval: A Comprehensive Benchmark for Large Language Models in Statistics","excerpt":"이 [arXiv]에 게시한 'StatEval: A Comprehensive Benchmark for Large Language Models in Statistics' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-13 13:44:18+0900","lastModifiedAt":"2025-10-13 13:44:18+0900","categories":["Review"],"tags":["Review","Statistical Reasoning","LLM Benchmark","Statistics Education","Proof Verification","Multi-agent Pipeline","Automated Extraction","Evaluation Framework"],"permalink":"/ai/review/2025-10-13-StatEval_A_Comprehensive_Benchmark_for_Large_Language_Models_in_Statistics/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-13-Speculative_Jacobi-Denoising_Decoding_for_Accelerating_Autoregressive_Text-to-image_Generation","title":"[논문리뷰] Speculative Jacobi-Denoising Decoding for Accelerating Autoregressive Text-to-image Generation","excerpt":"Han Shi이 [arXiv]에 게시한 'Speculative Jacobi-Denoising Decoding for Accelerating Autoregressive Text-to-image Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-13 13:44:18+0900","lastModifiedAt":"2025-10-13 13:44:18+0900","categories":["Review"],"tags":["Review","Autoregressive Models","Text-to-Image Generation","Inference Acceleration","Jacobi Decoding","Denoising Diffusion Models","Speculative Decoding","Multi-token Prediction","Fine-tuning"],"permalink":"/ai/review/2025-10-13-Speculative_Jacobi-Denoising_Decoding_for_Accelerating_Autoregressive_Text-to-image_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-13-SpaceVista_All-Scale_Visual_Spatial_Reasoning_from_mm_to_km","title":"[논문리뷰] SpaceVista: All-Scale Visual Spatial Reasoning from mm to km","excerpt":"Kaituo Feng이 [arXiv]에 게시한 'SpaceVista: All-Scale Visual Spatial Reasoning from mm to km' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-13 13:44:18+0900","lastModifiedAt":"2025-10-13 13:44:18+0900","categories":["Review"],"tags":["Review","Spatial Reasoning","Multi-Scale Vision","MLLM","Dataset","Scale Experts","Reinforcement Learning","Computer Vision","Robotics"],"permalink":"/ai/review/2025-10-13-SpaceVista_All-Scale_Visual_Spatial_Reasoning_from_mm_to_km/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-13-ReviewerToo_Should_AI_Join_The_Program_Committee_A_Look_At_The_Future_of_Peer_Review","title":"[논문리뷰] ReviewerToo: Should AI Join The Program Committee? A Look At The Future of Peer Review","excerpt":"Christopher Pal이 [arXiv]에 게시한 'ReviewerToo: Should AI Join The Program Committee? A Look At The Future of Peer Review' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-13 13:44:18+0900","lastModifiedAt":"2025-10-13 13:44:18+0900","categories":["Review"],"tags":["Review","Peer Review","AI-Assisted Review","Large Language Models","LLM Agents","Meta-Review","Conference Submissions","Reviewer Personas","Evaluation Metrics"],"permalink":"/ai/review/2025-10-13-ReviewerToo_Should_AI_Join_The_Program_Committee_A_Look_At_The_Future_of_Peer_Review/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-13-R-Horizon_How_Far_Can_Your_Large_Reasoning_Model_Really_Go_in_Breadth_and_Depth","title":"[논문리뷰] R-Horizon: How Far Can Your Large Reasoning Model Really Go in Breadth and Depth?","excerpt":"이 [arXiv]에 게시한 'R-Horizon: How Far Can Your Large Reasoning Model Really Go in Breadth and Depth?' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-13 13:44:18+0900","lastModifiedAt":"2025-10-13 13:44:18+0900","categories":["Review"],"tags":["Review","Long-Horizon Reasoning","Query Composition","Large Reasoning Models","Reinforcement Learning","Benchmark Evaluation","Thinking Budget","Performance Degradation","Chain-of-Thought"],"permalink":"/ai/review/2025-10-13-R-Horizon_How_Far_Can_Your_Large_Reasoning_Model_Really_Go_in_Breadth_and_Depth/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-13-Pseudo2Real_Task_Arithmetic_for_Pseudo-Label_Correction_in_Automatic_Speech_Recognition","title":"[논문리뷰] Pseudo2Real: Task Arithmetic for Pseudo-Label Correction in Automatic Speech Recognition","excerpt":"Shang-Tse Chen이 [arXiv]에 게시한 'Pseudo2Real: Task Arithmetic for Pseudo-Label Correction in Automatic Speech Recognition' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-13 13:44:18+0900","lastModifiedAt":"2025-10-13 13:44:18+0900","categories":["Review"],"tags":["Review","ASR","Pseudo-labeling","Domain Adaptation","Task Arithmetic","Correction Vector","Accent Adaptation","Speaker Clustering","Model Editing"],"permalink":"/ai/review/2025-10-13-Pseudo2Real_Task_Arithmetic_for_Pseudo-Label_Correction_in_Automatic_Speech_Recognition/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-13-Progressive_Gaussian_Transformer_with_Anisotropy-aware_Sampling_for_Open_Vocabulary_Occupancy_Prediction","title":"[논문리뷰] Progressive Gaussian Transformer with Anisotropy-aware Sampling for Open Vocabulary Occupancy Prediction","excerpt":"danxuhk이 [arXiv]에 게시한 'Progressive Gaussian Transformer with Anisotropy-aware Sampling for Open Vocabulary Occupancy Prediction' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-13 13:44:18+0900","lastModifiedAt":"2025-10-13 13:44:18+0900","categories":["Review"],"tags":["Review","3D Occupancy Prediction","Open Vocabulary","Gaussian Splatting","Transformer","Progressive Densification","Anisotropy-aware Sampling","Autonomous Driving"],"permalink":"/ai/review/2025-10-13-Progressive_Gaussian_Transformer_with_Anisotropy-aware_Sampling_for_Open_Vocabulary_Occupancy_Prediction/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-13-PhysToolBench_Benchmarking_Physical_Tool_Understanding_for_MLLMs","title":"[논문리뷰] PhysToolBench: Benchmarking Physical Tool Understanding for MLLMs","excerpt":"Xu Zheng이 [arXiv]에 게시한 'PhysToolBench: Benchmarking Physical Tool Understanding for MLLMs' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-13 13:44:18+0900","lastModifiedAt":"2025-10-13 13:44:18+0900","categories":["Review"],"tags":["Review","Multimodal Large Language Models (MLLMs)","Physical Tool Understanding","Benchmarking","Embodied AI","Visual Question Answering (VQA)","Tool Affordances","Reasoning"],"permalink":"/ai/review/2025-10-13-PhysToolBench_Benchmarking_Physical_Tool_Understanding_for_MLLMs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-13-Parallel_Test-Time_Scaling_for_Latent_Reasoning_Models","title":"[논문리뷰] Parallel Test-Time Scaling for Latent Reasoning Models","excerpt":"이 [arXiv]에 게시한 'Parallel Test-Time Scaling for Latent Reasoning Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-13 13:44:18+0900","lastModifiedAt":"2025-10-13 13:44:18+0900","categories":["Review"],"tags":["Review","Latent Reasoning","Test-Time Scaling","Parallel Inference","Stochastic Sampling","Monte Carlo Dropout","Additive Gaussian Noise","Latent Reward Model","Trajectory Aggregation"],"permalink":"/ai/review/2025-10-13-Parallel_Test-Time_Scaling_for_Latent_Reasoning_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-13-One_Patch_to_Caption_Them_All_A_Unified_Zero-Shot_Captioning_Framework","title":"[논문리뷰] One Patch to Caption Them All: A Unified Zero-Shot Captioning Framework","excerpt":"Giuseppe Amato이 [arXiv]에 게시한 'One Patch to Caption Them All: A Unified Zero-Shot Captioning Framework' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-13 13:44:18+0900","lastModifiedAt":"2025-10-13 13:44:18+0900","categories":["Review"],"tags":["Review","Zero-Shot Captioning","Region-Level Captioning","Vision Transformers","DINOv2","Patch-Centric","Modality Gap Mitigation","Visual-Language Models"],"permalink":"/ai/review/2025-10-13-One_Patch_to_Caption_Them_All_A_Unified_Zero-Shot_Captioning_Framework/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-13-Multimodal_Prompt_Optimization_Why_Not_Leverage_Multiple_Modalities_for_MLLMs","title":"[논문리뷰] Multimodal Prompt Optimization: Why Not Leverage Multiple Modalities for MLLMs","excerpt":"이 [arXiv]에 게시한 'Multimodal Prompt Optimization: Why Not Leverage Multiple Modalities for MLLMs' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-13 13:44:18+0900","lastModifiedAt":"2025-10-13 13:44:18+0900","categories":["Review"],"tags":["Review","Multimodal AI","Prompt Optimization","MLLMs","Bayesian Optimization","Cross-modal Alignment","Prompt Engineering","Generative AI","Exploration-Exploitation"],"permalink":"/ai/review/2025-10-13-Multimodal_Prompt_Optimization_Why_Not_Leverage_Multiple_Modalities_for_MLLMs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-13-MRMR_A_Realistic_and_Expert-Level_Multidisciplinary_Benchmark_for_Reasoning-Intensive_Multimodal_Retrieval","title":"[논문리뷰] MRMR: A Realistic and Expert-Level Multidisciplinary Benchmark for Reasoning-Intensive Multimodal Retrieval","excerpt":"Tingyu Song이 [arXiv]에 게시한 'MRMR: A Realistic and Expert-Level Multidisciplinary Benchmark for Reasoning-Intensive Multimodal Retrieval' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-13 13:44:18+0900","lastModifiedAt":"2025-10-13 13:44:18+0900","categories":["Review"],"tags":["Review","Multimodal Retrieval","Benchmark","Reasoning","Multidisciplinary","Expert-Level","Image-Text Interleaving","Contradiction Retrieval"],"permalink":"/ai/review/2025-10-13-MRMR_A_Realistic_and_Expert-Level_Multidisciplinary_Benchmark_for_Reasoning-Intensive_Multimodal_Retrieval/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-13-Mitigating_Overthinking_through_Reasoning_Shaping","title":"[논문리뷰] Mitigating Overthinking through Reasoning Shaping","excerpt":"Wen Luo이 [arXiv]에 게시한 'Mitigating Overthinking through Reasoning Shaping' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-13 13:44:18+0900","lastModifiedAt":"2025-10-13 13:44:18+0900","categories":["Review"],"tags":["Review","Large Reasoning Models (LRMs)","RLVR","Overthinking Mitigation","Reasoning Shaping","Segment-level Penalization","Computational Efficiency","Training Stability","Length-aware Weighting"],"permalink":"/ai/review/2025-10-13-Mitigating_Overthinking_through_Reasoning_Shaping/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-13-KORMo_Korean_Open_Reasoning_Model_for_Everyone","title":"[논문리뷰] KORMo: Korean Open Reasoning Model for Everyone","excerpt":"이 [arXiv]에 게시한 'KORMo: Korean Open Reasoning Model for Everyone' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-13 13:44:18+0900","lastModifiedAt":"2025-10-13 13:44:18+0900","categories":["Review"],"tags":["Review","Large Language Model","Korean","Bilingual","Synthetic Data","Fully Open Model","Tokenizer","Reasoning","Pretraining","Instruction Tuning"],"permalink":"/ai/review/2025-10-13-KORMo_Korean_Open_Reasoning_Model_for_Everyone/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-13-Instant4D_4D_Gaussian_Splatting_in_Minutes","title":"[논문리뷰] Instant4D: 4D Gaussian Splatting in Minutes","excerpt":"Li Lu이 [arXiv]에 게시한 'Instant4D: 4D Gaussian Splatting in Minutes' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-13 13:44:18+0900","lastModifiedAt":"2025-10-13 13:44:18+0900","categories":["Review"],"tags":["Review","4D Gaussian Splatting","Dynamic View Synthesis","Monocular Reconstruction","Visual SLAM","Grid Pruning","Real-time Rendering","GPU Memory Optimization"],"permalink":"/ai/review/2025-10-13-Instant4D_4D_Gaussian_Splatting_in_Minutes/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-13-Hybrid-grained_Feature_Aggregation_with_Coarse-to-fine_Language_Guidance_for_Self-supervised_Monocular_Depth_Estimation","title":"[논문리뷰] Hybrid-grained Feature Aggregation with Coarse-to-fine Language Guidance for Self-supervised Monocular Depth Estimation","excerpt":"Zekun Qi이 [arXiv]에 게시한 'Hybrid-grained Feature Aggregation with Coarse-to-fine Language Guidance for Self-supervised Monocular Depth Estimation' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-13 13:44:18+0900","lastModifiedAt":"2025-10-13 13:44:18+0900","categories":["Review"],"tags":["Review","Self-supervised Monocular Depth Estimation","Foundation Models","CLIP","DINO","Language Guidance","Coarse-to-fine Learning","Feature Aggregation","3D Perception"],"permalink":"/ai/review/2025-10-13-Hybrid-grained_Feature_Aggregation_with_Coarse-to-fine_Language_Guidance_for_Self-supervised_Monocular_Depth_Estimation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-13-GTAlign_Game-Theoretic_Alignment_of_LLM_Assistants_for_Mutual_Welfare","title":"[논문리뷰] GTAlign: Game-Theoretic Alignment of LLM Assistants for Mutual Welfare","excerpt":"이 [arXiv]에 게시한 'GTAlign: Game-Theoretic Alignment of LLM Assistants for Mutual Welfare' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-13 13:44:18+0900","lastModifiedAt":"2025-10-13 13:44:18+0900","categories":["Review"],"tags":["Review","Large Language Models","LLM Alignment","Game Theory","Reinforcement Learning","Mutual Welfare","Payoff Matrix","Strategic Decision Making","Human-AI Interaction"],"permalink":"/ai/review/2025-10-13-GTAlign_Game-Theoretic_Alignment_of_LLM_Assistants_for_Mutual_Welfare/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-13-Dyna-Mind_Learning_to_Simulate_from_Experience_for_Better_AI_Agents","title":"[논문리뷰] Dyna-Mind: Learning to Simulate from Experience for Better AI Agents","excerpt":"Qianhui Wu이 [arXiv]에 게시한 'Dyna-Mind: Learning to Simulate from Experience for Better AI Agents' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-13 13:44:18+0900","lastModifiedAt":"2025-10-13 13:44:18+0900","categories":["Review"],"tags":["Review","AI Agents","Reinforcement Learning","World Models","Simulation","Reasoning","Language Models","Planning","Interactive AI"],"permalink":"/ai/review/2025-10-13-Dyna-Mind_Learning_to_Simulate_from_Experience_for_Better_AI_Agents/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-13-Dont_Waste_Mistakes_Leveraging_Negative_RL-Groups_via_Confidence_Reweighting","title":"[논문리뷰] Don't Waste Mistakes: Leveraging Negative RL-Groups via Confidence Reweighting","excerpt":"Julia Kempe이 [arXiv]에 게시한 'Don't Waste Mistakes: Leveraging Negative RL-Groups via Confidence Reweighting' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-13 13:44:18+0900","lastModifiedAt":"2025-10-13 13:44:18+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","Large Language Models","Reasoning Tasks","GRPO","Negative Samples","Reward Modeling","Confidence Reweighting","Mathematical Reasoning"],"permalink":"/ai/review/2025-10-13-Dont_Waste_Mistakes_Leveraging_Negative_RL-Groups_via_Confidence_Reweighting/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-13-DISCO_Diversifying_Sample_Condensation_for_Efficient_Model_Evaluation","title":"[논문리뷰] DISCO: Diversifying Sample Condensation for Efficient Model Evaluation","excerpt":"이 [arXiv]에 게시한 'DISCO: Diversifying Sample Condensation for Efficient Model Evaluation' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-13 13:44:18+0900","lastModifiedAt":"2025-10-13 13:44:18+0900","categories":["Review"],"tags":["Review","Efficient Evaluation","Sample Condensation","Model Disagreement","Predictive Diversity","Performance Prediction","Large Language Models","Model Signatures","Meta-modeling"],"permalink":"/ai/review/2025-10-13-DISCO_Diversifying_Sample_Condensation_for_Efficient_Model_Evaluation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-13-D2E_Scaling_Vision-Action_Pretraining_on_Desktop_Data_for_Transfer_to_Embodied_AI","title":"[논문리뷰] D2E: Scaling Vision-Action Pretraining on Desktop Data for Transfer to Embodied AI","excerpt":"Haebin Seong이 [arXiv]에 게시한 'D2E: Scaling Vision-Action Pretraining on Desktop Data for Transfer to Embodied AI' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-13 13:44:18+0900","lastModifiedAt":"2025-10-13 13:44:18+0900","categories":["Review"],"tags":["Review","Embodied AI","Vision-Action Pretraining","Desktop Data","Inverse Dynamics Model (IDM)","Pseudo-labeling","Robotics","Generalization","Data Compression"],"permalink":"/ai/review/2025-10-13-D2E_Scaling_Vision-Action_Pretraining_on_Desktop_Data_for_Transfer_to_Embodied_AI/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-13-Bridging_Reasoning_to_Learning_Unmasking_Illusions_using_Complexity_Out_of_Distribution_Generalization","title":"[논문리뷰] Bridging Reasoning to Learning: Unmasking Illusions using Complexity Out of Distribution Generalization","excerpt":"Mahdi Ghaznavai이 [arXiv]에 게시한 'Bridging Reasoning to Learning: Unmasking Illusions using Complexity Out of Distribution Generalization' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-13 13:44:18+0900","lastModifiedAt":"2025-10-13 13:44:18+0900","categories":["Review"],"tags":["Review","Complexity OoD Generalization","System-1 Thinking","System-2 Reasoning","Kolmogorov Complexity","Inductive Biases","Large Language Models (LLMs)","Reasoning Evaluation"],"permalink":"/ai/review/2025-10-13-Bridging_Reasoning_to_Learning_Unmasking_Illusions_using_Complexity_Out_of_Distribution_Generalization/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-13-BigCodeArena_Unveiling_More_Reliable_Human_Preferences_in_Code_Generation_via_Execution","title":"[논문리뷰] BigCodeArena: Unveiling More Reliable Human Preferences in Code Generation via Execution","excerpt":"Hange Liu이 [arXiv]에 게시한 'BigCodeArena: Unveiling More Reliable Human Preferences in Code Generation via Execution' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-13 13:44:18+0900","lastModifiedAt":"2025-10-13 13:44:18+0900","categories":["Review"],"tags":["Review","Code Generation","Human Preference","LLM Evaluation","Execution Feedback","Benchmarking","Crowdsourcing","Software Engineering","Large Language Models"],"permalink":"/ai/review/2025-10-13-BigCodeArena_Unveiling_More_Reliable_Human_Preferences_in_Code_Generation_via_Execution/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-13-Better_Together_Leveraging_Unpaired_Multimodal_Data_for_Stronger_Unimodal_Models","title":"[논문리뷰] Better Together: Leveraging Unpaired Multimodal Data for Stronger Unimodal Models","excerpt":"이 [arXiv]에 게시한 'Better Together: Leveraging Unpaired Multimodal Data for Stronger Unimodal Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-13 13:44:18+0900","lastModifiedAt":"2025-10-13 13:44:18+0900","categories":["Review"],"tags":["Review","Unpaired Multimodal Learning","Unimodal Representation","Weight Sharing","Cross-modal Transfer","Fisher Information","Self-supervised Learning","Multimodal Neurons","Data Efficiency"],"permalink":"/ai/review/2025-10-13-Better_Together_Leveraging_Unpaired_Multimodal_Data_for_Stronger_Unimodal_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-13-A_Goal_Without_a_Plan_Is_Just_a_Wish_Efficient_and_Effective_Global_Planner_Training_for_Long-Horizon_Agent_Tasks","title":"[논문리뷰] A Goal Without a Plan Is Just a Wish: Efficient and Effective Global Planner Training for Long-Horizon Agent Tasks","excerpt":"Fanchao Qi이 [arXiv]에 게시한 'A Goal Without a Plan Is Just a Wish: Efficient and Effective Global Planner Training for Long-Horizon Agent Tasks' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-13 13:44:18+0900","lastModifiedAt":"2025-10-13 13:44:18+0900","categories":["Review"],"tags":["Review","Long-Horizon Tasks","LLM Agents","Global Planning","Reinforcement Learning","Supervised Fine-tuning","Homologous Consensus Filtering","Executor Capability Gain Reward","Plan-and-Execute"],"permalink":"/ai/review/2025-10-13-A_Goal_Without_a_Plan_Is_Just_a_Wish_Efficient_and_Effective_Global_Planner_Training_for_Long-Horizon_Agent_Tasks/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-13-AutoPR_Lets_Automate_Your_Academic_Promotion","title":"[논문리뷰] AutoPR: Let's Automate Your Academic Promotion!","excerpt":"Yixin Yuan이 [arXiv]에 게시한 'AutoPR: Let's Automate Your Academic Promotion!' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-13 13:44:18+0900","lastModifiedAt":"2025-10-13 13:44:18+0900","categories":["Review"],"tags":["Review","Academic Promotion","Large Language Models","Multi-Agent Systems","Scholarly Communication","Multimodal Processing","Benchmark","Content Generation","Social Media Marketing"],"permalink":"/ai/review/2025-10-13-AutoPR_Lets_Automate_Your_Academic_Promotion/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-13-ARES_Multimodal_Adaptive_Reasoning_via_Difficulty-Aware_Token-Level_Entropy_Shaping","title":"[논문리뷰] ARES: Multimodal Adaptive Reasoning via Difficulty-Aware Token-Level Entropy Shaping","excerpt":"Wenbo Hu이 [arXiv]에 게시한 'ARES: Multimodal Adaptive Reasoning via Difficulty-Aware Token-Level Entropy Shaping' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-13 13:44:18+0900","lastModifiedAt":"2025-10-13 13:44:18+0900","categories":["Review"],"tags":["Review","Multimodal Reasoning","Adaptive Learning","Reinforcement Learning","Entropy Shaping","Difficulty-Aware","Chain-of-Thought","Token-Level Analysis"],"permalink":"/ai/review/2025-10-13-ARES_Multimodal_Adaptive_Reasoning_via_Difficulty-Aware_Token-Level_Entropy_Shaping/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-13-Adaptive_Attacks_on_Trusted_Monitors_Subvert_AI_Control_Protocols","title":"[논문리뷰] Adaptive Attacks on Trusted Monitors Subvert AI Control Protocols","excerpt":"Maksym Andriushchenko이 [arXiv]에 게시한 'Adaptive Attacks on Trusted Monitors Subvert AI Control Protocols' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-13 13:44:18+0900","lastModifiedAt":"2025-10-13 13:44:18+0900","categories":["Review"],"tags":["Review","AI Control Protocols","LLM Monitors","Adaptive Attacks","Prompt Injection","Jailbreaking","Red Teaming","Scalable Oversight"],"permalink":"/ai/review/2025-10-13-Adaptive_Attacks_on_Trusted_Monitors_Subvert_AI_Control_Protocols/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-13-ACE_Attribution-Controlled_Knowledge_Editing_for_Multi-hop_Factual_Recall","title":"[논문리뷰] ACE: Attribution-Controlled Knowledge Editing for Multi-hop Factual Recall","excerpt":"Jiaqi Tang이 [arXiv]에 게시한 'ACE: Attribution-Controlled Knowledge Editing for Multi-hop Factual Recall' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-13 13:44:18+0900","lastModifiedAt":"2025-10-13 13:44:18+0900","categories":["Review"],"tags":["Review","Knowledge Editing","LLMs","Multi-hop Reasoning","Mechanistic Interpretability","Neuron-level Attribution","Factual Recall","Transformer Networks"],"permalink":"/ai/review/2025-10-13-ACE_Attribution-Controlled_Knowledge_Editing_for_Multi-hop_Factual_Recall/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-When_Thoughts_Meet_Facts_Reusable_Reasoning_for_Long-Context_LMs","title":"[논문리뷰] When Thoughts Meet Facts: Reusable Reasoning for Long-Context LMs","excerpt":"이 [arXiv]에 게시한 'When Thoughts Meet Facts: Reusable Reasoning for Long-Context LMs' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","Long-Context LMs","Multi-hop Reasoning","Thought Templates","Retrieval-Augmented Generation","Natural Language Feedback","Knowledge-intensive QA","Reasoning Reuse"],"permalink":"/ai/review/2025-10-10-When_Thoughts_Meet_Facts_Reusable_Reasoning_for_Long-Context_LMs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-VideoCanvas_Unified_Video_Completion_from_Arbitrary_Spatiotemporal_Patches_via_In-Context_Conditioning","title":"[논문리뷰] VideoCanvas: Unified Video Completion from Arbitrary Spatiotemporal Patches via In-Context Conditioning","excerpt":"Quande Liu이 [arXiv]에 게시한 'VideoCanvas: Unified Video Completion from Arbitrary Spatiotemporal Patches via In-Context Conditioning' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","Video Completion","Spatio-Temporal Control","In-Context Conditioning","Video Diffusion Models","RoPE Interpolation","VAE","Unified Framework","Video Generation"],"permalink":"/ai/review/2025-10-10-VideoCanvas_Unified_Video_Completion_from_Arbitrary_Spatiotemporal_Patches_via_In-Context_Conditioning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-UP2You_Fast_Reconstruction_of_Yourself_from_Unconstrained_Photo_Collections","title":"[논문리뷰] UP2You: Fast Reconstruction of Yourself from Unconstrained Photo Collections","excerpt":"Boqian Li이 [arXiv]에 게시한 'UP2You: Fast Reconstruction of Yourself from Unconstrained Photo Collections' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","3D Human Reconstruction","Unconstrained Photos","Data Rectifier","Multi-View Generation","Pose-Correlated Feature Aggregation","SMPL-X","Diffusion Models","Virtual Try-On"],"permalink":"/ai/review/2025-10-10-UP2You_Fast_Reconstruction_of_Yourself_from_Unconstrained_Photo_Collections/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-UniVideo_Unified_Understanding_Generation_and_Editing_for_Videos","title":"[논문리뷰] UniVideo: Unified Understanding, Generation, and Editing for Videos","excerpt":"Xintao Wang이 [arXiv]에 게시한 'UniVideo: Unified Understanding, Generation, and Editing for Videos' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","Unified Multimodal Model","Video Generation","Video Editing","MLLM","Diffusion Transformer","In-Context Learning","Zero-shot Generalization","Multimodal AI"],"permalink":"/ai/review/2025-10-10-UniVideo_Unified_Understanding_Generation_and_Editing_for_Videos/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-UniMMVSR_A_Unified_Multi-Modal_Framework_for_Cascaded_Video_Super-Resolution","title":"[논문리뷰] UniMMVSR: A Unified Multi-Modal Framework for Cascaded Video Super-Resolution","excerpt":"이 [arXiv]에 게시한 'UniMMVSR: A Unified Multi-Modal Framework for Cascaded Video Super-Resolution' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","Video Super-Resolution","Multi-Modal Generation","Latent Diffusion Models","Cascaded Framework","Condition Injection","Text-to-Video","Video Editing","4K Video"],"permalink":"/ai/review/2025-10-10-UniMMVSR_A_Unified_Multi-Modal_Framework_for_Cascaded_Video_Super-Resolution/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-UNIDOC-BENCH_A_Unified_Benchmark_for_Document-Centric_Multimodal_RAG","title":"[논문리뷰] UNIDOC-BENCH: A Unified Benchmark for Document-Centric Multimodal RAG","excerpt":"이 [arXiv]에 게시한 'UNIDOC-BENCH: A Unified Benchmark for Document-Centric Multimodal RAG' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","Multimodal RAG","Document AI","Benchmark","Information Retrieval","Large Language Models","Multimodal Embeddings","PDF Processing","Question Answering"],"permalink":"/ai/review/2025-10-10-UNIDOC-BENCH_A_Unified_Benchmark_for_Document-Centric_Multimodal_RAG/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-Training-Free_Group_Relative_Policy_Optimization","title":"[논문리뷰] Training-Free Group Relative Policy Optimization","excerpt":"이 [arXiv]에 게시한 'Training-Free Group Relative Policy Optimization' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","LLM Agents","Reinforcement Learning","Parameter-Free Optimization","Experiential Knowledge","Token Prior","Group Relative Policy Optimization","In-Context Learning","Cost-Effective AI"],"permalink":"/ai/review/2025-10-10-Training-Free_Group_Relative_Policy_Optimization/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-Towards_Scalable_and_Consistent_3D_Editing","title":"[논문리뷰] Towards Scalable and Consistent 3D Editing","excerpt":"Pan Zhou이 [arXiv]에 게시한 'Towards Scalable and Consistent 3D Editing' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","3D Editing","Generative Models","Transformer Architecture","Dataset Generation","Multimodal Learning","Conditional Generation","Image-to-3D"],"permalink":"/ai/review/2025-10-10-Towards_Scalable_and_Consistent_3D_Editing/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-The_Alignment_Waltz_Jointly_Training_Agents_to_Collaborate_for_Safety","title":"[논문리뷰] The Alignment Waltz: Jointly Training Agents to Collaborate for Safety","excerpt":"이 [arXiv]에 게시한 'The Alignment Waltz: Jointly Training Agents to Collaborate for Safety' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","LLM Safety","Multi-agent Reinforcement Learning","Safety Alignment","Overrefusal","Adversarial Attacks","Feedback Agent","Conversation Agent","Dynamic Improvement Reward"],"permalink":"/ai/review/2025-10-10-The_Alignment_Waltz_Jointly_Training_Agents_to_Collaborate_for_Safety/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-Taming_Text-to-Sounding_Video_Generation_via_Advanced_Modality_Condition_and_Interaction","title":"[논문리뷰] Taming Text-to-Sounding Video Generation via Advanced Modality Condition and Interaction","excerpt":"이 [arXiv]에 게시한 'Taming Text-to-Sounding Video Generation via Advanced Modality Condition and Interaction' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","Text-to-Sounding Video Generation","Diffusion Models","Dual-tower Architecture","Cross-modal Fusion","Visual Grounding","Hierarchical Captioning","Cross-Attention"],"permalink":"/ai/review/2025-10-10-Taming_Text-to-Sounding_Video_Generation_via_Advanced_Modality_Condition_and_Interaction/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-SViM3D_Stable_Video_Material_Diffusion_for_Single_Image_3D_Generation","title":"[논문리뷰] SViM3D: Stable Video Material Diffusion for Single Image 3D Generation","excerpt":"이 [arXiv]에 게시한 'SViM3D: Stable Video Material Diffusion for Single Image 3D Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","Single Image 3D Reconstruction","Material Prediction","Video Diffusion Models","Physically Based Rendering (PBR)","Inverse Rendering","Novel View Synthesis","Camera Control","Latent Diffusion"],"permalink":"/ai/review/2025-10-10-SViM3D_Stable_Video_Material_Diffusion_for_Single_Image_3D_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-Search-R3_Unifying_Reasoning_and_Embedding_Generation_in_Large_Language_Models","title":"[논문리뷰] Search-R3: Unifying Reasoning and Embedding Generation in Large Language Models","excerpt":"James Cheng이 [arXiv]에 게시한 'Search-R3: Unifying Reasoning and Embedding Generation in Large Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","Large Language Models","Reinforcement Learning","Sentence Embedding","Retrieval-Augmented Generation","Chain-of-Thought","Information Retrieval","Supervised Fine-tuning"],"permalink":"/ai/review/2025-10-10-Search-R3_Unifying_Reasoning_and_Embedding_Generation_in_Large_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-SciVideoBench_Benchmarking_Scientific_Video_Reasoning_in_Large_Multimodal_Models","title":"[논문리뷰] SciVideoBench: Benchmarking Scientific Video Reasoning in Large Multimodal Models","excerpt":"Mohit Bansal이 [arXiv]에 게시한 'SciVideoBench: Benchmarking Scientific Video Reasoning in Large Multimodal Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","Video Reasoning","Multimodal AI","Scientific Research","Large Multimodal Models","Benchmark","Quantitative Reasoning","Domain Knowledge","Visual Grounding"],"permalink":"/ai/review/2025-10-10-SciVideoBench_Benchmarking_Scientific_Video_Reasoning_in_Large_Multimodal_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-Reinforcing_Diffusion_Models_by_Direct_Group_Preference_Optimization","title":"[논문리뷰] Reinforcing Diffusion Models by Direct Group Preference Optimization","excerpt":"Jing Tang이 [arXiv]에 게시한 'Reinforcing Diffusion Models by Direct Group Preference Optimization' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","Diffusion Models","Reinforcement Learning","Preference Optimization","Group Preference","Direct Preference Optimization","ODE Samplers","Efficient Training"],"permalink":"/ai/review/2025-10-10-Reinforcing_Diffusion_Models_by_Direct_Group_Preference_Optimization/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-Recycling_Pretrained_Checkpoints_Orthogonal_Growth_of_Mixture-of-Experts_for_Efficient_Large_Language_Model_Pre-Training","title":"[논문리뷰] Recycling Pretrained Checkpoints: Orthogonal Growth of Mixture-of-Experts for Efficient Large Language Model Pre-Training","excerpt":"Peng Cheng이 [arXiv]에 게시한 'Recycling Pretrained Checkpoints: Orthogonal Growth of Mixture-of-Experts for Efficient Large Language Model Pre-Training' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","Mixture-of-Experts","Large Language Models","Checkpoint Recycling","Model Growth","Efficient Pretraining","Depth Growth","Width Growth","Sunk Cost"],"permalink":"/ai/review/2025-10-10-Recycling_Pretrained_Checkpoints_Orthogonal_Growth_of_Mixture-of-Experts_for_Efficient_Large_Language_Model_Pre-Training/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-R2RGEN_Real-to-Real_3D_Data_Generation_for_Spatially_Generalized_Manipulation","title":"[논문리뷰] R2RGEN: Real-to-Real 3D Data Generation for Spatially Generalized Manipulation","excerpt":"Zheng Zhu이 [arXiv]에 게시한 'R2RGEN: Real-to-Real 3D Data Generation for Spatially Generalized Manipulation' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","Robotic Manipulation","Data Augmentation","Spatial Generalization","3D Data Generation","Imitation Learning","Point Cloud","Real-to-Real","Mobile Manipulation"],"permalink":"/ai/review/2025-10-10-R2RGEN_Real-to-Real_3D_Data_Generation_for_Spatially_Generalized_Manipulation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-NewtonBench_Benchmarking_Generalizable_Scientific_Law_Discovery_in_LLM_Agents","title":"[논문리뷰] NewtonBench: Benchmarking Generalizable Scientific Law Discovery in LLM Agents","excerpt":"Baixuan Xu이 [arXiv]에 게시한 'NewtonBench: Benchmarking Generalizable Scientific Law Discovery in LLM Agents' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","LLM Agents","Scientific Law Discovery","Benchmarking","Metaphysical Shifts","Interactive Environments","Exploration-Exploitation","Tool Use"],"permalink":"/ai/review/2025-10-10-NewtonBench_Benchmarking_Generalizable_Scientific_Law_Discovery_in_LLM_Agents/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-NaViL_Rethinking_Scaling_Properties_of_Native_Multimodal_Large_Language_Models_under_Data_Constraints","title":"[논문리뷰] NaViL: Rethinking Scaling Properties of Native Multimodal Large Language Models under Data Constraints","excerpt":"이 [arXiv]에 게시한 'NaViL: Rethinking Scaling Properties of Native Multimodal Large Language Models under Data Constraints' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","Multimodal Large Language Models","Native MLLMs","Scaling Laws","Data Constraints","Visual Encoder","LLM Initialization","Mixture-of-Experts","End-to-end Training"],"permalink":"/ai/review/2025-10-10-NaViL_Rethinking_Scaling_Properties_of_Native_Multimodal_Large_Language_Models_under_Data_Constraints/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-MM-HELIX_Boosting_Multimodal_Long-Chain_Reflective_Reasoning_with_Holistic_Platform_and_Adaptive_Hybrid_Policy_Optimization","title":"[논문리뷰] MM-HELIX: Boosting Multimodal Long-Chain Reflective Reasoning with Holistic Platform and Adaptive Hybrid Policy Optimization","excerpt":"vanilla1116이 [arXiv]에 게시한 'MM-HELIX: Boosting Multimodal Long-Chain Reflective Reasoning with Holistic Platform and Adaptive Hybrid Policy Optimization' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","Multimodal LLMs","Reflective Reasoning","Long-Chain Reasoning","Benchmark","Policy Optimization","Data Generation","Reinforcement Learning","Backtracking"],"permalink":"/ai/review/2025-10-10-MM-HELIX_Boosting_Multimodal_Long-Chain_Reflective_Reasoning_with_Holistic_Platform_and_Adaptive_Hybrid_Policy_Optimization/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-Meta-Awareness_Enhances_Reasoning_Models_Self-Alignment_Reinforcement_Learning","title":"[논문리뷰] Meta-Awareness Enhances Reasoning Models: Self-Alignment Reinforcement Learning","excerpt":"이 [arXiv]에 게시한 'Meta-Awareness Enhances Reasoning Models: Self-Alignment Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","Meta-Awareness","Reinforcement Learning","Self-Alignment","LLM Reasoning","Training Efficiency","Generalization","Predictive Gating"],"permalink":"/ai/review/2025-10-10-Meta-Awareness_Enhances_Reasoning_Models_Self-Alignment_Reinforcement_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-Memory_Retrieval_and_Consolidation_in_Large_Language_Models_through_Function_Tokens","title":"[논문리뷰] Memory Retrieval and Consolidation in Large Language Models through Function Tokens","excerpt":"이 [arXiv]에 게시한 'Memory Retrieval and Consolidation in Large Language Models through Function Tokens' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","Large Language Models","LLM Interpretability","Function Tokens","Memory Retrieval","Memory Consolidation","Sparse Autoencoders","Pre-training"],"permalink":"/ai/review/2025-10-10-Memory_Retrieval_and_Consolidation_in_Large_Language_Models_through_Function_Tokens/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-MemMamba_Rethinking_Memory_Patterns_in_State_Space_Model","title":"[논문리뷰] MemMamba: Rethinking Memory Patterns in State Space Model","excerpt":"Xiao Sun이 [arXiv]에 게시한 'MemMamba: Rethinking Memory Patterns in State Space Model' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","State Space Models","Mamba","Long-sequence modeling","Memory decay","State summarization","Cross-layer attention","Perplexity","Linear complexity"],"permalink":"/ai/review/2025-10-10-MemMamba_Rethinking_Memory_Patterns_in_State_Space_Model/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-Low-probability_Tokens_Sustain_Exploration_in_Reinforcement_Learning_with_Verifiable_Reward","title":"[논문리뷰] Low-probability Tokens Sustain Exploration in Reinforcement Learning with Verifiable Reward","excerpt":"이 [arXiv]에 게시한 'Low-probability Tokens Sustain Exploration in Reinforcement Learning with Verifiable Reward' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","LLM Exploration","Verifiable Reward","Low-Probability Regularization","Reasoning Sparks","Policy Entropy","KL Divergence","Mathematical Reasoning"],"permalink":"/ai/review/2025-10-10-Low-probability_Tokens_Sustain_Exploration_in_Reinforcement_Learning_with_Verifiable_Reward/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-LongRM_Revealing_and_Unlocking_the_Context_Boundary_of_Reward_Modeling","title":"[논문리뷰] LongRM: Revealing and Unlocking the Context Boundary of Reward Modeling","excerpt":"이 [arXiv]에 게시한 'LongRM: Revealing and Unlocking the Context Boundary of Reward Modeling' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","Reward Model","Long Context","LLM Alignment","Multi-stage Training","Context Window Scaling","Preference Learning","Long-RewardBench"],"permalink":"/ai/review/2025-10-10-LongRM_Revealing_and_Unlocking_the_Context_Boundary_of_Reward_Modeling/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-LLMs_Learn_to_Deceive_Unintentionally_Emergent_Misalignment_in_Dishonesty_from_Misaligned_Samples_to_Biased_Human-AI_Interactions","title":"[논문리뷰] LLMs Learn to Deceive Unintentionally: Emergent Misalignment in Dishonesty from Misaligned Samples to Biased Human-AI Interactions","excerpt":"이 [arXiv]에 게시한 'LLMs Learn to Deceive Unintentionally: Emergent Misalignment in Dishonesty from Misaligned Samples to Biased Human-AI Interactions' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","LLM Misalignment","Dishonesty","Deception","Finetuning","Human-AI Interaction","Biased Feedback","Emergent Behavior"],"permalink":"/ai/review/2025-10-10-LLMs_Learn_to_Deceive_Unintentionally_Emergent_Misalignment_in_Dishonesty_from_Misaligned_Samples_to_Biased_Human-AI_Interactions/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-Learning_to_Route_LLMs_from_Bandit_Feedback_One_Policy_Many_Trade-offs","title":"[논문리뷰] Learning to Route LLMs from Bandit Feedback: One Policy, Many Trade-offs","excerpt":"Franck Dernoncourt이 [arXiv]에 게시한 'Learning to Route LLMs from Bandit Feedback: One Policy, Many Trade-offs' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","LLM Routing","Contextual Bandits","Bandit Feedback","Multi-objective Optimization","Preference-tuning","Policy Gradient","Cost-efficiency"],"permalink":"/ai/review/2025-10-10-Learning_to_Route_LLMs_from_Bandit_Feedback_One_Policy_Many_Trade-offs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-Learning_on_the_Job_An_Experience-Driven_Self-Evolving_Agent_for_Long-Horizon_Tasks","title":"[논문리뷰] Learning on the Job: An Experience-Driven Self-Evolving Agent for Long-Horizon Tasks","excerpt":"이 [arXiv]에 게시한 'Learning on the Job: An Experience-Driven Self-Evolving Agent for Long-Horizon Tasks' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","LLM Agents","Continuous Learning","Self-Evolving","Memory Module","Long-Horizon Planning","Productivity Tasks","Test-Time Learning","Experience Replay"],"permalink":"/ai/review/2025-10-10-Learning_on_the_Job_An_Experience-Driven_Self-Evolving_Agent_for_Long-Horizon_Tasks/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-Large_Scale_Diffusion_Distillation_via_Score-Regularized_Continuous-Time_Consistency","title":"[논문리뷰] Large Scale Diffusion Distillation via Score-Regularized Continuous-Time Consistency","excerpt":"Jintao Zhang이 [arXiv]에 게시한 'Large Scale Diffusion Distillation via Score-Regularized Continuous-Time Consistency' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","Diffusion Distillation","Consistency Models","Score Regularization","Large-Scale Generative Models","Text-to-Image","Text-to-Video","Model Acceleration","JVP"],"permalink":"/ai/review/2025-10-10-Large_Scale_Diffusion_Distillation_via_Score-Regularized_Continuous-Time_Consistency/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-InstructX_Towards_Unified_Visual_Editing_with_MLLM_Guidance","title":"[논문리뷰] InstructX: Towards Unified Visual Editing with MLLM Guidance","excerpt":"Xinghui Li이 [arXiv]에 게시한 'InstructX: Towards Unified Visual Editing with MLLM Guidance' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","Visual Editing","MLLM Guidance","Diffusion Models","Image Editing","Video Editing","Unified Framework","Multimodal AI","Instruction-based Editing"],"permalink":"/ai/review/2025-10-10-InstructX_Towards_Unified_Visual_Editing_with_MLLM_Guidance/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-Hybrid_Reinforcement_When_Reward_Is_Sparse_Its_Better_to_Be_Dense","title":"[논문리뷰] Hybrid Reinforcement: When Reward Is Sparse, It's Better to Be Dense","excerpt":"이 [arXiv]에 게시한 'Hybrid Reinforcement: When Reward Is Sparse, It's Better to Be Dense' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","Reward Modeling","Large Language Models (LLMs)","Mathematical Reasoning","Sparse Rewards","Dense Rewards","Hybrid Reinforcement","Verifier-based Rewards"],"permalink":"/ai/review/2025-10-10-Hybrid_Reinforcement_When_Reward_Is_Sparse_Its_Better_to_Be_Dense/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-GCPO_When_Contrast_Fails_Go_Gold","title":"[논문리뷰] GCPO: When Contrast Fails, Go Gold","excerpt":"이 [arXiv]에 게시한 'GCPO: When Contrast Fails, Go Gold' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","LLMs Reasoning","Policy Optimization","Contrastive Learning","Chain of Thought","Reference Answers","Math Reasoning","Gold-Standard Answer"],"permalink":"/ai/review/2025-10-10-GCPO_When_Contrast_Fails_Go_Gold/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-From_What_to_Why_A_Multi-Agent_System_for_Evidence-based_Chemical_Reaction_Condition_Reasoning","title":"[논문리뷰] From What to Why: A Multi-Agent System for Evidence-based Chemical Reaction Condition Reasoning","excerpt":"Feiwei Qin이 [arXiv]에 게시한 'From What to Why: A Multi-Agent System for Evidence-based Chemical Reaction Condition Reasoning' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","Multi-Agent System","Chemical Reaction Prediction","Explainable AI","Evidence-Based Reasoning","Large Language Models","Tool-Augmented LLMs","Scientific Discovery"],"permalink":"/ai/review/2025-10-10-From_What_to_Why_A_Multi-Agent_System_for_Evidence-based_Chemical_Reaction_Condition_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-First_Try_Matters_Revisiting_the_Role_of_Reflection_in_Reasoning_Models","title":"[논문리뷰] First Try Matters: Revisiting the Role of Reflection in Reasoning Models","excerpt":"Wee Sun Lee이 [arXiv]에 게시한 'First Try Matters: Revisiting the Role of Reflection in Reasoning Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","Large Language Models (LLMs)","Reasoning","Chain-of-Thought (CoT)","Reflection","Early Stopping","Supervised Fine-tuning (SFT)","Token Efficiency","Mathematical Reasoning"],"permalink":"/ai/review/2025-10-10-First_Try_Matters_Revisiting_the_Role_of_Reflection_in_Reasoning_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-Fidelity-Aware_Data_Composition_for_Robust_Robot_Generalization","title":"[논문리뷰] Fidelity-Aware Data Composition for Robust Robot Generalization","excerpt":"Liliang Chen이 [arXiv]에 게시한 'Fidelity-Aware Data Composition for Robust Robot Generalization' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","Robot Generalization","Data Augmentation","Out-of-Distribution (OOD)","Shortcut Learning","Information Fidelity","Data Composition","Diffusion Models","Multi-View Video Synthesis"],"permalink":"/ai/review/2025-10-10-Fidelity-Aware_Data_Composition_for_Robust_Robot_Generalization/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-Entropy_Regularizing_Activation_Boosting_Continuous_Control_Large_Language_Models_and_Image_Classification_with_Activation_as_Entropy_Constraints","title":"[논문리뷰] Entropy Regularizing Activation: Boosting Continuous Control, Large Language Models, and Image Classification with Activation as Entropy Constraints","excerpt":"Huazhe Xu이 [arXiv]에 게시한 'Entropy Regularizing Activation: Boosting Continuous Control, Large Language Models, and Image Classification with Activation as Entropy Constraints' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","Entropy Regularization","Activation Functions","Continuous Control","Large Language Models","Image Classification","Reinforcement Learning","Policy Stochasticity","Entropy Constraints"],"permalink":"/ai/review/2025-10-10-Entropy_Regularizing_Activation_Boosting_Continuous_Control_Large_Language_Models_and_Image_Classification_with_Activation_as_Entropy_Constraints/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-DexNDM_Closing_the_Reality_Gap_for_Dexterous_In-Hand_Rotation_via_Joint-Wise_Neural_Dynamics_Model","title":"[논문리뷰] DexNDM: Closing the Reality Gap for Dexterous In-Hand Rotation via Joint-Wise Neural Dynamics Model","excerpt":"Li Yi이 [arXiv]에 게시한 'DexNDM: Closing the Reality Gap for Dexterous In-Hand Rotation via Joint-Wise Neural Dynamics Model' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","Dexterous Manipulation","In-Hand Rotation","Sim-to-Real Transfer","Neural Dynamics Model","Joint-Wise Learning","Autonomous Data Collection","Reinforcement Learning","Robotics"],"permalink":"/ai/review/2025-10-10-DexNDM_Closing_the_Reality_Gap_for_Dexterous_In-Hand_Rotation_via_Joint-Wise_Neural_Dynamics_Model/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-DeepPrune_Parallel_Scaling_without_Inter-trace_Redundancy","title":"[논문리뷰] DeepPrune: Parallel Scaling without Inter-trace Redundancy","excerpt":"이 [arXiv]에 게시한 'DeepPrune: Parallel Scaling without Inter-trace Redundancy' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","Parallel Scaling","Chain-of-Thought","LLM Reasoning","Dynamic Pruning","Inter-trace Redundancy","Judge Model","Resource Efficiency","Answer Diversity"],"permalink":"/ai/review/2025-10-10-DeepPrune_Parallel_Scaling_without_Inter-trace_Redundancy/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-CoMAS_Co-Evolving_Multi-Agent_Systems_via_Interaction_Rewards","title":"[논문리뷰] CoMAS: Co-Evolving Multi-Agent Systems via Interaction Rewards","excerpt":"Yijiang Li이 [arXiv]에 게시한 'CoMAS: Co-Evolving Multi-Agent Systems via Interaction Rewards' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","Multi-Agent Systems","LLM Agents","Self-Evolution","Reinforcement Learning","Interaction Rewards","LLM-as-a-Judge","Decentralized Learning"],"permalink":"/ai/review/2025-10-10-CoMAS_Co-Evolving_Multi-Agent_Systems_via_Interaction_Rewards/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-Beyond_Turn_Limits_Training_Deep_Search_Agents_with_Dynamic_Context_Window","title":"[논문리뷰] Beyond Turn Limits: Training Deep Search Agents with Dynamic Context Window","excerpt":"Yaojie Lu이 [arXiv]에 게시한 'Beyond Turn Limits: Training Deep Search Agents with Dynamic Context Window' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","Deep Search Agents","Dynamic Context Window","Reinforcement Learning","Long-horizon Interaction","Context Management","High-difficulty Tasks","Multi-turn Reasoning","Web Agents"],"permalink":"/ai/review/2025-10-10-Beyond_Turn_Limits_Training_Deep_Search_Agents_with_Dynamic_Context_Window/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-Beyond_Outliers_A_Study_of_Optimizers_Under_Quantization","title":"[논문리뷰] Beyond Outliers: A Study of Optimizers Under Quantization","excerpt":"이 [arXiv]에 게시한 'Beyond Outliers: A Study of Optimizers Under Quantization' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","Quantization","Optimizers","LLM","Post-Training Quantization (PTQ)","Quantization-Aware Training (QAT)","Error Propagation","Scaling Laws","Shampoo"],"permalink":"/ai/review/2025-10-10-Beyond_Outliers_A_Study_of_Optimizers_Under_Quantization/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-ARTDECO_Towards_Efficient_and_High-Fidelity_On-the-Fly_3D_Reconstruction_with_Structured_Scene_Representation","title":"[논문리뷰] ARTDECO: Towards Efficient and High-Fidelity On-the-Fly 3D Reconstruction with Structured Scene Representation","excerpt":"이 [arXiv]에 게시한 'ARTDECO: Towards Efficient and High-Fidelity On-the-Fly 3D Reconstruction with Structured Scene Representation' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","3D Reconstruction","Monocular SLAM","Gaussian Splatting","Level of Detail (LoD)","Feed-Forward Models","Structured Scene Representation","Real-time","High-Fidelity"],"permalink":"/ai/review/2025-10-10-ARTDECO_Towards_Efficient_and_High-Fidelity_On-the-Fly_3D_Reconstruction_with_Structured_Scene_Representation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-Agent_Learning_via_Early_Experience","title":"[논문리뷰] Agent Learning via Early Experience","excerpt":"이 [arXiv]에 게시한 'Agent Learning via Early Experience' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","Language Agents","Early Experience","Reward-Free Learning","World Modeling","Self-Reflection","Imitation Learning","Reinforcement Learning","Out-of-Domain Generalization"],"permalink":"/ai/review/2025-10-10-Agent_Learning_via_Early_Experience/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-10-A2Search_Ambiguity-Aware_Question_Answering_with_Reinforcement_Learning","title":"[논문리뷰] A^2Search: Ambiguity-Aware Question Answering with Reinforcement Learning","excerpt":"이 [arXiv]에 게시한 'A^2Search: Ambiguity-Aware Question Answering with Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-10 13:53:45+0900","lastModifiedAt":"2025-10-10 13:53:45+0900","categories":["Review"],"tags":["Review","Question Answering","Reinforcement Learning","Large Language Models","Ambiguity Resolution","Multi-hop QA","Automated Data Generation","Tool-Augmented LLMs","AnsF1 Reward"],"permalink":"/ai/review/2025-10-10-A2Search_Ambiguity-Aware_Question_Answering_with_Reinforcement_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-9-WristWorld_Generating_Wrist-Views_via_4D_World_Models_for_Robotic_Manipulation","title":"[논문리뷰] WristWorld: Generating Wrist-Views via 4D World Models for Robotic Manipulation","excerpt":"이 [arXiv]에 게시한 'WristWorld: Generating Wrist-Views via 4D World Models for Robotic Manipulation' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-09 13:45:06+0900","lastModifiedAt":"2025-10-09 13:45:06+0900","categories":["Review"],"tags":["Review","4D World Models","Robotic Manipulation","Video Generation","Multi-view Synthesis","Visual-Language-Action (VLA)","Geometric Consistency","Diffusion Models","Wrist-View"],"permalink":"/ai/review/2025-10-9-WristWorld_Generating_Wrist-Views_via_4D_World_Models_for_Robotic_Manipulation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-9-Why_Low-Precision_Transformer_Training_Fails_An_Analysis_on_Flash_Attention","title":"[논문리뷰] Why Low-Precision Transformer Training Fails: An Analysis on Flash Attention","excerpt":"이 [arXiv]에 게시한 'Why Low-Precision Transformer Training Fails: An Analysis on Flash Attention' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-09 13:45:06+0900","lastModifiedAt":"2025-10-09 13:45:06+0900","categories":["Review"],"tags":["Review","Low-Precision Training","Flash Attention","Transformer","Numerical Stability","BF16","Rounding Error","Gradient Bias","Deep Learning Optimization"],"permalink":"/ai/review/2025-10-9-Why_Low-Precision_Transformer_Training_Fails_An_Analysis_on_Flash_Attention/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-9-When_Benchmarks_Age_Temporal_Misalignment_through_Large_Language_Model_Factuality_Evaluation","title":"[논문리뷰] When Benchmarks Age: Temporal Misalignment through Large Language Model Factuality Evaluation","excerpt":"이 [arXiv]에 게시한 'When Benchmarks Age: Temporal Misalignment through Large Language Model Factuality Evaluation' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-09 13:45:06+0900","lastModifiedAt":"2025-10-09 13:45:06+0900","categories":["Review"],"tags":["Review","LLM Factuality Evaluation","Benchmark Aging","Temporal Misalignment","Information Retrieval","Question Answering","Evaluation Metrics","GPT-4o-mini","Qwen2.5"],"permalink":"/ai/review/2025-10-9-When_Benchmarks_Age_Temporal_Misalignment_through_Large_Language_Model_Factuality_Evaluation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-9-Vibe_Checker_Aligning_Code_Evaluation_with_Human_Preference","title":"[논문리뷰] Vibe Checker: Aligning Code Evaluation with Human Preference","excerpt":"이 [arXiv]에 게시한 'Vibe Checker: Aligning Code Evaluation with Human Preference' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-09 13:45:06+0900","lastModifiedAt":"2025-10-09 13:45:06+0900","categories":["Review"],"tags":["Review","Code Evaluation","Instruction Following","Human Preference","Large Language Models","Vibe Check","Non-functional Requirements","VeriCode"],"permalink":"/ai/review/2025-10-9-Vibe_Checker_Aligning_Code_Evaluation_with_Human_Preference/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-9-U-Bench_A_Comprehensive_Understanding_of_U-Net_through_100-Variant_Benchmarking","title":"[논문리뷰] U-Bench: A Comprehensive Understanding of U-Net through 100-Variant Benchmarking","excerpt":"Heqin Zhu이 [arXiv]에 게시한 'U-Bench: A Comprehensive Understanding of U-Net through 100-Variant Benchmarking' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-09 13:45:06+0900","lastModifiedAt":"2025-10-09 13:45:06+0900","categories":["Review"],"tags":["Review","U-Net","Medical Image Segmentation","Benchmarking","Performance Evaluation","Efficiency Metrics","Zero-shot Generalization","U-Score"],"permalink":"/ai/review/2025-10-9-U-Bench_A_Comprehensive_Understanding_of_U-Net_through_100-Variant_Benchmarking/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-9-TTRV_Test-Time_Reinforcement_Learning_for_Vision_Language_Models","title":"[논문리뷰] TTRV: Test-Time Reinforcement Learning for Vision Language Models","excerpt":"Serena Yeung-Levy이 [arXiv]에 게시한 'TTRV: Test-Time Reinforcement Learning for Vision Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-09 13:45:06+0900","lastModifiedAt":"2025-10-09 13:45:06+0900","categories":["Review"],"tags":["Review","Vision-Language Models (VLMs)","Reinforcement Learning (RL)","Test-Time Adaptation","Unsupervised Learning","Image Recognition","Visual Question Answering (VQA)","Group Relative Policy Optimization (GRPO)","Entropy Regularization"],"permalink":"/ai/review/2025-10-9-TTRV_Test-Time_Reinforcement_Learning_for_Vision_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-9-The_Markovian_Thinker","title":"[논문리뷰] The Markovian Thinker","excerpt":"이 [arXiv]에 게시한 'The Markovian Thinker' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-09 13:45:06+0900","lastModifiedAt":"2025-10-09 13:45:06+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","Large Language Models","Chain-of-Thought","Markovian Thinking","Context Management","Computational Efficiency","Long-Context LLMs","Transformer Optimization"],"permalink":"/ai/review/2025-10-9-The_Markovian_Thinker/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-9-The_African_Languages_Lab_A_Collaborative_Approach_to_Advancing_Low-Resource_African_NLP","title":"[논문리뷰] The African Languages Lab: A Collaborative Approach to Advancing Low-Resource African NLP","excerpt":"이 [arXiv]에 게시한 'The African Languages Lab: A Collaborative Approach to Advancing Low-Resource African NLP' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-09 13:45:06+0900","lastModifiedAt":"2025-10-09 13:45:06+0900","categories":["Review"],"tags":["Review","Low-Resource NLP","African Languages","Data Collection","Multilingual Models","Fine-Tuning","Speech Data","Text Data","Capacity Building"],"permalink":"/ai/review/2025-10-9-The_African_Languages_Lab_A_Collaborative_Approach_to_Advancing_Low-Resource_African_NLP/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-9-StaMo_Unsupervised_Learning_of_Generalizable_Robot_Motion_from_Compact_State_Representation","title":"[논문리뷰] StaMo: Unsupervised Learning of Generalizable Robot Motion from Compact State Representation","excerpt":"이 [arXiv]에 게시한 'StaMo: Unsupervised Learning of Generalizable Robot Motion from Compact State Representation' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-09 13:45:06+0900","lastModifiedAt":"2025-10-09 13:45:06+0900","categories":["Review"],"tags":["Review","Robot Learning","State Representation","Motion Representation","Diffusion Models","Unsupervised Learning","World Modeling","Vision-Language Models","Latent Action"],"permalink":"/ai/review/2025-10-9-StaMo_Unsupervised_Learning_of_Generalizable_Robot_Motion_from_Compact_State_Representation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-9-SHANKS_Simultaneous_Hearing_and_Thinking_for_Spoken_Language_Models","title":"[논문리뷰] SHANKS: Simultaneous Hearing and Thinking for Spoken Language Models","excerpt":"Kevin Lin이 [arXiv]에 게시한 'SHANKS: Simultaneous Hearing and Thinking for Spoken Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-09 13:45:06+0900","lastModifiedAt":"2025-10-09 13:45:06+0900","categories":["Review"],"tags":["Review","Spoken Language Models","Real-time Interaction","Thinking While Listening","Chain-of-Thought","Interruption","Tool Calling","Streaming ASR"],"permalink":"/ai/review/2025-10-9-SHANKS_Simultaneous_Hearing_and_Thinking_for_Spoken_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-9-RLinf-VLA_A_Unified_and_Efficient_Framework_for_VLARL_Training","title":"[논문리뷰] RLinf-VLA: A Unified and Efficient Framework for VLA+RL Training","excerpt":"이 [arXiv]에 게시한 'RLinf-VLA: A Unified and Efficient Framework for VLA+RL Training' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-09 13:45:06+0900","lastModifiedAt":"2025-10-09 13:45:06+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","VLA Models","Robotics","GPU Management","PPO","GRPO","Sim-to-Real"],"permalink":"/ai/review/2025-10-9-RLinf-VLA_A_Unified_and_Efficient_Framework_for_VLARL_Training/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-9-Revisiting_the_Uniform_Information_Density_Hypothesis_in_LLM_Reasoning_Traces","title":"[논문리뷰] Revisiting the Uniform Information Density Hypothesis in LLM Reasoning Traces","excerpt":"이 [arXiv]에 게시한 'Revisiting the Uniform Information Density Hypothesis in LLM Reasoning Traces' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-09 13:45:06+0900","lastModifiedAt":"2025-10-09 13:45:06+0900","categories":["Review"],"tags":["Review","LLM Reasoning","Chain-of-Thought","Uniform Information Density","Information Theory","Reasoning Trace Analysis","Entropy","Mathematical Reasoning","Model Evaluation"],"permalink":"/ai/review/2025-10-9-Revisiting_the_Uniform_Information_Density_Hypothesis_in_LLM_Reasoning_Traces/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-9-Revisiting_Long-context_Modeling_from_Context_Denoising_Perspective","title":"[논문리뷰] Revisiting Long-context Modeling from Context Denoising Perspective","excerpt":"이 [arXiv]에 게시한 'Revisiting Long-context Modeling from Context Denoising Perspective' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-09 13:45:06+0900","lastModifiedAt":"2025-10-09 13:45:06+0900","categories":["Review"],"tags":["Review","Long-context Models","Context Denoising","Integrated Gradient","LLM Training","Context Window Scaling","Information Flow","Attention Mechanism"],"permalink":"/ai/review/2025-10-9-Revisiting_Long-context_Modeling_from_Context_Denoising_Perspective/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-9-Pushing_on_Multilingual_Reasoning_Models_with_Language-Mixed_Chain-of-Thought","title":"[논문리뷰] Pushing on Multilingual Reasoning Models with Language-Mixed Chain-of-Thought","excerpt":"이 [arXiv]에 게시한 'Pushing on Multilingual Reasoning Models with Language-Mixed Chain-of-Thought' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-09 13:45:06+0900","lastModifiedAt":"2025-10-09 13:45:06+0900","categories":["Review"],"tags":["Review","Multilingual Reasoning","Chain-of-Thought (CoT)","Language-Mixed CoT","Instruction Tuning","Korean LLMs","Data Curation","Supervised Fine-tuning (SFT)"],"permalink":"/ai/review/2025-10-9-Pushing_on_Multilingual_Reasoning_Models_with_Language-Mixed_Chain-of-Thought/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-9-Patch-as-Decodable-Token_Towards_Unified_Multi-Modal_Vision_Tasks_in_MLLMs","title":"[논문리뷰] Patch-as-Decodable-Token: Towards Unified Multi-Modal Vision Tasks in MLLMs","excerpt":"Jingyi Liao이 [arXiv]에 게시한 'Patch-as-Decodable-Token: Towards Unified Multi-Modal Vision Tasks in MLLMs' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-09 13:45:06+0900","lastModifiedAt":"2025-10-09 13:45:06+0900","categories":["Review"],"tags":["Review","Multimodal Large Language Models (MLLMs)","Visual Reference Tokens (VRTs)","Dense Prediction","Referring Expression Comprehension (REC)","Open-Vocabulary Detection (OVD)","Image Captioning","Unified Architecture","Autoregressive Generation"],"permalink":"/ai/review/2025-10-9-Patch-as-Decodable-Token_Towards_Unified_Multi-Modal_Vision_Tasks_in_MLLMs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-9-Online_Generic_Event_Boundary_Detection","title":"[논문리뷰] Online Generic Event Boundary Detection","excerpt":"Jonghyun Choi이 [arXiv]에 게시한 'Online Generic Event Boundary Detection' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-09 13:45:06+0900","lastModifiedAt":"2025-10-09 13:45:06+0900","categories":["Review"],"tags":["Review","Online Video Analysis","Event Boundary Detection","Event Segmentation Theory","Real-time AI","Anomaly Detection","Transformer Architecture"],"permalink":"/ai/review/2025-10-9-Online_Generic_Event_Boundary_Detection/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-9-OBS-Diff_Accurate_Pruning_For_Diffusion_Models_in_One-Shot","title":"[논문리뷰] OBS-Diff: Accurate Pruning For Diffusion Models in One-Shot","excerpt":"이 [arXiv]에 게시한 'OBS-Diff: Accurate Pruning For Diffusion Models in One-Shot' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-09 13:45:06+0900","lastModifiedAt":"2025-10-09 13:45:06+0900","categories":["Review"],"tags":["Review","Diffusion Models","Network Pruning","One-Shot Pruning","Optimal Brain Surgeon (OBS)","Model Compression","Timestep-Aware Hessian","Structured Pruning"],"permalink":"/ai/review/2025-10-9-OBS-Diff_Accurate_Pruning_For_Diffusion_Models_in_One-Shot/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-9-NorMuon_Making_Muon_more_efficient_and_scalable","title":"[논문리뷰] NorMuon: Making Muon more efficient and scalable","excerpt":"Tuo Zhao이 [arXiv]에 게시한 'NorMuon: Making Muon more efficient and scalable' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-09 13:45:06+0900","lastModifiedAt":"2025-10-09 13:45:06+0900","categories":["Review"],"tags":["Review","LLM Training","Optimizer","Muon","Orthogonalization","Adaptive Learning Rates","Distributed Training","FSDP2","NorMuon"],"permalink":"/ai/review/2025-10-9-NorMuon_Making_Muon_more_efficient_and_scalable/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-9-Native_Hybrid_Attention_for_Efficient_Sequence_Modeling","title":"[논문리뷰] Native Hybrid Attention for Efficient Sequence Modeling","excerpt":"Yu Cheng이 [arXiv]에 게시한 'Native Hybrid Attention for Efficient Sequence Modeling' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-09 13:45:06+0900","lastModifiedAt":"2025-10-09 13:45:06+0900","categories":["Review"],"tags":["Review","Sequence Modeling","Hybrid Attention","Transformer Architecture","Linear Attention","Sliding Window Attention","Long Context","Large Language Models (LLMs)","Efficiency"],"permalink":"/ai/review/2025-10-9-Native_Hybrid_Attention_for_Efficient_Sequence_Modeling/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-9-Multi-Agent_Tool-Integrated_Policy_Optimization","title":"[논문리뷰] Multi-Agent Tool-Integrated Policy Optimization","excerpt":"Lidong Bing이 [arXiv]에 게시한 'Multi-Agent Tool-Integrated Policy Optimization' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-09 13:45:06+0900","lastModifiedAt":"2025-10-09 13:45:06+0900","categories":["Review"],"tags":["Review","Multi-Agent RL","Tool-Integrated Planning","Large Language Models (LLMs)","Policy Optimization","Credit Assignment","Reinforcement Learning","MATPO"],"permalink":"/ai/review/2025-10-9-Multi-Agent_Tool-Integrated_Policy_Optimization/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-9-MLE-Smith_Scaling_MLE_Tasks_with_Automated_Multi-Agent_Pipeline","title":"[논문리뷰] MLE-Smith: Scaling MLE Tasks with Automated Multi-Agent Pipeline","excerpt":"이 [arXiv]에 게시한 'MLE-Smith: Scaling MLE Tasks with Automated Multi-Agent Pipeline' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-09 13:45:06+0900","lastModifiedAt":"2025-10-09 13:45:06+0900","categories":["Review"],"tags":["Review","MLE (Machine Learning Engineering)","Automated Task Generation","Multi-Agent System","LLM Agents","Benchmark","Data Curation","Hybrid Verification","Kaggle"],"permalink":"/ai/review/2025-10-9-MLE-Smith_Scaling_MLE_Tasks_with_Automated_Multi-Agent_Pipeline/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-9-Ming-UniVision_Joint_Image_Understanding_and_Generation_with_a_Unified_Continuous_Tokenizer","title":"[논문리뷰] Ming-UniVision: Joint Image Understanding and Generation with a Unified Continuous Tokenizer","excerpt":"이 [arXiv]에 게시한 'Ming-UniVision: Joint Image Understanding and Generation with a Unified Continuous Tokenizer' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-09 13:45:06+0900","lastModifiedAt":"2025-10-09 13:45:06+0900","categories":["Review"],"tags":["Review","Unified Vision-Language Model","Continuous Tokenizer","Autoregressive Generation","Image Understanding","Image Generation","Multimodal AI","In-context Editing"],"permalink":"/ai/review/2025-10-9-Ming-UniVision_Joint_Image_Understanding_and_Generation_with_a_Unified_Continuous_Tokenizer/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-9-MATRIX_Mask_Track_Alignment_for_Interaction-aware_Video_Generation","title":"[논문리뷰] MATRIX: Mask Track Alignment for Interaction-aware Video Generation","excerpt":"Hyunwook Choi이 [arXiv]에 게시한 'MATRIX: Mask Track Alignment for Interaction-aware Video Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-09 13:45:06+0900","lastModifiedAt":"2025-10-09 13:45:06+0900","categories":["Review"],"tags":["Review","Video Generation","Diffusion Transformers","Human-Object Interaction","Attention Alignment","Mask Tracking","Semantic Grounding","Semantic Propagation","Text-to-Video"],"permalink":"/ai/review/2025-10-9-MATRIX_Mask_Track_Alignment_for_Interaction-aware_Video_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-9-Lumina-DiMOO_An_Omni_Diffusion_Large_Language_Model_for_Multi-Modal_Generation_and_Understanding","title":"[논문리뷰] Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding","excerpt":"이 [arXiv]에 게시한 'Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-09 13:45:06+0900","lastModifiedAt":"2025-10-09 13:45:06+0900","categories":["Review"],"tags":["Review","Multi-modal LLM","Discrete Diffusion","Image Generation","Image Understanding","Omni-modal","Interactive Retouching","Generative AI","Reinforcement Learning"],"permalink":"/ai/review/2025-10-9-Lumina-DiMOO_An_Omni_Diffusion_Large_Language_Model_for_Multi-Modal_Generation_and_Understanding/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-9-Heptapod_Language_Modeling_on_Visual_Signals","title":"[논문리뷰] Heptapod: Language Modeling on Visual Signals","excerpt":"이 [arXiv]에 게시한 'Heptapod: Language Modeling on Visual Signals' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-09 13:45:06+0900","lastModifiedAt":"2025-10-09 13:45:06+0900","categories":["Review"],"tags":["Review","Autoregressive Models","Image Generation","Language Modeling","Causal Transformer","2D Distribution Prediction","Visual Tokenization","Self-Supervised Learning","Generative Models"],"permalink":"/ai/review/2025-10-9-Heptapod_Language_Modeling_on_Visual_Signals/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-9-G2RPO_Granular_GRPO_for_Precise_Reward_in_Flow_Models","title":"[논문리뷰] G^2RPO: Granular GRPO for Precise Reward in Flow Models","excerpt":"이 [arXiv]에 게시한 'G^2RPO: Granular GRPO for Precise Reward in Flow Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-09 13:45:06+0900","lastModifiedAt":"2025-10-09 13:45:06+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","Flow Models","Generative Models","Human Preference Alignment","Stochastic Differential Equations (SDE)","Reward Signal","Multi-Granularity"],"permalink":"/ai/review/2025-10-9-G2RPO_Granular_GRPO_for_Precise_Reward_in_Flow_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-9-DeepTravel_An_End-to-End_Agentic_Reinforcement_Learning_Framework_for_Autonomous_Travel_Planning_Agents","title":"[논문리뷰] DeepTravel: An End-to-End Agentic Reinforcement Learning Framework for Autonomous Travel Planning Agents","excerpt":"이 [arXiv]에 게시한 'DeepTravel: An End-to-End Agentic Reinforcement Learning Framework for Autonomous Travel Planning Agents' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-09 13:45:06+0900","lastModifiedAt":"2025-10-09 13:45:06+0900","categories":["Review"],"tags":["Review","Agentic Reinforcement Learning","Travel Planning","Large Language Models","Sandbox Environment","Hierarchical Reward Modeling","Experience Replay","Autonomous Agents"],"permalink":"/ai/review/2025-10-9-DeepTravel_An_End-to-End_Agentic_Reinforcement_Learning_Framework_for_Autonomous_Travel_Planning_Agents/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-9-D3QE_Learning_Discrete_Distribution_Discrepancy-aware_Quantization_Error_for_Autoregressive-Generated_Image_Detection","title":"[논문리뷰] D^3QE: Learning Discrete Distribution Discrepancy-aware Quantization Error for Autoregressive-Generated Image Detection","excerpt":"Yueqi Duan이 [arXiv]에 게시한 'D^3QE: Learning Discrete Distribution Discrepancy-aware Quantization Error for Autoregressive-Generated Image Detection' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-09 13:45:06+0900","lastModifiedAt":"2025-10-09 13:45:06+0900","categories":["Review"],"tags":["Review","Autoregressive Models","Image Detection","Discrete Distribution Discrepancy","Quantization Error","Transformer","Generative AI","Deepfake Detection"],"permalink":"/ai/review/2025-10-9-D3QE_Learning_Discrete_Distribution_Discrepancy-aware_Quantization_Error_for_Autoregressive-Generated_Image_Detection/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-9-CALM_Before_the_STORM_Unlocking_Native_Reasoning_for_Optimization_Modeling","title":"[논문리뷰] CALM Before the STORM: Unlocking Native Reasoning for Optimization Modeling","excerpt":"Chengpeng Li이 [arXiv]에 게시한 'CALM Before the STORM: Unlocking Native Reasoning for Optimization Modeling' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-09 13:45:06+0900","lastModifiedAt":"2025-10-09 13:45:06+0900","categories":["Review"],"tags":["Review","Large Reasoning Models","Optimization Modeling","Reflective Generation","Supervised Fine-tuning","Reinforcement Learning","Human-in-the-Loop","Code Generation","Domain Adaptation"],"permalink":"/ai/review/2025-10-9-CALM_Before_the_STORM_Unlocking_Native_Reasoning_for_Optimization_Modeling/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-9-Cache-to-Cache_Direct_Semantic_Communication_Between_Large_Language_Models","title":"[논문리뷰] Cache-to-Cache: Direct Semantic Communication Between Large Language Models","excerpt":"이 [arXiv]에 게시한 'Cache-to-Cache: Direct Semantic Communication Between Large Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-09 13:45:06+0900","lastModifiedAt":"2025-10-09 13:45:06+0900","categories":["Review"],"tags":["Review","Large Language Models (LLMs)","Inter-model Communication","KV-Cache","Semantic Transfer","Multi-LLM Systems","Cache Fusion","Latency Reduction","Knowledge Sharing"],"permalink":"/ai/review/2025-10-9-Cache-to-Cache_Direct_Semantic_Communication_Between_Large_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-9-Bridging_Text_and_Video_Generation_A_Survey","title":"[논문리뷰] Bridging Text and Video Generation: A Survey","excerpt":"G. Maragatham이 [arXiv]에 게시한 'Bridging Text and Video Generation: A Survey' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-09 13:45:06+0900","lastModifiedAt":"2025-10-09 13:45:06+0900","categories":["Review"],"tags":["Review","Text-to-Video Generation","Generative Models","Diffusion Models","GANs","VAEs","Video Synthesis","Survey","Evaluation Metrics"],"permalink":"/ai/review/2025-10-9-Bridging_Text_and_Video_Generation_A_Survey/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-9-Beyond_Monolingual_Assumptions_A_Survey_of_Code-Switched_NLP_in_the_Era_of_Large_Language_Models","title":"[논문리뷰] Beyond Monolingual Assumptions: A Survey of Code-Switched NLP in the Era of Large Language Models","excerpt":"이 [arXiv]에 게시한 'Beyond Monolingual Assumptions: A Survey of Code-Switched NLP in the Era of Large Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-09 13:45:06+0900","lastModifiedAt":"2025-10-09 13:45:06+0900","categories":["Review"],"tags":["Review","Code-switching","Multilingual NLP","Large Language Models","NLP Survey","Data Augmentation","Evaluation Metrics","Low-Resource Languages"],"permalink":"/ai/review/2025-10-9-Beyond_Monolingual_Assumptions_A_Survey_of_Code-Switched_NLP_in_the_Era_of_Large_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-9-Artificial_Hippocampus_Networks_for_Efficient_Long-Context_Modeling","title":"[논문리뷰] Artificial Hippocampus Networks for Efficient Long-Context Modeling","excerpt":"이 [arXiv]에 게시한 'Artificial Hippocampus Networks for Efficient Long-Context Modeling' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-09 13:45:06+0900","lastModifiedAt":"2025-10-09 13:45:06+0900","categories":["Review"],"tags":["Review","Long-Context Modeling","Transformer","RNN","Memory Management","Self-Distillation","Attention Mechanism","Artificial Hippocampus Networks","Cognitive Science"],"permalink":"/ai/review/2025-10-9-Artificial_Hippocampus_Networks_for_Efficient_Long-Context_Modeling/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-9-Are_We_Using_the_Right_Benchmark_An_Evaluation_Framework_for_Visual_Token_Compression_Methods","title":"[논문리뷰] Are We Using the Right Benchmark: An Evaluation Framework for Visual Token Compression Methods","excerpt":"Yiyu Wang이 [arXiv]에 게시한 'Are We Using the Right Benchmark: An Evaluation Framework for Visual Token Compression Methods' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-09 13:45:06+0900","lastModifiedAt":"2025-10-09 13:45:06+0900","categories":["Review"],"tags":["Review","Visual Token Compression","MLLMs","Evaluation Framework","Benchmarking","Downsampling","Data Filtering","Model Efficiency"],"permalink":"/ai/review/2025-10-9-Are_We_Using_the_Right_Benchmark_An_Evaluation_Framework_for_Visual_Token_Compression_Methods/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-9-AlphaApollo_Orchestrating_Foundation_Models_and_Professional_Tools_into_a_Self-Evolving_System_for_Deep_Agentic_Reasoning","title":"[논문리뷰] AlphaApollo: Orchestrating Foundation Models and Professional Tools into a Self-Evolving System for Deep Agentic Reasoning","excerpt":"Zongze Li이 [arXiv]에 게시한 'AlphaApollo: Orchestrating Foundation Models and Professional Tools into a Self-Evolving System for Deep Agentic Reasoning' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-09 13:45:06+0900","lastModifiedAt":"2025-10-09 13:45:06+0900","categories":["Review"],"tags":["Review","Foundation Models","Agentic Reasoning","Tool Use","Self-Evolving System","Retrieval-Augmented Generation","Computational Tools","Error Correction"],"permalink":"/ai/review/2025-10-9-AlphaApollo_Orchestrating_Foundation_Models_and_Professional_Tools_into_a_Self-Evolving_System_for_Deep_Agentic_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-VeriGuard_Enhancing_LLM_Agent_Safety_via_Verified_Code_Generation","title":"[논문리뷰] VeriGuard: Enhancing LLM Agent Safety via Verified Code Generation","excerpt":"이 [arXiv]에 게시한 'VeriGuard: Enhancing LLM Agent Safety via Verified Code Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","LLM Agents","Safety","Formal Verification","Code Generation","Runtime Monitoring","Security","Guardrails","Policy Enforcement"],"permalink":"/ai/review/2025-10-8-VeriGuard_Enhancing_LLM_Agent_Safety_via_Verified_Code_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-Training_Dynamics_Impact_Post-Training_Quantization_Robustness","title":"[논문리뷰] Training Dynamics Impact Post-Training Quantization Robustness","excerpt":"Jonas Geiping이 [arXiv]에 게시한 'Training Dynamics Impact Post-Training Quantization Robustness' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","Post-Training Quantization","Quantization Robustness","Training Dynamics","Learning Rate Schedules","Weight Averaging","Large Language Models","LLMs","Hyperparameter Tuning"],"permalink":"/ai/review/2025-10-8-Training_Dynamics_Impact_Post-Training_Quantization_Robustness/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-TensorBLEU_Vectorized_GPU-based_BLEU_Score_Implementation_for_Per-Sentence_In-Training_Evaluation","title":"[논문리뷰] TensorBLEU: Vectorized GPU-based BLEU Score Implementation for Per-Sentence In-Training Evaluation","excerpt":"이 [arXiv]에 게시한 'TensorBLEU: Vectorized GPU-based BLEU Score Implementation for Per-Sentence In-Training Evaluation' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","BLEU Score","GPU Acceleration","PyTorch","Natural Language Processing","Reinforcement Learning","Vectorization","In-Training Evaluation","N-gram Counting"],"permalink":"/ai/review/2025-10-8-TensorBLEU_Vectorized_GPU-based_BLEU_Score_Implementation_for_Per-Sentence_In-Training_Evaluation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-TaTToo_Tool-Grounded_Thinking_PRM_for_Test-Time_Scaling_in_Tabular_Reasoning","title":"[논문리뷰] TaTToo: Tool-Grounded Thinking PRM for Test-Time Scaling in Tabular Reasoning","excerpt":"이 [arXiv]에 게시한 'TaTToo: Tool-Grounded Thinking PRM for Test-Time Scaling in Tabular Reasoning' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","Process Reward Models","Tabular Reasoning","Test-Time Scaling","Tool Integration","Reinforcement Learning","Supervised Fine-tuning","Large Language Models","Data Curation"],"permalink":"/ai/review/2025-10-8-TaTToo_Tool-Grounded_Thinking_PRM_for_Test-Time_Scaling_in_Tabular_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-ShapeGen4D_Towards_High_Quality_4D_Shape_Generation_from_Videos","title":"[논문리뷰] ShapeGen4D: Towards High Quality 4D Shape Generation from Videos","excerpt":"Sergey Tulyakov이 [arXiv]에 게시한 'ShapeGen4D: Towards High Quality 4D Shape Generation from Videos' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","4D Shape Generation","Video-conditioned","Dynamic 3D Meshes","Latent Diffusion Model","Spatiotemporal Attention","Temporal Consistency","Pre-trained 3D Models","VAE"],"permalink":"/ai/review/2025-10-8-ShapeGen4D_Towards_High_Quality_4D_Shape_Generation_from_Videos/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-Scaling_Code-Assisted_Chain-of-Thoughts_and_Instructions_for_Model_Reasoning","title":"[논문리뷰] Scaling Code-Assisted Chain-of-Thoughts and Instructions for Model Reasoning","excerpt":"Zhuoshi Pan이 [arXiv]에 게시한 'Scaling Code-Assisted Chain-of-Thoughts and Instructions for Model Reasoning' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","Code-Assisted Reasoning","Chain-of-Thought (CoT)","Instruction Tuning","Data Augmentation","LLMs","Mathematical Reasoning","Self-Verification","Code Generation"],"permalink":"/ai/review/2025-10-8-Scaling_Code-Assisted_Chain-of-Thoughts_and_Instructions_for_Model_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-Revisiting_Modeling_and_Evaluation_Approaches_in_Speech_Emotion_Recognition_Considering_Subjectivity_of_Annotators_and_Ambiguity_of_Emotions","title":"[논문리뷰] Revisiting Modeling and Evaluation Approaches in Speech Emotion Recognition: Considering Subjectivity of Annotators and Ambiguity of Emotions","excerpt":"이 [arXiv]에 게시한 'Revisiting Modeling and Evaluation Approaches in Speech Emotion Recognition: Considering Subjectivity of Annotators and Ambiguity of Emotions' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","Speech Emotion Recognition","Annotator Subjectivity","Emotion Ambiguity","Soft Labels","Multi-label Classification","Evaluation Metrics","Loss Functions"],"permalink":"/ai/review/2025-10-8-Revisiting_Modeling_and_Evaluation_Approaches_in_Speech_Emotion_Recognition_Considering_Subjectivity_of_Annotators_and_Ambiguity_of_Emotions/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-Refusal_Falls_off_a_Cliff_How_Safety_Alignment_Fails_in_Reasoning","title":"[논문리뷰] Refusal Falls off a Cliff: How Safety Alignment Fails in Reasoning?","excerpt":"이 [arXiv]에 게시한 'Refusal Falls off a Cliff: How Safety Alignment Fails in Reasoning?' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","Safety Alignment","Large Reasoning Models","Mechanistic Interpretability","Refusal Cliff","Attention Heads","Data Selection","Linear Probing"],"permalink":"/ai/review/2025-10-8-Refusal_Falls_off_a_Cliff_How_Safety_Alignment_Fails_in_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-Presenting_a_Paper_is_an_Art_Self-Improvement_Aesthetic_Agents_for_Academic_Presentations","title":"[논문리뷰] Presenting a Paper is an Art: Self-Improvement Aesthetic Agents for Academic Presentations","excerpt":"이 [arXiv]에 게시한 'Presenting a Paper is an Art: Self-Improvement Aesthetic Agents for Academic Presentations' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","Self-Improvement Agent","Academic Presentation","Aesthetic Evaluation","Reinforcement Learning","Multi-task Learning","Presentation Generation","LLM-based Agents","Human Feedback"],"permalink":"/ai/review/2025-10-8-Presenting_a_Paper_is_an_Art_Self-Improvement_Aesthetic_Agents_for_Academic_Presentations/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-OneFlow_Concurrent_Mixed-Modal_and_Interleaved_Generation_with_Edit_Flows","title":"[논문리뷰] OneFlow: Concurrent Mixed-Modal and Interleaved Generation with Edit Flows","excerpt":"이 [arXiv]에 게시한 'OneFlow: Concurrent Mixed-Modal and Interleaved Generation with Edit Flows' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","Non-Autoregressive","Multimodal Generation","Edit Flows","Flow Matching","Interleaved Generation","Text-to-Image Synthesis","Unified Models"],"permalink":"/ai/review/2025-10-8-OneFlow_Concurrent_Mixed-Modal_and_Interleaved_Generation_with_Edit_Flows/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-No_Tokens_Wasted_Leveraging_Long_Context_in_Biomedical_Vision-Language_Models","title":"[논문리뷰] No Tokens Wasted: Leveraging Long Context in Biomedical Vision-Language Models","excerpt":"Xiao Xiao Sun이 [arXiv]에 게시한 'No Tokens Wasted: Leveraging Long Context in Biomedical Vision-Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","Biomedical Vision-Language Models","Long-context Modeling","Contrastive Learning","Token Efficiency","Zero-shot Classification","Medical Image Retrieval"],"permalink":"/ai/review/2025-10-8-No_Tokens_Wasted_Leveraging_Long_Context_in_Biomedical_Vision-Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-MixReasoning_Switching_Modes_to_Think","title":"[논문리뷰] MixReasoning: Switching Modes to Think","excerpt":"이 [arXiv]에 게시한 'MixReasoning: Switching Modes to Think' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","LLM Reasoning","Chain-of-Thought","Efficiency","LoRA","Adaptive Reasoning","Token Uncertainty","Dynamic Switching","Reasoning Compression"],"permalink":"/ai/review/2025-10-8-MixReasoning_Switching_Modes_to_Think/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-Mixing_Mechanisms_How_Language_Models_Retrieve_Bound_Entities_In-Context","title":"[논문리뷰] Mixing Mechanisms: How Language Models Retrieve Bound Entities In-Context","excerpt":"이 [arXiv]에 게시한 'Mixing Mechanisms: How Language Models Retrieve Bound Entities In-Context' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","Language Models","In-Context Learning","Entity Binding","Mechanistic Interpretability","Causal Abstraction","Long-Context Reasoning","Positional Encoding","Information Retrieval"],"permalink":"/ai/review/2025-10-8-Mixing_Mechanisms_How_Language_Models_Retrieve_Bound_Entities_In-Context/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-Margin_Adaptive_DPO_Leveraging_Reward_Model_for_Granular_Control_in_Preference_Optimization","title":"[논문리뷰] Margin Adaptive DPO: Leveraging Reward Model for Granular Control in Preference Optimization","excerpt":"sirano1004이 [arXiv]에 게시한 'Margin Adaptive DPO: Leveraging Reward Model for Granular Control in Preference Optimization' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","Direct Preference Optimization","Preference Alignment","Adaptive Regularization","Reward Model","Large Language Models","Sentiment Generation"],"permalink":"/ai/review/2025-10-8-Margin_Adaptive_DPO_Leveraging_Reward_Model_for_Granular_Control_in_Preference_Optimization/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-LightCache_Memory-Efficient_Training-Free_Acceleration_for_Video_Generation","title":"[논문리뷰] LightCache: Memory-Efficient, Training-Free Acceleration for Video Generation","excerpt":"Zheng Zhan이 [arXiv]에 게시한 'LightCache: Memory-Efficient, Training-Free Acceleration for Video Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","Video Generation","Diffusion Models","Memory Efficiency","Inference Acceleration","Training-Free","Cache Mechanism","GPU Optimization"],"permalink":"/ai/review/2025-10-8-LightCache_Memory-Efficient_Training-Free_Acceleration_for_Video_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-Less_is_More_Recursive_Reasoning_with_Tiny_Networks","title":"[논문리뷰] Less is More: Recursive Reasoning with Tiny Networks","excerpt":"이 [arXiv]에 게시한 'Less is More: Recursive Reasoning with Tiny Networks' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","Recursive Reasoning","Tiny Networks","Deep Supervision","Hierarchical Reasoning Model (HRM)","Sudoku-Extreme","ARC-AGI","Generalization","Parameter Efficiency"],"permalink":"/ai/review/2025-10-8-Less_is_More_Recursive_Reasoning_with_Tiny_Networks/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-In-the-Flow_Agentic_System_Optimization_for_Effective_Planning_and_Tool_Use","title":"[논문리뷰] In-the-Flow Agentic System Optimization for Effective Planning and Tool Use","excerpt":"이 [arXiv]에 게시한 'In-the-Flow Agentic System Optimization for Effective Planning and Tool Use' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","Agentic Systems","Large Language Models (LLMs)","Tool Use","Reinforcement Learning (RL)","On-policy Optimization","Flow-based Group Refined Policy Optimization (Flow-GRPO)","Multi-turn Reasoning"],"permalink":"/ai/review/2025-10-8-In-the-Flow_Agentic_System_Optimization_for_Effective_Planning_and_Tool_Use/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-Human3R_Everyone_Everywhere_All_at_Once","title":"[논문리뷰] Human3R: Everyone Everywhere All at Once","excerpt":"Yuliang Xiu이 [arXiv]에 게시한 'Human3R: Everyone Everywhere All at Once' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","4D Human-Scene Reconstruction","Online Reconstruction","Multi-person","SMPL-X","Transformer","Visual Prompt Tuning","Real-time","Foundation Model"],"permalink":"/ai/review/2025-10-8-Human3R_Everyone_Everywhere_All_at_Once/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-HoloScene_Simulation-Ready_Interactive_3D_Worlds_from_a_Single_Video","title":"[논문리뷰] HoloScene: Simulation-Ready Interactive 3D Worlds from a Single Video","excerpt":"Katelyn Gao이 [arXiv]에 게시한 'HoloScene: Simulation-Ready Interactive 3D Worlds from a Single Video' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","3D Reconstruction","Digital Twin","Scene Graph","Physical Simulation","Interactive Environments","Single Video Reconstruction","Neural Rendering"],"permalink":"/ai/review/2025-10-8-HoloScene_Simulation-Ready_Interactive_3D_Worlds_from_a_Single_Video/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-HalluGuard_Evidence-Grounded_Small_Reasoning_Models_to_Mitigate_Hallucinations_in_Retrieval-Augmented_Generation","title":"[논문리뷰] HalluGuard: Evidence-Grounded Small Reasoning Models to Mitigate Hallucinations in Retrieval-Augmented Generation","excerpt":"Radu State이 [arXiv]에 게시한 'HalluGuard: Evidence-Grounded Small Reasoning Models to Mitigate Hallucinations in Retrieval-Augmented Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","Hallucination Detection","Retrieval-Augmented Generation (RAG)","Small Reasoning Model (SRM)","Preference Fine-tuning","ORPO","Evidence Grounding","Fact-checking"],"permalink":"/ai/review/2025-10-8-HalluGuard_Evidence-Grounded_Small_Reasoning_Models_to_Mitigate_Hallucinations_in_Retrieval-Augmented_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-Fathom-DeepResearch_Unlocking_Long_Horizon_Information_Retrieval_and_Synthesis_for_SLMs","title":"[논문리뷰] Fathom-DeepResearch: Unlocking Long Horizon Information Retrieval and Synthesis for SLMs","excerpt":"이 [arXiv]에 게시한 'Fathom-DeepResearch: Unlocking Long Horizon Information Retrieval and Synthesis for SLMs' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","DeepResearch Agents","Tool-integrated Reasoning","Reinforcement Learning","Information Retrieval","Information Synthesis","Multi-agent Self-play","Reward Shaping","LLM"],"permalink":"/ai/review/2025-10-8-Fathom-DeepResearch_Unlocking_Long_Horizon_Information_Retrieval_and_Synthesis_for_SLMs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-Fast-dLLM_v2_Efficient_Block-Diffusion_LLM","title":"[논문리뷰] Fast-dLLM v2: Efficient Block-Diffusion LLM","excerpt":"이 [arXiv]에 게시한 'Fast-dLLM v2: Efficient Block-Diffusion LLM' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","Diffusion LLMs","Inference Acceleration","Parallel Decoding","Autoregressive Models","Caching","Fine-tuning","Block-wise Attention"],"permalink":"/ai/review/2025-10-8-Fast-dLLM_v2_Efficient_Block-Diffusion_LLM/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-Equilibrium_Matching_Generative_Modeling_with_Implicit_Energy-Based_Models","title":"[논문리뷰] Equilibrium Matching: Generative Modeling with Implicit Energy-Based Models","excerpt":"이 [arXiv]에 게시한 'Equilibrium Matching: Generative Modeling with Implicit Energy-Based Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","Generative Models","Equilibrium Dynamics","Energy-Based Models (EBMs)","Flow Matching","Diffusion Models","Optimization-Based Sampling","Image Generation"],"permalink":"/ai/review/2025-10-8-Equilibrium_Matching_Generative_Modeling_with_Implicit_Energy-Based_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-EgoNight_Towards_Egocentric_Vision_Understanding_at_Night_with_a_Challenging_Benchmark","title":"[논문리뷰] EgoNight: Towards Egocentric Vision Understanding at Night with a Challenging Benchmark","excerpt":"Tianwen Qian이 [arXiv]에 게시한 'EgoNight: Towards Egocentric Vision Understanding at Night with a Challenging Benchmark' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","Egocentric Vision","Nighttime Conditions","Visual Question Answering (VQA)","Day-Night Alignment","Multimodal Large Language Models (MLLMs)","Depth Estimation","Correspondence Retrieval","Benchmark"],"permalink":"/ai/review/2025-10-8-EgoNight_Towards_Egocentric_Vision_Understanding_at_Night_with_a_Challenging_Benchmark/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-DRIFT_Learning_from_Abundant_User_Dissatisfaction_in_Real-World_Preference_Learning","title":"[논문리뷰] DRIFT: Learning from Abundant User Dissatisfaction in Real-World Preference Learning","excerpt":"Zheli Liu이 [arXiv]에 게시한 'DRIFT: Learning from Abundant User Dissatisfaction in Real-World Preference Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","Preference Learning","LLMs","User Feedback","Dissatisfaction Signals","DPO","Iterative Training","RLHF","Exploration"],"permalink":"/ai/review/2025-10-8-DRIFT_Learning_from_Abundant_User_Dissatisfaction_in_Real-World_Preference_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-Drax_Speech_Recognition_with_Discrete_Flow_Matching","title":"[논문리뷰] Drax: Speech Recognition with Discrete Flow Matching","excerpt":"이 [arXiv]에 게시한 'Drax: Speech Recognition with Discrete Flow Matching' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","Automatic Speech Recognition (ASR)","Discrete Flow Matching (DFM)","Non-Autoregressive (NAR)","Generative Models","Tri-mixture Probability Path","Parallel Decoding","Accuracy-Efficiency Trade-off","Speech Synthesis"],"permalink":"/ai/review/2025-10-8-Drax_Speech_Recognition_with_Discrete_Flow_Matching/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-Distributional_Semantics_Tracing_A_Framework_for_Explaining_Hallucinations_in_Large_Language_Models","title":"[논문리뷰] Distributional Semantics Tracing: A Framework for Explaining Hallucinations in Large Language Models","excerpt":"Jacobo Azcona이 [arXiv]에 게시한 'Distributional Semantics Tracing: A Framework for Explaining Hallucinations in Large Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","LLM Hallucinations","Mechanistic Interpretability","Distributional Semantics Tracing (DST)","Dual-Process Theory","Semantic Drift","Commitment Layer","Faithfulness Score"],"permalink":"/ai/review/2025-10-8-Distributional_Semantics_Tracing_A_Framework_for_Explaining_Hallucinations_in_Large_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-Discrete_Diffusion_Models_with_MLLMs_for_Unified_Medical_Multimodal_Generation","title":"[논문리뷰] Discrete Diffusion Models with MLLMs for Unified Medical Multimodal Generation","excerpt":"이 [arXiv]에 게시한 'Discrete Diffusion Models with MLLMs for Unified Medical Multimodal Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","Discrete Diffusion Models","Multimodal Large Language Models (MLLMs)","Medical Image Generation","Medical Report Generation","Multimodal Generation","Medical AI","Cross-modal Alignment"],"permalink":"/ai/review/2025-10-8-Discrete_Diffusion_Models_with_MLLMs_for_Unified_Medical_Multimodal_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-Demystifying_deep_search_a_holistic_evaluation_with_hint-free_multi-hop_questions_and_factorised_metrics","title":"[논문리뷰] Demystifying deep search: a holistic evaluation with hint-free multi-hop questions and factorised metrics","excerpt":"이 [arXiv]에 게시한 'Demystifying deep search: a holistic evaluation with hint-free multi-hop questions and factorised metrics' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","Deep Search","Multi-hop Reasoning","Evaluation Benchmark","Retrieval-Augmented Generation","Web Agents","Diagnostic Metrics","Knowledge Utilization","Hint-Free Questions"],"permalink":"/ai/review/2025-10-8-Demystifying_deep_search_a_holistic_evaluation_with_hint-free_multi-hop_questions_and_factorised_metrics/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-Deforming_Videos_to_Masks_Flow_Matching_for_Referring_Video_Segmentation","title":"[논문리뷰] Deforming Videos to Masks: Flow Matching for Referring Video Segmentation","excerpt":"Chengzu Li이 [arXiv]에 게시한 'Deforming Videos to Masks: Flow Matching for Referring Video Segmentation' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","Referring Video Object Segmentation","Flow Matching","Video Segmentation","Generative Models","Text-to-Video","Continuous Flow","Diffusion Models"],"permalink":"/ai/review/2025-10-8-Deforming_Videos_to_Masks_Flow_Matching_for_Referring_Video_Segmentation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-CoDA_Coding_LM_via_Diffusion_Adaptation","title":"[논문리뷰] CoDA: Coding LM via Diffusion Adaptation","excerpt":"이 [arXiv]에 게시한 'CoDA: Coding LM via Diffusion Adaptation' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","Diffusion Language Models","Code Generation","Bidirectional Decoding","Text Infilling","Instruction Tuning","Lightweight Models","TPU Training"],"permalink":"/ai/review/2025-10-8-CoDA_Coding_LM_via_Diffusion_Adaptation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-CCD_Mitigating_Hallucinations_in_Radiology_MLLMs_via_Clinical_Contrastive_Decoding","title":"[논문리뷰] CCD: Mitigating Hallucinations in Radiology MLLMs via Clinical Contrastive Decoding","excerpt":"이 [arXiv]에 게시한 'CCD: Mitigating Hallucinations in Radiology MLLMs via Clinical Contrastive Decoding' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","Multimodal Large Language Models (MLLMs)","Radiology Report Generation (RRG)","Medical Hallucinations","Contrastive Decoding","Training-free Inference","Clinical AI","Visual Question Answering (VQA)"],"permalink":"/ai/review/2025-10-8-CCD_Mitigating_Hallucinations_in_Radiology_MLLMs_via_Clinical_Contrastive_Decoding/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-CARE_Cognitive-reasoning_Augmented_Reinforcement_for_Emotional_Support_Conversation","title":"[논문리뷰] CARE: Cognitive-reasoning Augmented Reinforcement for Emotional Support Conversation","excerpt":"이 [arXiv]에 게시한 'CARE: Cognitive-reasoning Augmented Reinforcement for Emotional Support Conversation' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","Emotional Support Conversation","Cognitive Reasoning","Reinforcement Learning","Dialogue Generation","Natural Language Processing","Large Language Models","Psychological Support"],"permalink":"/ai/review/2025-10-8-CARE_Cognitive-reasoning_Augmented_Reinforcement_for_Emotional_Support_Conversation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-BIRD-INTERACT_Re-imagining_Text-to-SQL_Evaluation_for_Large_Language_Models_via_Lens_of_Dynamic_Interactions","title":"[논문리뷰] BIRD-INTERACT: Re-imagining Text-to-SQL Evaluation for Large Language Models via Lens of Dynamic Interactions","excerpt":"Shipei Lin이 [arXiv]에 게시한 'BIRD-INTERACT: Re-imagining Text-to-SQL Evaluation for Large Language Models via Lens of Dynamic Interactions' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","Text-to-SQL","LLM Evaluation","Multi-turn Interaction","Dynamic Environment","User Simulator","Ambiguity Resolution","LLM Agents"],"permalink":"/ai/review/2025-10-8-BIRD-INTERACT_Re-imagining_Text-to-SQL_Evaluation_for_Large_Language_Models_via_Lens_of_Dynamic_Interactions/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-Benchmark_It_Yourself_BIY_Preparing_a_Dataset_and_Benchmarking_AI_Models_for_Scatterplot-Related_Tasks","title":"[논문리뷰] Benchmark It Yourself (BIY): Preparing a Dataset and Benchmarking AI Models for Scatterplot-Related Tasks","excerpt":"Pedro Bizarro이 [arXiv]에 게시한 'Benchmark It Yourself (BIY): Preparing a Dataset and Benchmarking AI Models for Scatterplot-Related Tasks' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","Scatterplot Analysis","AI Benchmarking","Multimodal LLMs","Synthetic Data Generation","Cluster Detection","Outlier Detection","Data Visualization","Prompt Engineering"],"permalink":"/ai/review/2025-10-8-Benchmark_It_Yourself_BIY_Preparing_a_Dataset_and_Benchmarking_AI_Models_for_Scatterplot-Related_Tasks/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-A_Contextual_Quality_Reward_Model_for_Reliable_and_Efficient_Best-of-N_Sampling","title":"[논문리뷰] A Contextual Quality Reward Model for Reliable and Efficient Best-of-N Sampling","excerpt":"sirano1004이 [arXiv]에 게시한 'A Contextual Quality Reward Model for Reliable and Efficient Best-of-N Sampling' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","Reward Model","Best-of-N Sampling","Preference Alignment","Contextual Acceptability","Discrete Choice Model","Alignment Guardrail","Inference Accelerator"],"permalink":"/ai/review/2025-10-8-A_Contextual_Quality_Reward_Model_for_Reliable_and_Efficient_Best-of-N_Sampling/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-ASPO_Asymmetric_Importance_Sampling_Policy_Optimization","title":"[논문리뷰] ASPO: Asymmetric Importance Sampling Policy Optimization","excerpt":"Xiu Li이 [arXiv]에 게시한 'ASPO: Asymmetric Importance Sampling Policy Optimization' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","Large Language Models","Importance Sampling","Policy Optimization","PPO-Clip","Outcome-Supervised RL","Token Weighting","GRPO"],"permalink":"/ai/review/2025-10-8-ASPO_Asymmetric_Importance_Sampling_Policy_Optimization/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-8-AInstein_Assessing_the_Feasibility_of_AI-Generated_Approaches_to_Research_Problems","title":"[논문리뷰] AInstein: Assessing the Feasibility of AI-Generated Approaches to Research Problems","excerpt":"Jose Dolz이 [arXiv]에 게시한 'AInstein: Assessing the Feasibility of AI-Generated Approaches to Research Problems' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-08 13:48:12+0900","lastModifiedAt":"2025-10-08 13:48:12+0900","categories":["Review"],"tags":["Review","LLM","Scientific Problem Solving","AI Research","Iterative Refinement","Autonomous Agents","Generative AI","Evaluation Framework","Problem Extraction"],"permalink":"/ai/review/2025-10-8-AInstein_Assessing_the_Feasibility_of_AI-Generated_Approaches_to_Research_Problems/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-7-Watch_and_Learn_Learning_to_Use_Computers_from_Online_Videos","title":"[논문리뷰] Watch and Learn: Learning to Use Computers from Online Videos","excerpt":"Oriana Riva이 [arXiv]에 게시한 'Watch and Learn: Learning to Use Computers from Online Videos' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-07 13:36:57+0900","lastModifiedAt":"2025-10-07 13:36:57+0900","categories":["Review"],"tags":["Review","Computer Use Agents","Inverse Dynamics Model","UI Trajectories","Web Videos","In-Context Learning","Supervised Fine-Tuning","Large Language Models","OSWorld Benchmark"],"permalink":"/ai/review/2025-10-7-Watch_and_Learn_Learning_to_Use_Computers_from_Online_Videos/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-7-Video-LMM_Post-Training_A_Deep_Dive_into_Video_Reasoning_with_Large_Multimodal_Models","title":"[논문리뷰] Video-LMM Post-Training: A Deep Dive into Video Reasoning with Large Multimodal Models","excerpt":"zeliang0426이 [arXiv]에 게시한 'Video-LMM Post-Training: A Deep Dive into Video Reasoning with Large Multimodal Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-07 13:36:57+0900","lastModifiedAt":"2025-10-07 13:36:57+0900","categories":["Review"],"tags":["Review","Video Reasoning","Large Multimodal Models (LMMs)","Post-training","Supervised Fine-tuning (SFT)","Reinforcement Learning (RL)","Test-Time Scaling (TTS)","Chain-of-Thought (CoT)"],"permalink":"/ai/review/2025-10-7-Video-LMM_Post-Training_A_Deep_Dive_into_Video_Reasoning_with_Large_Multimodal_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-7-VChain_Chain-of-Visual-Thought_for_Reasoning_in_Video_Generation","title":"[논문리뷰] VChain: Chain-of-Visual-Thought for Reasoning in Video Generation","excerpt":"Paul Debevec이 [arXiv]에 게시한 'VChain: Chain-of-Visual-Thought for Reasoning in Video Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-07 13:36:57+0900","lastModifiedAt":"2025-10-07 13:36:57+0900","categories":["Review"],"tags":["Review","Video Generation","Chain-of-Thought","Multimodal Models","Reasoning","Inference-Time Tuning","Sparse Supervision","Diffusion Models","Keyframe Generation"],"permalink":"/ai/review/2025-10-7-VChain_Chain-of-Visual-Thought_for_Reasoning_in_Video_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-7-Utility-Learning_Tension_in_Self-Modifying_Agents","title":"[논문리뷰] Utility-Learning Tension in Self-Modifying Agents","excerpt":"Peter Jin이 [arXiv]에 게시한 'Utility-Learning Tension in Self-Modifying Agents' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-07 13:36:57+0900","lastModifiedAt":"2025-10-07 13:36:57+0900","categories":["Review"],"tags":["Review","Self-Modifying Agents","PAC Learnability","VC Dimension","Capacity Bounds","Metacognition","Architectural Search","Algorithmic Stability","Generalization Theory"],"permalink":"/ai/review/2025-10-7-Utility-Learning_Tension_in_Self-Modifying_Agents/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-7-Thai_Semantic_End-of-Turn_Detection_for_Real-Time_Voice_Agents","title":"[논문리뷰] Thai Semantic End-of-Turn Detection for Real-Time Voice Agents","excerpt":"Monthol Charattrakool이 [arXiv]에 게시한 'Thai Semantic End-of-Turn Detection for Real-Time Voice Agents' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-07 13:36:57+0900","lastModifiedAt":"2025-10-07 13:36:57+0900","categories":["Review"],"tags":["Review","End-of-Turn Detection","Thai NLP","Voice Agents","Real-time Inference","Transformer Models","Few-shot Learning","Fine-tuning","Latency Optimization"],"permalink":"/ai/review/2025-10-7-Thai_Semantic_End-of-Turn_Detection_for_Real-Time_Voice_Agents/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-7-SwiReasoning_Switch-Thinking_in_Latent_and_Explicit_for_Pareto-Superior_Reasoning_LLMs","title":"[논문리뷰] SwiReasoning: Switch-Thinking in Latent and Explicit for Pareto-Superior Reasoning LLMs","excerpt":"이 [arXiv]에 게시한 'SwiReasoning: Switch-Thinking in Latent and Explicit for Pareto-Superior Reasoning LLMs' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-07 13:36:57+0900","lastModifiedAt":"2025-10-07 13:36:57+0900","categories":["Review"],"tags":["Review","LLM Reasoning","Latent Thinking","Explicit Thinking","Training-Free","Token Efficiency","Accuracy Improvement","Dynamic Switching","Entropy-based Control"],"permalink":"/ai/review/2025-10-7-SwiReasoning_Switch-Thinking_in_Latent_and_Explicit_for_Pareto-Superior_Reasoning_LLMs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-7-Self-Reflective_Generation_at_Test_Time","title":"[논문리뷰] Self-Reflective Generation at Test Time","excerpt":"Shuang Qiu이 [arXiv]에 게시한 'Self-Reflective Generation at Test Time' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-07 13:36:57+0900","lastModifiedAt":"2025-10-07 13:36:57+0900","categories":["Review"],"tags":["Review","Large Language Models","Self-Reflection","Test-Time Optimization","Uncertainty Monitoring","Proactive Error Prevention","Reasoning Tasks","Chain-of-Thought"],"permalink":"/ai/review/2025-10-7-Self-Reflective_Generation_at_Test_Time/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-7-SAEdit_Token-level_control_for_continuous_image_editing_via_Sparse_AutoEncoder","title":"[논문리뷰] SAEdit: Token-level control for continuous image editing via Sparse AutoEncoder","excerpt":"Or Patashnik이 [arXiv]에 게시한 'SAEdit: Token-level control for continuous image editing via Sparse AutoEncoder' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-07 13:36:57+0900","lastModifiedAt":"2025-10-07 13:36:57+0900","categories":["Review"],"tags":["Review","Image Editing","Diffusion Models","Sparse Autoencoder (SAE)","Text-to-Image","Disentangled Control","Continuous Control","Token-level Manipulation","Text Embeddings"],"permalink":"/ai/review/2025-10-7-SAEdit_Token-level_control_for_continuous_image_editing_via_Sparse_AutoEncoder/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-7-Reinforce-Ada_An_Adaptive_Sampling_Framework_for_Reinforce-Style_LLM_Training","title":"[논문리뷰] Reinforce-Ada: An Adaptive Sampling Framework for Reinforce-Style LLM Training","excerpt":"이 [arXiv]에 게시한 'Reinforce-Ada: An Adaptive Sampling Framework for Reinforce-Style LLM Training' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-07 13:36:57+0900","lastModifiedAt":"2025-10-07 13:36:57+0900","categories":["Review"],"tags":["Review","Reinforcement Learning (RL)","Large Language Models (LLMs)","Adaptive Sampling","Policy Gradient","Reward Optimization","Signal Collapse","Variance Reduction"],"permalink":"/ai/review/2025-10-7-Reinforce-Ada_An_Adaptive_Sampling_Framework_for_Reinforce-Style_LLM_Training/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-7-Reactive_Transformer_RxT_--_Stateful_Real-Time_Processing_for_Event-Driven_Reactive_Language_Models","title":"[논문리뷰] Reactive Transformer (RxT) -- Stateful Real-Time Processing for Event-Driven Reactive Language Models","excerpt":"이 [arXiv]에 게시한 'Reactive Transformer (RxT) -- Stateful Real-Time Processing for Event-Driven Reactive Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-07 13:36:57+0900","lastModifiedAt":"2025-10-07 13:36:57+0900","categories":["Review"],"tags":["Review","Reactive Transformer","Stateful LLM","Event-Driven AI","Asynchronous Memory","Conversational AI","Linear Scaling","Short-Term Memory (STM)","Memory Attention"],"permalink":"/ai/review/2025-10-7-Reactive_Transformer_RxT_--_Stateful_Real-Time_Processing_for_Event-Driven_Reactive_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-7-Optimal_Scaling_Needs_Optimal_Norm","title":"[논문리뷰] Optimal Scaling Needs Optimal Norm","excerpt":"Stefan Kesselheim이 [arXiv]에 게시한 'Optimal Scaling Needs Optimal Norm' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-07 13:36:57+0900","lastModifiedAt":"2025-10-07 13:36:57+0900","categories":["Review"],"tags":["Review","Optimal Scaling","Norm-Based Optimizers","Hyperparameter Transfer","Learning Rate Scaling","Batch Size Scaling","Transformer Models","Scion Optimizer","Large Language Models"],"permalink":"/ai/review/2025-10-7-Optimal_Scaling_Needs_Optimal_Norm/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-7-MoME_Mixture_of_Matryoshka_Experts_for_Audio-Visual_Speech_Recognition","title":"[논문리뷰] MoME: Mixture of Matryoshka Experts for Audio-Visual Speech Recognition","excerpt":"이 [arXiv]에 게시한 'MoME: Mixture of Matryoshka Experts for Audio-Visual Speech Recognition' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-07 13:36:57+0900","lastModifiedAt":"2025-10-07 13:36:57+0900","categories":["Review"],"tags":["Review","Audio-Visual Speech Recognition","Mixture of Experts","Matryoshka Representation Learning","Large Language Models","Elastic Inference","Token Compression","Multimodal AI"],"permalink":"/ai/review/2025-10-7-MoME_Mixture_of_Matryoshka_Experts_for_Audio-Visual_Speech_Recognition/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-7-MITS_Enhanced_Tree_Search_Reasoning_for_LLMs_via_Pointwise_Mutual_Information","title":"[논문리뷰] MITS: Enhanced Tree Search Reasoning for LLMs via Pointwise Mutual Information","excerpt":"이 [arXiv]에 게시한 'MITS: Enhanced Tree Search Reasoning for LLMs via Pointwise Mutual Information' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-07 13:36:57+0900","lastModifiedAt":"2025-10-07 13:36:57+0900","categories":["Review"],"tags":["Review","LLM Reasoning","Tree Search","Pointwise Mutual Information (PMI)","Dynamic Sampling","Beam Search","Weighted Voting","Information Theory","Computational Efficiency"],"permalink":"/ai/review/2025-10-7-MITS_Enhanced_Tree_Search_Reasoning_for_LLMs_via_Pointwise_Mutual_Information/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-7-LLMSQL_Upgrading_WikiSQL_for_the_LLM_Era_of_Text-to-SQL","title":"[논문리뷰] LLMSQL: Upgrading WikiSQL for the LLM Era of Text-to-SQL","excerpt":"이 [arXiv]에 게시한 'LLMSQL: Upgrading WikiSQL for the LLM Era of Text-to-SQL' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-07 13:36:57+0900","lastModifiedAt":"2025-10-07 13:36:57+0900","categories":["Review"],"tags":["Review","Text-to-SQL","WikiSQL","LLM","Dataset Curation","Natural Language Processing","Benchmark","SQL Generation","Data Cleaning"],"permalink":"/ai/review/2025-10-7-LLMSQL_Upgrading_WikiSQL_for_the_LLM_Era_of_Text-to-SQL/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-7-Learning_on_the_Job_Test-Time_Curricula_for_Targeted_Reinforcement_Learning","title":"[논문리뷰] Learning on the Job: Test-Time Curricula for Targeted Reinforcement Learning","excerpt":"이 [arXiv]에 게시한 'Learning on the Job: Test-Time Curricula for Targeted Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-07 13:36:57+0900","lastModifiedAt":"2025-10-07 13:36:57+0900","categories":["Review"],"tags":["Review","Test-Time Curriculum","Reinforcement Learning","Large Language Models","Self-Curated Learning","Continual Learning","Reasoning Benchmarks","Adaptive Training"],"permalink":"/ai/review/2025-10-7-Learning_on_the_Job_Test-Time_Curricula_for_Targeted_Reinforcement_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-7-Judging_with_Confidence_Calibrating_Autoraters_to_Preference_Distributions","title":"[논문리뷰] Judging with Confidence: Calibrating Autoraters to Preference Distributions","excerpt":"이 [arXiv]에 게시한 'Judging with Confidence: Calibrating Autoraters to Preference Distributions' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-07 13:36:57+0900","lastModifiedAt":"2025-10-07 13:36:57+0900","categories":["Review"],"tags":["Review","Large Language Models","Autoraters","Calibration","Preference Distributions","Reinforcement Learning","Supervised Fine-tuning","Positional Bias"],"permalink":"/ai/review/2025-10-7-Judging_with_Confidence_Calibrating_Autoraters_to_Preference_Distributions/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-7-Imperceptible_Jailbreaking_against_Large_Language_Models","title":"[논문리뷰] Imperceptible Jailbreaking against Large Language Models","excerpt":"이 [arXiv]에 게시한 'Imperceptible Jailbreaking against Large Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-07 13:36:57+0900","lastModifiedAt":"2025-10-07 13:36:57+0900","categories":["Review"],"tags":["Review","Large Language Models","Jailbreaking","Imperceptible Attacks","Unicode Variation Selectors","Adversarial Suffixes","Safety Alignment","Prompt Injection"],"permalink":"/ai/review/2025-10-7-Imperceptible_Jailbreaking_against_Large_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-7-Hybrid_Architectures_for_Language_Models_Systematic_Analysis_and_Design_Insights","title":"[논문리뷰] Hybrid Architectures for Language Models: Systematic Analysis and Design Insights","excerpt":"이 [arXiv]에 게시한 'Hybrid Architectures for Language Models: Systematic Analysis and Design Insights' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-07 13:36:57+0900","lastModifiedAt":"2025-10-07 13:36:57+0900","categories":["Review"],"tags":["Review","Hybrid LLM","Transformer Architecture","Mamba","State Space Models (SSM)","Computational Efficiency","Long-Context","Language Model Architectures","Scaling Laws"],"permalink":"/ai/review/2025-10-7-Hybrid_Architectures_for_Language_Models_Systematic_Analysis_and_Design_Insights/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-7-HiKE_Hierarchical_Evaluation_Framework_for_Korean-English_Code-Switching_Speech_Recognition","title":"[논문리뷰] HiKE: Hierarchical Evaluation Framework for Korean-English Code-Switching Speech Recognition","excerpt":"이 [arXiv]에 게시한 'HiKE: Hierarchical Evaluation Framework for Korean-English Code-Switching Speech Recognition' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-07 13:36:57+0900","lastModifiedAt":"2025-10-07 13:36:57+0900","categories":["Review"],"tags":["Review","Code-Switching","Speech Recognition","Korean-English ASR","Evaluation Framework","Multilingual ASR","Loanword Processing","Fine-tuning","Hierarchical Labeling"],"permalink":"/ai/review/2025-10-7-HiKE_Hierarchical_Evaluation_Framework_for_Korean-English_Code-Switching_Speech_Recognition/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-7-Graph2Eval_Automatic_Multimodal_Task_Generation_for_Agents_via_Knowledge_Graphs","title":"[논문리뷰] Graph2Eval: Automatic Multimodal Task Generation for Agents via Knowledge Graphs","excerpt":"Zeyi Liao이 [arXiv]에 게시한 'Graph2Eval: Automatic Multimodal Task Generation for Agents via Knowledge Graphs' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-07 13:36:57+0900","lastModifiedAt":"2025-10-07 13:36:57+0900","categories":["Review"],"tags":["Review","Agent Evaluation","Task Generation","Knowledge Graphs","Multimodal AI","Web Interaction","Document Comprehension","LLM-driven Agents"],"permalink":"/ai/review/2025-10-7-Graph2Eval_Automatic_Multimodal_Task_Generation_for_Agents_via_Knowledge_Graphs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-7-Good_Intentions_Beyond_ACL_Who_Does_NLP_for_Social_Good_and_Where","title":"[논문리뷰] Good Intentions Beyond ACL: Who Does NLP for Social Good, and Where?","excerpt":"Denis Peskoff이 [arXiv]에 게시한 'Good Intentions Beyond ACL: Who Does NLP for Social Good, and Where?' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-07 13:36:57+0900","lastModifiedAt":"2025-10-07 13:36:57+0900","categories":["Review"],"tags":["Review","NLP for Social Good","ACL Community","Scientometrics","Venue Analysis","Author Classification","Sustainable Development Goals","Neural Methods","Research Landscape"],"permalink":"/ai/review/2025-10-7-Good_Intentions_Beyond_ACL_Who_Does_NLP_for_Social_Good_and_Where/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-7-Front-Loading_Reasoning_The_Synergy_between_Pretraining_and_Post-Training_Data","title":"[논문리뷰] Front-Loading Reasoning: The Synergy between Pretraining and Post-Training Data","excerpt":"이 [arXiv]에 게시한 'Front-Loading Reasoning: The Synergy between Pretraining and Post-Training Data' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-07 13:36:57+0900","lastModifiedAt":"2025-10-07 13:36:57+0900","categories":["Review"],"tags":["Review","Large Language Models","Pretraining","Supervised Fine-tuning","Reasoning Data","Data Allocation","Diversity","Quality","Reinforcement Learning"],"permalink":"/ai/review/2025-10-7-Front-Loading_Reasoning_The_Synergy_between_Pretraining_and_Post-Training_Data/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-7-Factuality_Matters_When_Image_Generation_and_Editing_Meet_Structured_Visuals","title":"[논문리뷰] Factuality Matters: When Image Generation and Editing Meet Structured Visuals","excerpt":"Boxiang Qiu이 [arXiv]에 게시한 'Factuality Matters: When Image Generation and Editing Meet Structured Visuals' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-07 13:36:57+0900","lastModifiedAt":"2025-10-07 13:36:57+0900","categories":["Review"],"tags":["Review","Structured Visuals","Image Generation","Image Editing","Multimodal Reasoning","Factual Fidelity","Chain-of-Thought","Evaluation Benchmark","Diffusion Models"],"permalink":"/ai/review/2025-10-7-Factuality_Matters_When_Image_Generation_and_Editing_Meet_Structured_Visuals/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-7-EvolProver_Advancing_Automated_Theorem_Proving_by_Evolving_Formalized_Problems_via_Symmetry_and_Difficulty","title":"[논문리뷰] EvolProver: Advancing Automated Theorem Proving by Evolving Formalized Problems via Symmetry and Difficulty","excerpt":"Xuanwu Wang이 [arXiv]에 게시한 'EvolProver: Advancing Automated Theorem Proving by Evolving Formalized Problems via Symmetry and Difficulty' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-07 13:36:57+0900","lastModifiedAt":"2025-10-07 13:36:57+0900","categories":["Review"],"tags":["Review","Automated Theorem Proving","Data Augmentation","Large Language Models","Formal Mathematics","Symmetry","Difficulty Evolution","Abstract Syntax Tree","Generalizability"],"permalink":"/ai/review/2025-10-7-EvolProver_Advancing_Automated_Theorem_Proving_by_Evolving_Formalized_Problems_via_Symmetry_and_Difficulty/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-7-Epistemic_Diversity_and_Knowledge_Collapse_in_Large_Language_Models","title":"[논문리뷰] Epistemic Diversity and Knowledge Collapse in Large Language Models","excerpt":"이 [arXiv]에 게시한 'Epistemic Diversity and Knowledge Collapse in Large Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-07 13:36:57+0900","lastModifiedAt":"2025-10-07 13:36:57+0900","categories":["Review"],"tags":["Review","Large Language Models","Epistemic Diversity","Knowledge Collapse","Homogenization","Retrieval-Augmented Generation","LLM Evaluation","Information Diversity","Cultural Bias"],"permalink":"/ai/review/2025-10-7-Epistemic_Diversity_and_Knowledge_Collapse_in_Large_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-7-Code4MeV2_a_Research-oriented_Code-completion_Platform","title":"[논문리뷰] Code4MeV2: a Research-oriented Code-completion Platform","excerpt":"이 [arXiv]에 게시한 'Code4MeV2: a Research-oriented Code-completion Platform' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-07 13:36:57+0900","lastModifiedAt":"2025-10-07 13:36:57+0900","categories":["Review"],"tags":["Review","Code Completion","Research Platform","Human-AI Interaction","Software Engineering","Open Science","JetBrains IDE Plugin","Telemetry","AI4SE"],"permalink":"/ai/review/2025-10-7-Code4MeV2_a_Research-oriented_Code-completion_Platform/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-7-ChronoEdit_Towards_Temporal_Reasoning_for_Image_Editing_and_World_Simulation","title":"[논문리뷰] ChronoEdit: Towards Temporal Reasoning for Image Editing and World Simulation","excerpt":"이 [arXiv]에 게시한 'ChronoEdit: Towards Temporal Reasoning for Image Editing and World Simulation' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-07 13:36:57+0900","lastModifiedAt":"2025-10-07 13:36:57+0900","categories":["Review"],"tags":["Review","Image Editing","Video Generation","Temporal Reasoning","World Simulation","Physical Consistency","Diffusion Models","Generative Models"],"permalink":"/ai/review/2025-10-7-ChronoEdit_Towards_Temporal_Reasoning_for_Image_Editing_and_World_Simulation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-7-Character_Mixing_for_Video_Generation","title":"[논문리뷰] Character Mixing for Video Generation","excerpt":"이 [arXiv]에 게시한 'Character Mixing for Video Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-07 13:36:57+0900","lastModifiedAt":"2025-10-07 13:36:57+0900","categories":["Review"],"tags":["Review","Video Generation","Character Mixing","Style Preservation","Multi-character Interaction","Text-to-Video","Cross-Domain Synthesis","Identity Preservation"],"permalink":"/ai/review/2025-10-7-Character_Mixing_for_Video_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-7-Alignment_Tipping_Process_How_Self-Evolution_Pushes_LLM_Agents_Off_the_Rails","title":"[논문리뷰] Alignment Tipping Process: How Self-Evolution Pushes LLM Agents Off the Rails","excerpt":"Xinyuan Liu이 [arXiv]에 게시한 'Alignment Tipping Process: How Self-Evolution Pushes LLM Agents Off the Rails' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-07 13:36:57+0900","lastModifiedAt":"2025-10-07 13:36:57+0900","categories":["Review"],"tags":["Review","LLM Agents","Alignment","Self-Evolution","Behavioral Drift","Reinforcement Learning","Multi-Agent Systems","Alignment Tipping Process"],"permalink":"/ai/review/2025-10-7-Alignment_Tipping_Process_How_Self-Evolution_Pushes_LLM_Agents_Off_the_Rails/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-7-Agentic_Context_Engineering_Evolving_Contexts_for_Self-Improving_Language_Models","title":"[논문리뷰] Agentic Context Engineering: Evolving Contexts for Self-Improving Language Models","excerpt":"Fenglu Hong이 [arXiv]에 게시한 'Agentic Context Engineering: Evolving Contexts for Self-Improving Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-07 13:36:57+0900","lastModifiedAt":"2025-10-07 13:36:57+0900","categories":["Review"],"tags":["Review","LLM Context Adaptation","Agentic AI","Self-Improving Systems","Prompt Engineering","Context Management","Dynamic Playbooks","Incremental Learning"],"permalink":"/ai/review/2025-10-7-Agentic_Context_Engineering_Evolving_Contexts_for_Self-Improving_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-7-AdvEvo-MARL_Shaping_Internalized_Safety_through_Adversarial_Co-Evolution_in_Multi-Agent_Reinforcement_Learning","title":"[논문리뷰] AdvEvo-MARL: Shaping Internalized Safety through Adversarial Co-Evolution in Multi-Agent Reinforcement Learning","excerpt":"Zeliang Zhang이 [arXiv]에 게시한 'AdvEvo-MARL: Shaping Internalized Safety through Adversarial Co-Evolution in Multi-Agent Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-07 13:36:57+0900","lastModifiedAt":"2025-10-07 13:36:57+0900","categories":["Review"],"tags":["Review","Multi-Agent Reinforcement Learning","Adversarial Co-evolution","LLM Safety","Jailbreak Attacks","Internalized Safety","Public Baseline","System Robustness"],"permalink":"/ai/review/2025-10-7-AdvEvo-MARL_Shaping_Internalized_Safety_through_Adversarial_Co-Evolution_in_Multi-Agent_Reinforcement_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-6-Your_Agent_May_Misevolve_Emergent_Risks_in_Self-evolving_LLM_Agents","title":"[논문리뷰] Your Agent May Misevolve: Emergent Risks in Self-evolving LLM Agents","excerpt":"Boyi Wei이 [arXiv]에 게시한 'Your Agent May Misevolve: Emergent Risks in Self-evolving LLM Agents' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-06 13:29:11+0900","lastModifiedAt":"2025-10-06 13:29:11+0900","categories":["Review"],"tags":["Review","Self-evolving Agents","LLM Safety","Misevolution","Emergent Risks","Model Evolution","Memory Evolution","Tool Evolution","Workflow Evolution"],"permalink":"/ai/review/2025-10-6-Your_Agent_May_Misevolve_Emergent_Risks_in_Self-evolving_LLM_Agents/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-6-WAInjectBench_Benchmarking_Prompt_Injection_Detections_for_Web_Agents","title":"[논문리뷰] WAInjectBench: Benchmarking Prompt Injection Detections for Web Agents","excerpt":"Neil Zhenqiang Gong이 [arXiv]에 게시한 'WAInjectBench: Benchmarking Prompt Injection Detections for Web Agents' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-06 13:29:11+0900","lastModifiedAt":"2025-10-06 13:29:11+0900","categories":["Review"],"tags":["Review","Prompt Injection","Web Agents","Multimodal AI","Adversarial Attacks","Detection Benchmarking","Large Language Models","Image-based Detection","Text-based Detection"],"permalink":"/ai/review/2025-10-6-WAInjectBench_Benchmarking_Prompt_Injection_Detections_for_Web_Agents/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-6-Triangle_Splatting_Differentiable_Rendering_with_Opaque_Triangles","title":"[논문리뷰] Triangle Splatting+: Differentiable Rendering with Opaque Triangles","excerpt":"Matheus Gadelha이 [arXiv]에 게시한 'Triangle Splatting+: Differentiable Rendering with Opaque Triangles' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-06 13:29:11+0900","lastModifiedAt":"2025-10-06 13:29:11+0900","categories":["Review"],"tags":["Review","Differentiable Rendering","3D Reconstruction","Novel View Synthesis","Triangles","Opaque Primitives","Game Engines","Gaussian Splatting","Mesh-based Rendering"],"permalink":"/ai/review/2025-10-6-Triangle_Splatting_Differentiable_Rendering_with_Opaque_Triangles/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-6-TalkPlay-Tools_Conversational_Music_Recommendation_with_LLM_Tool_Calling","title":"[논문리뷰] TalkPlay-Tools: Conversational Music Recommendation with LLM Tool Calling","excerpt":"Juhan Nam이 [arXiv]에 게시한 'TalkPlay-Tools: Conversational Music Recommendation with LLM Tool Calling' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-06 13:29:11+0900","lastModifiedAt":"2025-10-06 13:29:11+0900","categories":["Review"],"tags":["Review","Conversational Recommendation","LLM Tool Calling","Music Recommendation","Multimodal Retrieval","Information Retrieval","Retrieval-Reranking","Semantic IDs"],"permalink":"/ai/review/2025-10-6-TalkPlay-Tools_Conversational_Music_Recommendation_with_LLM_Tool_Calling/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-6-SurveyBench_How_Well_Can_LLM-Agents_Write_Academic_Surveys","title":"[논문리뷰] SurveyBench: How Well Can LLM(-Agents) Write Academic Surveys?","excerpt":"Shuo Wang이 [arXiv]에 게시한 'SurveyBench: How Well Can LLM(-Agents) Write Academic Surveys?' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-06 13:29:11+0900","lastModifiedAt":"2025-10-06 13:29:11+0900","categories":["Review"],"tags":["Review","LLM","LLM Agents","Academic Survey Generation","Evaluation Framework","Benchmark","Quiz-driven Evaluation","Content Quality Metrics"],"permalink":"/ai/review/2025-10-6-SurveyBench_How_Well_Can_LLM-Agents_Write_Academic_Surveys/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-6-SpineBench_A_Clinically_Salient_Level-Aware_Benchmark_Powered_by_the_SpineMed-450k_Corpus","title":"[논문리뷰] SpineBench: A Clinically Salient, Level-Aware Benchmark Powered by the SpineMed-450k Corpus","excerpt":"Zhonghao Zhang이 [arXiv]에 게시한 'SpineBench: A Clinically Salient, Level-Aware Benchmark Powered by the SpineMed-450k Corpus' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-06 13:29:11+0900","lastModifiedAt":"2025-10-06 13:29:11+0900","categories":["Review"],"tags":["Review","Medical AI","Spine Diagnosis","Multimodal LLM","Benchmark","Dataset","Clinical Reasoning","Spine Surgery","Vision-Language Model"],"permalink":"/ai/review/2025-10-6-SpineBench_A_Clinically_Salient_Level-Aware_Benchmark_Powered_by_the_SpineMed-450k_Corpus/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-6-Self-Improvement_in_Multimodal_Large_Language_Models_A_Survey","title":"[논문리뷰] Self-Improvement in Multimodal Large Language Models: A Survey","excerpt":"Yapeng Tian이 [arXiv]에 게시한 'Self-Improvement in Multimodal Large Language Models: A Survey' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-06 13:29:11+0900","lastModifiedAt":"2025-10-06 13:29:11+0900","categories":["Review"],"tags":["Review","Multimodal Large Language Models (MLLMs)","Self-Improvement","Data Collection","Data Organization","Model Optimization","Survey","Reinforcement Learning","Direct Preference Optimization"],"permalink":"/ai/review/2025-10-6-Self-Improvement_in_Multimodal_Large_Language_Models_A_Survey/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-6-Scaling_Policy_Compliance_Assessment_in_Language_Models_with_Policy_Reasoning_Traces","title":"[논문리뷰] Scaling Policy Compliance Assessment in Language Models with Policy Reasoning Traces","excerpt":"이 [arXiv]에 게시한 'Scaling Policy Compliance Assessment in Language Models with Policy Reasoning Traces' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-06 13:29:11+0900","lastModifiedAt":"2025-10-06 13:29:11+0900","categories":["Review"],"tags":["Review","Policy Compliance","Large Language Models (LLMs)","Reasoning Traces","In-Context Learning (ICL)","Supervised Finetuning (SFT)","HIPAA","GDPR","ModelSpec"],"permalink":"/ai/review/2025-10-6-Scaling_Policy_Compliance_Assessment_in_Language_Models_with_Policy_Reasoning_Traces/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-6-REPAIR_Robust_Editing_via_Progressive_Adaptive_Intervention_and_Reintegration","title":"[논문리뷰] REPAIR: Robust Editing via Progressive Adaptive Intervention and Reintegration","excerpt":"이 [arXiv]에 게시한 'REPAIR: Robust Editing via Progressive Adaptive Intervention and Reintegration' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-06 13:29:11+0900","lastModifiedAt":"2025-10-06 13:29:11+0900","categories":["Review"],"tags":["Review","Model Editing","Lifelong Learning","LLMs","Continual Learning","Knowledge Distillation","Error Feedback","Memory Management","Parameter Merging"],"permalink":"/ai/review/2025-10-6-REPAIR_Robust_Editing_via_Progressive_Adaptive_Intervention_and_Reintegration/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-6-OrtSAE_Orthogonal_Sparse_Autoencoders_Uncover_Atomic_Features","title":"[논문리뷰] OrtSAE: Orthogonal Sparse Autoencoders Uncover Atomic Features","excerpt":"Elena Tutubalina이 [arXiv]에 게시한 'OrtSAE: Orthogonal Sparse Autoencoders Uncover Atomic Features' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-06 13:29:11+0900","lastModifiedAt":"2025-10-06 13:29:11+0900","categories":["Review"],"tags":["Review","Sparse Autoencoders","Mechanistic Interpretability","Feature Disentanglement","Orthogonality","LLM Features","Feature Absorption","Feature Composition"],"permalink":"/ai/review/2025-10-6-OrtSAE_Orthogonal_Sparse_Autoencoders_Uncover_Atomic_Features/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-6-NuRisk_A_Visual_Question_Answering_Dataset_for_Agent-Level_Risk_Assessment_in_Autonomous_Driving","title":"[논문리뷰] NuRisk: A Visual Question Answering Dataset for Agent-Level Risk Assessment in Autonomous Driving","excerpt":"이 [arXiv]에 게시한 'NuRisk: A Visual Question Answering Dataset for Agent-Level Risk Assessment in Autonomous Driving' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-06 13:29:11+0900","lastModifiedAt":"2025-10-06 13:29:11+0900","categories":["Review"],"tags":["Review","Visual Question Answering (VQA)","Autonomous Driving","Risk Assessment","Spatio-Temporal Reasoning","Large Vision Models (VLMs)","Dataset","Bird-Eye-View (BEV)","Fine-tuning"],"permalink":"/ai/review/2025-10-6-NuRisk_A_Visual_Question_Answering_Dataset_for_Agent-Level_Risk_Assessment_in_Autonomous_Driving/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-6-LSPO_Length-aware_Dynamic_Sampling_for_Policy_Optimization_in_LLM_Reasoning","title":"[논문리뷰] LSPO: Length-aware Dynamic Sampling for Policy Optimization in LLM Reasoning","excerpt":"이 [arXiv]에 게시한 'LSPO: Length-aware Dynamic Sampling for Policy Optimization in LLM Reasoning' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-06 13:29:11+0900","lastModifiedAt":"2025-10-06 13:29:11+0900","categories":["Review"],"tags":["Review","LLM Reasoning","RLVR","Dynamic Sampling","Policy Optimization","Response Length","Meta-RL","Overthinking"],"permalink":"/ai/review/2025-10-6-LSPO_Length-aware_Dynamic_Sampling_for_Policy_Optimization_in_LLM_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-6-LEAML_Label-Efficient_Adaptation_to_Out-of-Distribution_Visual_Tasks_for_Multimodal_Large_Language_Models","title":"[논문리뷰] LEAML: Label-Efficient Adaptation to Out-of-Distribution Visual Tasks for Multimodal Large Language Models","excerpt":"Yu-Chiang Frank Wang이 [arXiv]에 게시한 'LEAML: Label-Efficient Adaptation to Out-of-Distribution Visual Tasks for Multimodal Large Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-06 13:29:11+0900","lastModifiedAt":"2025-10-06 13:29:11+0900","categories":["Review"],"tags":["Review","Multimodal LLM","OOD Adaptation","Label Efficiency","VQA","Semi-Supervised Learning","Neuron Distillation","Pseudo Labeling","Medical Imaging"],"permalink":"/ai/review/2025-10-6-LEAML_Label-Efficient_Adaptation_to_Out-of-Distribution_Visual_Tasks_for_Multimodal_Large_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-6-Improving_GUI_Grounding_with_Explicit_Position-to-Coordinate_Mapping","title":"[논문리뷰] Improving GUI Grounding with Explicit Position-to-Coordinate Mapping","excerpt":"Spandana Gella이 [arXiv]에 게시한 'Improving GUI Grounding with Explicit Position-to-Coordinate Mapping' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-06 13:29:11+0900","lastModifiedAt":"2025-10-06 13:29:11+0900","categories":["Review"],"tags":["Review","GUI Grounding","Vision-Language Models","Positional Embedding","UI Automation","Coordinate Prediction","Resolution Generalization","Transformer Architecture"],"permalink":"/ai/review/2025-10-6-Improving_GUI_Grounding_with_Explicit_Position-to-Coordinate_Mapping/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-6-How_Confident_are_Video_Models_Empowering_Video_Models_to_Express_their_Uncertainty","title":"[논문리뷰] How Confident are Video Models? Empowering Video Models to Express their Uncertainty","excerpt":"Anirudha Majumdar이 [arXiv]에 게시한 'How Confident are Video Models? Empowering Video Models to Express their Uncertainty' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-06 13:29:11+0900","lastModifiedAt":"2025-10-06 13:29:11+0900","categories":["Review"],"tags":["Review","Video Generation","Uncertainty Quantification","Aleatoric Uncertainty","Epistemic Uncertainty","Model Calibration","Text-to-Video","Generative AI","VMF Distribution"],"permalink":"/ai/review/2025-10-6-How_Confident_are_Video_Models_Empowering_Video_Models_to_Express_their_Uncertainty/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-6-Free_Lunch_Alignment_of_Text-to-Image_Diffusion_Models_without_Preference_Image_Pairs","title":"[논문리뷰] Free Lunch Alignment of Text-to-Image Diffusion Models without Preference Image Pairs","excerpt":"이 [arXiv]에 게시한 'Free Lunch Alignment of Text-to-Image Diffusion Models without Preference Image Pairs' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-06 13:29:11+0900","lastModifiedAt":"2025-10-06 13:29:11+0900","categories":["Review"],"tags":["Review","Text-to-Image Models","Diffusion Models","Preference Optimization","LLMs","RLHF","Prompt Editing","Free Lunch Alignment","TDPO","TKTO"],"permalink":"/ai/review/2025-10-6-Free_Lunch_Alignment_of_Text-to-Image_Diffusion_Models_without_Preference_Image_Pairs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-6-FocusAgent_Simple_Yet_Effective_Ways_of_Trimming_the_Large_Context_of_Web_Agents","title":"[논문리뷰] FocusAgent: Simple Yet Effective Ways of Trimming the Large Context of Web Agents","excerpt":"Léo Boisvert이 [arXiv]에 게시한 'FocusAgent: Simple Yet Effective Ways of Trimming the Large Context of Web Agents' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-06 13:29:11+0900","lastModifiedAt":"2025-10-06 13:29:11+0900","categories":["Review"],"tags":["Review","Web Agents","LLM Context Pruning","Accessibility Tree","Prompt Injection","Retrieval Augmented Generation","Web Navigation","Agent Security","Efficient LLM"],"permalink":"/ai/review/2025-10-6-FocusAgent_Simple_Yet_Effective_Ways_of_Trimming_the_Large_Context_of_Web_Agents/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-6-Efficient_Multi-modal_Large_Language_Models_via_Progressive_Consistency_Distillation","title":"[논문리뷰] Efficient Multi-modal Large Language Models via Progressive Consistency Distillation","excerpt":"이 [arXiv]에 게시한 'Efficient Multi-modal Large Language Models via Progressive Consistency Distillation' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-06 13:29:11+0900","lastModifiedAt":"2025-10-06 13:29:11+0900","categories":["Review"],"tags":["Review","Multi-modal LLMs","Token Compression","Efficiency","Knowledge Distillation","Progressive Learning","Consistency Distillation","MLLM Training"],"permalink":"/ai/review/2025-10-6-Efficient_Multi-modal_Large_Language_Models_via_Progressive_Consistency_Distillation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-6-DiffTester_Accelerating_Unit_Test_Generation_for_Diffusion_LLMs_via_Repetitive_Pattern","title":"[논문리뷰] DiffTester: Accelerating Unit Test Generation for Diffusion LLMs via Repetitive Pattern","excerpt":"Jia Li이 [arXiv]에 게시한 'DiffTester: Accelerating Unit Test Generation for Diffusion LLMs via Repetitive Pattern' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-06 13:29:11+0900","lastModifiedAt":"2025-10-06 13:29:11+0900","categories":["Review"],"tags":["Review","Diffusion LLMs","Unit Test Generation","Acceleration","Repetitive Patterns","Abstract Syntax Tree","Software Testing","Code Generation"],"permalink":"/ai/review/2025-10-6-DiffTester_Accelerating_Unit_Test_Generation_for_Diffusion_LLMs_via_Repetitive_Pattern/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-6-Compose_Your_Policies_Improving_Diffusion-based_or_Flow-based_Robot_Policies_via_Test-time_Distribution-level_Composition","title":"[논문리뷰] Compose Your Policies! Improving Diffusion-based or Flow-based Robot Policies via Test-time Distribution-level Composition","excerpt":"이 [arXiv]에 게시한 'Compose Your Policies! Improving Diffusion-based or Flow-based Robot Policies via Test-time Distribution-level Composition' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-06 13:29:11+0900","lastModifiedAt":"2025-10-06 13:29:11+0900","categories":["Review"],"tags":["Review","Diffusion Models","Flow-based Models","Robotics Control","Policy Composition","Test-time Optimization","Score-based Models","Training-free"],"permalink":"/ai/review/2025-10-6-Compose_Your_Policies_Improving_Diffusion-based_or_Flow-based_Robot_Policies_via_Test-time_Distribution-level_Composition/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-6-CoDA_Agentic_Systems_for_Collaborative_Data_Visualization","title":"[논문리뷰] CoDA: Agentic Systems for Collaborative Data Visualization","excerpt":"이 [arXiv]에 게시한 'CoDA: Agentic Systems for Collaborative Data Visualization' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-06 13:29:11+0900","lastModifiedAt":"2025-10-06 13:29:11+0900","categories":["Review"],"tags":["Review","Multi-agent Systems","Data Visualization","LLM","Automation","Self-reflection","Code Generation","Natural Language to Visualization"],"permalink":"/ai/review/2025-10-6-CoDA_Agentic_Systems_for_Collaborative_Data_Visualization/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-6-A_Practitioners_Guide_to_Multi-turn_Agentic_Reinforcement_Learning","title":"[논문리뷰] A Practitioner's Guide to Multi-turn Agentic Reinforcement Learning","excerpt":"이 [arXiv]에 게시한 'A Practitioner's Guide to Multi-turn Agentic Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-06 13:29:11+0900","lastModifiedAt":"2025-10-06 13:29:11+0900","categories":["Review"],"tags":["Review","Multi-turn Reinforcement Learning","LLM Agents","Text-based Environments","Reward Shaping","Policy Optimization","Supervised Fine-tuning (SFT)","Generalization","Environment Complexity"],"permalink":"/ai/review/2025-10-6-A_Practitioners_Guide_to_Multi-turn_Agentic_Reinforcement_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-6-Apriel-1.5-15b-Thinker","title":"[논문리뷰] Apriel-1.5-15b-Thinker","excerpt":"이 [arXiv]에 게시한 'Apriel-1.5-15b-Thinker' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-06 13:29:11+0900","lastModifiedAt":"2025-10-06 13:29:11+0900","categories":["Review"],"tags":["Review","Multimodal Reasoning Model","Open-Weights Model","Continual Pretraining (CPT)","Supervised Fine-Tuning (SFT)","Training Design","Efficiency","Frontier Performance"],"permalink":"/ai/review/2025-10-6-Apriel-1.5-15b-Thinker/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-6-Align_Your_Tangent_Training_Better_Consistency_Models_via_Manifold-Aligned_Tangents","title":"[논문리뷰] Align Your Tangent: Training Better Consistency Models via Manifold-Aligned Tangents","excerpt":"Jong Chul Ye이 [arXiv]에 게시한 'Align Your Tangent: Training Better Consistency Models via Manifold-Aligned Tangents' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-06 13:29:11+0900","lastModifiedAt":"2025-10-06 13:29:11+0900","categories":["Review"],"tags":["Review","Consistency Models","Generative Models","Manifold Learning","Tangent Alignment","Diffusion Models","Training Dynamics","Manifold Feature Distance"],"permalink":"/ai/review/2025-10-6-Align_Your_Tangent_Training_Better_Consistency_Models_via_Manifold-Aligned_Tangents/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-2-Why_Cant_Transformers_Learn_Multiplication_Reverse-Engineering_Reveals_Long-Range_Dependency_Pitfalls","title":"[논문리뷰] Why Can't Transformers Learn Multiplication? Reverse-Engineering Reveals Long-Range Dependency Pitfalls","excerpt":"Stuart Shieber이 [arXiv]에 게시한 'Why Can't Transformers Learn Multiplication? Reverse-Engineering Reveals Long-Range Dependency Pitfalls' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-02 13:30:22+0900","lastModifiedAt":"2025-10-02 13:30:22+0900","categories":["Review"],"tags":["Review","Transformers","Multiplication","Long-Range Dependencies","Implicit Chain-of-Thought","Attention Mechanisms","Inductive Bias","Reverse Engineering"],"permalink":"/ai/review/2025-10-2-Why_Cant_Transformers_Learn_Multiplication_Reverse-Engineering_Reveals_Long-Range_Dependency_Pitfalls/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-2-VLM-FO1_Bridging_the_Gap_Between_High-Level_Reasoning_and_Fine-Grained_Perception_in_VLMs","title":"[논문리뷰] VLM-FO1: Bridging the Gap Between High-Level Reasoning and Fine-Grained Perception in VLMs","excerpt":"이 [arXiv]에 게시한 'VLM-FO1: Bridging the Gap Between High-Level Reasoning and Fine-Grained Perception in VLMs' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-02 13:30:22+0900","lastModifiedAt":"2025-10-02 13:30:22+0900","categories":["Review"],"tags":["Review","Vision-Language Models","Object Grounding","Fine-grained Perception","Hybrid Region Encoder","Plug-and-play","Two-stage Training","Visual Reasoning"],"permalink":"/ai/review/2025-10-2-VLM-FO1_Bridging_the_Gap_Between_High-Level_Reasoning_and_Fine-Grained_Perception_in_VLMs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-2-VLA-RFT_Vision-Language-Action_Reinforcement_Fine-tuning_with_Verified_Rewards_in_World_Simulators","title":"[논문리뷰] VLA-RFT: Vision-Language-Action Reinforcement Fine-tuning with Verified Rewards in World Simulators","excerpt":"Zirui Ge이 [arXiv]에 게시한 'VLA-RFT: Vision-Language-Action Reinforcement Fine-tuning with Verified Rewards in World Simulators' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-02 13:30:22+0900","lastModifiedAt":"2025-10-02 13:30:22+0900","categories":["Review"],"tags":["Review","Vision-Language-Action Models","Reinforcement Learning","World Models","Fine-tuning","Embodied AI","Robotics","Reward Design","Distribution Shift"],"permalink":"/ai/review/2025-10-2-VLA-RFT_Vision-Language-Action_Reinforcement_Fine-tuning_with_Verified_Rewards_in_World_Simulators/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-2-Training_Vision-Language_Process_Reward_Models_for_Test-Time_Scaling_in_Multimodal_Reasoning_Key_Insights_and_Lessons_Learned","title":"[논문리뷰] Training Vision-Language Process Reward Models for Test-Time Scaling in Multimodal Reasoning: Key Insights and Lessons Learned","excerpt":"이 [arXiv]에 게시한 'Training Vision-Language Process Reward Models for Test-Time Scaling in Multimodal Reasoning: Key Insights and Lessons Learned' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-02 13:30:22+0900","lastModifiedAt":"2025-10-02 13:30:22+0900","categories":["Review"],"tags":["Review","Vision-Language Models (VLMs)","Process Reward Models (PRMs)","Multimodal Reasoning","Test-Time Scaling (TTS)","Process Supervision","Dataset Construction","Perception Errors","MCTS"],"permalink":"/ai/review/2025-10-2-Training_Vision-Language_Process_Reward_Models_for_Test-Time_Scaling_in_Multimodal_Reasoning_Key_Insights_and_Lessons_Learned/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-2-ReSWD_ReSTIRd_not_shaken._Combining_Reservoir_Sampling_and_Sliced_Wasserstein_Distance_for_Variance_Reduction","title":"[논문리뷰] ReSWD: ReSTIR'd, not shaken. Combining Reservoir Sampling and Sliced Wasserstein Distance for Variance Reduction","excerpt":"이 [arXiv]에 게시한 'ReSWD: ReSTIR'd, not shaken. Combining Reservoir Sampling and Sliced Wasserstein Distance for Variance Reduction' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-02 13:30:22+0900","lastModifiedAt":"2025-10-02 13:30:22+0900","categories":["Review"],"tags":["Review","Sliced Wasserstein Distance","Reservoir Sampling","Variance Reduction","Distribution Matching","Diffusion Guidance","Color Correction","Monte Carlo Estimation"],"permalink":"/ai/review/2025-10-2-ReSWD_ReSTIRd_not_shaken._Combining_Reservoir_Sampling_and_Sliced_Wasserstein_Distance_for_Variance_Reduction/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-2-PIPer_On-Device_Environment_Setup_via_Online_Reinforcement_Learning","title":"[논문리뷰] PIPer: On-Device Environment Setup via Online Reinforcement Learning","excerpt":"이 [arXiv]에 게시한 'PIPer: On-Device Environment Setup via Online Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-02 13:30:22+0900","lastModifiedAt":"2025-10-02 13:30:22+0900","categories":["Review"],"tags":["Review","Environment Setup","LLMs","Reinforcement Learning","Supervised Fine-tuning","On-device AI","Software Engineering","Verifiable Rewards"],"permalink":"/ai/review/2025-10-2-PIPer_On-Device_Environment_Setup_via_Online_Reinforcement_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-2-On_Predictability_of_Reinforcement_Learning_Dynamics_for_Large_Language_Models","title":"[논문리뷰] On Predictability of Reinforcement Learning Dynamics for Large Language Models","excerpt":"Yuqing Huang이 [arXiv]에 게시한 'On Predictability of Reinforcement Learning Dynamics for Large Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-02 13:30:22+0900","lastModifiedAt":"2025-10-02 13:30:22+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","Large Language Models","Parameter Dynamics","Rank-1 Dominance","Linear Dynamics","SVD","Model Acceleration","Predictability"],"permalink":"/ai/review/2025-10-2-On_Predictability_of_Reinforcement_Learning_Dynamics_for_Large_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-2-Making_not_Taking_the_Best_of_N","title":"[논문리뷰] Making, not Taking, the Best of N","excerpt":"이 [arXiv]에 게시한 'Making, not Taking, the Best of N' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-02 13:30:22+0900","lastModifiedAt":"2025-10-02 13:30:22+0900","categories":["Review"],"tags":["Review","LLM Aggregation","Generative Fusion","Best-of-N","Synthetic Data Generation","Test-Time Scaling","Multilingual Models","Ensemble Learning"],"permalink":"/ai/review/2025-10-2-Making_not_Taking_the_Best_of_N/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-2-Knapsack_RL_Unlocking_Exploration_of_LLMs_via_Optimizing_Budget_Allocation","title":"[논문리뷰] Knapsack RL: Unlocking Exploration of LLMs via Optimizing Budget Allocation","excerpt":"이 [arXiv]에 게시한 'Knapsack RL: Unlocking Exploration of LLMs via Optimizing Budget Allocation' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-02 13:30:22+0900","lastModifiedAt":"2025-10-02 13:30:22+0900","categories":["Review"],"tags":["Review","Large Language Models (LLMs)","Reinforcement Learning (RL)","Exploration Budget Allocation","Knapsack Problem","Group Relative Policy Optimization (GRPO)","Mathematical Reasoning","Resource Optimization"],"permalink":"/ai/review/2025-10-2-Knapsack_RL_Unlocking_Exploration_of_LLMs_via_Optimizing_Budget_Allocation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-2-JoyAgent-JDGenie_Technical_Report_on_the_GAIA","title":"[논문리뷰] JoyAgent-JDGenie: Technical Report on the GAIA","excerpt":"이 [arXiv]에 게시한 'JoyAgent-JDGenie: Technical Report on the GAIA' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-02 13:30:22+0900","lastModifiedAt":"2025-10-02 13:30:22+0900","categories":["Review"],"tags":["Review","Generalist Agent","Multi-Agent System","Plan-Execute","ReAct","Hierarchical Memory","Tool Integration","GAIA Benchmark","LLM Agent"],"permalink":"/ai/review/2025-10-2-JoyAgent-JDGenie_Technical_Report_on_the_GAIA/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-2-Infusing_Theory_of_Mind_into_Socially_Intelligent_LLM_Agents","title":"[논문리뷰] Infusing Theory of Mind into Socially Intelligent LLM Agents","excerpt":"이 [arXiv]에 게시한 'Infusing Theory of Mind into Socially Intelligent LLM Agents' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-02 13:30:22+0900","lastModifiedAt":"2025-10-02 13:30:22+0900","categories":["Review"],"tags":["Review","Theory of Mind","Large Language Models","Social Agents","Dialogue Systems","Mental State Modeling","Look-ahead Planning","Supervised Fine-tuning","Sotopia Benchmark"],"permalink":"/ai/review/2025-10-2-Infusing_Theory_of_Mind_into_Socially_Intelligent_LLM_Agents/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-2-In-Place_Feedback_A_New_Paradigm_for_Guiding_LLMs_in_Multi-Turn_Reasoning","title":"[논문리뷰] In-Place Feedback: A New Paradigm for Guiding LLMs in Multi-Turn Reasoning","excerpt":"Chaehyeon Chung이 [arXiv]에 게시한 'In-Place Feedback: A New Paradigm for Guiding LLMs in Multi-Turn Reasoning' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-02 13:30:22+0900","lastModifiedAt":"2025-10-02 13:30:22+0900","categories":["Review"],"tags":["Review","LLM Feedback","Multi-turn Reasoning","In-place Editing","Token Efficiency","Error Correction","Human-AI Interaction","Reasoning Tasks"],"permalink":"/ai/review/2025-10-2-In-Place_Feedback_A_New_Paradigm_for_Guiding_LLMs_in_Multi-Turn_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-2-Hyperdimensional_Probe_Decoding_LLM_Representations_via_Vector_Symbolic_Architectures","title":"[논문리뷰] Hyperdimensional Probe: Decoding LLM Representations via Vector Symbolic Architectures","excerpt":"Andrea Passerini이 [arXiv]에 게시한 'Hyperdimensional Probe: Decoding LLM Representations via Vector Symbolic Architectures' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-02 13:30:22+0900","lastModifiedAt":"2025-10-02 13:30:22+0900","categories":["Review"],"tags":["Review","LLM Interpretability","Vector Symbolic Architectures","Neural Probing","Information Decoding","Hyperdimensional Computing","Latent Representations"],"permalink":"/ai/review/2025-10-2-Hyperdimensional_Probe_Decoding_LLM_Representations_via_Vector_Symbolic_Architectures/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-2-GUI-KV_Efficient_GUI_Agents_via_KV_Cache_with_Spatio-Temporal_Awareness","title":"[논문리뷰] GUI-KV: Efficient GUI Agents via KV Cache with Spatio-Temporal Awareness","excerpt":"Chien-Sheng Wu이 [arXiv]에 게시한 'GUI-KV: Efficient GUI Agents via KV Cache with Spatio-Temporal Awareness' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-02 13:30:22+0900","lastModifiedAt":"2025-10-02 13:30:22+0900","categories":["Review"],"tags":["Review","GUI Agents","KV Cache Compression","Spatio-Temporal Awareness","Vision-Language Models","Efficiency","Attention Sparsity","QR Decomposition"],"permalink":"/ai/review/2025-10-2-GUI-KV_Efficient_GUI_Agents_via_KV_Cache_with_Spatio-Temporal_Awareness/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-2-GEM_A_Gym_for_Agentic_LLMs","title":"[논문리뷰] GEM: A Gym for Agentic LLMs","excerpt":"이 [arXiv]에 게시한 'GEM: A Gym for Agentic LLMs' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-02 13:30:22+0900","lastModifiedAt":"2025-10-02 13:30:22+0900","categories":["Review"],"tags":["Review","Agentic LLMs","Reinforcement Learning","Environment Simulator","Multi-turn Interactions","Return Batch Normalization","Tool Integration","Benchmarking"],"permalink":"/ai/review/2025-10-2-GEM_A_Gym_for_Agentic_LLMs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-2-Flash-Searcher_Fast_and_Effective_Web_Agents_via_DAG-Based_Parallel_Execution","title":"[논문리뷰] Flash-Searcher: Fast and Effective Web Agents via DAG-Based Parallel Execution","excerpt":"이 [arXiv]에 게시한 'Flash-Searcher: Fast and Effective Web Agents via DAG-Based Parallel Execution' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-02 13:30:22+0900","lastModifiedAt":"2025-10-02 13:30:22+0900","categories":["Review"],"tags":["Review","LLM Agents","Parallel Execution","DAG-based Planning","Tool Orchestration","Web Agents","Reasoning Framework","Efficiency"],"permalink":"/ai/review/2025-10-2-Flash-Searcher_Fast_and_Effective_Web_Agents_via_DAG-Based_Parallel_Execution/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-2-Eliciting_Secret_Knowledge_from_Language_Models","title":"[논문리뷰] Eliciting Secret Knowledge from Language Models","excerpt":"Neel Nanda이 [arXiv]에 게시한 'Eliciting Secret Knowledge from Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-02 13:30:22+0900","lastModifiedAt":"2025-10-02 13:30:22+0900","categories":["Review"],"tags":["Review","Language Models","Secret Elicitation","Mechanistic Interpretability","Black-box Methods","White-box Methods","AI Auditing","Model Organisms","Prefill Attacks"],"permalink":"/ai/review/2025-10-2-Eliciting_Secret_Knowledge_from_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-2-DeepSearch_Overcome_the_Bottleneck_of_Reinforcement_Learning_with_Verifiable_Rewards_via_Monte_Carlo_Tree_Search","title":"[논문리뷰] DeepSearch: Overcome the Bottleneck of Reinforcement Learning with Verifiable Rewards via Monte Carlo Tree Search","excerpt":"이 [arXiv]에 게시한 'DeepSearch: Overcome the Bottleneck of Reinforcement Learning with Verifiable Rewards via Monte Carlo Tree Search' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-02 13:30:22+0900","lastModifiedAt":"2025-10-02 13:30:22+0900","categories":["Review"],"tags":["Review","Reinforcement Learning with Verifiable Rewards (RLVR)","Monte Carlo Tree Search (MCTS)","Mathematical Reasoning","Large Language Models (LLMs)","Systematic Exploration","Adaptive Training","Tree-GRPO"],"permalink":"/ai/review/2025-10-2-DeepSearch_Overcome_the_Bottleneck_of_Reinforcement_Learning_with_Verifiable_Rewards_via_Monte_Carlo_Tree_Search/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-2-CurES_From_Gradient_Analysis_to_Efficient_Curriculum_Learning_for_Reasoning_LLMs","title":"[논문리뷰] CurES: From Gradient Analysis to Efficient Curriculum Learning for Reasoning LLMs","excerpt":"Hengyi Cai이 [arXiv]에 게시한 'CurES: From Gradient Analysis to Efficient Curriculum Learning for Reasoning LLMs' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-02 13:30:22+0900","lastModifiedAt":"2025-10-02 13:30:22+0900","categories":["Review"],"tags":["Review","Curriculum Learning","LLMs","Reasoning","Gradient Optimization","Reinforcement Learning","Bayesian Inference","Sample Efficiency"],"permalink":"/ai/review/2025-10-2-CurES_From_Gradient_Analysis_to_Efficient_Curriculum_Learning_for_Reasoning_LLMs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-2-Code2Video_A_Code-centric_Paradigm_for_Educational_Video_Generation","title":"[논문리뷰] Code2Video: A Code-centric Paradigm for Educational Video Generation","excerpt":"이 [arXiv]에 게시한 'Code2Video: A Code-centric Paradigm for Educational Video Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-02 13:30:22+0900","lastModifiedAt":"2025-10-02 13:30:22+0900","categories":["Review"],"tags":["Review","Educational Video Generation","Code-centric AI","Multi-agent Framework","Manim","Vision-Language Models","Knowledge Transfer","Code Generation","MMMC Benchmark"],"permalink":"/ai/review/2025-10-2-Code2Video_A_Code-centric_Paradigm_for_Educational_Video_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-2-BroRL_Scaling_Reinforcement_Learning_via_Broadened_Exploration","title":"[논문리뷰] BroRL: Scaling Reinforcement Learning via Broadened Exploration","excerpt":"이 [arXiv]에 게시한 'BroRL: Scaling Reinforcement Learning via Broadened Exploration' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-02 13:30:22+0900","lastModifiedAt":"2025-10-02 13:30:22+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","LLMs","Scaling Laws","Exploration","Rollout Size","Verifiable Rewards","PPO","Mass Balance Equation"],"permalink":"/ai/review/2025-10-2-BroRL_Scaling_Reinforcement_Learning_via_Broadened_Exploration/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-2-Boolean_Satisfiability_via_Imitation_Learning","title":"[논문리뷰] Boolean Satisfiability via Imitation Learning","excerpt":"Xiangyu Xu이 [arXiv]에 게시한 'Boolean Satisfiability via Imitation Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-02 13:30:22+0900","lastModifiedAt":"2025-10-02 13:30:22+0900","categories":["Review"],"tags":["Review","Boolean Satisfiability","Imitation Learning","CDCL Solvers","Branching Policy","KeyTrace","Transformer Architecture","Perceiver AR"],"permalink":"/ai/review/2025-10-2-Boolean_Satisfiability_via_Imitation_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-2-BindWeave_Subject-Consistent_Video_Generation_via_Cross-Modal_Integration","title":"[논문리뷰] BindWeave: Subject-Consistent Video Generation via Cross-Modal Integration","excerpt":"Xiangyang Xia이 [arXiv]에 게시한 'BindWeave: Subject-Consistent Video Generation via Cross-Modal Integration' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-02 13:30:22+0900","lastModifiedAt":"2025-10-02 13:30:22+0900","categories":["Review"],"tags":["Review","Video Generation","Subject Consistency","Cross-Modal Integration","Diffusion Models","Multimodal LLM","Diffusion Transformer","Text-to-Video"],"permalink":"/ai/review/2025-10-2-BindWeave_Subject-Consistent_Video_Generation_via_Cross-Modal_Integration/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-2-BiasFreeBench_a_Benchmark_for_Mitigating_Bias_in_Large_Language_Model_Responses","title":"[논문리뷰] BiasFreeBench: a Benchmark for Mitigating Bias in Large Language Model Responses","excerpt":"Julian McAuley이 [arXiv]에 게시한 'BiasFreeBench: a Benchmark for Mitigating Bias in Large Language Model Responses' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-02 13:30:22+0900","lastModifiedAt":"2025-10-02 13:30:22+0900","categories":["Review"],"tags":["Review","LLM Bias Mitigation","Benchmark","Evaluation Metrics","Prompt Engineering","Fine-tuning","Bias-Free Score","Fairness"],"permalink":"/ai/review/2025-10-2-BiasFreeBench_a_Benchmark_for_Mitigating_Bias_in_Large_Language_Model_Responses/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-2-Beyond_Log_Likelihood_Probability-Based_Objectives_for_Supervised_Fine-Tuning_across_the_Model_Capability_Continuum","title":"[논문리뷰] Beyond Log Likelihood: Probability-Based Objectives for Supervised Fine-Tuning across the Model Capability Continuum","excerpt":"Hanghang Tong이 [arXiv]에 게시한 'Beyond Log Likelihood: Probability-Based Objectives for Supervised Fine-Tuning across the Model Capability Continuum' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-02 13:30:22+0900","lastModifiedAt":"2025-10-02 13:30:22+0900","categories":["Review"],"tags":["Review","Supervised Fine-tuning (SFT)","Large Language Models (LLMs)","Training Objectives","Negative Log Likelihood (NLL)","Model Capability Continuum","Generalization","Probability-based Loss Functions"],"permalink":"/ai/review/2025-10-2-Beyond_Log_Likelihood_Probability-Based_Objectives_for_Supervised_Fine-Tuning_across_the_Model_Capability_Continuum/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-2-An_Empirical_Study_of_Testing_Practices_in_Open_Source_AI_Agent_Frameworks_and_Agentic_Applications","title":"[논문리뷰] An Empirical Study of Testing Practices in Open Source AI Agent Frameworks and Agentic Applications","excerpt":"Bram Adams이 [arXiv]에 게시한 'An Empirical Study of Testing Practices in Open Source AI Agent Frameworks and Agentic Applications' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-02 13:30:22+0900","lastModifiedAt":"2025-10-02 13:30:22+0900","categories":["Review"],"tags":["Review","AI Agent","LLM Agent","Testing","Empirical Study","Software Quality","Agent Frameworks","Agentic Applications","Non-Determinism"],"permalink":"/ai/review/2025-10-2-An_Empirical_Study_of_Testing_Practices_in_Open_Source_AI_Agent_Frameworks_and_Agentic_Applications/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-2-ACON_Optimizing_Context_Compression_for_Long-horizon_LLM_Agents","title":"[논문리뷰] ACON: Optimizing Context Compression for Long-horizon LLM Agents","excerpt":"이 [arXiv]에 게시한 'ACON: Optimizing Context Compression for Long-horizon LLM Agents' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-02 13:30:22+0900","lastModifiedAt":"2025-10-02 13:30:22+0900","categories":["Review"],"tags":["Review","LLM Agents","Context Compression","Long-horizon Tasks","Prompt Optimization","Knowledge Distillation","Memory Efficiency","Task Performance","Failure Analysis"],"permalink":"/ai/review/2025-10-2-ACON_Optimizing_Context_Compression_for_Long-horizon_LLM_Agents/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-Winning_the_Pruning_Gamble_A_Unified_Approach_to_Joint_Sample_and_Token_Pruning_for_Efficient_Supervised_Fine-Tuning","title":"[논문리뷰] Winning the Pruning Gamble: A Unified Approach to Joint Sample and Token Pruning for Efficient Supervised Fine-Tuning","excerpt":"Yue Min이 [arXiv]에 게시한 'Winning the Pruning Gamble: A Unified Approach to Joint Sample and Token Pruning for Efficient Supervised Fine-Tuning' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","LLM SFT","Data Pruning","Sample Pruning","Token Pruning","Error-Uncertainty Plane","Q-Tuning","Data Efficiency","Dynamic Pruning"],"permalink":"/ai/review/2025-10-1-Winning_the_Pruning_Gamble_A_Unified_Approach_to_Joint_Sample_and_Token_Pruning_for_Efficient_Supervised_Fine-Tuning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-Who_invented_deep_residual_learning","title":"[논문리뷰] Who invented deep residual learning?","excerpt":"Juergen Schmidhuber이 [arXiv]에 게시한 'Who invented deep residual learning?' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","Deep Learning History","Residual Connections","Recurrent Neural Networks (RNN)","Long Short-Term Memory (LSTM)","Feedforward Neural Networks (FNN)","Highway Networks","ResNet","Vanishing Gradient"],"permalink":"/ai/review/2025-10-1-Who_invented_deep_residual_learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-Whos_Your_Judge_On_the_Detectability_of_LLM-Generated_Judgments","title":"[논문리뷰] Who's Your Judge? On the Detectability of LLM-Generated Judgments","excerpt":"이 [arXiv]에 게시한 'Who's Your Judge? On the Detectability of LLM-Generated Judgments' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","LLM-as-a-judge","Judgment Detection","Bias Quantification","Feature Engineering","Interpretability","Peer Review","AI Ethics","Evaluation"],"permalink":"/ai/review/2025-10-1-Whos_Your_Judge_On_the_Detectability_of_LLM-Generated_Judgments/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-Voice_Evaluation_of_Reasoning_Ability_Diagnosing_the_Modality-Induced_Performance_Gap","title":"[논문리뷰] Voice Evaluation of Reasoning Ability: Diagnosing the Modality-Induced Performance Gap","excerpt":"Hengfan Zhang이 [arXiv]에 게시한 'Voice Evaluation of Reasoning Ability: Diagnosing the Modality-Induced Performance Gap' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","Voice AI","LLM","Reasoning","Benchmark","Modality Gap","Latency","Speech Recognition","Generative AI","Real-time Systems","Conversational AI"],"permalink":"/ai/review/2025-10-1-Voice_Evaluation_of_Reasoning_Ability_Diagnosing_the_Modality-Induced_Performance_Gap/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-VitaBench_Benchmarking_LLM_Agents_with_Versatile_Interactive_Tasks_in_Real-world_Applications","title":"[논문리뷰] VitaBench: Benchmarking LLM Agents with Versatile Interactive Tasks in Real-world Applications","excerpt":"이 [arXiv]에 게시한 'VitaBench: Benchmarking LLM Agents with Versatile Interactive Tasks in Real-world Applications' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","LLM Agents","Benchmarking","Interactive Tasks","Real-world Applications","Tool Use","Multi-turn Conversation","Task Complexity"],"permalink":"/ai/review/2025-10-1-VitaBench_Benchmarking_LLM_Agents_with_Versatile_Interactive_Tasks_in_Real-world_Applications/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-VisualOverload_Probing_Visual_Understanding_of_VLMs_in_Really_Dense_Scenes","title":"[논문리뷰] VisualOverload: Probing Visual Understanding of VLMs in Really Dense Scenes","excerpt":"Muhammad Huzaifa이 [arXiv]에 게시한 'VisualOverload: Probing Visual Understanding of VLMs in Really Dense Scenes' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","Visual Question Answering","Multimodal Models","Dense Scenes","Fine-Grained Perception","Benchmark","Error Analysis","Counting","OCR"],"permalink":"/ai/review/2025-10-1-VisualOverload_Probing_Visual_Understanding_of_VLMs_in_Really_Dense_Scenes/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-Vision-Zero_Scalable_VLM_Self-Improvement_via_Strategic_Gamified_Self-Play","title":"[논문리뷰] Vision-Zero: Scalable VLM Self-Improvement via Strategic Gamified Self-Play","excerpt":"Jing Shi이 [arXiv]에 게시한 'Vision-Zero: Scalable VLM Self-Improvement via Strategic Gamified Self-Play' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","Vision-Language Models (VLMs)","Self-Play","Reinforcement Learning","Gamification","Data Efficiency","Strategic Reasoning","Multimodal AI","Self-Improvement"],"permalink":"/ai/review/2025-10-1-Vision-Zero_Scalable_VLM_Self-Improvement_via_Strategic_Gamified_Self-Play/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-TTT3R_3D_Reconstruction_as_Test-Time_Training","title":"[논문리뷰] TTT3R: 3D Reconstruction as Test-Time Training","excerpt":"Anpei Chen이 [arXiv]에 게시한 'TTT3R: 3D Reconstruction as Test-Time Training' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","3D Reconstruction","Test-Time Training (TTT)","Recurrent Neural Networks (RNN)","Online Learning","Length Generalization","Associative Memory","State Update Rule"],"permalink":"/ai/review/2025-10-1-TTT3R_3D_Reconstruction_as_Test-Time_Training/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-TruthRL_Incentivizing_Truthful_LLMs_via_Reinforcement_Learning","title":"[논문리뷰] TruthRL: Incentivizing Truthful LLMs via Reinforcement Learning","excerpt":"이 [arXiv]에 게시한 'TruthRL: Incentivizing Truthful LLMs via Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","LLM Hallucination","Truthfulness","Reinforcement Learning","Ternary Reward","Abstention","Knowledge Boundary","GRPO","RLHF"],"permalink":"/ai/review/2025-10-1-TruthRL_Incentivizing_Truthful_LLMs_via_Reinforcement_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-Thinking_Sparks_Emergent_Attention_Heads_in_Reasoning_Models_During_Post_Training","title":"[논문리뷰] Thinking Sparks!: Emergent Attention Heads in Reasoning Models During Post Training","excerpt":"이 [arXiv]에 게시한 'Thinking Sparks!: Emergent Attention Heads in Reasoning Models During Post Training' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","Mechanistic Interpretability","Attention Heads","Post-Training","Supervised Fine-Tuning (SFT)","Reinforcement Learning (RL)","Circuit Analysis","Reasoning Models","Transformer Architecture"],"permalink":"/ai/review/2025-10-1-Thinking_Sparks_Emergent_Attention_Heads_in_Reasoning_Models_During_Post_Training/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-The_Dragon_Hatchling_The_Missing_Link_between_the_Transformer_and_Models_of_the_Brain","title":"[논문리뷰] The Dragon Hatchling: The Missing Link between the Transformer and Models of the Brain","excerpt":"이 [arXiv]에 게시한 'The Dragon Hatchling: The Missing Link between the Transformer and Models of the Brain' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","Large Language Models","Brain-Inspired AI","Graph Neural Networks","Hebbian Learning","Scale-Free Networks","Model Interpretability","Transformer Architecture"],"permalink":"/ai/review/2025-10-1-The_Dragon_Hatchling_The_Missing_Link_between_the_Transformer_and_Models_of_the_Brain/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-Test-Time_Policy_Adaptation_for_Enhanced_Multi-Turn_Interactions_with_LLMs","title":"[논문리뷰] Test-Time Policy Adaptation for Enhanced Multi-Turn Interactions with LLMs","excerpt":"Yao Shu이 [arXiv]에 게시한 'Test-Time Policy Adaptation for Enhanced Multi-Turn Interactions with LLMs' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","Large Language Models","Multi-turn Interaction","Test-Time Adaptation","Reinforcement Learning from Human Feedback","Policy Optimization","Online Learning","Self-Correction"],"permalink":"/ai/review/2025-10-1-Test-Time_Policy_Adaptation_for_Enhanced_Multi-Turn_Interactions_with_LLMs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-TAU_A_Benchmark_for_Cultural_Sound_Understanding_Beyond_Semantics","title":"[논문리뷰] TAU: A Benchmark for Cultural Sound Understanding Beyond Semantics","excerpt":"Szu-Chi Chen이 [arXiv]에 게시한 'TAU: A Benchmark for Cultural Sound Understanding Beyond Semantics' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","Audio Language Models","Cultural Sound Understanding","Localized Benchmark","Non-semantic Audio","Human-in-the-loop","Multimodal AI","Taipei Soundscape"],"permalink":"/ai/review/2025-10-1-TAU_A_Benchmark_for_Cultural_Sound_Understanding_Beyond_Semantics/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-Stable_Cinemetrics_Structured_Taxonomy_and_Evaluation_for_Professional_Video_Generation","title":"[논문리뷰] Stable Cinemetrics : Structured Taxonomy and Evaluation for Professional Video Generation","excerpt":"이 [arXiv]에 게시한 'Stable Cinemetrics : Structured Taxonomy and Evaluation for Professional Video Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","Video Generation","Evaluation Framework","Cinematic Control","Taxonomy","Human Annotation","Vision-Language Models","Text-to-Video"],"permalink":"/ai/review/2025-10-1-Stable_Cinemetrics_Structured_Taxonomy_and_Evaluation_for_Professional_Video_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-Specialization_after_Generalization_Towards_Understanding_Test-Time_Training_in_Foundation_Models","title":"[논문리뷰] Specialization after Generalization: Towards Understanding Test-Time Training in Foundation Models","excerpt":"이 [arXiv]에 게시한 'Specialization after Generalization: Towards Understanding Test-Time Training in Foundation Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","Test-Time Training (TTT)","Foundation Models","Underparameterization","Sparse Autoencoders (SAE)","Linear Representation Hypothesis (LRH)","Specialization","Scaling Laws","In-Distribution Data"],"permalink":"/ai/review/2025-10-1-Specialization_after_Generalization_Towards_Understanding_Test-Time_Training_in_Foundation_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-Regression_Language_Models_for_Code","title":"[논문리뷰] Regression Language Models for Code","excerpt":"이 [arXiv]에 게시한 'Regression Language Models for Code' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","Regression Language Model","Code Performance Prediction","Static Analysis","Neural Architecture Search","Text-to-Text Regression","Multi-task Learning","T5Gemma","ONNX"],"permalink":"/ai/review/2025-10-1-Regression_Language_Models_for_Code/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-ProfVLM_A_Lightweight_Video-Language_Model_for_Multi-View_Proficiency_Estimation","title":"[논문리뷰] ProfVLM: A Lightweight Video-Language Model for Multi-View Proficiency Estimation","excerpt":"Antonio Liotta이 [arXiv]에 게시한 'ProfVLM: A Lightweight Video-Language Model for Multi-View Proficiency Estimation' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","Video-Language Model","Proficiency Estimation","Multi-View Video","Action Quality Assessment","Lightweight Model","Generative Feedback"],"permalink":"/ai/review/2025-10-1-ProfVLM_A_Lightweight_Video-Language_Model_for_Multi-View_Proficiency_Estimation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-Probing_the_Critical_Point_CritPt_of_AI_Reasoning_a_Frontier_Physics_Research_Benchmark","title":"[논문리뷰] Probing the Critical Point (CritPt) of AI Reasoning: a Frontier Physics Research Benchmark","excerpt":"Penghao Zhu이 [arXiv]에 게시한 'Probing the Critical Point (CritPt) of AI Reasoning: a Frontier Physics Research Benchmark' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","AI Reasoning","Physics Research","LLM Evaluation","Scientific Benchmark","Frontier Physics","Problem Solving","Model Reliability","Auto-grading"],"permalink":"/ai/review/2025-10-1-Probing_the_Critical_Point_CritPt_of_AI_Reasoning_a_Frontier_Physics_Research_Benchmark/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-OffTopicEval_When_Large_Language_Models_Enter_the_Wrong_Chat_Almost_Always","title":"[논문리뷰] OffTopicEval: When Large Language Models Enter the Wrong Chat, Almost Always!","excerpt":"이 [arXiv]에 게시한 'OffTopicEval: When Large Language Models Enter the Wrong Chat, Almost Always!' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","Large Language Models (LLMs)","Operational Safety","Out-of-Domain (OOD)","Prompt Steering","Jailbreak Attacks","Evaluation Benchmark","Refusal Rate"],"permalink":"/ai/review/2025-10-1-OffTopicEval_When_Large_Language_Models_Enter_the_Wrong_Chat_Almost_Always/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-OceanGym_A_Benchmark_Environment_for_Underwater_Embodied_Agents","title":"[논문리뷰] OceanGym: A Benchmark Environment for Underwater Embodied Agents","excerpt":"이 [arXiv]에 게시한 'OceanGym: A Benchmark Environment for Underwater Embodied Agents' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","Underwater Robotics","Embodied AI","Benchmark Environment","Multi-modal Large Language Models","Autonomous Underwater Vehicles","Perception","Decision-Making","Simulation"],"permalink":"/ai/review/2025-10-1-OceanGym_A_Benchmark_Environment_for_Underwater_Embodied_Agents/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-MotionRAG_Motion_Retrieval-Augmented_Image-to-Video_Generation","title":"[논문리뷰] MotionRAG: Motion Retrieval-Augmented Image-to-Video Generation","excerpt":"Limin Wang이 [arXiv]에 게시한 'MotionRAG: Motion Retrieval-Augmented Image-to-Video Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","Image-to-Video Generation","Motion Transfer","Retrieval-Augmented Generation (RAG)","In-Context Learning","Diffusion Models","Video Diffusion","Motion Realism"],"permalink":"/ai/review/2025-10-1-MotionRAG_Motion_Retrieval-Augmented_Image-to-Video_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-More_Thought_Less_Accuracy_On_the_Dual_Nature_of_Reasoning_in_Vision-Language_Models","title":"[논문리뷰] More Thought, Less Accuracy? On the Dual Nature of Reasoning in Vision-Language Models","excerpt":"Fabian Waschkowski이 [arXiv]에 게시한 'More Thought, Less Accuracy? On the Dual Nature of Reasoning in Vision-Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","Vision-Language Models","Multimodal Reasoning","Reasoning","Visual Forgetting","Perceptual Grounding","Reinforcement Learning","Policy Optimization","Visual Anchors"],"permalink":"/ai/review/2025-10-1-More_Thought_Less_Accuracy_On_the_Dual_Nature_of_Reasoning_in_Vision-Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-Mem-α_Learning_Memory_Construction_via_Reinforcement_Learning","title":"[논문리뷰] Mem-α: Learning Memory Construction via Reinforcement Learning","excerpt":"Yuzhen Mao이 [arXiv]에 게시한 'Mem-α: Learning Memory Construction via Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","LLM Agents","External Memory","Reinforcement Learning","Memory Management","Long-Context Understanding","Tool Learning","RAG","Memory Architecture"],"permalink":"/ai/review/2025-10-1-Mem-α_Learning_Memory_Construction_via_Reinforcement_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-MCPMark_A_Benchmark_for_Stress-Testing_Realistic_and_Comprehensive_MCP_Use","title":"[논문리뷰] MCPMark: A Benchmark for Stress-Testing Realistic and Comprehensive MCP Use","excerpt":"이 [arXiv]에 게시한 'MCPMark: A Benchmark for Stress-Testing Realistic and Comprehensive MCP Use' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","LLM Agents","Model Context Protocol","Benchmark","Tool Use","CRUD Operations","Workflow Automation","Stress Testing","Evaluation"],"permalink":"/ai/review/2025-10-1-MCPMark_A_Benchmark_for_Stress-Testing_Realistic_and_Comprehensive_MCP_Use/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-MANI-Pure_Magnitude-Adaptive_Noise_Injection_for_Adversarial_Purification","title":"[논문리뷰] MANI-Pure: Magnitude-Adaptive Noise Injection for Adversarial Purification","excerpt":"Zhiming Luo이 [arXiv]에 게시한 'MANI-Pure: Magnitude-Adaptive Noise Injection for Adversarial Purification' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","Adversarial Purification","Diffusion Models","Frequency Domain","Adaptive Noise Injection","Robustness","Image Security","Magnitude Spectrum"],"permalink":"/ai/review/2025-10-1-MANI-Pure_Magnitude-Adaptive_Noise_Injection_for_Adversarial_Purification/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-Learning_to_See_Before_Seeing_Demystifying_LLM_Visual_Priors_from_Language_Pre-training","title":"[논문리뷰] Learning to See Before Seeing: Demystifying LLM Visual Priors from Language Pre-training","excerpt":"Koustuv Sinha이 [arXiv]에 게시한 'Learning to See Before Seeing: Demystifying LLM Visual Priors from Language Pre-training' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","LLM Visual Priors","Language Pre-training","Multimodal LLM","Data Mixture Optimization","Reasoning Prior","Perception Prior","VQA","MLE-Bench"],"permalink":"/ai/review/2025-10-1-Learning_to_See_Before_Seeing_Demystifying_LLM_Visual_Priors_from_Language_Pre-training/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-Learning_Human-Perceived_Fakeness_in_AI-Generated_Videos_via_Multimodal_LLMs","title":"[논문리뷰] Learning Human-Perceived Fakeness in AI-Generated Videos via Multimodal LLMs","excerpt":"이 [arXiv]에 게시한 'Learning Human-Perceived Fakeness in AI-Generated Videos via Multimodal LLMs' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","AI-Generated Videos","Deepfake Detection","Multimodal LLMs","Human Perception","Video Generation Evaluation","Spatiotemporal Annotation","Reward Modeling"],"permalink":"/ai/review/2025-10-1-Learning_Human-Perceived_Fakeness_in_AI-Generated_Videos_via_Multimodal_LLMs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-LayerD_Decomposing_Raster_Graphic_Designs_into_Layers","title":"[논문리뷰] LayerD: Decomposing Raster Graphic Designs into Layers","excerpt":"Kota Yamaguchi이 [arXiv]에 게시한 'LayerD: Decomposing Raster Graphic Designs into Layers' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","Graphic Design","Image Decomposition","Layer Extraction","Image Matting","Background Completion","Deep Learning","Creative AI","Dynamic Time Warping"],"permalink":"/ai/review/2025-10-1-LayerD_Decomposing_Raster_Graphic_Designs_into_Layers/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-Knowledge_Homophily_in_Large_Language_Models","title":"[논문리뷰] Knowledge Homophily in Large Language Models","excerpt":"Nedim Lipka이 [arXiv]에 게시한 'Knowledge Homophily in Large Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","LLM","Knowledge Homophily","Graph Neural Networks","Knowledge Graph","Knowledge Injection","Question Answering","Fine-tuning","Knowledge Retrieval"],"permalink":"/ai/review/2025-10-1-Knowledge_Homophily_in_Large_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-jina-reranker-v3_Last_but_Not_Late_Interaction_for_Document_Reranking","title":"[논문리뷰] jina-reranker-v3: Last but Not Late Interaction for Document Reranking","excerpt":"이 [arXiv]에 게시한 'jina-reranker-v3: Last but Not Late Interaction for Document Reranking' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","Document Reranking","Last but Not Late Interaction","Multilingual","Transformer Architecture","Cross-Encoder","InfoNCE Loss","Contextual Embedding","Qwen3"],"permalink":"/ai/review/2025-10-1-jina-reranker-v3_Last_but_Not_Late_Interaction_for_Document_Reranking/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-InfoAgent_Advancing_Autonomous_Information-Seeking_Agents","title":"[논문리뷰] InfoAgent: Advancing Autonomous Information-Seeking Agents","excerpt":"이 [arXiv]에 게시한 'InfoAgent: Advancing Autonomous Information-Seeking Agents' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","LLM Agents","Information Seeking","Reinforcement Learning","Data Synthesis","Web Search Tools","Tool Use","Deep Research Agents"],"permalink":"/ai/review/2025-10-1-InfoAgent_Advancing_Autonomous_Information-Seeking_Agents/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-IMG_Calibrating_Diffusion_Models_via_Implicit_Multimodal_Guidance","title":"[논문리뷰] IMG: Calibrating Diffusion Models via Implicit Multimodal Guidance","excerpt":"이 [arXiv]에 게시한 'IMG: Calibrating Diffusion Models via Implicit Multimodal Guidance' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","Diffusion Models","Multimodal Alignment","MLLM","Image Re-generation","Preference Learning","Implicit Guidance","Text-to-Image"],"permalink":"/ai/review/2025-10-1-IMG_Calibrating_Diffusion_Models_via_Implicit_Multimodal_Guidance/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-Humanline_Online_Alignment_as_Perceptual_Loss","title":"[논문리뷰] Humanline: Online Alignment as Perceptual Loss","excerpt":"이 [arXiv]에 게시한 'Humanline: Online Alignment as Perceptual Loss' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","LLM Alignment","Online RLHF","Offline RLHF","Prospect Theory","Perceptual Loss","Human-Centric AI","Reinforcement Learning"],"permalink":"/ai/review/2025-10-1-Humanline_Online_Alignment_as_Perceptual_Loss/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-Ferret-UI_Lite_Lessons_from_Building_Small_On-Device_GUI_Agents","title":"[논문리뷰] Ferret-UI Lite: Lessons from Building Small On-Device GUI Agents","excerpt":"이 [arXiv]에 게시한 'Ferret-UI Lite: Lessons from Building Small On-Device GUI Agents' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","GUI Agents","On-Device AI","Multimodal LLM","GUI Grounding","GUI Navigation","Reinforcement Learning","Supervised Fine-tuning","Synthetic Data"],"permalink":"/ai/review/2025-10-1-Ferret-UI_Lite_Lessons_from_Building_Small_On-Device_GUI_Agents/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-Estimating_Time_Series_Foundation_Model_Transferability_via_In-Context_Learning","title":"[논문리뷰] Estimating Time Series Foundation Model Transferability via In-Context Learning","excerpt":"Jun Qi이 [arXiv]에 게시한 'Estimating Time Series Foundation Model Transferability via In-Context Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","Time Series Foundation Models","Transferability Estimation","In-Context Learning","Tabular Foundation Models","Model Selection","Entropy Profile","Meta-learning","Forecasting"],"permalink":"/ai/review/2025-10-1-Estimating_Time_Series_Foundation_Model_Transferability_via_In-Context_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-EntroPE_Entropy-Guided_Dynamic_Patch_Encoder_for_Time_Series_Forecasting","title":"[논문리뷰] EntroPE: Entropy-Guided Dynamic Patch Encoder for Time Series Forecasting","excerpt":"이 [arXiv]에 게시한 'EntroPE: Entropy-Guided Dynamic Patch Encoder for Time Series Forecasting' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","Time Series Forecasting","Transformer","Dynamic Patching","Entropy","Predictive Uncertainty","Adaptive Encoding","Attention Mechanisms","Causal Transformer"],"permalink":"/ai/review/2025-10-1-EntroPE_Entropy-Guided_Dynamic_Patch_Encoder_for_Time_Series_Forecasting/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-Efficient_Audio-Visual_Speech_Separation_with_Discrete_Lip_Semantics_and_Multi-Scale_Global-Local_Attention","title":"[논문리뷰] Efficient Audio-Visual Speech Separation with Discrete Lip Semantics and Multi-Scale Global-Local Attention","excerpt":"이 [arXiv]에 게시한 'Efficient Audio-Visual Speech Separation with Discrete Lip Semantics and Multi-Scale Global-Local Attention' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","Audio-Visual Speech Separation","Deep Learning","Efficiency","Discrete Lip Semantics","Global-Local Attention","Lightweight Models","VQ-VAE"],"permalink":"/ai/review/2025-10-1-Efficient_Audio-Visual_Speech_Separation_with_Discrete_Lip_Semantics_and_Multi-Scale_Global-Local_Attention/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-dParallel_Learnable_Parallel_Decoding_for_dLLMs","title":"[논문리뷰] dParallel: Learnable Parallel Decoding for dLLMs","excerpt":"이 [arXiv]에 게시한 'dParallel: Learnable Parallel Decoding for dLLMs' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","Diffusion Language Models","Parallel Decoding","Inference Acceleration","Certainty Distillation","Self-Distillation","Masked Language Models","LLaDA"],"permalink":"/ai/review/2025-10-1-dParallel_Learnable_Parallel_Decoding_for_dLLMs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-DeepScientist_Advancing_Frontier-Pushing_Scientific_Findings_Progressively","title":"[논문리뷰] DeepScientist: Advancing Frontier-Pushing Scientific Findings Progressively","excerpt":"이 [arXiv]에 게시한 'DeepScientist: Advancing Frontier-Pushing Scientific Findings Progressively' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","AI Scientist","Autonomous Scientific Discovery","Bayesian Optimization","LLM-based Agents","SOTA-Surpassing","Findings Memory","Exploration-Exploitation"],"permalink":"/ai/review/2025-10-1-DeepScientist_Advancing_Frontier-Pushing_Scientific_Findings_Progressively/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-DC-VideoGen_Efficient_Video_Generation_with_Deep_Compression_Video_Autoencoder","title":"[논문리뷰] DC-VideoGen: Efficient Video Generation with Deep Compression Video Autoencoder","excerpt":"이 [arXiv]에 게시한 'DC-VideoGen: Efficient Video Generation with Deep Compression Video Autoencoder' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","Video Generation","Diffusion Models","Video Autoencoder","Deep Compression","Model Acceleration","Fine-tuning","Latent Space","Temporal Modeling"],"permalink":"/ai/review/2025-10-1-DC-VideoGen_Efficient_Video_Generation_with_Deep_Compression_Video_Autoencoder/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-DA2_Depth_Anything_in_Any_Direction","title":"[논문리뷰] DA^2: Depth Anything in Any Direction","excerpt":"이 [arXiv]에 게시한 'DA^2: Depth Anything in Any Direction' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","Panoramic Depth Estimation","Zero-shot Generalization","Data Curation","SphereViT","Spherical Geometry","360-degree Imaging","Vision Transformer"],"permalink":"/ai/review/2025-10-1-DA2_Depth_Anything_in_Any_Direction/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-d2Cache_Accelerating_Diffusion-Based_LLMs_via_Dual_Adaptive_Caching","title":"[논문리뷰] d^2Cache: Accelerating Diffusion-Based LLMs via Dual Adaptive Caching","excerpt":"Jiarui Wang이 [arXiv]에 게시한 'd^2Cache: Accelerating Diffusion-Based LLMs via Dual Adaptive Caching' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","Diffusion Models","Large Language Models (LLMs)","Inference Acceleration","KV Cache","Bidirectional Attention","Adaptive Caching","Token Selection"],"permalink":"/ai/review/2025-10-1-d2Cache_Accelerating_Diffusion-Based_LLMs_via_Dual_Adaptive_Caching/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-Context_Is_What_You_Need_The_Maximum_Effective_Context_Window_for_Real_World_Limits_of_LLMs","title":"[논문리뷰] Context Is What You Need: The Maximum Effective Context Window for Real World Limits of LLMs","excerpt":"normanpaulsen이 [arXiv]에 게시한 'Context Is What You Need: The Maximum Effective Context Window for Real World Limits of LLMs' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","Large Language Models","Context Window","Effective Context Window","Model Performance","Hallucination Rates","RAG Systems","Token Limits"],"permalink":"/ai/review/2025-10-1-Context_Is_What_You_Need_The_Maximum_Effective_Context_Window_for_Real_World_Limits_of_LLMs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-BuildBench_Benchmarking_LLM_Agents_on_Compiling_Real-World_Open-Source_Software","title":"[논문리뷰] BuildBench: Benchmarking LLM Agents on Compiling Real-World Open-Source Software","excerpt":"이 [arXiv]에 게시한 'BuildBench: Benchmarking LLM Agents on Compiling Real-World Open-Source Software' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","LLM Agents","Open-Source Software","Compilation","Benchmarking","Software Engineering","Error Resolution","Retrieval-Augmented Generation"],"permalink":"/ai/review/2025-10-1-BuildBench_Benchmarking_LLM_Agents_on_Compiling_Real-World_Open-Source_Software/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-Benefits_and_Pitfalls_of_Reinforcement_Learning_for_Language_Model_Planning_A_Theoretical_Perspective","title":"[논문리뷰] Benefits and Pitfalls of Reinforcement Learning for Language Model Planning: A Theoretical Perspective","excerpt":"이 [arXiv]에 게시한 'Benefits and Pitfalls of Reinforcement Learning for Language Model Planning: A Theoretical Perspective' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","Large Language Models","Planning","Policy Gradient","Q-learning","Supervised Fine-Tuning","Diversity Collapse","Reward Hacking"],"permalink":"/ai/review/2025-10-1-Benefits_and_Pitfalls_of_Reinforcement_Learning_for_Language_Model_Planning_A_Theoretical_Perspective/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-A_Cartography_of_Open_Collaboration_in_Open_Source_AI_Mapping_Practices_Motivations_and_Governance_in_14_Open_Large_Language_Model_Projects","title":"[논문리뷰] A Cartography of Open Collaboration in Open Source AI: Mapping Practices, Motivations, and Governance in 14 Open Large Language Model Projects","excerpt":"Jennifer Ding이 [arXiv]에 게시한 'A Cartography of Open Collaboration in Open Source AI: Mapping Practices, Motivations, and Governance in 14 Open Large Language Model Projects' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","Open Source AI","LLM Development","Open Collaboration","Governance Models","Developer Motivations","Community Engagement","AI Ecosystem"],"permalink":"/ai/review/2025-10-1-A_Cartography_of_Open_Collaboration_in_Open_Source_AI_Mapping_Practices_Motivations_and_Governance_in_14_Open_Large_Language_Model_Projects/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-10-1-Attention_as_a_Compass_Efficient_Exploration_for_Process-Supervised_RL_in_Reasoning_Models","title":"[논문리뷰] Attention as a Compass: Efficient Exploration for Process-Supervised RL in Reasoning Models","excerpt":"이 [arXiv]에 게시한 'Attention as a Compass: Efficient Exploration for Process-Supervised RL in Reasoning Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-10-01 14:04:08+0900","lastModifiedAt":"2025-10-01 14:04:08+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","Process-Supervised RL","Large Language Models","Reasoning Models","Attention Mechanism","Efficient Exploration","Adaptive Sampling","Off-Policy Training"],"permalink":"/ai/review/2025-10-1-Attention_as_a_Compass_Efficient_Exploration_for_Process-Supervised_RL_in_Reasoning_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-30-Visual_Jigsaw_Post-Training_Improves_MLLMs","title":"[논문리뷰] Visual Jigsaw Post-Training Improves MLLMs","excerpt":"Lewei Lu이 [arXiv]에 게시한 'Visual Jigsaw Post-Training Improves MLLMs' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-30 13:52:24+0900","lastModifiedAt":"2025-09-30 13:52:24+0900","categories":["Review"],"tags":["Review","MLLMs","Post-training","Self-supervised Learning","Visual Understanding","Jigsaw Puzzles","RLVR","Multimodal Perception","Spatial Reasoning"],"permalink":"/ai/review/2025-9-30-Visual_Jigsaw_Post-Training_Improves_MLLMs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-30-StableToken_A_Noise-Robust_Semantic_Speech_Tokenizer_for_Resilient_SpeechLLMs","title":"[논문리뷰] StableToken: A Noise-Robust Semantic Speech Tokenizer for Resilient SpeechLLMs","excerpt":"Wei Jia이 [arXiv]에 게시한 'StableToken: A Noise-Robust Semantic Speech Tokenizer for Resilient SpeechLLMs' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-30 13:52:24+0900","lastModifiedAt":"2025-09-30 13:52:24+0900","categories":["Review"],"tags":["Review","Speech Tokenizer","Noise Robustness","Semantic Tokens","SpeechLLMs","Voting-LFQ","Consensus Training","Automatic Speech Recognition","Speech Synthesis"],"permalink":"/ai/review/2025-9-30-StableToken_A_Noise-Robust_Semantic_Speech_Tokenizer_for_Resilient_SpeechLLMs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-30-SLA_Beyond_Sparsity_in_Diffusion_Transformers_via_Fine-Tunable_Sparse-Linear_Attention","title":"[논문리뷰] SLA: Beyond Sparsity in Diffusion Transformers via Fine-Tunable Sparse-Linear Attention","excerpt":"이 [arXiv]에 게시한 'SLA: Beyond Sparsity in Diffusion Transformers via Fine-Tunable Sparse-Linear Attention' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-30 13:52:24+0900","lastModifiedAt":"2025-09-30 13:52:24+0900","categories":["Review"],"tags":["Review","Diffusion Transformers","Sparse Attention","Linear Attention","Model Acceleration","Video Generation","Attention Mechanisms","Fine-tuning"],"permalink":"/ai/review/2025-9-30-SLA_Beyond_Sparsity_in_Diffusion_Transformers_via_Fine-Tunable_Sparse-Linear_Attention/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-30-SANA-Video_Efficient_Video_Generation_with_Block_Linear_Diffusion_Transformer","title":"[논문리뷰] SANA-Video: Efficient Video Generation with Block Linear Diffusion Transformer","excerpt":"이 [arXiv]에 게시한 'SANA-Video: Efficient Video Generation with Block Linear Diffusion Transformer' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-30 13:52:24+0900","lastModifiedAt":"2025-09-30 13:52:24+0900","categories":["Review"],"tags":["Review","Video Generation","Diffusion Model","Linear Attention","Transformer","Long Video","Efficient Inference","Constant Memory","Low-Cost Training","RTX Deployment"],"permalink":"/ai/review/2025-9-30-SANA-Video_Efficient_Video_Generation_with_Block_Linear_Diffusion_Transformer/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-30-RealUnify_Do_Unified_Models_Truly_Benefit_from_Unification_A_Comprehensive_Benchmark","title":"[논문리뷰] RealUnify: Do Unified Models Truly Benefit from Unification? A Comprehensive Benchmark","excerpt":"Yuran Wang이 [arXiv]에 게시한 'RealUnify: Do Unified Models Truly Benefit from Unification? A Comprehensive Benchmark' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-30 13:52:24+0900","lastModifiedAt":"2025-09-30 13:52:24+0900","categories":["Review"],"tags":["Review","Unified Models","Multimodal AI","Benchmark","Capability Synergy","Visual Understanding","Image Generation","Dual-Evaluation Protocol"],"permalink":"/ai/review/2025-9-30-RealUnify_Do_Unified_Models_Truly_Benefit_from_Unification_A_Comprehensive_Benchmark/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-30-Random_Policy_Valuation_is_Enough_for_LLM_Reasoning_with_Verifiable_Rewards","title":"[논문리뷰] Random Policy Valuation is Enough for LLM Reasoning with Verifiable Rewards","excerpt":"Binxing Jiao이 [arXiv]에 게시한 'Random Policy Valuation is Enough for LLM Reasoning with Verifiable Rewards' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-30 13:52:24+0900","lastModifiedAt":"2025-09-30 13:52:24+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","LLM Reasoning","Policy Valuation","Markov Decision Process","Diversity","Math Reasoning","Verifiable Rewards"],"permalink":"/ai/review/2025-9-30-Random_Policy_Valuation_is_Enough_for_LLM_Reasoning_with_Verifiable_Rewards/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-30-OpenGPT-4o-Image_A_Comprehensive_Dataset_for_Advanced_Image_Generation_and_Editing","title":"[논문리뷰] OpenGPT-4o-Image: A Comprehensive Dataset for Advanced Image Generation and Editing","excerpt":"Huanyu Zhang이 [arXiv]에 게시한 'OpenGPT-4o-Image: A Comprehensive Dataset for Advanced Image Generation and Editing' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-30 13:52:24+0900","lastModifiedAt":"2025-09-30 13:52:24+0900","categories":["Review"],"tags":["Review","Image Generation","Image Editing","Multimodal AI","Dataset","Instruction Following","Taxonomy","GPT-40"],"permalink":"/ai/review/2025-9-30-OpenGPT-4o-Image_A_Comprehensive_Dataset_for_Advanced_Image_Generation_and_Editing/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-30-Multiplayer_Nash_Preference_Optimization","title":"[논문리뷰] Multiplayer Nash Preference Optimization","excerpt":"이 [arXiv]에 게시한 'Multiplayer Nash Preference Optimization' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-30 13:52:24+0900","lastModifiedAt":"2025-09-30 13:52:24+0900","categories":["Review"],"tags":["Review","RLHF","LLM Alignment","Nash Equilibrium","Multiplayer Games","Preference Optimization","Non-transitive Preferences","Game Theory"],"permalink":"/ai/review/2025-9-30-Multiplayer_Nash_Preference_Optimization/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-30-EditScore_Unlocking_Online_RL_for_Image_Editing_via_High-Fidelity_Reward_Modeling","title":"[논문리뷰] EditScore: Unlocking Online RL for Image Editing via High-Fidelity Reward Modeling","excerpt":"이 [arXiv]에 게시한 'EditScore: Unlocking Online RL for Image Editing via High-Fidelity Reward Modeling' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-30 13:52:24+0900","lastModifiedAt":"2025-09-30 13:52:24+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","Image Editing","Reward Modeling","Instruction-Guided Editing","Online RL","Visual Language Models","Benchmark","Self-Ensembling"],"permalink":"/ai/review/2025-9-30-EditScore_Unlocking_Online_RL_for_Image_Editing_via_High-Fidelity_Reward_Modeling/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-30-EasySteer_A_Unified_Framework_for_High-Performance_and_Extensible_LLM_Steering","title":"[논문리뷰] EasySteer: A Unified Framework for High-Performance and Extensible LLM Steering","excerpt":"이 [arXiv]에 게시한 'EasySteer: A Unified Framework for High-Performance and Extensible LLM Steering' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-30 13:52:24+0900","lastModifiedAt":"2025-09-30 13:52:24+0900","categories":["Review"],"tags":["Review","LLM Steering Framework","vLLM Integration","Hidden State Manipulation","Inference Optimization","Extensibility","Modular Architecture","Reasoning Mitigation","Hallucination Reduction"],"permalink":"/ai/review/2025-9-30-EasySteer_A_Unified_Framework_for_High-Performance_and_Extensible_LLM_Steering/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-X-Streamer_Unified_Human_World_Modeling_with_Audiovisual_Interaction","title":"[논문리뷰] X-Streamer: Unified Human World Modeling with Audiovisual Interaction","excerpt":"Guoxian Song이 [arXiv]에 게시한 'X-Streamer: Unified Human World Modeling with Audiovisual Interaction' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","Digital Human","Multimodal AI","Real-time Streaming","Video Generation","Diffusion Models","Transformer Architecture","Audiovisual Synchronization","World Modeling"],"permalink":"/ai/review/2025-9-29-X-Streamer_Unified_Human_World_Modeling_with_Audiovisual_Interaction/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-X-CoT_Explainable_Text-to-Video_Retrieval_via_LLM-based_Chain-of-Thought_Reasoning","title":"[논문리뷰] X-CoT: Explainable Text-to-Video Retrieval via LLM-based Chain-of-Thought Reasoning","excerpt":"Raghuveer Rao이 [arXiv]에 게시한 'X-CoT: Explainable Text-to-Video Retrieval via LLM-based Chain-of-Thought Reasoning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","Text-to-Video Retrieval","LLM","Chain-of-Thought","Explainable AI","Multimodal Retrieval","Bradley-Terry Model","Video Annotation"],"permalink":"/ai/review/2025-9-29-X-CoT_Explainable_Text-to-Video_Retrieval_via_LLM-based_Chain-of-Thought_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-WoW_Towards_a_World_omniscient_World_model_Through_Embodied_Interaction","title":"[논문리뷰] WoW: Towards a World omniscient World model Through Embodied Interaction","excerpt":"Weishi Mi이 [arXiv]에 게시한 'WoW: Towards a World omniscient World model Through Embodied Interaction' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","World Model","Embodied AI","Robotics","Diffusion Models","Physical Reasoning","Vision Language Models","Interaction Data","Self-Optimization"],"permalink":"/ai/review/2025-9-29-WoW_Towards_a_World_omniscient_World_model_Through_Embodied_Interaction/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-Where_MLLMs_Attend_and_What_They_Rely_On_Explaining_Autoregressive_Token_Generation","title":"[논문리뷰] Where MLLMs Attend and What They Rely On: Explaining Autoregressive Token Generation","excerpt":"Shiming Liu이 [arXiv]에 게시한 'Where MLLMs Attend and What They Rely On: Explaining Autoregressive Token Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","MLLM","Interpretability","Attribution","Token Generation","Black-box Explanation","Hallucination Diagnosis","Multimodality","VQA"],"permalink":"/ai/review/2025-9-29-Where_MLLMs_Attend_and_What_They_Rely_On_Explaining_Autoregressive_Token_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-WebGen-Agent_Enhancing_Interactive_Website_Generation_with_Multi-Level_Feedback_and_Step-Level_Reinforcement_Learning","title":"[논문리뷰] WebGen-Agent: Enhancing Interactive Website Generation with Multi-Level Feedback and Step-Level Reinforcement Learning","excerpt":"Zhuofan Zong이 [arXiv]에 게시한 'WebGen-Agent: Enhancing Interactive Website Generation with Multi-Level Feedback and Step-Level Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","Website Generation","Code Agent","LLM","VLM","Reinforcement Learning","Multi-Level Feedback","GUI Agent","Step-GRPO"],"permalink":"/ai/review/2025-9-29-WebGen-Agent_Enhancing_Interactive_Website_Generation_with_Multi-Level_Feedback_and_Step-Level_Reinforcement_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-VoiceAssistant-Eval_Benchmarking_AI_Assistants_across_Listening_Speaking_and_Viewing","title":"[논문리뷰] VoiceAssistant-Eval: Benchmarking AI Assistants across Listening, Speaking, and Viewing","excerpt":"이 [arXiv]에 게시한 'VoiceAssistant-Eval: Benchmarking AI Assistants across Listening, Speaking, and Viewing' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","AI Assistants","Multimodal Benchmarking","Audio Understanding","Speech Synthesis","Vision-Language Models","Role-play","Safety","Robustness"],"permalink":"/ai/review/2025-9-29-VoiceAssistant-Eval_Benchmarking_AI_Assistants_across_Listening_Speaking_and_Viewing/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-Variational_Reasoning_for_Language_Models","title":"[논문리뷰] Variational Reasoning for Language Models","excerpt":"이 [arXiv]에 게시한 'Variational Reasoning for Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","Variational Inference","Language Models","Reasoning","ELBO","IWAE","Reinforcement Learning","Latent Variables","Forward-KL"],"permalink":"/ai/review/2025-9-29-Variational_Reasoning_for_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-UniVid_Unifying_Vision_Tasks_with_Pre-trained_Video_Generation_Models","title":"[논문리뷰] UniVid: Unifying Vision Tasks with Pre-trained Video Generation Models","excerpt":"Yuchao Gu이 [arXiv]에 게시한 'UniVid: Unifying Vision Tasks with Pre-trained Video Generation Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","Unified Vision Modeling","Video Generation","Diffusion Transformer","Supervised Fine-tuning","Cross-modal","Cross-source Tasks","Visual Sentences","LoRA"],"permalink":"/ai/review/2025-9-29-UniVid_Unifying_Vision_Tasks_with_Pre-trained_Video_Generation_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-UltraHorizon_Benchmarking_Agent_Capabilities_in_Ultra_Long-Horizon_Scenarios","title":"[논문리뷰] UltraHorizon: Benchmarking Agent Capabilities in Ultra Long-Horizon Scenarios","excerpt":"Zeyu Qin이 [arXiv]에 게시한 'UltraHorizon: Benchmarking Agent Capabilities in Ultra Long-Horizon Scenarios' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","LLM Agents","Long-Horizon Reasoning","Benchmarking","Partially Observable","Tool Use","Memory Management","Exploration"],"permalink":"/ai/review/2025-9-29-UltraHorizon_Benchmarking_Agent_Capabilities_in_Ultra_Long-Horizon_Scenarios/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-TUN3D_Towards_Real-World_Scene_Understanding_from_Unposed_Images","title":"[논문리뷰] TUN3D: Towards Real-World Scene Understanding from Unposed Images","excerpt":"Anna Vorontsova이 [arXiv]에 게시한 'TUN3D: Towards Real-World Scene Understanding from Unposed Images' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","3D Scene Understanding","Layout Estimation","3D Object Detection","Unposed Images","Sparse Convolutional Networks","Multi-view Stereo","Real-time AI"],"permalink":"/ai/review/2025-9-29-TUN3D_Towards_Real-World_Scene_Understanding_from_Unposed_Images/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-Think-on-Graph_3.0_Efficient_and_Adaptive_LLM_Reasoning_on_Heterogeneous_Graphs_via_Multi-Agent_Dual-Evolving_Context_Retrieval","title":"[논문리뷰] Think-on-Graph 3.0: Efficient and Adaptive LLM Reasoning on Heterogeneous Graphs via Multi-Agent Dual-Evolving Context Retrieval","excerpt":"이 [arXiv]에 게시한 'Think-on-Graph 3.0: Efficient and Adaptive LLM Reasoning on Heterogeneous Graphs via Multi-Agent Dual-Evolving Context Retrieval' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","RAG","LLM Reasoning","Knowledge Graphs","Multi-Agent Systems","Context Retrieval","Heterogeneous Graphs","Adaptive Learning","Dual-Evolution"],"permalink":"/ai/review/2025-9-29-Think-on-Graph_3.0_Efficient_and_Adaptive_LLM_Reasoning_on_Heterogeneous_Graphs_via_Multi-Agent_Dual-Evolving_Context_Retrieval/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-StateX_Enhancing_RNN_Recall_via_Post-training_State_Expansion","title":"[논문리뷰] StateX: Enhancing RNN Recall via Post-training State Expansion","excerpt":"Zhiyuan Liu이 [arXiv]에 게시한 'StateX: Enhancing RNN Recall via Post-training State Expansion' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","RNN","State Expansion","Post-training","Long-context Recall","Linear Attention","State Space Models","GLA","Mamba2"],"permalink":"/ai/review/2025-9-29-StateX_Enhancing_RNN_Recall_via_Post-training_State_Expansion/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-SPARK_Synergistic_Policy_And_Reward_Co-Evolving_Framework","title":"[논문리뷰] SPARK: Synergistic Policy And Reward Co-Evolving Framework","excerpt":"이 [arXiv]에 게시한 'SPARK: Synergistic Policy And Reward Co-Evolving Framework' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","LLMs","LVLMs","Reward Modeling","Policy Optimization","Self-Reflection","Verifiable Rewards","Co-evolution"],"permalink":"/ai/review/2025-9-29-SPARK_Synergistic_Policy_And_Reward_Co-Evolving_Framework/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-See_Point_Fly_A_Learning-Free_VLM_Framework_for_Universal_Unmanned_Aerial_Navigation","title":"[논문리뷰] See, Point, Fly: A Learning-Free VLM Framework for Universal Unmanned Aerial Navigation","excerpt":"Chih-Hai Su이 [arXiv]에 게시한 'See, Point, Fly: A Learning-Free VLM Framework for Universal Unmanned Aerial Navigation' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","Vision-Language Models","UAV Navigation","Zero-shot","Spatial Grounding","Waypoint Prompting","Autonomous Navigation","Adaptive Control"],"permalink":"/ai/review/2025-9-29-See_Point_Fly_A_Learning-Free_VLM_Framework_for_Universal_Unmanned_Aerial_Navigation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-ReviewScore_Misinformed_Peer_Review_Detection_with_Large_Language_Models","title":"[논문리뷰] ReviewScore: Misinformed Peer Review Detection with Large Language Models","excerpt":"이 [arXiv]에 게시한 'ReviewScore: Misinformed Peer Review Detection with Large Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","Peer Review","Review Quality","Large Language Models (LLMs)","Misinformed Review","Argument Reconstruction","Factuality Evaluation","Natural Language Processing","Automated Evaluation"],"permalink":"/ai/review/2025-9-29-ReviewScore_Misinformed_Peer_Review_Detection_with_Large_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-RefAM_Attention_Magnets_for_Zero-Shot_Referral_Segmentation","title":"[논문리뷰] RefAM: Attention Magnets for Zero-Shot Referral Segmentation","excerpt":"Federico Tombari이 [arXiv]에 게시한 'RefAM: Attention Magnets for Zero-Shot Referral Segmentation' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","Zero-Shot Segmentation","Referring Segmentation","Diffusion Transformers (DiTs)","Attention Mechanisms","Attention Sinks","Stop Words","Vision-Language Models","Training-Free Methods"],"permalink":"/ai/review/2025-9-29-RefAM_Attention_Magnets_for_Zero-Shot_Referral_Segmentation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-Real-Time_Object_Detection_Meets_DINOv3","title":"[논문리뷰] Real-Time Object Detection Meets DINOv3","excerpt":"Xi Shen이 [arXiv]에 게시한 'Real-Time Object Detection Meets DINOv3' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","Real-time Object Detection","DINOv3","DEIMv2","Vision Transformer","Multi-scale Features","Spatial Tuning Adapter","Lightweight Models","Object Detection Framework"],"permalink":"/ai/review/2025-9-29-Real-Time_Object_Detection_Meets_DINOv3/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-Quantile_Advantage_Estimation_for_Entropy-Safe_Reasoning","title":"[논문리뷰] Quantile Advantage Estimation for Entropy-Safe Reasoning","excerpt":"An Zhang이 [arXiv]에 게시한 'Quantile Advantage Estimation for Entropy-Safe Reasoning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","LLM Reasoning","Entropy Control","Advantage Estimation","Quantile Baseline","Exploration-Exploitation","RLVR"],"permalink":"/ai/review/2025-9-29-Quantile_Advantage_Estimation_for_Entropy-Safe_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-PromptCoT_2.0_Scaling_Prompt_Synthesis_for_Large_Language_Model_Reasoning","title":"[논문리뷰] PromptCoT 2.0: Scaling Prompt Synthesis for Large Language Model Reasoning","excerpt":"Lingpeng Kong이 [arXiv]에 게시한 'PromptCoT 2.0: Scaling Prompt Synthesis for Large Language Model Reasoning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","Prompt Synthesis","Large Language Models","Reasoning","Expectation-Maximization","Self-Play","Supervised Fine-Tuning","Task Generation","Rationale Generation"],"permalink":"/ai/review/2025-9-29-PromptCoT_2.0_Scaling_Prompt_Synthesis_for_Large_Language_Model_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-No_Prompt_Left_Behind_Exploiting_Zero-Variance_Prompts_in_LLM_Reinforcement_Learning_via_Entropy-Guided_Advantage_Shaping","title":"[논문리뷰] No Prompt Left Behind: Exploiting Zero-Variance Prompts in LLM Reinforcement Learning via Entropy-Guided Advantage Shaping","excerpt":"이 [arXiv]에 게시한 'No Prompt Left Behind: Exploiting Zero-Variance Prompts in LLM Reinforcement Learning via Entropy-Guided Advantage Shaping' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","LLM Reinforcement Learning","Zero-Variance Prompts","Advantage Shaping","Entropy-Guided","Math Reasoning","RLVR","Group Relative Policy Optimization"],"permalink":"/ai/review/2025-9-29-No_Prompt_Left_Behind_Exploiting_Zero-Variance_Prompts_in_LLM_Reinforcement_Learning_via_Entropy-Guided_Advantage_Shaping/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-MinerU2.5_A_Decoupled_Vision-Language_Model_for_Efficient_High-Resolution_Document_Parsing","title":"[논문리뷰] MinerU2.5: A Decoupled Vision-Language Model for Efficient High-Resolution Document Parsing","excerpt":"SunYuefeng이 [arXiv]에 게시한 'MinerU2.5: A Decoupled Vision-Language Model for Efficient High-Resolution Document Parsing' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","Document Parsing","Vision-Language Model","High-Resolution","Two-Stage Inference","Layout Analysis","Content Recognition","Data Engine","Computational Efficiency"],"permalink":"/ai/review/2025-9-29-MinerU2.5_A_Decoupled_Vision-Language_Model_for_Efficient_High-Resolution_Document_Parsing/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-Mind-the-Glitch_Visual_Correspondence_for_Detecting_Inconsistencies_in_Subject-Driven_Generation","title":"[논문리뷰] Mind-the-Glitch: Visual Correspondence for Detecting Inconsistencies in Subject-Driven Generation","excerpt":"Peter Wonka이 [arXiv]에 게시한 'Mind-the-Glitch: Visual Correspondence for Detecting Inconsistencies in Subject-Driven Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","Subject-Driven Generation","Visual Inconsistency Detection","Feature Disentanglement","Diffusion Models","Semantic Correspondence","Evaluation Metric","Spatial Localization","Contrastive Learning"],"permalink":"/ai/review/2025-9-29-Mind-the-Glitch_Visual_Correspondence_for_Detecting_Inconsistencies_in_Subject-Driven_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-MesaTask_Towards_Task-Driven_Tabletop_Scene_Generation_via_3D_Spatial_Reasoning","title":"[논문리뷰] MesaTask: Towards Task-Driven Tabletop Scene Generation via 3D Spatial Reasoning","excerpt":"Weipeng Zhong이 [arXiv]에 게시한 'MesaTask: Towards Task-Driven Tabletop Scene Generation via 3D Spatial Reasoning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","3D Scene Generation","Robotic Manipulation","Large Language Models","Spatial Reasoning","Dataset","Direct Preference Optimization","Tabletop Scene"],"permalink":"/ai/review/2025-9-29-MesaTask_Towards_Task-Driven_Tabletop_Scene_Generation_via_3D_Spatial_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-LucidFlux_Caption-Free_Universal_Image_Restoration_via_a_Large-Scale_Diffusion_Transformer","title":"[논문리뷰] LucidFlux: Caption-Free Universal Image Restoration via a Large-Scale Diffusion Transformer","excerpt":"이 [arXiv]에 게시한 'LucidFlux: Caption-Free Universal Image Restoration via a Large-Scale Diffusion Transformer' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","Universal Image Restoration","Diffusion Transformer","Caption-Free","Semantic Alignment","Image Quality Assessment","Data Curation","Real-World Degradations","Deep Learning"],"permalink":"/ai/review/2025-9-29-LucidFlux_Caption-Free_Universal_Image_Restoration_via_a_Large-Scale_Diffusion_Transformer/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-LongLive_Real-time_Interactive_Long_Video_Generation","title":"[논문리뷰] LongLive: Real-time Interactive Long Video Generation","excerpt":"이 [arXiv]에 게시한 'LongLive: Real-time Interactive Long Video Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","Long Video Generation","Real-time","Interactive AI","Autoregressive Models","KV Cache","Streaming Tuning","Attention Sink","Diffusion Models"],"permalink":"/ai/review/2025-9-29-LongLive_Real-time_Interactive_Long_Video_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-Learn_the_Ropes_Then_Trust_the_Wins_Self-imitation_with_Progressive_Exploration_for_Agentic_Reinforcement_Learning","title":"[논문리뷰] Learn the Ropes, Then Trust the Wins: Self-imitation with Progressive Exploration for Agentic Reinforcement Learning","excerpt":"Gang Li이 [arXiv]에 게시한 'Learn the Ropes, Then Trust the Wins: Self-imitation with Progressive Exploration for Agentic Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","LLM Agents","Exploration-Exploitation","Self-Imitation Learning","Intrinsic Rewards","Curriculum Learning","Policy Entropy","Tool Use"],"permalink":"/ai/review/2025-9-29-Learn_the_Ropes_Then_Trust_the_Wins_Self-imitation_with_Progressive_Exploration_for_Agentic_Reinforcement_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-Language_Models_Can_Learn_from_Verbal_Feedback_Without_Scalar_Rewards","title":"[논문리뷰] Language Models Can Learn from Verbal Feedback Without Scalar Rewards","excerpt":"이 [arXiv]에 게시한 'Language Models Can Learn from Verbal Feedback Without Scalar Rewards' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","Verbal Feedback","Conditional Generation","Large Language Models","Feedback-Conditional Policy","Offline-Online Learning","Reward Hypothesis Bypass"],"permalink":"/ai/review/2025-9-29-Language_Models_Can_Learn_from_Verbal_Feedback_Without_Scalar_Rewards/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-Instruction-Following_Evaluation_in_Function_Calling_for_Large_Language_Models","title":"[논문리뷰] Instruction-Following Evaluation in Function Calling for Large Language Models","excerpt":"NikolaiSkripko이 [arXiv]에 게시한 'Instruction-Following Evaluation in Function Calling for Large Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","Function Calling","LLMs","Instruction Following","Benchmarking","JSON Schema","AI Agents","Evaluation Metrics"],"permalink":"/ai/review/2025-9-29-Instruction-Following_Evaluation_in_Function_Calling_for_Large_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-HiGS_History-Guided_Sampling_for_Plug-and-Play_Enhancement_of_Diffusion_Models","title":"[논문리뷰] HiGS: History-Guided Sampling for Plug-and-Play Enhancement of Diffusion Models","excerpt":"Romann M. Weber이 [arXiv]에 게시한 'HiGS: History-Guided Sampling for Plug-and-Play Enhancement of Diffusion Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","Diffusion Models","Sampling","Generative AI","Image Generation","Plug-and-Play","Training-Free","Guidance","Momentum-Based Methods"],"permalink":"/ai/review/2025-9-29-HiGS_History-Guided_Sampling_for_Plug-and-Play_Enhancement_of_Diffusion_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-FlashEdit_Decoupling_Speed_Structure_and_Semantics_for_Precise_Image_Editing","title":"[논문리뷰] FlashEdit: Decoupling Speed, Structure, and Semantics for Precise Image Editing","excerpt":"Linghe Kong이 [arXiv]에 게시한 'FlashEdit: Decoupling Speed, Structure, and Semantics for Precise Image Editing' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","Text-Guided Image Editing","Diffusion Models","Real-Time Editing","One-Step Inversion","Attention Control","Background Preservation","Semantic Disentanglement"],"permalink":"/ai/review/2025-9-29-FlashEdit_Decoupling_Speed_Structure_and_Semantics_for_Precise_Image_Editing/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-Fine-tuning_Done_Right_in_Model_Editing","title":"[논문리뷰] Fine-tuning Done Right in Model Editing","excerpt":"Du Su이 [arXiv]에 게시한 'Fine-tuning Done Right in Model Editing' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","Model Editing","Fine-tuning","Large Language Models","Catastrophic Forgetting","Breadth-First Pipeline","Depth-First Pipeline","Localized Tuning","Lifelong Learning"],"permalink":"/ai/review/2025-9-29-Fine-tuning_Done_Right_in_Model_Editing/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-Finding_3D_Positions_of_Distant_Objects_from_Noisy_Camera_Movement_and_Semantic_Segmentation_Sequences","title":"[논문리뷰] Finding 3D Positions of Distant Objects from Noisy Camera Movement and Semantic Segmentation Sequences","excerpt":"Eija Honkavaara이 [arXiv]에 게시한 'Finding 3D Positions of Distant Objects from Noisy Camera Movement and Semantic Segmentation Sequences' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","3D Object Localization","Particle Filter","Multi-target Tracking","Drone Surveillance","Wildfire Monitoring","Semantic Segmentation","Camera Pose Estimation"],"permalink":"/ai/review/2025-9-29-Finding_3D_Positions_of_Distant_Objects_from_Noisy_Camera_Movement_and_Semantic_Segmentation_Sequences/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-ERGO_Efficient_High-Resolution_Visual_Understanding_for_Vision-Language_Models","title":"[논문리뷰] ERGO: Efficient High-Resolution Visual Understanding for Vision-Language Models","excerpt":"Ki-Ung Song이 [arXiv]에 게시한 'ERGO: Efficient High-Resolution Visual Understanding for Vision-Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","High-Resolution Vision","Vision-Language Models","Efficient Reasoning","Coarse-to-Fine","Reinforcement Learning","Visual Understanding","Attention Mechanism"],"permalink":"/ai/review/2025-9-29-ERGO_Efficient_High-Resolution_Visual_Understanding_for_Vision-Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-EPO_Entropy-regularized_Policy_Optimization_for_LLM_Agents_Reinforcement_Learning","title":"[논문리뷰] EPO: Entropy-regularized Policy Optimization for LLM Agents Reinforcement Learning","excerpt":"Li Yu-Jhe이 [arXiv]에 게시한 'EPO: Entropy-regularized Policy Optimization for LLM Agents Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","LLM Agents","Reinforcement Learning","Entropy Regularization","Policy Optimization","Sparse Rewards","Multi-turn Environments","Exploration-Exploitation"],"permalink":"/ai/review/2025-9-29-EPO_Entropy-regularized_Policy_Optimization_for_LLM_Agents_Reinforcement_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-D-Artemis_A_Deliberative_Cognitive_Framework_for_Mobile_GUI_Multi-Agents","title":"[논문리뷰] D-Artemis: A Deliberative Cognitive Framework for Mobile GUI Multi-Agents","excerpt":"Jinyuan Li이 [arXiv]에 게시한 'D-Artemis: A Deliberative Cognitive Framework for Mobile GUI Multi-Agents' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","Mobile GUI Automation","Multi-Agent System","Cognitive Architecture","Pre-execution Alignment","Post-execution Reflection","Retrieval-Augmented Generation","Multimodal LLM","Deliberative AI"],"permalink":"/ai/review/2025-9-29-D-Artemis_A_Deliberative_Cognitive_Framework_for_Mobile_GUI_Multi-Agents/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-CHURRO_Making_History_Readable_with_an_Open-Weight_Large_Vision-Language_Model_for_High-Accuracy_Low-Cost_Historical_Text_Recognition","title":"[논문리뷰] CHURRO: Making History Readable with an Open-Weight Large Vision-Language Model for High-Accuracy, Low-Cost Historical Text Recognition","excerpt":"이 [arXiv]에 게시한 'CHURRO: Making History Readable with an Open-Weight Large Vision-Language Model for High-Accuracy, Low-Cost Historical Text Recognition' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","Historical Text Recognition","Vision-Language Model","Open-Weight Model","OCR","Cultural Heritage","Low-Cost AI","Dataset Curation","Fine-tuning"],"permalink":"/ai/review/2025-9-29-CHURRO_Making_History_Readable_with_an_Open-Weight_Large_Vision-Language_Model_for_High-Accuracy_Low-Cost_Historical_Text_Recognition/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-Chasing_the_Tail_Effective_Rubric-based_Reward_Modeling_for_Large_Language_Model_Post-Training","title":"[논문리뷰] Chasing the Tail: Effective Rubric-based Reward Modeling for Large Language Model Post-Training","excerpt":"이 [arXiv]에 게시한 'Chasing the Tail: Effective Rubric-based Reward Modeling for Large Language Model Post-Training' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","LLM","Reinforcement Fine-tuning","Reward Modeling","Reward Over-optimization","Rubric-based Rewards","High-reward Tail","Off-policy Data","LLM Alignment"],"permalink":"/ai/review/2025-9-29-Chasing_the_Tail_Effective_Rubric-based_Reward_Modeling_for_Large_Language_Model_Post-Training/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-29-CapRL_Stimulating_Dense_Image_Caption_Capabilities_via_Reinforcement_Learning","title":"[논문리뷰] CapRL: Stimulating Dense Image Caption Capabilities via Reinforcement Learning","excerpt":"이 [arXiv]에 게시한 'CapRL: Stimulating Dense Image Caption Capabilities via Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-29 13:47:46+0900","lastModifiedAt":"2025-09-29 13:47:46+0900","categories":["Review"],"tags":["Review","Image Captioning","Reinforcement Learning","Verifiable Rewards","LVLMs","VQA","Data Curation","Caption Quality"],"permalink":"/ai/review/2025-9-29-CapRL_Stimulating_Dense_Image_Caption_Capabilities_via_Reinforcement_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0000-index_of_python_enhancement_proposals_peps","title":"[Active] PEP 0 - Index of Python Enhancement Proposals (PEPs)","excerpt":"Python Enhancement Proposal 0: 'Index of Python Enhancement Proposals (PEPs)'에 대한 한국어 번역입니다.","date":"2025-09-27 21:19:02+0900","lastModifiedAt":"2025-09-27 21:19:02+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/0/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-8106-2025_term_steering_council_election","title":"[Final] PEP 8106 - 2025 Term Steering Council election","excerpt":"Python Enhancement Proposal 8106: '2025 Term Steering Council election'에 대한 한국어 번역입니다.","date":"2025-09-27 19:35:42+0900","lastModifiedAt":"2025-09-27 19:35:42+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/8106/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-8105-2024_term_steering_council_election","title":"[Final] PEP 8105 - 2024 Term Steering Council election","excerpt":"Python Enhancement Proposal 8105: '2024 Term Steering Council election'에 대한 한국어 번역입니다.","date":"2025-09-27 19:34:28+0900","lastModifiedAt":"2025-09-27 19:34:28+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/8105/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-8104-2023_term_steering_council_election","title":"[Final] PEP 8104 - 2023 Term Steering Council election","excerpt":"Python Enhancement Proposal 8104: '2023 Term Steering Council election'에 대한 한국어 번역입니다.","date":"2025-09-27 19:34:01+0900","lastModifiedAt":"2025-09-27 19:34:01+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/8104/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-8103-2022_term_steering_council_election","title":"[Final] PEP 8103 - 2022 Term Steering Council election","excerpt":"Python Enhancement Proposal 8103: '2022 Term Steering Council election'에 대한 한국어 번역입니다.","date":"2025-09-27 19:31:17+0900","lastModifiedAt":"2025-09-27 19:31:17+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/8103/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-8102-2021_term_steering_council_election","title":"[Final] PEP 8102 - 2021 Term Steering Council election","excerpt":"Python Enhancement Proposal 8102: '2021 Term Steering Council election'에 대한 한국어 번역입니다.","date":"2025-09-27 19:31:05+0900","lastModifiedAt":"2025-09-27 19:31:05+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/8102/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-8101-2020_term_steering_council_election","title":"[Final] PEP 8101 - 2020 Term Steering Council election","excerpt":"Python Enhancement Proposal 8101: '2020 Term Steering Council election'에 대한 한국어 번역입니다.","date":"2025-09-27 19:30:45+0900","lastModifiedAt":"2025-09-27 19:30:45+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/8101/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-8100-january_2019_steering_council_election","title":"[Final] PEP 8100 - January 2019 Steering Council election","excerpt":"Python Enhancement Proposal 8100: 'January 2019 Steering Council election'에 대한 한국어 번역입니다.","date":"2025-09-27 19:30:34+0900","lastModifiedAt":"2025-09-27 19:30:34+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/8100/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-8016-the_steering_council_model","title":"[Accepted] PEP 8016 - The Steering Council Model","excerpt":"Python Enhancement Proposal 8016: 'The Steering Council Model'에 대한 한국어 번역입니다.","date":"2025-09-27 19:30:11+0900","lastModifiedAt":"2025-09-27 19:30:11+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/8016/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-8015-organization_of_the_python_community","title":"[Rejected] PEP 8015 - Organization of the Python community","excerpt":"Python Enhancement Proposal 8015: 'Organization of the Python community'에 대한 한국어 번역입니다.","date":"2025-09-27 19:29:53+0900","lastModifiedAt":"2025-09-27 19:29:53+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/8015/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-8014-the_commons_governance_model","title":"[Rejected] PEP 8014 - The Commons Governance Model","excerpt":"Python Enhancement Proposal 8014: 'The Commons Governance Model'에 대한 한국어 번역입니다.","date":"2025-09-27 19:29:07+0900","lastModifiedAt":"2025-09-27 19:29:07+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/8014/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-8013-the_external_council_governance_model","title":"[Rejected] PEP 8013 - The External Council Governance Model","excerpt":"Python Enhancement Proposal 8013: 'The External Council Governance Model'에 대한 한국어 번역입니다.","date":"2025-09-27 19:28:36+0900","lastModifiedAt":"2025-09-27 19:28:36+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/8013/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-8012-the_community_governance_model","title":"[Rejected] PEP 8012 - The Community Governance Model","excerpt":"Python Enhancement Proposal 8012: 'The Community Governance Model'에 대한 한국어 번역입니다.","date":"2025-09-27 19:28:04+0900","lastModifiedAt":"2025-09-27 19:28:04+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/8012/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-8011-python_governance_model_lead_by_trio_of_pythonistas","title":"[Rejected] PEP 8011 - Python Governance Model Lead by Trio of Pythonistas","excerpt":"Python Enhancement Proposal 8011: 'Python Governance Model Lead by Trio of Pythonistas'에 대한 한국어 번역입니다.","date":"2025-09-27 19:27:38+0900","lastModifiedAt":"2025-09-27 19:27:38+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/8011/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-8010-the_technical_leader_governance_model","title":"[Rejected] PEP 8010 - The Technical Leader Governance Model","excerpt":"Python Enhancement Proposal 8010: 'The Technical Leader Governance Model'에 대한 한국어 번역입니다.","date":"2025-09-27 19:27:12+0900","lastModifiedAt":"2025-09-27 19:27:12+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/8010/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-8002-open_source_governance_survey","title":"[Final] PEP 8002 - Open Source Governance Survey","excerpt":"Python Enhancement Proposal 8002: 'Open Source Governance Survey'에 대한 한국어 번역입니다.","date":"2025-09-27 19:26:46+0900","lastModifiedAt":"2025-09-27 19:26:46+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/8002/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-8001-python_governance_voting_process","title":"[Final] PEP 8001 - Python Governance Voting Process","excerpt":"Python Enhancement Proposal 8001: 'Python Governance Voting Process'에 대한 한국어 번역입니다.","date":"2025-09-27 19:25:35+0900","lastModifiedAt":"2025-09-27 19:25:35+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/8001/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-8000-python_language_governance_proposal_overview","title":"[Final] PEP 8000 - Python Language Governance Proposal Overview","excerpt":"Python Enhancement Proposal 8000: 'Python Language Governance Proposal Overview'에 대한 한국어 번역입니다.","date":"2025-09-27 19:25:09+0900","lastModifiedAt":"2025-09-27 19:25:09+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/8000/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3333-python_web_server_gateway_interface_v1.0.1","title":"[Final] PEP 3333 - Python Web Server Gateway Interface v1.0.1","excerpt":"Python Enhancement Proposal 3333: 'Python Web Server Gateway Interface v1.0.1'에 대한 한국어 번역입니다.","date":"2025-09-27 19:24:56+0900","lastModifiedAt":"2025-09-27 19:24:56+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3333/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3156-asynchronous_io_support_rebooted_the_asyncio_module","title":"[Final] PEP 3156 - Asynchronous IO Support Rebooted: the “asyncio” Module","excerpt":"Python Enhancement Proposal 3156: 'Asynchronous IO Support Rebooted: the “asyncio” Module'에 대한 한국어 번역입니다.","date":"2025-09-27 19:21:50+0900","lastModifiedAt":"2025-09-27 19:21:50+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3156/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3155-qualified_name_for_classes_and_functions","title":"[Final] PEP 3155 - Qualified name for classes and functions","excerpt":"Python Enhancement Proposal 3155: 'Qualified name for classes and functions'에 대한 한국어 번역입니다.","date":"2025-09-27 19:20:50+0900","lastModifiedAt":"2025-09-27 19:20:50+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3155/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3154-pickle_protocol_version_4","title":"[Final] PEP 3154 - Pickle protocol version 4","excerpt":"Python Enhancement Proposal 3154: 'Pickle protocol version 4'에 대한 한국어 번역입니다.","date":"2025-09-27 19:20:26+0900","lastModifiedAt":"2025-09-27 19:20:26+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3154/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3153-asynchronous_io_support","title":"[Superseded] PEP 3153 - Asynchronous IO support","excerpt":"Python Enhancement Proposal 3153: 'Asynchronous IO support'에 대한 한국어 번역입니다.","date":"2025-09-27 14:42:18+0900","lastModifiedAt":"2025-09-27 14:42:18+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3153/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3152-cofunctions","title":"[Rejected] PEP 3152 - Cofunctions","excerpt":"Python Enhancement Proposal 3152: 'Cofunctions'에 대한 한국어 번역입니다.","date":"2025-09-27 14:41:43+0900","lastModifiedAt":"2025-09-27 14:41:43+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3152/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3151-reworking_the_os_and_io_exception_hierarchy","title":"[Final] PEP 3151 - Reworking the OS and IO exception hierarchy","excerpt":"Python Enhancement Proposal 3151: 'Reworking the OS and IO exception hierarchy'에 대한 한국어 번역입니다.","date":"2025-09-27 14:41:26+0900","lastModifiedAt":"2025-09-27 14:41:26+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3151/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3150-statement_local_namespaces_aka_given_clause","title":"[Deferred] PEP 3150 - Statement local namespaces (aka “given” clause)","excerpt":"Python Enhancement Proposal 3150: 'Statement local namespaces (aka “given” clause)'에 대한 한국어 번역입니다.","date":"2025-09-27 14:40:31+0900","lastModifiedAt":"2025-09-27 14:40:31+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3150/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3149-abi_version_tagged_.so_files","title":"[Final] PEP 3149 - ABI version tagged .so files","excerpt":"Python Enhancement Proposal 3149: 'ABI version tagged .so files'에 대한 한국어 번역입니다.","date":"2025-09-27 14:39:52+0900","lastModifiedAt":"2025-09-27 14:39:52+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3149/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3148-futures_-_execute_computations_asynchronously","title":"[Final] PEP 3148 - futures - execute computations asynchronously","excerpt":"Python Enhancement Proposal 3148: 'futures - execute computations asynchronously'에 대한 한국어 번역입니다.","date":"2025-09-27 14:39:26+0900","lastModifiedAt":"2025-09-27 14:39:26+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3148/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3147-pyc_repository_directories","title":"[Final] PEP 3147 - PYC Repository Directories","excerpt":"Python Enhancement Proposal 3147: 'PYC Repository Directories'에 대한 한국어 번역입니다.","date":"2025-09-27 14:39:02+0900","lastModifiedAt":"2025-09-27 14:39:02+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3147/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3146-merging_unladen_swallow_into_cpython","title":"[Withdrawn] PEP 3146 - Merging Unladen Swallow into CPython","excerpt":"Python Enhancement Proposal 3146: 'Merging Unladen Swallow into CPython'에 대한 한국어 번역입니다.","date":"2025-09-27 14:38:28+0900","lastModifiedAt":"2025-09-27 14:38:28+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3146/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3145-asynchronous_io_for_subprocess.popen","title":"[Withdrawn] PEP 3145 - Asynchronous I/O For subprocess.Popen","excerpt":"Python Enhancement Proposal 3145: 'Asynchronous I/O For subprocess.Popen'에 대한 한국어 번역입니다.","date":"2025-09-27 14:37:24+0900","lastModifiedAt":"2025-09-27 14:37:24+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3145/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3144-ip_address_manipulation_library_for_the_python_standard_library","title":"[Final] PEP 3144 - IP Address Manipulation Library for the Python Standard Library","excerpt":"Python Enhancement Proposal 3144: 'IP Address Manipulation Library for the Python Standard Library'에 대한 한국어 번역입니다.","date":"2025-09-27 14:37:11+0900","lastModifiedAt":"2025-09-27 14:37:11+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3144/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3143-standard_daemon_process_library","title":"[Deferred] PEP 3143 - Standard daemon process library","excerpt":"Python Enhancement Proposal 3143: 'Standard daemon process library'에 대한 한국어 번역입니다.","date":"2025-09-27 14:36:57+0900","lastModifiedAt":"2025-09-27 14:36:57+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3143/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3142-add_a_while_clause_to_generator_expressions","title":"[Rejected] PEP 3142 - Add a “while” clause to generator expressions","excerpt":"Python Enhancement Proposal 3142: 'Add a “while” clause to generator expressions'에 대한 한국어 번역입니다.","date":"2025-09-27 14:36:16+0900","lastModifiedAt":"2025-09-27 14:36:16+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3142/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3141-a_type_hierarchy_for_numbers","title":"[Final] PEP 3141 - A Type Hierarchy for Numbers","excerpt":"Python Enhancement Proposal 3141: 'A Type Hierarchy for Numbers'에 대한 한국어 번역입니다.","date":"2025-09-27 14:36:02+0900","lastModifiedAt":"2025-09-27 14:36:02+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3141/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3140-strcontainer_should_call_stritem_not_repritem","title":"[Rejected] PEP 3140 - str(container) should call str(item), not repr(item)","excerpt":"Python Enhancement Proposal 3140: 'str(container) should call str(item), not repr(item)'에 대한 한국어 번역입니다.","date":"2025-09-27 14:35:43+0900","lastModifiedAt":"2025-09-27 14:35:43+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3140/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3139-cleaning_out_sys_and_the_interpreter_module","title":"[Rejected] PEP 3139 - Cleaning out sys and the “interpreter” module","excerpt":"Python Enhancement Proposal 3139: 'Cleaning out sys and the “interpreter” module'에 대한 한국어 번역입니다.","date":"2025-09-27 14:35:24+0900","lastModifiedAt":"2025-09-27 14:35:24+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3139/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3138-string_representation_in_python_3000","title":"[Final] PEP 3138 - String representation in Python 3000","excerpt":"Python Enhancement Proposal 3138: 'String representation in Python 3000'에 대한 한국어 번역입니다.","date":"2025-09-27 14:35:12+0900","lastModifiedAt":"2025-09-27 14:35:12+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3138/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3137-immutable_bytes_and_mutable_buffer","title":"[Final] PEP 3137 - Immutable Bytes and Mutable Buffer","excerpt":"Python Enhancement Proposal 3137: 'Immutable Bytes and Mutable Buffer'에 대한 한국어 번역입니다.","date":"2025-09-27 14:34:47+0900","lastModifiedAt":"2025-09-27 14:34:47+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3137/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3136-labeled_break_and_continue","title":"[Rejected] PEP 3136 - Labeled break and continue","excerpt":"Python Enhancement Proposal 3136: 'Labeled break and continue'에 대한 한국어 번역입니다.","date":"2025-09-27 14:34:24+0900","lastModifiedAt":"2025-09-27 14:34:24+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3136/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3135-new_super","title":"[Final] PEP 3135 - New Super","excerpt":"Python Enhancement Proposal 3135: 'New Super'에 대한 한국어 번역입니다.","date":"2025-09-27 14:34:00+0900","lastModifiedAt":"2025-09-27 14:34:00+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3135/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3134-exception_chaining_and_embedded_tracebacks","title":"[Final] PEP 3134 - Exception Chaining and Embedded Tracebacks","excerpt":"Python Enhancement Proposal 3134: 'Exception Chaining and Embedded Tracebacks'에 대한 한국어 번역입니다.","date":"2025-09-27 14:33:48+0900","lastModifiedAt":"2025-09-27 14:33:48+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3134/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3133-introducing_roles","title":"[Rejected] PEP 3133 - Introducing Roles","excerpt":"Python Enhancement Proposal 3133: 'Introducing Roles'에 대한 한국어 번역입니다.","date":"2025-09-27 14:33:16+0900","lastModifiedAt":"2025-09-27 14:33:16+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3133/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3132-extended_iterable_unpacking","title":"[Final] PEP 3132 - Extended Iterable Unpacking","excerpt":"Python Enhancement Proposal 3132: 'Extended Iterable Unpacking'에 대한 한국어 번역입니다.","date":"2025-09-27 14:32:37+0900","lastModifiedAt":"2025-09-27 14:32:37+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3132/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3131-supporting_non-ascii_identifiers","title":"[Final] PEP 3131 - Supporting Non-ASCII Identifiers","excerpt":"Python Enhancement Proposal 3131: 'Supporting Non-ASCII Identifiers'에 대한 한국어 번역입니다.","date":"2025-09-27 14:32:23+0900","lastModifiedAt":"2025-09-27 14:32:23+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3131/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3130-access_to_current_moduleclassfunction","title":"[Rejected] PEP 3130 - Access to Current Module/Class/Function","excerpt":"Python Enhancement Proposal 3130: 'Access to Current Module/Class/Function'에 대한 한국어 번역입니다.","date":"2025-09-27 14:31:53+0900","lastModifiedAt":"2025-09-27 14:31:53+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3130/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3129-class_decorators","title":"[Final] PEP 3129 - Class Decorators","excerpt":"Python Enhancement Proposal 3129: 'Class Decorators'에 대한 한국어 번역입니다.","date":"2025-09-27 14:31:32+0900","lastModifiedAt":"2025-09-27 14:31:32+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3129/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3128-blist_a_faster_list-like_type","title":"[Rejected] PEP 3128 - BList: A Faster List-like Type","excerpt":"Python Enhancement Proposal 3128: 'BList: A Faster List-like Type'에 대한 한국어 번역입니다.","date":"2025-09-27 14:31:22+0900","lastModifiedAt":"2025-09-27 14:31:22+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3128/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3127-integer_literal_support_and_syntax","title":"[Final] PEP 3127 - Integer Literal Support and Syntax","excerpt":"Python Enhancement Proposal 3127: 'Integer Literal Support and Syntax'에 대한 한국어 번역입니다.","date":"2025-09-27 14:30:46+0900","lastModifiedAt":"2025-09-27 14:30:46+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3127/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3126-remove_implicit_string_concatenation","title":"[Rejected] PEP 3126 - Remove Implicit String Concatenation","excerpt":"Python Enhancement Proposal 3126: 'Remove Implicit String Concatenation'에 대한 한국어 번역입니다.","date":"2025-09-27 14:30:11+0900","lastModifiedAt":"2025-09-27 14:30:11+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3126/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3125-remove_backslash_continuation","title":"[Rejected] PEP 3125 - Remove Backslash Continuation","excerpt":"Python Enhancement Proposal 3125: 'Remove Backslash Continuation'에 대한 한국어 번역입니다.","date":"2025-09-27 14:29:48+0900","lastModifiedAt":"2025-09-27 14:29:48+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3125/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3124-overloading_generic_functions_interfaces_and_adaptation","title":"[Deferred] PEP 3124 - Overloading, Generic Functions, Interfaces, and Adaptation","excerpt":"Python Enhancement Proposal 3124: 'Overloading, Generic Functions, Interfaces, and Adaptation'에 대한 한국어 번역입니다.","date":"2025-09-27 14:29:34+0900","lastModifiedAt":"2025-09-27 14:29:34+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3124/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3123-making_pyobject_head_conform_to_standard_c","title":"[Final] PEP 3123 - Making PyObject_HEAD conform to standard C","excerpt":"Python Enhancement Proposal 3123: 'Making PyObject_HEAD conform to standard C'에 대한 한국어 번역입니다.","date":"2025-09-27 14:28:28+0900","lastModifiedAt":"2025-09-27 14:28:28+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3123/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3122-delineation_of_the_main_module","title":"[Rejected] PEP 3122 - Delineation of the main module","excerpt":"Python Enhancement Proposal 3122: 'Delineation of the main module'에 대한 한국어 번역입니다.","date":"2025-09-27 14:28:16+0900","lastModifiedAt":"2025-09-27 14:28:16+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3122/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3121-extension_module_initialization_and_finalization","title":"[Final] PEP 3121 - Extension Module Initialization and Finalization","excerpt":"Python Enhancement Proposal 3121: 'Extension Module Initialization and Finalization'에 대한 한국어 번역입니다.","date":"2025-09-27 14:27:55+0900","lastModifiedAt":"2025-09-27 14:27:55+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3121/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3120-using_utf-8_as_the_default_source_encoding","title":"[Final] PEP 3120 - Using UTF-8 as the default source encoding","excerpt":"Python Enhancement Proposal 3120: 'Using UTF-8 as the default source encoding'에 대한 한국어 번역입니다.","date":"2025-09-27 14:27:43+0900","lastModifiedAt":"2025-09-27 14:27:43+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3120/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3119-introducing_abstract_base_classes","title":"[Final] PEP 3119 - Introducing Abstract Base Classes","excerpt":"Python Enhancement Proposal 3119: 'Introducing Abstract Base Classes'에 대한 한국어 번역입니다.","date":"2025-09-27 14:27:33+0900","lastModifiedAt":"2025-09-27 14:27:33+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3119/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3118-revising_the_buffer_protocol","title":"[Final] PEP 3118 - Revising the buffer protocol","excerpt":"Python Enhancement Proposal 3118: 'Revising the buffer protocol'에 대한 한국어 번역입니다.","date":"2025-09-27 14:26:38+0900","lastModifiedAt":"2025-09-27 14:26:38+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3118/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3117-postfix_type_declarations","title":"[Rejected] PEP 3117 - Postfix type declarations","excerpt":"Python Enhancement Proposal 3117: 'Postfix type declarations'에 대한 한국어 번역입니다.","date":"2025-09-27 14:25:21+0900","lastModifiedAt":"2025-09-27 14:25:21+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3117/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3116-new_io","title":"[Final] PEP 3116 - New I/O","excerpt":"Python Enhancement Proposal 3116: 'New I/O'에 대한 한국어 번역입니다.","date":"2025-09-27 14:24:50+0900","lastModifiedAt":"2025-09-27 14:24:50+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3116/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3115-metaclasses_in_python_3000","title":"[Final] PEP 3115 - Metaclasses in Python 3000","excerpt":"Python Enhancement Proposal 3115: 'Metaclasses in Python 3000'에 대한 한국어 번역입니다.","date":"2025-09-27 14:22:47+0900","lastModifiedAt":"2025-09-27 14:22:47+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3115/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3114-renaming_iterator.next_to_iterator.__next","title":"[Final] PEP 3114 - Renaming iterator.next() to iterator.__next__()","excerpt":"Python Enhancement Proposal 3114: 'Renaming iterator.next() to iterator.__next__()'에 대한 한국어 번역입니다.","date":"2025-09-27 14:22:21+0900","lastModifiedAt":"2025-09-27 14:22:21+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3114/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3113-removal_of_tuple_parameter_unpacking","title":"[Final] PEP 3113 - Removal of Tuple Parameter Unpacking","excerpt":"Python Enhancement Proposal 3113: 'Removal of Tuple Parameter Unpacking'에 대한 한국어 번역입니다.","date":"2025-09-27 14:22:03+0900","lastModifiedAt":"2025-09-27 14:22:03+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3113/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3112-bytes_literals_in_python_3000","title":"[Final] PEP 3112 - Bytes literals in Python 3000","excerpt":"Python Enhancement Proposal 3112: 'Bytes literals in Python 3000'에 대한 한국어 번역입니다.","date":"2025-09-27 14:21:44+0900","lastModifiedAt":"2025-09-27 14:21:44+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3112/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3111-simple_input_built-in_in_python_3000","title":"[Final] PEP 3111 - Simple input built-in in Python 3000","excerpt":"Python Enhancement Proposal 3111: 'Simple input built-in in Python 3000'에 대한 한국어 번역입니다.","date":"2025-09-27 14:21:32+0900","lastModifiedAt":"2025-09-27 14:21:32+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3111/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3110-catching_exceptions_in_python_3000","title":"[Final] PEP 3110 - Catching Exceptions in Python 3000","excerpt":"Python Enhancement Proposal 3110: 'Catching Exceptions in Python 3000'에 대한 한국어 번역입니다.","date":"2025-09-27 14:21:16+0900","lastModifiedAt":"2025-09-27 14:21:16+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3110/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3109-raising_exceptions_in_python_3000","title":"[Final] PEP 3109 - Raising Exceptions in Python 3000","excerpt":"Python Enhancement Proposal 3109: 'Raising Exceptions in Python 3000'에 대한 한국어 번역입니다.","date":"2025-09-27 14:21:02+0900","lastModifiedAt":"2025-09-27 14:21:02+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3109/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3108-standard_library_reorganization","title":"[Final] PEP 3108 - Standard Library Reorganization","excerpt":"Python Enhancement Proposal 3108: 'Standard Library Reorganization'에 대한 한국어 번역입니다.","date":"2025-09-27 14:20:43+0900","lastModifiedAt":"2025-09-27 14:20:43+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3108/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3107-function_annotations","title":"[Final] PEP 3107 - Function Annotations","excerpt":"Python Enhancement Proposal 3107: 'Function Annotations'에 대한 한국어 번역입니다.","date":"2025-09-27 14:19:43+0900","lastModifiedAt":"2025-09-27 14:19:43+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3107/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3106-revamping_dict.keys_.values_and_.items","title":"[Final] PEP 3106 - Revamping dict.keys(), .values() and .items()","excerpt":"Python Enhancement Proposal 3106: 'Revamping dict.keys(), .values() and .items()'에 대한 한국어 번역입니다.","date":"2025-09-27 14:18:13+0900","lastModifiedAt":"2025-09-27 14:18:13+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3106/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3105-make_print_a_function","title":"[Final] PEP 3105 - Make print a function","excerpt":"Python Enhancement Proposal 3105: 'Make print a function'에 대한 한국어 번역입니다.","date":"2025-09-27 14:17:54+0900","lastModifiedAt":"2025-09-27 14:17:54+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3105/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3104-access_to_names_in_outer_scopes","title":"[Final] PEP 3104 - Access to Names in Outer Scopes","excerpt":"Python Enhancement Proposal 3104: 'Access to Names in Outer Scopes'에 대한 한국어 번역입니다.","date":"2025-09-27 14:17:40+0900","lastModifiedAt":"2025-09-27 14:17:40+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3104/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3103-a_switchcase_statement","title":"[Rejected] PEP 3103 - A Switch/Case Statement","excerpt":"Python Enhancement Proposal 3103: 'A Switch/Case Statement'에 대한 한국어 번역입니다.","date":"2025-09-27 14:17:03+0900","lastModifiedAt":"2025-09-27 14:17:03+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3103/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3102-keyword-only_arguments","title":"[Final] PEP 3102 - Keyword-Only Arguments","excerpt":"Python Enhancement Proposal 3102: 'Keyword-Only Arguments'에 대한 한국어 번역입니다.","date":"2025-09-27 14:16:28+0900","lastModifiedAt":"2025-09-27 14:16:28+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3102/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3101-advanced_string_formatting","title":"[Final] PEP 3101 - Advanced String Formatting","excerpt":"Python Enhancement Proposal 3101: 'Advanced String Formatting'에 대한 한국어 번역입니다.","date":"2025-09-27 14:16:14+0900","lastModifiedAt":"2025-09-27 14:16:14+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3101/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3100-miscellaneous_python_3.0_plans","title":"[Final] PEP 3100 - Miscellaneous Python 3.0 Plans","excerpt":"Python Enhancement Proposal 3100: 'Miscellaneous Python 3.0 Plans'에 대한 한국어 번역입니다.","date":"2025-09-27 14:13:27+0900","lastModifiedAt":"2025-09-27 14:13:27+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3100/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3099-things_that_will_not_change_in_python_3000","title":"[Final] PEP 3099 - Things that will Not Change in Python 3000","excerpt":"Python Enhancement Proposal 3099: 'Things that will Not Change in Python 3000'에 대한 한국어 번역입니다.","date":"2025-09-27 14:12:36+0900","lastModifiedAt":"2025-09-27 14:12:36+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3099/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3003-python_language_moratorium","title":"[Final] PEP 3003 - Python Language Moratorium","excerpt":"Python Enhancement Proposal 3003: 'Python Language Moratorium'에 대한 한국어 번역입니다.","date":"2025-09-27 14:12:18+0900","lastModifiedAt":"2025-09-27 14:12:18+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3003/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3002-procedure_for_backwards-incompatible_changes","title":"[Final] PEP 3002 - Procedure for Backwards-Incompatible Changes","excerpt":"Python Enhancement Proposal 3002: 'Procedure for Backwards-Incompatible Changes'에 대한 한국어 번역입니다.","date":"2025-09-27 14:12:06+0900","lastModifiedAt":"2025-09-27 14:12:06+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3002/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3001-procedure_for_reviewing_and_improving_standard_library_modules","title":"[Withdrawn] PEP 3001 - Procedure for reviewing and improving standard library modules","excerpt":"Python Enhancement Proposal 3001: 'Procedure for reviewing and improving standard library modules'에 대한 한국어 번역입니다.","date":"2025-09-27 14:11:53+0900","lastModifiedAt":"2025-09-27 14:11:53+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3001/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-3000-python_3000","title":"[Final] PEP 3000 - Python 3000","excerpt":"Python Enhancement Proposal 3000: 'Python 3000'에 대한 한국어 번역입니다.","date":"2025-09-27 14:11:40+0900","lastModifiedAt":"2025-09-27 14:11:40+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3000/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-2026-calendar_versioning_for_python","title":"[Rejected] PEP 2026 - Calendar versioning for Python","excerpt":"Python Enhancement Proposal 2026: 'Calendar versioning for Python'에 대한 한국어 번역입니다.","date":"2025-09-27 14:11:21+0900","lastModifiedAt":"2025-09-27 14:11:21+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/2026/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0806-mixed_syncasync_context_managers_with_precise_async_marking","title":"[Draft] PEP 806 - Mixed sync/async context managers with precise async marking","excerpt":"Python Enhancement Proposal 806: 'Mixed sync/async context managers with precise async marking'에 대한 한국어 번역입니다.","date":"2025-09-27 14:10:48+0900","lastModifiedAt":"2025-09-27 14:10:48+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/806/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0804-an_external_dependency_registry_and_name_mapping_mechanism","title":"[Draft] PEP 804 - An external dependency registry and name mapping mechanism","excerpt":"Python Enhancement Proposal 804: 'An external dependency registry and name mapping mechanism'에 대한 한국어 번역입니다.","date":"2025-09-27 14:10:24+0900","lastModifiedAt":"2025-09-27 14:10:24+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/804/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0803-stable_abi_for_free-threaded_builds","title":"[Draft] PEP 803 - Stable ABI for Free-Threaded Builds","excerpt":"Python Enhancement Proposal 803: 'Stable ABI for Free-Threaded Builds'에 대한 한국어 번역입니다.","date":"2025-09-27 14:09:56+0900","lastModifiedAt":"2025-09-27 14:09:56+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/803/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0802-display_syntax_for_the_empty_set","title":"[Draft] PEP 802 - Display Syntax for the Empty Set","excerpt":"Python Enhancement Proposal 802: 'Display Syntax for the Empty Set'에 대한 한국어 번역입니다.","date":"2025-09-27 14:09:30+0900","lastModifiedAt":"2025-09-27 14:09:30+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/802/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0801-reserved","title":"[Active] PEP 801 - Reserved","excerpt":"Python Enhancement Proposal 801: 'Reserved'에 대한 한국어 번역입니다.","date":"2025-09-27 14:09:12+0900","lastModifiedAt":"2025-09-27 14:09:12+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/801/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0800-disjoint_bases_in_the_type_system","title":"[Draft] PEP 800 - Disjoint bases in the type system","excerpt":"Python Enhancement Proposal 800: 'Disjoint bases in the type system'에 대한 한국어 번역입니다.","date":"2025-09-27 14:09:06+0900","lastModifiedAt":"2025-09-27 14:09:06+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/800/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0799-a_dedicatedprofilingpackage_for_organizing_python_profiling_tools","title":"[Draft] PEP 799 - A dedicatedprofilingpackage for organizing Python profiling tools","excerpt":"Python Enhancement Proposal 799: 'A dedicatedprofilingpackage for organizing Python profiling tools'에 대한 한국어 번역입니다.","date":"2025-09-27 14:08:50+0900","lastModifiedAt":"2025-09-27 14:08:50+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/799/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0798-unpacking_in_comprehensions","title":"[Draft] PEP 798 - Unpacking in Comprehensions","excerpt":"Python Enhancement Proposal 798: 'Unpacking in Comprehensions'에 대한 한국어 번역입니다.","date":"2025-09-27 14:08:32+0900","lastModifiedAt":"2025-09-27 14:08:32+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/798/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0794-import_name_metadata","title":"[Accepted] PEP 794 - Import Name Metadata","excerpt":"Python Enhancement Proposal 794: 'Import Name Metadata'에 대한 한국어 번역입니다.","date":"2025-09-27 14:07:32+0900","lastModifiedAt":"2025-09-27 14:07:32+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/794/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0793-pymodexport_a_new_entry_point_for_c_extension_modules","title":"[Draft] PEP 793 - PyModExport: A new entry point for C extension modules","excerpt":"Python Enhancement Proposal 793: 'PyModExport: A new entry point for C extension modules'에 대한 한국어 번역입니다.","date":"2025-09-27 14:07:12+0900","lastModifiedAt":"2025-09-27 14:07:12+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/793/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0792-project_status_markers_in_the_simple_index","title":"[Final] PEP 792 - Project status markers in the simple index","excerpt":"Python Enhancement Proposal 792: 'Project status markers in the simple index'에 대한 한국어 번역입니다.","date":"2025-09-27 14:05:09+0900","lastModifiedAt":"2025-09-27 14:05:09+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/792/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0791-intmath_module_for_integer-specific_mathematics_functions","title":"[Draft] PEP 791 - intmath — module for integer-specific mathematics functions","excerpt":"Python Enhancement Proposal 791: 'intmath — module for integer-specific mathematics functions'에 대한 한국어 번역입니다.","date":"2025-09-27 14:04:51+0900","lastModifiedAt":"2025-09-27 14:04:51+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/791/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0790-python_3.15_release_schedule","title":"[Active] PEP 790 - Python 3.15 Release Schedule","excerpt":"Python Enhancement Proposal 790: 'Python 3.15 Release Schedule'에 대한 한국어 번역입니다.","date":"2025-09-27 14:04:34+0900","lastModifiedAt":"2025-09-27 14:04:34+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/790/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0789-preventing_task-cancellation_bugs_by_limiting_yield_in_async_generators","title":"[Draft] PEP 789 - Preventing task-cancellation bugs by limiting yield in async generators","excerpt":"Python Enhancement Proposal 789: 'Preventing task-cancellation bugs by limiting yield in async generators'에 대한 한국어 번역입니다.","date":"2025-09-27 14:04:23+0900","lastModifiedAt":"2025-09-27 14:04:23+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/789/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0788-pyinterpreterref_interpreter_references_in_the_c_api","title":"[Draft] PEP 788 - PyInterpreterRef: Interpreter References in the C API","excerpt":"Python Enhancement Proposal 788: 'PyInterpreterRef: Interpreter References in the C API'에 대한 한국어 번역입니다.","date":"2025-09-27 14:03:48+0900","lastModifiedAt":"2025-09-27 14:03:48+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/788/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0787-safer_subprocess_usage_using_t-strings","title":"[Deferred] PEP 787 - Safer subprocess usage using t-strings","excerpt":"Python Enhancement Proposal 787: 'Safer subprocess usage using t-strings'에 대한 한국어 번역입니다.","date":"2025-09-27 14:00:15+0900","lastModifiedAt":"2025-09-27 14:00:15+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/787/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0785-new_methods_for_easier_handling_ofexceptiongroups","title":"[Draft] PEP 785 - New methods for easier handling ofExceptionGroups","excerpt":"Python Enhancement Proposal 785: 'New methods for easier handling ofExceptionGroups'에 대한 한국어 번역입니다.","date":"2025-09-27 13:59:04+0900","lastModifiedAt":"2025-09-27 13:59:04+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/785/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0784-adding_zstandard_to_the_standard_library","title":"[Final] PEP 784 - Adding Zstandard to the standard library","excerpt":"Python Enhancement Proposal 784: 'Adding Zstandard to the standard library'에 대한 한국어 번역입니다.","date":"2025-09-27 13:58:47+0900","lastModifiedAt":"2025-09-27 13:58:47+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/784/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0783-emscripten_packaging","title":"[Draft] PEP 783 - Emscripten Packaging","excerpt":"Python Enhancement Proposal 783: 'Emscripten Packaging'에 대한 한국어 번역입니다.","date":"2025-09-27 13:58:16+0900","lastModifiedAt":"2025-09-27 13:58:16+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/783/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0782-add_pybyteswriter_c_api","title":"[Final] PEP 782 - Add PyBytesWriter C API","excerpt":"Python Enhancement Proposal 782: 'Add PyBytesWriter C API'에 대한 한국어 번역입니다.","date":"2025-09-27 13:58:01+0900","lastModifiedAt":"2025-09-27 13:58:01+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/782/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0781-maketype_checkinga_built-in_constant","title":"[Draft] PEP 781 - MakeTYPE_CHECKINGa built-in constant","excerpt":"Python Enhancement Proposal 781: 'MakeTYPE_CHECKINGa built-in constant'에 대한 한국어 번역입니다.","date":"2025-09-27 13:57:36+0900","lastModifiedAt":"2025-09-27 13:57:36+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/781/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0780-abi_features_as_environment_markers","title":"[Draft] PEP 780 - ABI features as environment markers","excerpt":"Python Enhancement Proposal 780: 'ABI features as environment markers'에 대한 한국어 번역입니다.","date":"2025-09-27 13:57:13+0900","lastModifiedAt":"2025-09-27 13:57:13+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/780/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0779-criteria_for_supported_status_for_free-threaded_python","title":"[Accepted] PEP 779 - Criteria for supported status for free-threaded Python","excerpt":"Python Enhancement Proposal 779: 'Criteria for supported status for free-threaded Python'에 대한 한국어 번역입니다.","date":"2025-09-27 13:56:46+0900","lastModifiedAt":"2025-09-27 13:56:46+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/779/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0778-supporting_symlinks_in_wheels","title":"[Deferred] PEP 778 - Supporting Symlinks in Wheels","excerpt":"Python Enhancement Proposal 778: 'Supporting Symlinks in Wheels'에 대한 한국어 번역입니다.","date":"2025-09-27 13:56:34+0900","lastModifiedAt":"2025-09-27 13:56:34+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/778/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0777-how_to_re-invent_the_wheel","title":"[Draft] PEP 777 - How to Re-invent the Wheel","excerpt":"Python Enhancement Proposal 777: 'How to Re-invent the Wheel'에 대한 한국어 번역입니다.","date":"2025-09-27 13:56:09+0900","lastModifiedAt":"2025-09-27 13:56:09+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/777/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0776-emscripten_support","title":"[Draft] PEP 776 - Emscripten Support","excerpt":"Python Enhancement Proposal 776: 'Emscripten Support'에 대한 한국어 번역입니다.","date":"2025-09-27 13:55:47+0900","lastModifiedAt":"2025-09-27 13:55:47+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/776/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0775-make_zlib_required_to_build_cpython","title":"[Withdrawn] PEP 775 - Make zlib required to build CPython","excerpt":"Python Enhancement Proposal 775: 'Make zlib required to build CPython'에 대한 한국어 번역입니다.","date":"2025-09-27 13:55:17+0900","lastModifiedAt":"2025-09-27 13:55:17+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/775/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0774-removing_the_llvm_requirement_for_jit_builds","title":"[Deferred] PEP 774 - Removing the LLVM requirement for JIT builds","excerpt":"Python Enhancement Proposal 774: 'Removing the LLVM requirement for JIT builds'에 대한 한국어 번역입니다.","date":"2025-09-27 13:55:06+0900","lastModifiedAt":"2025-09-27 13:55:06+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/774/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0773-a_python_installation_manager_for_windows","title":"[Accepted] PEP 773 - A Python Installation Manager for Windows","excerpt":"Python Enhancement Proposal 773: 'A Python Installation Manager for Windows'에 대한 한국어 번역입니다.","date":"2025-09-27 13:54:28+0900","lastModifiedAt":"2025-09-27 13:54:28+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/773/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0772-packaging_council_governance_process","title":"[Draft] PEP 772 - Packaging Council governance process","excerpt":"Python Enhancement Proposal 772: 'Packaging Council governance process'에 대한 한국어 번역입니다.","date":"2025-09-27 13:53:40+0900","lastModifiedAt":"2025-09-27 13:53:40+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/772/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0771-default_extras_for_python_software_packages","title":"[Draft] PEP 771 - Default Extras for Python Software Packages","excerpt":"Python Enhancement Proposal 771: 'Default Extras for Python Software Packages'에 대한 한국어 번역입니다.","date":"2025-09-27 13:52:58+0900","lastModifiedAt":"2025-09-27 13:52:58+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/771/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0770-improving_measurability_of_python_packages_with_software_bill-of-materials","title":"[Accepted] PEP 770 - Improving measurability of Python packages with Software Bill-of-Materials","excerpt":"Python Enhancement Proposal 770: 'Improving measurability of Python packages with Software Bill-of-Materials'에 대한 한국어 번역입니다.","date":"2025-09-27 13:51:21+0900","lastModifiedAt":"2025-09-27 13:51:21+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/770/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0769-add_a_default_keyword_argument_to_attrgetter_itemgetter_and_getitem","title":"[Rejected] PEP 769 - Add a ‘default’ keyword argument to ‘attrgetter’, ‘itemgetter’ and ‘getitem’","excerpt":"Python Enhancement Proposal 769: 'Add a ‘default’ keyword argument to ‘attrgetter’, ‘itemgetter’ and ‘getitem’'에 대한 한국어 번역입니다.","date":"2025-09-27 13:50:33+0900","lastModifiedAt":"2025-09-27 13:50:33+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/769/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0768-safe_external_debugger_interface_for_cpython","title":"[Accepted] PEP 768 - Safe external debugger interface for CPython","excerpt":"Python Enhancement Proposal 768: 'Safe external debugger interface for CPython'에 대한 한국어 번역입니다.","date":"2025-09-27 13:50:05+0900","lastModifiedAt":"2025-09-27 13:50:05+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/768/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0767-annotating_read-only_attributes","title":"[Draft] PEP 767 - Annotating Read-Only Attributes","excerpt":"Python Enhancement Proposal 767: 'Annotating Read-Only Attributes'에 대한 한국어 번역입니다.","date":"2025-09-27 13:49:33+0900","lastModifiedAt":"2025-09-27 13:49:33+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/767/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0766-explicit_priority_choices_among_multiple_indexes","title":"[Draft] PEP 766 - Explicit Priority Choices Among Multiple Indexes","excerpt":"Python Enhancement Proposal 766: 'Explicit Priority Choices Among Multiple Indexes'에 대한 한국어 번역입니다.","date":"2025-09-27 13:46:56+0900","lastModifiedAt":"2025-09-27 13:46:56+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/766/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0765-disallow_returnbreakcontinue_that_exit_a_finally_block","title":"[Final] PEP 765 - Disallow return/break/continue that exit a finally block","excerpt":"Python Enhancement Proposal 765: 'Disallow return/break/continue that exit a finally block'에 대한 한국어 번역입니다.","date":"2025-09-27 13:46:10+0900","lastModifiedAt":"2025-09-27 13:46:10+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/765/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0764-inline_typed_dictionaries","title":"[Draft] PEP 764 - Inline typed dictionaries","excerpt":"Python Enhancement Proposal 764: 'Inline typed dictionaries'에 대한 한국어 번역입니다.","date":"2025-09-27 13:45:41+0900","lastModifiedAt":"2025-09-27 13:45:41+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/764/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0763-limiting_deletions_on_pypi","title":"[Draft] PEP 763 - Limiting deletions on PyPI","excerpt":"Python Enhancement Proposal 763: 'Limiting deletions on PyPI'에 대한 한국어 번역입니다.","date":"2025-09-27 13:45:17+0900","lastModifiedAt":"2025-09-27 13:45:17+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/763/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0762-repl-acing_the_default_repl","title":"[Final] PEP 762 - REPL-acing the default REPL","excerpt":"Python Enhancement Proposal 762: 'REPL-acing the default REPL'에 대한 한국어 번역입니다.","date":"2025-09-27 13:44:46+0900","lastModifiedAt":"2025-09-27 13:44:46+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/762/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0761-deprecating_pgp_signatures_for_cpython_artifacts","title":"[Active] PEP 761 - Deprecating PGP signatures for CPython artifacts","excerpt":"Python Enhancement Proposal 761: 'Deprecating PGP signatures for CPython artifacts'에 대한 한국어 번역입니다.","date":"2025-09-27 13:44:29+0900","lastModifiedAt":"2025-09-27 13:44:29+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/761/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0760-no_more_bare_excepts","title":"[Withdrawn] PEP 760 - No More Bare Excepts","excerpt":"Python Enhancement Proposal 760: 'No More Bare Excepts'에 대한 한국어 번역입니다.","date":"2025-09-27 13:44:07+0900","lastModifiedAt":"2025-09-27 13:44:07+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/760/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0759-external_wheel_hosting","title":"[Withdrawn] PEP 759 - External Wheel Hosting","excerpt":"Python Enhancement Proposal 759: 'External Wheel Hosting'에 대한 한국어 번역입니다.","date":"2025-09-27 13:43:53+0900","lastModifiedAt":"2025-09-27 13:43:53+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/759/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0758-allowexceptandexceptexpressions_without_parentheses","title":"[Final] PEP 758 - Allowexceptandexcept*expressions without parentheses","excerpt":"Python Enhancement Proposal 758: 'Allowexceptandexcept*expressions without parentheses'에 대한 한국어 번역입니다.","date":"2025-09-27 13:43:13+0900","lastModifiedAt":"2025-09-27 13:43:13+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/758/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0757-c_api_to_import-export_python_integers","title":"[Final] PEP 757 - C API to import-export Python integers","excerpt":"Python Enhancement Proposal 757: 'C API to import-export Python integers'에 대한 한국어 번역입니다.","date":"2025-09-27 13:42:57+0900","lastModifiedAt":"2025-09-27 13:42:57+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/757/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0756-add_pyunicode_export_and_pyunicode_import_c_functions","title":"[Withdrawn] PEP 756 - Add PyUnicode_Export() and PyUnicode_Import() C functions","excerpt":"Python Enhancement Proposal 756: 'Add PyUnicode_Export() and PyUnicode_Import() C functions'에 대한 한국어 번역입니다.","date":"2025-09-27 13:41:47+0900","lastModifiedAt":"2025-09-27 13:41:47+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/756/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0755-implicit_namespace_policy_for_pypi","title":"[Draft] PEP 755 - Implicit namespace policy for PyPI","excerpt":"Python Enhancement Proposal 755: 'Implicit namespace policy for PyPI'에 대한 한국어 번역입니다.","date":"2025-09-27 13:41:27+0900","lastModifiedAt":"2025-09-27 13:41:27+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/755/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0754-ieee_754_floating_point_special_values","title":"[Rejected] PEP 754 - IEEE 754 Floating Point Special Values","excerpt":"Python Enhancement Proposal 754: 'IEEE 754 Floating Point Special Values'에 대한 한국어 번역입니다.","date":"2025-09-27 13:41:12+0900","lastModifiedAt":"2025-09-27 13:41:12+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/754/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0753-uniform_project_urls_in_core_metadata","title":"[Accepted] PEP 753 - Uniform project URLs in core metadata","excerpt":"Python Enhancement Proposal 753: 'Uniform project URLs in core metadata'에 대한 한국어 번역입니다.","date":"2025-09-27 13:40:57+0900","lastModifiedAt":"2025-09-27 13:40:57+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/753/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0752-implicit_namespaces_for_package_repositories","title":"[Draft] PEP 752 - Implicit namespaces for package repositories","excerpt":"Python Enhancement Proposal 752: 'Implicit namespaces for package repositories'에 대한 한국어 번역입니다.","date":"2025-09-27 13:40:26+0900","lastModifiedAt":"2025-09-27 13:40:26+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/752/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0751-a_file_format_to_record_python_dependencies_for_installation_reproducibility","title":"[Final] PEP 751 - A file format to record Python dependencies for installation reproducibility","excerpt":"Python Enhancement Proposal 751: 'A file format to record Python dependencies for installation reproducibility'에 대한 한국어 번역입니다.","date":"2025-09-27 13:40:01+0900","lastModifiedAt":"2025-09-27 13:40:01+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/751/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0750-template_strings","title":"[Final] PEP 750 - Template Strings","excerpt":"Python Enhancement Proposal 750: 'Template Strings'에 대한 한국어 번역입니다.","date":"2025-09-27 13:38:50+0900","lastModifiedAt":"2025-09-27 13:38:50+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/750/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0749-implementing_pep_649","title":"[Accepted] PEP 749 - Implementing PEP 649","excerpt":"Python Enhancement Proposal 749: 'Implementing PEP 649'에 대한 한국어 번역입니다.","date":"2025-09-27 13:37:09+0900","lastModifiedAt":"2025-09-27 13:37:09+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/749/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0748-a_unified_tls_api_for_python","title":"[Draft] PEP 748 - A Unified TLS API for Python","excerpt":"Python Enhancement Proposal 748: 'A Unified TLS API for Python'에 대한 한국어 번역입니다.","date":"2025-09-27 13:35:46+0900","lastModifiedAt":"2025-09-27 13:35:46+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/748/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0747-annotating_type_forms","title":"[Draft] PEP 747 - Annotating Type Forms","excerpt":"Python Enhancement Proposal 747: 'Annotating Type Forms'에 대한 한국어 번역입니다.","date":"2025-09-27 13:35:04+0900","lastModifiedAt":"2025-09-27 13:35:04+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/747/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0746-type_checking_annotated_metadata","title":"[Draft] PEP 746 - Type checking Annotated metadata","excerpt":"Python Enhancement Proposal 746: 'Type checking Annotated metadata'에 대한 한국어 번역입니다.","date":"2025-09-27 13:34:43+0900","lastModifiedAt":"2025-09-27 13:34:43+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/746/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0745-python_3.14_release_schedule","title":"[Active] PEP 745 - Python 3.14 Release Schedule","excerpt":"Python Enhancement Proposal 745: 'Python 3.14 Release Schedule'에 대한 한국어 번역입니다.","date":"2025-09-27 13:34:29+0900","lastModifiedAt":"2025-09-27 13:34:29+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/745/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0744-jit_compilation","title":"[Draft] PEP 744 - JIT Compilation","excerpt":"Python Enhancement Proposal 744: 'JIT Compilation'에 대한 한국어 번역입니다.","date":"2025-09-27 13:34:20+0900","lastModifiedAt":"2025-09-27 13:34:20+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/744/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0743-add_py_compat_api_version_to_the_python_c_api","title":"[Draft] PEP 743 - Add Py_COMPAT_API_VERSION to the Python C API","excerpt":"Python Enhancement Proposal 743: 'Add Py_COMPAT_API_VERSION to the Python C API'에 대한 한국어 번역입니다.","date":"2025-09-27 13:33:51+0900","lastModifiedAt":"2025-09-27 13:33:51+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/743/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0742-narrowing_types_with_typeis","title":"[Final] PEP 742 - Narrowing types with TypeIs","excerpt":"Python Enhancement Proposal 742: 'Narrowing types with TypeIs'에 대한 한국어 번역입니다.","date":"2025-09-27 13:33:17+0900","lastModifiedAt":"2025-09-27 13:33:17+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/742/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0741-python_configuration_c_api","title":"[Final] PEP 741 - Python Configuration C API","excerpt":"Python Enhancement Proposal 741: 'Python Configuration C API'에 대한 한국어 번역입니다.","date":"2025-09-27 13:32:38+0900","lastModifiedAt":"2025-09-27 13:32:38+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/741/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0740-index_support_for_digital_attestations","title":"[Final] PEP 740 - Index support for digital attestations","excerpt":"Python Enhancement Proposal 740: 'Index support for digital attestations'에 대한 한국어 번역입니다.","date":"2025-09-27 13:31:46+0900","lastModifiedAt":"2025-09-27 13:31:46+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/740/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0739-build-details.json1.0_a_static_description_file_for_python_build_details","title":"[Accepted] PEP 739 - build-details.json1.0 — a static description file for Python build details","excerpt":"Python Enhancement Proposal 739: 'build-details.json1.0 — a static description file for Python build details'에 대한 한국어 번역입니다.","date":"2025-09-27 13:28:50+0900","lastModifiedAt":"2025-09-27 13:28:50+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/739/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0738-adding_android_as_a_supported_platform","title":"[Final] PEP 738 - Adding Android as a supported platform","excerpt":"Python Enhancement Proposal 738: 'Adding Android as a supported platform'에 대한 한국어 번역입니다.","date":"2025-09-27 13:28:23+0900","lastModifiedAt":"2025-09-27 13:28:23+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/738/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0737-c_api_to_format_a_type_fully_qualified_name","title":"[Final] PEP 737 - C API to format a type fully qualified name","excerpt":"Python Enhancement Proposal 737: 'C API to format a type fully qualified name'에 대한 한국어 번역입니다.","date":"2025-09-27 13:28:04+0900","lastModifiedAt":"2025-09-27 13:28:04+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/737/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0736-shorthand_syntax_for_keyword_arguments_at_invocation","title":"[Rejected] PEP 736 - Shorthand syntax for keyword arguments at invocation","excerpt":"Python Enhancement Proposal 736: 'Shorthand syntax for keyword arguments at invocation'에 대한 한국어 번역입니다.","date":"2025-09-27 13:27:17+0900","lastModifiedAt":"2025-09-27 13:27:17+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/736/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0735-dependency_groups_in_pyproject.toml","title":"[Final] PEP 735 - Dependency Groups in pyproject.toml","excerpt":"Python Enhancement Proposal 735: 'Dependency Groups in pyproject.toml'에 대한 한국어 번역입니다.","date":"2025-09-27 13:26:47+0900","lastModifiedAt":"2025-09-27 13:26:47+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/735/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0734-multiple_interpreters_in_the_stdlib","title":"[Final] PEP 734 - Multiple Interpreters in the Stdlib","excerpt":"Python Enhancement Proposal 734: 'Multiple Interpreters in the Stdlib'에 대한 한국어 번역입니다.","date":"2025-09-27 13:25:59+0900","lastModifiedAt":"2025-09-27 13:25:59+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/734/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0733-an_evaluation_of_pythons_public_c_api","title":"[Final] PEP 733 - An Evaluation of Python’s Public C API","excerpt":"Python Enhancement Proposal 733: 'An Evaluation of Python’s Public C API'에 대한 한국어 번역입니다.","date":"2025-09-27 13:23:51+0900","lastModifiedAt":"2025-09-27 13:23:51+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/733/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0732-the_python_documentation_editorial_board","title":"[Active] PEP 732 - The Python Documentation Editorial Board","excerpt":"Python Enhancement Proposal 732: 'The Python Documentation Editorial Board'에 대한 한국어 번역입니다.","date":"2025-09-27 13:23:00+0900","lastModifiedAt":"2025-09-27 13:23:00+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/732/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0731-c_api_working_group_charter","title":"[Active] PEP 731 - C API Working Group Charter","excerpt":"Python Enhancement Proposal 731: 'C API Working Group Charter'에 대한 한국어 번역입니다.","date":"2025-09-27 13:22:44+0900","lastModifiedAt":"2025-09-27 13:22:44+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/731/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0730-adding_ios_as_a_supported_platform","title":"[Final] PEP 730 - Adding iOS as a supported platform","excerpt":"Python Enhancement Proposal 730: 'Adding iOS as a supported platform'에 대한 한국어 번역입니다.","date":"2025-09-27 13:22:30+0900","lastModifiedAt":"2025-09-27 13:22:30+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/730/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0729-typing_governance_process","title":"[Active] PEP 729 - Typing governance process","excerpt":"Python Enhancement Proposal 729: 'Typing governance process'에 대한 한국어 번역입니다.","date":"2025-09-27 13:21:49+0900","lastModifiedAt":"2025-09-27 13:21:49+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/729/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0728-typeddict_with_typed_extra_items","title":"[Accepted] PEP 728 - TypedDict with Typed Extra Items","excerpt":"Python Enhancement Proposal 728: 'TypedDict with Typed Extra Items'에 대한 한국어 번역입니다.","date":"2025-09-27 13:20:42+0900","lastModifiedAt":"2025-09-27 13:20:42+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/728/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0727-documentation_in_annotated_metadata","title":"[Withdrawn] PEP 727 - Documentation in Annotated Metadata","excerpt":"Python Enhancement Proposal 727: 'Documentation in Annotated Metadata'에 대한 한국어 번역입니다.","date":"2025-09-27 13:19:38+0900","lastModifiedAt":"2025-09-27 13:19:38+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/727/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0726-module__setattr__and__delattr","title":"[Rejected] PEP 726 - Module__setattr__and__delattr__","excerpt":"Python Enhancement Proposal 726: 'Module__setattr__and__delattr__'에 대한 한국어 번역입니다.","date":"2025-09-27 13:19:13+0900","lastModifiedAt":"2025-09-27 13:19:13+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/726/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0725-specifying_external_dependencies_in_pyproject.toml","title":"[Draft] PEP 725 - Specifying external dependencies in pyproject.toml","excerpt":"Python Enhancement Proposal 725: 'Specifying external dependencies in pyproject.toml'에 대한 한국어 번역입니다.","date":"2025-09-27 13:18:53+0900","lastModifiedAt":"2025-09-27 13:18:53+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/725/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0724-stricter_type_guards","title":"[Withdrawn] PEP 724 - Stricter Type Guards","excerpt":"Python Enhancement Proposal 724: 'Stricter Type Guards'에 대한 한국어 번역입니다.","date":"2025-09-27 13:17:29+0900","lastModifiedAt":"2025-09-27 13:17:29+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/724/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0723-inline_script_metadata","title":"[Final] PEP 723 - Inline script metadata","excerpt":"Python Enhancement Proposal 723: 'Inline script metadata'에 대한 한국어 번역입니다.","date":"2025-09-27 13:17:06+0900","lastModifiedAt":"2025-09-27 13:17:06+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/723/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0722-dependency_specification_for_single-file_scripts","title":"[Rejected] PEP 722 - Dependency specification for single-file scripts","excerpt":"Python Enhancement Proposal 722: 'Dependency specification for single-file scripts'에 대한 한국어 번역입니다.","date":"2025-09-27 13:16:11+0900","lastModifiedAt":"2025-09-27 13:16:11+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/722/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0721-using_tarfile.data_filter_for_source_distribution_extraction","title":"[Final] PEP 721 - Using tarfile.data_filter for source distribution extraction","excerpt":"Python Enhancement Proposal 721: 'Using tarfile.data_filter for source distribution extraction'에 대한 한국어 번역입니다.","date":"2025-09-27 13:15:15+0900","lastModifiedAt":"2025-09-27 13:15:15+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/721/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0720-cross-compiling_python_packages","title":"[Draft] PEP 720 - Cross-compiling Python packages","excerpt":"Python Enhancement Proposal 720: 'Cross-compiling Python packages'에 대한 한국어 번역입니다.","date":"2025-09-27 13:14:54+0900","lastModifiedAt":"2025-09-27 13:14:54+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/720/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0719-python_3.13_release_schedule","title":"[Active] PEP 719 - Python 3.13 Release Schedule","excerpt":"Python Enhancement Proposal 719: 'Python 3.13 Release Schedule'에 대한 한국어 번역입니다.","date":"2025-09-27 13:14:04+0900","lastModifiedAt":"2025-09-27 13:14:04+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/719/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0718-subscriptable_functions","title":"[Draft] PEP 718 - Subscriptable functions","excerpt":"Python Enhancement Proposal 718: 'Subscriptable functions'에 대한 한국어 번역입니다.","date":"2025-09-27 13:13:52+0900","lastModifiedAt":"2025-09-27 13:13:52+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/718/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0715-disabling_bdist_egg_distribution_uploads_on_pypi","title":"[Final] PEP 715 - Disabling bdist_egg distribution uploads on PyPI","excerpt":"Python Enhancement Proposal 715: 'Disabling bdist_egg distribution uploads on PyPI'에 대한 한국어 번역입니다.","date":"2025-09-27 13:13:33+0900","lastModifiedAt":"2025-09-27 13:13:33+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/715/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0714-rename_dist-info-metadata_in_the_simple_api","title":"[Accepted] PEP 714 - Rename dist-info-metadata in the Simple API","excerpt":"Python Enhancement Proposal 714: 'Rename dist-info-metadata in the Simple API'에 대한 한국어 번역입니다.","date":"2025-09-27 13:13:16+0900","lastModifiedAt":"2025-09-27 13:13:16+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/714/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0713-callable_modules","title":"[Rejected] PEP 713 - Callable Modules","excerpt":"Python Enhancement Proposal 713: 'Callable Modules'에 대한 한국어 번역입니다.","date":"2025-09-27 13:12:51+0900","lastModifiedAt":"2025-09-27 13:12:51+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/713/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0712-adding_a_converter_parameter_to_dataclasses.field","title":"[Rejected] PEP 712 - Adding a “converter” parameter to dataclasses.field","excerpt":"Python Enhancement Proposal 712: 'Adding a “converter” parameter to dataclasses.field'에 대한 한국어 번역입니다.","date":"2025-09-27 13:12:37+0900","lastModifiedAt":"2025-09-27 13:12:37+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/712/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0711-pybi_a_standard_format_for_distributing_python_binaries","title":"[Draft] PEP 711 - PyBI: a standard format for distributing Python Binaries","excerpt":"Python Enhancement Proposal 711: 'PyBI: a standard format for distributing Python Binaries'에 대한 한국어 번역입니다.","date":"2025-09-27 13:12:07+0900","lastModifiedAt":"2025-09-27 13:12:07+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/711/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0710-recording_the_provenance_of_installed_packages","title":"[Draft] PEP 710 - Recording the provenance of installed packages","excerpt":"Python Enhancement Proposal 710: 'Recording the provenance of installed packages'에 대한 한국어 번역입니다.","date":"2025-09-27 13:11:44+0900","lastModifiedAt":"2025-09-27 13:11:44+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/710/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0709-inlined_comprehensions","title":"[Final] PEP 709 - Inlined comprehensions","excerpt":"Python Enhancement Proposal 709: 'Inlined comprehensions'에 대한 한국어 번역입니다.","date":"2025-09-27 13:10:56+0900","lastModifiedAt":"2025-09-27 13:10:56+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/709/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0708-extending_the_repository_api_to_mitigate_dependency_confusion_attacks","title":"[Provisional] PEP 708 - Extending the Repository API to Mitigate Dependency Confusion Attacks","excerpt":"Python Enhancement Proposal 708: 'Extending the Repository API to Mitigate Dependency Confusion Attacks'에 대한 한국어 번역입니다.","date":"2025-09-27 13:10:38+0900","lastModifiedAt":"2025-09-27 13:10:38+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/708/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0707-a_simplified_signature_for___exit___and___aexit","title":"[Rejected] PEP 707 - A simplified signature for __exit__ and __aexit__","excerpt":"Python Enhancement Proposal 707: 'A simplified signature for __exit__ and __aexit__'에 대한 한국어 번역입니다.","date":"2025-09-27 13:09:56+0900","lastModifiedAt":"2025-09-27 13:09:56+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/707/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0706-filter_for_tarfile.extractall","title":"[Final] PEP 706 - Filter for tarfile.extractall","excerpt":"Python Enhancement Proposal 706: 'Filter for tarfile.extractall'에 대한 한국어 번역입니다.","date":"2025-09-27 13:09:29+0900","lastModifiedAt":"2025-09-27 13:09:29+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/706/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0705-typeddict_read-only_items","title":"[Final] PEP 705 - TypedDict: Read-only items","excerpt":"Python Enhancement Proposal 705: 'TypedDict: Read-only items'에 대한 한국어 번역입니다.","date":"2025-09-27 13:08:52+0900","lastModifiedAt":"2025-09-27 13:08:52+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/705/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0704-require_virtual_environments_by_default_for_package_installers","title":"[Withdrawn] PEP 704 - Require virtual environments by default for package installers","excerpt":"Python Enhancement Proposal 704: 'Require virtual environments by default for package installers'에 대한 한국어 번역입니다.","date":"2025-09-27 13:08:22+0900","lastModifiedAt":"2025-09-27 13:08:22+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/704/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0703-making_the_global_interpreter_lock_optional_in_cpython","title":"[Accepted] PEP 703 - Making the Global Interpreter Lock Optional in CPython","excerpt":"Python Enhancement Proposal 703: 'Making the Global Interpreter Lock Optional in CPython'에 대한 한국어 번역입니다.","date":"2025-09-27 13:08:02+0900","lastModifiedAt":"2025-09-27 13:08:02+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/703/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0702-marking_deprecations_using_the_type_system","title":"[Final] PEP 702 - Marking deprecations using the type system","excerpt":"Python Enhancement Proposal 702: 'Marking deprecations using the type system'에 대한 한국어 번역입니다.","date":"2025-09-27 13:07:08+0900","lastModifiedAt":"2025-09-27 13:07:08+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/702/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0701-syntactic_formalization_of_f-strings","title":"[Accepted] PEP 701 - Syntactic formalization of f-strings","excerpt":"Python Enhancement Proposal 701: 'Syntactic formalization of f-strings'에 대한 한국어 번역입니다.","date":"2025-09-27 13:06:50+0900","lastModifiedAt":"2025-09-27 13:06:50+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/701/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0700-additional_fields_for_the_simple_api_for_package_indexes","title":"[Final] PEP 700 - Additional Fields for the Simple API for Package Indexes","excerpt":"Python Enhancement Proposal 700: 'Additional Fields for the Simple API for Package Indexes'에 대한 한국어 번역입니다.","date":"2025-09-27 13:05:58+0900","lastModifiedAt":"2025-09-27 13:05:58+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/700/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0699-remove_private_dict_version_field_added_in_pep_509","title":"[Accepted] PEP 699 - Remove private dict version field added in PEP 509","excerpt":"Python Enhancement Proposal 699: 'Remove private dict version field added in PEP 509'에 대한 한국어 번역입니다.","date":"2025-09-27 13:05:33+0900","lastModifiedAt":"2025-09-27 13:05:33+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/699/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0698-override_decorator_for_static_typing","title":"[Final] PEP 698 - Override Decorator for Static Typing","excerpt":"Python Enhancement Proposal 698: 'Override Decorator for Static Typing'에 대한 한국어 번역입니다.","date":"2025-09-27 13:05:19+0900","lastModifiedAt":"2025-09-27 13:05:19+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/698/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0697-limited_c_api_for_extending_opaque_types","title":"[Final] PEP 697 - Limited C API for Extending Opaque Types","excerpt":"Python Enhancement Proposal 697: 'Limited C API for Extending Opaque Types'에 대한 한국어 번역입니다.","date":"2025-09-27 13:04:45+0900","lastModifiedAt":"2025-09-27 13:04:45+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/697/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0696-type_defaults_for_type_parameters","title":"[Final] PEP 696 - Type Defaults for Type Parameters","excerpt":"Python Enhancement Proposal 696: 'Type Defaults for Type Parameters'에 대한 한국어 번역입니다.","date":"2025-09-27 13:04:16+0900","lastModifiedAt":"2025-09-27 13:04:16+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/696/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0695-type_parameter_syntax","title":"[Final] PEP 695 - Type Parameter Syntax","excerpt":"Python Enhancement Proposal 695: 'Type Parameter Syntax'에 대한 한국어 번역입니다.","date":"2025-09-27 13:03:44+0900","lastModifiedAt":"2025-09-27 13:03:44+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/695/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0694-upload_2.0_api_for_python_package_indexes","title":"[Draft] PEP 694 - Upload 2.0 API for Python Package Indexes","excerpt":"Python Enhancement Proposal 694: 'Upload 2.0 API for Python Package Indexes'에 대한 한국어 번역입니다.","date":"2025-09-27 10:23:36+0900","lastModifiedAt":"2025-09-27 10:23:36+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/694/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0693-python_3.12_release_schedule","title":"[Active] PEP 693 - Python 3.12 Release Schedule","excerpt":"Python Enhancement Proposal 693: 'Python 3.12 Release Schedule'에 대한 한국어 번역입니다.","date":"2025-09-27 10:22:22+0900","lastModifiedAt":"2025-09-27 10:22:22+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/693/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0692-using_typeddict_for_more_precise_kwargs_typing","title":"[Final] PEP 692 - Using TypedDict for more precise **kwargs typing","excerpt":"Python Enhancement Proposal 692: 'Using TypedDict for more precise **kwargs typing'에 대한 한국어 번역입니다.","date":"2025-09-27 10:21:57+0900","lastModifiedAt":"2025-09-27 10:21:57+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/692/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0691-json-based_simple_api_for_python_package_indexes","title":"[Accepted] PEP 691 - JSON-based Simple API for Python Package Indexes","excerpt":"Python Enhancement Proposal 691: 'JSON-based Simple API for Python Package Indexes'에 대한 한국어 번역입니다.","date":"2025-09-27 10:21:04+0900","lastModifiedAt":"2025-09-27 10:21:04+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/691/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0690-lazy_imports","title":"[Rejected] PEP 690 - Lazy Imports","excerpt":"Python Enhancement Proposal 690: 'Lazy Imports'에 대한 한국어 번역입니다.","date":"2025-09-27 10:19:51+0900","lastModifiedAt":"2025-09-27 10:19:51+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/690/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0689-unstable_c_api_tier","title":"[Final] PEP 689 - Unstable C API tier","excerpt":"Python Enhancement Proposal 689: 'Unstable C API tier'에 대한 한국어 번역입니다.","date":"2025-09-27 10:13:23+0900","lastModifiedAt":"2025-09-27 10:13:23+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/689/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0688-making_the_buffer_protocol_accessible_in_python","title":"[Final] PEP 688 - Making the buffer protocol accessible in Python","excerpt":"Python Enhancement Proposal 688: 'Making the buffer protocol accessible in Python'에 대한 한국어 번역입니다.","date":"2025-09-27 10:13:02+0900","lastModifiedAt":"2025-09-27 10:13:02+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/688/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0687-isolating_modules_in_the_standard_library","title":"[Accepted] PEP 687 - Isolating modules in the standard library","excerpt":"Python Enhancement Proposal 687: 'Isolating modules in the standard library'에 대한 한국어 번역입니다.","date":"2025-09-27 10:12:44+0900","lastModifiedAt":"2025-09-27 10:12:44+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/687/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0686-make_utf-8_mode_default","title":"[Accepted] PEP 686 - Make UTF-8 mode default","excerpt":"Python Enhancement Proposal 686: 'Make UTF-8 mode default'에 대한 한국어 번역입니다.","date":"2025-09-27 10:12:32+0900","lastModifiedAt":"2025-09-27 10:12:32+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/686/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0685-comparison_of_extra_names_for_optional_distribution_dependencies","title":"[Final] PEP 685 - Comparison of extra names for optional distribution dependencies","excerpt":"Python Enhancement Proposal 685: 'Comparison of extra names for optional distribution dependencies'에 대한 한국어 번역입니다.","date":"2025-09-27 10:12:15+0900","lastModifiedAt":"2025-09-27 10:12:15+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/685/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0684-a_per-interpreter_gil","title":"[Final] PEP 684 - A Per-Interpreter GIL","excerpt":"Python Enhancement Proposal 684: 'A Per-Interpreter GIL'에 대한 한국어 번역입니다.","date":"2025-09-27 10:11:59+0900","lastModifiedAt":"2025-09-27 10:11:59+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/684/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0683-immortal_objects_using_a_fixed_refcount","title":"[Final] PEP 683 - Immortal Objects, Using a Fixed Refcount","excerpt":"Python Enhancement Proposal 683: 'Immortal Objects, Using a Fixed Refcount'에 대한 한국어 번역입니다.","date":"2025-09-27 10:11:29+0900","lastModifiedAt":"2025-09-27 10:11:29+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/683/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0682-format_specifier_for_signed_zero","title":"[Final] PEP 682 - Format Specifier for Signed Zero","excerpt":"Python Enhancement Proposal 682: 'Format Specifier for Signed Zero'에 대한 한국어 번역입니다.","date":"2025-09-27 10:10:49+0900","lastModifiedAt":"2025-09-27 10:10:49+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/682/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0681-data_class_transforms","title":"[Final] PEP 681 - Data Class Transforms","excerpt":"Python Enhancement Proposal 681: 'Data Class Transforms'에 대한 한국어 번역입니다.","date":"2025-09-27 10:10:35+0900","lastModifiedAt":"2025-09-27 10:10:35+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/681/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0680-tomllib_support_for_parsing_toml_in_the_standard_library","title":"[Final] PEP 680 - tomllib: Support for Parsing TOML in the Standard Library","excerpt":"Python Enhancement Proposal 680: 'tomllib: Support for Parsing TOML in the Standard Library'에 대한 한국어 번역입니다.","date":"2025-09-27 10:10:11+0900","lastModifiedAt":"2025-09-27 10:10:11+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/680/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0679-new_assert_statement_syntax_with_parentheses","title":"[Draft] PEP 679 - New assert statement syntax with parentheses","excerpt":"Python Enhancement Proposal 679: 'New assert statement syntax with parentheses'에 대한 한국어 번역입니다.","date":"2025-09-27 10:09:51+0900","lastModifiedAt":"2025-09-27 10:09:51+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/679/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0678-enriching_exceptions_with_notes","title":"[Final] PEP 678 - Enriching Exceptions with Notes","excerpt":"Python Enhancement Proposal 678: 'Enriching Exceptions with Notes'에 대한 한국어 번역입니다.","date":"2025-09-27 10:09:33+0900","lastModifiedAt":"2025-09-27 10:09:33+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/678/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0677-callable_type_syntax","title":"[Rejected] PEP 677 - Callable Type Syntax","excerpt":"Python Enhancement Proposal 677: 'Callable Type Syntax'에 대한 한국어 번역입니다.","date":"2025-09-27 10:09:13+0900","lastModifiedAt":"2025-09-27 10:09:13+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/677/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0676-pep_infrastructure_process","title":"[Active] PEP 676 - PEP Infrastructure Process","excerpt":"Python Enhancement Proposal 676: 'PEP Infrastructure Process'에 대한 한국어 번역입니다.","date":"2025-09-27 10:08:50+0900","lastModifiedAt":"2025-09-27 10:08:50+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/676/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0675-arbitrary_literal_string_type","title":"[Final] PEP 675 - Arbitrary Literal String Type","excerpt":"Python Enhancement Proposal 675: 'Arbitrary Literal String Type'에 대한 한국어 번역입니다.","date":"2025-09-27 10:08:22+0900","lastModifiedAt":"2025-09-27 10:08:22+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/675/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0674-disallow_using_macros_as_l-values","title":"[Deferred] PEP 674 - Disallow using macros as l-values","excerpt":"Python Enhancement Proposal 674: 'Disallow using macros as l-values'에 대한 한국어 번역입니다.","date":"2025-09-27 10:07:42+0900","lastModifiedAt":"2025-09-27 10:07:42+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/674/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0673-self_type","title":"[Final] PEP 673 - Self Type","excerpt":"Python Enhancement Proposal 673: 'Self Type'에 대한 한국어 번역입니다.","date":"2025-09-27 10:07:14+0900","lastModifiedAt":"2025-09-27 10:07:14+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/673/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0672-unicode-related_security_considerations_for_python","title":"[Active] PEP 672 - Unicode-related Security Considerations for Python","excerpt":"Python Enhancement Proposal 672: 'Unicode-related Security Considerations for Python'에 대한 한국어 번역입니다.","date":"2025-09-27 10:06:17+0900","lastModifiedAt":"2025-09-27 10:06:17+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/672/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0671-syntax_for_late-bound_function_argument_defaults","title":"[Draft] PEP 671 - Syntax for late-bound function argument defaults","excerpt":"Python Enhancement Proposal 671: 'Syntax for late-bound function argument defaults'에 대한 한국어 번역입니다.","date":"2025-09-27 10:05:44+0900","lastModifiedAt":"2025-09-27 10:05:44+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/671/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0670-convert_macros_to_functions_in_the_python_c_api","title":"[Final] PEP 670 - Convert macros to functions in the Python C API","excerpt":"Python Enhancement Proposal 670: 'Convert macros to functions in the Python C API'에 대한 한국어 번역입니다.","date":"2025-09-27 10:05:27+0900","lastModifiedAt":"2025-09-27 10:05:27+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/670/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0669-low_impact_monitoring_for_cpython","title":"[Final] PEP 669 - Low Impact Monitoring for CPython","excerpt":"Python Enhancement Proposal 669: 'Low Impact Monitoring for CPython'에 대한 한국어 번역입니다.","date":"2025-09-27 10:04:48+0900","lastModifiedAt":"2025-09-27 10:04:48+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/669/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0668-marking_python_base_environments_as_externally_managed","title":"[Accepted] PEP 668 - Marking Python base environments as “externally managed”","excerpt":"Python Enhancement Proposal 668: 'Marking Python base environments as “externally managed”'에 대한 한국어 번역입니다.","date":"2025-09-27 10:04:11+0900","lastModifiedAt":"2025-09-27 10:04:11+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/668/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0667-consistent_views_of_namespaces","title":"[Final] PEP 667 - Consistent views of namespaces","excerpt":"Python Enhancement Proposal 667: 'Consistent views of namespaces'에 대한 한국어 번역입니다.","date":"2025-09-27 10:03:19+0900","lastModifiedAt":"2025-09-27 10:03:19+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/667/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0666-reject_foolish_indentation","title":"[Rejected] PEP 666 - Reject Foolish Indentation","excerpt":"Python Enhancement Proposal 666: 'Reject Foolish Indentation'에 대한 한국어 번역입니다.","date":"2025-09-27 10:02:26+0900","lastModifiedAt":"2025-09-27 10:02:26+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/666/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0665-a_file_format_to_list_python_dependencies_for_reproducibility_of_an_application","title":"[Rejected] PEP 665 - A file format to list Python dependencies for reproducibility of an application","excerpt":"Python Enhancement Proposal 665: 'A file format to list Python dependencies for reproducibility of an application'에 대한 한국어 번역입니다.","date":"2025-09-27 10:02:15+0900","lastModifiedAt":"2025-09-27 10:02:15+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/665/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0664-python_3.11_release_schedule","title":"[Active] PEP 664 - Python 3.11 Release Schedule","excerpt":"Python Enhancement Proposal 664: 'Python 3.11 Release Schedule'에 대한 한국어 번역입니다.","date":"2025-09-27 09:57:22+0900","lastModifiedAt":"2025-09-27 09:57:22+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/664/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0663-standardizing_enum_str_repr_and_format_behaviors","title":"[Rejected] PEP 663 - Standardizing Enum str(), repr(), and format() behaviors","excerpt":"Python Enhancement Proposal 663: 'Standardizing Enum str(), repr(), and format() behaviors'에 대한 한국어 번역입니다.","date":"2025-09-27 09:57:11+0900","lastModifiedAt":"2025-09-27 09:57:11+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/663/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0662-editable_installs_via_virtual_wheels","title":"[Rejected] PEP 662 - Editable installs via virtual wheels","excerpt":"Python Enhancement Proposal 662: 'Editable installs via virtual wheels'에 대한 한국어 번역입니다.","date":"2025-09-27 09:56:52+0900","lastModifiedAt":"2025-09-27 09:56:52+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/662/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0661-sentinel_values","title":"[Deferred] PEP 661 - Sentinel Values","excerpt":"Python Enhancement Proposal 661: 'Sentinel Values'에 대한 한국어 번역입니다.","date":"2025-09-27 09:55:59+0900","lastModifiedAt":"2025-09-27 09:55:59+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/661/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0660-editable_installs_for_pyproject.toml_based_builds_wheel_based","title":"[Final] PEP 660 - Editable installs for pyproject.toml based builds (wheel based)","excerpt":"Python Enhancement Proposal 660: 'Editable installs for pyproject.toml based builds (wheel based)'에 대한 한국어 번역입니다.","date":"2025-09-27 09:55:28+0900","lastModifiedAt":"2025-09-27 09:55:28+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/660/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0659-specializing_adaptive_interpreter","title":"[Final] PEP 659 - Specializing Adaptive Interpreter","excerpt":"Python Enhancement Proposal 659: 'Specializing Adaptive Interpreter'에 대한 한국어 번역입니다.","date":"2025-09-27 09:54:44+0900","lastModifiedAt":"2025-09-27 09:54:44+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/659/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0658-serve_distribution_metadata_in_the_simple_repository_api","title":"[Accepted] PEP 658 - Serve Distribution Metadata in the Simple Repository API","excerpt":"Python Enhancement Proposal 658: 'Serve Distribution Metadata in the Simple Repository API'에 대한 한국어 번역입니다.","date":"2025-09-27 09:54:18+0900","lastModifiedAt":"2025-09-27 09:54:18+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/658/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0657-include_fine_grained_error_locations_in_tracebacks","title":"[Final] PEP 657 - Include Fine Grained Error Locations in Tracebacks","excerpt":"Python Enhancement Proposal 657: 'Include Fine Grained Error Locations in Tracebacks'에 대한 한국어 번역입니다.","date":"2025-09-27 09:54:06+0900","lastModifiedAt":"2025-09-27 09:54:06+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/657/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0656-platform_tag_for_linux_distributions_using_musl","title":"[Final] PEP 656 - Platform Tag for Linux Distributions Using Musl","excerpt":"Python Enhancement Proposal 656: 'Platform Tag for Linux Distributions Using Musl'에 대한 한국어 번역입니다.","date":"2025-09-27 09:53:36+0900","lastModifiedAt":"2025-09-27 09:53:36+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/656/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0655-marking_individual_typeddict_items_as_required_or_potentially-missing","title":"[Final] PEP 655 - Marking individual TypedDict items as required or potentially-missing","excerpt":"Python Enhancement Proposal 655: 'Marking individual TypedDict items as required or potentially-missing'에 대한 한국어 번역입니다.","date":"2025-09-27 09:53:14+0900","lastModifiedAt":"2025-09-27 09:53:14+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/655/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0654-exception_groups_and_except","title":"[Final] PEP 654 - Exception Groups and except*","excerpt":"Python Enhancement Proposal 654: 'Exception Groups and except*'에 대한 한국어 번역입니다.","date":"2025-09-27 09:52:52+0900","lastModifiedAt":"2025-09-27 09:52:52+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/654/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0653-precise_semantics_for_pattern_matching","title":"[Draft] PEP 653 - Precise Semantics for Pattern Matching","excerpt":"Python Enhancement Proposal 653: 'Precise Semantics for Pattern Matching'에 대한 한국어 번역입니다.","date":"2025-09-27 09:52:27+0900","lastModifiedAt":"2025-09-27 09:52:27+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/653/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0652-maintaining_the_stable_abi","title":"[Final] PEP 652 - Maintaining the Stable ABI","excerpt":"Python Enhancement Proposal 652: 'Maintaining the Stable ABI'에 대한 한국어 번역입니다.","date":"2025-09-27 01:41:49+0900","lastModifiedAt":"2025-09-27 01:41:49+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/652/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0651-robust_stack_overflow_handling","title":"[Rejected] PEP 651 - Robust Stack Overflow Handling","excerpt":"Python Enhancement Proposal 651: 'Robust Stack Overflow Handling'에 대한 한국어 번역입니다.","date":"2025-09-27 01:41:16+0900","lastModifiedAt":"2025-09-27 01:41:16+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/651/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0650-specifying_installer_requirements_for_python_projects","title":"[Withdrawn] PEP 650 - Specifying Installer Requirements for Python Projects","excerpt":"Python Enhancement Proposal 650: 'Specifying Installer Requirements for Python Projects'에 대한 한국어 번역입니다.","date":"2025-09-27 01:40:48+0900","lastModifiedAt":"2025-09-27 01:40:48+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/650/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0649-deferred_evaluation_of_annotations_using_descriptors","title":"[Accepted] PEP 649 - Deferred Evaluation Of Annotations Using Descriptors","excerpt":"Python Enhancement Proposal 649: 'Deferred Evaluation Of Annotations Using Descriptors'에 대한 한국어 번역입니다.","date":"2025-09-27 01:39:54+0900","lastModifiedAt":"2025-09-27 01:39:54+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/649/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0648-extensible_customizations_of_the_interpreter_at_startup","title":"[Rejected] PEP 648 - Extensible customizations of the interpreter at startup","excerpt":"Python Enhancement Proposal 648: 'Extensible customizations of the interpreter at startup'에 대한 한국어 번역입니다.","date":"2025-09-27 01:37:58+0900","lastModifiedAt":"2025-09-27 01:37:58+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/648/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0647-user-defined_type_guards","title":"[Final] PEP 647 - User-Defined Type Guards","excerpt":"Python Enhancement Proposal 647: 'User-Defined Type Guards'에 대한 한국어 번역입니다.","date":"2025-09-27 01:37:28+0900","lastModifiedAt":"2025-09-27 01:37:28+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/647/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0646-variadic_generics","title":"[Final] PEP 646 - Variadic Generics","excerpt":"Python Enhancement Proposal 646: 'Variadic Generics'에 대한 한국어 번역입니다.","date":"2025-09-27 01:37:00+0900","lastModifiedAt":"2025-09-27 01:37:00+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/646/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0645-allow_writing_optional_types_asx","title":"[Withdrawn] PEP 645 - Allow writing optional types asx?","excerpt":"Python Enhancement Proposal 645: 'Allow writing optional types asx?'에 대한 한국어 번역입니다.","date":"2025-09-27 01:34:51+0900","lastModifiedAt":"2025-09-27 01:34:51+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/645/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0644-require_openssl_1.1.1_or_newer","title":"[Final] PEP 644 - Require OpenSSL 1.1.1 or newer","excerpt":"Python Enhancement Proposal 644: 'Require OpenSSL 1.1.1 or newer'에 대한 한국어 번역입니다.","date":"2025-09-27 01:34:31+0900","lastModifiedAt":"2025-09-27 01:34:31+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/644/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0643-metadata_for_package_source_distributions","title":"[Final] PEP 643 - Metadata for Package Source Distributions","excerpt":"Python Enhancement Proposal 643: 'Metadata for Package Source Distributions'에 대한 한국어 번역입니다.","date":"2025-09-27 01:33:51+0900","lastModifiedAt":"2025-09-27 01:33:51+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/643/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0642-explicit_pattern_syntax_for_structural_pattern_matching","title":"[Rejected] PEP 642 - Explicit Pattern Syntax for Structural Pattern Matching","excerpt":"Python Enhancement Proposal 642: 'Explicit Pattern Syntax for Structural Pattern Matching'에 대한 한국어 번역입니다.","date":"2025-09-27 01:33:04+0900","lastModifiedAt":"2025-09-27 01:33:04+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/642/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0641-using_an_underscore_in_the_version_portion_of_python_3.10_compatibility_tags","title":"[Rejected] PEP 641 - Using an underscore in the version portion of Python 3.10 compatibility tags","excerpt":"Python Enhancement Proposal 641: 'Using an underscore in the version portion of Python 3.10 compatibility tags'에 대한 한국어 번역입니다.","date":"2025-09-27 01:32:00+0900","lastModifiedAt":"2025-09-27 01:32:00+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/641/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0640-unused_variable_syntax","title":"[Rejected] PEP 640 - Unused variable syntax","excerpt":"Python Enhancement Proposal 640: 'Unused variable syntax'에 대한 한국어 번역입니다.","date":"2025-09-27 01:31:38+0900","lastModifiedAt":"2025-09-27 01:31:38+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/640/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0639-improving_license_clarity_with_better_package_metadata","title":"[Final] PEP 639 - Improving License Clarity with Better Package Metadata","excerpt":"Python Enhancement Proposal 639: 'Improving License Clarity with Better Package Metadata'에 대한 한국어 번역입니다.","date":"2025-09-27 01:31:09+0900","lastModifiedAt":"2025-09-27 01:31:09+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/639/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0638-syntactic_macros","title":"[Draft] PEP 638 - Syntactic Macros","excerpt":"Python Enhancement Proposal 638: 'Syntactic Macros'에 대한 한국어 번역입니다.","date":"2025-09-27 01:30:41+0900","lastModifiedAt":"2025-09-27 01:30:41+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/638/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0637-support_for_indexing_with_keyword_arguments","title":"[Rejected] PEP 637 - Support for indexing with keyword arguments","excerpt":"Python Enhancement Proposal 637: 'Support for indexing with keyword arguments'에 대한 한국어 번역입니다.","date":"2025-09-27 01:29:49+0900","lastModifiedAt":"2025-09-27 01:29:49+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/637/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0636-structural_pattern_matching_tutorial","title":"[Final] PEP 636 - Structural Pattern Matching: Tutorial","excerpt":"Python Enhancement Proposal 636: 'Structural Pattern Matching: Tutorial'에 대한 한국어 번역입니다.","date":"2025-09-27 01:29:01+0900","lastModifiedAt":"2025-09-27 01:29:01+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/636/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0635-structural_pattern_matching_motivation_and_rationale","title":"[Final] PEP 635 - Structural Pattern Matching: Motivation and Rationale","excerpt":"Python Enhancement Proposal 635: 'Structural Pattern Matching: Motivation and Rationale'에 대한 한국어 번역입니다.","date":"2025-09-27 01:26:51+0900","lastModifiedAt":"2025-09-27 01:26:51+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/635/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0634-structural_pattern_matching_specification","title":"[Final] PEP 634 - Structural Pattern Matching: Specification","excerpt":"Python Enhancement Proposal 634: 'Structural Pattern Matching: Specification'에 대한 한국어 번역입니다.","date":"2025-09-27 01:25:49+0900","lastModifiedAt":"2025-09-27 01:25:49+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/634/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0633-dependency_specification_in_pyproject.toml_using_an_exploded_toml_table","title":"[Rejected] PEP 633 - Dependency specification in pyproject.toml using an exploded TOML table","excerpt":"Python Enhancement Proposal 633: 'Dependency specification in pyproject.toml using an exploded TOML table'에 대한 한국어 번역입니다.","date":"2025-09-27 01:25:08+0900","lastModifiedAt":"2025-09-27 01:25:08+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/633/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0632-deprecate_distutils_module","title":"[Final] PEP 632 - Deprecate distutils module","excerpt":"Python Enhancement Proposal 632: 'Deprecate distutils module'에 대한 한국어 번역입니다.","date":"2025-09-27 01:16:21+0900","lastModifiedAt":"2025-09-27 01:16:21+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/632/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0631-dependency_specification_in_pyproject.toml_based_on_pep_508","title":"[Superseded] PEP 631 - Dependency specification in pyproject.toml based on PEP 508","excerpt":"Python Enhancement Proposal 631: 'Dependency specification in pyproject.toml based on PEP 508'에 대한 한국어 번역입니다.","date":"2025-09-27 01:15:39+0900","lastModifiedAt":"2025-09-27 01:15:39+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/631/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0630-isolating_extension_modules","title":"[Final] PEP 630 - Isolating Extension Modules","excerpt":"Python Enhancement Proposal 630: 'Isolating Extension Modules'에 대한 한국어 번역입니다.","date":"2025-09-27 01:13:23+0900","lastModifiedAt":"2025-09-27 01:13:23+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/630/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0355-path_-_object_oriented_filesystem_paths","title":"[Rejected] PEP 355 - Path - Object oriented filesystem paths","excerpt":"Python Enhancement Proposal 355: 'Path - Object oriented filesystem paths'에 대한 한국어 번역입니다.","date":"2025-09-27 01:12:42+0900","lastModifiedAt":"2025-09-27 01:12:42+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/355/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0343-the_with_statement","title":"[Final] PEP 343 - The “with” Statement","excerpt":"Python Enhancement Proposal 343: 'The “with” Statement'에 대한 한국어 번역입니다.","date":"2025-09-27 01:01:20+0900","lastModifiedAt":"2025-09-27 01:01:20+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/343/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0335-overloadable_boolean_operators","title":"[Rejected] PEP 335 - Overloadable Boolean Operators","excerpt":"Python Enhancement Proposal 335: 'Overloadable Boolean Operators'에 대한 한국어 번역입니다.","date":"2025-09-27 00:55:17+0900","lastModifiedAt":"2025-09-27 00:55:17+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/335/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0629-versioning_pypis_simple_api","title":"[Final] PEP 629 - Versioning PyPI’s Simple API","excerpt":"Python Enhancement Proposal 629: 'Versioning PyPI’s Simple API'에 대한 한국어 번역입니다.","date":"2025-09-27 00:30:52+0900","lastModifiedAt":"2025-09-27 00:30:52+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/629/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0628-addmath.tau","title":"[Final] PEP 628 - Addmath.tau","excerpt":"Python Enhancement Proposal 628: 'Addmath.tau'에 대한 한국어 번역입니다.","date":"2025-09-27 00:30:25+0900","lastModifiedAt":"2025-09-27 00:30:25+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/628/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0627-recording_installed_projects","title":"[Final] PEP 627 - Recording installed projects","excerpt":"Python Enhancement Proposal 627: 'Recording installed projects'에 대한 한국어 번역입니다.","date":"2025-09-27 00:30:10+0900","lastModifiedAt":"2025-09-27 00:30:10+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/627/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0626-precise_line_numbers_for_debugging_and_other_tools.","title":"[Final] PEP 626 - Precise line numbers for debugging and other tools.","excerpt":"Python Enhancement Proposal 626: 'Precise line numbers for debugging and other tools.'에 대한 한국어 번역입니다.","date":"2025-09-27 00:29:42+0900","lastModifiedAt":"2025-09-27 00:29:42+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/626/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0608-coordinated_python_release","title":"[Rejected] PEP 608 - Coordinated Python release","excerpt":"Python Enhancement Proposal 608: 'Coordinated Python release'에 대한 한국어 번역입니다.","date":"2025-09-27 00:19:32+0900","lastModifiedAt":"2025-09-27 00:19:32+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/608/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-27-pep-0599-the_manylinux2014_platform_tag","title":"[Superseded] PEP 599 - The manylinux2014 Platform Tag","excerpt":"Python Enhancement Proposal 599: 'The manylinux2014 Platform Tag'에 대한 한국어 번역입니다.","date":"2025-09-27 00:14:20+0900","lastModifiedAt":"2025-09-27 00:14:20+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/599/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0573-module_state_access_from_c_extension_methods","title":"[Final] PEP 573 - Module State Access from C Extension Methods","excerpt":"Python Enhancement Proposal 573: 'Module State Access from C Extension Methods'에 대한 한국어 번역입니다.","date":"2025-09-26 23:59:37+0900","lastModifiedAt":"2025-09-26 23:59:37+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/573/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0572-assignment_expressions","title":"[Final] PEP 572 - Assignment Expressions","excerpt":"Python Enhancement Proposal 572: 'Assignment Expressions'에 대한 한국어 번역입니다.","date":"2025-09-26 23:58:55+0900","lastModifiedAt":"2025-09-26 23:58:55+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/572/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0571-the_manylinux2010_platform_tag","title":"[Superseded] PEP 571 - The manylinux2010 Platform Tag","excerpt":"Python Enhancement Proposal 571: 'The manylinux2010 Platform Tag'에 대한 한국어 번역입니다.","date":"2025-09-26 23:56:56+0900","lastModifiedAt":"2025-09-26 23:56:56+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/571/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0570-python_positional-only_parameters","title":"[Final] PEP 570 - Python Positional-Only Parameters","excerpt":"Python Enhancement Proposal 570: 'Python Positional-Only Parameters'에 대한 한국어 번역입니다.","date":"2025-09-26 23:56:05+0900","lastModifiedAt":"2025-09-26 23:56:05+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/570/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0569-python_3.8_release_schedule","title":"[Final] PEP 569 - Python 3.8 Release Schedule","excerpt":"Python Enhancement Proposal 569: 'Python 3.8 Release Schedule'에 대한 한국어 번역입니다.","date":"2025-09-26 23:51:49+0900","lastModifiedAt":"2025-09-26 23:51:49+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/569/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0568-generator-sensitivity_for_context_variables","title":"[Deferred] PEP 568 - Generator-sensitivity for Context Variables","excerpt":"Python Enhancement Proposal 568: 'Generator-sensitivity for Context Variables'에 대한 한국어 번역입니다.","date":"2025-09-26 23:51:20+0900","lastModifiedAt":"2025-09-26 23:51:20+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/568/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0567-context_variables","title":"[Final] PEP 567 - Context Variables","excerpt":"Python Enhancement Proposal 567: 'Context Variables'에 대한 한국어 번역입니다.","date":"2025-09-26 23:50:36+0900","lastModifiedAt":"2025-09-26 23:50:36+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/567/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0566-metadata_for_python_software_packages_2.1","title":"[Final] PEP 566 - Metadata for Python Software Packages 2.1","excerpt":"Python Enhancement Proposal 566: 'Metadata for Python Software Packages 2.1'에 대한 한국어 번역입니다.","date":"2025-09-26 23:49:52+0900","lastModifiedAt":"2025-09-26 23:49:52+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/566/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0565-show_deprecationwarning_in___main","title":"[Final] PEP 565 - Show DeprecationWarning in __main__","excerpt":"Python Enhancement Proposal 565: 'Show DeprecationWarning in __main__'에 대한 한국어 번역입니다.","date":"2025-09-26 23:49:30+0900","lastModifiedAt":"2025-09-26 23:49:30+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/565/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0564-add_new_time_functions_with_nanosecond_resolution","title":"[Final] PEP 564 - Add new time functions with nanosecond resolution","excerpt":"Python Enhancement Proposal 564: 'Add new time functions with nanosecond resolution'에 대한 한국어 번역입니다.","date":"2025-09-26 23:48:58+0900","lastModifiedAt":"2025-09-26 23:48:58+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/564/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0563-postponed_evaluation_of_annotations","title":"[Superseded] PEP 563 - Postponed Evaluation of Annotations","excerpt":"Python Enhancement Proposal 563: 'Postponed Evaluation of Annotations'에 대한 한국어 번역입니다.","date":"2025-09-26 23:48:31+0900","lastModifiedAt":"2025-09-26 23:48:31+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/563/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0562-module___getattr___and___dir","title":"[Final] PEP 562 - Module __getattr__ and __dir__","excerpt":"Python Enhancement Proposal 562: 'Module __getattr__ and __dir__'에 대한 한국어 번역입니다.","date":"2025-09-26 23:47:20+0900","lastModifiedAt":"2025-09-26 23:47:20+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/562/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0561-distributing_and_packaging_type_information","title":"[Final] PEP 561 - Distributing and Packaging Type Information","excerpt":"Python Enhancement Proposal 561: 'Distributing and Packaging Type Information'에 대한 한국어 번역입니다.","date":"2025-09-26 23:46:31+0900","lastModifiedAt":"2025-09-26 23:46:31+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/561/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0560-core_support_for_typing_module_and_generic_types","title":"[Final] PEP 560 - Core support for typing module and generic types","excerpt":"Python Enhancement Proposal 560: 'Core support for typing module and generic types'에 대한 한국어 번역입니다.","date":"2025-09-26 23:45:50+0900","lastModifiedAt":"2025-09-26 23:45:50+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/560/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0559-built-in_noop","title":"[Rejected] PEP 559 - Built-in noop()","excerpt":"Python Enhancement Proposal 559: 'Built-in noop()'에 대한 한국어 번역입니다.","date":"2025-09-26 23:45:26+0900","lastModifiedAt":"2025-09-26 23:45:26+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/559/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0558-defined_semantics_for_locals","title":"[Withdrawn] PEP 558 - Defined semantics for locals()","excerpt":"Python Enhancement Proposal 558: 'Defined semantics for locals()'에 대한 한국어 번역입니다.","date":"2025-09-26 23:45:10+0900","lastModifiedAt":"2025-09-26 23:45:10+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/558/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0557-data_classes","title":"[Final] PEP 557 - Data Classes","excerpt":"Python Enhancement Proposal 557: 'Data Classes'에 대한 한국어 번역입니다.","date":"2025-09-26 23:42:21+0900","lastModifiedAt":"2025-09-26 23:42:21+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/557/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0556-threaded_garbage_collection","title":"[Deferred] PEP 556 - Threaded garbage collection","excerpt":"Python Enhancement Proposal 556: 'Threaded garbage collection'에 대한 한국어 번역입니다.","date":"2025-09-26 23:41:31+0900","lastModifiedAt":"2025-09-26 23:41:31+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/556/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0555-context-local_variables_contextvars","title":"[Withdrawn] PEP 555 - Context-local variables (contextvars)","excerpt":"Python Enhancement Proposal 555: 'Context-local variables (contextvars)'에 대한 한국어 번역입니다.","date":"2025-09-26 23:40:56+0900","lastModifiedAt":"2025-09-26 23:40:56+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/555/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0554-multiple_interpreters_in_the_stdlib","title":"[Superseded] PEP 554 - Multiple Interpreters in the Stdlib","excerpt":"Python Enhancement Proposal 554: 'Multiple Interpreters in the Stdlib'에 대한 한국어 번역입니다.","date":"2025-09-26 23:40:00+0900","lastModifiedAt":"2025-09-26 23:40:00+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/554/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0553-built-in_breakpoint","title":"[Final] PEP 553 - Built-in breakpoint()","excerpt":"Python Enhancement Proposal 553: 'Built-in breakpoint()'에 대한 한국어 번역입니다.","date":"2025-09-26 23:38:53+0900","lastModifiedAt":"2025-09-26 23:38:53+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/553/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0552-deterministic_pycs","title":"[Final] PEP 552 - Deterministic pycs","excerpt":"Python Enhancement Proposal 552: 'Deterministic pycs'에 대한 한국어 번역입니다.","date":"2025-09-26 23:38:24+0900","lastModifiedAt":"2025-09-26 23:38:24+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/552/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0551-security_transparency_in_the_python_runtime","title":"[Withdrawn] PEP 551 - Security transparency in the Python runtime","excerpt":"Python Enhancement Proposal 551: 'Security transparency in the Python runtime'에 대한 한국어 번역입니다.","date":"2025-09-26 23:37:57+0900","lastModifiedAt":"2025-09-26 23:37:57+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/551/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0550-execution_context","title":"[Withdrawn] PEP 550 - Execution Context","excerpt":"Python Enhancement Proposal 550: 'Execution Context'에 대한 한국어 번역입니다.","date":"2025-09-26 23:36:24+0900","lastModifiedAt":"2025-09-26 23:36:24+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/550/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0549-instance_descriptors","title":"[Rejected] PEP 549 - Instance Descriptors","excerpt":"Python Enhancement Proposal 549: 'Instance Descriptors'에 대한 한국어 번역입니다.","date":"2025-09-26 23:35:20+0900","lastModifiedAt":"2025-09-26 23:35:20+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/549/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0548-more_flexible_loop_control","title":"[Rejected] PEP 548 - More Flexible Loop Control","excerpt":"Python Enhancement Proposal 548: 'More Flexible Loop Control'에 대한 한국어 번역입니다.","date":"2025-09-26 23:35:01+0900","lastModifiedAt":"2025-09-26 23:35:01+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/548/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0547-running_extension_modules_using_the_-m_option","title":"[Deferred] PEP 547 - Running extension modules using the -m option","excerpt":"Python Enhancement Proposal 547: 'Running extension modules using the -m option'에 대한 한국어 번역입니다.","date":"2025-09-26 23:34:23+0900","lastModifiedAt":"2025-09-26 23:34:23+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/547/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0546-backport_ssl.memorybio_and_ssl.sslobject_to_python_2.7","title":"[Rejected] PEP 546 - Backport ssl.MemoryBIO and ssl.SSLObject to Python 2.7","excerpt":"Python Enhancement Proposal 546: 'Backport ssl.MemoryBIO and ssl.SSLObject to Python 2.7'에 대한 한국어 번역입니다.","date":"2025-09-26 23:33:55+0900","lastModifiedAt":"2025-09-26 23:33:55+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/546/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0545-python_documentation_translations","title":"[Active] PEP 545 - Python Documentation Translations","excerpt":"Python Enhancement Proposal 545: 'Python Documentation Translations'에 대한 한국어 번역입니다.","date":"2025-09-26 23:33:31+0900","lastModifiedAt":"2025-09-26 23:33:31+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/545/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0544-protocols_structural_subtyping_static_duck_typing","title":"[Final] PEP 544 - Protocols: Structural subtyping (static duck typing)","excerpt":"Python Enhancement Proposal 544: 'Protocols: Structural subtyping (static duck typing)'에 대한 한국어 번역입니다.","date":"2025-09-26 23:32:41+0900","lastModifiedAt":"2025-09-26 23:32:41+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/544/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0543-a_unified_tls_api_for_python","title":"[Withdrawn] PEP 543 - A Unified TLS API for Python","excerpt":"Python Enhancement Proposal 543: 'A Unified TLS API for Python'에 대한 한국어 번역입니다.","date":"2025-09-26 23:30:50+0900","lastModifiedAt":"2025-09-26 23:30:50+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/543/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0542-dot_notation_assignment_in_function_header","title":"[Rejected] PEP 542 - Dot Notation Assignment In Function Header","excerpt":"Python Enhancement Proposal 542: 'Dot Notation Assignment In Function Header'에 대한 한국어 번역입니다.","date":"2025-09-26 23:30:04+0900","lastModifiedAt":"2025-09-26 23:30:04+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/542/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0541-package_index_name_retention","title":"[Final] PEP 541 - Package Index Name Retention","excerpt":"Python Enhancement Proposal 541: 'Package Index Name Retention'에 대한 한국어 번역입니다.","date":"2025-09-26 23:29:44+0900","lastModifiedAt":"2025-09-26 23:29:44+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/541/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0540-add_a_new_utf-8_mode","title":"[Final] PEP 540 - Add a new UTF-8 Mode","excerpt":"Python Enhancement Proposal 540: 'Add a new UTF-8 Mode'에 대한 한국어 번역입니다.","date":"2025-09-26 23:29:04+0900","lastModifiedAt":"2025-09-26 23:29:04+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/540/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0539-a_new_c-api_for_thread-local_storage_in_cpython","title":"[Final] PEP 539 - A New C-API for Thread-Local Storage in CPython","excerpt":"Python Enhancement Proposal 539: 'A New C-API for Thread-Local Storage in CPython'에 대한 한국어 번역입니다.","date":"2025-09-26 23:28:37+0900","lastModifiedAt":"2025-09-26 23:28:37+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/539/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0538-coercing_the_legacy_c_locale_to_a_utf-8_based_locale","title":"[Final] PEP 538 - Coercing the legacy C locale to a UTF-8 based locale","excerpt":"Python Enhancement Proposal 538: 'Coercing the legacy C locale to a UTF-8 based locale'에 대한 한국어 번역입니다.","date":"2025-09-26 23:28:03+0900","lastModifiedAt":"2025-09-26 23:28:03+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/538/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0537-python_3.7_release_schedule","title":"[Final] PEP 537 - Python 3.7 Release Schedule","excerpt":"Python Enhancement Proposal 537: 'Python 3.7 Release Schedule'에 대한 한국어 번역입니다.","date":"2025-09-26 23:27:21+0900","lastModifiedAt":"2025-09-26 23:27:21+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/537/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0536-final_grammar_for_literal_string_interpolation","title":"[Withdrawn] PEP 536 - Final Grammar for Literal String Interpolation","excerpt":"Python Enhancement Proposal 536: 'Final Grammar for Literal String Interpolation'에 대한 한국어 번역입니다.","date":"2025-09-26 23:26:52+0900","lastModifiedAt":"2025-09-26 23:26:52+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/536/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0535-rich_comparison_chaining","title":"[Deferred] PEP 535 - Rich comparison chaining","excerpt":"Python Enhancement Proposal 535: 'Rich comparison chaining'에 대한 한국어 번역입니다.","date":"2025-09-26 23:26:10+0900","lastModifiedAt":"2025-09-26 23:26:10+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/535/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0534-improved_errors_for_missing_standard_library_modules","title":"[Deferred] PEP 534 - Improved Errors for Missing Standard Library Modules","excerpt":"Python Enhancement Proposal 534: 'Improved Errors for Missing Standard Library Modules'에 대한 한국어 번역입니다.","date":"2025-09-26 23:25:45+0900","lastModifiedAt":"2025-09-26 23:25:45+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/534/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0533-deterministic_cleanup_for_iterators","title":"[Deferred] PEP 533 - Deterministic cleanup for iterators","excerpt":"Python Enhancement Proposal 533: 'Deterministic cleanup for iterators'에 대한 한국어 번역입니다.","date":"2025-09-26 23:25:05+0900","lastModifiedAt":"2025-09-26 23:25:05+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/533/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0532-a_circuit_breaking_protocol_and_binary_operators","title":"[Deferred] PEP 532 - A circuit breaking protocol and binary operators","excerpt":"Python Enhancement Proposal 532: 'A circuit breaking protocol and binary operators'에 대한 한국어 번역입니다.","date":"2025-09-26 23:23:40+0900","lastModifiedAt":"2025-09-26 23:23:40+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/532/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0531-existence_checking_operators","title":"[Withdrawn] PEP 531 - Existence checking operators","excerpt":"Python Enhancement Proposal 531: 'Existence checking operators'에 대한 한국어 번역입니다.","date":"2025-09-26 23:22:20+0900","lastModifiedAt":"2025-09-26 23:22:20+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/531/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0530-asynchronous_comprehensions","title":"[Final] PEP 530 - Asynchronous Comprehensions","excerpt":"Python Enhancement Proposal 530: 'Asynchronous Comprehensions'에 대한 한국어 번역입니다.","date":"2025-09-26 23:21:12+0900","lastModifiedAt":"2025-09-26 23:21:12+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/530/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0529-change_windows_filesystem_encoding_to_utf-8","title":"[Final] PEP 529 - Change Windows filesystem encoding to UTF-8","excerpt":"Python Enhancement Proposal 529: 'Change Windows filesystem encoding to UTF-8'에 대한 한국어 번역입니다.","date":"2025-09-26 23:20:53+0900","lastModifiedAt":"2025-09-26 23:20:53+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/529/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0528-change_windows_console_encoding_to_utf-8","title":"[Final] PEP 528 - Change Windows console encoding to UTF-8","excerpt":"Python Enhancement Proposal 528: 'Change Windows console encoding to UTF-8'에 대한 한국어 번역입니다.","date":"2025-09-26 23:19:55+0900","lastModifiedAt":"2025-09-26 23:19:55+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/528/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0527-removing_underused_file_typesextensions_on_pypi","title":"[Final] PEP 527 - Removing Un(der)used file types/extensions on PyPI","excerpt":"Python Enhancement Proposal 527: 'Removing Un(der)used file types/extensions on PyPI'에 대한 한국어 번역입니다.","date":"2025-09-26 23:19:32+0900","lastModifiedAt":"2025-09-26 23:19:32+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/527/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0526-syntax_for_variable_annotations","title":"[Final] PEP 526 - Syntax for Variable Annotations","excerpt":"Python Enhancement Proposal 526: 'Syntax for Variable Annotations'에 대한 한국어 번역입니다.","date":"2025-09-26 23:19:02+0900","lastModifiedAt":"2025-09-26 23:19:02+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/526/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0525-asynchronous_generators","title":"[Final] PEP 525 - Asynchronous Generators","excerpt":"Python Enhancement Proposal 525: 'Asynchronous Generators'에 대한 한국어 번역입니다.","date":"2025-09-26 23:17:46+0900","lastModifiedAt":"2025-09-26 23:17:46+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/525/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0524-make_os.urandom_blocking_on_linux","title":"[Final] PEP 524 - Make os.urandom() blocking on Linux","excerpt":"Python Enhancement Proposal 524: 'Make os.urandom() blocking on Linux'에 대한 한국어 번역입니다.","date":"2025-09-26 23:16:54+0900","lastModifiedAt":"2025-09-26 23:16:54+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/524/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0523-adding_a_frame_evaluation_api_to_cpython","title":"[Final] PEP 523 - Adding a frame evaluation API to CPython","excerpt":"Python Enhancement Proposal 523: 'Adding a frame evaluation API to CPython'에 대한 한국어 번역입니다.","date":"2025-09-26 23:16:26+0900","lastModifiedAt":"2025-09-26 23:16:26+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/523/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0522-allow_blockingioerror_in_security_sensitive_apis","title":"[Rejected] PEP 522 - Allow BlockingIOError in security sensitive APIs","excerpt":"Python Enhancement Proposal 522: 'Allow BlockingIOError in security sensitive APIs'에 대한 한국어 번역입니다.","date":"2025-09-26 23:15:31+0900","lastModifiedAt":"2025-09-26 23:15:31+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/522/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0521-managing_global_context_via_with_blocks_in_generators_and_coroutines","title":"[Withdrawn] PEP 521 - Managing global context via ‘with’ blocks in generators and coroutines","excerpt":"Python Enhancement Proposal 521: 'Managing global context via ‘with’ blocks in generators and coroutines'에 대한 한국어 번역입니다.","date":"2025-09-26 23:14:33+0900","lastModifiedAt":"2025-09-26 23:14:33+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/521/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0520-preserving_class_attribute_definition_order","title":"[Final] PEP 520 - Preserving Class Attribute Definition Order","excerpt":"Python Enhancement Proposal 520: 'Preserving Class Attribute Definition Order'에 대한 한국어 번역입니다.","date":"2025-09-26 23:13:52+0900","lastModifiedAt":"2025-09-26 23:13:52+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/520/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0519-adding_a_file_system_path_protocol","title":"[Final] PEP 519 - Adding a file system path protocol","excerpt":"Python Enhancement Proposal 519: 'Adding a file system path protocol'에 대한 한국어 번역입니다.","date":"2025-09-26 23:13:13+0900","lastModifiedAt":"2025-09-26 23:13:13+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/519/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0518-specifying_minimum_build_system_requirements_for_python_projects","title":"[Final] PEP 518 - Specifying Minimum Build System Requirements for Python Projects","excerpt":"Python Enhancement Proposal 518: 'Specifying Minimum Build System Requirements for Python Projects'에 대한 한국어 번역입니다.","date":"2025-09-26 23:12:43+0900","lastModifiedAt":"2025-09-26 23:12:43+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/518/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0517-a_build-system_independent_format_for_source_trees","title":"[Final] PEP 517 - A build-system independent format for source trees","excerpt":"Python Enhancement Proposal 517: 'A build-system independent format for source trees'에 대한 한국어 번역입니다.","date":"2025-09-26 23:11:54+0900","lastModifiedAt":"2025-09-26 23:11:54+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/517/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0516-build_system_abstraction_for_pipconda_etc","title":"[Rejected] PEP 516 - Build system abstraction for pip/conda etc","excerpt":"Python Enhancement Proposal 516: 'Build system abstraction for pip/conda etc'에 대한 한국어 번역입니다.","date":"2025-09-26 23:11:03+0900","lastModifiedAt":"2025-09-26 23:11:03+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/516/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0515-underscores_in_numeric_literals","title":"[Final] PEP 515 - Underscores in Numeric Literals","excerpt":"Python Enhancement Proposal 515: 'Underscores in Numeric Literals'에 대한 한국어 번역입니다.","date":"2025-09-26 23:10:13+0900","lastModifiedAt":"2025-09-26 23:10:13+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/515/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0514-python_registration_in_the_windows_registry","title":"[Active] PEP 514 - Python registration in the Windows registry","excerpt":"Python Enhancement Proposal 514: 'Python registration in the Windows registry'에 대한 한국어 번역입니다.","date":"2025-09-26 23:09:52+0900","lastModifiedAt":"2025-09-26 23:09:52+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/514/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0513-a_platform_tag_for_portable_linux_built_distributions","title":"[Superseded] PEP 513 - A Platform Tag for Portable Linux Built Distributions","excerpt":"Python Enhancement Proposal 513: 'A Platform Tag for Portable Linux Built Distributions'에 대한 한국어 번역입니다.","date":"2025-09-26 23:03:09+0900","lastModifiedAt":"2025-09-26 23:03:09+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/513/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0512-migrating_from_hg.python.org_to_github","title":"[Final] PEP 512 - Migrating from hg.python.org to GitHub","excerpt":"Python Enhancement Proposal 512: 'Migrating from hg.python.org to GitHub'에 대한 한국어 번역입니다.","date":"2025-09-26 22:57:36+0900","lastModifiedAt":"2025-09-26 22:57:36+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/512/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0511-api_for_code_transformers","title":"[Rejected] PEP 511 - API for code transformers","excerpt":"Python Enhancement Proposal 511: 'API for code transformers'에 대한 한국어 번역입니다.","date":"2025-09-26 22:56:47+0900","lastModifiedAt":"2025-09-26 22:56:47+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/511/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0510-specialize_functions_with_guards","title":"[Rejected] PEP 510 - Specialize functions with guards","excerpt":"Python Enhancement Proposal 510: 'Specialize functions with guards'에 대한 한국어 번역입니다.","date":"2025-09-26 22:55:51+0900","lastModifiedAt":"2025-09-26 22:55:51+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/510/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0509-add_a_private_version_to_dict","title":"[Superseded] PEP 509 - Add a private version to dict","excerpt":"Python Enhancement Proposal 509: 'Add a private version to dict'에 대한 한국어 번역입니다.","date":"2025-09-26 22:55:06+0900","lastModifiedAt":"2025-09-26 22:55:06+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/509/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0508-dependency_specification_for_python_software_packages","title":"[Final] PEP 508 - Dependency specification for Python Software Packages","excerpt":"Python Enhancement Proposal 508: 'Dependency specification for Python Software Packages'에 대한 한국어 번역입니다.","date":"2025-09-26 22:54:08+0900","lastModifiedAt":"2025-09-26 22:54:08+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/508/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0507-migrate_cpython_to_git_and_gitlab","title":"[Rejected] PEP 507 - Migrate CPython to Git and GitLab","excerpt":"Python Enhancement Proposal 507: 'Migrate CPython to Git and GitLab'에 대한 한국어 번역입니다.","date":"2025-09-26 22:53:39+0900","lastModifiedAt":"2025-09-26 22:53:39+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/507/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0506-adding_a_secrets_module_to_the_standard_library","title":"[Final] PEP 506 - Adding A Secrets Module To The Standard Library","excerpt":"Python Enhancement Proposal 506: 'Adding A Secrets Module To The Standard Library'에 대한 한국어 번역입니다.","date":"2025-09-26 22:53:00+0900","lastModifiedAt":"2025-09-26 22:53:00+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/506/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0505-none-aware_operators","title":"[Deferred] PEP 505 - None-aware operators","excerpt":"Python Enhancement Proposal 505: 'None-aware operators'에 대한 한국어 번역입니다.","date":"2025-09-26 22:52:11+0900","lastModifiedAt":"2025-09-26 22:52:11+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/505/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0504-using_the_system_rng_by_default","title":"[Withdrawn] PEP 504 - Using the System RNG by default","excerpt":"Python Enhancement Proposal 504: 'Using the System RNG by default'에 대한 한국어 번역입니다.","date":"2025-09-26 22:47:22+0900","lastModifiedAt":"2025-09-26 22:47:22+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/504/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0503-simple_repository_api","title":"[Final] PEP 503 - Simple Repository API","excerpt":"Python Enhancement Proposal 503: 'Simple Repository API'에 대한 한국어 번역입니다.","date":"2025-09-26 22:45:48+0900","lastModifiedAt":"2025-09-26 22:45:48+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/503/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0502-string_interpolation_-_extended_discussion","title":"[Rejected] PEP 502 - String Interpolation - Extended Discussion","excerpt":"Python Enhancement Proposal 502: 'String Interpolation - Extended Discussion'에 대한 한국어 번역입니다.","date":"2025-09-26 22:45:25+0900","lastModifiedAt":"2025-09-26 22:45:25+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/502/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0501-general_purpose_template_literal_strings","title":"[Withdrawn] PEP 501 - General purpose template literal strings","excerpt":"Python Enhancement Proposal 501: 'General purpose template literal strings'에 대한 한국어 번역입니다.","date":"2025-09-26 22:44:34+0900","lastModifiedAt":"2025-09-26 22:44:34+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/501/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0500-a_protocol_for_delegating_datetime_methods_to_their_tzinfo_implementations","title":"[Rejected] PEP 500 - A protocol for delegating datetime methods to their tzinfo implementations","excerpt":"Python Enhancement Proposal 500: 'A protocol for delegating datetime methods to their tzinfo implementations'에 대한 한국어 번역입니다.","date":"2025-09-26 22:43:18+0900","lastModifiedAt":"2025-09-26 22:43:18+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/500/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0499-python-mfooshould_also_bindfooinsys.modules","title":"[Deferred] PEP 499 - python-mfooshould also bind'foo'insys.modules","excerpt":"Python Enhancement Proposal 499: 'python-mfooshould also bind'foo'insys.modules'에 대한 한국어 번역입니다.","date":"2025-09-26 22:42:49+0900","lastModifiedAt":"2025-09-26 22:42:49+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/499/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0498-literal_string_interpolation","title":"[Final] PEP 498 - Literal String Interpolation","excerpt":"Python Enhancement Proposal 498: 'Literal String Interpolation'에 대한 한국어 번역입니다.","date":"2025-09-26 22:42:20+0900","lastModifiedAt":"2025-09-26 22:42:20+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/498/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0497-a_standard_mechanism_for_backward_compatibility","title":"[Rejected] PEP 497 - A standard mechanism for backward compatibility","excerpt":"Python Enhancement Proposal 497: 'A standard mechanism for backward compatibility'에 대한 한국어 번역입니다.","date":"2025-09-26 22:41:11+0900","lastModifiedAt":"2025-09-26 22:41:11+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/497/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0496-environment_markers","title":"[Rejected] PEP 496 - Environment Markers","excerpt":"Python Enhancement Proposal 496: 'Environment Markers'에 대한 한국어 번역입니다.","date":"2025-09-26 22:40:36+0900","lastModifiedAt":"2025-09-26 22:40:36+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/496/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0495-local_time_disambiguation","title":"[Final] PEP 495 - Local Time Disambiguation","excerpt":"Python Enhancement Proposal 495: 'Local Time Disambiguation'에 대한 한국어 번역입니다.","date":"2025-09-26 22:40:14+0900","lastModifiedAt":"2025-09-26 22:40:14+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/495/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0494-python_3.6_release_schedule","title":"[Final] PEP 494 - Python 3.6 Release Schedule","excerpt":"Python Enhancement Proposal 494: 'Python 3.6 Release Schedule'에 대한 한국어 번역입니다.","date":"2025-09-26 22:39:23+0900","lastModifiedAt":"2025-09-26 22:39:23+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/494/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0493-https_verification_migration_tools_for_python_2.7","title":"[Final] PEP 493 - HTTPS verification migration tools for Python 2.7","excerpt":"Python Enhancement Proposal 493: 'HTTPS verification migration tools for Python 2.7'에 대한 한국어 번역입니다.","date":"2025-09-26 22:38:56+0900","lastModifiedAt":"2025-09-26 22:38:56+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/493/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0492-coroutines_with_async_and_await_syntax","title":"[Final] PEP 492 - Coroutines with async and await syntax","excerpt":"Python Enhancement Proposal 492: 'Coroutines with async and await syntax'에 대한 한국어 번역입니다.","date":"2025-09-26 22:37:54+0900","lastModifiedAt":"2025-09-26 22:37:54+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/492/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0491-the_wheel_binary_package_format_1.9","title":"[Deferred] PEP 491 - The Wheel Binary Package Format 1.9","excerpt":"Python Enhancement Proposal 491: 'The Wheel Binary Package Format 1.9'에 대한 한국어 번역입니다.","date":"2025-09-26 22:36:44+0900","lastModifiedAt":"2025-09-26 22:36:44+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/491/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0490-chain_exceptions_at_c_level","title":"[Rejected] PEP 490 - Chain exceptions at C level","excerpt":"Python Enhancement Proposal 490: 'Chain exceptions at C level'에 대한 한국어 번역입니다.","date":"2025-09-26 22:35:41+0900","lastModifiedAt":"2025-09-26 22:35:41+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/490/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0489-multi-phase_extension_module_initialization","title":"[Final] PEP 489 - Multi-phase extension module initialization","excerpt":"Python Enhancement Proposal 489: 'Multi-phase extension module initialization'에 대한 한국어 번역입니다.","date":"2025-09-26 22:35:12+0900","lastModifiedAt":"2025-09-26 22:35:12+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/489/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0488-elimination_of_pyo_files","title":"[Final] PEP 488 - Elimination of PYO files","excerpt":"Python Enhancement Proposal 488: 'Elimination of PYO files'에 대한 한국어 번역입니다.","date":"2025-09-26 22:34:01+0900","lastModifiedAt":"2025-09-26 22:34:01+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/488/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0487-simpler_customisation_of_class_creation","title":"[Final] PEP 487 - Simpler customisation of class creation","excerpt":"Python Enhancement Proposal 487: 'Simpler customisation of class creation'에 대한 한국어 번역입니다.","date":"2025-09-26 22:33:21+0900","lastModifiedAt":"2025-09-26 22:33:21+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/487/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0486-make_the_python_launcher_aware_of_virtual_environments","title":"[Final] PEP 486 - Make the Python Launcher aware of virtual environments","excerpt":"Python Enhancement Proposal 486: 'Make the Python Launcher aware of virtual environments'에 대한 한국어 번역입니다.","date":"2025-09-26 22:33:02+0900","lastModifiedAt":"2025-09-26 22:33:02+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/486/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0485-a_function_for_testing_approximate_equality","title":"[Final] PEP 485 - A Function for testing approximate equality","excerpt":"Python Enhancement Proposal 485: 'A Function for testing approximate equality'에 대한 한국어 번역입니다.","date":"2025-09-26 22:32:41+0900","lastModifiedAt":"2025-09-26 22:32:41+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/485/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0484-type_hints","title":"[Final] PEP 484 - Type Hints","excerpt":"Python Enhancement Proposal 484: 'Type Hints'에 대한 한국어 번역입니다.","date":"2025-09-26 22:32:07+0900","lastModifiedAt":"2025-09-26 22:32:07+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/484/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0483-the_theory_of_type_hints","title":"[Final] PEP 483 - The Theory of Type Hints","excerpt":"Python Enhancement Proposal 483: 'The Theory of Type Hints'에 대한 한국어 번역입니다.","date":"2025-09-26 22:28:39+0900","lastModifiedAt":"2025-09-26 22:28:39+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/483/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0482-literature_overview_for_type_hints","title":"[Final] PEP 482 - Literature Overview for Type Hints","excerpt":"Python Enhancement Proposal 482: 'Literature Overview for Type Hints'에 대한 한국어 번역입니다.","date":"2025-09-26 22:27:40+0900","lastModifiedAt":"2025-09-26 22:27:40+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/482/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0481-migrate_cpython_to_git_github_and_phabricator","title":"[Withdrawn] PEP 481 - Migrate CPython to Git, Github, and Phabricator","excerpt":"Python Enhancement Proposal 481: 'Migrate CPython to Git, Github, and Phabricator'에 대한 한국어 번역입니다.","date":"2025-09-26 22:27:20+0900","lastModifiedAt":"2025-09-26 22:27:20+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/481/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0480-surviving_a_compromise_of_pypi_end-to-end_signing_of_packages","title":"[Draft] PEP 480 - Surviving a Compromise of PyPI: End-to-end signing of packages","excerpt":"Python Enhancement Proposal 480: 'Surviving a Compromise of PyPI: End-to-end signing of packages'에 대한 한국어 번역입니다.","date":"2025-09-26 22:26:39+0900","lastModifiedAt":"2025-09-26 22:26:39+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/480/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0479-change_stopiteration_handling_inside_generators","title":"[Final] PEP 479 - Change StopIteration handling inside generators","excerpt":"Python Enhancement Proposal 479: 'Change StopIteration handling inside generators'에 대한 한국어 번역입니다.","date":"2025-09-26 22:23:28+0900","lastModifiedAt":"2025-09-26 22:23:28+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/479/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0478-python_3.5_release_schedule","title":"[Final] PEP 478 - Python 3.5 Release Schedule","excerpt":"Python Enhancement Proposal 478: 'Python 3.5 Release Schedule'에 대한 한국어 번역입니다.","date":"2025-09-26 22:22:47+0900","lastModifiedAt":"2025-09-26 22:22:47+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/478/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0477-backport_ensurepip_pep_453_to_python_2.7","title":"[Final] PEP 477 - Backport ensurepip (PEP 453) to Python 2.7","excerpt":"Python Enhancement Proposal 477: 'Backport ensurepip (PEP 453) to Python 2.7'에 대한 한국어 번역입니다.","date":"2025-09-26 22:22:24+0900","lastModifiedAt":"2025-09-26 22:22:24+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/477/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0476-enabling_certificate_verification_by_default_for_stdlib_http_clients","title":"[Final] PEP 476 - Enabling certificate verification by default for stdlib http clients","excerpt":"Python Enhancement Proposal 476: 'Enabling certificate verification by default for stdlib http clients'에 대한 한국어 번역입니다.","date":"2025-09-26 22:22:04+0900","lastModifiedAt":"2025-09-26 22:22:04+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/476/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0475-retry_system_calls_failing_with_eintr","title":"[Final] PEP 475 - Retry system calls failing with EINTR","excerpt":"Python Enhancement Proposal 475: 'Retry system calls failing with EINTR'에 대한 한국어 번역입니다.","date":"2025-09-26 22:21:40+0900","lastModifiedAt":"2025-09-26 22:21:40+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/475/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0474-creating_forge.python.org","title":"[Withdrawn] PEP 474 - Creating forge.python.org","excerpt":"Python Enhancement Proposal 474: 'Creating forge.python.org'에 대한 한국어 번역입니다.","date":"2025-09-26 22:21:06+0900","lastModifiedAt":"2025-09-26 22:21:06+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/474/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0473-adding_structured_data_to_built-in_exceptions","title":"[Rejected] PEP 473 - Adding structured data to built-in exceptions","excerpt":"Python Enhancement Proposal 473: 'Adding structured data to built-in exceptions'에 대한 한국어 번역입니다.","date":"2025-09-26 22:19:47+0900","lastModifiedAt":"2025-09-26 22:19:47+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/473/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0472-support_for_indexing_with_keyword_arguments","title":"[Rejected] PEP 472 - Support for indexing with keyword arguments","excerpt":"Python Enhancement Proposal 472: 'Support for indexing with keyword arguments'에 대한 한국어 번역입니다.","date":"2025-09-26 22:19:17+0900","lastModifiedAt":"2025-09-26 22:19:17+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/472/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0471-os.scandir_function_a_better_and_faster_directory_iterator","title":"[Final] PEP 471 - os.scandir() function – a better and faster directory iterator","excerpt":"Python Enhancement Proposal 471: 'os.scandir() function – a better and faster directory iterator'에 대한 한국어 번역입니다.","date":"2025-09-26 22:18:05+0900","lastModifiedAt":"2025-09-26 22:18:05+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/471/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0470-removing_external_hosting_support_on_pypi","title":"[Final] PEP 470 - Removing External Hosting Support on PyPI","excerpt":"Python Enhancement Proposal 470: 'Removing External Hosting Support on PyPI'에 대한 한국어 번역입니다.","date":"2025-09-26 22:17:18+0900","lastModifiedAt":"2025-09-26 22:17:18+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/470/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0469-migration_of_dict_iteration_code_to_python_3","title":"[Withdrawn] PEP 469 - Migration of dict iteration code to Python 3","excerpt":"Python Enhancement Proposal 469: 'Migration of dict iteration code to Python 3'에 대한 한국어 번역입니다.","date":"2025-09-26 22:15:48+0900","lastModifiedAt":"2025-09-26 22:15:48+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/469/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0468-preserving_the_order_of_kwargs_in_a_function.","title":"[Final] PEP 468 - Preserving the order of **kwargs in a function.","excerpt":"Python Enhancement Proposal 468: 'Preserving the order of **kwargs in a function.'에 대한 한국어 번역입니다.","date":"2025-09-26 22:15:02+0900","lastModifiedAt":"2025-09-26 22:15:02+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/468/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0467-minor_api_improvements_for_binary_sequences","title":"[Draft] PEP 467 - Minor API improvements for binary sequences","excerpt":"Python Enhancement Proposal 467: 'Minor API improvements for binary sequences'에 대한 한국어 번역입니다.","date":"2025-09-26 22:14:25+0900","lastModifiedAt":"2025-09-26 22:14:25+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/467/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0466-network_security_enhancements_for_python_2.7.x","title":"[Final] PEP 466 - Network Security Enhancements for Python 2.7.x","excerpt":"Python Enhancement Proposal 466: 'Network Security Enhancements for Python 2.7.x'에 대한 한국어 번역입니다.","date":"2025-09-26 22:13:59+0900","lastModifiedAt":"2025-09-26 22:13:59+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/466/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0465-a_dedicated_infix_operator_for_matrix_multiplication","title":"[Final] PEP 465 - A dedicated infix operator for matrix multiplication","excerpt":"Python Enhancement Proposal 465: 'A dedicated infix operator for matrix multiplication'에 대한 한국어 번역입니다.","date":"2025-09-26 22:12:46+0900","lastModifiedAt":"2025-09-26 22:12:46+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/465/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0464-removal_of_the_pypi_mirror_authenticity_api","title":"[Final] PEP 464 - Removal of the PyPI Mirror Authenticity API","excerpt":"Python Enhancement Proposal 464: 'Removal of the PyPI Mirror Authenticity API'에 대한 한국어 번역입니다.","date":"2025-09-26 22:11:47+0900","lastModifiedAt":"2025-09-26 22:11:47+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/464/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0463-exception-catching_expressions","title":"[Rejected] PEP 463 - Exception-catching expressions","excerpt":"Python Enhancement Proposal 463: 'Exception-catching expressions'에 대한 한국어 번역입니다.","date":"2025-09-26 22:11:32+0900","lastModifiedAt":"2025-09-26 22:11:32+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/463/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0462-core_development_workflow_automation_for_cpython","title":"[Withdrawn] PEP 462 - Core development workflow automation for CPython","excerpt":"Python Enhancement Proposal 462: 'Core development workflow automation for CPython'에 대한 한국어 번역입니다.","date":"2025-09-26 22:10:21+0900","lastModifiedAt":"2025-09-26 22:10:21+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/462/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0461-adding_formatting_to_bytes_and_bytearray","title":"[Final] PEP 461 - Adding % formatting to bytes and bytearray","excerpt":"Python Enhancement Proposal 461: 'Adding % formatting to bytes and bytearray'에 대한 한국어 번역입니다.","date":"2025-09-26 22:09:29+0900","lastModifiedAt":"2025-09-26 22:09:29+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/461/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0460-add_binary_interpolation_and_formatting","title":"[Withdrawn] PEP 460 - Add binary interpolation and formatting","excerpt":"Python Enhancement Proposal 460: 'Add binary interpolation and formatting'에 대한 한국어 번역입니다.","date":"2025-09-26 22:08:41+0900","lastModifiedAt":"2025-09-26 22:08:41+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/460/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0459-standard_metadata_extensions_for_python_software_packages","title":"[Withdrawn] PEP 459 - Standard Metadata Extensions for Python Software Packages","excerpt":"Python Enhancement Proposal 459: 'Standard Metadata Extensions for Python Software Packages'에 대한 한국어 번역입니다.","date":"2025-09-26 22:08:18+0900","lastModifiedAt":"2025-09-26 22:08:18+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/459/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0458-secure_pypi_downloads_with_signed_repository_metadata","title":"[Accepted] PEP 458 - Secure PyPI downloads with signed repository metadata","excerpt":"Python Enhancement Proposal 458: 'Secure PyPI downloads with signed repository metadata'에 대한 한국어 번역입니다.","date":"2025-09-26 22:07:13+0900","lastModifiedAt":"2025-09-26 22:07:13+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/458/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0457-notation_for_positional-only_parameters","title":"[Final] PEP 457 - Notation For Positional-Only Parameters","excerpt":"Python Enhancement Proposal 457: 'Notation For Positional-Only Parameters'에 대한 한국어 번역입니다.","date":"2025-09-26 22:06:22+0900","lastModifiedAt":"2025-09-26 22:06:22+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/457/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0456-secure_and_interchangeable_hash_algorithm","title":"[Final] PEP 456 - Secure and interchangeable hash algorithm","excerpt":"Python Enhancement Proposal 456: 'Secure and interchangeable hash algorithm'에 대한 한국어 번역입니다.","date":"2025-09-26 22:05:49+0900","lastModifiedAt":"2025-09-26 22:05:49+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/456/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0455-adding_a_key-transforming_dictionary_to_collections","title":"[Rejected] PEP 455 - Adding a key-transforming dictionary to collections","excerpt":"Python Enhancement Proposal 455: 'Adding a key-transforming dictionary to collections'에 대한 한국어 번역입니다.","date":"2025-09-26 22:05:06+0900","lastModifiedAt":"2025-09-26 22:05:06+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/455/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0454-add_a_new_tracemalloc_module_to_trace_python_memory_allocations","title":"[Final] PEP 454 - Add a new tracemalloc module to trace Python memory allocations","excerpt":"Python Enhancement Proposal 454: 'Add a new tracemalloc module to trace Python memory allocations'에 대한 한국어 번역입니다.","date":"2025-09-26 22:04:39+0900","lastModifiedAt":"2025-09-26 22:04:39+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/454/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0453-explicit_bootstrapping_of_pip_in_python_installations","title":"[Final] PEP 453 - Explicit bootstrapping of pip in Python installations","excerpt":"Python Enhancement Proposal 453: 'Explicit bootstrapping of pip in Python installations'에 대한 한국어 번역입니다.","date":"2025-09-26 22:03:55+0900","lastModifiedAt":"2025-09-26 22:03:55+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/453/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0452-api_for_cryptographic_hash_functions_v2.0","title":"[Final] PEP 452 - API for Cryptographic Hash Functions v2.0","excerpt":"Python Enhancement Proposal 452: 'API for Cryptographic Hash Functions v2.0'에 대한 한국어 번역입니다.","date":"2025-09-26 22:03:16+0900","lastModifiedAt":"2025-09-26 22:03:16+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/452/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0451-a_modulespec_type_for_the_import_system","title":"[Final] PEP 451 - A ModuleSpec Type for the Import System","excerpt":"Python Enhancement Proposal 451: 'A ModuleSpec Type for the Import System'에 대한 한국어 번역입니다.","date":"2025-09-26 22:02:47+0900","lastModifiedAt":"2025-09-26 22:02:47+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/451/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0450-adding_a_statistics_module_to_the_standard_library","title":"[Final] PEP 450 - Adding A Statistics Module To The Standard Library","excerpt":"Python Enhancement Proposal 450: 'Adding A Statistics Module To The Standard Library'에 대한 한국어 번역입니다.","date":"2025-09-26 22:00:57+0900","lastModifiedAt":"2025-09-26 22:00:57+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/450/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0449-removal_of_the_pypi_mirror_auto_discovery_and_naming_scheme","title":"[Final] PEP 449 - Removal of the PyPI Mirror Auto Discovery and Naming Scheme","excerpt":"Python Enhancement Proposal 449: 'Removal of the PyPI Mirror Auto Discovery and Naming Scheme'에 대한 한국어 번역입니다.","date":"2025-09-26 22:00:20+0900","lastModifiedAt":"2025-09-26 22:00:20+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/449/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0448-additional_unpacking_generalizations","title":"[Final] PEP 448 - Additional Unpacking Generalizations","excerpt":"Python Enhancement Proposal 448: 'Additional Unpacking Generalizations'에 대한 한국어 번역입니다.","date":"2025-09-26 22:00:00+0900","lastModifiedAt":"2025-09-26 22:00:00+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/448/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0447-add___getdescriptor___method_to_metaclass","title":"[Deferred] PEP 447 - Add __getdescriptor__ method to metaclass","excerpt":"Python Enhancement Proposal 447: 'Add __getdescriptor__ method to metaclass'에 대한 한국어 번역입니다.","date":"2025-09-26 21:59:30+0900","lastModifiedAt":"2025-09-26 21:59:30+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/447/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0446-make_newly_created_file_descriptors_non-inheritable","title":"[Final] PEP 446 - Make newly created file descriptors non-inheritable","excerpt":"Python Enhancement Proposal 446: 'Make newly created file descriptors non-inheritable'에 대한 한국어 번역입니다.","date":"2025-09-26 21:58:51+0900","lastModifiedAt":"2025-09-26 21:58:51+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/446/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0445-add_new_apis_to_customize_python_memory_allocators","title":"[Final] PEP 445 - Add new APIs to customize Python memory allocators","excerpt":"Python Enhancement Proposal 445: 'Add new APIs to customize Python memory allocators'에 대한 한국어 번역입니다.","date":"2025-09-26 21:58:25+0900","lastModifiedAt":"2025-09-26 21:58:25+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/445/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0444-python_web3_interface","title":"[Deferred] PEP 444 - Python Web3 Interface","excerpt":"Python Enhancement Proposal 444: 'Python Web3 Interface'에 대한 한국어 번역입니다.","date":"2025-09-26 21:57:54+0900","lastModifiedAt":"2025-09-26 21:57:54+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/444/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0443-single-dispatch_generic_functions","title":"[Final] PEP 443 - Single-dispatch generic functions","excerpt":"Python Enhancement Proposal 443: 'Single-dispatch generic functions'에 대한 한국어 번역입니다.","date":"2025-09-26 21:55:16+0900","lastModifiedAt":"2025-09-26 21:55:16+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/443/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0442-safe_object_finalization","title":"[Final] PEP 442 - Safe object finalization","excerpt":"Python Enhancement Proposal 442: 'Safe object finalization'에 대한 한국어 번역입니다.","date":"2025-09-26 21:54:42+0900","lastModifiedAt":"2025-09-26 21:54:42+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/442/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0441-improving_python_zip_application_support","title":"[Final] PEP 441 - Improving Python ZIP Application Support","excerpt":"Python Enhancement Proposal 441: 'Improving Python ZIP Application Support'에 대한 한국어 번역입니다.","date":"2025-09-26 21:54:04+0900","lastModifiedAt":"2025-09-26 21:54:04+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/441/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0440-version_identification_and_dependency_specification","title":"[Final] PEP 440 - Version Identification and Dependency Specification","excerpt":"Python Enhancement Proposal 440: 'Version Identification and Dependency Specification'에 대한 한국어 번역입니다.","date":"2025-09-26 21:53:38+0900","lastModifiedAt":"2025-09-26 21:53:38+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/440/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0439-inclusion_of_implicit_pip_bootstrap_in_python_installation","title":"[Rejected] PEP 439 - Inclusion of implicit pip bootstrap in Python installation","excerpt":"Python Enhancement Proposal 439: 'Inclusion of implicit pip bootstrap in Python installation'에 대한 한국어 번역입니다.","date":"2025-09-26 21:52:55+0900","lastModifiedAt":"2025-09-26 21:52:55+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/439/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0438-transitioning_to_release-file_hosting_on_pypi","title":"[Superseded] PEP 438 - Transitioning to release-file hosting on PyPI","excerpt":"Python Enhancement Proposal 438: 'Transitioning to release-file hosting on PyPI'에 대한 한국어 번역입니다.","date":"2025-09-26 21:52:24+0900","lastModifiedAt":"2025-09-26 21:52:24+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/438/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0437-a_dsl_for_specifying_signatures_annotations_and_argument_converters","title":"[Rejected] PEP 437 - A DSL for specifying signatures, annotations and argument converters","excerpt":"Python Enhancement Proposal 437: 'A DSL for specifying signatures, annotations and argument converters'에 대한 한국어 번역입니다.","date":"2025-09-26 21:51:38+0900","lastModifiedAt":"2025-09-26 21:51:38+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/437/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0436-the_argument_clinic_dsl","title":"[Final] PEP 436 - The Argument Clinic DSL","excerpt":"Python Enhancement Proposal 436: 'The Argument Clinic DSL'에 대한 한국어 번역입니다.","date":"2025-09-26 21:51:01+0900","lastModifiedAt":"2025-09-26 21:51:01+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/436/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0435-adding_an_enum_type_to_the_python_standard_library","title":"[Final] PEP 435 - Adding an Enum type to the Python standard library","excerpt":"Python Enhancement Proposal 435: 'Adding an Enum type to the Python standard library'에 대한 한국어 번역입니다.","date":"2025-09-26 21:46:35+0900","lastModifiedAt":"2025-09-26 21:46:35+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/435/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0434-idle_enhancement_exception_for_all_branches","title":"[Active] PEP 434 - IDLE Enhancement Exception for All Branches","excerpt":"Python Enhancement Proposal 434: 'IDLE Enhancement Exception for All Branches'에 대한 한국어 번역입니다.","date":"2025-09-26 21:45:59+0900","lastModifiedAt":"2025-09-26 21:45:59+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/434/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0433-easier_suppression_of_file_descriptor_inheritance","title":"[Superseded] PEP 433 - Easier suppression of file descriptor inheritance","excerpt":"Python Enhancement Proposal 433: 'Easier suppression of file descriptor inheritance'에 대한 한국어 번역입니다.","date":"2025-09-26 21:45:26+0900","lastModifiedAt":"2025-09-26 21:45:26+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/433/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0432-restructuring_the_cpython_startup_sequence","title":"[Withdrawn] PEP 432 - Restructuring the CPython startup sequence","excerpt":"Python Enhancement Proposal 432: 'Restructuring the CPython startup sequence'에 대한 한국어 번역입니다.","date":"2025-09-26 21:44:16+0900","lastModifiedAt":"2025-09-26 21:44:16+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/432/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0431-time_zone_support_improvements","title":"[Superseded] PEP 431 - Time zone support improvements","excerpt":"Python Enhancement Proposal 431: 'Time zone support improvements'에 대한 한국어 번역입니다.","date":"2025-09-26 21:43:32+0900","lastModifiedAt":"2025-09-26 21:43:32+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/431/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0430-migrating_to_python_3_as_the_default_online_documentation","title":"[Final] PEP 430 - Migrating to Python 3 as the default online documentation","excerpt":"Python Enhancement Proposal 430: 'Migrating to Python 3 as the default online documentation'에 대한 한국어 번역입니다.","date":"2025-09-26 21:43:01+0900","lastModifiedAt":"2025-09-26 21:43:01+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/430/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0429-python_3.4_release_schedule","title":"[Final] PEP 429 - Python 3.4 Release Schedule","excerpt":"Python Enhancement Proposal 429: 'Python 3.4 Release Schedule'에 대한 한국어 번역입니다.","date":"2025-09-26 21:42:34+0900","lastModifiedAt":"2025-09-26 21:42:34+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/429/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0428-the_pathlib_module_object-oriented_filesystem_paths","title":"[Final] PEP 428 - The pathlib module – object-oriented filesystem paths","excerpt":"Python Enhancement Proposal 428: 'The pathlib module – object-oriented filesystem paths'에 대한 한국어 번역입니다.","date":"2025-09-26 21:42:10+0900","lastModifiedAt":"2025-09-26 21:42:10+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/428/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0427-the_wheel_binary_package_format_1.0","title":"[Final] PEP 427 - The Wheel Binary Package Format 1.0","excerpt":"Python Enhancement Proposal 427: 'The Wheel Binary Package Format 1.0'에 대한 한국어 번역입니다.","date":"2025-09-26 21:41:28+0900","lastModifiedAt":"2025-09-26 21:41:28+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/427/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0426-metadata_for_python_software_packages_2.0","title":"[Withdrawn] PEP 426 - Metadata for Python Software Packages 2.0","excerpt":"Python Enhancement Proposal 426: 'Metadata for Python Software Packages 2.0'에 대한 한국어 번역입니다.","date":"2025-09-26 21:40:33+0900","lastModifiedAt":"2025-09-26 21:40:33+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/426/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0425-compatibility_tags_for_built_distributions","title":"[Final] PEP 425 - Compatibility Tags for Built Distributions","excerpt":"Python Enhancement Proposal 425: 'Compatibility Tags for Built Distributions'에 대한 한국어 번역입니다.","date":"2025-09-26 21:40:01+0900","lastModifiedAt":"2025-09-26 21:40:01+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/425/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0424-a_method_for_exposing_a_length_hint","title":"[Final] PEP 424 - A method for exposing a length hint","excerpt":"Python Enhancement Proposal 424: 'A method for exposing a length hint'에 대한 한국어 번역입니다.","date":"2025-09-26 21:39:24+0900","lastModifiedAt":"2025-09-26 21:39:24+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/424/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0423-naming_conventions_and_recipes_related_to_packaging","title":"[Deferred] PEP 423 - Naming conventions and recipes related to packaging","excerpt":"Python Enhancement Proposal 423: 'Naming conventions and recipes related to packaging'에 대한 한국어 번역입니다.","date":"2025-09-26 21:39:09+0900","lastModifiedAt":"2025-09-26 21:39:09+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/423/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0422-simpler_customisation_of_class_creation","title":"[Withdrawn] PEP 422 - Simpler customisation of class creation","excerpt":"Python Enhancement Proposal 422: 'Simpler customisation of class creation'에 대한 한국어 번역입니다.","date":"2025-09-26 21:38:32+0900","lastModifiedAt":"2025-09-26 21:38:32+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/422/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0421-adding_sys.implementation","title":"[Final] PEP 421 - Adding sys.implementation","excerpt":"Python Enhancement Proposal 421: 'Adding sys.implementation'에 대한 한국어 번역입니다.","date":"2025-09-26 21:37:48+0900","lastModifiedAt":"2025-09-26 21:37:48+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/421/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0420-implicit_namespace_packages","title":"[Final] PEP 420 - Implicit Namespace Packages","excerpt":"Python Enhancement Proposal 420: 'Implicit Namespace Packages'에 대한 한국어 번역입니다.","date":"2025-09-26 21:37:09+0900","lastModifiedAt":"2025-09-26 21:37:09+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/420/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0419-protecting_cleanup_statements_from_interruptions","title":"[Deferred] PEP 419 - Protecting cleanup statements from interruptions","excerpt":"Python Enhancement Proposal 419: 'Protecting cleanup statements from interruptions'에 대한 한국어 번역입니다.","date":"2025-09-26 21:36:35+0900","lastModifiedAt":"2025-09-26 21:36:35+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/419/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0418-add_monotonic_time_performance_counter_and_process_time_functions","title":"[Final] PEP 418 - Add monotonic time, performance counter, and process time functions","excerpt":"Python Enhancement Proposal 418: 'Add monotonic time, performance counter, and process time functions'에 대한 한국어 번역입니다.","date":"2025-09-26 21:35:49+0900","lastModifiedAt":"2025-09-26 21:35:49+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/418/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0417-including_mock_in_the_standard_library","title":"[Final] PEP 417 - Including mock in the Standard Library","excerpt":"Python Enhancement Proposal 417: 'Including mock in the Standard Library'에 대한 한국어 번역입니다.","date":"2025-09-26 21:35:01+0900","lastModifiedAt":"2025-09-26 21:35:01+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/417/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0416-add_a_frozendict_builtin_type","title":"[Rejected] PEP 416 - Add a frozendict builtin type","excerpt":"Python Enhancement Proposal 416: 'Add a frozendict builtin type'에 대한 한국어 번역입니다.","date":"2025-09-26 21:34:46+0900","lastModifiedAt":"2025-09-26 21:34:46+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/416/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0415-implement_context_suppression_with_exception_attributes","title":"[Final] PEP 415 - Implement context suppression with exception attributes","excerpt":"Python Enhancement Proposal 415: 'Implement context suppression with exception attributes'에 대한 한국어 번역입니다.","date":"2025-09-26 21:34:10+0900","lastModifiedAt":"2025-09-26 21:34:10+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/415/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0414-explicit_unicode_literal_for_python_3.3","title":"[Final] PEP 414 - Explicit Unicode Literal for Python 3.3","excerpt":"Python Enhancement Proposal 414: 'Explicit Unicode Literal for Python 3.3'에 대한 한국어 번역입니다.","date":"2025-09-26 21:33:55+0900","lastModifiedAt":"2025-09-26 21:33:55+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/414/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0413-faster_evolution_of_the_python_standard_library","title":"[Withdrawn] PEP 413 - Faster evolution of the Python Standard Library","excerpt":"Python Enhancement Proposal 413: 'Faster evolution of the Python Standard Library'에 대한 한국어 번역입니다.","date":"2025-09-26 21:33:07+0900","lastModifiedAt":"2025-09-26 21:33:07+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/413/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0412-key-sharing_dictionary","title":"[Final] PEP 412 - Key-Sharing Dictionary","excerpt":"Python Enhancement Proposal 412: 'Key-Sharing Dictionary'에 대한 한국어 번역입니다.","date":"2025-09-26 21:32:26+0900","lastModifiedAt":"2025-09-26 21:32:26+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/412/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0411-provisional_packages_in_the_python_standard_library","title":"[Superseded] PEP 411 - Provisional packages in the Python standard library","excerpt":"Python Enhancement Proposal 411: 'Provisional packages in the Python standard library'에 대한 한국어 번역입니다.","date":"2025-09-26 21:31:48+0900","lastModifiedAt":"2025-09-26 21:31:48+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/411/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0410-use_decimal.decimal_type_for_timestamps","title":"[Rejected] PEP 410 - Use decimal.Decimal type for timestamps","excerpt":"Python Enhancement Proposal 410: 'Use decimal.Decimal type for timestamps'에 대한 한국어 번역입니다.","date":"2025-09-26 21:31:14+0900","lastModifiedAt":"2025-09-26 21:31:14+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/410/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0409-suppressing_exception_context","title":"[Final] PEP 409 - Suppressing exception context","excerpt":"Python Enhancement Proposal 409: 'Suppressing exception context'에 대한 한국어 번역입니다.","date":"2025-09-26 21:30:26+0900","lastModifiedAt":"2025-09-26 21:30:26+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/409/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0408-standard_library___preview___package","title":"[Rejected] PEP 408 - Standard library __preview__ package","excerpt":"Python Enhancement Proposal 408: 'Standard library __preview__ package'에 대한 한국어 번역입니다.","date":"2025-09-26 21:30:04+0900","lastModifiedAt":"2025-09-26 21:30:04+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/408/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0407-new_release_cycle_and_introducing_long-term_support_versions","title":"[Deferred] PEP 407 - New release cycle and introducing long-term support versions","excerpt":"Python Enhancement Proposal 407: 'New release cycle and introducing long-term support versions'에 대한 한국어 번역입니다.","date":"2025-09-26 21:29:25+0900","lastModifiedAt":"2025-09-26 21:29:25+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/407/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0406-improved_encapsulation_of_import_state","title":"[Withdrawn] PEP 406 - Improved Encapsulation of Import State","excerpt":"Python Enhancement Proposal 406: 'Improved Encapsulation of Import State'에 대한 한국어 번역입니다.","date":"2025-09-26 21:29:05+0900","lastModifiedAt":"2025-09-26 21:29:05+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/406/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0405-python_virtual_environments","title":"[Final] PEP 405 - Python Virtual Environments","excerpt":"Python Enhancement Proposal 405: 'Python Virtual Environments'에 대한 한국어 번역입니다.","date":"2025-09-26 21:28:37+0900","lastModifiedAt":"2025-09-26 21:28:37+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/405/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0404-python_2.8_un-release_schedule","title":"[Final] PEP 404 - Python 2.8 Un-release Schedule","excerpt":"Python Enhancement Proposal 404: 'Python 2.8 Un-release Schedule'에 대한 한국어 번역입니다.","date":"2025-09-26 21:27:55+0900","lastModifiedAt":"2025-09-26 21:27:55+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/404/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0403-general_purpose_decorator_clause_aka_in_clause","title":"[Deferred] PEP 403 - General purpose decorator clause (aka “@in” clause)","excerpt":"Python Enhancement Proposal 403: 'General purpose decorator clause (aka “@in” clause)'에 대한 한국어 번역입니다.","date":"2025-09-26 21:27:31+0900","lastModifiedAt":"2025-09-26 21:27:31+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/403/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0402-simplified_package_layout_and_partitioning","title":"[Rejected] PEP 402 - Simplified Package Layout and Partitioning","excerpt":"Python Enhancement Proposal 402: 'Simplified Package Layout and Partitioning'에 대한 한국어 번역입니다.","date":"2025-09-26 21:26:40+0900","lastModifiedAt":"2025-09-26 21:26:40+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/402/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0401-bdfl_retirement","title":"[April Fool!] PEP 401 - BDFL Retirement","excerpt":"Python Enhancement Proposal 401: 'BDFL Retirement'에 대한 한국어 번역입니다.","date":"2025-09-26 21:25:14+0900","lastModifiedAt":"2025-09-26 21:25:14+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/401/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0400-deprecate_codecs.streamreader_and_codecs.streamwriter","title":"[Deferred] PEP 400 - Deprecate codecs.StreamReader and codecs.StreamWriter","excerpt":"Python Enhancement Proposal 400: 'Deprecate codecs.StreamReader and codecs.StreamWriter'에 대한 한국어 번역입니다.","date":"2025-09-26 21:24:56+0900","lastModifiedAt":"2025-09-26 21:24:56+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/400/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0399-pure_pythonc_accelerator_module_compatibility_requirements","title":"[Final] PEP 399 - Pure Python/C Accelerator Module Compatibility Requirements","excerpt":"Python Enhancement Proposal 399: 'Pure Python/C Accelerator Module Compatibility Requirements'에 대한 한국어 번역입니다.","date":"2025-09-26 21:24:25+0900","lastModifiedAt":"2025-09-26 21:24:25+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/399/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0398-python_3.3_release_schedule","title":"[Final] PEP 398 - Python 3.3 Release Schedule","excerpt":"Python Enhancement Proposal 398: 'Python 3.3 Release Schedule'에 대한 한국어 번역입니다.","date":"2025-09-26 21:23:58+0900","lastModifiedAt":"2025-09-26 21:23:58+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/398/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0397-python_launcher_for_windows","title":"[Final] PEP 397 - Python launcher for Windows","excerpt":"Python Enhancement Proposal 397: 'Python launcher for Windows'에 대한 한국어 번역입니다.","date":"2025-09-26 21:23:27+0900","lastModifiedAt":"2025-09-26 21:23:27+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/397/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0396-module_version_numbers","title":"[Withdrawn] PEP 396 - Module Version Numbers","excerpt":"Python Enhancement Proposal 396: 'Module Version Numbers'에 대한 한국어 번역입니다.","date":"2025-09-26 21:22:37+0900","lastModifiedAt":"2025-09-26 21:22:37+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/396/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0395-qualified_names_for_modules","title":"[Withdrawn] PEP 395 - Qualified Names for Modules","excerpt":"Python Enhancement Proposal 395: 'Qualified Names for Modules'에 대한 한국어 번역입니다.","date":"2025-09-26 21:22:00+0900","lastModifiedAt":"2025-09-26 21:22:00+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/395/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0394-the_python_command_on_unix-like_systems","title":"[Active] PEP 394 - The “python” Command on Unix-Like Systems","excerpt":"Python Enhancement Proposal 394: 'The “python” Command on Unix-Like Systems'에 대한 한국어 번역입니다.","date":"2025-09-26 21:21:20+0900","lastModifiedAt":"2025-09-26 21:21:20+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/394/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0393-flexible_string_representation","title":"[Final] PEP 393 - Flexible String Representation","excerpt":"Python Enhancement Proposal 393: 'Flexible String Representation'에 대한 한국어 번역입니다.","date":"2025-09-26 21:20:21+0900","lastModifiedAt":"2025-09-26 21:20:21+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/393/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0392-python_3.2_release_schedule","title":"[Final] PEP 392 - Python 3.2 Release Schedule","excerpt":"Python Enhancement Proposal 392: 'Python 3.2 Release Schedule'에 대한 한국어 번역입니다.","date":"2025-09-26 21:19:41+0900","lastModifiedAt":"2025-09-26 21:19:41+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/392/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0391-dictionary-based_configuration_for_logging","title":"[Final] PEP 391 - Dictionary-Based Configuration For Logging","excerpt":"Python Enhancement Proposal 391: 'Dictionary-Based Configuration For Logging'에 대한 한국어 번역입니다.","date":"2025-09-26 21:19:23+0900","lastModifiedAt":"2025-09-26 21:19:23+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/391/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0390-static_metadata_for_distutils","title":"[Rejected] PEP 390 - Static metadata for Distutils","excerpt":"Python Enhancement Proposal 390: 'Static metadata for Distutils'에 대한 한국어 번역입니다.","date":"2025-09-26 21:09:17+0900","lastModifiedAt":"2025-09-26 21:09:17+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/390/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0389-argparse_-_new_command_line_parsing_module","title":"[Final] PEP 389 - argparse - New Command Line Parsing Module","excerpt":"Python Enhancement Proposal 389: 'argparse - New Command Line Parsing Module'에 대한 한국어 번역입니다.","date":"2025-09-26 21:08:50+0900","lastModifiedAt":"2025-09-26 21:08:50+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/389/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0387-backwards_compatibility_policy","title":"[Active] PEP 387 - Backwards Compatibility Policy","excerpt":"Python Enhancement Proposal 387: 'Backwards Compatibility Policy'에 대한 한국어 번역입니다.","date":"2025-09-26 21:07:43+0900","lastModifiedAt":"2025-09-26 21:07:43+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/387/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0386-changing_the_version_comparison_module_in_distutils","title":"[Superseded] PEP 386 - Changing the version comparison module in Distutils","excerpt":"Python Enhancement Proposal 386: 'Changing the version comparison module in Distutils'에 대한 한국어 번역입니다.","date":"2025-09-26 21:07:16+0900","lastModifiedAt":"2025-09-26 21:07:16+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/386/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0385-migrating_from_subversion_to_mercurial","title":"[Final] PEP 385 - Migrating from Subversion to Mercurial","excerpt":"Python Enhancement Proposal 385: 'Migrating from Subversion to Mercurial'에 대한 한국어 번역입니다.","date":"2025-09-26 21:05:29+0900","lastModifiedAt":"2025-09-26 21:05:29+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/385/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0384-defining_a_stable_abi","title":"[Final] PEP 384 - Defining a Stable ABI","excerpt":"Python Enhancement Proposal 384: 'Defining a Stable ABI'에 대한 한국어 번역입니다.","date":"2025-09-26 21:04:32+0900","lastModifiedAt":"2025-09-26 21:04:32+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/384/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0383-non-decodable_bytes_in_system_character_interfaces","title":"[Final] PEP 383 - Non-decodable Bytes in System Character Interfaces","excerpt":"Python Enhancement Proposal 383: 'Non-decodable Bytes in System Character Interfaces'에 대한 한국어 번역입니다.","date":"2025-09-26 21:03:51+0900","lastModifiedAt":"2025-09-26 21:03:51+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/383/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0382-namespace_packages","title":"[Rejected] PEP 382 - Namespace Packages","excerpt":"Python Enhancement Proposal 382: 'Namespace Packages'에 대한 한국어 번역입니다.","date":"2025-09-26 21:03:27+0900","lastModifiedAt":"2025-09-26 21:03:27+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/382/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0381-mirroring_infrastructure_for_pypi","title":"[Withdrawn] PEP 381 - Mirroring infrastructure for PyPI","excerpt":"Python Enhancement Proposal 381: 'Mirroring infrastructure for PyPI'에 대한 한국어 번역입니다.","date":"2025-09-26 21:02:58+0900","lastModifiedAt":"2025-09-26 21:02:58+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/381/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0380-syntax_for_delegating_to_a_subgenerator","title":"[Final] PEP 380 - Syntax for Delegating to a Subgenerator","excerpt":"Python Enhancement Proposal 380: 'Syntax for Delegating to a Subgenerator'에 대한 한국어 번역입니다.","date":"2025-09-26 21:02:19+0900","lastModifiedAt":"2025-09-26 21:02:19+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/380/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0379-adding_an_assignment_expression","title":"[Withdrawn] PEP 379 - Adding an Assignment Expression","excerpt":"Python Enhancement Proposal 379: 'Adding an Assignment Expression'에 대한 한국어 번역입니다.","date":"2025-09-26 21:01:34+0900","lastModifiedAt":"2025-09-26 21:01:34+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/379/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0378-format_specifier_for_thousands_separator","title":"[Final] PEP 378 - Format Specifier for Thousands Separator","excerpt":"Python Enhancement Proposal 378: 'Format Specifier for Thousands Separator'에 대한 한국어 번역입니다.","date":"2025-09-26 21:01:13+0900","lastModifiedAt":"2025-09-26 21:01:13+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/378/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0377-allow___enter___methods_to_skip_the_statement_body","title":"[Rejected] PEP 377 - Allow __enter__() methods to skip the statement body","excerpt":"Python Enhancement Proposal 377: 'Allow __enter__() methods to skip the statement body'에 대한 한국어 번역입니다.","date":"2025-09-26 21:00:13+0900","lastModifiedAt":"2025-09-26 21:00:13+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/377/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0376-database_of_installed_python_distributions","title":"[Final] PEP 376 - Database of Installed Python Distributions","excerpt":"Python Enhancement Proposal 376: 'Database of Installed Python Distributions'에 대한 한국어 번역입니다.","date":"2025-09-26 20:59:42+0900","lastModifiedAt":"2025-09-26 20:59:42+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/376/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0375-python_3.1_release_schedule","title":"[Final] PEP 375 - Python 3.1 Release Schedule","excerpt":"Python Enhancement Proposal 375: 'Python 3.1 Release Schedule'에 대한 한국어 번역입니다.","date":"2025-09-26 20:59:16+0900","lastModifiedAt":"2025-09-26 20:59:16+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/375/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0374-choosing_a_distributed_vcs_for_the_python_project","title":"[Final] PEP 374 - Choosing a distributed VCS for the Python project","excerpt":"Python Enhancement Proposal 374: 'Choosing a distributed VCS for the Python project'에 대한 한국어 번역입니다.","date":"2025-09-26 20:59:02+0900","lastModifiedAt":"2025-09-26 20:59:02+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/374/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0373-python_2.7_release_schedule","title":"[Final] PEP 373 - Python 2.7 Release Schedule","excerpt":"Python Enhancement Proposal 373: 'Python 2.7 Release Schedule'에 대한 한국어 번역입니다.","date":"2025-09-26 20:56:29+0900","lastModifiedAt":"2025-09-26 20:56:29+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/373/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0372-adding_an_ordered_dictionary_to_collections","title":"[Final] PEP 372 - Adding an ordered dictionary to collections","excerpt":"Python Enhancement Proposal 372: 'Adding an ordered dictionary to collections'에 대한 한국어 번역입니다.","date":"2025-09-26 20:56:08+0900","lastModifiedAt":"2025-09-26 20:56:08+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/372/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0371-addition_of_the_multiprocessing_package_to_the_standard_library","title":"[Final] PEP 371 - Addition of the multiprocessing package to the standard library","excerpt":"Python Enhancement Proposal 371: 'Addition of the multiprocessing package to the standard library'에 대한 한국어 번역입니다.","date":"2025-09-26 20:55:33+0900","lastModifiedAt":"2025-09-26 20:55:33+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/371/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0370-per_user_site-packages_directory","title":"[Final] PEP 370 - Per user site-packages directory","excerpt":"Python Enhancement Proposal 370: 'Per user site-packages directory'에 대한 한국어 번역입니다.","date":"2025-09-26 20:54:08+0900","lastModifiedAt":"2025-09-26 20:54:08+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/370/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0369-post_import_hooks","title":"[Withdrawn] PEP 369 - Post import hooks","excerpt":"Python Enhancement Proposal 369: 'Post import hooks'에 대한 한국어 번역입니다.","date":"2025-09-26 20:53:39+0900","lastModifiedAt":"2025-09-26 20:53:39+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/369/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0368-standard_image_protocol_and_class","title":"[Deferred] PEP 368 - Standard image protocol and class","excerpt":"Python Enhancement Proposal 368: 'Standard image protocol and class'에 대한 한국어 번역입니다.","date":"2025-09-26 20:53:03+0900","lastModifiedAt":"2025-09-26 20:53:03+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/368/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0367-new_super","title":"[Superseded] PEP 367 - New Super","excerpt":"Python Enhancement Proposal 367: 'New Super'에 대한 한국어 번역입니다.","date":"2025-09-26 20:50:02+0900","lastModifiedAt":"2025-09-26 20:50:02+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/367/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0366-main_module_explicit_relative_imports","title":"[Final] PEP 366 - Main module explicit relative imports","excerpt":"Python Enhancement Proposal 366: 'Main module explicit relative imports'에 대한 한국어 번역입니다.","date":"2025-09-26 20:49:35+0900","lastModifiedAt":"2025-09-26 20:49:35+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/366/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0329-treating_builtins_as_constants_in_the_standard_library","title":"[Rejected] PEP 329 - Treating Builtins as Constants in the Standard Library","excerpt":"Python Enhancement Proposal 329: 'Treating Builtins as Constants in the Standard Library'에 대한 한국어 번역입니다.","date":"2025-09-26 20:37:36+0900","lastModifiedAt":"2025-09-26 20:37:36+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/329/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0326-a_case_for_top_and_bottom_values","title":"[Rejected] PEP 326 - A Case for Top and Bottom Values","excerpt":"Python Enhancement Proposal 326: 'A Case for Top and Bottom Values'에 대한 한국어 번역입니다.","date":"2025-09-26 20:37:04+0900","lastModifiedAt":"2025-09-26 20:37:04+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/326/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0365-adding_the_pkg_resources_module","title":"[Rejected] PEP 365 - Adding the pkg_resources module","excerpt":"Python Enhancement Proposal 365: 'Adding the pkg_resources module'에 대한 한국어 번역입니다.","date":"2025-09-26 19:09:15+0900","lastModifiedAt":"2025-09-26 19:09:15+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/365/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0364-transitioning_to_the_py3k_standard_library","title":"[Withdrawn] PEP 364 - Transitioning to the Py3K Standard Library","excerpt":"Python Enhancement Proposal 364: 'Transitioning to the Py3K Standard Library'에 대한 한국어 번역입니다.","date":"2025-09-26 19:08:59+0900","lastModifiedAt":"2025-09-26 19:08:59+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/364/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0363-syntax_for_dynamic_attribute_access","title":"[Rejected] PEP 363 - Syntax For Dynamic Attribute Access","excerpt":"Python Enhancement Proposal 363: 'Syntax For Dynamic Attribute Access'에 대한 한국어 번역입니다.","date":"2025-09-26 19:08:27+0900","lastModifiedAt":"2025-09-26 19:08:27+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/363/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0362-function_signature_object","title":"[Final] PEP 362 - Function Signature Object","excerpt":"Python Enhancement Proposal 362: 'Function Signature Object'에 대한 한국어 번역입니다.","date":"2025-09-26 19:08:03+0900","lastModifiedAt":"2025-09-26 19:08:03+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/362/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0361-python_2.6_and_3.0_release_schedule","title":"[Final] PEP 361 - Python 2.6 and 3.0 Release Schedule","excerpt":"Python Enhancement Proposal 361: 'Python 2.6 and 3.0 Release Schedule'에 대한 한국어 번역입니다.","date":"2025-09-26 19:07:30+0900","lastModifiedAt":"2025-09-26 19:07:30+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/361/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0360-externally_maintained_packages","title":"[Final] PEP 360 - Externally Maintained Packages","excerpt":"Python Enhancement Proposal 360: 'Externally Maintained Packages'에 대한 한국어 번역입니다.","date":"2025-09-26 19:07:10+0900","lastModifiedAt":"2025-09-26 19:07:10+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/360/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0359-the_make_statement","title":"[Withdrawn] PEP 359 - The “make” Statement","excerpt":"Python Enhancement Proposal 359: 'The “make” Statement'에 대한 한국어 번역입니다.","date":"2025-09-26 19:06:53+0900","lastModifiedAt":"2025-09-26 19:06:53+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/359/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0358-the_bytes_object","title":"[Final] PEP 358 - The “bytes” Object","excerpt":"Python Enhancement Proposal 358: 'The “bytes” Object'에 대한 한국어 번역입니다.","date":"2025-09-26 19:04:13+0900","lastModifiedAt":"2025-09-26 19:04:13+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/358/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0357-allowing_any_object_to_be_used_for_slicing","title":"[Final] PEP 357 - Allowing Any Object to be Used for Slicing","excerpt":"Python Enhancement Proposal 357: 'Allowing Any Object to be Used for Slicing'에 대한 한국어 번역입니다.","date":"2025-09-26 19:03:31+0900","lastModifiedAt":"2025-09-26 19:03:31+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/357/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0356-python_2.5_release_schedule","title":"[Final] PEP 356 - Python 2.5 Release Schedule","excerpt":"Python Enhancement Proposal 356: 'Python 2.5 Release Schedule'에 대한 한국어 번역입니다.","date":"2025-09-26 19:03:07+0900","lastModifiedAt":"2025-09-26 19:03:07+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/356/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0354-enumerations_in_python","title":"[Superseded] PEP 354 - Enumerations in Python","excerpt":"Python Enhancement Proposal 354: 'Enumerations in Python'에 대한 한국어 번역입니다.","date":"2025-09-26 18:59:58+0900","lastModifiedAt":"2025-09-26 18:59:58+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/354/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0353-using_ssize_t_as_the_index_type","title":"[Final] PEP 353 - Using ssize_t as the index type","excerpt":"Python Enhancement Proposal 353: 'Using ssize_t as the index type'에 대한 한국어 번역입니다.","date":"2025-09-26 18:59:36+0900","lastModifiedAt":"2025-09-26 18:59:36+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/353/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0352-required_superclass_for_exceptions","title":"[Final] PEP 352 - Required Superclass for Exceptions","excerpt":"Python Enhancement Proposal 352: 'Required Superclass for Exceptions'에 대한 한국어 번역입니다.","date":"2025-09-26 18:59:06+0900","lastModifiedAt":"2025-09-26 18:59:06+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/352/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0351-the_freeze_protocol","title":"[Rejected] PEP 351 - The freeze protocol","excerpt":"Python Enhancement Proposal 351: 'The freeze protocol'에 대한 한국어 번역입니다.","date":"2025-09-26 18:58:26+0900","lastModifiedAt":"2025-09-26 18:58:26+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/351/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0350-codetags","title":"[Rejected] PEP 350 - Codetags","excerpt":"Python Enhancement Proposal 350: 'Codetags'에 대한 한국어 번역입니다.","date":"2025-09-26 18:58:11+0900","lastModifiedAt":"2025-09-26 18:58:11+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/350/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0349-allow_str_to_return_unicode_strings","title":"[Rejected] PEP 349 - Allow str() to return unicode strings","excerpt":"Python Enhancement Proposal 349: 'Allow str() to return unicode strings'에 대한 한국어 번역입니다.","date":"2025-09-26 18:57:18+0900","lastModifiedAt":"2025-09-26 18:57:18+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/349/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0348-exception_reorganization_for_python_3.0","title":"[Rejected] PEP 348 - Exception Reorganization for Python 3.0","excerpt":"Python Enhancement Proposal 348: 'Exception Reorganization for Python 3.0'에 대한 한국어 번역입니다.","date":"2025-09-26 18:56:58+0900","lastModifiedAt":"2025-09-26 18:56:58+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/348/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0347-migrating_the_python_cvs_to_subversion","title":"[Final] PEP 347 - Migrating the Python CVS to Subversion","excerpt":"Python Enhancement Proposal 347: 'Migrating the Python CVS to Subversion'에 대한 한국어 번역입니다.","date":"2025-09-26 18:56:24+0900","lastModifiedAt":"2025-09-26 18:56:24+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/347/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0346-user_defined_with_statements","title":"[Withdrawn] PEP 346 - User Defined (”with”) Statements","excerpt":"Python Enhancement Proposal 346: 'User Defined (”with”) Statements'에 대한 한국어 번역입니다.","date":"2025-09-26 18:55:56+0900","lastModifiedAt":"2025-09-26 18:55:56+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/346/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0345-metadata_for_python_software_packages_1.2","title":"[Superseded] PEP 345 - Metadata for Python Software Packages 1.2","excerpt":"Python Enhancement Proposal 345: 'Metadata for Python Software Packages 1.2'에 대한 한국어 번역입니다.","date":"2025-09-26 18:54:36+0900","lastModifiedAt":"2025-09-26 18:54:36+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/345/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0344-exception_chaining_and_embedded_tracebacks","title":"[Superseded] PEP 344 - Exception Chaining and Embedded Tracebacks","excerpt":"Python Enhancement Proposal 344: 'Exception Chaining and Embedded Tracebacks'에 대한 한국어 번역입니다.","date":"2025-09-26 18:54:00+0900","lastModifiedAt":"2025-09-26 18:54:00+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/344/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0342-coroutines_via_enhanced_generators","title":"[Final] PEP 342 - Coroutines via Enhanced Generators","excerpt":"Python Enhancement Proposal 342: 'Coroutines via Enhanced Generators'에 대한 한국어 번역입니다.","date":"2025-09-26 18:48:58+0900","lastModifiedAt":"2025-09-26 18:48:58+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/342/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0341-unifying_try-except_and_try-finally","title":"[Final] PEP 341 - Unifying try-except and try-finally","excerpt":"Python Enhancement Proposal 341: 'Unifying try-except and try-finally'에 대한 한국어 번역입니다.","date":"2025-09-26 18:48:18+0900","lastModifiedAt":"2025-09-26 18:48:18+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/341/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0340-anonymous_block_statements","title":"[Rejected] PEP 340 - Anonymous Block Statements","excerpt":"Python Enhancement Proposal 340: 'Anonymous Block Statements'에 대한 한국어 번역입니다.","date":"2025-09-26 18:48:04+0900","lastModifiedAt":"2025-09-26 18:48:04+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/340/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0339-design_of_the_cpython_compiler","title":"[Withdrawn] PEP 339 - Design of the CPython Compiler","excerpt":"Python Enhancement Proposal 339: 'Design of the CPython Compiler'에 대한 한국어 번역입니다.","date":"2025-09-26 18:46:48+0900","lastModifiedAt":"2025-09-26 18:46:48+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/339/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0338-executing_modules_as_scripts","title":"[Final] PEP 338 - Executing modules as scripts","excerpt":"Python Enhancement Proposal 338: 'Executing modules as scripts'에 대한 한국어 번역입니다.","date":"2025-09-26 18:45:56+0900","lastModifiedAt":"2025-09-26 18:45:56+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/338/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0337-logging_usage_in_the_standard_library","title":"[Deferred] PEP 337 - Logging Usage in the Standard Library","excerpt":"Python Enhancement Proposal 337: 'Logging Usage in the Standard Library'에 대한 한국어 번역입니다.","date":"2025-09-26 18:45:28+0900","lastModifiedAt":"2025-09-26 18:45:28+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/337/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0336-make_none_callable","title":"[Rejected] PEP 336 - Make None Callable","excerpt":"Python Enhancement Proposal 336: 'Make None Callable'에 대한 한국어 번역입니다.","date":"2025-09-26 18:45:11+0900","lastModifiedAt":"2025-09-26 18:45:11+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/336/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0334-simple_coroutines_via_suspenditeration","title":"[Withdrawn] PEP 334 - Simple Coroutines via SuspendIteration","excerpt":"Python Enhancement Proposal 334: 'Simple Coroutines via SuspendIteration'에 대한 한국어 번역입니다.","date":"2025-09-26 18:43:20+0900","lastModifiedAt":"2025-09-26 18:43:20+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/334/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0333-python_web_server_gateway_interface_v1.0","title":"[Final] PEP 333 - Python Web Server Gateway Interface v1.0","excerpt":"Python Enhancement Proposal 333: 'Python Web Server Gateway Interface v1.0'에 대한 한국어 번역입니다.","date":"2025-09-26 18:42:49+0900","lastModifiedAt":"2025-09-26 18:42:49+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/333/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0332-byte_vectors_and_stringunicode_unification","title":"[Rejected] PEP 332 - Byte vectors and String/Unicode Unification","excerpt":"Python Enhancement Proposal 332: 'Byte vectors and String/Unicode Unification'에 대한 한국어 번역입니다.","date":"2025-09-26 18:38:55+0900","lastModifiedAt":"2025-09-26 18:38:55+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/332/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0331-locale-independent_floatstring_conversions","title":"[Final] PEP 331 - Locale-Independent Float/String Conversions","excerpt":"Python Enhancement Proposal 331: 'Locale-Independent Float/String Conversions'에 대한 한국어 번역입니다.","date":"2025-09-26 18:38:41+0900","lastModifiedAt":"2025-09-26 18:38:41+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/331/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0330-python_bytecode_verification","title":"[Rejected] PEP 330 - Python Bytecode Verification","excerpt":"Python Enhancement Proposal 330: 'Python Bytecode Verification'에 대한 한국어 번역입니다.","date":"2025-09-26 18:38:18+0900","lastModifiedAt":"2025-09-26 18:38:18+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/330/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0328-imports_multi-line_and_absoluterelative","title":"[Final] PEP 328 - Imports: Multi-Line and Absolute/Relative","excerpt":"Python Enhancement Proposal 328: 'Imports: Multi-Line and Absolute/Relative'에 대한 한국어 번역입니다.","date":"2025-09-26 18:36:33+0900","lastModifiedAt":"2025-09-26 18:36:33+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/328/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0327-decimal_data_type","title":"[Final] PEP 327 - Decimal Data Type","excerpt":"Python Enhancement Proposal 327: 'Decimal Data Type'에 대한 한국어 번역입니다.","date":"2025-09-26 18:35:48+0900","lastModifiedAt":"2025-09-26 18:35:48+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/327/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0325-resource-release_support_for_generators","title":"[Rejected] PEP 325 - Resource-Release Support for Generators","excerpt":"Python Enhancement Proposal 325: 'Resource-Release Support for Generators'에 대한 한국어 번역입니다.","date":"2025-09-26 18:31:57+0900","lastModifiedAt":"2025-09-26 18:31:57+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/325/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0324-subprocess_-_new_process_module","title":"[Final] PEP 324 - subprocess - New process module","excerpt":"Python Enhancement Proposal 324: 'subprocess - New process module'에 대한 한국어 번역입니다.","date":"2025-09-26 18:31:27+0900","lastModifiedAt":"2025-09-26 18:31:27+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/324/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0323-copyable_iterators","title":"[Deferred] PEP 323 - Copyable Iterators","excerpt":"Python Enhancement Proposal 323: 'Copyable Iterators'에 대한 한국어 번역입니다.","date":"2025-09-26 18:31:01+0900","lastModifiedAt":"2025-09-26 18:31:01+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/323/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0322-reverse_iteration","title":"[Final] PEP 322 - Reverse Iteration","excerpt":"Python Enhancement Proposal 322: 'Reverse Iteration'에 대한 한국어 번역입니다.","date":"2025-09-26 18:30:23+0900","lastModifiedAt":"2025-09-26 18:30:23+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/322/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0321-datetime_parsing_and_formatting","title":"[Withdrawn] PEP 321 - Date/Time Parsing and Formatting","excerpt":"Python Enhancement Proposal 321: 'Date/Time Parsing and Formatting'에 대한 한국어 번역입니다.","date":"2025-09-26 18:30:01+0900","lastModifiedAt":"2025-09-26 18:30:01+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/321/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0320-python_2.4_release_schedule","title":"[Final] PEP 320 - Python 2.4 Release Schedule","excerpt":"Python Enhancement Proposal 320: 'Python 2.4 Release Schedule'에 대한 한국어 번역입니다.","date":"2025-09-26 18:29:42+0900","lastModifiedAt":"2025-09-26 18:29:42+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/320/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0319-python_synchronizeasynchronize_block","title":"[Rejected] PEP 319 - Python Synchronize/Asynchronize Block","excerpt":"Python Enhancement Proposal 319: 'Python Synchronize/Asynchronize Block'에 대한 한국어 번역입니다.","date":"2025-09-26 18:29:20+0900","lastModifiedAt":"2025-09-26 18:29:20+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/319/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0318-decorators_for_functions_and_methods","title":"[Final] PEP 318 - Decorators for Functions and Methods","excerpt":"Python Enhancement Proposal 318: 'Decorators for Functions and Methods'에 대한 한국어 번역입니다.","date":"2025-09-26 18:28:53+0900","lastModifiedAt":"2025-09-26 18:28:53+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/318/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0317-eliminate_implicit_exception_instantiation","title":"[Rejected] PEP 317 - Eliminate Implicit Exception Instantiation","excerpt":"Python Enhancement Proposal 317: 'Eliminate Implicit Exception Instantiation'에 대한 한국어 번역입니다.","date":"2025-09-26 18:28:16+0900","lastModifiedAt":"2025-09-26 18:28:16+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/317/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0316-programming_by_contract_for_python","title":"[Deferred] PEP 316 - Programming by Contract for Python","excerpt":"Python Enhancement Proposal 316: 'Programming by Contract for Python'에 대한 한국어 번역입니다.","date":"2025-09-26 18:27:40+0900","lastModifiedAt":"2025-09-26 18:27:40+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/316/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0315-enhanced_while_loop","title":"[Rejected] PEP 315 - Enhanced While Loop","excerpt":"Python Enhancement Proposal 315: 'Enhanced While Loop'에 대한 한국어 번역입니다.","date":"2025-09-26 18:13:38+0900","lastModifiedAt":"2025-09-26 18:13:38+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/315/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0314-metadata_for_python_software_packages_1.1","title":"[Superseded] PEP 314 - Metadata for Python Software Packages 1.1","excerpt":"Python Enhancement Proposal 314: 'Metadata for Python Software Packages 1.1'에 대한 한국어 번역입니다.","date":"2025-09-26 18:13:21+0900","lastModifiedAt":"2025-09-26 18:13:21+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/314/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0313-adding_roman_numeral_literals_to_python","title":"[Rejected] PEP 313 - Adding Roman Numeral Literals to Python","excerpt":"Python Enhancement Proposal 313: 'Adding Roman Numeral Literals to Python'에 대한 한국어 번역입니다.","date":"2025-09-26 18:12:44+0900","lastModifiedAt":"2025-09-26 18:12:44+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/313/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0312-simple_implicit_lambda","title":"[Deferred] PEP 312 - Simple Implicit Lambda","excerpt":"Python Enhancement Proposal 312: 'Simple Implicit Lambda'에 대한 한국어 번역입니다.","date":"2025-09-26 18:12:24+0900","lastModifiedAt":"2025-09-26 18:12:24+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/312/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0311-simplified_global_interpreter_lock_acquisition_for_extensions","title":"[Final] PEP 311 - Simplified Global Interpreter Lock Acquisition for Extensions","excerpt":"Python Enhancement Proposal 311: 'Simplified Global Interpreter Lock Acquisition for Extensions'에 대한 한국어 번역입니다.","date":"2025-09-26 18:12:03+0900","lastModifiedAt":"2025-09-26 18:12:03+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/311/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0310-reliable_acquisitionrelease_pairs","title":"[Rejected] PEP 310 - Reliable Acquisition/Release Pairs","excerpt":"Python Enhancement Proposal 310: 'Reliable Acquisition/Release Pairs'에 대한 한국어 번역입니다.","date":"2025-09-26 18:11:37+0900","lastModifiedAt":"2025-09-26 18:11:37+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/310/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0309-partial_function_application","title":"[Final] PEP 309 - Partial Function Application","excerpt":"Python Enhancement Proposal 309: 'Partial Function Application'에 대한 한국어 번역입니다.","date":"2025-09-26 18:11:12+0900","lastModifiedAt":"2025-09-26 18:11:12+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/309/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0308-conditional_expressions","title":"[Final] PEP 308 - Conditional Expressions","excerpt":"Python Enhancement Proposal 308: 'Conditional Expressions'에 대한 한국어 번역입니다.","date":"2025-09-26 18:10:46+0900","lastModifiedAt":"2025-09-26 18:10:46+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/308/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0307-extensions_to_the_pickle_protocol","title":"[Final] PEP 307 - Extensions to the pickle protocol","excerpt":"Python Enhancement Proposal 307: 'Extensions to the pickle protocol'에 대한 한국어 번역입니다.","date":"2025-09-26 18:10:28+0900","lastModifiedAt":"2025-09-26 18:10:28+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/307/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0306-how_to_change_pythons_grammar","title":"[Withdrawn] PEP 306 - How to Change Python’s Grammar","excerpt":"Python Enhancement Proposal 306: 'How to Change Python’s Grammar'에 대한 한국어 번역입니다.","date":"2025-09-26 18:09:57+0900","lastModifiedAt":"2025-09-26 18:09:57+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/306/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0305-csv_file_api","title":"[Final] PEP 305 - CSV File API","excerpt":"Python Enhancement Proposal 305: 'CSV File API'에 대한 한국어 번역입니다.","date":"2025-09-26 18:09:42+0900","lastModifiedAt":"2025-09-26 18:09:42+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/305/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0304-controlling_generation_of_bytecode_files","title":"[Withdrawn] PEP 304 - Controlling Generation of Bytecode Files","excerpt":"Python Enhancement Proposal 304: 'Controlling Generation of Bytecode Files'에 대한 한국어 번역입니다.","date":"2025-09-26 18:09:05+0900","lastModifiedAt":"2025-09-26 18:09:05+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/304/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0303-extend_divmod_for_multiple_divisors","title":"[Rejected] PEP 303 - Extend divmod() for Multiple Divisors","excerpt":"Python Enhancement Proposal 303: 'Extend divmod() for Multiple Divisors'에 대한 한국어 번역입니다.","date":"2025-09-26 18:08:34+0900","lastModifiedAt":"2025-09-26 18:08:34+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/303/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0302-new_import_hooks","title":"[Final] PEP 302 - New Import Hooks","excerpt":"Python Enhancement Proposal 302: 'New Import Hooks'에 대한 한국어 번역입니다.","date":"2025-09-26 18:08:12+0900","lastModifiedAt":"2025-09-26 18:08:12+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/302/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0301-package_index_and_metadata_for_distutils","title":"[Final] PEP 301 - Package Index and Metadata for Distutils","excerpt":"Python Enhancement Proposal 301: 'Package Index and Metadata for Distutils'에 대한 한국어 번역입니다.","date":"2025-09-26 18:07:29+0900","lastModifiedAt":"2025-09-26 18:07:29+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/301/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0299-special___main___function_in_modules","title":"[Rejected] PEP 299 - Special __main__() function in modules","excerpt":"Python Enhancement Proposal 299: 'Special __main__() function in modules'에 대한 한국어 번역입니다.","date":"2025-09-26 18:07:00+0900","lastModifiedAt":"2025-09-26 18:07:00+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/299/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0298-the_locked_buffer_interface","title":"[Withdrawn] PEP 298 - The Locked Buffer Interface","excerpt":"Python Enhancement Proposal 298: 'The Locked Buffer Interface'에 대한 한국어 번역입니다.","date":"2025-09-26 18:06:42+0900","lastModifiedAt":"2025-09-26 18:06:42+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/298/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0297-support_for_system_upgrades","title":"[Rejected] PEP 297 - Support for System Upgrades","excerpt":"Python Enhancement Proposal 297: 'Support for System Upgrades'에 대한 한국어 번역입니다.","date":"2025-09-26 18:06:11+0900","lastModifiedAt":"2025-09-26 18:06:11+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/297/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0296-adding_a_bytes_object_type","title":"[Withdrawn] PEP 296 - Adding a bytes Object Type","excerpt":"Python Enhancement Proposal 296: 'Adding a bytes Object Type'에 대한 한국어 번역입니다.","date":"2025-09-26 18:05:57+0900","lastModifiedAt":"2025-09-26 18:05:57+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/296/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0295-interpretation_of_multiline_string_constants","title":"[Rejected] PEP 295 - Interpretation of multiline string constants","excerpt":"Python Enhancement Proposal 295: 'Interpretation of multiline string constants'에 대한 한국어 번역입니다.","date":"2025-09-26 18:05:22+0900","lastModifiedAt":"2025-09-26 18:05:22+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/295/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0294-type_names_in_the_types_module","title":"[Rejected] PEP 294 - Type Names in the types Module","excerpt":"Python Enhancement Proposal 294: 'Type Names in the types Module'에 대한 한국어 번역입니다.","date":"2025-09-26 18:05:08+0900","lastModifiedAt":"2025-09-26 18:05:08+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/294/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0293-codec_error_handling_callbacks","title":"[Final] PEP 293 - Codec Error Handling Callbacks","excerpt":"Python Enhancement Proposal 293: 'Codec Error Handling Callbacks'에 대한 한국어 번역입니다.","date":"2025-09-26 18:04:55+0900","lastModifiedAt":"2025-09-26 18:04:55+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/293/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0292-simpler_string_substitutions","title":"[Final] PEP 292 - Simpler String Substitutions","excerpt":"Python Enhancement Proposal 292: 'Simpler String Substitutions'에 대한 한국어 번역입니다.","date":"2025-09-26 18:04:32+0900","lastModifiedAt":"2025-09-26 18:04:32+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/292/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0291-backward_compatibility_for_the_python_2_standard_library","title":"[Superseded] PEP 291 - Backward Compatibility for the Python 2 Standard Library","excerpt":"Python Enhancement Proposal 291: 'Backward Compatibility for the Python 2 Standard Library'에 대한 한국어 번역입니다.","date":"2025-09-26 18:04:05+0900","lastModifiedAt":"2025-09-26 18:04:05+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/291/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0290-code_migration_and_modernization","title":"[Active] PEP 290 - Code Migration and Modernization","excerpt":"Python Enhancement Proposal 290: 'Code Migration and Modernization'에 대한 한국어 번역입니다.","date":"2025-09-26 18:00:45+0900","lastModifiedAt":"2025-09-26 18:00:45+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/290/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0289-generator_expressions","title":"[Final] PEP 289 - Generator Expressions","excerpt":"Python Enhancement Proposal 289: 'Generator Expressions'에 대한 한국어 번역입니다.","date":"2025-09-26 17:59:59+0900","lastModifiedAt":"2025-09-26 17:59:59+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/289/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0288-generators_attributes_and_exceptions","title":"[Withdrawn] PEP 288 - Generators Attributes and Exceptions","excerpt":"Python Enhancement Proposal 288: 'Generators Attributes and Exceptions'에 대한 한국어 번역입니다.","date":"2025-09-26 17:59:36+0900","lastModifiedAt":"2025-09-26 17:59:36+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/288/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0287-restructuredtext_docstring_format","title":"[Active] PEP 287 - reStructuredText Docstring Format","excerpt":"Python Enhancement Proposal 287: 'reStructuredText Docstring Format'에 대한 한국어 번역입니다.","date":"2025-09-26 17:59:15+0900","lastModifiedAt":"2025-09-26 17:59:15+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/287/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0286-enhanced_argument_tuples","title":"[Deferred] PEP 286 - Enhanced Argument Tuples","excerpt":"Python Enhancement Proposal 286: 'Enhanced Argument Tuples'에 대한 한국어 번역입니다.","date":"2025-09-26 17:58:16+0900","lastModifiedAt":"2025-09-26 17:58:16+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/286/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0285-adding_a_bool_type","title":"[Final] PEP 285 - Adding a bool type","excerpt":"Python Enhancement Proposal 285: 'Adding a bool type'에 대한 한국어 번역입니다.","date":"2025-09-26 17:58:00+0900","lastModifiedAt":"2025-09-26 17:58:00+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/285/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0284-integer_for-loops","title":"[Rejected] PEP 284 - Integer for-loops","excerpt":"Python Enhancement Proposal 284: 'Integer for-loops'에 대한 한국어 번역입니다.","date":"2025-09-26 17:57:40+0900","lastModifiedAt":"2025-09-26 17:57:40+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/284/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0283-python_2.3_release_schedule","title":"[Final] PEP 283 - Python 2.3 Release Schedule","excerpt":"Python Enhancement Proposal 283: 'Python 2.3 Release Schedule'에 대한 한국어 번역입니다.","date":"2025-09-26 17:57:14+0900","lastModifiedAt":"2025-09-26 17:57:14+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/283/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0282-a_logging_system","title":"[Final] PEP 282 - A Logging System","excerpt":"Python Enhancement Proposal 282: 'A Logging System'에 대한 한국어 번역입니다.","date":"2025-09-26 17:56:46+0900","lastModifiedAt":"2025-09-26 17:56:46+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/282/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0281-loop_counter_iteration_with_range_and_xrange","title":"[Rejected] PEP 281 - Loop Counter Iteration with range and xrange","excerpt":"Python Enhancement Proposal 281: 'Loop Counter Iteration with range and xrange'에 대한 한국어 번역입니다.","date":"2025-09-26 17:56:00+0900","lastModifiedAt":"2025-09-26 17:56:00+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/281/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0280-optimizing_access_to_globals","title":"[Deferred] PEP 280 - Optimizing access to globals","excerpt":"Python Enhancement Proposal 280: 'Optimizing access to globals'에 대한 한국어 번역입니다.","date":"2025-09-26 17:55:42+0900","lastModifiedAt":"2025-09-26 17:55:42+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/280/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0279-the_enumerate_built-in_function","title":"[Final] PEP 279 - The enumerate() built-in function","excerpt":"Python Enhancement Proposal 279: 'The enumerate() built-in function'에 대한 한국어 번역입니다.","date":"2025-09-26 17:55:04+0900","lastModifiedAt":"2025-09-26 17:55:04+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/279/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0278-universal_newline_support","title":"[Final] PEP 278 - Universal Newline Support","excerpt":"Python Enhancement Proposal 278: 'Universal Newline Support'에 대한 한국어 번역입니다.","date":"2025-09-26 17:54:43+0900","lastModifiedAt":"2025-09-26 17:54:43+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/278/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0277-unicode_file_name_support_for_windows_nt","title":"[Final] PEP 277 - Unicode file name support for Windows NT","excerpt":"Python Enhancement Proposal 277: 'Unicode file name support for Windows NT'에 대한 한국어 번역입니다.","date":"2025-09-26 17:54:18+0900","lastModifiedAt":"2025-09-26 17:54:18+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/277/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0276-simple_iterator_for_ints","title":"[Rejected] PEP 276 - Simple Iterator for ints","excerpt":"Python Enhancement Proposal 276: 'Simple Iterator for ints'에 대한 한국어 번역입니다.","date":"2025-09-26 17:54:04+0900","lastModifiedAt":"2025-09-26 17:54:04+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/276/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0275-switching_on_multiple_values","title":"[Rejected] PEP 275 - Switching on Multiple Values","excerpt":"Python Enhancement Proposal 275: 'Switching on Multiple Values'에 대한 한국어 번역입니다.","date":"2025-09-26 17:53:28+0900","lastModifiedAt":"2025-09-26 17:53:28+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/275/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0274-dict_comprehensions","title":"[Final] PEP 274 - Dict Comprehensions","excerpt":"Python Enhancement Proposal 274: 'Dict Comprehensions'에 대한 한국어 번역입니다.","date":"2025-09-26 17:53:00+0900","lastModifiedAt":"2025-09-26 17:53:00+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/274/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0273-import_modules_from_zip_archives","title":"[Final] PEP 273 - Import Modules from Zip Archives","excerpt":"Python Enhancement Proposal 273: 'Import Modules from Zip Archives'에 대한 한국어 번역입니다.","date":"2025-09-26 17:52:44+0900","lastModifiedAt":"2025-09-26 17:52:44+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/273/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0272-api_for_block_encryption_algorithms_v1.0","title":"[Final] PEP 272 - API for Block Encryption Algorithms v1.0","excerpt":"Python Enhancement Proposal 272: 'API for Block Encryption Algorithms v1.0'에 대한 한국어 번역입니다.","date":"2025-09-26 17:52:18+0900","lastModifiedAt":"2025-09-26 17:52:18+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/272/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0271-prefixing_sys.path_by_command_line_option","title":"[Rejected] PEP 271 - Prefixing sys.path by command line option","excerpt":"Python Enhancement Proposal 271: 'Prefixing sys.path by command line option'에 대한 한국어 번역입니다.","date":"2025-09-26 17:51:56+0900","lastModifiedAt":"2025-09-26 17:51:56+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/271/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0270-uniq_method_for_list_objects","title":"[Rejected] PEP 270 - uniq method for list objects","excerpt":"Python Enhancement Proposal 270: 'uniq method for list objects'에 대한 한국어 번역입니다.","date":"2025-09-26 17:51:43+0900","lastModifiedAt":"2025-09-26 17:51:43+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/270/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0269-pgen_module_for_python","title":"[Deferred] PEP 269 - Pgen Module for Python","excerpt":"Python Enhancement Proposal 269: 'Pgen Module for Python'에 대한 한국어 번역입니다.","date":"2025-09-26 17:51:28+0900","lastModifiedAt":"2025-09-26 17:51:28+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/269/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0268-extended_http_functionality_and_webdav","title":"[Rejected] PEP 268 - Extended HTTP functionality and WebDAV","excerpt":"Python Enhancement Proposal 268: 'Extended HTTP functionality and WebDAV'에 대한 한국어 번역입니다.","date":"2025-09-26 17:51:10+0900","lastModifiedAt":"2025-09-26 17:51:10+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/268/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0267-optimized_access_to_module_namespaces","title":"[Deferred] PEP 267 - Optimized Access to Module Namespaces","excerpt":"Python Enhancement Proposal 267: 'Optimized Access to Module Namespaces'에 대한 한국어 번역입니다.","date":"2025-09-26 17:50:38+0900","lastModifiedAt":"2025-09-26 17:50:38+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/267/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0266-optimizing_global_variableattribute_access","title":"[Withdrawn] PEP 266 - Optimizing Global Variable/Attribute Access","excerpt":"Python Enhancement Proposal 266: 'Optimizing Global Variable/Attribute Access'에 대한 한국어 번역입니다.","date":"2025-09-26 17:49:31+0900","lastModifiedAt":"2025-09-26 17:49:31+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/266/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0265-sorting_dictionaries_by_value","title":"[Rejected] PEP 265 - Sorting Dictionaries by Value","excerpt":"Python Enhancement Proposal 265: 'Sorting Dictionaries by Value'에 대한 한국어 번역입니다.","date":"2025-09-26 17:48:48+0900","lastModifiedAt":"2025-09-26 17:48:48+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/265/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0264-future_statements_in_simulated_shells","title":"[Final] PEP 264 - Future statements in simulated shells","excerpt":"Python Enhancement Proposal 264: 'Future statements in simulated shells'에 대한 한국어 번역입니다.","date":"2025-09-26 17:47:23+0900","lastModifiedAt":"2025-09-26 17:47:23+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/264/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0263-defining_python_source_code_encodings","title":"[Final] PEP 263 - Defining Python Source Code Encodings","excerpt":"Python Enhancement Proposal 263: 'Defining Python Source Code Encodings'에 대한 한국어 번역입니다.","date":"2025-09-26 17:46:12+0900","lastModifiedAt":"2025-09-26 17:46:12+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/263/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0262-a_database_of_installed_python_packages","title":"[Rejected] PEP 262 - A Database of Installed Python Packages","excerpt":"Python Enhancement Proposal 262: 'A Database of Installed Python Packages'에 대한 한국어 번역입니다.","date":"2025-09-26 17:44:46+0900","lastModifiedAt":"2025-09-26 17:44:46+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/262/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0261-support_for_wide_unicode_characters","title":"[Final] PEP 261 - Support for “wide” Unicode characters","excerpt":"Python Enhancement Proposal 261: 'Support for “wide” Unicode characters'에 대한 한국어 번역입니다.","date":"2025-09-26 17:43:32+0900","lastModifiedAt":"2025-09-26 17:43:32+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/261/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0260-simplify_xrange","title":"[Final] PEP 260 - Simplify xrange()","excerpt":"Python Enhancement Proposal 260: 'Simplify xrange()'에 대한 한국어 번역입니다.","date":"2025-09-26 17:42:10+0900","lastModifiedAt":"2025-09-26 17:42:10+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/260/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0259-omit_printing_newline_after_newline","title":"[Rejected] PEP 259 - Omit printing newline after newline","excerpt":"Python Enhancement Proposal 259: 'Omit printing newline after newline'에 대한 한국어 번역입니다.","date":"2025-09-26 17:41:02+0900","lastModifiedAt":"2025-09-26 17:41:02+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/259/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0258-docutils_design_specification","title":"[Rejected] PEP 258 - Docutils Design Specification","excerpt":"Python Enhancement Proposal 258: 'Docutils Design Specification'에 대한 한국어 번역입니다.","date":"2025-09-26 17:39:51+0900","lastModifiedAt":"2025-09-26 17:39:51+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/258/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0257-docstring_conventions","title":"[Active] PEP 257 - Docstring Conventions","excerpt":"Python Enhancement Proposal 257: 'Docstring Conventions'에 대한 한국어 번역입니다.","date":"2025-09-26 17:37:43+0900","lastModifiedAt":"2025-09-26 17:37:43+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/257/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0256-docstring_processing_system_framework","title":"[Rejected] PEP 256 - Docstring Processing System Framework","excerpt":"Python Enhancement Proposal 256: 'Docstring Processing System Framework'에 대한 한국어 번역입니다.","date":"2025-09-26 17:36:23+0900","lastModifiedAt":"2025-09-26 17:36:23+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/256/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0255-simple_generators","title":"[Final] PEP 255 - Simple Generators","excerpt":"Python Enhancement Proposal 255: 'Simple Generators'에 대한 한국어 번역입니다.","date":"2025-09-26 17:35:06+0900","lastModifiedAt":"2025-09-26 17:35:06+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/255/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0254-making_classes_look_more_like_types","title":"[Rejected] PEP 254 - Making Classes Look More Like Types","excerpt":"Python Enhancement Proposal 254: 'Making Classes Look More Like Types'에 대한 한국어 번역입니다.","date":"2025-09-26 17:33:28+0900","lastModifiedAt":"2025-09-26 17:33:28+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/254/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0253-subtyping_built-in_types","title":"[Final] PEP 253 - Subtyping Built-in Types","excerpt":"Python Enhancement Proposal 253: 'Subtyping Built-in Types'에 대한 한국어 번역입니다.","date":"2025-09-26 17:32:18+0900","lastModifiedAt":"2025-09-26 17:32:18+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/253/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0252-making_types_look_more_like_classes","title":"[Final] PEP 252 - Making Types Look More Like Classes","excerpt":"Python Enhancement Proposal 252: 'Making Types Look More Like Classes'에 대한 한국어 번역입니다.","date":"2025-09-26 17:30:03+0900","lastModifiedAt":"2025-09-26 17:30:03+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/252/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0251-python_2.2_release_schedule","title":"[Final] PEP 251 - Python 2.2 Release Schedule","excerpt":"Python Enhancement Proposal 251: 'Python 2.2 Release Schedule'에 대한 한국어 번역입니다.","date":"2025-09-26 17:27:59+0900","lastModifiedAt":"2025-09-26 17:27:59+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/251/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0250-using_site-packages_on_windows","title":"[Final] PEP 250 - Using site-packages on Windows","excerpt":"Python Enhancement Proposal 250: 'Using site-packages on Windows'에 대한 한국어 번역입니다.","date":"2025-09-26 17:26:48+0900","lastModifiedAt":"2025-09-26 17:26:48+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/250/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0249-python_database_api_specification_v2.0","title":"[Final] PEP 249 - Python Database API Specification v2.0","excerpt":"Python Enhancement Proposal 249: 'Python Database API Specification v2.0'에 대한 한국어 번역입니다.","date":"2025-09-26 17:25:38+0900","lastModifiedAt":"2025-09-26 17:25:38+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/249/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0248-python_database_api_specification_v1.0","title":"[Final] PEP 248 - Python Database API Specification v1.0","excerpt":"Python Enhancement Proposal 248: 'Python Database API Specification v1.0'에 대한 한국어 번역입니다.","date":"2025-09-26 17:23:30+0900","lastModifiedAt":"2025-09-26 17:23:30+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/248/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0247-api_for_cryptographic_hash_functions","title":"[Final] PEP 247 - API for Cryptographic Hash Functions","excerpt":"Python Enhancement Proposal 247: 'API for Cryptographic Hash Functions'에 대한 한국어 번역입니다.","date":"2025-09-26 17:22:10+0900","lastModifiedAt":"2025-09-26 17:22:10+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/247/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0246-object_adaptation","title":"[Rejected] PEP 246 - Object Adaptation","excerpt":"Python Enhancement Proposal 246: 'Object Adaptation'에 대한 한국어 번역입니다.","date":"2025-09-26 17:20:56+0900","lastModifiedAt":"2025-09-26 17:20:56+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/246/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0245-python_interface_syntax","title":"[Rejected] PEP 245 - Python Interface Syntax","excerpt":"Python Enhancement Proposal 245: 'Python Interface Syntax'에 대한 한국어 번역입니다.","date":"2025-09-26 17:16:57+0900","lastModifiedAt":"2025-09-26 17:16:57+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/245/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0244-thedirectivestatement","title":"[Rejected] PEP 244 - Thedirectivestatement","excerpt":"Python Enhancement Proposal 244: 'Thedirectivestatement'에 대한 한국어 번역입니다.","date":"2025-09-26 17:15:30+0900","lastModifiedAt":"2025-09-26 17:15:30+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/244/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0243-module_repository_upload_mechanism","title":"[Withdrawn] PEP 243 - Module Repository Upload Mechanism","excerpt":"Python Enhancement Proposal 243: 'Module Repository Upload Mechanism'에 대한 한국어 번역입니다.","date":"2025-09-26 17:14:15+0900","lastModifiedAt":"2025-09-26 17:14:15+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/243/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0242-numeric_kinds","title":"[Withdrawn] PEP 242 - Numeric Kinds","excerpt":"Python Enhancement Proposal 242: 'Numeric Kinds'에 대한 한국어 번역입니다.","date":"2025-09-26 17:13:00+0900","lastModifiedAt":"2025-09-26 17:13:00+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/242/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0241-metadata_for_python_software_packages","title":"[Superseded] PEP 241 - Metadata for Python Software Packages","excerpt":"Python Enhancement Proposal 241: 'Metadata for Python Software Packages'에 대한 한국어 번역입니다.","date":"2025-09-26 17:11:45+0900","lastModifiedAt":"2025-09-26 17:11:45+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/241/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0240-adding_a_rational_literal_to_python","title":"[Rejected] PEP 240 - Adding a Rational Literal to Python","excerpt":"Python Enhancement Proposal 240: 'Adding a Rational Literal to Python'에 대한 한국어 번역입니다.","date":"2025-09-26 17:10:32+0900","lastModifiedAt":"2025-09-26 17:10:32+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/240/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0239-adding_a_rational_type_to_python","title":"[Rejected] PEP 239 - Adding a Rational Type to Python","excerpt":"Python Enhancement Proposal 239: 'Adding a Rational Type to Python'에 대한 한국어 번역입니다.","date":"2025-09-26 17:09:22+0900","lastModifiedAt":"2025-09-26 17:09:22+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/239/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0238-changing_the_division_operator","title":"[Final] PEP 238 - Changing the Division Operator","excerpt":"Python Enhancement Proposal 238: 'Changing the Division Operator'에 대한 한국어 번역입니다.","date":"2025-09-26 17:08:05+0900","lastModifiedAt":"2025-09-26 17:08:05+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/238/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0237-unifying_long_integers_and_integers","title":"[Final] PEP 237 - Unifying Long Integers and Integers","excerpt":"Python Enhancement Proposal 237: 'Unifying Long Integers and Integers'에 대한 한국어 번역입니다.","date":"2025-09-26 17:06:31+0900","lastModifiedAt":"2025-09-26 17:06:31+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/237/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0236-back_to_the___future","title":"[Final] PEP 236 - Back to the __future__","excerpt":"Python Enhancement Proposal 236: 'Back to the __future__'에 대한 한국어 번역입니다.","date":"2025-09-26 17:05:02+0900","lastModifiedAt":"2025-09-26 17:05:02+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/236/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0235-import_on_case-insensitive_platforms","title":"[Final] PEP 235 - Import on Case-Insensitive Platforms","excerpt":"Python Enhancement Proposal 235: 'Import on Case-Insensitive Platforms'에 대한 한국어 번역입니다.","date":"2025-09-26 17:03:34+0900","lastModifiedAt":"2025-09-26 17:03:34+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/235/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0234-iterators","title":"[Final] PEP 234 - Iterators","excerpt":"Python Enhancement Proposal 234: 'Iterators'에 대한 한국어 번역입니다.","date":"2025-09-26 17:02:22+0900","lastModifiedAt":"2025-09-26 17:02:22+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/234/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0233-python_online_help","title":"[Deferred] PEP 233 - Python Online Help","excerpt":"Python Enhancement Proposal 233: 'Python Online Help'에 대한 한국어 번역입니다.","date":"2025-09-26 17:00:50+0900","lastModifiedAt":"2025-09-26 17:00:50+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/233/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0232-function_attributes","title":"[Final] PEP 232 - Function Attributes","excerpt":"Python Enhancement Proposal 232: 'Function Attributes'에 대한 한국어 번역입니다.","date":"2025-09-26 16:59:42+0900","lastModifiedAt":"2025-09-26 16:59:42+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/232/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0231-findattr","title":"[Rejected] PEP 231 - __findattr__()","excerpt":"Python Enhancement Proposal 231: '__findattr__()'에 대한 한국어 번역입니다.","date":"2025-09-26 16:58:10+0900","lastModifiedAt":"2025-09-26 16:58:10+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/231/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0230-warning_framework","title":"[Final] PEP 230 - Warning Framework","excerpt":"Python Enhancement Proposal 230: 'Warning Framework'에 대한 한국어 번역입니다.","date":"2025-09-26 16:53:00+0900","lastModifiedAt":"2025-09-26 16:53:00+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/230/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0229-using_distutils_to_build_python","title":"[Final] PEP 229 - Using Distutils to Build Python","excerpt":"Python Enhancement Proposal 229: 'Using Distutils to Build Python'에 대한 한국어 번역입니다.","date":"2025-09-26 16:51:00+0900","lastModifiedAt":"2025-09-26 16:51:00+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/229/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0228-reworking_pythons_numeric_model","title":"[Withdrawn] PEP 228 - Reworking Python’s Numeric Model","excerpt":"Python Enhancement Proposal 228: 'Reworking Python’s Numeric Model'에 대한 한국어 번역입니다.","date":"2025-09-26 16:49:50+0900","lastModifiedAt":"2025-09-26 16:49:50+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/228/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0227-statically_nested_scopes","title":"[Final] PEP 227 - Statically Nested Scopes","excerpt":"Python Enhancement Proposal 227: 'Statically Nested Scopes'에 대한 한국어 번역입니다.","date":"2025-09-26 16:48:35+0900","lastModifiedAt":"2025-09-26 16:48:35+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/227/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0226-python_2.1_release_schedule","title":"[Final] PEP 226 - Python 2.1 Release Schedule","excerpt":"Python Enhancement Proposal 226: 'Python 2.1 Release Schedule'에 대한 한국어 번역입니다.","date":"2025-09-26 16:47:09+0900","lastModifiedAt":"2025-09-26 16:47:09+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/226/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0225-elementwiseobjectwise_operators","title":"[Rejected] PEP 225 - Elementwise/Objectwise Operators","excerpt":"Python Enhancement Proposal 225: 'Elementwise/Objectwise Operators'에 대한 한국어 번역입니다.","date":"2025-09-26 16:45:47+0900","lastModifiedAt":"2025-09-26 16:45:47+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/225/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0224-attribute_docstrings","title":"[Rejected] PEP 224 - Attribute Docstrings","excerpt":"Python Enhancement Proposal 224: 'Attribute Docstrings'에 대한 한국어 번역입니다.","date":"2025-09-26 16:43:48+0900","lastModifiedAt":"2025-09-26 16:43:48+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/224/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0223-change_the_meaning_ofxescapes","title":"[Final] PEP 223 - Change the Meaning of '\\x' Escapes","excerpt":"Python Enhancement Proposal 223: 'Change the Meaning of '\\x' Escapes'에 대한 한국어 번역입니다.","date":"2025-09-26 16:42:30+0900","lastModifiedAt":"2025-09-26 16:42:30+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/223/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0222-web_library_enhancements","title":"[Deferred] PEP 222 - Web Library Enhancements","excerpt":"Python Enhancement Proposal 222: 'Web Library Enhancements'에 대한 한국어 번역입니다.","date":"2025-09-26 16:41:15+0900","lastModifiedAt":"2025-09-26 16:41:15+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/222/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0221-import_as","title":"[Final] PEP 221 - Import As","excerpt":"Python Enhancement Proposal 221: 'Import As'에 대한 한국어 번역입니다.","date":"2025-09-26 16:39:52+0900","lastModifiedAt":"2025-09-26 16:39:52+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/221/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0220-coroutines_generators_continuations","title":"[Rejected] PEP 220 - Coroutines, Generators, Continuations","excerpt":"Python Enhancement Proposal 220: 'Coroutines, Generators, Continuations'에 대한 한국어 번역입니다.","date":"2025-09-26 16:38:41+0900","lastModifiedAt":"2025-09-26 16:38:41+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/220/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0219-stackless_python","title":"[Deferred] PEP 219 - Stackless Python","excerpt":"Python Enhancement Proposal 219: 'Stackless Python'에 대한 한국어 번역입니다.","date":"2025-09-26 16:37:30+0900","lastModifiedAt":"2025-09-26 16:37:30+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/219/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0218-adding_a_built-in_set_object_type","title":"[Final] PEP 218 - Adding a Built-In Set Object Type","excerpt":"Python Enhancement Proposal 218: 'Adding a Built-In Set Object Type'에 대한 한국어 번역입니다.","date":"2025-09-26 16:36:13+0900","lastModifiedAt":"2025-09-26 16:36:13+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/218/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0217-display_hook_for_interactive_use","title":"[Final] PEP 217 - Display Hook for Interactive Use","excerpt":"Python Enhancement Proposal 217: 'Display Hook for Interactive Use'에 대한 한국어 번역입니다.","date":"2025-09-26 16:34:58+0900","lastModifiedAt":"2025-09-26 16:34:58+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/217/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0216-docstring_format","title":"[Withdrawn] PEP 216 - Docstring Format","excerpt":"Python Enhancement Proposal 216: 'Docstring Format'에 대한 한국어 번역입니다.","date":"2025-09-26 16:33:50+0900","lastModifiedAt":"2025-09-26 16:33:50+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/216/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0215-string_interpolation","title":"[Superseded] PEP 215 - String Interpolation","excerpt":"Python Enhancement Proposal 215: 'String Interpolation'에 대한 한국어 번역입니다.","date":"2025-09-26 16:32:37+0900","lastModifiedAt":"2025-09-26 16:32:37+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/215/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0214-extended_print_statement","title":"[Final] PEP 214 - Extended Print Statement","excerpt":"Python Enhancement Proposal 214: 'Extended Print Statement'에 대한 한국어 번역입니다.","date":"2025-09-26 16:31:25+0900","lastModifiedAt":"2025-09-26 16:31:25+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/214/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0213-attribute_access_handlers","title":"[Deferred] PEP 213 - Attribute Access Handlers","excerpt":"Python Enhancement Proposal 213: 'Attribute Access Handlers'에 대한 한국어 번역입니다.","date":"2025-09-26 16:29:57+0900","lastModifiedAt":"2025-09-26 16:29:57+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/213/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0212-loop_counter_iteration","title":"[Rejected] PEP 212 - Loop Counter Iteration","excerpt":"Python Enhancement Proposal 212: 'Loop Counter Iteration'에 대한 한국어 번역입니다.","date":"2025-09-26 16:28:28+0900","lastModifiedAt":"2025-09-26 16:28:28+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/212/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0211-adding_a_new_outer_product_operator","title":"[Rejected] PEP 211 - Adding A New Outer Product Operator","excerpt":"Python Enhancement Proposal 211: 'Adding A New Outer Product Operator'에 대한 한국어 번역입니다.","date":"2025-09-26 16:27:14+0900","lastModifiedAt":"2025-09-26 16:27:14+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/211/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0210-decoupling_the_interpreter_loop","title":"[Rejected] PEP 210 - Decoupling the Interpreter Loop","excerpt":"Python Enhancement Proposal 210: 'Decoupling the Interpreter Loop'에 대한 한국어 번역입니다.","date":"2025-09-26 16:25:55+0900","lastModifiedAt":"2025-09-26 16:25:55+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/210/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0209-multi-dimensional_arrays","title":"[Withdrawn] PEP 209 - Multi-dimensional Arrays","excerpt":"Python Enhancement Proposal 209: 'Multi-dimensional Arrays'에 대한 한국어 번역입니다.","date":"2025-09-26 16:21:26+0900","lastModifiedAt":"2025-09-26 16:21:26+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/209/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0208-reworking_the_coercion_model","title":"[Final] PEP 208 - Reworking the Coercion Model","excerpt":"Python Enhancement Proposal 208: 'Reworking the Coercion Model'에 대한 한국어 번역입니다.","date":"2025-09-26 16:20:00+0900","lastModifiedAt":"2025-09-26 16:20:00+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/208/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0207-rich_comparisons","title":"[Final] PEP 207 - Rich Comparisons","excerpt":"Python Enhancement Proposal 207: 'Rich Comparisons'에 대한 한국어 번역입니다.","date":"2025-09-26 16:18:40+0900","lastModifiedAt":"2025-09-26 16:18:40+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/207/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0206-python_advanced_library","title":"[Withdrawn] PEP 206 - Python Advanced Library","excerpt":"Python Enhancement Proposal 206: 'Python Advanced Library'에 대한 한국어 번역입니다.","date":"2025-09-26 16:17:22+0900","lastModifiedAt":"2025-09-26 16:17:22+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/206/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0205-weak_references","title":"[Final] PEP 205 - Weak References","excerpt":"Python Enhancement Proposal 205: 'Weak References'에 대한 한국어 번역입니다.","date":"2025-09-26 16:16:10+0900","lastModifiedAt":"2025-09-26 16:16:10+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/205/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0204-range_literals","title":"[Rejected] PEP 204 - Range Literals","excerpt":"Python Enhancement Proposal 204: 'Range Literals'에 대한 한국어 번역입니다.","date":"2025-09-26 16:14:46+0900","lastModifiedAt":"2025-09-26 16:14:46+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/204/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0203-augmented_assignments","title":"[Final] PEP 203 - Augmented Assignments","excerpt":"Python Enhancement Proposal 203: 'Augmented Assignments'에 대한 한국어 번역입니다.","date":"2025-09-26 16:13:23+0900","lastModifiedAt":"2025-09-26 16:13:23+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/203/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0202-list_comprehensions","title":"[Final] PEP 202 - List Comprehensions","excerpt":"Python Enhancement Proposal 202: 'List Comprehensions'에 대한 한국어 번역입니다.","date":"2025-09-26 16:12:08+0900","lastModifiedAt":"2025-09-26 16:12:08+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/202/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0201-lockstep_iteration","title":"[Final] PEP 201 - Lockstep Iteration","excerpt":"Python Enhancement Proposal 201: 'Lockstep Iteration'에 대한 한국어 번역입니다.","date":"2025-09-26 16:10:52+0900","lastModifiedAt":"2025-09-26 16:10:52+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/201/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0200-python_2.0_release_schedule","title":"[Final] PEP 200 - Python 2.0 Release Schedule","excerpt":"Python Enhancement Proposal 200: 'Python 2.0 Release Schedule'에 대한 한국어 번역입니다.","date":"2025-09-26 16:09:15+0900","lastModifiedAt":"2025-09-26 16:09:15+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/200/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0160-python_1.6_release_schedule","title":"[Final] PEP 160 - Python 1.6 Release Schedule","excerpt":"Python Enhancement Proposal 160: 'Python 1.6 Release Schedule'에 대한 한국어 번역입니다.","date":"2025-09-26 16:07:53+0900","lastModifiedAt":"2025-09-26 16:07:53+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/160/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0103-collecting_information_about_git","title":"[Withdrawn] PEP 103 - Collecting information about git","excerpt":"Python Enhancement Proposal 103: 'Collecting information about git'에 대한 한국어 번역입니다.","date":"2025-09-26 16:06:44+0900","lastModifiedAt":"2025-09-26 16:06:44+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/103/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0102-doing_python_micro_releases","title":"[Superseded] PEP 102 - Doing Python Micro Releases","excerpt":"Python Enhancement Proposal 102: 'Doing Python Micro Releases'에 대한 한국어 번역입니다.","date":"2025-09-26 16:04:40+0900","lastModifiedAt":"2025-09-26 16:04:40+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/102/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0101-doing_python_releases_101","title":"[Active] PEP 101 - Doing Python Releases 101","excerpt":"Python Enhancement Proposal 101: 'Doing Python Releases 101'에 대한 한국어 번역입니다.","date":"2025-09-26 16:02:21+0900","lastModifiedAt":"2025-09-26 16:02:21+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/101/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0100-python_unicode_integration","title":"[Final] PEP 100 - Python Unicode Integration","excerpt":"Python Enhancement Proposal 100: 'Python Unicode Integration'에 대한 한국어 번역입니다.","date":"2025-09-26 16:00:20+0900","lastModifiedAt":"2025-09-26 16:00:20+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/100/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0042-feature_requests","title":"[Withdrawn] PEP 42 - Feature Requests","excerpt":"Python Enhancement Proposal 42: 'Feature Requests'에 대한 한국어 번역입니다.","date":"2025-09-26 15:56:44+0900","lastModifiedAt":"2025-09-26 15:56:44+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/42/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0020-the_zen_of_python","title":"[Active] PEP 20 - The Zen of Python","excerpt":"Python Enhancement Proposal 20: 'The Zen of Python'에 대한 한국어 번역입니다.","date":"2025-09-26 15:55:10+0900","lastModifiedAt":"2025-09-26 15:55:10+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/20/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0013-python_language_governance","title":"[Active] PEP 13 - Python Language Governance","excerpt":"Python Enhancement Proposal 13: 'Python Language Governance'에 대한 한국어 번역입니다.","date":"2025-09-26 15:54:00+0900","lastModifiedAt":"2025-09-26 15:54:00+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/13/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0012-sample_restructuredtext_pep_template","title":"[Active] PEP 12 - Sample reStructuredText PEP Template","excerpt":"Python Enhancement Proposal 12: 'Sample reStructuredText PEP Template'에 대한 한국어 번역입니다.","date":"2025-09-26 15:52:34+0900","lastModifiedAt":"2025-09-26 15:52:34+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/12/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0011-cpython_platform_support","title":"[Active] PEP 11 - CPython platform support","excerpt":"Python Enhancement Proposal 11: 'CPython platform support'에 대한 한국어 번역입니다.","date":"2025-09-26 15:49:46+0900","lastModifiedAt":"2025-09-26 15:49:46+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/11/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0010-voting_guidelines","title":"[Active] PEP 10 - Voting Guidelines","excerpt":"Python Enhancement Proposal 10: 'Voting Guidelines'에 대한 한국어 번역입니다.","date":"2025-09-26 15:48:17+0900","lastModifiedAt":"2025-09-26 15:48:17+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/10/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0009-sample_plaintext_pep_template","title":"[Withdrawn] PEP 9 - Sample Plaintext PEP Template","excerpt":"Python Enhancement Proposal 9: 'Sample Plaintext PEP Template'에 대한 한국어 번역입니다.","date":"2025-09-26 15:47:09+0900","lastModifiedAt":"2025-09-26 15:47:09+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/9/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0008-style_guide_for_python_code","title":"[Active] PEP 8 - Style Guide for Python Code","excerpt":"Python Enhancement Proposal 8: 'Style Guide for Python Code'에 대한 한국어 번역입니다.","date":"2025-09-26 15:45:52+0900","lastModifiedAt":"2025-09-26 15:45:52+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/8/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0007-style_guide_for_c_code","title":"[Active] PEP 7 - Style Guide for C Code","excerpt":"Python Enhancement Proposal 7: 'Style Guide for C Code'에 대한 한국어 번역입니다.","date":"2025-09-26 15:43:52+0900","lastModifiedAt":"2025-09-26 15:43:52+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/7/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0006-bug_fix_releases","title":"[Superseded] PEP 6 - Bug Fix Releases","excerpt":"Python Enhancement Proposal 6: 'Bug Fix Releases'에 대한 한국어 번역입니다.","date":"2025-09-26 15:42:30+0900","lastModifiedAt":"2025-09-26 15:42:30+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/6/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0005-guidelines_for_language_evolution","title":"[Superseded] PEP 5 - Guidelines for Language Evolution","excerpt":"Python Enhancement Proposal 5: 'Guidelines for Language Evolution'에 대한 한국어 번역입니다.","date":"2025-09-26 15:40:01+0900","lastModifiedAt":"2025-09-26 15:40:01+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/5/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0004-deprecation_of_standard_modules","title":"[Active] PEP 4 - Deprecation of Standard Modules","excerpt":"Python Enhancement Proposal 4: 'Deprecation of Standard Modules'에 대한 한국어 번역입니다.","date":"2025-09-26 15:38:53+0900","lastModifiedAt":"2025-09-26 15:38:53+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/4/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0003-guidelines_for_handling_bug_reports","title":"[Withdrawn] PEP 3 - Guidelines for Handling Bug Reports","excerpt":"Python Enhancement Proposal 3: 'Guidelines for Handling Bug Reports'에 대한 한국어 번역입니다.","date":"2025-09-26 15:37:46+0900","lastModifiedAt":"2025-09-26 15:37:46+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/3/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0002-procedure_for_adding_new_modules","title":"[Active] PEP 2 - Procedure for Adding New Modules","excerpt":"Python Enhancement Proposal 2: 'Procedure for Adding New Modules'에 대한 한국어 번역입니다.","date":"2025-09-26 15:36:38+0900","lastModifiedAt":"2025-09-26 15:36:38+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/2/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-09-26-pep-0001-pep_purpose_and_guidelines","title":"[Active] PEP 1 - PEP Purpose and Guidelines","excerpt":"Python Enhancement Proposal 1: 'PEP Purpose and Guidelines'에 대한 한국어 번역입니다.","date":"2025-09-26 15:31:21+0900","lastModifiedAt":"2025-09-26 15:31:21+0900","categories":["Python","PEP"],"tags":["Python","PEP","Translation"],"permalink":"/python/pep/1/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-26-When_Judgment_Becomes_Noise_How_Design_Failures_in_LLM_Judge_Benchmarks_Silently_Undermine_Validity","title":"[논문리뷰] When Judgment Becomes Noise: How Design Failures in LLM Judge Benchmarks Silently Undermine Validity","excerpt":"John P Dickerson이 [arXiv]에 게시한 'When Judgment Becomes Noise: How Design Failures in LLM Judge Benchmarks Silently Undermine Validity' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-26 13:35:32+0900","lastModifiedAt":"2025-09-26 13:35:32+0900","categories":["Review"],"tags":["Review","LLM Judge","Benchmark Evaluation","Validity","Reliability","Psychometrics","Factor Analysis","Schema Adherence","ELO Ranking"],"permalink":"/ai/review/2025-9-26-When_Judgment_Becomes_Noise_How_Design_Failures_in_LLM_Judge_Benchmarks_Silently_Undermine_Validity/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-26-VCRL_Variance-based_Curriculum_Reinforcement_Learning_for_Large_Language_Models","title":"[논문리뷰] VCRL: Variance-based Curriculum Reinforcement Learning for Large Language Models","excerpt":"Yuewei Zhang이 [arXiv]에 게시한 'VCRL: Variance-based Curriculum Reinforcement Learning for Large Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-26 13:35:32+0900","lastModifiedAt":"2025-09-26 13:35:32+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","Curriculum Learning","Large Language Models","Mathematical Reasoning","Variance-based Sampling","Replay Learning","Policy Optimization"],"permalink":"/ai/review/2025-9-26-VCRL_Variance-based_Curriculum_Reinforcement_Learning_for_Large_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-26-V-GameGym_Visual_Game_Generation_for_Code_Large_Language_Models","title":"[논문리뷰] V-GameGym: Visual Game Generation for Code Large Language Models","excerpt":"Shawn Guo이 [arXiv]에 게시한 'V-GameGym: Visual Game Generation for Code Large Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-26 13:35:32+0900","lastModifiedAt":"2025-09-26 13:35:32+0900","categories":["Review"],"tags":["Review","Code Large Language Models","Visual Game Generation","Benchmark","Pygame","Multimodal Evaluation","Software Engineering","AI-assisted Game Development"],"permalink":"/ai/review/2025-9-26-V-GameGym_Visual_Game_Generation_for_Code_Large_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-26-Understanding_the_Thinking_Process_of_Reasoning_Models_A_Perspective_from_Schoenfelds_Episode_Theory","title":"[논문리뷰] Understanding the Thinking Process of Reasoning Models: A Perspective from Schoenfeld's Episode Theory","excerpt":"Yanbin Fu이 [arXiv]에 게시한 'Understanding the Thinking Process of Reasoning Models: A Perspective from Schoenfeld's Episode Theory' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-26 13:35:32+0900","lastModifiedAt":"2025-09-26 13:35:32+0900","categories":["Review"],"tags":["Review","Large Reasoning Models","Cognitive Science","Schoenfeld's Episode Theory","Math Problem Solving","Chain-of-Thought","Behavioral Analysis","Dataset Annotation"],"permalink":"/ai/review/2025-9-26-Understanding_the_Thinking_Process_of_Reasoning_Models_A_Perspective_from_Schoenfelds_Episode_Theory/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-26-TrustJudge_Inconsistencies_of_LLM-as-a-Judge_and_How_to_Alleviate_Them","title":"[논문리뷰] TrustJudge: Inconsistencies of LLM-as-a-Judge and How to Alleviate Them","excerpt":"Zhuohao Yu이 [arXiv]에 게시한 'TrustJudge: Inconsistencies of LLM-as-a-Judge and How to Alleviate Them' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-26 13:35:32+0900","lastModifiedAt":"2025-09-26 13:35:32+0900","categories":["Review"],"tags":["Review","LLM-as-a-Judge","Evaluation Frameworks","Inconsistency Reduction","Probabilistic Scoring","Transitivity","Information Loss","Perplexity","Large Language Models"],"permalink":"/ai/review/2025-9-26-TrustJudge_Inconsistencies_of_LLM-as-a-Judge_and_How_to_Alleviate_Them/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-26-Tree_Search_for_LLM_Agent_Reinforcement_Learning","title":"[논문리뷰] Tree Search for LLM Agent Reinforcement Learning","excerpt":"Xiangxiang Chu이 [arXiv]에 게시한 'Tree Search for LLM Agent Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-26 13:35:32+0900","lastModifiedAt":"2025-09-26 13:35:32+0900","categories":["Review"],"tags":["Review","LLM Agents","Reinforcement Learning","Tree Search","Policy Optimization","Preference Learning","Sparse Rewards","Multi-turn Tasks"],"permalink":"/ai/review/2025-9-26-Tree_Search_for_LLM_Agent_Reinforcement_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-26-Thinking_While_Listening_Simple_Test_Time_Scaling_For_Audio_Classification","title":"[논문리뷰] Thinking While Listening: Simple Test Time Scaling For Audio Classification","excerpt":"Mert Pilanci이 [arXiv]에 게시한 'Thinking While Listening: Simple Test Time Scaling For Audio Classification' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-26 13:35:32+0900","lastModifiedAt":"2025-09-26 13:35:32+0900","categories":["Review"],"tags":["Review","Audio Classification","Test-Time Scaling","Reasoning Traces","Large Language Models (LLMs)","Transformer Architectures","Zero-shot Reasoning","Computational Efficiency"],"permalink":"/ai/review/2025-9-26-Thinking_While_Listening_Simple_Test_Time_Scaling_For_Audio_Classification/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-26-Thinking_Augmented_Pre-training","title":"[논문리뷰] Thinking Augmented Pre-training","excerpt":"Furu Wei이 [arXiv]에 게시한 'Thinking Augmented Pre-training' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-26 13:35:32+0900","lastModifiedAt":"2025-09-26 13:35:32+0900","categories":["Review"],"tags":["Review","Large Language Models (LLMs)","Pre-training","Data Augmentation","Reasoning","Data Efficiency","Thinking Trajectories"],"permalink":"/ai/review/2025-9-26-Thinking_Augmented_Pre-training/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-26-The_Unanticipated_Asymmetry_Between_Perceptual_Optimization_and_Assessment","title":"[논문리뷰] The Unanticipated Asymmetry Between Perceptual Optimization and Assessment","excerpt":"Du Chen이 [arXiv]에 게시한 'The Unanticipated Asymmetry Between Perceptual Optimization and Assessment' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-26 13:35:32+0900","lastModifiedAt":"2025-09-26 13:35:32+0900","categories":["Review"],"tags":["Review","Perceptual Optimization","Image Quality Assessment (IQA)","Adversarial Training","Discriminators","Super-Resolution","Fidelity Metrics","Deep Learning"],"permalink":"/ai/review/2025-9-26-The_Unanticipated_Asymmetry_Between_Perceptual_Optimization_and_Assessment/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-26-StyleBench_Evaluating_thinking_styles_in_Large_Language_Models","title":"[논문리뷰] StyleBench: Evaluating thinking styles in Large Language Models","excerpt":"Javad Lavaei이 [arXiv]에 게시한 'StyleBench: Evaluating thinking styles in Large Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-26 13:35:32+0900","lastModifiedAt":"2025-09-26 13:35:32+0900","categories":["Review"],"tags":["Review","Large Language Models","Reasoning Strategies","Prompt Engineering","LLM Evaluation","Benchmark","Thinking Styles","Scaling Laws","Meta-Reasoning"],"permalink":"/ai/review/2025-9-26-StyleBench_Evaluating_thinking_styles_in_Large_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-26-Seedream_4.0_Toward_Next-generation_Multimodal_Image_Generation","title":"[논문리뷰] Seedream 4.0: Toward Next-generation Multimodal Image Generation","excerpt":"Yunpeng Chen이 [arXiv]에 게시한 'Seedream 4.0: Toward Next-generation Multimodal Image Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-26 13:35:32+0900","lastModifiedAt":"2025-09-26 13:35:32+0900","categories":["Review"],"tags":["Review","Multimodal Image Generation","Diffusion Transformer","VAE","Image Editing","Text-to-Image","Model Acceleration","Human Evaluation"],"permalink":"/ai/review/2025-9-26-Seedream_4.0_Toward_Next-generation_Multimodal_Image_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-26-SD3.5-Flash_Distribution-Guided_Distillation_of_Generative_Flows","title":"[논문리뷰] SD3.5-Flash: Distribution-Guided Distillation of Generative Flows","excerpt":"Yi-Zhe Song이 [arXiv]에 게시한 'SD3.5-Flash: Distribution-Guided Distillation of Generative Flows' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-26 13:35:32+0900","lastModifiedAt":"2025-09-26 13:35:32+0900","categories":["Review"],"tags":["Review","Generative AI","Image Generation","Diffusion Models","Rectified Flow","Model Distillation","Few-Step Generation","Computational Efficiency","Prompt Alignment"],"permalink":"/ai/review/2025-9-26-SD3.5-Flash_Distribution-Guided_Distillation_of_Generative_Flows/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-26-SciReasoner_Laying_the_Scientific_Reasoning_Ground_Across_Disciplines","title":"[논문리뷰] SciReasoner: Laying the Scientific Reasoning Ground Across Disciplines","excerpt":"Jiabei Xiao이 [arXiv]에 게시한 'SciReasoner: Laying the Scientific Reasoning Ground Across Disciplines' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-26 13:35:32+0900","lastModifiedAt":"2025-09-26 13:35:32+0900","categories":["Review"],"tags":["Review","Scientific Reasoning","Foundation Models","Multi-modal Learning","Cross-domain Generalization","Chain-of-Thought","Reinforcement Learning","Scientific Discovery","Molecular Design"],"permalink":"/ai/review/2025-9-26-SciReasoner_Laying_the_Scientific_Reasoning_Ground_Across_Disciplines/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-26-SceneWeaver_All-in-One_3D_Scene_Synthesis_with_an_Extensible_and_Self-Reflective_Agent","title":"[논문리뷰] SceneWeaver: All-in-One 3D Scene Synthesis with an Extensible and Self-Reflective Agent","excerpt":"Siyuan Huang이 [arXiv]에 게시한 'SceneWeaver: All-in-One 3D Scene Synthesis with an Extensible and Self-Reflective Agent' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-26 13:35:32+0900","lastModifiedAt":"2025-09-26 13:35:32+0900","categories":["Review"],"tags":["Review","3D Scene Synthesis","Agentic Framework","LLMs","Self-Reflection","Tool-Use","Physical Plausibility","Iterative Refinement","Embodied AI"],"permalink":"/ai/review/2025-9-26-SceneWeaver_All-in-One_3D_Scene_Synthesis_with_an_Extensible_and_Self-Reflective_Agent/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-26-ScaleDiff_Scaling_Difficult_Problems_for_Advanced_Mathematical_Reasoning","title":"[논문리뷰] ScaleDiff: Scaling Difficult Problems for Advanced Mathematical Reasoning","excerpt":"Yu Li이 [arXiv]에 게시한 'ScaleDiff: Scaling Difficult Problems for Advanced Mathematical Reasoning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-26 13:35:32+0900","lastModifiedAt":"2025-09-26 13:35:32+0900","categories":["Review"],"tags":["Review","Mathematical Reasoning","Large Reasoning Models (LRMs)","Difficulty Scaling","Data Augmentation","Supervised Fine-Tuning (SFT)","Problem Generation","Solution Distillation"],"permalink":"/ai/review/2025-9-26-ScaleDiff_Scaling_Difficult_Problems_for_Advanced_Mathematical_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-26-Residual_Off-Policy_RL_for_Finetuning_Behavior_Cloning_Policies","title":"[논문리뷰] Residual Off-Policy RL for Finetuning Behavior Cloning Policies","excerpt":"Pieter Abbeel이 [arXiv]에 게시한 'Residual Off-Policy RL for Finetuning Behavior Cloning Policies' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-26 13:35:32+0900","lastModifiedAt":"2025-09-26 13:35:32+0900","categories":["Review"],"tags":["Review","Reinforcement Learning (RL)","Behavior Cloning (BC)","Residual Learning","Off-Policy RL","Robot Manipulation","Real-World Robotics","High-DoF Systems","Sample Efficiency"],"permalink":"/ai/review/2025-9-26-Residual_Off-Policy_RL_for_Finetuning_Behavior_Cloning_Policies/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-26-Recon-Act_A_Self-Evolving_Multi-Agent_Browser-Use_System_via_Web_Reconnaissance_Tool_Generation_and_Task_Execution","title":"[논문리뷰] Recon-Act: A Self-Evolving Multi-Agent Browser-Use System via Web Reconnaissance, Tool Generation, and Task Execution","excerpt":"Jinjie Gu이 [arXiv]에 게시한 'Recon-Act: A Self-Evolving Multi-Agent Browser-Use System via Web Reconnaissance, Tool Generation, and Task Execution' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-26 13:35:32+0900","lastModifiedAt":"2025-09-26 13:35:32+0900","categories":["Review"],"tags":["Review","Multi-Agent System","Browser Automation","Web Reconnaissance","Tool Generation","Task Execution","Self-Evolving AI","LLM/VLM","VisualWebArena"],"permalink":"/ai/review/2025-9-26-Recon-Act_A_Self-Evolving_Multi-Agent_Browser-Use_System_via_Web_Reconnaissance_Tool_Generation_and_Task_Execution/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-26-Quantized_Visual_Geometry_Grounded_Transformer","title":"[논문리뷰] Quantized Visual Geometry Grounded Transformer","excerpt":"Yuqi Li이 [arXiv]에 게시한 'Quantized Visual Geometry Grounded Transformer' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-26 13:35:32+0900","lastModifiedAt":"2025-09-26 13:35:32+0900","categories":["Review"],"tags":["Review","Quantization","Post-Training Quantization","3D Reconstruction","Visual Transformer","Model Compression","Efficient Inference","Hadamard Rotation","Calibration Sampling"],"permalink":"/ai/review/2025-9-26-Quantized_Visual_Geometry_Grounded_Transformer/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-26-MOSS-ChatV_Reinforcement_Learning_with_Process_Reasoning_Reward_for_Video_Temporal_Reasoning","title":"[논문리뷰] MOSS-ChatV: Reinforcement Learning with Process Reasoning Reward for Video Temporal Reasoning","excerpt":"Junyan Zhang이 [arXiv]에 게시한 'MOSS-ChatV: Reinforcement Learning with Process Reasoning Reward for Video Temporal Reasoning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-26 13:35:32+0900","lastModifiedAt":"2025-09-26 13:35:32+0900","categories":["Review"],"tags":["Review","Video Temporal Reasoning","Reinforcement Learning","Process Supervision","Dynamic Time Warping","Multimodal Large Language Models","Video State Prediction","Reward Hacking"],"permalink":"/ai/review/2025-9-26-MOSS-ChatV_Reinforcement_Learning_with_Process_Reasoning_Reward_for_Video_Temporal_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-26-MMR1_Enhancing_Multimodal_Reasoning_with_Variance-Aware_Sampling_and_Open_Resources","title":"[논문리뷰] MMR1: Enhancing Multimodal Reasoning with Variance-Aware Sampling and Open Resources","excerpt":"Jing Wang이 [arXiv]에 게시한 'MMR1: Enhancing Multimodal Reasoning with Variance-Aware Sampling and Open Resources' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-26 13:35:32+0900","lastModifiedAt":"2025-09-26 13:35:32+0900","categories":["Review"],"tags":["Review","Multimodal Reasoning","Reinforcement Learning","Variance-Aware Sampling","Gradient Vanishing","Data Curation","Chain-of-Thought","GRPO"],"permalink":"/ai/review/2025-9-26-MMR1_Enhancing_Multimodal_Reasoning_with_Variance-Aware_Sampling_and_Open_Resources/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-26-MI-Fuse_Label_Fusion_for_Unsupervised_Domain_Adaptation_with_Closed-Source_Large-Audio_Language_Model","title":"[논문리뷰] MI-Fuse: Label Fusion for Unsupervised Domain Adaptation with Closed-Source Large-Audio Language Model","excerpt":"Hung-yi Lee이 [arXiv]에 게시한 'MI-Fuse: Label Fusion for Unsupervised Domain Adaptation with Closed-Source Large-Audio Language Model' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-26 13:35:32+0900","lastModifiedAt":"2025-09-26 13:35:32+0900","categories":["Review"],"tags":["Review","Speech Emotion Recognition","Source-Free Unsupervised Domain Adaptation","Large Audio-Language Models","Label Fusion","Mutual Information","API-Only Models","Domain Mismatch"],"permalink":"/ai/review/2025-9-26-MI-Fuse_Label_Fusion_for_Unsupervised_Domain_Adaptation_with_Closed-Source_Large-Audio_Language_Model/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-26-Interactive_Recommendation_Agent_with_Active_User_Commands","title":"[논문리뷰] Interactive Recommendation Agent with Active User Commands","excerpt":"Xueyang Feng이 [arXiv]에 게시한 'Interactive Recommendation Agent with Active User Commands' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-26 13:35:32+0900","lastModifiedAt":"2025-09-26 13:35:32+0900","categories":["Review"],"tags":["Review","Interactive Recommendation","Large Language Models","Multi-Agent System","Natural Language Processing","Knowledge Distillation","User Control"],"permalink":"/ai/review/2025-9-26-Interactive_Recommendation_Agent_with_Active_User_Commands/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-26-Hunyuan3D-Omni_A_Unified_Framework_for_Controllable_Generation_of_3D_Assets","title":"[논문리뷰] Hunyuan3D-Omni: A Unified Framework for Controllable Generation of 3D Assets","excerpt":"Bowen Zhang이 [arXiv]에 게시한 'Hunyuan3D-Omni: A Unified Framework for Controllable Generation of 3D Assets' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-26 13:35:32+0900","lastModifiedAt":"2025-09-26 13:35:32+0900","categories":["Review"],"tags":["Review","3D Generation","Controllable Generation","Multi-modal Conditioning","Diffusion Models","Point Clouds","Voxels","Bounding Boxes","Skeletons","Hunyuan3D"],"permalink":"/ai/review/2025-9-26-Hunyuan3D-Omni_A_Unified_Framework_for_Controllable_Generation_of_3D_Assets/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-26-Does_FLUX_Already_Know_How_to_Perform_Physically_Plausible_Image_Composition","title":"[논문리뷰] Does FLUX Already Know How to Perform Physically Plausible Image Composition?","excerpt":"Chen Zhao이 [arXiv]에 게시한 'Does FLUX Already Know How to Perform Physically Plausible Image Composition?' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-26 13:35:32+0900","lastModifiedAt":"2025-09-26 13:35:32+0900","categories":["Review"],"tags":["Review","Image Composition","Diffusion Models","Training-Free","Physically Plausible","FLUX","Adapter","Guidance","Benchmark"],"permalink":"/ai/review/2025-9-26-Does_FLUX_Already_Know_How_to_Perform_Physically_Plausible_Image_Composition/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-26-Discrete_Diffusion_for_Reflective_Vision-Language-Action_Models_in_Autonomous_Driving","title":"[논문리뷰] Discrete Diffusion for Reflective Vision-Language-Action Models in Autonomous Driving","excerpt":"Hang Zhao이 [arXiv]에 게시한 'Discrete Diffusion for Reflective Vision-Language-Action Models in Autonomous Driving' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-26 13:35:32+0900","lastModifiedAt":"2025-09-26 13:35:32+0900","categories":["Review"],"tags":["Review","Autonomous Driving","Vision-Language-Action Models","Discrete Diffusion","Reflection Mechanism","Trajectory Generation","Safety Constraints","Imitation Learning"],"permalink":"/ai/review/2025-9-26-Discrete_Diffusion_for_Reflective_Vision-Language-Action_Models_in_Autonomous_Driving/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-26-CHARM_Control-point-based_3D_Anime_Hairstyle_Auto-Regressive_Modeling","title":"[논문리뷰] CHARM: Control-point-based 3D Anime Hairstyle Auto-Regressive Modeling","excerpt":"Yushi Bai이 [arXiv]에 게시한 'CHARM: Control-point-based 3D Anime Hairstyle Auto-Regressive Modeling' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-26 13:35:32+0900","lastModifiedAt":"2025-09-26 13:35:32+0900","categories":["Review"],"tags":["Review","3D Anime Hairstyle","Autoregressive Modeling","Control Points","Parametric Representation","Transformer","Generative AI","Dataset (AnimeHair)","Computer Graphics"],"permalink":"/ai/review/2025-9-26-CHARM_Control-point-based_3D_Anime_Hairstyle_Auto-Regressive_Modeling/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-26-CE-GPPO_Controlling_Entropy_via_Gradient-Preserving_Clipping_Policy_Optimization_in_Reinforcement_Learning","title":"[논문리뷰] CE-GPPO: Controlling Entropy via Gradient-Preserving Clipping Policy Optimization in Reinforcement Learning","excerpt":"Wenping Hu이 [arXiv]에 게시한 'CE-GPPO: Controlling Entropy via Gradient-Preserving Clipping Policy Optimization in Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-26 13:35:32+0900","lastModifiedAt":"2025-09-26 13:35:32+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","Large Language Models","Policy Optimization","PPO","Entropy Control","Gradient Clipping","Exploration-Exploitation"],"permalink":"/ai/review/2025-9-26-CE-GPPO_Controlling_Entropy_via_Gradient-Preserving_Clipping_Policy_Optimization_in_Reinforcement_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-26-Blueprints_of_Trust_AI_System_Cards_for_End_to_End_Transparency_and_Governance","title":"[논문리뷰] Blueprints of Trust: AI System Cards for End to End Transparency and Governance","excerpt":"Roman Zhukov이 [arXiv]에 게시한 'Blueprints of Trust: AI System Cards for End to End Transparency and Governance' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-26 13:35:32+0900","lastModifiedAt":"2025-09-26 13:35:32+0900","categories":["Review"],"tags":["Review","AI Governance","Transparency","AI System Card","Hazard-Aware System Card","Data Provenance","AI Safety","AI Risk Management","ISO/IEC 42001"],"permalink":"/ai/review/2025-9-26-Blueprints_of_Trust_AI_System_Cards_for_End_to_End_Transparency_and_Governance/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-26-BESPOKE_Benchmark_for_Search-Augmented_Large_Language_Model_Personalization_via_Diagnostic_Feedback","title":"[논문리뷰] BESPOKE: Benchmark for Search-Augmented Large Language Model Personalization via Diagnostic Feedback","excerpt":"Dongha Lee이 [arXiv]에 게시한 'BESPOKE: Benchmark for Search-Augmented Large Language Model Personalization via Diagnostic Feedback' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-26 13:35:32+0900","lastModifiedAt":"2025-09-26 13:35:32+0900","categories":["Review"],"tags":["Review","Search-Augmented LLMs","Personalization","Benchmark","Diagnostic Feedback","User History","Evaluation Framework","RAG"],"permalink":"/ai/review/2025-9-26-BESPOKE_Benchmark_for_Search-Augmented_Large_Language_Model_Personalization_via_Diagnostic_Feedback/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-26-Behind_RoPE_How_Does_Causal_Mask_Encode_Positional_Information","title":"[논문리뷰] Behind RoPE: How Does Causal Mask Encode Positional Information?","excerpt":"Yeyun Gong이 [arXiv]에 게시한 'Behind RoPE: How Does Causal Mask Encode Positional Information?' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-26 13:35:32+0900","lastModifiedAt":"2025-09-26 13:35:32+0900","categories":["Review"],"tags":["Review","Transformer Decoder","Causal Mask","Positional Encoding","RoPE","Attention Mechanism","Length Generalization","Large Language Models"],"permalink":"/ai/review/2025-9-26-Behind_RoPE_How_Does_Causal_Mask_Encode_Positional_Information/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-26-AutoIntent_AutoML_for_Text_Classification","title":"[논문리뷰] AutoIntent: AutoML for Text Classification","excerpt":"Denis Kuznetsov이 [arXiv]에 게시한 'AutoIntent: AutoML for Text Classification' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-26 13:35:32+0900","lastModifiedAt":"2025-09-26 13:35:32+0900","categories":["Review"],"tags":["Review","AutoML","Text Classification","Intent Classification","Transformer Embeddings","Out-of-Scope Detection","Multi-label Classification","Few-shot Learning","Sklearn-like Interface"],"permalink":"/ai/review/2025-9-26-AutoIntent_AutoML_for_Text_Classification/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-25-Video_models_are_zero-shot_learners_and_reasoners","title":"[논문리뷰] Video models are zero-shot learners and reasoners","excerpt":"rgeirhos이 [arXiv]에 게시한 'Video models are zero-shot learners and reasoners' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-25 13:08:16+0900","lastModifiedAt":"2025-09-25 13:08:16+0900","categories":["Review"],"tags":["Review","Video Models","Zero-shot Learning","Visual Reasoning","Foundation Models","Generative AI","Perception","Manipulation","Modeling"],"permalink":"/ai/review/2025-9-25-Video_models_are_zero-shot_learners_and_reasoners/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-25-SIM-CoT_Supervised_Implicit_Chain-of-Thought","title":"[논문리뷰] SIM-CoT: Supervised Implicit Chain-of-Thought","excerpt":"Yuhang Cao이 [arXiv]에 게시한 'SIM-CoT: Supervised Implicit Chain-of-Thought' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-25 13:08:16+0900","lastModifiedAt":"2025-09-25 13:08:16+0900","categories":["Review"],"tags":["Review","Implicit Reasoning","Chain-of-Thought","LLM","Latent Space","Supervised Learning","Model Stability","Interpretability"],"permalink":"/ai/review/2025-9-25-SIM-CoT_Supervised_Implicit_Chain-of-Thought/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-25-PhysCtrl_Generative_Physics_for_Controllable_and_Physics-Grounded_Video_Generation","title":"[논문리뷰] PhysCtrl: Generative Physics for Controllable and Physics-Grounded Video Generation","excerpt":"Yiming Huang이 [arXiv]에 게시한 'PhysCtrl: Generative Physics for Controllable and Physics-Grounded Video Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-25 13:08:16+0900","lastModifiedAt":"2025-09-25 13:08:16+0900","categories":["Review"],"tags":["Review","Video Generation","Physics-Grounded","Controllable Generation","Diffusion Models","Point Cloud Trajectories","Material Simulation","Generative Physics"],"permalink":"/ai/review/2025-9-25-PhysCtrl_Generative_Physics_for_Controllable_and_Physics-Grounded_Video_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-25-On_the_Use_of_Agentic_Coding_An_Empirical_Study_of_Pull_Requests_on_GitHub","title":"[논문리뷰] On the Use of Agentic Coding: An Empirical Study of Pull Requests on GitHub","excerpt":"Hajimu Iida이 [arXiv]에 게시한 'On the Use of Agentic Coding: An Empirical Study of Pull Requests on GitHub' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-25 13:08:16+0900","lastModifiedAt":"2025-09-25 13:08:16+0900","categories":["Review"],"tags":["Review","Agentic Coding","AI Agents","Large Language Models","GitHub Pull Requests","Software Engineering","Empirical Study","Code Generation","Software Development"],"permalink":"/ai/review/2025-9-25-On_the_Use_of_Agentic_Coding_An_Empirical_Study_of_Pull_Requests_on_GitHub/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-25-Logics-Parsing_Technical_Report","title":"[논문리뷰] Logics-Parsing Technical Report","excerpt":"Fan Yang이 [arXiv]에 게시한 'Logics-Parsing Technical Report' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-25 13:08:16+0900","lastModifiedAt":"2025-09-25 13:08:16+0900","categories":["Review"],"tags":["Review","Document Parsing","Large Vision-Language Models (LVLM)","Reinforcement Learning (RL)","Layout Analysis","Reading Order","Supervised Fine-Tuning (SFT)","HTML Annotation","Benchmarking"],"permalink":"/ai/review/2025-9-25-Logics-Parsing_Technical_Report/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-25-LLMs4All_A_Review_on_Large_Language_Models_for_Research_and_Applications_in_Academic_Disciplines","title":"[논문리뷰] LLMs4All: A Review on Large Language Models for Research and Applications in Academic Disciplines","excerpt":"Yanfang이 [arXiv]에 게시한 'LLMs4All: A Review on Large Language Models for Research and Applications in Academic Disciplines' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-25 13:08:16+0900","lastModifiedAt":"2025-09-25 13:08:16+0900","categories":["Review"],"tags":["Review","Large Language Models","Generative AI","Academic Disciplines","LLM Applications","Review","Cross-disciplinary Research","Benchmarks"],"permalink":"/ai/review/2025-9-25-LLMs4All_A_Review_on_Large_Language_Models_for_Research_and_Applications_in_Academic_Disciplines/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-25-Lavida-O_Elastic_Large_Masked_Diffusion_Models_for_Unified_Multimodal_Understanding_and_Generation","title":"[논문리뷰] Lavida-O: Elastic Large Masked Diffusion Models for Unified Multimodal Understanding and Generation","excerpt":"Zhe Lin이 [arXiv]에 게시한 'Lavida-O: Elastic Large Masked Diffusion Models for Unified Multimodal Understanding and Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-25 13:08:16+0900","lastModifiedAt":"2025-09-25 13:08:16+0900","categories":["Review"],"tags":["Review","Multimodal AI","Masked Diffusion Models","Image Understanding","Image Generation","Image Editing","Object Grounding","ElasticMoT","Self-reflection"],"permalink":"/ai/review/2025-9-25-Lavida-O_Elastic_Large_Masked_Diffusion_Models_for_Unified_Multimodal_Understanding_and_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-25-EmbeddingGemma_Powerful_and_Lightweight_Text_Representations","title":"[논문리뷰] EmbeddingGemma: Powerful and Lightweight Text Representations","excerpt":"Marksherwood이 [arXiv]에 게시한 'EmbeddingGemma: Powerful and Lightweight Text Representations' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-25 13:08:16+0900","lastModifiedAt":"2025-09-25 13:08:16+0900","categories":["Review"],"tags":["Review","Text Embeddings","Lightweight Models","Encoder-Decoder","Knowledge Distillation","Model Souping","Quantization","Multilingual","Gemma"],"permalink":"/ai/review/2025-9-25-EmbeddingGemma_Powerful_and_Lightweight_Text_Representations/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-25-EditVerse_Unifying_Image_and_Video_Editing_and_Generation_with_In-Context_Learning","title":"[논문리뷰] EditVerse: Unifying Image and Video Editing and Generation with In-Context Learning","excerpt":"Tianyu Wang이 [arXiv]에 게시한 'EditVerse: Unifying Image and Video Editing and Generation with In-Context Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-25 13:08:16+0900","lastModifiedAt":"2025-09-25 13:08:16+0900","categories":["Review"],"tags":["Review","Unified Multimodal Model","In-Context Learning","Image and Video Editing","Video Generation","Full Self-Attention","Rotary Positional Embedding","Cross-Modal Knowledge Transfer"],"permalink":"/ai/review/2025-9-25-EditVerse_Unifying_Image_and_Video_Editing_and_Generation_with_In-Context_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-25-Advancing_Speech_Understanding_in_Speech-Aware_Language_Models_with_GRPO","title":"[논문리뷰] Advancing Speech Understanding in Speech-Aware Language Models with GRPO","excerpt":"Avihu이 [arXiv]에 게시한 'Advancing Speech Understanding in Speech-Aware Language Models with GRPO' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-25 13:08:16+0900","lastModifiedAt":"2025-09-25 13:08:16+0900","categories":["Review"],"tags":["Review","Speech-Aware Language Models","SALLMs","GRPO","Reinforcement Learning","Speech Understanding","Spoken Question Answering","Automatic Speech Translation","BLEU Metric"],"permalink":"/ai/review/2025-9-25-Advancing_Speech_Understanding_in_Speech-Aware_Language_Models_with_GRPO/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-24-Zero-Shot_Multi-Spectral_Learning_Reimagining_a_Generalist_Multimodal_Gemini_2.5_Model_for_Remote_Sensing_Applications","title":"[논문리뷰] Zero-Shot Multi-Spectral Learning: Reimagining a Generalist Multimodal Gemini 2.5 Model for Remote Sensing Applications","excerpt":"Genady Beryozkin이 [arXiv]에 게시한 'Zero-Shot Multi-Spectral Learning: Reimagining a Generalist Multimodal Gemini 2.5 Model for Remote Sensing Applications' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-24 13:14:19+0900","lastModifiedAt":"2025-09-24 13:14:19+0900","categories":["Review"],"tags":["Review","Remote Sensing","Zero-Shot Learning","Multimodal Models","Multi-spectral Imagery","Gemini 2.5","Prompt Engineering","Land Cover Classification","Pseudo-Image"],"permalink":"/ai/review/2025-9-24-Zero-Shot_Multi-Spectral_Learning_Reimagining_a_Generalist_Multimodal_Gemini_2.5_Model_for_Remote_Sensing_Applications/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-24-What_Characterizes_Effective_Reasoning_Revisiting_Length_Review_and_Structure_of_CoT","title":"[논문리뷰] What Characterizes Effective Reasoning? Revisiting Length, Review, and Structure of CoT","excerpt":"Anthony Hartshorn이 [arXiv]에 게시한 'What Characterizes Effective Reasoning? Revisiting Length, Review, and Structure of CoT' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-24 13:14:19+0900","lastModifiedAt":"2025-09-24 13:14:19+0900","categories":["Review"],"tags":["Review","Chain-of-Thought","Reasoning Effectiveness","Large Reasoning Models","Failed-Step Fraction","Test-time Scaling","Reasoning Graph","Model Evaluation"],"permalink":"/ai/review/2025-9-24-What_Characterizes_Effective_Reasoning_Revisiting_Length_Review_and_Structure_of_CoT/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-24-VolSplat_Rethinking_Feed-Forward_3D_Gaussian_Splatting_with_Voxel-Aligned_Prediction","title":"[논문리뷰] VolSplat: Rethinking Feed-Forward 3D Gaussian Splatting with Voxel-Aligned Prediction","excerpt":"Haoxiao Wang이 [arXiv]에 게시한 'VolSplat: Rethinking Feed-Forward 3D Gaussian Splatting with Voxel-Aligned Prediction' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-24 13:14:19+0900","lastModifiedAt":"2025-09-24 13:14:19+0900","categories":["Review"],"tags":["Review","3D Gaussian Splatting","Novel View Synthesis","Voxel-Aligned Prediction","Feed-Forward Reconstruction","Multi-View Consistency","Scene Representation","Computer Vision"],"permalink":"/ai/review/2025-9-24-VolSplat_Rethinking_Feed-Forward_3D_Gaussian_Splatting_with_Voxel-Aligned_Prediction/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-24-VIR-Bench_Evaluating_Geospatial_and_Temporal_Understanding_of_MLLMs_via_Travel_Video_Itinerary_Reconstruction","title":"[논문리뷰] VIR-Bench: Evaluating Geospatial and Temporal Understanding of MLLMs via Travel Video Itinerary Reconstruction","excerpt":"So Fukuda이 [arXiv]에 게시한 'VIR-Bench: Evaluating Geospatial and Temporal Understanding of MLLMs via Travel Video Itinerary Reconstruction' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-24 13:14:19+0900","lastModifiedAt":"2025-09-24 13:14:19+0900","categories":["Review"],"tags":["Review","Multimodal LLMs","Video Understanding","Geospatial Reasoning","Temporal Reasoning","Travel Itinerary Reconstruction","Benchmark","Agent System","VLOG"],"permalink":"/ai/review/2025-9-24-VIR-Bench_Evaluating_Geospatial_and_Temporal_Understanding_of_MLLMs_via_Travel_Video_Itinerary_Reconstruction/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-24-Reinforcement_Learning_on_Pre-Training_Data","title":"[논문리뷰] Reinforcement Learning on Pre-Training Data","excerpt":"Evander Yang이 [arXiv]에 게시한 'Reinforcement Learning on Pre-Training Data' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-24 13:14:19+0900","lastModifiedAt":"2025-09-24 13:14:19+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","Pre-training","Large Language Models","Self-supervised Learning","Scaling Laws","Next-segment Reasoning","Reward Modeling"],"permalink":"/ai/review/2025-9-24-Reinforcement_Learning_on_Pre-Training_Data/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-24-OpenGVL_-_Benchmarking_Visual_Temporal_Progress_for_Data_Curation","title":"[논문리뷰] OpenGVL - Benchmarking Visual Temporal Progress for Data Curation","excerpt":"Viktor Petrenko이 [arXiv]에 게시한 'OpenGVL - Benchmarking Visual Temporal Progress for Data Curation' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-24 13:14:19+0900","lastModifiedAt":"2025-09-24 13:14:19+0900","categories":["Review"],"tags":["Review","Robotics Data Curation","Visual Temporal Progress","Generative Value Learning (GVL)","Vision-Language Models (VLMs)","Benchmark","Task Progress Prediction","Value-Order Correlation (VOC)"],"permalink":"/ai/review/2025-9-24-OpenGVL_-_Benchmarking_Visual_Temporal_Progress_for_Data_Curation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-24-MiniCPM-V_4.5_Cooking_Efficient_MLLMs_via_Architecture_Data_and_Training_Recipe","title":"[논문리뷰] MiniCPM-V 4.5: Cooking Efficient MLLMs via Architecture, Data, and Training Recipe","excerpt":"Wenshuo Ma이 [arXiv]에 게시한 'MiniCPM-V 4.5: Cooking Efficient MLLMs via Architecture, Data, and Training Recipe' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-24 13:14:19+0900","lastModifiedAt":"2025-09-24 13:14:19+0900","categories":["Review"],"tags":["Review","MLLM Efficiency","Multimodal Transformer","3D-Resampler","Document AI","Hybrid Reinforcement Learning","Video Understanding","Efficient Inference"],"permalink":"/ai/review/2025-9-24-MiniCPM-V_4.5_Cooking_Efficient_MLLMs_via_Architecture_Data_and_Training_Recipe/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-24-MAPO_Mixed_Advantage_Policy_Optimization","title":"[논문리뷰] MAPO: Mixed Advantage Policy Optimization","excerpt":"Xuankun Rong이 [arXiv]에 게시한 'MAPO: Mixed Advantage Policy Optimization' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-24 13:14:19+0900","lastModifiedAt":"2025-09-24 13:14:19+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","Foundation Models","Policy Optimization","Advantage Function","Trajectory Certainty","Multimodal Reasoning","GRPO"],"permalink":"/ai/review/2025-9-24-MAPO_Mixed_Advantage_Policy_Optimization/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-24-Lyra_Generative_3D_Scene_Reconstruction_via_Video_Diffusion_Model_Self-Distillation","title":"[논문리뷰] Lyra: Generative 3D Scene Reconstruction via Video Diffusion Model Self-Distillation","excerpt":"Yifeng Jiang이 [arXiv]에 게시한 'Lyra: Generative 3D Scene Reconstruction via Video Diffusion Model Self-Distillation' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-24 13:14:19+0900","lastModifiedAt":"2025-09-24 13:14:19+0900","categories":["Review"],"tags":["Review","Generative AI","3D Scene Reconstruction","Video Diffusion Models","Self-Distillation","3D Gaussian Splatting","Dynamic 4D Generation","Monocular Input"],"permalink":"/ai/review/2025-9-24-Lyra_Generative_3D_Scene_Reconstruction_via_Video_Diffusion_Model_Self-Distillation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-24-Large_Language_Models_Discriminate_Against_Speakers_of_German_Dialects","title":"[논문리뷰] Large Language Models Discriminate Against Speakers of German Dialects","excerpt":"Katharina von der Wense이 [arXiv]에 게시한 'Large Language Models Discriminate Against Speakers of German Dialects' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-24 13:14:19+0900","lastModifiedAt":"2025-09-24 13:14:19+0900","categories":["Review"],"tags":["Review","Large Language Models","Bias","German Dialects","Sociolinguistics","Stereotypes","Implicit Association Test","Decision Making"],"permalink":"/ai/review/2025-9-24-Large_Language_Models_Discriminate_Against_Speakers_of_German_Dialects/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-24-HyRF_Hybrid_Radiance_Fields_for_Memory-efficient_and_High-quality_Novel_View_Synthesis","title":"[논문리뷰] HyRF: Hybrid Radiance Fields for Memory-efficient and High-quality Novel View Synthesis","excerpt":"Dan Xu이 [arXiv]에 게시한 'HyRF: Hybrid Radiance Fields for Memory-efficient and High-quality Novel View Synthesis' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-24 13:14:19+0900","lastModifiedAt":"2025-09-24 13:14:19+0900","categories":["Review"],"tags":["Review","Novel View Synthesis","3D Gaussian Splatting (3DGS)","Neural Radiance Fields (NeRF)","Memory Efficiency","High-Quality Rendering","Hybrid Representation","Real-time Rendering"],"permalink":"/ai/review/2025-9-24-HyRF_Hybrid_Radiance_Fields_for_Memory-efficient_and_High-quality_Novel_View_Synthesis/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-24-Hyper-Bagel_A_Unified_Acceleration_Framework_for_Multimodal_Understanding_and_Generation","title":"[논문리뷰] Hyper-Bagel: A Unified Acceleration Framework for Multimodal Understanding and Generation","excerpt":"Jianbin Zheng이 [arXiv]에 게시한 'Hyper-Bagel: A Unified Acceleration Framework for Multimodal Understanding and Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-24 13:14:19+0900","lastModifiedAt":"2025-09-24 13:14:19+0900","categories":["Review"],"tags":["Review","Multimodal AI","Acceleration Framework","Speculative Decoding","Diffusion Distillation","Unified Models","Text-to-Image Generation","Image Editing","Computational Efficiency"],"permalink":"/ai/review/2025-9-24-Hyper-Bagel_A_Unified_Acceleration_Framework_for_Multimodal_Understanding_and_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-24-GeoSVR_Taming_Sparse_Voxels_for_Geometrically_Accurate_Surface_Reconstruction","title":"[논문리뷰] GeoSVR: Taming Sparse Voxels for Geometrically Accurate Surface Reconstruction","excerpt":"Jin Zheng이 [arXiv]에 게시한 'GeoSVR: Taming Sparse Voxels for Geometrically Accurate Surface Reconstruction' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-24 13:14:19+0900","lastModifiedAt":"2025-09-24 13:14:19+0900","categories":["Review"],"tags":["Review","Surface Reconstruction","Sparse Voxels","Geometric Accuracy","Neural Radiance Fields","3D Gaussian Splatting","Monocular Depth","Voxel Uncertainty"],"permalink":"/ai/review/2025-9-24-GeoSVR_Taming_Sparse_Voxels_for_Geometrically_Accurate_Surface_Reconstruction/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-24-Do_You_Need_Proprioceptive_States_in_Visuomotor_Policies","title":"[논문리뷰] Do You Need Proprioceptive States in Visuomotor Policies?","excerpt":"Yushen Liang이 [arXiv]에 게시한 'Do You Need Proprioceptive States in Visuomotor Policies?' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-24 13:14:19+0900","lastModifiedAt":"2025-09-24 13:14:19+0900","categories":["Review"],"tags":["Review","Visuomotor Policies","Spatial Generalization","Imitation Learning","Proprioception","State-free Policies","Robot Manipulation","End-Effector Control","Data Efficiency"],"permalink":"/ai/review/2025-9-24-Do_You_Need_Proprioceptive_States_in_Visuomotor_Policies/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-24-CAR-Flow_Condition-Aware_Reparameterization_Aligns_Source_and_Target_for_Better_Flow_Matching","title":"[논문리뷰] CAR-Flow: Condition-Aware Reparameterization Aligns Source and Target for Better Flow Matching","excerpt":"Rui Qian이 [arXiv]에 게시한 'CAR-Flow: Condition-Aware Reparameterization Aligns Source and Target for Better Flow Matching' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-24 13:14:19+0900","lastModifiedAt":"2025-09-24 13:14:19+0900","categories":["Review"],"tags":["Review","Flow Matching","Conditional Generative Models","Reparameterization","Mode Collapse","Image Generation","Latent Space Alignment","Diffusion Models"],"permalink":"/ai/review/2025-9-24-CAR-Flow_Condition-Aware_Reparameterization_Aligns_Source_and_Target_for_Better_Flow_Matching/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-24-Baseer_A_Vision-Language_Model_for_Arabic_Document-to-Markdown_OCR","title":"[논문리뷰] Baseer: A Vision-Language Model for Arabic Document-to-Markdown OCR","excerpt":"Zeina Aldallal이 [arXiv]에 게시한 'Baseer: A Vision-Language Model for Arabic Document-to-Markdown OCR' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-24 13:14:19+0900","lastModifiedAt":"2025-09-24 13:14:19+0900","categories":["Review"],"tags":["Review","Arabic OCR","Vision-Language Model","Fine-tuning","Document Understanding","Markdown Conversion","Benchmark"],"permalink":"/ai/review/2025-9-24-Baseer_A_Vision-Language_Model_for_Arabic_Document-to-Markdown_OCR/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-23-When_Big_Models_Train_Small_Ones_Label-Free_Model_Parity_Alignment_for_Efficient_Visual_Question_Answering_using_Small_VLMs","title":"[논문리뷰] When Big Models Train Small Ones: Label-Free Model Parity Alignment for Efficient Visual Question Answering using Small VLMs","excerpt":"Anand Mishra이 [arXiv]에 게시한 'When Big Models Train Small Ones: Label-Free Model Parity Alignment for Efficient Visual Question Answering using Small VLMs' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-23 13:36:03+0900","lastModifiedAt":"2025-09-23 13:36:03+0900","categories":["Review"],"tags":["Review","VQA","Small VLMs","Large VLMs","Knowledge Transfer","Pseudo-labeling","Label-Free Learning","Model Parity Alignment","Computational Efficiency"],"permalink":"/ai/review/2025-9-23-When_Big_Models_Train_Small_Ones_Label-Free_Model_Parity_Alignment_for_Efficient_Visual_Question_Answering_using_Small_VLMs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-23-VideoFrom3D_3D_Scene_Video_Generation_via_Complementary_Image_and_Video_Diffusion_Models","title":"[논문리뷰] VideoFrom3D: 3D Scene Video Generation via Complementary Image and Video Diffusion Models","excerpt":"Sunghyun Cho이 [arXiv]에 게시한 'VideoFrom3D: 3D Scene Video Generation via Complementary Image and Video Diffusion Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-23 13:36:03+0900","lastModifiedAt":"2025-09-23 13:36:03+0900","categories":["Review"],"tags":["Review","3D Scene Generation","Video Diffusion","Image Diffusion","Generative Models","Computer Graphics","Temporal Consistency","Sparse Anchor Views"],"permalink":"/ai/review/2025-9-23-VideoFrom3D_3D_Scene_Video_Generation_via_Complementary_Image_and_Video_Diffusion_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-23-VaseVQA_Multimodal_Agent_and_Benchmark_for_Ancient_Greek_Pottery","title":"[논문리뷰] VaseVQA: Multimodal Agent and Benchmark for Ancient Greek Pottery","excerpt":"Shiya Huang이 [arXiv]에 게시한 'VaseVQA: Multimodal Agent and Benchmark for Ancient Greek Pottery' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-23 13:36:03+0900","lastModifiedAt":"2025-09-23 13:36:03+0900","categories":["Review"],"tags":["Review","Multimodal Large Language Models","Visual Question Answering","Reinforcement Learning","Cultural Heritage","Ancient Greek Pottery","Supervised Fine-Tuning","Benchmark"],"permalink":"/ai/review/2025-9-23-VaseVQA_Multimodal_Agent_and_Benchmark_for_Ancient_Greek_Pottery/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-23-Understanding_Embedding_Scaling_in_Collaborative_Filtering","title":"[논문리뷰] Understanding Embedding Scaling in Collaborative Filtering","excerpt":"Yonghui Yang이 [arXiv]에 게시한 'Understanding Embedding Scaling in Collaborative Filtering' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-23 13:36:03+0900","lastModifiedAt":"2025-09-23 13:36:03+0900","categories":["Review"],"tags":["Review","Collaborative Filtering","Embedding Scaling","Noise Robustness","Recommender Systems","Graph Neural Networks","Self-supervised Learning","Performance Degradation"],"permalink":"/ai/review/2025-9-23-Understanding_Embedding_Scaling_in_Collaborative_Filtering/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-23-Turk-LettuceDetect_A_Hallucination_Detection_Models_for_Turkish_RAG_Applications","title":"[논문리뷰] Turk-LettuceDetect: A Hallucination Detection Models for Turkish RAG Applications","excerpt":"Fatma Betül Terzioğlu이 [arXiv]에 게시한 'Turk-LettuceDetect: A Hallucination Detection Models for Turkish RAG Applications' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-23 13:36:03+0900","lastModifiedAt":"2025-09-23 13:36:03+0900","categories":["Review"],"tags":["Review","Hallucination Detection","Retrieval Augmented Generation","Large Language Models","Turkish NLP","Token Classification","ModernBERT","Low-Resource Languages"],"permalink":"/ai/review/2025-9-23-Turk-LettuceDetect_A_Hallucination_Detection_Models_for_Turkish_RAG_Applications/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-23-TempSamp-R1_Effective_Temporal_Sampling_with_Reinforcement_Fine-Tuning_for_Video_LLMs","title":"[논문리뷰] TempSamp-R1: Effective Temporal Sampling with Reinforcement Fine-Tuning for Video LLMs","excerpt":"Shaohui Jiao이 [arXiv]에 게시한 'TempSamp-R1: Effective Temporal Sampling with Reinforcement Fine-Tuning for Video LLMs' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-23 13:36:03+0900","lastModifiedAt":"2025-09-23 13:36:03+0900","categories":["Review"],"tags":["Review","Video LLMs","Temporal Grounding","Reinforcement Learning","Off-policy Learning","Reward Shaping","Chain-of-Thought","Multimodal LLMs"],"permalink":"/ai/review/2025-9-23-TempSamp-R1_Effective_Temporal_Sampling_with_Reinforcement_Fine-Tuning_for_Video_LLMs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-23-Synthetic_bootstrapped_pretraining","title":"[논문리뷰] Synthetic bootstrapped pretraining","excerpt":"Emmanuel Candès이 [arXiv]에 게시한 'Synthetic bootstrapped pretraining' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-23 13:36:03+0900","lastModifiedAt":"2025-09-23 13:36:03+0900","categories":["Review"],"tags":["Review","Language Model Pretraining","Synthetic Data","Inter-document Correlation","Data Augmentation","Transformer","Bootstrapping","Concept Learning"],"permalink":"/ai/review/2025-9-23-Synthetic_bootstrapped_pretraining/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-23-SWE-Bench_Pro_Can_AI_Agents_Solve_Long-Horizon_Software_Engineering_Tasks","title":"[논문리뷰] SWE-Bench Pro: Can AI Agents Solve Long-Horizon Software Engineering Tasks?","excerpt":"Yannis Yiming He이 [arXiv]에 게시한 'SWE-Bench Pro: Can AI Agents Solve Long-Horizon Software Engineering Tasks?' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-23 13:36:03+0900","lastModifiedAt":"2025-09-23 13:36:03+0900","categories":["Review"],"tags":["Review","AI Agents","Software Engineering","LLMs","Code Generation","Benchmark","Contamination Resistance","Long-Horizon Tasks","Enterprise Software"],"permalink":"/ai/review/2025-9-23-SWE-Bench_Pro_Can_AI_Agents_Solve_Long-Horizon_Software_Engineering_Tasks/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-23-SCAN_Self-Denoising_Monte_Carlo_Annotation_for_Robust_Process_Reward_Learning","title":"[논문리뷰] SCAN: Self-Denoising Monte Carlo Annotation for Robust Process Reward Learning","excerpt":"Zhaopeng Tu이 [arXiv]에 게시한 'SCAN: Self-Denoising Monte Carlo Annotation for Robust Process Reward Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-23 13:36:03+0900","lastModifiedAt":"2025-09-23 13:36:03+0900","categories":["Review"],"tags":["Review","Process Reward Models","Monte Carlo Annotation","Noise Denoising","Robust Learning","Self-Supervision","Mathematical Reasoning","Large Language Models"],"permalink":"/ai/review/2025-9-23-SCAN_Self-Denoising_Monte_Carlo_Annotation_for_Robust_Process_Reward_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-23-Reasoning_Core_A_Scalable_RL_Environment_for_LLM_Symbolic_Reasoning","title":"[논문리뷰] Reasoning Core: A Scalable RL Environment for LLM Symbolic Reasoning","excerpt":"Damien Sileo이 [arXiv]에 게시한 'Reasoning Core: A Scalable RL Environment for LLM Symbolic Reasoning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-23 13:36:03+0900","lastModifiedAt":"2025-09-23 13:36:03+0900","categories":["Review"],"tags":["Review","LLM Reasoning","Symbolic AI","Reinforcement Learning","Procedural Content Generation","Verifiable Rewards","Adaptive Curricula","First-Order Logic","PDDL Planning"],"permalink":"/ai/review/2025-9-23-Reasoning_Core_A_Scalable_RL_Environment_for_LLM_Symbolic_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-23-QWHA_Quantization-Aware_Walsh-Hadamard_Adaptation_for_Parameter-Efficient_Fine-Tuning_on_Large_Language_Models","title":"[논문리뷰] QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models","excerpt":"Jae-Joon Kim이 [arXiv]에 게시한 'QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-23 13:36:03+0900","lastModifiedAt":"2025-09-23 13:36:03+0900","categories":["Review"],"tags":["Review","LLM Fine-tuning","Quantization-Aware PEFT","Walsh-Hadamard Transform","Sparse Adaptation","Low-bit Quantization","Parameter-Efficient Learning"],"permalink":"/ai/review/2025-9-23-QWHA_Quantization-Aware_Walsh-Hadamard_Adaptation_for_Parameter-Efficient_Fine-Tuning_on_Large_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-23-Qwen3-Omni_Technical_Report","title":"[논문리뷰] Qwen3-Omni Technical Report","excerpt":"Lhma-aslp이 [arXiv]에 게시한 'Qwen3-Omni Technical Report' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-23 13:36:03+0900","lastModifiedAt":"2025-09-23 13:36:03+0900","categories":["Review"],"tags":["Review","Multimodal Model","Thinker-Talker Architecture","Mixture-of-Experts","Low-latency","Audio Understanding","Cross-modal Reasoning","State-of-the-Art","Real-time Interaction"],"permalink":"/ai/review/2025-9-23-Qwen3-Omni_Technical_Report/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-23-OmniInsert_Mask-Free_Video_Insertion_of_Any_Reference_via_Diffusion_Transformer_Models","title":"[논문리뷰] OmniInsert: Mask-Free Video Insertion of Any Reference via Diffusion Transformer Models","excerpt":"Pengze Zhang이 [arXiv]에 게시한 'OmniInsert: Mask-Free Video Insertion of Any Reference via Diffusion Transformer Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-23 13:36:03+0900","lastModifiedAt":"2025-09-23 13:36:03+0900","categories":["Review"],"tags":["Review","Video Insertion","Diffusion Models","Diffusion Transformers","Mask-Free","Data Augmentation","Progressive Training","Preference Optimization","Video Generation"],"permalink":"/ai/review/2025-9-23-OmniInsert_Mask-Free_Video_Insertion_of_Any_Reference_via_Diffusion_Transformer_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-23-MetaEmbed_Scaling_Multimodal_Retrieval_at_Test-Time_with_Flexible_Late_Interaction","title":"[논문리뷰] MetaEmbed: Scaling Multimodal Retrieval at Test-Time with Flexible Late Interaction","excerpt":"Xintao Chen이 [arXiv]에 게시한 'MetaEmbed: Scaling Multimodal Retrieval at Test-Time with Flexible Late Interaction' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-23 13:36:03+0900","lastModifiedAt":"2025-09-23 13:36:03+0900","categories":["Review"],"tags":["Review","Multimodal Retrieval","Late Interaction","Meta Tokens","Matryoshka Representation Learning","Test-Time Scaling","Vision-Language Models","Dense Retrieval","Efficiency"],"permalink":"/ai/review/2025-9-23-MetaEmbed_Scaling_Multimodal_Retrieval_at_Test-Time_with_Flexible_Late_Interaction/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-23-Mano_Report","title":"[논문리뷰] Mano Report","excerpt":"Minghui Wu이 [arXiv]에 게시한 'Mano Report' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-23 13:36:03+0900","lastModifiedAt":"2025-09-23 13:36:03+0900","categories":["Review"],"tags":["Review","GUI Agent","Multi-modal Foundation Model","Reinforcement Learning","Supervised Fine-tuning","Simulated Environment","Data Generation","Error Recovery","Web Automation"],"permalink":"/ai/review/2025-9-23-Mano_Report/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-23-LIMI_Less_is_More_for_Agency","title":"[논문리뷰] LIMI: Less is More for Agency","excerpt":"happyZYM이 [arXiv]에 게시한 'LIMI: Less is More for Agency' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-23 13:36:03+0900","lastModifiedAt":"2025-09-23 13:36:03+0900","categories":["Review"],"tags":["Review","AI Agency","Data Curation","Less Is More","Agentic Intelligence","Foundation Models","Evaluation Benchmark","Efficiency Principle","Large Language Models"],"permalink":"/ai/review/2025-9-23-LIMI_Less_is_More_for_Agency/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-23-GeoPQA_Bridging_the_Visual_Perception_Gap_in_MLLMs_for_Geometric_Reasoning","title":"[논문리뷰] GeoPQA: Bridging the Visual Perception Gap in MLLMs for Geometric Reasoning","excerpt":"Hou Pong Chan이 [arXiv]에 게시한 'GeoPQA: Bridging the Visual Perception Gap in MLLMs for Geometric Reasoning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-23 13:36:03+0900","lastModifiedAt":"2025-09-23 13:36:03+0900","categories":["Review"],"tags":["Review","Multimodal Large Language Models (MLLMs)","Geometric Reasoning","Visual Perception","Reinforcement Learning (RL)","Two-stage Training","GeoPQA Benchmark","Perceptual Bottleneck"],"permalink":"/ai/review/2025-9-23-GeoPQA_Bridging_the_Visual_Perception_Gap_in_MLLMs_for_Geometric_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-23-From_Uniform_to_Heterogeneous_Tailoring_Policy_Optimization_to_Every_Tokens_Nature","title":"[논문리뷰] From Uniform to Heterogeneous: Tailoring Policy Optimization to Every Token's Nature","excerpt":"Bin Cui이 [arXiv]에 게시한 'From Uniform to Heterogeneous: Tailoring Policy Optimization to Every Token's Nature' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-23 13:36:03+0900","lastModifiedAt":"2025-09-23 13:36:03+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","LLMs","Policy Optimization","Token Heterogeneity","Adaptive Sampling","Advantage Redistribution","Asymmetric Clipping","Entropy-based RL"],"permalink":"/ai/review/2025-9-23-From_Uniform_to_Heterogeneous_Tailoring_Policy_Optimization_to_Every_Tokens_Nature/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-23-From_Hugging_Face_to_GitHub_Tracing_License_Drift_in_the_Open-Source_AI_Ecosystem","title":"[논문리뷰] From Hugging Face to GitHub: Tracing License Drift in the Open-Source AI Ecosystem","excerpt":"Ahmed E. Hassan이 [arXiv]에 게시한 'From Hugging Face to GitHub: Tracing License Drift in the Open-Source AI Ecosystem' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-23 13:36:03+0900","lastModifiedAt":"2025-09-23 13:36:03+0900","categories":["Review"],"tags":["Review","Open-Source AI","License Compliance","License Drift","AI Supply Chain","Hugging Face","GitHub","LicenseRec","Legal Risk"],"permalink":"/ai/review/2025-9-23-From_Hugging_Face_to_GitHub_Tracing_License_Drift_in_the_Open-Source_AI_Ecosystem/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-23-FlagEval_Findings_Report_A_Preliminary_Evaluation_of_Large_Reasoning_Models_on_Automatically_Verifiable_Textual_and_Visual_Questions","title":"[논문리뷰] FlagEval Findings Report: A Preliminary Evaluation of Large Reasoning Models on Automatically Verifiable Textual and Visual Questions","excerpt":"tengdai722이 [arXiv]에 게시한 'FlagEval Findings Report: A Preliminary Evaluation of Large Reasoning Models on Automatically Verifiable Textual and Visual Questions' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-23 13:36:03+0900","lastModifiedAt":"2025-09-23 13:36:03+0900","categories":["Review"],"tags":["Review","Large Reasoning Models","LLM Evaluation","Multimodal AI","Reasoning Behaviors","Hallucination","Contamination-Free","AI Safety","Instruction Following"],"permalink":"/ai/review/2025-9-23-FlagEval_Findings_Report_A_Preliminary_Evaluation_of_Large_Reasoning_Models_on_Automatically_Verifiable_Textual_and_Visual_Questions/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-23-EpiCache_Episodic_KV_Cache_Management_for_Long_Conversational_Question_Answering","title":"[논문리뷰] EpiCache: Episodic KV Cache Management for Long Conversational Question Answering","excerpt":"Minsik Cho이 [arXiv]에 게시한 'EpiCache: Episodic KV Cache Management for Long Conversational Question Answering' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-23 13:36:03+0900","lastModifiedAt":"2025-09-23 13:36:03+0900","categories":["Review"],"tags":["Review","KV Cache Management","Long Conversational QA","LLMs","Memory Efficiency","Episodic Clustering","Block Prefill Eviction","Sensitivity-aware Allocation"],"permalink":"/ai/review/2025-9-23-EpiCache_Episodic_KV_Cache_Management_for_Long_Conversational_Question_Answering/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-23-DIWALI_-_Diversity_and_Inclusivity_aWare_cuLture_specific_Items_for_India_Dataset_and_Assessment_of_LLMs_for_Cultural_Text_Adaptation_in_Indian_Context","title":"[논문리뷰] DIWALI - Diversity and Inclusivity aWare cuLture specific Items for India: Dataset and Assessment of LLMs for Cultural Text Adaptation in Indian Context","excerpt":"Maunendra Sankar Desarkar이 [arXiv]에 게시한 'DIWALI - Diversity and Inclusivity aWare cuLture specific Items for India: Dataset and Assessment of LLMs for Cultural Text Adaptation in Indian Context' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-23 13:36:03+0900","lastModifiedAt":"2025-09-23 13:36:03+0900","categories":["Review"],"tags":["Review","Cultural Adaptation","Large Language Models","Indian Culture","Dataset Creation","CSI","Human Evaluation","LLM Evaluation","Cultural Bias"],"permalink":"/ai/review/2025-9-23-DIWALI_-_Diversity_and_Inclusivity_aWare_cuLture_specific_Items_for_India_Dataset_and_Assessment_of_LLMs_for_Cultural_Text_Adaptation_in_Indian_Context/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-23-DiffusionNFT_Online_Diffusion_Reinforcement_with_Forward_Process","title":"[논문리뷰] DiffusionNFT: Online Diffusion Reinforcement with Forward Process","excerpt":"Qinsheng Zhang이 [arXiv]에 게시한 'DiffusionNFT: Online Diffusion Reinforcement with Forward Process' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-23 13:36:03+0900","lastModifiedAt":"2025-09-23 13:36:03+0900","categories":["Review"],"tags":["Review","Diffusion Models","Reinforcement Learning","Online RL","Flow Matching","Forward Process","CFG-free","Image Generation","Negative-Aware FineTuning"],"permalink":"/ai/review/2025-9-23-DiffusionNFT_Online_Diffusion_Reinforcement_with_Forward_Process/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-23-Cross-Attention_is_Half_Explanation_in_Speech-to-Text_Models","title":"[논문리뷰] Cross-Attention is Half Explanation in Speech-to-Text Models","excerpt":"Luisa Bentivogli이 [arXiv]에 게시한 'Cross-Attention is Half Explanation in Speech-to-Text Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-23 13:36:03+0900","lastModifiedAt":"2025-09-23 13:36:03+0900","categories":["Review"],"tags":["Review","Cross-attention","Speech-to-Text (S2T)","Explainable AI (XAI)","Saliency Maps","Feature Attribution","Transformer","Context Mixing","Correlation"],"permalink":"/ai/review/2025-9-23-Cross-Attention_is_Half_Explanation_in_Speech-to-Text_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-23-ContextFlow_Training-Free_Video_Object_Editing_via_Adaptive_Context_Enrichment","title":"[논문리뷰] ContextFlow: Training-Free Video Object Editing via Adaptive Context Enrichment","excerpt":"Yue Ma이 [arXiv]에 게시한 'ContextFlow: Training-Free Video Object Editing via Adaptive Context Enrichment' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-23 13:36:03+0900","lastModifiedAt":"2025-09-23 13:36:03+0900","categories":["Review"],"tags":["Review","Video Object Editing","Training-Free","Diffusion Transformers","Rectified Flow","Adaptive Context Enrichment","Guidance Responsiveness","Temporal Consistency","Image-to-Video"],"permalink":"/ai/review/2025-9-23-ContextFlow_Training-Free_Video_Object_Editing_via_Adaptive_Context_Enrichment/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-23-CodeFuse-CR-Bench_A_Comprehensiveness-aware_Benchmark_for_End-to-End_Code_Review_Evaluation_in_Python_Projects","title":"[논문리뷰] CodeFuse-CR-Bench: A Comprehensiveness-aware Benchmark for End-to-End Code Review Evaluation in Python Projects","excerpt":"Hang Yu이 [arXiv]에 게시한 'CodeFuse-CR-Bench: A Comprehensiveness-aware Benchmark for End-to-End Code Review Evaluation in Python Projects' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-23 13:36:03+0900","lastModifiedAt":"2025-09-23 13:36:03+0900","categories":["Review"],"tags":["Review","Code Review","LLMs","Benchmark","Python Projects","End-to-End Evaluation","Context-Awareness","Software Engineering","LLM-as-a-Judge"],"permalink":"/ai/review/2025-9-23-CodeFuse-CR-Bench_A_Comprehensiveness-aware_Benchmark_for_End-to-End_Code_Review_Evaluation_in_Python_Projects/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-23-ByteWrist_A_Parallel_Robotic_Wrist_Enabling_Flexible_and_Anthropomorphic_Motion_for_Confined_Spaces","title":"[논문리뷰] ByteWrist: A Parallel Robotic Wrist Enabling Flexible and Anthropomorphic Motion for Confined Spaces","excerpt":"Jiafeng Xu이 [arXiv]에 게시한 'ByteWrist: A Parallel Robotic Wrist Enabling Flexible and Anthropomorphic Motion for Confined Spaces' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-23 13:36:03+0900","lastModifiedAt":"2025-09-23 13:36:03+0900","categories":["Review"],"tags":["Review","Robotics","Parallel Manipulator","Robotic Wrist","Confined Space Manipulation","Kinematics","Anthropomorphic Robot","Robot Design"],"permalink":"/ai/review/2025-9-23-ByteWrist_A_Parallel_Robotic_Wrist_Enabling_Flexible_and_Anthropomorphic_Motion_for_Confined_Spaces/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-23-AuditoryBench_Can_Language_Models_Understand_Auditory_Knowledge_without_Hearing","title":"[논문리뷰] AuditoryBench++: Can Language Models Understand Auditory Knowledge without Hearing?","excerpt":"Jaeho Lee이 [arXiv]에 게시한 'AuditoryBench++: Can Language Models Understand Auditory Knowledge without Hearing?' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-23 13:36:03+0900","lastModifiedAt":"2025-09-23 13:36:03+0900","categories":["Review"],"tags":["Review","Auditory Knowledge","Large Language Models","Multimodal Reasoning","Benchmark","Chain-of-Thought","Auditory Imagination","Text-only Reasoning"],"permalink":"/ai/review/2025-9-23-AuditoryBench_Can_Language_Models_Understand_Auditory_Knowledge_without_Hearing/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-23-ARE_Scaling_Up_Agent_Environments_and_Evaluations","title":"[논문리뷰] ARE: Scaling Up Agent Environments and Evaluations","excerpt":"Matteo Bettini이 [arXiv]에 게시한 'ARE: Scaling Up Agent Environments and Evaluations' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-23 13:36:03+0900","lastModifiedAt":"2025-09-23 13:36:03+0900","categories":["Review"],"tags":["Review","Agent Environments","Agent Evaluation","LLM Agents","Asynchronous Systems","Reinforcement Learning","Tool Use","Multi-agent Collaboration","Benchmark"],"permalink":"/ai/review/2025-9-23-ARE_Scaling_Up_Agent_Environments_and_Evaluations/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-23-Analyzing_the_Effects_of_Supervised_Fine-Tuning_on_Model_Knowledge_from_Token_and_Parameter_Levels","title":"[논문리뷰] Analyzing the Effects of Supervised Fine-Tuning on Model Knowledge from Token and Parameter Levels","excerpt":"Qi Zhang이 [arXiv]에 게시한 'Analyzing the Effects of Supervised Fine-Tuning on Model Knowledge from Token and Parameter Levels' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-23 13:36:03+0900","lastModifiedAt":"2025-09-23 13:36:03+0900","categories":["Review"],"tags":["Review","Supervised Fine-Tuning (SFT)","Large Language Models (LLMs)","Model Knowledge","Closed-Book Question Answering (CBQA)","Parameter Restoration","Kullback-Leibler Divergence","Knowledge Forgetting"],"permalink":"/ai/review/2025-9-23-Analyzing_the_Effects_of_Supervised_Fine-Tuning_on_Model_Knowledge_from_Token_and_Parameter_Levels/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-22-WhisTLE_Deeply_Supervised_Text-Only_Domain_Adaptation_for_Pretrained_Speech_Recognition_Transformers","title":"[논문리뷰] WhisTLE: Deeply Supervised, Text-Only Domain Adaptation for Pretrained Speech Recognition Transformers","excerpt":"Karun Kumar이 [arXiv]에 게시한 'WhisTLE: Deeply Supervised, Text-Only Domain Adaptation for Pretrained Speech Recognition Transformers' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-22 13:11:29+0900","lastModifiedAt":"2025-09-22 13:11:29+0900","categories":["Review"],"tags":["Review","ASR","Domain Adaptation","Text-Only Training","Transformer","Variational Autoencoder","Deep Supervision","Whisper","Encoder-Decoder Models"],"permalink":"/ai/review/2025-9-22-WhisTLE_Deeply_Supervised_Text-Only_Domain_Adaptation_for_Pretrained_Speech_Recognition_Transformers/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-22-Video2Roleplay_A_Multimodal_Dataset_and_Framework_for_Video-Guided_Role-playing_Agents","title":"[논문리뷰] Video2Roleplay: A Multimodal Dataset and Framework for Video-Guided Role-playing Agents","excerpt":"Chao Zhang이 [arXiv]에 게시한 'Video2Roleplay: A Multimodal Dataset and Framework for Video-Guided Role-playing Agents' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-22 13:11:29+0900","lastModifiedAt":"2025-09-22 13:11:29+0900","categories":["Review"],"tags":["Review","Role-playing Agents (RPAs)","Multimodal AI","Video Understanding","Large Language Models (LLMs)","Dataset Creation","Dynamic Role Profiles","Adaptive Temporal Sampling","Fine-tuning"],"permalink":"/ai/review/2025-9-22-Video2Roleplay_A_Multimodal_Dataset_and_Framework_for_Video-Guided_Role-playing_Agents/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-22-SPATIALGEN_Layout-guided_3D_Indoor_Scene_Generation","title":"[논문리뷰] SPATIALGEN: Layout-guided 3D Indoor Scene Generation","excerpt":"Yongsen Mao이 [arXiv]에 게시한 'SPATIALGEN: Layout-guided 3D Indoor Scene Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-22 13:11:29+0900","lastModifiedAt":"2025-09-22 13:11:29+0900","categories":["Review"],"tags":["Review","3D Scene Generation","Layout Guidance","Diffusion Models","Multi-view Synthesis","Synthetic Dataset","Indoor Environments","Gaussian Splatting","Semantic Consistency"],"permalink":"/ai/review/2025-9-22-SPATIALGEN_Layout-guided_3D_Indoor_Scene_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-22-RPG_A_Repository_Planning_Graph_for_Unified_and_Scalable_Codebase_Generation","title":"[논문리뷰] RPG: A Repository Planning Graph for Unified and Scalable Codebase Generation","excerpt":"Steven Liu이 [arXiv]에 게시한 'RPG: A Repository Planning Graph for Unified and Scalable Codebase Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-22 13:11:29+0900","lastModifiedAt":"2025-09-22 13:11:29+0900","categories":["Review"],"tags":["Review","Code Generation","LLMs","Repository Planning","Graph-based Representation","Software Engineering","Agent Frameworks","Scalable Codebase"],"permalink":"/ai/review/2025-9-22-RPG_A_Repository_Planning_Graph_for_Unified_and_Scalable_Codebase_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-22-RGB-Only_Supervised_Camera_Parameter_Optimization_in_Dynamic_Scenes","title":"[논문리뷰] RGB-Only Supervised Camera Parameter Optimization in Dynamic Scenes","excerpt":"Narendra Ahuja이 [arXiv]에 게시한 'RGB-Only Supervised Camera Parameter Optimization in Dynamic Scenes' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-22 13:11:29+0900","lastModifiedAt":"2025-09-22 13:11:29+0900","categories":["Review"],"tags":["Review","Camera Parameter Optimization","Dynamic Scenes","RGB-Only Supervision","Structure from Motion","Outlier Robustness","3D Gaussian Splatting","Two-stage Optimization","Point Tracking"],"permalink":"/ai/review/2025-9-22-RGB-Only_Supervised_Camera_Parameter_Optimization_in_Dynamic_Scenes/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-22-MANZANO_A_Simple_and_Scalable_Unified_Multimodal_Model_with_a_Hybrid_Vision_Tokenizer","title":"[논문리뷰] MANZANO: A Simple and Scalable Unified Multimodal Model with a Hybrid Vision Tokenizer","excerpt":"jialingt이 [arXiv]에 게시한 'MANZANO: A Simple and Scalable Unified Multimodal Model with a Hybrid Vision Tokenizer' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-22 13:11:29+0900","lastModifiedAt":"2025-09-22 13:11:29+0900","categories":["Review"],"tags":["Review","Multimodal LLM","Hybrid Tokenizer","Text-to-Image Generation","Visual Question Answering","Autoregressive Model","Diffusion Decoder","Unified Architecture","Model Scaling"],"permalink":"/ai/review/2025-9-22-MANZANO_A_Simple_and_Scalable_Unified_Multimodal_Model_with_a_Hybrid_Vision_Tokenizer/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-22-Lynx_Towards_High-Fidelity_Personalized_Video_Generation","title":"[논문리뷰] Lynx: Towards High-Fidelity Personalized Video Generation","excerpt":"Linjie Luo이 [arXiv]에 게시한 'Lynx: Towards High-Fidelity Personalized Video Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-22 13:11:29+0900","lastModifiedAt":"2025-09-22 13:11:29+0900","categories":["Review"],"tags":["Review","Personalized Video Generation","Diffusion Transformer","Identity Preservation","Video Synthesis","Adapter Networks","Facial Recognition","Cross-Attention"],"permalink":"/ai/review/2025-9-22-Lynx_Towards_High-Fidelity_Personalized_Video_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-22-Latent_Zoning_Network_A_Unified_Principle_for_Generative_Modeling_Representation_Learning_and_Classification","title":"[논문리뷰] Latent Zoning Network: A Unified Principle for Generative Modeling, Representation Learning, and Classification","excerpt":"Wenyu Wang이 [arXiv]에 게시한 'Latent Zoning Network: A Unified Principle for Generative Modeling, Representation Learning, and Classification' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-22 13:11:29+0900","lastModifiedAt":"2025-09-22 13:11:29+0900","categories":["Review"],"tags":["Review","Generative Modeling","Representation Learning","Classification","Unified Framework","Latent Space","Flow Matching","Deep Learning","Image Generation"],"permalink":"/ai/review/2025-9-22-Latent_Zoning_Network_A_Unified_Principle_for_Generative_Modeling_Representation_Learning_and_Classification/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-22-Do_You_Hear_What_I_Mean_Quantifying_the_Instruction-Perception_Gap_in_Instruction-Guided_Expressive_Text-To-Speech_Systems","title":"[논문리뷰] Do You Hear What I Mean? Quantifying the Instruction-Perception Gap in Instruction-Guided Expressive Text-To-Speech Systems","excerpt":"Hung-yi Lee이 [arXiv]에 게시한 'Do You Hear What I Mean? Quantifying the Instruction-Perception Gap in Instruction-Guided Expressive Text-To-Speech Systems' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-22 13:11:29+0900","lastModifiedAt":"2025-09-22 13:11:29+0900","categories":["Review"],"tags":["Review","Instruction-Guided TTS","Expressive Speech Synthesis","Human Perception","Subjective Evaluation","Controllability","Instruction Following","Evaluation Metrics"],"permalink":"/ai/review/2025-9-22-Do_You_Hear_What_I_Mean_Quantifying_the_Instruction-Perception_Gap_in_Instruction-Guided_Expressive_Text-To-Speech_Systems/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-22-BTL-UI_Blink-Think-Link_Reasoning_Model_for_GUI_Agent","title":"[논문리뷰] BTL-UI: Blink-Think-Link Reasoning Model for GUI Agent","excerpt":"Jiahui Yang이 [arXiv]에 게시한 'BTL-UI: Blink-Think-Link Reasoning Model for GUI Agent' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-22 13:11:29+0900","lastModifiedAt":"2025-09-22 13:11:29+0900","categories":["Review"],"tags":["Review","GUI Agent","Human-GUI Interaction","Cognitive Modeling","Reinforcement Learning","Multimodal Large Language Models","Attention Mechanisms","Action Planning"],"permalink":"/ai/review/2025-9-22-BTL-UI_Blink-Think-Link_Reasoning_Model_for_GUI_Agent/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-22-BaseReward_A_Strong_Baseline_for_Multimodal_Reward_Model","title":"[논문리뷰] BaseReward: A Strong Baseline for Multimodal Reward Model","excerpt":"jianfeipan이 [arXiv]에 게시한 'BaseReward: A Strong Baseline for Multimodal Reward Model' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-22 13:11:29+0900","lastModifiedAt":"2025-09-22 13:11:29+0900","categories":["Review"],"tags":["Review","Multimodal Reward Model","MLLM Alignment","RLHF","Reward Head Architecture","Data Curation","Ensemble Methods","BaseReward"],"permalink":"/ai/review/2025-9-22-BaseReward_A_Strong_Baseline_for_Multimodal_Reward_Model/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-22-A_Vision-Language-Action-Critic_Model_for_Robotic_Real-World_Reinforcement_Learning","title":"[논문리뷰] A Vision-Language-Action-Critic Model for Robotic Real-World Reinforcement Learning","excerpt":"Jiangmiao이 [arXiv]에 게시한 'A Vision-Language-Action-Critic Model for Robotic Real-World Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-22 13:11:29+0900","lastModifiedAt":"2025-09-22 13:11:29+0900","categories":["Review"],"tags":["Review","Robotics","Reinforcement Learning (RL)","Vision-Language-Action (VLA) Models","Reward Modeling","Human-in-the-Loop","Dense Rewards","Generalization","Autoregressive Models"],"permalink":"/ai/review/2025-9-22-A_Vision-Language-Action-Critic_Model_for_Robotic_Real-World_Reinforcement_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-22-Ask-to-Clarify_Resolving_Instruction_Ambiguity_through_Multi-turn_Dialogue","title":"[논문리뷰] Ask-to-Clarify: Resolving Instruction Ambiguity through Multi-turn Dialogue","excerpt":"Hui Zhang이 [arXiv]에 게시한 'Ask-to-Clarify: Resolving Instruction Ambiguity through Multi-turn Dialogue' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-22 13:11:29+0900","lastModifiedAt":"2025-09-22 13:11:29+0900","categories":["Review"],"tags":["Review","Embodied AI","Human-Robot Interaction","Multi-turn Dialogue","Instruction Following","Vision-Language Models","Diffusion Models","Ambiguity Resolution","Low-level Actions"],"permalink":"/ai/review/2025-9-22-Ask-to-Clarify_Resolving_Instruction_Ambiguity_through_Multi-turn_Dialogue/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-19-WorldForge_Unlocking_Emergent_3D4D_Generation_in_Video_Diffusion_Model_via_Training-Free_Guidance","title":"[논문리뷰] WorldForge: Unlocking Emergent 3D/4D Generation in Video Diffusion Model via Training-Free Guidance","excerpt":"Ruibo Li이 [arXiv]에 게시한 'WorldForge: Unlocking Emergent 3D/4D Generation in Video Diffusion Model via Training-Free Guidance' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-19 13:12:21+0900","lastModifiedAt":"2025-09-19 13:12:21+0900","categories":["Review"],"tags":["Review","Video Diffusion Models","3D/4D Generation","Training-Free Guidance","Camera Trajectory Control","Novel View Synthesis","Geometric Consistency","Inference-Time Optimization"],"permalink":"/ai/review/2025-9-19-WorldForge_Unlocking_Emergent_3D4D_Generation_in_Video_Diffusion_Model_via_Training-Free_Guidance/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-19-Unleashing_the_Potential_of_Multimodal_LLMs_for_Zero-Shot_Spatio-Temporal_Video_Grounding","title":"[논문리뷰] Unleashing the Potential of Multimodal LLMs for Zero-Shot Spatio-Temporal Video Grounding","excerpt":"Rynson W. H. Lau이 [arXiv]에 게시한 'Unleashing the Potential of Multimodal LLMs for Zero-Shot Spatio-Temporal Video Grounding' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-19 13:12:21+0900","lastModifiedAt":"2025-09-19 13:12:21+0900","categories":["Review"],"tags":["Review","Spatio-Temporal Video Grounding","Multimodal Large Language Models","Zero-Shot Learning","Visual Grounding","Decomposed Spatio-Temporal Highlighting","Logit-Guided Re-attention","Temporal-Augmented Assembling"],"permalink":"/ai/review/2025-9-19-Unleashing_the_Potential_of_Multimodal_LLMs_for_Zero-Shot_Spatio-Temporal_Video_Grounding/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-19-Understand_Before_You_Generate_Self-Guided_Training_for_Autoregressive_Image_Generation","title":"[논문리뷰] Understand Before You Generate: Self-Guided Training for Autoregressive Image Generation","excerpt":"Xihui Liu이 [arXiv]에 게시한 'Understand Before You Generate: Self-Guided Training for Autoregressive Image Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-19 13:12:21+0900","lastModifiedAt":"2025-09-19 13:12:21+0900","categories":["Review"],"tags":["Review","Autoregressive Models","Image Generation","Self-Supervised Learning","Visual Understanding","Masked Image Modeling","Contrastive Learning","Next-Token Prediction","LlamaGen"],"permalink":"/ai/review/2025-9-19-Understand_Before_You_Generate_Self-Guided_Training_for_Autoregressive_Image_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-19-ScaleCUA_Scaling_Open-Source_Computer_Use_Agents_with_Cross-Platform_Data","title":"[논문리뷰] ScaleCUA: Scaling Open-Source Computer Use Agents with Cross-Platform Data","excerpt":"Zehao Li이 [arXiv]에 게시한 'ScaleCUA: Scaling Open-Source Computer Use Agents with Cross-Platform Data' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-19 13:12:21+0900","lastModifiedAt":"2025-09-19 13:12:21+0900","categories":["Review"],"tags":["Review","Computer Use Agents","Vision-Language Models","Cross-Platform Data","GUI Automation","Data Scaling","Open-Source","Task Completion","GUI Grounding"],"permalink":"/ai/review/2025-9-19-ScaleCUA_Scaling_Open-Source_Computer_Use_Agents_with_Cross-Platform_Data/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-19-RynnVLA-001_Using_Human_Demonstrations_to_Improve_Robot_Manipulation","title":"[논문리뷰] RynnVLA-001: Using Human Demonstrations to Improve Robot Manipulation","excerpt":"SpaceProduct이 [arXiv]에 게시한 'RynnVLA-001: Using Human Demonstrations to Improve Robot Manipulation' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-19 13:12:21+0900","lastModifiedAt":"2025-09-19 13:12:21+0900","categories":["Review"],"tags":["Review","Vision-Language-Action (VLA) Model","Robot Manipulation","Human Demonstrations","Video Generative Pretraining","Ego-Centric Video","Trajectory Prediction","ActionVAE","Transformer"],"permalink":"/ai/review/2025-9-19-RynnVLA-001_Using_Human_Demonstrations_to_Improve_Robot_Manipulation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-19-RecoWorld_Building_Simulated_Environments_for_Agentic_Recommender_Systems","title":"[논문리뷰] RecoWorld: Building Simulated Environments for Agentic Recommender Systems","excerpt":"Mingyuan Wu이 [arXiv]에 게시한 'RecoWorld: Building Simulated Environments for Agentic Recommender Systems' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-19 13:12:21+0900","lastModifiedAt":"2025-09-19 13:12:21+0900","categories":["Review"],"tags":["Review","Agentic Recommender Systems","Simulated Environments","LLM-driven Simulation","Multi-turn Interaction","Reinforcement Learning","User Retention","Instruction Following","Multi-agent Systems"],"permalink":"/ai/review/2025-9-19-RecoWorld_Building_Simulated_Environments_for_Agentic_Recommender_Systems/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-19-Reasoning_over_Boundaries_Enhancing_Specification_Alignment_via_Test-time_Delibration","title":"[논문리뷰] Reasoning over Boundaries: Enhancing Specification Alignment via Test-time Delibration","excerpt":"Zhilin Wang이 [arXiv]에 게시한 'Reasoning over Boundaries: Enhancing Specification Alignment via Test-time Delibration' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-19 13:12:21+0900","lastModifiedAt":"2025-09-19 13:12:21+0900","categories":["Review"],"tags":["Review","LLMs","Specification Alignment","Test-Time Deliberation","Safety-Behavior Trade-off","ALIGN3","SPECBENCH","Prompt Engineering"],"permalink":"/ai/review/2025-9-19-Reasoning_over_Boundaries_Enhancing_Specification_Alignment_via_Test-time_Delibration/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-19-MultiEdit_Advancing_Instruction-based_Image_Editing_on_Diverse_and_Challenging_Tasks","title":"[논문리뷰] MultiEdit: Advancing Instruction-based Image Editing on Diverse and Challenging Tasks","excerpt":"Xijun Gu이 [arXiv]에 게시한 'MultiEdit: Advancing Instruction-based Image Editing on Diverse and Challenging Tasks' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-19 13:12:21+0900","lastModifiedAt":"2025-09-19 13:12:21+0900","categories":["Review"],"tags":["Review","Instruction-based Image Editing","Dataset","Multi-modal LLM","Image Generation","Style Transfer","Multi-task Learning","Fine-tuning"],"permalink":"/ai/review/2025-9-19-MultiEdit_Advancing_Instruction-based_Image_Editing_on_Diverse_and_Challenging_Tasks/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-19-Mind_the_Gap_A_Closer_Look_at_Tokenization_for_Multiple-Choice_Question_Answering_with_LLMs","title":"[논문리뷰] Mind the Gap: A Closer Look at Tokenization for Multiple-Choice Question Answering with LLMs","excerpt":"Katharina von der Wense이 [arXiv]에 게시한 'Mind the Gap: A Closer Look at Tokenization for Multiple-Choice Question Answering with LLMs' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-19 13:12:21+0900","lastModifiedAt":"2025-09-19 13:12:21+0900","categories":["Review"],"tags":["Review","LLM Evaluation","Multiple-Choice QA","Tokenization","Prompt Sensitivity","Accuracy","Calibration","Model Ranking"],"permalink":"/ai/review/2025-9-19-Mind_the_Gap_A_Closer_Look_at_Tokenization_for_Multiple-Choice_Question_Answering_with_LLMs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-19-FSG-Net_Frequency-Spatial_Synergistic_Gated_Network_for_High-Resolution_Remote_Sensing_Change_Detection","title":"[논문리뷰] FSG-Net: Frequency-Spatial Synergistic Gated Network for High-Resolution Remote Sensing Change Detection","excerpt":"Zhewei Zhang이 [arXiv]에 게시한 'FSG-Net: Frequency-Spatial Synergistic Gated Network for High-Resolution Remote Sensing Change Detection' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-19 13:12:21+0900","lastModifiedAt":"2025-09-19 13:12:21+0900","categories":["Review"],"tags":["Review","Change Detection","Remote Sensing","Frequency-Spatial Analysis","Wavelet Transform","Attention Mechanism","Gated Fusion","Deep Learning"],"permalink":"/ai/review/2025-9-19-FSG-Net_Frequency-Spatial_Synergistic_Gated_Network_for_High-Resolution_Remote_Sensing_Change_Detection/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-19-FlowRL_Matching_Reward_Distributions_for_LLM_Reasoning","title":"[논문리뷰] FlowRL: Matching Reward Distributions for LLM Reasoning","excerpt":"Hengli Li이 [arXiv]에 게시한 'FlowRL: Matching Reward Distributions for LLM Reasoning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-19 13:12:21+0900","lastModifiedAt":"2025-09-19 13:12:21+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","Large Language Models","Reward Distribution Matching","GFlowNets","Mode Collapse","Diverse Reasoning","Flow-Balanced Optimization"],"permalink":"/ai/review/2025-9-19-FlowRL_Matching_Reward_Distributions_for_LLM_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-19-FinSearchComp_Towards_a_Realistic_Expert-Level_Evaluation_of_Financial_Search_and_Reasoning","title":"[논문리뷰] FinSearchComp: Towards a Realistic, Expert-Level Evaluation of Financial Search and Reasoning","excerpt":"Jiashuo Liu이 [arXiv]에 게시한 'FinSearchComp: Towards a Realistic, Expert-Level Evaluation of Financial Search and Reasoning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-19 13:12:21+0900","lastModifiedAt":"2025-09-19 13:12:21+0900","categories":["Review"],"tags":["Review","Financial LLMs","Agent Benchmarking","Open-domain Search","Financial Reasoning","Time-Sensitive Data","Multi-hop QA","Tool Use"],"permalink":"/ai/review/2025-9-19-FinSearchComp_Towards_a_Realistic_Expert-Level_Evaluation_of_Financial_Search_and_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-19-Evolving_Language_Models_without_Labels_Majority_Drives_Selection_Novelty_Promotes_Variation","title":"[논문리뷰] Evolving Language Models without Labels: Majority Drives Selection, Novelty Promotes Variation","excerpt":"Kishan Panaganti이 [arXiv]에 게시한 'Evolving Language Models without Labels: Majority Drives Selection, Novelty Promotes Variation' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-19 13:12:21+0900","lastModifiedAt":"2025-09-19 13:12:21+0900","categories":["Review"],"tags":["Review","Label-free Reinforcement Learning","LLMs","Self-improvement","Entropy Collapse","Novelty Reward","Test-Time RL","GRPO","Evolutionary Computing Principles"],"permalink":"/ai/review/2025-9-19-Evolving_Language_Models_without_Labels_Majority_Drives_Selection_Novelty_Promotes_Variation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-19-EchoVLM_Dynamic_Mixture-of-Experts_Vision-Language_Model_for_Universal_Ultrasound_Intelligence","title":"[논문리뷰] EchoVLM: Dynamic Mixture-of-Experts Vision-Language Model for Universal Ultrasound Intelligence","excerpt":"Qinghua Huang이 [arXiv]에 게시한 'EchoVLM: Dynamic Mixture-of-Experts Vision-Language Model for Universal Ultrasound Intelligence' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-19 13:12:21+0900","lastModifiedAt":"2025-09-19 13:12:21+0900","categories":["Review"],"tags":["Review","Vision-Language Models","Ultrasound Imaging","Medical Diagnosis","Mixture-of-Experts (MoE)","Instruction Tuning","Multimodal AI","Report Generation","VQA"],"permalink":"/ai/review/2025-9-19-EchoVLM_Dynamic_Mixture-of-Experts_Vision-Language_Model_for_Universal_Ultrasound_Intelligence/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-19-AToken_A_Unified_Tokenizer_for_Vision","title":"[논문리뷰] AToken: A Unified Tokenizer for Vision","excerpt":"Mingze Xu이 [arXiv]에 게시한 'AToken: A Unified Tokenizer for Vision' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-19 13:12:21+0900","lastModifiedAt":"2025-09-19 13:12:21+0900","categories":["Review"],"tags":["Review","Unified Visual Tokenizer","Multimodal AI","Transformer Architecture","4D Representation","Adversarial-free Training","Reconstruction","Semantic Understanding","Generative Models"],"permalink":"/ai/review/2025-9-19-AToken_A_Unified_Tokenizer_for_Vision/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-18-Wan-Animate_Unified_Character_Animation_and_Replacement_with_Holistic_Replication","title":"[논문리뷰] Wan-Animate: Unified Character Animation and Replacement with Holistic Replication","excerpt":"Mingyang Huang이 [arXiv]에 게시한 'Wan-Animate: Unified Character Animation and Replacement with Holistic Replication' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-18 13:07:00+0900","lastModifiedAt":"2025-09-18 13:07:00+0900","categories":["Review"],"tags":["Review","Character Animation","Video Replacement","Diffusion Models","Transformer","DiT","Relighting LoRA","Holistic Replication","Open-Source"],"permalink":"/ai/review/2025-9-18-Wan-Animate_Unified_Character_Animation_and_Replacement_with_Holistic_Replication/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-18-THOR_Tool-Integrated_Hierarchical_Optimization_via_RL_for_Mathematical_Reasoning","title":"[논문리뷰] THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning","excerpt":"Yicheng Pan이 [arXiv]에 게시한 'THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-18 13:07:00+0900","lastModifiedAt":"2025-09-18 13:07:00+0900","categories":["Review"],"tags":["Review","Mathematical Reasoning","Tool-Integrated Reasoning","Reinforcement Learning","Hierarchical Optimization","Self-Correction","Large Language Models","Code Generation"],"permalink":"/ai/review/2025-9-18-THOR_Tool-Integrated_Hierarchical_Optimization_via_RL_for_Mathematical_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-18-SteeringControl_Holistic_Evaluation_of_Alignment_Steering_in_LLMs","title":"[논문리뷰] SteeringControl: Holistic Evaluation of Alignment Steering in LLMs","excerpt":"Zhun Wang이 [arXiv]에 게시한 'SteeringControl: Holistic Evaluation of Alignment Steering in LLMs' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-18 13:07:00+0900","lastModifiedAt":"2025-09-18 13:07:00+0900","categories":["Review"],"tags":["Review","LLM Alignment","Representation Steering","Benchmark","Behavioral Entanglement","Bias Mitigation","Harmful Generation","Hallucination Control","Modular Framework"],"permalink":"/ai/review/2025-9-18-SteeringControl_Holistic_Evaluation_of_Alignment_Steering_in_LLMs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-18-Scrub_It_Out_Erasing_Sensitive_Memorization_in_Code_Language_Models_via_Machine_Unlearning","title":"[논문리뷰] Scrub It Out! Erasing Sensitive Memorization in Code Language Models via Machine Unlearning","excerpt":"Zhou Yang이 [arXiv]에 게시한 'Scrub It Out! Erasing Sensitive Memorization in Code Language Models via Machine Unlearning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-18 13:07:00+0900","lastModifiedAt":"2025-09-18 13:07:00+0900","categories":["Review"],"tags":["Review","Code Language Models","Machine Unlearning","Sensitive Memorization","Privacy","Gradient Ascent","Model Utility","Code Generation"],"permalink":"/ai/review/2025-9-18-Scrub_It_Out_Erasing_Sensitive_Memorization_in_Code_Language_Models_via_Machine_Unlearning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-18-SAIL-VL2_Technical_Report","title":"[논문리뷰] SAIL-VL2 Technical Report","excerpt":"Zijian Kang이 [arXiv]에 게시한 'SAIL-VL2 Technical Report' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-18 13:07:00+0900","lastModifiedAt":"2025-09-18 13:07:00+0900","categories":["Review"],"tags":["Review","Vision-Language Model","Multimodal Understanding","Mixture-of-Experts","Progressive Training","Data Curation","Supervised Fine-tuning","Reinforcement Learning","SAIL-ViT"],"permalink":"/ai/review/2025-9-18-SAIL-VL2_Technical_Report/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-18-PANORAMA_The_Rise_of_Omnidirectional_Vision_in_the_Embodied_AI_Era","title":"[논문리뷰] PANORAMA: The Rise of Omnidirectional Vision in the Embodied AI Era","excerpt":"Zihao Dongfang이 [arXiv]에 게시한 'PANORAMA: The Rise of Omnidirectional Vision in the Embodied AI Era' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-18 13:07:00+0900","lastModifiedAt":"2025-09-18 13:07:00+0900","categories":["Review"],"tags":["Review","Omnidirectional Vision","Embodied AI","Panoramic Perception","Multi-modal Learning","Dataset Development","Robot Navigation","Spatial Reasoning","System Architecture"],"permalink":"/ai/review/2025-9-18-PANORAMA_The_Rise_of_Omnidirectional_Vision_in_the_Embodied_AI_Era/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-18-MARS2_2025_Challenge_on_Multimodal_Reasoning_Datasets_Methods_Results_Discussion_and_Outlook","title":"[논문리뷰] MARS2 2025 Challenge on Multimodal Reasoning: Datasets, Methods, Results, Discussion, and Outlook","excerpt":"Bowen Zhou이 [arXiv]에 게시한 'MARS2 2025 Challenge on Multimodal Reasoning: Datasets, Methods, Results, Discussion, and Outlook' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-18 13:07:00+0900","lastModifiedAt":"2025-09-18 13:07:00+0900","categories":["Review"],"tags":["Review","Multimodal Reasoning","Large Language Models (LLMs)","Multimodal Large Language Models (MLLMs)","Visual Grounding","Visual Question Answering","Advertisement Video Analysis","Real-world Scenarios","Challenge Benchmark"],"permalink":"/ai/review/2025-9-18-MARS2_2025_Challenge_on_Multimodal_Reasoning_Datasets_Methods_Results_Discussion_and_Outlook/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-18-Improving_Context_Fidelity_via_Native_Retrieval-Augmented_Reasoning","title":"[논문리뷰] Improving Context Fidelity via Native Retrieval-Augmented Reasoning","excerpt":"Xiangru Tang이 [arXiv]에 게시한 'Improving Context Fidelity via Native Retrieval-Augmented Reasoning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-18 13:07:00+0900","lastModifiedAt":"2025-09-18 13:07:00+0900","categories":["Review"],"tags":["Review","Context Fidelity","Retrieval-Augmented Generation (RAG)","Large Language Models (LLMs)","Reinforcement Learning (RL)","Supervised Fine-Tuning (SFT)","Hallucination","Question Answering","In-context Retrieval","Curriculum Learning"],"permalink":"/ai/review/2025-9-18-Improving_Context_Fidelity_via_Native_Retrieval-Augmented_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-18-Hala_Technical_Report_Building_Arabic-Centric_Instruction_Translation_Models_at_Scale","title":"[논문리뷰] Hala Technical Report: Building Arabic-Centric Instruction & Translation Models at Scale","excerpt":"Bernard Ghanem이 [arXiv]에 게시한 'Hala Technical Report: Building Arabic-Centric Instruction & Translation Models at Scale' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-18 13:07:00+0900","lastModifiedAt":"2025-09-18 13:07:00+0900","categories":["Review"],"tags":["Review","Arabic NLP","Instruction Tuning","Machine Translation","Large Language Models","FP8 Quantization","Data Bootstrapping","Model Merging","Language-Centric AI"],"permalink":"/ai/review/2025-9-18-Hala_Technical_Report_Building_Arabic-Centric_Instruction_Translation_Models_at_Scale/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-18-GenExam_A_Multidisciplinary_Text-to-Image_Exam","title":"[논문리뷰] GenExam: A Multidisciplinary Text-to-Image Exam","excerpt":"Yu Qiao이 [arXiv]에 게시한 'GenExam: A Multidisciplinary Text-to-Image Exam' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-18 13:07:00+0900","lastModifiedAt":"2025-09-18 13:07:00+0900","categories":["Review"],"tags":["Review","Text-to-Image Generation","Multidisciplinary","Benchmark","Evaluation","AGI","Reasoning","Scoring System","Visual Question Answering"],"permalink":"/ai/review/2025-9-18-GenExam_A_Multidisciplinary_Text-to-Image_Exam/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-17-WebWeaver_Structuring_Web-Scale_Evidence_with_Dynamic_Outlines_for_Open-Ended_Deep_Research","title":"[논문리뷰] WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for Open-Ended Deep Research","excerpt":"Houquan Zhou이 [arXiv]에 게시한 'WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for Open-Ended Deep Research' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-17 13:16:01+0900","lastModifiedAt":"2025-09-17 13:16:01+0900","categories":["Review"],"tags":["Review","Open-Ended Deep Research","LLM Agents","Dynamic Outline","Evidence Acquisition","Hierarchical Writing","Memory Bank","State-of-the-Art","Supervised Fine-Tuning"],"permalink":"/ai/review/2025-9-17-WebWeaver_Structuring_Web-Scale_Evidence_with_Dynamic_Outlines_for_Open-Ended_Deep_Research/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-17-WebSailor-V2_Bridging_the_Chasm_to_Proprietary_Agents_via_Synthetic_Data_and_Scalable_Reinforcement_Learning","title":"[논문리뷰] WebSailor-V2: Bridging the Chasm to Proprietary Agents via Synthetic Data and Scalable Reinforcement Learning","excerpt":"Huifeng Yin이 [arXiv]에 게시한 'WebSailor-V2: Bridging the Chasm to Proprietary Agents via Synthetic Data and Scalable Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-17 13:16:01+0900","lastModifiedAt":"2025-09-17 13:16:01+0900","categories":["Review"],"tags":["Review","Web Agents","Reinforcement Learning","Synthetic Data","Knowledge Graphs","LLMs","Supervised Fine-Tuning","Sim-to-Real Transfer","Agentic AI"],"permalink":"/ai/review/2025-9-17-WebSailor-V2_Bridging_the_Chasm_to_Proprietary_Agents_via_Synthetic_Data_and_Scalable_Reinforcement_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-17-WebResearcher_Unleashing_unbounded_reasoning_capability_in_Long-Horizon_Agents","title":"[논문리뷰] WebResearcher: Unleashing unbounded reasoning capability in Long-Horizon Agents","excerpt":"Wenbiao Yin이 [arXiv]에 게시한 'WebResearcher: Unleashing unbounded reasoning capability in Long-Horizon Agents' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-17 13:16:01+0900","lastModifiedAt":"2025-09-17 13:16:01+0900","categories":["Review"],"tags":["Review","Agentic AI","Deep Research","Iterative Reasoning","Long-Horizon Tasks","Context Management","Data Synthesis","Tool-Augmented LLMs","Markov Decision Process"],"permalink":"/ai/review/2025-9-17-WebResearcher_Unleashing_unbounded_reasoning_capability_in_Long-Horizon_Agents/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-17-Towards_General_Agentic_Intelligence_via_Environment_Scaling","title":"[논문리뷰] Towards General Agentic Intelligence via Environment Scaling","excerpt":"Guangyu Li이 [arXiv]에 게시한 'Towards General Agentic Intelligence via Environment Scaling' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-17 13:16:01+0900","lastModifiedAt":"2025-09-17 13:16:01+0900","categories":["Review"],"tags":["Review","Agentic AI","Environment Scaling","Function Calling","Tool Use","Large Language Models","Synthetic Data Generation","Supervised Fine-tuning"],"permalink":"/ai/review/2025-9-17-Towards_General_Agentic_Intelligence_via_Environment_Scaling/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-17-Single-stream_Policy_Optimization","title":"[논문리뷰] Single-stream Policy Optimization","excerpt":"Zihan Ding이 [arXiv]에 게시한 'Single-stream Policy Optimization' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-17 13:16:01+0900","lastModifiedAt":"2025-09-17 13:16:01+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","LLM Optimization","Policy Gradient","Variance Reduction","Adaptive Sampling","Scalability","Agentic Systems","RLVR"],"permalink":"/ai/review/2025-9-17-Single-stream_Policy_Optimization/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-17-Scaling_Agents_via_Continual_Pre-training","title":"[논문리뷰] Scaling Agents via Continual Pre-training","excerpt":"Guangyu Li이 [arXiv]에 게시한 'Scaling Agents via Continual Pre-training' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-17 13:16:01+0900","lastModifiedAt":"2025-09-17 13:16:01+0900","categories":["Review"],"tags":["Review","Agentic LLMs","Continual Pre-training","Deep Research Agents","Tool Use","Multi-step Reasoning","Data Synthesis","Scaling Laws"],"permalink":"/ai/review/2025-9-17-Scaling_Agents_via_Continual_Pre-training/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-17-ReSum_Unlocking_Long-Horizon_Search_Intelligence_via_Context_Summarization","title":"[논문리뷰] ReSum: Unlocking Long-Horizon Search Intelligence via Context Summarization","excerpt":"Litu Ou이 [arXiv]에 게시한 'ReSum: Unlocking Long-Horizon Search Intelligence via Context Summarization' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-17 13:16:01+0900","lastModifiedAt":"2025-09-17 13:16:01+0900","categories":["Review"],"tags":["Review","LLM Agents","Context Management","Summarization","ReAct","Reinforcement Learning","Web Search","Long-Horizon Reasoning"],"permalink":"/ai/review/2025-9-17-ReSum_Unlocking_Long-Horizon_Search_Intelligence_via_Context_Summarization/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-17-Optimal_Brain_Restoration_for_Joint_Quantization_and_Sparsification_of_LLMs","title":"[논문리뷰] Optimal Brain Restoration for Joint Quantization and Sparsification of LLMs","excerpt":"Luca Benini이 [arXiv]에 게시한 'Optimal Brain Restoration for Joint Quantization and Sparsification of LLMs' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-17 13:16:01+0900","lastModifiedAt":"2025-09-17 13:16:01+0900","categories":["Review"],"tags":["Review","LLM Compression","Quantization","Sparsification","Post-training Quantization","Hessian-based Optimization","Error Compensation","Low-bit LLMs"],"permalink":"/ai/review/2025-9-17-Optimal_Brain_Restoration_for_Joint_Quantization_and_Sparsification_of_LLMs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-17-Multiple_Instance_Learning_Framework_with_Masked_Hard_Instance_Mining_for_Gigapixel_Histopathology_Image_Analysis","title":"[논문리뷰] Multiple Instance Learning Framework with Masked Hard Instance Mining for Gigapixel Histopathology Image Analysis","excerpt":"Bo Liu이 [arXiv]에 게시한 'Multiple Instance Learning Framework with Masked Hard Instance Mining for Gigapixel Histopathology Image Analysis' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-17 13:16:01+0900","lastModifiedAt":"2025-09-17 13:16:01+0900","categories":["Review"],"tags":["Review","Multiple Instance Learning","Hard Instance Mining","Computational Pathology","Whole Slide Images","Masked Learning","Siamese Network","Medical Image Analysis"],"permalink":"/ai/review/2025-9-17-Multiple_Instance_Learning_Framework_with_Masked_Hard_Instance_Mining_for_Gigapixel_Histopathology_Image_Analysis/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-17-Multimodal_Reasoning_for_Science_Technical_Report_and_1st_Place_Solution_to_the_ICML_2025_SeePhys_Challenge","title":"[논문리뷰] Multimodal Reasoning for Science: Technical Report and 1st Place Solution to the ICML 2025 SeePhys Challenge","excerpt":"Wentao Zhang이 [arXiv]에 게시한 'Multimodal Reasoning for Science: Technical Report and 1st Place Solution to the ICML 2025 SeePhys Challenge' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-17 13:16:01+0900","lastModifiedAt":"2025-09-17 13:16:01+0900","categories":["Review"],"tags":["Review","Multimodal Reasoning","Science AI","Caption-assisted Reasoning","SeePhys Challenge","Large Language Models","Visual Question Answering","Physics Problems","Cross-modal Alignment"],"permalink":"/ai/review/2025-9-17-Multimodal_Reasoning_for_Science_Technical_Report_and_1st_Place_Solution_to_the_ICML_2025_SeePhys_Challenge/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-17-Hunyuan3D_Studio_End-to-End_AI_Pipeline_for_Game-Ready_3D_Asset_Generation","title":"[논문리뷰] Hunyuan3D Studio: End-to-End AI Pipeline for Game-Ready 3D Asset Generation","excerpt":"Lixin Xu이 [arXiv]에 게시한 'Hunyuan3D Studio: End-to-End AI Pipeline for Game-Ready 3D Asset Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-17 13:16:01+0900","lastModifiedAt":"2025-09-17 13:16:01+0900","categories":["Review"],"tags":["Review","3D Asset Generation","AI Pipeline","Generative AI","Game Development","Diffusion Models","Neural Modules","Retopology","UV Unwrapping"],"permalink":"/ai/review/2025-9-17-Hunyuan3D_Studio_End-to-End_AI_Pipeline_for_Game-Ready_3D_Asset_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-17-Exact_Coset_Sampling_for_Quantum_Lattice_Algorithms","title":"[논문리뷰] Exact Coset Sampling for Quantum Lattice Algorithms","excerpt":"Yifan Zhang이 [arXiv]에 게시한 'Exact Coset Sampling for Quantum Lattice Algorithms' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-17 13:16:01+0900","lastModifiedAt":"2025-09-17 13:16:01+0900","categories":["Review"],"tags":["Review","Quantum Algorithms","Lattice Problems","Coset Sampling","Quantum Fourier Transform (QFT)","Modular Arithmetic","Quantum Cryptography","Exact Sampling"],"permalink":"/ai/review/2025-9-17-Exact_Coset_Sampling_for_Quantum_Lattice_Algorithms/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-17-EconProver_Towards_More_Economical_Test-Time_Scaling_for_Automated_Theorem_Proving","title":"[논문리뷰] EconProver: Towards More Economical Test-Time Scaling for Automated Theorem Proving","excerpt":"Shansan Gong이 [arXiv]에 게시한 'EconProver: Towards More Economical Test-Time Scaling for Automated Theorem Proving' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-17 13:16:01+0900","lastModifiedAt":"2025-09-17 13:16:01+0900","categories":["Review"],"tags":["Review","Automated Theorem Proving","LLM","Test-Time Scaling","Chain-of-Thought","Reinforcement Learning","Efficiency Optimization","Token Cost","Sampling Cost","Dynamic CoT Switching"],"permalink":"/ai/review/2025-9-17-EconProver_Towards_More_Economical_Test-Time_Scaling_for_Automated_Theorem_Proving/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-17-3D_Aware_Region_Prompted_Vision_Language_Model","title":"[논문리뷰] 3D Aware Region Prompted Vision Language Model","excerpt":"Xiaolong Li이 [arXiv]에 게시한 '3D Aware Region Prompted Vision Language Model' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-17 13:16:01+0900","lastModifiedAt":"2025-09-17 13:16:01+0900","categories":["Review"],"tags":["Review","3D Vision","Vision-Language Models","Spatial Reasoning","Region Prompting","Multi-view Learning","Depth Estimation","Unified Representation","Generative AI"],"permalink":"/ai/review/2025-9-17-3D_Aware_Region_Prompted_Vision_Language_Model/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-16-UI-S1_Advancing_GUI_Automation_via_Semi-online_Reinforcement_Learning","title":"[논문리뷰] UI-S1: Advancing GUI Automation via Semi-online Reinforcement Learning","excerpt":"Yongliang Shen이 [arXiv]에 게시한 'UI-S1: Advancing GUI Automation via Semi-online Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-16 13:16:41+0900","lastModifiedAt":"2025-09-16 13:16:41+0900","categories":["Review"],"tags":["Review","GUI Automation","Reinforcement Learning","Semi-online RL","Offline RL","Online RL","Patch Module","Multi-turn Interaction","Large Language Models"],"permalink":"/ai/review/2025-9-16-UI-S1_Advancing_GUI_Automation_via_Semi-online_Reinforcement_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-16-SearchInstruct_Enhancing_Domain_Adaptation_via_Retrieval-Based_Instruction_Dataset_Creation","title":"[논문리뷰] SearchInstruct: Enhancing Domain Adaptation via Retrieval-Based Instruction Dataset Creation","excerpt":"Heshaam Faili이 [arXiv]에 게시한 'SearchInstruct: Enhancing Domain Adaptation via Retrieval-Based Instruction Dataset Creation' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-16 13:16:41+0900","lastModifiedAt":"2025-09-16 13:16:41+0900","categories":["Review"],"tags":["Review","LLM","Instruction Tuning","Domain Adaptation","Retrieval-Augmented Generation","Dataset Creation","Model Editing","Supervised Fine-Tuning"],"permalink":"/ai/review/2025-9-16-SearchInstruct_Enhancing_Domain_Adaptation_via_Retrieval-Based_Instruction_Dataset_Creation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-16-PersonaX_Multimodal_Datasets_with_LLM-Inferred_Behavior_Traits","title":"[논문리뷰] PersonaX: Multimodal Datasets with LLM-Inferred Behavior Traits","excerpt":"Zhenhao Chen이 [arXiv]에 게시한 'PersonaX: Multimodal Datasets with LLM-Inferred Behavior Traits' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-16 13:16:41+0900","lastModifiedAt":"2025-09-16 13:16:41+0900","categories":["Review"],"tags":["Review","Multimodal Dataset","LLM Inference","Behavioral Traits","Causal Representation Learning","Big Five","Multimodal AI","Causal Discovery","Human-Computer Interaction"],"permalink":"/ai/review/2025-9-16-PersonaX_Multimodal_Datasets_with_LLM-Inferred_Behavior_Traits/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-16-OmniWorld_A_Multi-Domain_and_Multi-Modal_Dataset_for_4D_World_Modeling","title":"[논문리뷰] OmniWorld: A Multi-Domain and Multi-Modal Dataset for 4D World Modeling","excerpt":"Yang Zhou이 [arXiv]에 게시한 'OmniWorld: A Multi-Domain and Multi-Modal Dataset for 4D World Modeling' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-16 13:16:41+0900","lastModifiedAt":"2025-09-16 13:16:41+0900","categories":["Review"],"tags":["Review","4D World Modeling","Multi-Modal Dataset","Multi-Domain Data","Geometric Foundation Models","Video Generation","Spatio-Temporal Data","Dataset Benchmark"],"permalink":"/ai/review/2025-9-16-OmniWorld_A_Multi-Domain_and_Multi-Modal_Dataset_for_4D_World_Modeling/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-16-Measuring_Epistemic_Humility_in_Multimodal_Large_Language_Models","title":"[논문리뷰] Measuring Epistemic Humility in Multimodal Large Language Models","excerpt":"Kaiyang Zhou이 [arXiv]에 게시한 'Measuring Epistemic Humility in Multimodal Large Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-16 13:16:41+0900","lastModifiedAt":"2025-09-16 13:16:41+0900","categories":["Review"],"tags":["Review","Multimodal Large Language Models","Hallucination","Epistemic Humility","Benchmark","False-Option Rejection","Visual Question Answering","Scene Graph"],"permalink":"/ai/review/2025-9-16-Measuring_Epistemic_Humility_in_Multimodal_Large_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-16-Lost_in_Embeddings_Information_Loss_in_Vision-Language_Models","title":"[논문리뷰] Lost in Embeddings: Information Loss in Vision-Language Models","excerpt":"Ivan Vulić이 [arXiv]에 게시한 'Lost in Embeddings: Information Loss in Vision-Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-16 13:16:41+0900","lastModifiedAt":"2025-09-16 13:16:41+0900","categories":["Review"],"tags":["Review","Vision-Language Models","Information Loss","Embeddings","Connectors","k-NN Overlap Ratio","Embedding Reconstruction","Multimodal AI"],"permalink":"/ai/review/2025-9-16-Lost_in_Embeddings_Information_Loss_in_Vision-Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-16-Look_Again_Think_Slowly_Enhancing_Visual_Reflection_in_Vision-Language_Models","title":"[논문리뷰] Look Again, Think Slowly: Enhancing Visual Reflection in Vision-Language Models","excerpt":"Shuo Ren이 [arXiv]에 게시한 'Look Again, Think Slowly: Enhancing Visual Reflection in Vision-Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-16 13:16:41+0900","lastModifiedAt":"2025-09-16 13:16:41+0900","categories":["Review"],"tags":["Review","Vision-Language Models","Visual Reasoning","Reflection","Reinforcement Learning","Visual Attention","Slow Thinking","Multimodal Agents"],"permalink":"/ai/review/2025-9-16-Look_Again_Think_Slowly_Enhancing_Visual_Reflection_in_Vision-Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-16-Locality_in_Image_Diffusion_Models_Emerges_from_Data_Statistics","title":"[논문리뷰] Locality in Image Diffusion Models Emerges from Data Statistics","excerpt":"Vincent Sitzmann이 [arXiv]에 게시한 'Locality in Image Diffusion Models Emerges from Data Statistics' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-16 13:16:41+0900","lastModifiedAt":"2025-09-16 13:16:41+0900","categories":["Review"],"tags":["Review","Diffusion Models","Locality","Data Statistics","Optimal Denoiser","Wiener Filter","Sensitivity Fields","Generative Models","Inductive Bias"],"permalink":"/ai/review/2025-9-16-Locality_in_Image_Diffusion_Models_Emerges_from_Data_Statistics/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-16-Learning_to_Optimize_Multi-Objective_Alignment_Through_Dynamic_Reward_Weighting","title":"[논문리뷰] Learning to Optimize Multi-Objective Alignment Through Dynamic Reward Weighting","excerpt":"Changlong Yu이 [arXiv]에 게시한 'Learning to Optimize Multi-Objective Alignment Through Dynamic Reward Weighting' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-16 13:16:41+0900","lastModifiedAt":"2025-09-16 13:16:41+0900","categories":["Review"],"tags":["Review","Multi-objective Reinforcement Learning","LLM Alignment","Dynamic Reward Weighting","Pareto Front Optimization","Hypervolume Indicator","Gradient-based Optimization","Online RL"],"permalink":"/ai/review/2025-9-16-Learning_to_Optimize_Multi-Objective_Alignment_Through_Dynamic_Reward_Weighting/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-16-LazyDrag_Enabling_Stable_Drag-Based_Editing_on_Multi-Modal_Diffusion_Transformers_via_Explicit_Correspondence","title":"[논문리뷰] LazyDrag: Enabling Stable Drag-Based Editing on Multi-Modal Diffusion Transformers via Explicit Correspondence","excerpt":"Lionel M. Ni이 [arXiv]에 게시한 'LazyDrag: Enabling Stable Drag-Based Editing on Multi-Modal Diffusion Transformers via Explicit Correspondence' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-16 13:16:41+0900","lastModifiedAt":"2025-09-16 13:16:41+0900","categories":["Review"],"tags":["Review","Image Editing","Diffusion Models","Multi-Modal Transformers","Drag-based Editing","Explicit Correspondence","Attention Control","Identity Preservation","Training-Free"],"permalink":"/ai/review/2025-9-16-LazyDrag_Enabling_Stable_Drag-Based_Editing_on_Multi-Modal_Diffusion_Transformers_via_Explicit_Correspondence/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-16-InternScenes_A_Large-scale_Simulatable_Indoor_Scene_Dataset_with_Realistic_Layouts","title":"[논문리뷰] InternScenes: A Large-scale Simulatable Indoor Scene Dataset with Realistic Layouts","excerpt":"Wenzhe Cai이 [arXiv]에 게시한 'InternScenes: A Large-scale Simulatable Indoor Scene Dataset with Realistic Layouts' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-16 13:16:41+0900","lastModifiedAt":"2025-09-16 13:16:41+0900","categories":["Review"],"tags":["Review","Embodied AI","3D Scene Dataset","Simulation Environment","Scene Generation","Point-Goal Navigation","Realistic Layouts","Object Interaction","Real-to-Sim"],"permalink":"/ai/review/2025-9-16-InternScenes_A_Large-scale_Simulatable_Indoor_Scene_Dataset_with_Realistic_Layouts/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-16-GAPrune_Gradient-Alignment_Pruning_for_Domain-Aware_Embeddings","title":"[논문리뷰] GAPrune: Gradient-Alignment Pruning for Domain-Aware Embeddings","excerpt":"Yixuan Tang이 [arXiv]에 게시한 'GAPrune: Gradient-Alignment Pruning for Domain-Aware Embeddings' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-16 13:16:41+0900","lastModifiedAt":"2025-09-16 13:16:41+0900","categories":["Review"],"tags":["Review","Model Pruning","Domain Adaptation","Embedding Models","Gradient Alignment","Fisher Information","Model Compression","LLMs"],"permalink":"/ai/review/2025-9-16-GAPrune_Gradient-Alignment_Pruning_for_Domain-Aware_Embeddings/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-16-EthicsMH_A_Pilot_Benchmark_for_Ethical_Reasoning_in_Mental_Health_AI","title":"[논문리뷰] EthicsMH: A Pilot Benchmark for Ethical Reasoning in Mental Health AI","excerpt":"UVSKKR이 [arXiv]에 게시한 'EthicsMH: A Pilot Benchmark for Ethical Reasoning in Mental Health AI' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-16 13:16:41+0900","lastModifiedAt":"2025-09-16 13:16:41+0900","categories":["Review"],"tags":["Review","Ethical Reasoning","Mental Health AI","Benchmark Dataset","Large Language Models","AI Ethics","Clinical Decision Support","Human-in-the-loop"],"permalink":"/ai/review/2025-9-16-EthicsMH_A_Pilot_Benchmark_for_Ethical_Reasoning_in_Mental_Health_AI/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-16-Dr.V_A_Hierarchical_Perception-Temporal-Cognition_Framework_to_Diagnose_Video_Hallucination_by_Fine-grained_Spatial-Temporal_Grounding","title":"[논문리뷰] Dr.V: A Hierarchical Perception-Temporal-Cognition Framework to Diagnose Video Hallucination by Fine-grained Spatial-Temporal Grounding","excerpt":"Li Zheng이 [arXiv]에 게시한 'Dr.V: A Hierarchical Perception-Temporal-Cognition Framework to Diagnose Video Hallucination by Fine-grained Spatial-Temporal Grounding' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-16 13:16:41+0900","lastModifiedAt":"2025-09-16 13:16:41+0900","categories":["Review"],"tags":["Review","Video Hallucination","Large Video Models (LVMs)","Hierarchical Reasoning","Spatial-Temporal Grounding","Diagnostic Framework","Benchmark Dataset","Multimodal AI"],"permalink":"/ai/review/2025-9-16-Dr.V_A_Hierarchical_Perception-Temporal-Cognition_Framework_to_Diagnose_Video_Hallucination_by_Fine-grained_Spatial-Temporal_Grounding/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-16-CognitiveSky_Scalable_Sentiment_and_Narrative_Analysis_for_Decentralized_Social_Media","title":"[논문리뷰] CognitiveSky: Scalable Sentiment and Narrative Analysis for Decentralized Social Media","excerpt":"Subasish Das이 [arXiv]에 게시한 'CognitiveSky: Scalable Sentiment and Narrative Analysis for Decentralized Social Media' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-16 13:16:41+0900","lastModifiedAt":"2025-09-16 13:16:41+0900","categories":["Review"],"tags":["Review","Sentiment Analysis","Narrative Analysis","Decentralized Social Media","Bluesky","Transformer Models","Topic Modeling","Real-time Processing","Data Visualization"],"permalink":"/ai/review/2025-9-16-CognitiveSky_Scalable_Sentiment_and_Narrative_Analysis_for_Decentralized_Social_Media/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-15-X-Part_high_fidelity_and_structure_coherent_shape_decomposition","title":"[논문리뷰] X-Part: high fidelity and structure coherent shape decomposition","excerpt":"Yunhan Yang이 [arXiv]에 게시한 'X-Part: high fidelity and structure coherent shape decomposition' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-15 13:12:08+0900","lastModifiedAt":"2025-09-15 13:12:08+0900","categories":["Review"],"tags":["Review","3D Shape Decomposition","Diffusion Models","Part-level Generation","Controllable Generation","Bounding Box Prompts","Semantic Features","Interactive Editing","Generative AI"],"permalink":"/ai/review/2025-9-15-X-Part_high_fidelity_and_structure_coherent_shape_decomposition/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-15-VStyle_A_Benchmark_for_Voice_Style_Adaptation_with_Spoken_Instructions","title":"[논문리뷰] VStyle: A Benchmark for Voice Style Adaptation with Spoken Instructions","excerpt":"Dong Zhang이 [arXiv]에 게시한 'VStyle: A Benchmark for Voice Style Adaptation with Spoken Instructions' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-15 13:12:08+0900","lastModifiedAt":"2025-09-15 13:12:08+0900","categories":["Review"],"tags":["Review","Voice Style Adaptation","Spoken Language Models","Benchmark","LALM-as-a-Judge","Speech Generation","Multilingual","Evaluation Framework"],"permalink":"/ai/review/2025-9-15-VStyle_A_Benchmark_for_Voice_Style_Adaptation_with_Spoken_Instructions/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-15-Virtual_Agent_Economies","title":"[논문리뷰] Virtual Agent Economies","excerpt":"William A. Cunningham이 [arXiv]에 게시한 'Virtual Agent Economies' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-15 13:12:08+0900","lastModifiedAt":"2025-09-15 13:12:08+0900","categories":["Review"],"tags":["Review","AI Agents","Virtual Economy","Multi-Agent Systems","Economic Mechanisms","Governance","Blockchain","Resource Allocation","Agent Alignment"],"permalink":"/ai/review/2025-9-15-Virtual_Agent_Economies/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-15-The_Illusion_of_Diminishing_Returns_Measuring_Long_Horizon_Execution_in_LLMs","title":"[논문리뷰] The Illusion of Diminishing Returns: Measuring Long Horizon Execution in LLMs","excerpt":"Jonas Geiping이 [arXiv]에 게시한 'The Illusion of Diminishing Returns: Measuring Long Horizon Execution in LLMs' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-15 13:12:08+0900","lastModifiedAt":"2025-09-15 13:12:08+0900","categories":["Review"],"tags":["Review","Large Language Models","Long-Horizon Tasks","Execution Capability","Scaling Laws","Self-Conditioning","Thinking Models","Agentic AI"],"permalink":"/ai/review/2025-9-15-The_Illusion_of_Diminishing_Returns_Measuring_Long_Horizon_Execution_in_LLMs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-15-QuantAgent_Price-Driven_Multi-Agent_LLMs_for_High-Frequency_Trading","title":"[논문리뷰] QuantAgent: Price-Driven Multi-Agent LLMs for High-Frequency Trading","excerpt":"Chenyu You이 [arXiv]에 게시한 'QuantAgent: Price-Driven Multi-Agent LLMs for High-Frequency Trading' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-15 13:12:08+0900","lastModifiedAt":"2025-09-15 13:12:08+0900","categories":["Review"],"tags":["Review","High-Frequency Trading","Multi-Agent Systems","Large Language Models","Technical Analysis","Algorithmic Trading","Financial Reasoning","Price-Driven Signals"],"permalink":"/ai/review/2025-9-15-QuantAgent_Price-Driven_Multi-Agent_LLMs_for_High-Frequency_Trading/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-15-MCP-AgentBench_Evaluating_Real-World_Language_Agent_Performance_with_MCP-Mediated_Tools","title":"[논문리뷰] MCP-AgentBench: Evaluating Real-World Language Agent Performance with MCP-Mediated Tools","excerpt":"Xiaorui Wang이 [arXiv]에 게시한 'MCP-AgentBench: Evaluating Real-World Language Agent Performance with MCP-Mediated Tools' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-15 13:12:08+0900","lastModifiedAt":"2025-09-15 13:12:08+0900","categories":["Review"],"tags":["Review","Language Agents","Tool Use","Benchmarks","Model Context Protocol (MCP)","LLM Evaluation","Agentic AI","Real-World Performance"],"permalink":"/ai/review/2025-9-15-MCP-AgentBench_Evaluating_Real-World_Language_Agent_Performance_with_MCP-Mediated_Tools/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-15-LoFT_Parameter-Efficient_Fine-Tuning_for_Long-tailed_Semi-Supervised_Learning_in_Open-World_Scenarios","title":"[논문리뷰] LoFT: Parameter-Efficient Fine-Tuning for Long-tailed Semi-Supervised Learning in Open-World Scenarios","excerpt":"Bing Su이 [arXiv]에 게시한 'LoFT: Parameter-Efficient Fine-Tuning for Long-tailed Semi-Supervised Learning in Open-World Scenarios' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-15 13:12:08+0900","lastModifiedAt":"2025-09-15 13:12:08+0900","categories":["Review"],"tags":["Review","Long-tailed Learning","Semi-Supervised Learning","Parameter-Efficient Fine-Tuning","Foundation Models","Open-World Scenarios","OOD Detection","Confidence Calibration"],"permalink":"/ai/review/2025-9-15-LoFT_Parameter-Efficient_Fine-Tuning_for_Long-tailed_Semi-Supervised_Learning_in_Open-World_Scenarios/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-15-IntrEx_A_Dataset_for_Modeling_Engagement_in_Educational_Conversations","title":"[논문리뷰] IntrEx: A Dataset for Modeling Engagement in Educational Conversations","excerpt":"Gabriele Pergola이 [arXiv]에 게시한 'IntrEx: A Dataset for Modeling Engagement in Educational Conversations' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-15 13:12:08+0900","lastModifiedAt":"2025-09-15 13:12:08+0900","categories":["Review"],"tags":["Review","Educational Dialogue","Engagement Modeling","Dataset Annotation","Second Language Learning","Human Feedback","LLM Alignment","Readability Metrics"],"permalink":"/ai/review/2025-9-15-IntrEx_A_Dataset_for_Modeling_Engagement_in_Educational_Conversations/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-15-Inpainting-Guided_Policy_Optimization_for_Diffusion_Large_Language_Models","title":"[논문리뷰] Inpainting-Guided Policy Optimization for Diffusion Large Language Models","excerpt":"Chenyu Wang이 [arXiv]에 게시한 'Inpainting-Guided Policy Optimization for Diffusion Large Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-15 13:12:08+0900","lastModifiedAt":"2025-09-15 13:12:08+0900","categories":["Review"],"tags":["Review","Diffusion LLMs","Reinforcement Learning","Inpainting","Policy Optimization","Exploration","Mathematical Reasoning","GRPO"],"permalink":"/ai/review/2025-9-15-Inpainting-Guided_Policy_Optimization_for_Diffusion_Large_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-15-InfGen_A_Resolution-Agnostic_Paradigm_for_Scalable_Image_Synthesis","title":"[논문리뷰] InfGen: A Resolution-Agnostic Paradigm for Scalable Image Synthesis","excerpt":"Song Guo이 [arXiv]에 게시한 'InfGen: A Resolution-Agnostic Paradigm for Scalable Image Synthesis' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-15 13:12:08+0900","lastModifiedAt":"2025-09-15 13:12:08+0900","categories":["Review"],"tags":["Review","Image Synthesis","Resolution-Agnostic","Diffusion Models","Latent Space","VAE Decoder","High-Resolution Image Generation","Generative AI","Transformer Architecture"],"permalink":"/ai/review/2025-9-15-InfGen_A_Resolution-Agnostic_Paradigm_for_Scalable_Image_Synthesis/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-15-HANRAG_Heuristic_Accurate_Noise-resistant_Retrieval-Augmented_Generation_for_Multi-hop_Question_Answering","title":"[논문리뷰] HANRAG: Heuristic Accurate Noise-resistant Retrieval-Augmented Generation for Multi-hop Question Answering","excerpt":"Zhehao Tan이 [arXiv]에 게시한 'HANRAG: Heuristic Accurate Noise-resistant Retrieval-Augmented Generation for Multi-hop Question Answering' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-15 13:12:08+0900","lastModifiedAt":"2025-09-15 13:12:08+0900","categories":["Review"],"tags":["Review","Retrieval-Augmented Generation","Multi-hop QA","Noise Resistance","LLM","Query Decomposition","Adaptive Retrieval","Heuristic Framework","Revelator"],"permalink":"/ai/review/2025-9-15-HANRAG_Heuristic_Accurate_Noise-resistant_Retrieval-Augmented_Generation_for_Multi-hop_Question_Answering/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-15-FLOWER_Democratizing_Generalist_Robot_Policies_with_Efficient_Vision-Language-Action_Flow_Policies","title":"[논문리뷰] FLOWER: Democratizing Generalist Robot Policies with Efficient Vision-Language-Action Flow Policies","excerpt":"Fabian Otto이 [arXiv]에 게시한 'FLOWER: Democratizing Generalist Robot Policies with Efficient Vision-Language-Action Flow Policies' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-15 13:12:08+0900","lastModifiedAt":"2025-09-15 13:12:08+0900","categories":["Review"],"tags":["Review","Generalist Robot Policies","Vision-Language-Action Models","Efficient AI","Imitation Learning","Diffusion Models","Intermediate Fusion","Robotics"],"permalink":"/ai/review/2025-9-15-FLOWER_Democratizing_Generalist_Robot_Policies_with_Efficient_Vision-Language-Action_Flow_Policies/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-15-CMHG_A_Dataset_and_Benchmark_for_Headline_Generation_of_Minority_Languages_in_China","title":"[논문리뷰] CMHG: A Dataset and Benchmark for Headline Generation of Minority Languages in China","excerpt":"XU Han이 [arXiv]에 게시한 'CMHG: A Dataset and Benchmark for Headline Generation of Minority Languages in China' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-15 13:12:08+0900","lastModifiedAt":"2025-09-15 13:12:08+0900","categories":["Review"],"tags":["Review","Headline Generation","Minority Languages","Low-Resource NLP","Dataset","Benchmark","Natural Language Generation","Chinese Minority Languages"],"permalink":"/ai/review/2025-9-15-CMHG_A_Dataset_and_Benchmark_for_Headline_Generation_of_Minority_Languages_in_China/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-12-VLA-Adapter_An_Effective_Paradigm_for_Tiny-Scale_Vision-Language-Action_Model","title":"[논문리뷰] VLA-Adapter: An Effective Paradigm for Tiny-Scale Vision-Language-Action Model","excerpt":"Zirui Ge이 [arXiv]에 게시한 'VLA-Adapter: An Effective Paradigm for Tiny-Scale Vision-Language-Action Model' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-12 13:12:46+0900","lastModifiedAt":"2025-09-12 13:12:46+0900","categories":["Review"],"tags":["Review","Vision-Language-Action Models","Robotics","Multimodal Learning","Efficient AI","Model Adaptation","Bridge Attention","Low-resource Training"],"permalink":"/ai/review/2025-9-12-VLA-Adapter_An_Effective_Paradigm_for_Tiny-Scale_Vision-Language-Action_Model/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-12-Visual_Programmability_A_Guide_for_Code-as-Thought_in_Chart_Understanding","title":"[논문리뷰] Visual Programmability: A Guide for Code-as-Thought in Chart Understanding","excerpt":"Ethan Chern이 [arXiv]에 게시한 'Visual Programmability: A Guide for Code-as-Thought in Chart Understanding' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-12 13:12:46+0900","lastModifiedAt":"2025-09-12 13:12:46+0900","categories":["Review"],"tags":["Review","Visual Programmability","Code-as-Thought (CaT)","Chart Understanding","Vision-Language Models (VLMs)","Reinforcement Learning (RL)","Adaptive Reasoning","Dual-Reward System","Multimodal AI"],"permalink":"/ai/review/2025-9-12-Visual_Programmability_A_Guide_for_Code-as-Thought_in_Chart_Understanding/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-12-The_Choice_of_Divergence_A_Neglected_Key_to_Mitigating_Diversity_Collapse_in_Reinforcement_Learning_with_Verifiable_Reward","title":"[논문리뷰] The Choice of Divergence: A Neglected Key to Mitigating Diversity Collapse in Reinforcement Learning with Verifiable Reward","excerpt":"Xiaoyu Tan이 [arXiv]에 게시한 'The Choice of Divergence: A Neglected Key to Mitigating Diversity Collapse in Reinforcement Learning with Verifiable Reward' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-12 13:12:46+0900","lastModifiedAt":"2025-09-12 13:12:46+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","Large Language Models (LLMs)","Diversity Collapse","f-divergence","Forward-KL","JS-divergence","Pass@k","Catastrophic Forgetting"],"permalink":"/ai/review/2025-9-12-The_Choice_of_Divergence_A_Neglected_Key_to_Mitigating_Diversity_Collapse_in_Reinforcement_Learning_with_Verifiable_Reward/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-12-SpatialVID_A_Large-Scale_Video_Dataset_with_Spatial_Annotations","title":"[논문리뷰] SpatialVID: A Large-Scale Video Dataset with Spatial Annotations","excerpt":"Jian Gao이 [arXiv]에 게시한 'SpatialVID: A Large-Scale Video Dataset with Spatial Annotations' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-12 13:12:46+0900","lastModifiedAt":"2025-09-12 13:12:46+0900","categories":["Review"],"tags":["Review","Video Dataset","Spatial Annotation","Camera Pose Estimation","Depth Map","Structured Caption","Motion Instruction","3D Vision","World Modeling"],"permalink":"/ai/review/2025-9-12-SpatialVID_A_Large-Scale_Video_Dataset_with_Spatial_Annotations/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-12-SimpleVLA-RL_Scaling_VLA_Training_via_Reinforcement_Learning","title":"[논문리뷰] SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning","excerpt":"Zhaohui Yang이 [arXiv]에 게시한 'SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-12 13:12:46+0900","lastModifiedAt":"2025-09-12 13:12:46+0900","categories":["Review"],"tags":["Review","Reinforcement Learning (RL)","Vision-Language-Action (VLA) Models","Robotic Manipulation","Data Scarcity","Generalization","Sim-to-Real Transfer","Online RL","Long-Horizon Planning"],"permalink":"/ai/review/2025-9-12-SimpleVLA-RL_Scaling_VLA_Training_via_Reinforcement_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-12-Reasoning_Introduces_New_Poisoning_Attacks_Yet_Makes_Them_More_Complicated","title":"[논문리뷰] Reasoning Introduces New Poisoning Attacks Yet Makes Them More Complicated","excerpt":"Jamie Hayes이 [arXiv]에 게시한 'Reasoning Introduces New Poisoning Attacks Yet Makes Them More Complicated' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-12 13:12:46+0900","lastModifiedAt":"2025-09-12 13:12:46+0900","categories":["Review"],"tags":["Review","LLM Security","Data Poisoning","Chain-of-Thought","Reasoning Models","Backdoor Attacks","CoT Unfaithfulness","Emergent Robustness"],"permalink":"/ai/review/2025-9-12-Reasoning_Introduces_New_Poisoning_Attacks_Yet_Makes_Them_More_Complicated/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-12-OmniEVA_Embodied_Versatile_Planner_via_Task-Adaptive_3D-Grounded_and_Embodiment-aware_Reasoning","title":"[논문리뷰] OmniEVA: Embodied Versatile Planner via Task-Adaptive 3D-Grounded and Embodiment-aware Reasoning","excerpt":"Yuzheng Zhuang이 [arXiv]에 게시한 'OmniEVA: Embodied Versatile Planner via Task-Adaptive 3D-Grounded and Embodiment-aware Reasoning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-12 13:12:46+0900","lastModifiedAt":"2025-09-12 13:12:46+0900","categories":["Review"],"tags":["Review","Embodied AI","Multimodal LLMs","3D Grounding","Task-Adaptive Reasoning","Embodiment-Aware Planning","Robotics","Spatial Reasoning"],"permalink":"/ai/review/2025-9-12-OmniEVA_Embodied_Versatile_Planner_via_Task-Adaptive_3D-Grounded_and_Embodiment-aware_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-12-Modality_Alignment_with_Multi-scale_Bilateral_Attention_for_Multimodal_Recommendation","title":"[논문리뷰] Modality Alignment with Multi-scale Bilateral Attention for Multimodal Recommendation","excerpt":"Dong-Ho Lee이 [arXiv]에 게시한 'Modality Alignment with Multi-scale Bilateral Attention for Multimodal Recommendation' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-12 13:12:46+0900","lastModifiedAt":"2025-09-12 13:12:46+0900","categories":["Review"],"tags":["Review","Multimodal Recommendation","Modality Alignment","Attention Mechanism","Dilated Convolution","Maximum Mean Discrepancy","Contrastive Learning","Dimensionality Reduction"],"permalink":"/ai/review/2025-9-12-Modality_Alignment_with_Multi-scale_Bilateral_Attention_for_Multimodal_Recommendation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-12-LoCoBench_A_Benchmark_for_Long-Context_Large_Language_Models_in_Complex_Software_Engineering","title":"[논문리뷰] LoCoBench: A Benchmark for Long-Context Large Language Models in Complex Software Engineering","excerpt":"Jianguo Zhang이 [arXiv]에 게시한 'LoCoBench: A Benchmark for Long-Context Large Language Models in Complex Software Engineering' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-12 13:12:46+0900","lastModifiedAt":"2025-09-12 13:12:46+0900","categories":["Review"],"tags":["Review","Long-Context LLMs","Software Engineering","Code Evaluation","Benchmark","Multi-file Reasoning","Architectural Understanding","Context Length","Software Development Lifecycle","Metrics"],"permalink":"/ai/review/2025-9-12-LoCoBench_A_Benchmark_for_Long-Context_Large_Language_Models_in_Complex_Software_Engineering/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-12-Kling-Avatar_Grounding_Multimodal_Instructions_for_Cascaded_Long-Duration_Avatar_Animation_Synthesis","title":"[논문리뷰] Kling-Avatar: Grounding Multimodal Instructions for Cascaded Long-Duration Avatar Animation Synthesis","excerpt":"Wentao Hu이 [arXiv]에 게시한 'Kling-Avatar: Grounding Multimodal Instructions for Cascaded Long-Duration Avatar Animation Synthesis' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-12 13:12:46+0900","lastModifiedAt":"2025-09-12 13:12:46+0900","categories":["Review"],"tags":["Review","Avatar Animation","Multimodal Instructions","Long-Duration Video Generation","MLLM Director","Cascaded Framework","Lip Synchronization","Instruction Grounding","Video Diffusion Transformers"],"permalink":"/ai/review/2025-9-12-Kling-Avatar_Grounding_Multimodal_Instructions_for_Cascaded_Long-Duration_Avatar_Animation_Synthesis/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-12-HuMo_Human-Centric_Video_Generation_via_Collaborative_Multi-Modal_Conditioning","title":"[논문리뷰] HuMo: Human-Centric Video Generation via Collaborative Multi-Modal Conditioning","excerpt":"Zhuowei Chen이 [arXiv]에 게시한 'HuMo: Human-Centric Video Generation via Collaborative Multi-Modal Conditioning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-12 13:12:46+0900","lastModifiedAt":"2025-09-12 13:12:46+0900","categories":["Review"],"tags":["Review","Human-Centric Video Generation","Multimodal Conditioning","Text-to-Video","Image-to-Video","Audio-to-Video","Diffusion Models","Subject Preservation","Audio-Visual Synchronization","Progressive Training"],"permalink":"/ai/review/2025-9-12-HuMo_Human-Centric_Video_Generation_via_Collaborative_Multi-Modal_Conditioning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-12-Harnessing_Uncertainty_Entropy-Modulated_Policy_Gradients_for_Long-Horizon_LLM_Agents","title":"[논문리뷰] Harnessing Uncertainty: Entropy-Modulated Policy Gradients for Long-Horizon LLM Agents","excerpt":"Xintao Wang이 [arXiv]에 게시한 'Harnessing Uncertainty: Entropy-Modulated Policy Gradients for Long-Horizon LLM Agents' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-12 13:12:46+0900","lastModifiedAt":"2025-09-12 13:12:46+0900","categories":["Review"],"tags":["Review","LLM Agents","Reinforcement Learning","Policy Gradients","Entropy Modulation","Credit Assignment","Uncertainty","Long-Horizon Tasks","Self-Calibrating Gradient Scaling"],"permalink":"/ai/review/2025-9-12-Harnessing_Uncertainty_Entropy-Modulated_Policy_Gradients_for_Long-Horizon_LLM_Agents/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-12-Gradient-Attention_Guided_Dual-Masking_Synergetic_Framework_for_Robust_Text-based_Person_Retrieval","title":"[논문리뷰] Gradient-Attention Guided Dual-Masking Synergetic Framework for Robust Text-based Person Retrieval","excerpt":"Kaicheng Yang이 [arXiv]에 게시한 'Gradient-Attention Guided Dual-Masking Synergetic Framework for Robust Text-based Person Retrieval' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-12 13:12:46+0900","lastModifiedAt":"2025-09-12 13:12:46+0900","categories":["Review"],"tags":["Review","Text-based Person Retrieval","CLIP","MLLM","Data Curation","Dual-Masking","Gradient-Attention","WebPerson Dataset"],"permalink":"/ai/review/2025-9-12-Gradient-Attention_Guided_Dual-Masking_Synergetic_Framework_for_Robust_Text-based_Person_Retrieval/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-12-FLUX-Reason-6M_PRISM-Bench_A_Million-Scale_Text-to-Image_Reasoning_Dataset_and_Comprehensive_Benchmark","title":"[논문리뷰] FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark","excerpt":"Shuai Bai이 [arXiv]에 게시한 'FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-12 13:12:46+0900","lastModifiedAt":"2025-09-12 13:12:46+0900","categories":["Review"],"tags":["Review","Text-to-Image Generation","Reasoning Dataset","Benchmark","Generation Chain-of-Thought","Vision-Language Model","Image Aesthetics","Prompt Alignment"],"permalink":"/ai/review/2025-9-12-FLUX-Reason-6M_PRISM-Bench_A_Million-Scale_Text-to-Image_Reasoning_Dataset_and_Comprehensive_Benchmark/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-12-EchoX_Towards_Mitigating_Acoustic-Semantic_Gap_via_Echo_Training_for_Speech-to-Speech_LLMs","title":"[논문리뷰] EchoX: Towards Mitigating Acoustic-Semantic Gap via Echo Training for Speech-to-Speech LLMs","excerpt":"Kaiqi Kou이 [arXiv]에 게시한 'EchoX: Towards Mitigating Acoustic-Semantic Gap via Echo Training for Speech-to-Speech LLMs' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-12 13:12:46+0900","lastModifiedAt":"2025-09-12 13:12:46+0900","categories":["Review"],"tags":["Review","Speech-to-Speech LLMs","Acoustic-Semantic Gap","Echo Training","Unit Language","Streaming Inference","Knowledge-based QA"],"permalink":"/ai/review/2025-9-12-EchoX_Towards_Mitigating_Acoustic-Semantic_Gap_via_Echo_Training_for_Speech-to-Speech_LLMs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-12-Can_Understanding_and_Generation_Truly_Benefit_Together_--_or_Just_Coexist","title":"[논문리뷰] Can Understanding and Generation Truly Benefit Together -- or Just Coexist?","excerpt":"Hui Han이 [arXiv]에 게시한 'Can Understanding and Generation Truly Benefit Together -- or Just Coexist?' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-12 13:12:46+0900","lastModifiedAt":"2025-09-12 13:12:46+0900","categories":["Review"],"tags":["Review","Multimodal Understanding","Multimodal Generation","Unified Models","Auto-Encoder","Reinforcement Learning","Image-to-Text","Text-to-Image","Reconstruction Fidelity"],"permalink":"/ai/review/2025-9-12-Can_Understanding_and_Generation_Truly_Benefit_Together_--_or_Just_Coexist/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-12-2D_Gaussian_Splatting_with_Semantic_Alignment_for_Image_Inpainting","title":"[논문리뷰] 2D Gaussian Splatting with Semantic Alignment for Image Inpainting","excerpt":"Guangming Lu이 [arXiv]에 게시한 '2D Gaussian Splatting with Semantic Alignment for Image Inpainting' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-12 13:12:46+0900","lastModifiedAt":"2025-09-12 13:12:46+0900","categories":["Review"],"tags":["Review","Image Inpainting","2D Gaussian Splatting","Semantic Alignment","DINO Features","Patch-level Rasterization","Continuous Representation","Generative Models"],"permalink":"/ai/review/2025-9-12-2D_Gaussian_Splatting_with_Semantic_Alignment_for_Image_Inpainting/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-11-think_So_lets_replace_this_phrase_with_insult..._think_Lessons_learned_from_generation_of_toxic_texts_with_LLMs","title":"[논문리뷰] <think> So let's replace this phrase with insult... </think> Lessons learned from generation of toxic texts with LLMs","excerpt":"Alexander Panchenko이 [arXiv]에 게시한 '<think> So let's replace this phrase with insult... </think> Lessons learned from generation of toxic texts with LLMs' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-11 13:02:36+0900","lastModifiedAt":"2025-09-11 13:02:36+0900","categories":["Review"],"tags":["Review","Toxic Text Generation","LLMs","Text Detoxification","Lexical Diversity","Synthetic Data","Human Annotation","Style Transfer"],"permalink":"/ai/review/2025-9-11-think_So_lets_replace_this_phrase_with_insult..._think_Lessons_learned_from_generation_of_toxic_texts_with_LLMs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-11-RewardDance_Reward_Scaling_in_Visual_Generation","title":"[논문리뷰] RewardDance: Reward Scaling in Visual Generation","excerpt":"Liang Li이 [arXiv]에 게시한 'RewardDance: Reward Scaling in Visual Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-11 13:02:36+0900","lastModifiedAt":"2025-09-11 13:02:36+0900","categories":["Review"],"tags":["Review","Reward Model","Visual Generation","RLHF","VLM","Reward Scaling","Reward Hacking","Generative Paradigm","Context Scaling","Text-to-Image","Text-to-Video"],"permalink":"/ai/review/2025-9-11-RewardDance_Reward_Scaling_in_Visual_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-11-P3-SAM_Native_3D_Part_Segmentation","title":"[논문리뷰] P3-SAM: Native 3D Part Segmentation","excerpt":"Yunhan Yang이 [arXiv]에 게시한 'P3-SAM: Native 3D Part Segmentation' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-11 13:02:36+0900","lastModifiedAt":"2025-09-11 13:02:36+0900","categories":["Review"],"tags":["Review","3D Part Segmentation","Point Cloud Segmentation","Prompt-based Segmentation","Deep Learning","Transformer","Interactive Segmentation","Automatic Segmentation","Native 3D"],"permalink":"/ai/review/2025-9-11-P3-SAM_Native_3D_Part_Segmentation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-11-Hunyuan-MT_Technical_Report","title":"[논문리뷰] Hunyuan-MT Technical Report","excerpt":"Yang Du이 [arXiv]에 게시한 'Hunyuan-MT Technical Report' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-11 13:02:36+0900","lastModifiedAt":"2025-09-11 13:02:36+0900","categories":["Review"],"tags":["Review","Machine Translation","Large Language Model","Multilingual","Low-Resource Languages","Reinforcement Learning","Weak-to-Strong Learning","Slow Thinking"],"permalink":"/ai/review/2025-9-11-Hunyuan-MT_Technical_Report/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-11-HumanAgencyBench_Scalable_Evaluation_of_Human_Agency_Support_in_AI_Assistants","title":"[논문리뷰] HumanAgencyBench: Scalable Evaluation of Human Agency Support in AI Assistants","excerpt":"Jacy Reese Anthis이 [arXiv]에 게시한 'HumanAgencyBench: Scalable Evaluation of Human Agency Support in AI Assistants' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-11 13:02:36+0900","lastModifiedAt":"2025-09-11 13:02:36+0900","categories":["Review"],"tags":["Review","Human Agency","AI Assistants","LLM Evaluation","Benchmark","Sociotechnical AI","AI Alignment","Scalable Evaluation"],"permalink":"/ai/review/2025-9-11-HumanAgencyBench_Scalable_Evaluation_of_Human_Agency_Support_in_AI_Assistants/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-11-EnvX_Agentize_Everything_with_Agentic_AI","title":"[논문리뷰] EnvX: Agentize Everything with Agentic AI","excerpt":"Wenzheng Tom Tang이 [arXiv]에 게시한 'EnvX: Agentize Everything with Agentic AI' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-11 13:02:36+0900","lastModifiedAt":"2025-09-11 13:02:36+0900","categories":["Review"],"tags":["Review","Agentic AI","Multi-Agent Systems","Code Repository","Agentization","Natural Language Interaction","Agent-to-Agent Protocol","LLM-based Agents"],"permalink":"/ai/review/2025-9-11-EnvX_Agentize_Everything_with_Agentic_AI/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-11-A_Survey_of_Reinforcement_Learning_for_Large_Reasoning_Models","title":"[논문리뷰] A Survey of Reinforcement Learning for Large Reasoning Models","excerpt":"Runze Liu이 [arXiv]에 게시한 'A Survey of Reinforcement Learning for Large Reasoning Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-11 13:02:36+0900","lastModifiedAt":"2025-09-11 13:02:36+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","Large Reasoning Models","LLMs","Reward Design","Policy Optimization","Verifiable Rewards","Agentic AI","Multimodal AI"],"permalink":"/ai/review/2025-9-11-A_Survey_of_Reinforcement_Learning_for_Large_Reasoning_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-11-AgentGym-RL_Training_LLM_Agents_for_Long-Horizon_Decision_Making_through_Multi-Turn_Reinforcement_Learning","title":"[논문리뷰] AgentGym-RL: Training LLM Agents for Long-Horizon Decision Making through Multi-Turn Reinforcement Learning","excerpt":"Honglin Guo이 [arXiv]에 게시한 'AgentGym-RL: Training LLM Agents for Long-Horizon Decision Making through Multi-Turn Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-11 13:02:36+0900","lastModifiedAt":"2025-09-11 13:02:36+0900","categories":["Review"],"tags":["Review","LLM Agents","Reinforcement Learning","Multi-Turn Interaction","Long-Horizon Decision Making","Agent Framework","Exploration-Exploitation","Progressive Scaling"],"permalink":"/ai/review/2025-9-11-AgentGym-RL_Training_LLM_Agents_for_Long-Horizon_Decision_Making_through_Multi-Turn_Reinforcement_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-11-3D_and_4D_World_Modeling_A_Survey","title":"[논문리뷰] 3D and 4D World Modeling: A Survey","excerpt":"Ao Liang이 [arXiv]에 게시한 '3D and 4D World Modeling: A Survey' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-11 13:02:36+0900","lastModifiedAt":"2025-09-11 13:02:36+0900","categories":["Review"],"tags":["Review","3D World Modeling","4D World Modeling","Generative Models","Predictive Models","LiDAR","Occupancy Grids","Video Generation","Autonomous Driving","Robotics"],"permalink":"/ai/review/2025-9-11-3D_and_4D_World_Modeling_A_Survey/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-10-ΔL_Normalization_Rethink_Loss_Aggregation_in_RLVR","title":"[논문리뷰] ΔL Normalization: Rethink Loss Aggregation in RLVR","excerpt":"Lili Qiu이 [arXiv]에 게시한 'ΔL Normalization: Rethink Loss Aggregation in RLVR' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-10 13:11:01+0900","lastModifiedAt":"2025-09-10 13:11:01+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","LLMs","Gradient Variance","Loss Aggregation","Unbiased Estimator","RLVR","Policy Gradient","Normalization"],"permalink":"/ai/review/2025-9-10-ΔL_Normalization_Rethink_Loss_Aggregation_in_RLVR/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-10-Visual_Representation_Alignment_for_Multimodal_Large_Language_Models","title":"[논문리뷰] Visual Representation Alignment for Multimodal Large Language Models","excerpt":"Heeseong Shin이 [arXiv]에 게시한 'Visual Representation Alignment for Multimodal Large Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-10 13:11:01+0900","lastModifiedAt":"2025-09-10 13:11:01+0900","categories":["Review"],"tags":["Review","Multimodal LLMs","Visual Representation Alignment","Foundation Models","Regularization","Fine-grained Visual Understanding","Spatial Reasoning","Object Counting","Vision-Language Models"],"permalink":"/ai/review/2025-9-10-Visual_Representation_Alignment_for_Multimodal_Large_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-10-UMO_Scaling_Multi-Identity_Consistency_for_Image_Customization_via_Matching_Reward","title":"[논문리뷰] UMO: Scaling Multi-Identity Consistency for Image Customization via Matching Reward","excerpt":"Fei Ding이 [arXiv]에 게시한 'UMO: Scaling Multi-Identity Consistency for Image Customization via Matching Reward' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-10 13:11:01+0900","lastModifiedAt":"2025-09-10 13:11:01+0900","categories":["Review"],"tags":["Review","Image Customization","Multi-Identity Generation","Identity Consistency","Identity Confusion","Reinforcement Learning","Diffusion Models","Matching Reward","Global Assignment"],"permalink":"/ai/review/2025-9-10-UMO_Scaling_Multi-Identity_Consistency_for_Image_Customization_via_Matching_Reward/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-10-Staying_in_the_Sweet_Spot_Responsive_Reasoning_Evolution_via_Capability-Adaptive_Hint_Scaffolding","title":"[논문리뷰] Staying in the Sweet Spot: Responsive Reasoning Evolution via Capability-Adaptive Hint Scaffolding","excerpt":"Yongcheng Zeng이 [arXiv]에 게시한 'Staying in the Sweet Spot: Responsive Reasoning Evolution via Capability-Adaptive Hint Scaffolding' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-10 13:11:01+0900","lastModifiedAt":"2025-09-10 13:11:01+0900","categories":["Review"],"tags":["Review","RLVR","LLM Reasoning","Adaptive Learning","Hint Scaffolding","Item Response Theory","Exploration Efficiency","Problem Difficulty","Policy Optimization"],"permalink":"/ai/review/2025-9-10-Staying_in_the_Sweet_Spot_Responsive_Reasoning_Evolution_via_Capability-Adaptive_Hint_Scaffolding/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-10-SimpleQA_Verified_A_Reliable_Factuality_Benchmark_to_Measure_Parametric_Knowledge","title":"[논문리뷰] SimpleQA Verified: A Reliable Factuality Benchmark to Measure Parametric Knowledge","excerpt":"Dipanjan Das이 [arXiv]에 게시한 'SimpleQA Verified: A Reliable Factuality Benchmark to Measure Parametric Knowledge' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-10 13:11:01+0900","lastModifiedAt":"2025-09-10 13:11:01+0900","categories":["Review"],"tags":["Review","LLM Factuality","Parametric Knowledge","Benchmark","Question Answering","Data Curation","Evaluation Metrics","Hallucination Mitigation","Large Language Models"],"permalink":"/ai/review/2025-9-10-SimpleQA_Verified_A_Reliable_Factuality_Benchmark_to_Measure_Parametric_Knowledge/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-10-Reconstruction_Alignment_Improves_Unified_Multimodal_Models","title":"[논문리뷰] Reconstruction Alignment Improves Unified Multimodal Models","excerpt":"XuDong Wang이 [arXiv]에 게시한 'Reconstruction Alignment Improves Unified Multimodal Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-10 13:11:01+0900","lastModifiedAt":"2025-09-10 13:11:01+0900","categories":["Review"],"tags":["Review","Unified Multimodal Models","Image Generation","Image Editing","Post-training","Self-supervised Learning","Reconstruction Alignment","Visual Embeddings"],"permalink":"/ai/review/2025-9-10-Reconstruction_Alignment_Improves_Unified_Multimodal_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-10-Q-Sched_Pushing_the_Boundaries_of_Few-Step_Diffusion_Models_with_Quantization-Aware_Scheduling","title":"[논문리뷰] Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling","excerpt":"Diana Marculescu이 [arXiv]에 게시한 'Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-10 13:11:01+0900","lastModifiedAt":"2025-09-10 13:11:01+0900","categories":["Review"],"tags":["Review","Diffusion Models","Quantization","Few-Step Generation","Model Compression","Noise Scheduling","Post-Training Quantization","Image Quality Metrics","Latent Consistency Models"],"permalink":"/ai/review/2025-9-10-Q-Sched_Pushing_the_Boundaries_of_Few-Step_Diffusion_Models_with_Quantization-Aware_Scheduling/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-10-Parallel-R1_Towards_Parallel_Thinking_via_Reinforcement_Learning","title":"[논문리뷰] Parallel-R1: Towards Parallel Thinking via Reinforcement Learning","excerpt":"Xinyu Yang이 [arXiv]에 게시한 'Parallel-R1: Towards Parallel Thinking via Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-10 13:11:01+0900","lastModifiedAt":"2025-09-10 13:11:01+0900","categories":["Review"],"tags":["Review","Large Language Models","Parallel Thinking","Reinforcement Learning","Mathematical Reasoning","Progressive Curriculum","Reward Design","Exploration Scaffold"],"permalink":"/ai/review/2025-9-10-Parallel-R1_Towards_Parallel_Thinking_via_Reinforcement_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-10-Mini-o3_Scaling_Up_Reasoning_Patterns_and_Interaction_Turns_for_Visual_Search","title":"[논문리뷰] Mini-o3: Scaling Up Reasoning Patterns and Interaction Turns for Visual Search","excerpt":"Tianjian Li이 [arXiv]에 게시한 'Mini-o3: Scaling Up Reasoning Patterns and Interaction Turns for Visual Search' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-10 13:11:01+0900","lastModifiedAt":"2025-09-10 13:11:01+0900","categories":["Review"],"tags":["Review","Visual Search","Multi-Turn Reasoning","Reinforcement Learning","Tool-Integrated Agents","Exploratory Reasoning","Data Augmentation","Over-turn Masking","Visual Language Models"],"permalink":"/ai/review/2025-9-10-Mini-o3_Scaling_Up_Reasoning_Patterns_and_Interaction_Turns_for_Visual_Search/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-10-Language_Self-Play_For_Data-Free_Training","title":"[논문리뷰] Language Self-Play For Data-Free Training","excerpt":"Vijai Mohan이 [arXiv]에 게시한 'Language Self-Play For Data-Free Training' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-10 13:11:01+0900","lastModifiedAt":"2025-09-10 13:11:01+0900","categories":["Review"],"tags":["Review","Large Language Models","Reinforcement Learning","Self-Play","Data-Free Training","Instruction Following","Adversarial Training","Reward Modeling"],"permalink":"/ai/review/2025-9-10-Language_Self-Play_For_Data-Free_Training/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-10-F1_A_Vision-Language-Action_Model_Bridging_Understanding_and_Generation_to_Actions","title":"[논문리뷰] F1: A Vision-Language-Action Model Bridging Understanding and Generation to Actions","excerpt":"Zherui Qiu이 [arXiv]에 게시한 'F1: A Vision-Language-Action Model Bridging Understanding and Generation to Actions' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-10 13:11:01+0900","lastModifiedAt":"2025-09-10 13:11:01+0900","categories":["Review"],"tags":["Review","Vision-Language-Action","Embodied AI","Visual Foresight","Predictive Inverse Dynamics","Mixture-of-Transformer","Robot Manipulation","Multi-stage Training","Generalization"],"permalink":"/ai/review/2025-9-10-F1_A_Vision-Language-Action_Model_Bridging_Understanding_and_Generation_to_Actions/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-10-Directly_Aligning_the_Full_Diffusion_Trajectory_with_Fine-Grained_Human_Preference","title":"[논문리뷰] Directly Aligning the Full Diffusion Trajectory with Fine-Grained Human Preference","excerpt":"Yingfang Zhang이 [arXiv]에 게시한 'Directly Aligning the Full Diffusion Trajectory with Fine-Grained Human Preference' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-10 13:11:01+0900","lastModifiedAt":"2025-09-10 13:11:01+0900","categories":["Review"],"tags":["Review","Diffusion Models","Reinforcement Learning","Human Preference","Text-to-Image Generation","Reward Hacking","Direct-Align","SRPO","Fine-Grained Control","Flow Matching Models"],"permalink":"/ai/review/2025-9-10-Directly_Aligning_the_Full_Diffusion_Trajectory_with_Fine-Grained_Human_Preference/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-10-Curia_A_Multi-Modal_Foundation_Model_for_Radiology","title":"[논문리뷰] Curia: A Multi-Modal Foundation Model for Radiology","excerpt":"Elodie Ferreres이 [arXiv]에 게시한 'Curia: A Multi-Modal Foundation Model for Radiology' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-10 13:11:01+0900","lastModifiedAt":"2025-09-10 13:11:01+0900","categories":["Review"],"tags":["Review","Foundation Model","Radiology","Computed Tomography (CT)","Magnetic Resonance Imaging (MRI)","Self-supervised Learning","Vision Transformer","Cross-Modality Generalization"],"permalink":"/ai/review/2025-9-10-Curia_A_Multi-Modal_Foundation_Model_for_Radiology/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-10-Causal_Attention_with_Lookahead_Keys","title":"[논문리뷰] Causal Attention with Lookahead Keys","excerpt":"Quanquan Gu이 [arXiv]에 게시한 'Causal Attention with Lookahead Keys' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-10 13:11:01+0900","lastModifiedAt":"2025-09-10 13:11:01+0900","categories":["Review"],"tags":["Review","Causal Attention","Lookahead Keys","Autoregressive Modeling","Language Models","Transformer","Perplexity Reduction","Parallel Training","Efficient Inference"],"permalink":"/ai/review/2025-9-10-Causal_Attention_with_Lookahead_Keys/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-9-WebExplorer_Explore_and_Evolve_for_Training_Long-Horizon_Web_Agents","title":"[논문리뷰] WebExplorer: Explore and Evolve for Training Long-Horizon Web Agents","excerpt":"Aili Chen이 [arXiv]에 게시한 'WebExplorer: Explore and Evolve for Training Long-Horizon Web Agents' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-09 13:19:09+0900","lastModifiedAt":"2025-09-09 13:19:09+0900","categories":["Review"],"tags":["Review","Web Agents","Long-Horizon Reasoning","Large Language Models (LLMs)","Data Generation","Reinforcement Learning (RL)","Supervised Fine-tuning (SFT)","Web Navigation","Information Retrieval"],"permalink":"/ai/review/2025-9-9-WebExplorer_Explore_and_Evolve_for_Training_Long-Horizon_Web_Agents/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-9-UniVerse-1_Unified_Audio-Video_Generation_via_Stitching_of_Experts","title":"[논문리뷰] UniVerse-1: Unified Audio-Video Generation via Stitching of Experts","excerpt":"Xinyao Liao이 [arXiv]에 게시한 'UniVerse-1: Unified Audio-Video Generation via Stitching of Experts' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-09 13:19:09+0900","lastModifiedAt":"2025-09-09 13:19:09+0900","categories":["Review"],"tags":["Review","Unified Audio-Video Generation","Stitching of Experts (SoE)","Multimodal Diffusion","Online Annotation","Cross-modal Noise Correlation","Foundation Models","Verse-Bench"],"permalink":"/ai/review/2025-9-9-UniVerse-1_Unified_Audio-Video_Generation_via_Stitching_of_Experts/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-9-Test-Time_Scaling_in_Reasoning_Models_Is_Not_Effective_for_Knowledge-Intensive_Tasks_Yet","title":"[논문리뷰] Test-Time Scaling in Reasoning Models Is Not Effective for Knowledge-Intensive Tasks Yet","excerpt":"See-Kiong Ng이 [arXiv]에 게시한 'Test-Time Scaling in Reasoning Models Is Not Effective for Knowledge-Intensive Tasks Yet' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-09 13:19:09+0900","lastModifiedAt":"2025-09-09 13:19:09+0900","categories":["Review"],"tags":["Review","Test-Time Scaling","Reasoning Models","Knowledge-Intensive Tasks","Hallucinations","Factual Accuracy","Chain-of-Thought","Large Language Models"],"permalink":"/ai/review/2025-9-9-Test-Time_Scaling_in_Reasoning_Models_Is_Not_Effective_for_Knowledge-Intensive_Tasks_Yet/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-9-Scaling_up_Multi-Turn_Off-Policy_RL_and_Multi-Agent_Tree_Search_for_LLM_Step-Provers","title":"[논문리뷰] Scaling up Multi-Turn Off-Policy RL and Multi-Agent Tree Search for LLM Step-Provers","excerpt":"Xia Xiao이 [arXiv]에 게시한 'Scaling up Multi-Turn Off-Policy RL and Multi-Agent Tree Search for LLM Step-Provers' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-09 13:19:09+0900","lastModifiedAt":"2025-09-09 13:19:09+0900","categories":["Review"],"tags":["Review","LLM Step-Provers","Reinforcement Learning (RL)","Off-Policy RL","Multi-Agent Systems","Tree Search","Automated Theorem Proving (ATP)","Formal Mathematics","AlphaZero"],"permalink":"/ai/review/2025-9-9-Scaling_up_Multi-Turn_Off-Policy_RL_and_Multi-Agent_Tree_Search_for_LLM_Step-Provers/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-9-Saturation-Driven_Dataset_Generation_for_LLM_Mathematical_Reasoning_in_the_TPTP_Ecosystem","title":"[논문리뷰] Saturation-Driven Dataset Generation for LLM Mathematical Reasoning in the TPTP Ecosystem","excerpt":"Damien Sileo이 [arXiv]에 게시한 'Saturation-Driven Dataset Generation for LLM Mathematical Reasoning in the TPTP Ecosystem' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-09 13:19:09+0900","lastModifiedAt":"2025-09-09 13:19:09+0900","categories":["Review"],"tags":["Review","Automated Theorem Proving","LLM","Mathematical Reasoning","Synthetic Data Generation","TPTP Ecosystem","Saturation Proving","Proof Graph Reconstruction","Data Augmentation"],"permalink":"/ai/review/2025-9-9-Saturation-Driven_Dataset_Generation_for_LLM_Mathematical_Reasoning_in_the_TPTP_Ecosystem/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-9-Rtextbf2AI_Towards_Resistant_and_Resilient_AI_in_an_Evolving_World","title":"[논문리뷰] R^textbf{2AI}: Towards Resistant and Resilient AI in an Evolving World","excerpt":"Bowen Zhou이 [arXiv]에 게시한 'R^textbf{2AI}: Towards Resistant and Resilient AI in an Evolving World' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-09 13:19:09+0900","lastModifiedAt":"2025-09-09 13:19:09+0900","categories":["Review"],"tags":["Review","AI Safety","Resistant AI","Resilient AI","Coevolution","Fast-Slow Models","Adversarial Training","Continual Learning","AGI Alignment"],"permalink":"/ai/review/2025-9-9-Rtextbf2AI_Towards_Resistant_and_Resilient_AI_in_an_Evolving_World/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-9-Revolutionizing_Reinforcement_Learning_Framework_for_Diffusion_Large_Language_Models","title":"[논문리뷰] Revolutionizing Reinforcement Learning Framework for Diffusion Large Language Models","excerpt":"Ke Shen이 [arXiv]에 게시한 'Revolutionizing Reinforcement Learning Framework for Diffusion Large Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-09 13:19:09+0900","lastModifiedAt":"2025-09-09 13:19:09+0900","categories":["Review"],"tags":["Review","Diffusion Language Models","Reinforcement Learning","Trajectory-aware RL","Value Model","Masked Diffusion Models","Large Language Models","Reasoning Tasks","Code Generation"],"permalink":"/ai/review/2025-9-9-Revolutionizing_Reinforcement_Learning_Framework_for_Diffusion_Large_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-9-Reverse-Engineered_Reasoning_for_Open-Ended_Generation","title":"[논문리뷰] Reverse-Engineered Reasoning for Open-Ended Generation","excerpt":"Wangchunshu Zhou이 [arXiv]에 게시한 'Reverse-Engineered Reasoning for Open-Ended Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-09 13:19:09+0900","lastModifiedAt":"2025-09-09 13:19:09+0900","categories":["Review"],"tags":["Review","Deep Reasoning","Open-Ended Generation","Reverse-Engineered Reasoning (REER)","LLMs","Synthetic Data","Iterative Refinement","Perplexity Minimization","DeepWriting-20K"],"permalink":"/ai/review/2025-9-9-Reverse-Engineered_Reasoning_for_Open-Ended_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-9-Reinforcement_Learning_Foundations_for_Deep_Research_Systems_A_Survey","title":"[논문리뷰] Reinforcement Learning Foundations for Deep Research Systems: A Survey","excerpt":"Wei Han이 [arXiv]에 게시한 'Reinforcement Learning Foundations for Deep Research Systems: A Survey' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-09 13:19:09+0900","lastModifiedAt":"2025-09-09 13:19:09+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","Deep Research Systems","Agentic AI","Tool Use","Hierarchical Agents","Reward Design","Multimodal AI","RL Frameworks"],"permalink":"/ai/review/2025-9-9-Reinforcement_Learning_Foundations_for_Deep_Research_Systems_A_Survey/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-9-Reinforced_Visual_Perception_with_Tools","title":"[논문리뷰] Reinforced Visual Perception with Tools","excerpt":"Mingyang Fu이 [arXiv]에 게시한 'Reinforced Visual Perception with Tools' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-09 13:19:09+0900","lastModifiedAt":"2025-09-09 13:19:09+0900","categories":["Review"],"tags":["Review","Visual Reasoning","Multimodal LLMs","Reinforcement Learning","Tool Usage","Perception-heavy Benchmarks","GRPO","Vision Tools"],"permalink":"/ai/review/2025-9-9-Reinforced_Visual_Perception_with_Tools/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-9-Paper2Agent_Reimagining_Research_Papers_As_Interactive_and_Reliable_AI_Agents","title":"[논문리뷰] Paper2Agent: Reimagining Research Papers As Interactive and Reliable AI Agents","excerpt":"James Zou이 [arXiv]에 게시한 'Paper2Agent: Reimagining Research Papers As Interactive and Reliable AI Agents' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-09 13:19:09+0900","lastModifiedAt":"2025-09-09 13:19:09+0900","categories":["Review"],"tags":["Review","AI Agents","Research Reproducibility","Scientific Communication","Model Context Protocol (MCP)","Natural Language Interaction","Genomics","Single-Cell Analysis","Spatial Transcriptomics"],"permalink":"/ai/review/2025-9-9-Paper2Agent_Reimagining_Research_Papers_As_Interactive_and_Reliable_AI_Agents/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-9-MAS-Bench_A_Unified_Benchmark_for_Shortcut-Augmented_Hybrid_Mobile_GUI_Agents","title":"[논문리뷰] MAS-Bench: A Unified Benchmark for Shortcut-Augmented Hybrid Mobile GUI Agents","excerpt":"Zhengxi Lu이 [arXiv]에 게시한 'MAS-Bench: A Unified Benchmark for Shortcut-Augmented Hybrid Mobile GUI Agents' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-09 13:19:09+0900","lastModifiedAt":"2025-09-09 13:19:09+0900","categories":["Review"],"tags":["Review","Mobile GUI Agents","Hybrid Automation","Shortcut Generation","Benchmark","Task Efficiency","LLM-based Agents","Mobile Robotics"],"permalink":"/ai/review/2025-9-9-MAS-Bench_A_Unified_Benchmark_for_Shortcut-Augmented_Hybrid_Mobile_GUI_Agents/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-9-Llama-GENBA-10B_A_Trilingual_Large_Language_Model_for_German_English_and_Bavarian","title":"[논문리뷰] Llama-GENBA-10B: A Trilingual Large Language Model for German, English and Bavarian","excerpt":"Hoi-Fong Mak이 [arXiv]에 게시한 'Llama-GENBA-10B: A Trilingual Large Language Model for German, English and Bavarian' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-09 13:19:09+0900","lastModifiedAt":"2025-09-09 13:19:09+0900","categories":["Review"],"tags":["Review","Multilingual LLM","Low-Resource Language","German","Bavarian Dialect","Cross-Lingual Transfer","Continuous Pretraining","Llama-3.1","Model Expansion"],"permalink":"/ai/review/2025-9-9-Llama-GENBA-10B_A_Trilingual_Large_Language_Model_for_German_English_and_Bavarian/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-9-Interleaving_Reasoning_for_Better_Text-to-Image_Generation","title":"[논문리뷰] Interleaving Reasoning for Better Text-to-Image Generation","excerpt":"Shixiang Tang이 [arXiv]에 게시한 'Interleaving Reasoning for Better Text-to-Image Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-09 13:19:09+0900","lastModifiedAt":"2025-09-09 13:19:09+0900","categories":["Review"],"tags":["Review","Text-to-Image Generation","Interleaving Reasoning","Multimodal Learning","Visual Quality","Fine-grained Detail","Diffusion Models","Self-Correction"],"permalink":"/ai/review/2025-9-9-Interleaving_Reasoning_for_Better_Text-to-Image_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-9-Focusing_by_Contrastive_Attention_Enhancing_VLMs_Visual_Reasoning","title":"[논문리뷰] Focusing by Contrastive Attention: Enhancing VLMs' Visual Reasoning","excerpt":"Baolong Bi이 [arXiv]에 게시한 'Focusing by Contrastive Attention: Enhancing VLMs' Visual Reasoning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-09 13:19:09+0900","lastModifiedAt":"2025-09-09 13:19:09+0900","categories":["Review"],"tags":["Review","Vision-Language Models (VLMs)","Visual Reasoning","Attention Mechanisms","Contrastive Learning","Noise Suppression","Visual Complexity","Training-Free"],"permalink":"/ai/review/2025-9-9-Focusing_by_Contrastive_Attention_Enhancing_VLMs_Visual_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-9-Easier_Painting_Than_Thinking_Can_Text-to-Image_Models_Set_the_Stage_but_Not_Direct_the_Play","title":"[논문리뷰] Easier Painting Than Thinking: Can Text-to-Image Models Set the Stage, but Not Direct the Play?","excerpt":"Rui Chen이 [arXiv]에 게시한 'Easier Painting Than Thinking: Can Text-to-Image Models Set the Stage, but Not Direct the Play?' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-09 13:19:09+0900","lastModifiedAt":"2025-09-09 13:19:09+0900","categories":["Review"],"tags":["Review","Text-to-Image Generation","T2I Benchmarking","Compositional Reasoning","Deductive Inference","Inductive Inference","Abductive Inference","MLLM Evaluation"],"permalink":"/ai/review/2025-9-9-Easier_Painting_Than_Thinking_Can_Text-to-Image_Models_Set_the_Stage_but_Not_Direct_the_Play/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-9-Does_DINOv3_Set_a_New_Medical_Vision_Standard","title":"[논문리뷰] Does DINOv3 Set a New Medical Vision Standard?","excerpt":"Bailiang Jian이 [arXiv]에 게시한 'Does DINOv3 Set a New Medical Vision Standard?' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-09 13:19:09+0900","lastModifiedAt":"2025-09-09 13:19:09+0900","categories":["Review"],"tags":["Review","Medical Imaging","Foundation Models","DINOv3","Self-Supervised Learning","Vision Transformer","2D/3D Classification","Segmentation","Domain Adaptation","Scaling Laws"],"permalink":"/ai/review/2025-9-9-Does_DINOv3_Set_a_New_Medical_Vision_Standard/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-9-D-HUMOR_Dark_Humor_Understanding_via_Multimodal_Open-ended_Reasoning","title":"[논문리뷰] D-HUMOR: Dark Humor Understanding via Multimodal Open-ended Reasoning","excerpt":"Dhanvin Sanjay Namboodiri이 [arXiv]에 게시한 'D-HUMOR: Dark Humor Understanding via Multimodal Open-ended Reasoning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-09 13:19:09+0900","lastModifiedAt":"2025-09-09 13:19:09+0900","categories":["Review"],"tags":["Review","Dark Humor Detection","Multimodal Reasoning","Vision-Language Models (VLMs)","Iterative Reasoning Refinement","Meme Analysis","Content Moderation","Cross-Modal Attention","Dataset Annotation"],"permalink":"/ai/review/2025-9-9-D-HUMOR_Dark_Humor_Understanding_via_Multimodal_Open-ended_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-8-WinT3R_Window-Based_Streaming_Reconstruction_with_Camera_Token_Pool","title":"[논문리뷰] WinT3R: Window-Based Streaming Reconstruction with Camera Token Pool","excerpt":"Wenzheng Chang이 [arXiv]에 게시한 'WinT3R: Window-Based Streaming Reconstruction with Camera Token Pool' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-08 13:10:18+0900","lastModifiedAt":"2025-09-08 13:10:18+0900","categories":["Review"],"tags":["Review","Online 3D Reconstruction","Camera Pose Estimation","Streaming Reconstruction","Sliding Window","Camera Token Pool","Real-time Performance","Computer Vision"],"permalink":"/ai/review/2025-9-8-WinT3R_Window-Based_Streaming_Reconstruction_with_Camera_Token_Pool/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-8-WildScore_Benchmarking_MLLMs_in-the-Wild_Symbolic_Music_Reasoning","title":"[논문리뷰] WildScore: Benchmarking MLLMs in-the-Wild Symbolic Music Reasoning","excerpt":"Amit Namburi이 [arXiv]에 게시한 'WildScore: Benchmarking MLLMs in-the-Wild Symbolic Music Reasoning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-08 13:10:18+0900","lastModifiedAt":"2025-09-08 13:10:18+0900","categories":["Review"],"tags":["Review","Multimodal Large Language Models","Symbolic Music Reasoning","Music Score Analysis","Benchmarking","Visual Question Answering","In-the-Wild Data","Music Theory"],"permalink":"/ai/review/2025-9-8-WildScore_Benchmarking_MLLMs_in-the-Wild_Symbolic_Music_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-8-Why_Language_Models_Hallucinate","title":"[논문리뷰] Why Language Models Hallucinate","excerpt":"Edwin Zhang이 [arXiv]에 게시한 'Why Language Models Hallucinate' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-08 13:10:18+0900","lastModifiedAt":"2025-09-08 13:10:18+0900","categories":["Review"],"tags":["Review","Language Models","Hallucination","Pretraining","Post-training","Evaluation Metrics","Binary Classification","Uncertainty Quantification","Calibration"],"permalink":"/ai/review/2025-9-8-Why_Language_Models_Hallucinate/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-8-U-ARM_Ultra_low-cost_general_teleoperation_interface_for_robot_manipulation","title":"[논문리뷰] U-ARM : Ultra low-cost general teleoperation interface for robot manipulation","excerpt":"Junda Huang이 [arXiv]에 게시한 'U-ARM : Ultra low-cost general teleoperation interface for robot manipulation' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-08 13:10:18+0900","lastModifiedAt":"2025-09-08 13:10:18+0900","categories":["Review"],"tags":["Review","Teleoperation","Robot Manipulation","Low-Cost Hardware","3D Printing","Leader-Follower System","Data Collection","Robotics Interface","Open Source"],"permalink":"/ai/review/2025-9-8-U-ARM_Ultra_low-cost_general_teleoperation_interface_for_robot_manipulation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-8-Symbolic_Graphics_Programming_with_Large_Language_Models","title":"[논문리뷰] Symbolic Graphics Programming with Large Language Models","excerpt":"Kaipeng Zhang이 [arXiv]에 게시한 'Symbolic Graphics Programming with Large Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-08 13:10:18+0900","lastModifiedAt":"2025-09-08 13:10:18+0900","categories":["Review"],"tags":["Review","Symbolic Graphics Programming","Large Language Models","Reinforcement Learning","SVG Generation","Text-to-Image Synthesis","Cross-Modal Alignment","Program Synthesis"],"permalink":"/ai/review/2025-9-8-Symbolic_Graphics_Programming_with_Large_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-8-Set_Block_Decoding_is_a_Language_Model_Inference_Accelerator","title":"[논문리뷰] Set Block Decoding is a Language Model Inference Accelerator","excerpt":"Jeremy Reizenstein이 [arXiv]에 게시한 'Set Block Decoding is a Language Model Inference Accelerator' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-08 13:10:18+0900","lastModifiedAt":"2025-09-08 13:10:18+0900","categories":["Review"],"tags":["Review","Language Model Inference","Acceleration","Set Block Decoding","Next Token Prediction","Masked Token Prediction","Parallel Decoding","KV-caching","Diffusion Models"],"permalink":"/ai/review/2025-9-8-Set_Block_Decoding_is_a_Language_Model_Inference_Accelerator/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-8-On_Robustness_and_Reliability_of_Benchmark-Based_Evaluation_of_LLMs","title":"[논문리뷰] On Robustness and Reliability of Benchmark-Based Evaluation of LLMs","excerpt":"Kevin Roitero이 [arXiv]에 게시한 'On Robustness and Reliability of Benchmark-Based Evaluation of LLMs' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-08 13:10:18+0900","lastModifiedAt":"2025-09-08 13:10:18+0900","categories":["Review"],"tags":["Review","LLM Evaluation","Model Robustness","Benchmark Reliability","Paraphrasing","Linguistic Variability","Generalization","Question Answering"],"permalink":"/ai/review/2025-9-8-On_Robustness_and_Reliability_of_Benchmark-Based_Evaluation_of_LLMs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-8-MedVista3D_Vision-Language_Modeling_for_Reducing_Diagnostic_Errors_in_3D_CT_Disease_Detection_Understanding_and_Reporting","title":"[논문리뷰] MedVista3D: Vision-Language Modeling for Reducing Diagnostic Errors in 3D CT Disease Detection, Understanding and Reporting","excerpt":"Vanessa Wildman이 [arXiv]에 게시한 'MedVista3D: Vision-Language Modeling for Reducing Diagnostic Errors in 3D CT Disease Detection, Understanding and Reporting' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-08 13:10:18+0900","lastModifiedAt":"2025-09-08 13:10:18+0900","categories":["Review"],"tags":["Review","3D CT","Vision-Language Model","Medical Imaging","Diagnostic Error Reduction","Multi-scale Alignment","Semantic Enrichment","Radiology Reporting","Zero-shot Learning"],"permalink":"/ai/review/2025-9-8-MedVista3D_Vision-Language_Modeling_for_Reducing_Diagnostic_Errors_in_3D_CT_Disease_Detection_Understanding_and_Reporting/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-8-LuxDiT_Lighting_Estimation_with_Video_Diffusion_Transformer","title":"[논문리뷰] LuxDiT: Lighting Estimation with Video Diffusion Transformer","excerpt":"Sanja Fidler이 [arXiv]에 게시한 'LuxDiT: Lighting Estimation with Video Diffusion Transformer' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-08 13:10:18+0900","lastModifiedAt":"2025-09-08 13:10:18+0900","categories":["Review"],"tags":["Review","Lighting Estimation","HDR Environment Map","Diffusion Models","Video Transformer","Low-Rank Adaptation","Generative Models","Synthetic Data"],"permalink":"/ai/review/2025-9-8-LuxDiT_Lighting_Estimation_with_Video_Diffusion_Transformer/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-8-LatticeWorld_A_Multimodal_Large_Language_Model-Empowered_Framework_for_Interactive_Complex_World_Generation","title":"[논문리뷰] LatticeWorld: A Multimodal Large Language Model-Empowered Framework for Interactive Complex World Generation","excerpt":"Zhan Zhao이 [arXiv]에 게시한 'LatticeWorld: A Multimodal Large Language Model-Empowered Framework for Interactive Complex World Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-08 13:10:18+0900","lastModifiedAt":"2025-09-08 13:10:18+0900","categories":["Review"],"tags":["Review","Multimodal LLM","3D World Generation","Unreal Engine 5","Procedural Content Generation","Interactive Environments","Sim-to-Real","Spatial Understanding","Multimodal Input"],"permalink":"/ai/review/2025-9-8-LatticeWorld_A_Multimodal_Large_Language_Model-Empowered_Framework_for_Interactive_Complex_World_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-8-Bootstrapping_Task_Spaces_for_Self-Improvement","title":"[논문리뷰] Bootstrapping Task Spaces for Self-Improvement","excerpt":"Yoram Bachrach이 [arXiv]에 게시한 'Bootstrapping Task Spaces for Self-Improvement' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-08 13:10:18+0900","lastModifiedAt":"2025-09-08 13:10:18+0900","categories":["Review"],"tags":["Review","Reinforcement Learning (RL)","Large Language Models (LLMs)","Self-Improvement","Autocurriculum","Task-Space Exploration","Inference-Time Iteration","Policy Optimization"],"permalink":"/ai/review/2025-9-8-Bootstrapping_Task_Spaces_for_Self-Improvement/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-8-Behavioral_Fingerprinting_of_Large_Language_Models","title":"[논문리뷰] Behavioral Fingerprinting of Large Language Models","excerpt":"Xing Li이 [arXiv]에 게시한 'Behavioral Fingerprinting of Large Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-08 13:10:18+0900","lastModifiedAt":"2025-09-08 13:10:18+0900","categories":["Review"],"tags":["Review","Large Language Models","Behavioral Evaluation","Model Alignment","Sycophancy","World Model Brittleness","Metacognition","Personality Profiling"],"permalink":"/ai/review/2025-9-8-Behavioral_Fingerprinting_of_Large_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-5-Video-MTR_Reinforced_Multi-Turn_Reasoning_for_Long_Video_Understanding","title":"[논문리뷰] Video-MTR: Reinforced Multi-Turn Reasoning for Long Video Understanding","excerpt":"Lionel Ni이 [arXiv]에 게시한 'Video-MTR: Reinforced Multi-Turn Reasoning for Long Video Understanding' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-05 13:07:20+0900","lastModifiedAt":"2025-09-05 13:07:20+0900","categories":["Review"],"tags":["Review","Long Video Understanding","Reinforcement Learning","Multi-Turn Reasoning","MLLMs","Video Segment Selection","Bi-level Reward","Question Answering"],"permalink":"/ai/review/2025-9-5-Video-MTR_Reinforced_Multi-Turn_Reasoning_for_Long_Video_Understanding/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-5-Transition_Models_Rethinking_the_Generative_Learning_Objective","title":"[논문리뷰] Transition Models: Rethinking the Generative Learning Objective","excerpt":"Yangguang Li이 [arXiv]에 게시한 'Transition Models: Rethinking the Generative Learning Objective' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-05 13:07:20+0900","lastModifiedAt":"2025-09-05 13:07:20+0900","categories":["Review"],"tags":["Review","Generative Models","Diffusion Models","Training Objective","Continuous-Time Dynamics","State Transition","Few-Step Generation","Scalable Training","Image Generation"],"permalink":"/ai/review/2025-9-5-Transition_Models_Rethinking_the_Generative_Learning_Objective/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-5-Towards_a_Unified_View_of_Large_Language_Model_Post-Training","title":"[논문리뷰] Towards a Unified View of Large Language Model Post-Training","excerpt":"Hongyi Liu이 [arXiv]에 게시한 'Towards a Unified View of Large Language Model Post-Training' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-05 13:07:20+0900","lastModifiedAt":"2025-09-05 13:07:20+0900","categories":["Review"],"tags":["Review","Large Language Models (LLMs)","Post-Training","Reinforcement Learning (RL)","Supervised Fine-Tuning (SFT)","Policy Gradient","Unified Framework","Hybrid Algorithms","Bias-Variance Tradeoff"],"permalink":"/ai/review/2025-9-5-Towards_a_Unified_View_of_Large_Language_Model_Post-Training/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-5-NER_Retriever_Zero-Shot_Named_Entity_Retrieval_with_Type-Aware_Embeddings","title":"[논문리뷰] NER Retriever: Zero-Shot Named Entity Retrieval with Type-Aware Embeddings","excerpt":"Oren Glickman이 [arXiv]에 게시한 'NER Retriever: Zero-Shot Named Entity Retrieval with Type-Aware Embeddings' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-05 13:07:20+0900","lastModifiedAt":"2025-09-05 13:07:20+0900","categories":["Review"],"tags":["Review","Named Entity Retrieval","Zero-Shot Learning","Type-Aware Embeddings","Large Language Models (LLMs)","Contrastive Learning","Internal Representations","Information Retrieval"],"permalink":"/ai/review/2025-9-5-NER_Retriever_Zero-Shot_Named_Entity_Retrieval_with_Type-Aware_Embeddings/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-5-Inverse_IFEval_Can_LLMs_Unlearn_Stubborn_Training_Conventions_to_Follow_Real_Instructions","title":"[논문리뷰] Inverse IFEval: Can LLMs Unlearn Stubborn Training Conventions to Follow Real Instructions?","excerpt":"Yu Fu이 [arXiv]에 게시한 'Inverse IFEval: Can LLMs Unlearn Stubborn Training Conventions to Follow Real Instructions?' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-05 13:07:20+0900","lastModifiedAt":"2025-09-05 13:07:20+0900","categories":["Review"],"tags":["Review","LLMs","Instruction Following","Benchmark","Cognitive Inertia","Out-of-Distribution","Supervised Fine-Tuning","Evaluation","Robustness"],"permalink":"/ai/review/2025-9-5-Inverse_IFEval_Can_LLMs_Unlearn_Stubborn_Training_Conventions_to_Follow_Real_Instructions/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-5-From_Editor_to_Dense_Geometry_Estimator","title":"[논문리뷰] From Editor to Dense Geometry Estimator","excerpt":"Lang Nie이 [arXiv]에 게시한 'From Editor to Dense Geometry Estimator' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-05 13:07:20+0900","lastModifiedAt":"2025-09-05 13:07:20+0900","categories":["Review"],"tags":["Review","Dense Geometry Estimation","Diffusion Transformer","Image Editing","Zero-shot Learning","Depth Estimation","Normal Estimation","Flow Matching","Logarithmic Quantization"],"permalink":"/ai/review/2025-9-5-From_Editor_to_Dense_Geometry_Estimator/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-5-Few-step_Flow_for_3D_Generation_via_Marginal-Data_Transport_Distillation","title":"[논문리뷰] Few-step Flow for 3D Generation via Marginal-Data Transport Distillation","excerpt":"Lingxi Xie이 [arXiv]에 게시한 'Few-step Flow for 3D Generation via Marginal-Data Transport Distillation' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-05 13:07:20+0900","lastModifiedAt":"2025-09-05 13:07:20+0900","categories":["Review"],"tags":["Review","3D Generation","Flow-based Models","Model Distillation","Few-step Sampling","Marginal-Data Transport","Velocity Matching","Velocity Distillation"],"permalink":"/ai/review/2025-9-5-Few-step_Flow_for_3D_Generation_via_Marginal-Data_Transport_Distillation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-5-False_Sense_of_Security_Why_Probing-based_Malicious_Input_Detection_Fails_to_Generalize","title":"[논문리뷰] False Sense of Security: Why Probing-based Malicious Input Detection Fails to Generalize","excerpt":"Muhao Chen이 [arXiv]에 게시한 'False Sense of Security: Why Probing-based Malicious Input Detection Fails to Generalize' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-05 13:07:20+0900","lastModifiedAt":"2025-09-05 13:07:20+0900","categories":["Review"],"tags":["Review","LLM Safety","Malicious Input Detection","Probing Classifiers","Out-of-Distribution Generalization","Superficial Patterns","Instructional Patterns","Trigger Words","AI Safety"],"permalink":"/ai/review/2025-9-5-False_Sense_of_Security_Why_Probing-based_Malicious_Input_Detection_Fails_to_Generalize/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-5-Durian_Dual_Reference-guided_Portrait_Animation_with_Attribute_Transfer","title":"[논문리뷰] Durian: Dual Reference-guided Portrait Animation with Attribute Transfer","excerpt":"Hanbyul Joo이 [arXiv]에 게시한 'Durian: Dual Reference-guided Portrait Animation with Attribute Transfer' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-05 13:07:20+0900","lastModifiedAt":"2025-09-05 13:07:20+0900","categories":["Review"],"tags":["Review","Portrait Animation","Attribute Transfer","Diffusion Models","Dual Reference Networks","Zero-shot Learning","Self-Reconstruction","Facial Editing"],"permalink":"/ai/review/2025-9-5-Durian_Dual_Reference-guided_Portrait_Animation_with_Attribute_Transfer/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-5-Drivel-ology_Challenging_LLMs_with_Interpreting_Nonsense_with_Depth","title":"[논문리뷰] Drivel-ology: Challenging LLMs with Interpreting Nonsense with Depth","excerpt":"Chi-Li Chen이 [arXiv]에 게시한 'Drivel-ology: Challenging LLMs with Interpreting Nonsense with Depth' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-05 13:07:20+0900","lastModifiedAt":"2025-09-05 13:07:20+0900","categories":["Review"],"tags":["Review","Large Language Models","Pragmatic Understanding","Drivelology","Benchmark Dataset","Multilingual NLP","Semantic Reasoning","Contextual Inference"],"permalink":"/ai/review/2025-9-5-Drivel-ology_Challenging_LLMs_with_Interpreting_Nonsense_with_Depth/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-5-Drawing2CAD_Sequence-to-Sequence_Learning_for_CAD_Generation_from_Vector_Drawings","title":"[논문리뷰] Drawing2CAD: Sequence-to-Sequence Learning for CAD Generation from Vector Drawings","excerpt":"Meie Fang이 [arXiv]에 게시한 'Drawing2CAD: Sequence-to-Sequence Learning for CAD Generation from Vector Drawings' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-05 13:07:20+0900","lastModifiedAt":"2025-09-05 13:07:20+0900","categories":["Review"],"tags":["Review","CAD Generation","Vector Graphics","Sequence-to-Sequence Learning","Transformer Architecture","Engineering Drawings","Multi-modal Learning","Soft Target Loss","Dual Decoder"],"permalink":"/ai/review/2025-9-5-Drawing2CAD_Sequence-to-Sequence_Learning_for_CAD_Generation_from_Vector_Drawings/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-5-Delta_Activations_A_Representation_for_Finetuned_Large_Language_Models","title":"[논문리뷰] Delta Activations: A Representation for Finetuned Large Language Models","excerpt":"Ser-Nam Lim이 [arXiv]에 게시한 'Delta Activations: A Representation for Finetuned Large Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-05 13:07:20+0900","lastModifiedAt":"2025-09-05 13:07:20+0900","categories":["Review"],"tags":["Review","LLM Embedding","Delta Activations","Finetuned Models","Model Representation","Model Clustering","Additive Property","Task Embedding","Model Merging"],"permalink":"/ai/review/2025-9-5-Delta_Activations_A_Representation_for_Finetuned_Large_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-5-DeepResearch_Arena_The_First_Exam_of_LLMs_Research_Abilities_via_Seminar-Grounded_Tasks","title":"[논문리뷰] DeepResearch Arena: The First Exam of LLMs' Research Abilities via Seminar-Grounded Tasks","excerpt":"Jiaxuan Lu이 [arXiv]에 게시한 'DeepResearch Arena: The First Exam of LLMs' Research Abilities via Seminar-Grounded Tasks' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-05 13:07:20+0900","lastModifiedAt":"2025-09-05 13:07:20+0900","categories":["Review"],"tags":["Review","LLM Evaluation","Research Agents","Benchmark","Multi-Agent System","Seminar-Grounded Tasks","Data Leakage Prevention","Ill-Structured Problems"],"permalink":"/ai/review/2025-9-5-DeepResearch_Arena_The_First_Exam_of_LLMs_Research_Abilities_via_Seminar-Grounded_Tasks/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-4-Robix_A_Unified_Model_for_Robot_Interaction_Reasoning_and_Planning","title":"[논문리뷰] Robix: A Unified Model for Robot Interaction, Reasoning and Planning","excerpt":"Zixuan Wang이 [arXiv]에 게시한 'Robix: A Unified Model for Robot Interaction, Reasoning and Planning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-04 12:56:15+0900","lastModifiedAt":"2025-09-04 12:56:15+0900","categories":["Review"],"tags":["Review","Robot Learning","Vision-Language Models (VLMs)","Embodied AI","Human-Robot Interaction (HRI)","Task Planning","Reinforcement Learning (RL)","Chain-of-Thought (CoT) Reasoning","Robotics"],"permalink":"/ai/review/2025-9-4-Robix_A_Unified_Model_for_Robot_Interaction_Reasoning_and_Planning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-4-Open_Data_Synthesis_For_Deep_Research","title":"[논문리뷰] Open Data Synthesis For Deep Research","excerpt":"Zheng Liu이 [arXiv]에 게시한 'Open Data Synthesis For Deep Research' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-04 12:56:15+0900","lastModifiedAt":"2025-09-04 12:56:15+0900","categories":["Review"],"tags":["Review","Data Synthesis","Deep Research","Hierarchical Constraint Satisfaction Problems","Large Language Models","Agentic AI","Reinforcement Learning","Question Answering"],"permalink":"/ai/review/2025-9-4-Open_Data_Synthesis_For_Deep_Research/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-4-MOSAIC_Multi-Subject_Personalized_Generation_via_Correspondence-Aware_Alignment_and_Disentanglement","title":"[논문리뷰] MOSAIC: Multi-Subject Personalized Generation via Correspondence-Aware Alignment and Disentanglement","excerpt":"Hualiang Wang이 [arXiv]에 게시한 'MOSAIC: Multi-Subject Personalized Generation via Correspondence-Aware Alignment and Disentanglement' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-04 12:56:15+0900","lastModifiedAt":"2025-09-04 12:56:15+0900","categories":["Review"],"tags":["Review","Multi-Subject Generation","Personalized Image Synthesis","Semantic Correspondence","Attention Disentanglement","Diffusion Models","Identity Preservation","Dataset"],"permalink":"/ai/review/2025-9-4-MOSAIC_Multi-Subject_Personalized_Generation_via_Correspondence-Aware_Alignment_and_Disentanglement/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-4-Mixture_of_Global_and_Local_Experts_with_Diffusion_Transformer_for_Controllable_Face_Generation","title":"[논문리뷰] Mixture of Global and Local Experts with Diffusion Transformer for Controllable Face Generation","excerpt":"Kai Li이 [arXiv]에 게시한 'Mixture of Global and Local Experts with Diffusion Transformer for Controllable Face Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-04 12:56:15+0900","lastModifiedAt":"2025-09-04 12:56:15+0900","categories":["Review"],"tags":["Review","Diffusion Transformer","Mixture of Experts","Controllable Generation","Face Generation","Multimodal Synthesis","Semantic Control","Image Generation"],"permalink":"/ai/review/2025-9-4-Mixture_of_Global_and_Local_Experts_with_Diffusion_Transformer_for_Controllable_Face_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-4-LMEnt_A_Suite_for_Analyzing_Knowledge_in_Language_Models_from_Pretraining_Data_to_Representations","title":"[논문리뷰] LMEnt: A Suite for Analyzing Knowledge in Language Models from Pretraining Data to Representations","excerpt":"Yoav Gur-Arieh이 [arXiv]에 게시한 'LMEnt: A Suite for Analyzing Knowledge in Language Models from Pretraining Data to Representations' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-04 12:56:15+0900","lastModifiedAt":"2025-09-04 12:56:15+0900","categories":["Review"],"tags":["Review","Language Models","Knowledge Acquisition","Pretraining Data","Entity Linking","Coreference Resolution","Information Retrieval","Model Analysis","Checkpoints"],"permalink":"/ai/review/2025-9-4-LMEnt_A_Suite_for_Analyzing_Knowledge_in_Language_Models_from_Pretraining_Data_to_Representations/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-3-ViSTA-SLAM_Visual_SLAM_with_Symmetric_Two-view_Association","title":"[논문리뷰] ViSTA-SLAM: Visual SLAM with Symmetric Two-view Association","excerpt":"Daniel Cremers이 [arXiv]에 게시한 'ViSTA-SLAM: Visual SLAM with Symmetric Two-view Association' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-03 13:36:21+0900","lastModifiedAt":"2025-09-03 13:36:21+0900","categories":["Review"],"tags":["Review","Monocular SLAM","Dense Reconstruction","Neural Networks","Pose Graph Optimization","Intrinsics-free","Real-time","Two-view Association"],"permalink":"/ai/review/2025-9-3-ViSTA-SLAM_Visual_SLAM_with_Symmetric_Two-view_Association/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-3-VerlTool_Towards_Holistic_Agentic_Reinforcement_Learning_with_Tool_Use","title":"[논문리뷰] VerlTool: Towards Holistic Agentic Reinforcement Learning with Tool Use","excerpt":"Zhiheng Lyu이 [arXiv]에 게시한 'VerlTool: Towards Holistic Agentic Reinforcement Learning with Tool Use' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-03 13:36:21+0900","lastModifiedAt":"2025-09-03 13:36:21+0900","categories":["Review"],"tags":["Review","Agentic Reinforcement Learning","Tool Use","Large Language Models","Reinforcement Learning from Verifiable Rewards (RLVR)","Asynchronous Execution","Multi-modal AI","Framework"],"permalink":"/ai/review/2025-9-3-VerlTool_Towards_Holistic_Agentic_Reinforcement_Learning_with_Tool_Use/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-3-Universal_Deep_Research_Bring_Your_Own_Model_and_Strategy","title":"[논문리뷰] Universal Deep Research: Bring Your Own Model and Strategy","excerpt":"Pavlo Molchanov이 [arXiv]에 게시한 'Universal Deep Research: Bring Your Own Model and Strategy' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-03 13:36:21+0900","lastModifiedAt":"2025-09-03 13:36:21+0900","categories":["Review"],"tags":["Review","Agentic Systems","Language Models (LLMs)","Research Automation","Customizable Strategies","Code Generation","Deep Research","User-Defined Agents","Sandboxed Execution"],"permalink":"/ai/review/2025-9-3-Universal_Deep_Research_Bring_Your_Own_Model_and_Strategy/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-3-UI-TARS-2_Technical_Report_Advancing_GUI_Agent_with_Multi-Turn_Reinforcement_Learning","title":"[논문리뷰] UI-TARS-2 Technical Report: Advancing GUI Agent with Multi-Turn Reinforcement Learning","excerpt":"Haoyang Zou이 [arXiv]에 게시한 'UI-TARS-2 Technical Report: Advancing GUI Agent with Multi-Turn Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-03 13:36:21+0900","lastModifiedAt":"2025-09-03 13:36:21+0900","categories":["Review"],"tags":["Review","GUI Agent","Multi-Turn RL","Reinforcement Learning","Data Flywheel","Agent Framework","Hybrid Environments","Parameter Interpolation"],"permalink":"/ai/review/2025-9-3-UI-TARS-2_Technical_Report_Advancing_GUI_Agent_with_Multi-Turn_Reinforcement_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-3-Towards_More_Diverse_and_Challenging_Pre-training_for_Point_Cloud_Learning_Self-Supervised_Cross_Reconstruction_with_Decoupled_Views","title":"[논문리뷰] Towards More Diverse and Challenging Pre-training for Point Cloud Learning: Self-Supervised Cross Reconstruction with Decoupled Views","excerpt":"Junchi Yan이 [arXiv]에 게시한 'Towards More Diverse and Challenging Pre-training for Point Cloud Learning: Self-Supervised Cross Reconstruction with Decoupled Views' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-03 13:36:21+0900","lastModifiedAt":"2025-09-03 13:36:21+0900","categories":["Review"],"tags":["Review","Point Cloud Learning","Self-Supervised Learning","Cross Reconstruction","Decoupled Views","Generative Models","Positional Encoding","3D Vision"],"permalink":"/ai/review/2025-9-3-Towards_More_Diverse_and_Challenging_Pre-training_for_Point_Cloud_Learning_Self-Supervised_Cross_Reconstruction_with_Decoupled_Views/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-3-The_Landscape_of_Agentic_Reinforcement_Learning_for_LLMs_A_Survey","title":"[논문리뷰] The Landscape of Agentic Reinforcement Learning for LLMs: A Survey","excerpt":"Hejia Geng이 [arXiv]에 게시한 'The Landscape of Agentic Reinforcement Learning for LLMs: A Survey' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-03 13:36:21+0900","lastModifiedAt":"2025-09-03 13:36:21+0900","categories":["Review"],"tags":["Review","Agentic Reinforcement Learning","Large Language Models","LLM Agents","Sequential Decision Making","Policy Optimization","Tool Use","Dynamic Environments","Autonomous AI"],"permalink":"/ai/review/2025-9-3-The_Landscape_of_Agentic_Reinforcement_Learning_for_LLMs_A_Survey/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-3-The_Gold_Medals_in_an_Empty_Room_Diagnosing_Metalinguistic_Reasoning_in_LLMs_with_Camlang","title":"[논문리뷰] The Gold Medals in an Empty Room: Diagnosing Metalinguistic Reasoning in LLMs with Camlang","excerpt":"Solomon Tsai이 [arXiv]에 게시한 'The Gold Medals in an Empty Room: Diagnosing Metalinguistic Reasoning in LLMs with Camlang' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-03 13:36:21+0900","lastModifiedAt":"2025-09-03 13:36:21+0900","categories":["Review"],"tags":["Review","LLMs","Metalinguistic Reasoning","Constructed Language","Camlang","Second Language Acquisition","Zero-shot Learning","Natural Language Understanding","Commonsense Reasoning"],"permalink":"/ai/review/2025-9-3-The_Gold_Medals_in_an_Empty_Room_Diagnosing_Metalinguistic_Reasoning_in_LLMs_with_Camlang/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-3-SQL-of-Thought_Multi-agentic_Text-to-SQL_with_Guided_Error_Correction","title":"[논문리뷰] SQL-of-Thought: Multi-agentic Text-to-SQL with Guided Error Correction","excerpt":"bindsch이 [arXiv]에 게시한 'SQL-of-Thought: Multi-agentic Text-to-SQL with Guided Error Correction' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-03 13:36:21+0900","lastModifiedAt":"2025-09-03 13:36:21+0900","categories":["Review"],"tags":["Review","Text-to-SQL","Multi-agent Systems","Chain-of-Thought","Error Correction","Large Language Models","Query Planning","Database Interaction"],"permalink":"/ai/review/2025-9-3-SQL-of-Thought_Multi-agentic_Text-to-SQL_with_Guided_Error_Correction/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-3-SimpleTIR_End-to-End_Reinforcement_Learning_for_Multi-Turn_Tool-Integrated_Reasoning","title":"[논문리뷰] SimpleTIR: End-to-End Reinforcement Learning for Multi-Turn Tool-Integrated Reasoning","excerpt":"Qian Liu이 [arXiv]에 게시한 'SimpleTIR: End-to-End Reinforcement Learning for Multi-Turn Tool-Integrated Reasoning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-03 13:36:21+0900","lastModifiedAt":"2025-09-03 13:36:21+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","Large Language Models","Tool-Integrated Reasoning","Multi-turn Reasoning","Gradient Explosion","Training Stability","Trajectory Filtering","Zero RL"],"permalink":"/ai/review/2025-9-3-SimpleTIR_End-to-End_Reinforcement_Learning_for_Multi-Turn_Tool-Integrated_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-3-Reasoning_Vectors_Transferring_Chain-of-Thought_Capabilities_via_Task_Arithmetic","title":"[논문리뷰] Reasoning Vectors: Transferring Chain-of-Thought Capabilities via Task Arithmetic","excerpt":"Bernard Ghanem이 [arXiv]에 게시한 'Reasoning Vectors: Transferring Chain-of-Thought Capabilities via Task Arithmetic' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-03 13:36:21+0900","lastModifiedAt":"2025-09-03 13:36:21+0900","categories":["Review"],"tags":["Review","Reasoning Vectors","Task Arithmetic","Chain-of-Thought","LLMs","Reinforcement Learning","Model Merging","Parameter Transfer"],"permalink":"/ai/review/2025-9-3-Reasoning_Vectors_Transferring_Chain-of-Thought_Capabilities_via_Task_Arithmetic/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-3-POINTS-Reader_Distillation-Free_Adaptation_of_Vision-Language_Models_for_Document_Conversion","title":"[논문리뷰] POINTS-Reader: Distillation-Free Adaptation of Vision-Language Models for Document Conversion","excerpt":"Haicheng Wang이 [arXiv]에 게시한 'POINTS-Reader: Distillation-Free Adaptation of Vision-Language Models for Document Conversion' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-03 13:36:21+0900","lastModifiedAt":"2025-09-03 13:36:21+0900","categories":["Review"],"tags":["Review","문서 변환","시각-언어 모델","자가 개선","합성 데이터","증류 없는 학습","OCR","멀티모달 AI","데이터 필터링"],"permalink":"/ai/review/2025-9-3-POINTS-Reader_Distillation-Free_Adaptation_of_Vision-Language_Models_for_Document_Conversion/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-3-OpenVision_2_A_Family_of_Generative_Pretrained_Visual_Encoders_for_Multimodal_Learning","title":"[논문리뷰] OpenVision 2: A Family of Generative Pretrained Visual Encoders for Multimodal Learning","excerpt":"Zirui Wang이 [arXiv]에 게시한 'OpenVision 2: A Family of Generative Pretrained Visual Encoders for Multimodal Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-03 13:36:21+0900","lastModifiedAt":"2025-09-03 13:36:21+0900","categories":["Review"],"tags":["Review","Multimodal Learning","Vision Encoder","Generative Pretraining","Captioning Loss","Training Efficiency","Image-Text Models","Large Language Models"],"permalink":"/ai/review/2025-9-3-OpenVision_2_A_Family_of_Generative_Pretrained_Visual_Encoders_for_Multimodal_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-3-MobiAgent_A_Systematic_Framework_for_Customizable_Mobile_Agents","title":"[논문리뷰] MobiAgent: A Systematic Framework for Customizable Mobile Agents","excerpt":"Wangbo Gong이 [arXiv]에 게시한 'MobiAgent: A Systematic Framework for Customizable Mobile Agents' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-03 13:36:21+0900","lastModifiedAt":"2025-09-03 13:36:21+0900","categories":["Review"],"tags":["Review","Mobile Agents","GUI Agents","Vision-Language Models","Agent Acceleration","Benchmarking","Reinforcement Learning","Data Collection"],"permalink":"/ai/review/2025-9-3-MobiAgent_A_Systematic_Framework_for_Customizable_Mobile_Agents/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-3-Metis_Training_Large_Language_Models_with_Advanced_Low-Bit_Quantization","title":"[논문리뷰] Metis: Training Large Language Models with Advanced Low-Bit Quantization","excerpt":"Hengjie Cao이 [arXiv]에 게시한 'Metis: Training Large Language Models with Advanced Low-Bit Quantization' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-03 13:36:21+0900","lastModifiedAt":"2025-09-03 13:36:21+0900","categories":["Review"],"tags":["Review","Low-Bit Quantization","LLMs","Spectral Decomposition","Anisotropy","Adaptive Learning Rate","Regularization","FP8 Training","FP4 Training"],"permalink":"/ai/review/2025-9-3-Metis_Training_Large_Language_Models_with_Advanced_Low-Bit_Quantization/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-3-MedDINOv3_How_to_adapt_vision_foundation_models_for_medical_image_segmentation","title":"[논문리뷰] MedDINOv3: How to adapt vision foundation models for medical image segmentation?","excerpt":"Xiaofeng Yang이 [arXiv]에 게시한 'MedDINOv3: How to adapt vision foundation models for medical image segmentation?' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-03 13:36:21+0900","lastModifiedAt":"2025-09-03 13:36:21+0900","categories":["Review"],"tags":["Review","Medical Image Segmentation","Vision Foundation Models","Self-supervised Learning","Vision Transformers (ViT)","Domain Adaptation","DINOv3","CT Imaging"],"permalink":"/ai/review/2025-9-3-MedDINOv3_How_to_adapt_vision_foundation_models_for_medical_image_segmentation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-3-M3Ret_Unleashing_Zero-shot_Multimodal_Medical_Image_Retrieval_via_Self-Supervision","title":"[논문리뷰] M3Ret: Unleashing Zero-shot Multimodal Medical Image Retrieval via Self-Supervision","excerpt":"Yan-Jie Zhou이 [arXiv]에 게시한 'M3Ret: Unleashing Zero-shot Multimodal Medical Image Retrieval via Self-Supervision' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-03 13:36:21+0900","lastModifiedAt":"2025-09-03 13:36:21+0900","categories":["Review"],"tags":["Review","Medical Image Retrieval","Self-Supervised Learning","Multimodal","Zero-shot","Foundation Models","MAE","SimDINO","Vision Transformer"],"permalink":"/ai/review/2025-9-3-M3Ret_Unleashing_Zero-shot_Multimodal_Medical_Image_Retrieval_via_Self-Supervision/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-3-LLaVA-Critic-R1_Your_Critic_Model_is_Secretly_a_Strong_Policy_Model","title":"[논문리뷰] LLaVA-Critic-R1: Your Critic Model is Secretly a Strong Policy Model","excerpt":"Jianwei Yang이 [arXiv]에 게시한 'LLaVA-Critic-R1: Your Critic Model is Secretly a Strong Policy Model' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-03 13:36:21+0900","lastModifiedAt":"2025-09-03 13:36:21+0900","categories":["Review"],"tags":["Review","Vision-Language Models (VLMs)","Critic Models","Policy Models","Reinforcement Learning (RL)","Self-Criticism","Multimodal Reasoning","Preference Learning","Generative Models"],"permalink":"/ai/review/2025-9-3-LLaVA-Critic-R1_Your_Critic_Model_is_Secretly_a_Strong_Policy_Model/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-3-Kwai_Keye-VL_1.5_Technical_Report","title":"[논문리뷰] Kwai Keye-VL 1.5 Technical Report","excerpt":"SXxtyz이 [arXiv]에 게시한 'Kwai Keye-VL 1.5 Technical Report' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-03 13:36:21+0900","lastModifiedAt":"2025-09-03 13:36:21+0900","categories":["Review"],"tags":["Review","Multimodal LLMs","Video Understanding","Slow-Fast Encoding","Long Context","Chain-of-Thought","Reinforcement Learning","Human Alignment","Native-Resolution Vision Encoder"],"permalink":"/ai/review/2025-9-3-Kwai_Keye-VL_1.5_Technical_Report/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-3-Jointly_Reinforcing_Diversity_and_Quality_in_Language_Model_Generations","title":"[논문리뷰] Jointly Reinforcing Diversity and Quality in Language Model Generations","excerpt":"Tianlu이 [arXiv]에 게시한 'Jointly Reinforcing Diversity and Quality in Language Model Generations' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-03 13:36:21+0900","lastModifiedAt":"2025-09-03 13:36:21+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","Language Models","Diversity Optimization","Quality Enhancement","Semantic Clustering","Post-training","Generative AI"],"permalink":"/ai/review/2025-9-3-Jointly_Reinforcing_Diversity_and_Quality_in_Language_Model_Generations/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-3-Improving_Large_Vision_and_Language_Models_by_Learning_from_a_Panel_of_Peers","title":"[논문리뷰] Improving Large Vision and Language Models by Learning from a Panel of Peers","excerpt":"Simon Jenni이 [arXiv]에 게시한 'Improving Large Vision and Language Models by Learning from a Panel of Peers' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-03 13:36:21+0900","lastModifiedAt":"2025-09-03 13:36:21+0900","categories":["Review"],"tags":["Review","Large Vision and Language Models (LVLMs)","Self-Improvement","Peer Learning","Preference Alignment","Reward Modeling","Multimodal Learning","Knowledge Transfer"],"permalink":"/ai/review/2025-9-3-Improving_Large_Vision_and_Language_Models_by_Learning_from_a_Panel_of_Peers/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-3-Implicit_Actor_Critic_Coupling_via_a_Supervised_Learning_Framework_for_RLVR","title":"[논문리뷰] Implicit Actor Critic Coupling via a Supervised Learning Framework for RLVR","excerpt":"Lu Wang이 [arXiv]에 게시한 'Implicit Actor Critic Coupling via a Supervised Learning Framework for RLVR' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-03 13:36:21+0900","lastModifiedAt":"2025-09-03 13:36:21+0900","categories":["Review"],"tags":["Review","RLVR","Large Language Models","Actor-Critic","Supervised Learning","Mathematical Reasoning","Policy Optimization","Cross-Entropy Loss"],"permalink":"/ai/review/2025-9-3-Implicit_Actor_Critic_Coupling_via_a_Supervised_Learning_Framework_for_RLVR/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-3-GenCompositor_Generative_Video_Compositing_with_Diffusion_Transformer","title":"[논문리뷰] GenCompositor: Generative Video Compositing with Diffusion Transformer","excerpt":"Lingen Li이 [arXiv]에 게시한 'GenCompositor: Generative Video Compositing with Diffusion Transformer' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-03 13:36:21+0900","lastModifiedAt":"2025-09-03 13:36:21+0900","categories":["Review"],"tags":["Review","Video Compositing","Diffusion Transformer","Generative Models","Video Editing","Position Embedding","Diffusion Models","Masked Token Injection","Video Harmonization"],"permalink":"/ai/review/2025-9-3-GenCompositor_Generative_Video_Compositing_with_Diffusion_Transformer/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-3-FlashAdventure_A_Benchmark_for_GUI_Agents_Solving_Full_Story_Arcs_in_Diverse_Adventure_Games","title":"[논문리뷰] FlashAdventure: A Benchmark for GUI Agents Solving Full Story Arcs in Diverse Adventure Games","excerpt":"Dongmin Park이 [arXiv]에 게시한 'FlashAdventure: A Benchmark for GUI Agents Solving Full Story Arcs in Diverse Adventure Games' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-03 13:36:21+0900","lastModifiedAt":"2025-09-03 13:36:21+0900","categories":["Review"],"tags":["Review","GUI Agents","Adventure Games","Benchmark","Full Story Arc","Observation-Behavior Gap","LLMs","Automated Evaluation"],"permalink":"/ai/review/2025-9-3-FlashAdventure_A_Benchmark_for_GUI_Agents_Solving_Full_Story_Arcs_in_Diverse_Adventure_Games/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-3-FastFit_Accelerating_Multi-Reference_Virtual_Try-On_via_Cacheable_Diffusion_Models","title":"[논문리뷰] FastFit: Accelerating Multi-Reference Virtual Try-On via Cacheable Diffusion Models","excerpt":"Zhen Wang이 [arXiv]에 게시한 'FastFit: Accelerating Multi-Reference Virtual Try-On via Cacheable Diffusion Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-03 13:36:21+0900","lastModifiedAt":"2025-09-03 13:36:21+0900","categories":["Review"],"tags":["Review","Virtual Try-On","Diffusion Models","Cacheable Architecture","Multi-Reference","Semi-Attention","Efficiency","Image Synthesis"],"permalink":"/ai/review/2025-9-3-FastFit_Accelerating_Multi-Reference_Virtual_Try-On_via_Cacheable_Diffusion_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-3-Fantastic_Pretraining_Optimizers_and_Where_to_Find_Them","title":"[논문리뷰] Fantastic Pretraining Optimizers and Where to Find Them","excerpt":"Percy Liang이 [arXiv]에 게시한 'Fantastic Pretraining Optimizers and Where to Find Them' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-03 13:36:21+0900","lastModifiedAt":"2025-09-03 13:36:21+0900","categories":["Review"],"tags":["Review","Deep Learning Optimizers","Large Language Models","Hyperparameter Tuning","Pretraining Speedup","Scaling Laws","AdamW","Matrix-based Optimizers","Data-to-Model Ratio"],"permalink":"/ai/review/2025-9-3-Fantastic_Pretraining_Optimizers_and_Where_to_Find_Them/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-3-ELV-Halluc_Benchmarking_Semantic_Aggregation_Hallucinations_in_Long_Video_Understanding","title":"[논문리뷰] ELV-Halluc: Benchmarking Semantic Aggregation Hallucinations in Long Video Understanding","excerpt":"Xuanyu Zheng이 [arXiv]에 게시한 'ELV-Halluc: Benchmarking Semantic Aggregation Hallucinations in Long Video Understanding' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-03 13:36:21+0900","lastModifiedAt":"2025-09-03 13:36:21+0900","categories":["Review"],"tags":["Review","Long Video Understanding","Hallucination","Semantic Aggregation","Video MLLM","Benchmark","DPO","Positional Encoding","VideoQA"],"permalink":"/ai/review/2025-9-3-ELV-Halluc_Benchmarking_Semantic_Aggregation_Hallucinations_in_Long_Video_Understanding/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-3-Discrete_Noise_Inversion_for_Next-scale_Autoregressive_Text-based_Image_Editing","title":"[논문리뷰] Discrete Noise Inversion for Next-scale Autoregressive Text-based Image Editing","excerpt":"Amin Heyrani Nobar이 [arXiv]에 게시한 'Discrete Noise Inversion for Next-scale Autoregressive Text-based Image Editing' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-03 13:36:21+0900","lastModifiedAt":"2025-09-03 13:36:21+0900","categories":["Review"],"tags":["Review","Image Editing","Autoregressive Models","Noise Inversion","Text-to-Image","Gumbel-max Trick","Training-free","Location-aware Argmax Inversion"],"permalink":"/ai/review/2025-9-3-Discrete_Noise_Inversion_for_Next-scale_Autoregressive_Text-based_Image_Editing/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-3-DCPO_Dynamic_Clipping_Policy_Optimization","title":"[논문리뷰] DCPO: Dynamic Clipping Policy Optimization","excerpt":"Kai Lu이 [arXiv]에 게시한 'DCPO: Dynamic Clipping Policy Optimization' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-03 13:36:21+0900","lastModifiedAt":"2025-09-03 13:36:21+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","LLM","Policy Optimization","Dynamic Clipping","Advantage Standardization","RLVR","Reasoning"],"permalink":"/ai/review/2025-9-3-DCPO_Dynamic_Clipping_Policy_Optimization/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-3-C-DiffDet_Fusing_Global_Scene_Context_with_Generative_Denoising_for_High-Fidelity_Object_Detection","title":"[논문리뷰] C-DiffDet+: Fusing Global Scene Context with Generative Denoising for High-Fidelity Object Detection","excerpt":"Vito Renó이 [arXiv]에 게시한 'C-DiffDet+: Fusing Global Scene Context with Generative Denoising for High-Fidelity Object Detection' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-03 13:36:21+0900","lastModifiedAt":"2025-09-03 13:36:21+0900","categories":["Review"],"tags":["Review","Object Detection","Diffusion Model","Global Scene Context","Context-Aware Fusion","Fine-grained Detection","Automotive Damage Assessment","Generative Denoising","Cross-Attention"],"permalink":"/ai/review/2025-9-3-C-DiffDet_Fusing_Global_Scene_Context_with_Generative_Denoising_for_High-Fidelity_Object_Detection/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-3-Benchmarking_Optimizers_for_Large_Language_Model_Pretraining","title":"[논문리뷰] Benchmarking Optimizers for Large Language Model Pretraining","excerpt":"mjaggi이 [arXiv]에 게시한 'Benchmarking Optimizers for Large Language Model Pretraining' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-03 13:36:21+0900","lastModifiedAt":"2025-09-03 13:36:21+0900","categories":["Review"],"tags":["Review","LLM Optimizers","Benchmarking","Hyperparameter Tuning","AdamW","AdEMAMix","MARS","Mixture of Experts (MoE)","Weight Decay"],"permalink":"/ai/review/2025-9-3-Benchmarking_Optimizers_for_Large_Language_Model_Pretraining/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-3-Baichuan-M2_Scaling_Medical_Capability_with_Large_Verifier_System","title":"[논문리뷰] Baichuan-M2: Scaling Medical Capability with Large Verifier System","excerpt":"Jayok6이 [arXiv]에 게시한 'Baichuan-M2: Scaling Medical Capability with Large Verifier System' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-03 13:36:21+0900","lastModifiedAt":"2025-09-03 13:36:21+0900","categories":["Review"],"tags":["Review","Medical AI","LLM","Reinforcement Learning","Verifier System","Patient Simulator","Clinical Rubrics","Baichuan-M2","HealthBench"],"permalink":"/ai/review/2025-9-3-Baichuan-M2_Scaling_Medical_Capability_with_Large_Verifier_System/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-3-Attributes_as_Textual_Genes_Leveraging_LLMs_as_Genetic_Algorithm_Simulators_for_Conditional_Synthetic_Data_Generation","title":"[논문리뷰] Attributes as Textual Genes: Leveraging LLMs as Genetic Algorithm Simulators for Conditional Synthetic Data Generation","excerpt":"Xiaolei Huang이 [arXiv]에 게시한 'Attributes as Textual Genes: Leveraging LLMs as Genetic Algorithm Simulators for Conditional Synthetic Data Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-03 13:36:21+0900","lastModifiedAt":"2025-09-03 13:36:21+0900","categories":["Review"],"tags":["Review","Synthetic Data Generation","Large Language Models (LLMs)","Genetic Algorithms","Textual Data Augmentation","Active Learning","NLP","Data Diversity"],"permalink":"/ai/review/2025-9-3-Attributes_as_Textual_Genes_Leveraging_LLMs_as_Genetic_Algorithm_Simulators_for_Conditional_Synthetic_Data_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-3-AMBEDKAR-A_Multi-level_Bias_Elimination_through_a_Decoding_Approach_with_Knowledge_Augmentation_for_Robust_Constitutional_Alignment_of_Language_Models","title":"[논문리뷰] AMBEDKAR-A Multi-level Bias Elimination through a Decoding Approach with Knowledge Augmentation for Robust Constitutional Alignment of Language Models","excerpt":"Rahul Karthikeyan이 [arXiv]에 게시한 'AMBEDKAR-A Multi-level Bias Elimination through a Decoding Approach with Knowledge Augmentation for Robust Constitutional Alignment of Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-03 13:36:21+0900","lastModifiedAt":"2025-09-03 13:36:21+0900","categories":["Review"],"tags":["Review","Bias Mitigation","Large Language Models","Speculative Decoding","Constitutional AI","Fairness","Inference-Time Control","Indian Sociocultural Context"],"permalink":"/ai/review/2025-9-3-AMBEDKAR-A_Multi-level_Bias_Elimination_through_a_Decoding_Approach_with_Knowledge_Augmentation_for_Robust_Constitutional_Alignment_of_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-2-UI-Level_Evaluation_of_ALLaM_34B_Measuring_an_Arabic-Centric_LLM_via_HUMAIN_Chat","title":"[논문리뷰] UI-Level Evaluation of ALLaM 34B: Measuring an Arabic-Centric LLM via HUMAIN Chat","excerpt":"Omartificial-Intelligence-Space이 [arXiv]에 게시한 'UI-Level Evaluation of ALLaM 34B: Measuring an Arabic-Centric LLM via HUMAIN Chat' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-02 13:01:41+0900","lastModifiedAt":"2025-09-02 13:01:41+0900","categories":["Review"],"tags":["Review","Arabic LLM","UI-level Evaluation","ALLaM 34B","HUMAIN Chat","Dialectal Arabic","LLM as a Judge","Safety Evaluation"],"permalink":"/ai/review/2025-9-2-UI-Level_Evaluation_of_ALLaM_34B_Measuring_an_Arabic-Centric_LLM_via_HUMAIN_Chat/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-2-T2R-bench_A_Benchmark_for_Generating_Article-Level_Reports_from_Real_World_Industrial_Tables","title":"[논문리뷰] T2R-bench: A Benchmark for Generating Article-Level Reports from Real World Industrial Tables","excerpt":"Yu Zhao이 [arXiv]에 게시한 'T2R-bench: A Benchmark for Generating Article-Level Reports from Real World Industrial Tables' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-02 13:01:41+0900","lastModifiedAt":"2025-09-02 13:01:41+0900","categories":["Review"],"tags":["Review","Table-to-Report Generation","Large Language Models (LLMs)","Benchmark Dataset","Industrial Applications","Table Reasoning","Evaluation Metrics","Real-world Data"],"permalink":"/ai/review/2025-9-2-T2R-bench_A_Benchmark_for_Generating_Article-Level_Reports_from_Real_World_Industrial_Tables/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-2-PVPO_Pre-Estimated_Value-Based_Policy_Optimization_for_Agentic_Reasoning","title":"[논문리뷰] PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic Reasoning","excerpt":"Yuewei Zhang이 [arXiv]에 게시한 'PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic Reasoning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-02 13:01:41+0900","lastModifiedAt":"2025-09-02 13:01:41+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","Critic-Free RL","Agentic Reasoning","Policy Optimization","Large Language Models (LLMs)","Advantage Estimation","Group Sampling","Static Value Estimation"],"permalink":"/ai/review/2025-9-2-PVPO_Pre-Estimated_Value-Based_Policy_Optimization_for_Agentic_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-2-No_Label_Left_Behind_A_Unified_Surface_Defect_Detection_Model_for_all_Supervision_Regimes","title":"[논문리뷰] No Label Left Behind: A Unified Surface Defect Detection Model for all Supervision Regimes","excerpt":"Danijel Skočaj이 [arXiv]에 게시한 'No Label Left Behind: A Unified Surface Defect Detection Model for all Supervision Regimes' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-02 13:01:41+0900","lastModifiedAt":"2025-09-02 13:01:41+0900","categories":["Review"],"tags":["Review","Surface Defect Detection","Anomaly Detection","Mixed Supervision","Deep Learning","Industrial Inspection","Unified Model"],"permalink":"/ai/review/2025-9-2-No_Label_Left_Behind_A_Unified_Surface_Defect_Detection_Model_for_all_Supervision_Regimes/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-2-How_Can_Input_Reformulation_Improve_Tool_Usage_Accuracy_in_a_Complex_Dynamic_Environment_A_Study_on_τ-bench","title":"[논문리뷰] How Can Input Reformulation Improve Tool Usage Accuracy in a Complex Dynamic Environment? A Study on τ-bench","excerpt":"Jayanth Srinivasa이 [arXiv]에 게시한 'How Can Input Reformulation Improve Tool Usage Accuracy in a Complex Dynamic Environment? A Study on τ-bench' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-02 13:01:41+0900","lastModifiedAt":"2025-09-02 13:01:41+0900","categories":["Review"],"tags":["Review","LLM Agents","Tool Use","Function Calling","Input Reformulation","Dynamic Environments","τ-bench","Context Engineering","Multi-Agent Framework"],"permalink":"/ai/review/2025-9-2-How_Can_Input_Reformulation_Improve_Tool_Usage_Accuracy_in_a_Complex_Dynamic_Environment_A_Study_on_τ-bench/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-2-From_reactive_to_cognitive_brain-inspired_spatial_intelligence_for_embodied_agents","title":"[논문리뷰] From reactive to cognitive: brain-inspired spatial intelligence for embodied agents","excerpt":"Songming Liu이 [arXiv]에 게시한 'From reactive to cognitive: brain-inspired spatial intelligence for embodied agents' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-02 13:01:41+0900","lastModifiedAt":"2025-09-02 13:01:41+0900","categories":["Review"],"tags":["Review","Spatial Cognition","Embodied Agents","Brain-inspired AI","Cognitive Map","Spatial Memory","MLLMs","Navigation"],"permalink":"/ai/review/2025-9-2-From_reactive_to_cognitive_brain-inspired_spatial_intelligence_for_embodied_agents/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-1-UItron_Foundational_GUI_Agent_with_Advanced_Perception_and_Planning","title":"[논문리뷰] UItron: Foundational GUI Agent with Advanced Perception and Planning","excerpt":"Yufeng Zhong이 [arXiv]에 게시한 'UItron: Foundational GUI Agent with Advanced Perception and Planning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-01 13:14:34+0900","lastModifiedAt":"2025-09-01 13:14:34+0900","categories":["Review"],"tags":["Review","GUI Agent","Foundational Model","Multimodal LLM","Perception","Planning","Reinforcement Learning","Data Engineering","Chinese App Scenarios"],"permalink":"/ai/review/2025-9-1-UItron_Foundational_GUI_Agent_with_Advanced_Perception_and_Planning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-1-TiKMiX_Take_Data_Influence_into_Dynamic_Mixture_for_Language_Model_Pre-training","title":"[논문리뷰] TiKMiX: Take Data Influence into Dynamic Mixture for Language Model Pre-training","excerpt":"Jiyao Deng이 [arXiv]에 게시한 'TiKMiX: Take Data Influence into Dynamic Mixture for Language Model Pre-training' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-01 13:14:34+0900","lastModifiedAt":"2025-09-01 13:14:34+0900","categories":["Review"],"tags":["Review","Language Model Pre-training","Dynamic Data Mixing","Data Influence","Group Influence","Optimization","Regression Model","LLM Training"],"permalink":"/ai/review/2025-9-1-TiKMiX_Take_Data_Influence_into_Dynamic_Mixture_for_Language_Model_Pre-training/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-1-Think_in_Games_Learning_to_Reason_in_Games_via_Reinforcement_Learning_with_Large_Language_Models","title":"[논문리뷰] Think in Games: Learning to Reason in Games via Reinforcement Learning with Large Language Models","excerpt":"Yifan Lu이 [arXiv]에 게시한 'Think in Games: Learning to Reason in Games via Reinforcement Learning with Large Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-01 13:14:34+0900","lastModifiedAt":"2025-09-01 13:14:34+0900","categories":["Review"],"tags":["Review","Large Language Models","Reinforcement Learning","Game AI","Procedural Knowledge","Declarative Knowledge","Explainable AI","Strategic Decision-Making"],"permalink":"/ai/review/2025-9-1-Think_in_Games_Learning_to_Reason_in_Games_via_Reinforcement_Learning_with_Large_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-1-TalkVid_A_Large-Scale_Diversified_Dataset_for_Audio-Driven_Talking_Head_Synthesis","title":"[논문리뷰] TalkVid: A Large-Scale Diversified Dataset for Audio-Driven Talking Head Synthesis","excerpt":"Pengcheng Chen이 [arXiv]에 게시한 'TalkVid: A Large-Scale Diversified Dataset for Audio-Driven Talking Head Synthesis' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-01 13:14:34+0900","lastModifiedAt":"2025-09-01 13:14:34+0900","categories":["Review"],"tags":["Review","Audio-Driven Talking Head Synthesis","Large-Scale Dataset","Data Diversity","Data Curation","Evaluation Benchmark","Generalization Gap","Algorithmic Fairness"],"permalink":"/ai/review/2025-9-1-TalkVid_A_Large-Scale_Diversified_Dataset_for_Audio-Driven_Talking_Head_Synthesis/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-1-R-4B_Incentivizing_General-Purpose_Auto-Thinking_Capability_in_MLLMs_via_Bi-Mode_Annealing_and_Reinforce_Learning","title":"[논문리뷰] R-4B: Incentivizing General-Purpose Auto-Thinking Capability in MLLMs via Bi-Mode Annealing and Reinforce Learning","excerpt":"Han Hu이 [arXiv]에 게시한 'R-4B: Incentivizing General-Purpose Auto-Thinking Capability in MLLMs via Bi-Mode Annealing and Reinforce Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-01 13:14:34+0900","lastModifiedAt":"2025-09-01 13:14:34+0900","categories":["Review"],"tags":["Review","Multimodal Large Language Models (MLLMs)","Auto-Thinking","Reinforcement Learning (RL)","Bi-mode Annealing","Bi-mode Policy Optimization (BPO)","General-Purpose AI","Reasoning","Efficiency"],"permalink":"/ai/review/2025-9-1-R-4B_Incentivizing_General-Purpose_Auto-Thinking_Capability_in_MLLMs_via_Bi-Mode_Annealing_and_Reinforce_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-1-Morae_Proactively_Pausing_UI_Agents_for_User_Choices","title":"[논문리뷰] Morae: Proactively Pausing UI Agents for User Choices","excerpt":"Amy Pavel이 [arXiv]에 게시한 'Morae: Proactively Pausing UI Agents for User Choices' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-01 13:14:34+0900","lastModifiedAt":"2025-09-01 13:14:34+0900","categories":["Review"],"tags":["Review","UI Agents","Accessibility","Human-Agent Interaction","Mixed-Initiative AI","Large Multimodal Models","Proactive AI","User Choice","Blind and Low-Vision Users"],"permalink":"/ai/review/2025-9-1-Morae_Proactively_Pausing_UI_Agents_for_User_Choices/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-1-Mimicking_the_Physicists_EyeA_VLM-centric_Approach_for_Physics_Formula_Discovery","title":"[논문리뷰] Mimicking the Physicist's Eye:A VLM-centric Approach for Physics Formula Discovery","excerpt":"Wenjie Zhou이 [arXiv]에 게시한 'Mimicking the Physicist's Eye:A VLM-centric Approach for Physics Formula Discovery' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-01 13:14:34+0900","lastModifiedAt":"2025-09-01 13:14:34+0900","categories":["Review"],"tags":["Review","Physics Formula Discovery","Multimodal AI","Vision-Language Models","Symbolic Regression","Causal Chain of Thought","Reinforcement Learning","Agentic AI"],"permalink":"/ai/review/2025-9-1-Mimicking_the_Physicists_EyeA_VLM-centric_Approach_for_Physics_Formula_Discovery/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-1-HERMES_Human-to-Robot_Embodied_Learning_from_Multi-Source_Motion_Data_for_Mobile_Dexterous_Manipulation","title":"[논문리뷰] HERMES: Human-to-Robot Embodied Learning from Multi-Source Motion Data for Mobile Dexterous Manipulation","excerpt":"Tianhai Liang이 [arXiv]에 게시한 'HERMES: Human-to-Robot Embodied Learning from Multi-Source Motion Data for Mobile Dexterous Manipulation' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-01 13:14:34+0900","lastModifiedAt":"2025-09-01 13:14:34+0900","categories":["Review"],"tags":["Review","Dexterous Manipulation","Mobile Manipulation","Human-to-Robot Learning","Sim2Real","Reinforcement Learning","Depth Image","Visual Localization","Bimanual Control"],"permalink":"/ai/review/2025-9-1-HERMES_Human-to-Robot_Embodied_Learning_from_Multi-Source_Motion_Data_for_Mobile_Dexterous_Manipulation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-1-EmbodiedOneVision_Interleaved_Vision-Text-Action_Pretraining_for_General_Robot_Control","title":"[논문리뷰] EmbodiedOneVision: Interleaved Vision-Text-Action Pretraining for General Robot Control","excerpt":"Zhaoqing Chen이 [arXiv]에 게시한 'EmbodiedOneVision: Interleaved Vision-Text-Action Pretraining for General Robot Control' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-01 13:14:34+0900","lastModifiedAt":"2025-09-01 13:14:34+0900","categories":["Review"],"tags":["Review","Embodied AI","Robot Control","Vision-Language-Action Models","Multimodal Pretraining","Flow Matching","Foundation Models","Generalization","Real-world Robotics"],"permalink":"/ai/review/2025-9-1-EmbodiedOneVision_Interleaved_Vision-Text-Action_Pretraining_for_General_Robot_Control/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-1-Efficient_Code_Embeddings_from_Code_Generation_Models","title":"[논문리뷰] Efficient Code Embeddings from Code Generation Models","excerpt":"Han Xiao이 [arXiv]에 게시한 'Efficient Code Embeddings from Code Generation Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-01 13:14:34+0900","lastModifiedAt":"2025-09-01 13:14:34+0900","categories":["Review"],"tags":["Review","Code Embeddings","Code Generation Models","Autoregressive Backbones","Last-Token Pooling","Instruction Tuning","Contrastive Learning","Retrieval-Augmented Generation","MTEB Benchmark"],"permalink":"/ai/review/2025-9-1-Efficient_Code_Embeddings_from_Code_Generation_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-1-Droplet3D_Commonsense_Priors_from_Videos_Facilitate_3D_Generation","title":"[논문리뷰] Droplet3D: Commonsense Priors from Videos Facilitate 3D Generation","excerpt":"Qi Jia이 [arXiv]에 게시한 'Droplet3D: Commonsense Priors from Videos Facilitate 3D Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-01 13:14:34+0900","lastModifiedAt":"2025-09-01 13:14:34+0900","categories":["Review"],"tags":["Review","3D Generation","Video Diffusion Models","Spatial Consistency","Semantic Knowledge","Multi-view Synthesis","Large-scale Dataset","Image-to-3D","Text-to-3D"],"permalink":"/ai/review/2025-9-1-Droplet3D_Commonsense_Priors_from_Videos_Facilitate_3D_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-1-CLIPSym_Delving_into_Symmetry_Detection_with_CLIP","title":"[논문리뷰] CLIPSym: Delving into Symmetry Detection with CLIP","excerpt":"Raymond A. Yeh이 [arXiv]에 게시한 'CLIPSym: Delving into Symmetry Detection with CLIP' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-01 13:14:34+0900","lastModifiedAt":"2025-09-01 13:14:34+0900","categories":["Review"],"tags":["Review","Symmetry Detection","Vision-Language Models","CLIP","Equivariant Networks","Prompt Engineering","Geometric Deep Learning"],"permalink":"/ai/review/2025-9-1-CLIPSym_Delving_into_Symmetry_Detection_with_CLIP/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-1-A_Survey_of_Scientific_Large_Language_Models_From_Data_Foundations_to_Agent_Frontiers","title":"[논문리뷰] A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers","excerpt":"Jiamin Wu이 [arXiv]에 게시한 'A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-01 13:14:34+0900","lastModifiedAt":"2025-09-01 13:14:34+0900","categories":["Review"],"tags":["Review","Scientific LLMs","AI for Science","Scientific Data","Agentic AI","Multimodal Integration","Knowledge Representation","Autonomous Discovery","Data Ecosystems"],"permalink":"/ai/review/2025-9-1-A_Survey_of_Scientific_Large_Language_Models_From_Data_Foundations_to_Agent_Frontiers/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-1-AHELM_A_Holistic_Evaluation_of_Audio-Language_Models","title":"[논문리뷰] AHELM: A Holistic Evaluation of Audio-Language Models","excerpt":"Siwei Yang이 [arXiv]에 게시한 'AHELM: A Holistic Evaluation of Audio-Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-01 13:14:34+0900","lastModifiedAt":"2025-09-01 13:14:34+0900","categories":["Review"],"tags":["Review","Audio-Language Models","Holistic Evaluation","Benchmarking","Multimodality","Fairness","Robustness","Reasoning","Bias Detection"],"permalink":"/ai/review/2025-9-1-AHELM_A_Holistic_Evaluation_of_Audio-Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-9-1-A.S.E_A_Repository-Level_Benchmark_for_Evaluating_Security_in_AI-Generated_Code","title":"[논문리뷰] A.S.E: A Repository-Level Benchmark for Evaluating Security in AI-Generated Code","excerpt":"Libo Chen이 [arXiv]에 게시한 'A.S.E: A Repository-Level Benchmark for Evaluating Security in AI-Generated Code' 논문에 대한 자세한 리뷰입니다.","date":"2025-09-01 13:14:34+0900","lastModifiedAt":"2025-09-01 13:14:34+0900","categories":["Review"],"tags":["Review","AI-Generated Code Security","LLM Evaluation","Repository-Level Benchmark","Code Security","Vulnerability Detection","Static Analysis","Reproducibility","Context-Awareness"],"permalink":"/ai/review/2025-9-1-A.S.E_A_Repository-Level_Benchmark_for_Evaluating_Security_in_AI-Generated_Code/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-29-USO_Unified_Style_and_Subject-Driven_Generation_via_Disentangled_and_Reward_Learning","title":"[논문리뷰] USO: Unified Style and Subject-Driven Generation via Disentangled and Reward Learning","excerpt":"Jiahe Tian이 [arXiv]에 게시한 'USO: Unified Style and Subject-Driven Generation via Disentangled and Reward Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-29 13:14:44+0900","lastModifiedAt":"2025-08-29 13:14:44+0900","categories":["Review"],"tags":["Review","Style-Driven Generation","Subject-Driven Generation","Disentangled Representation","Reward Learning","Cross-Task Learning","Diffusion Models","Image Customization","Unified Framework"],"permalink":"/ai/review/2025-8-29-USO_Unified_Style_and_Subject-Driven_Generation_via_Disentangled_and_Reward_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-29-Turning_the_Spell_Around_Lightweight_Alignment_Amplification_via_Rank-One_Safety_Injection","title":"[논문리뷰] Turning the Spell Around: Lightweight Alignment Amplification via Rank-One Safety Injection","excerpt":"Bernard Ghanem이 [arXiv]에 게시한 'Turning the Spell Around: Lightweight Alignment Amplification via Rank-One Safety Injection' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-29 13:14:44+0900","lastModifiedAt":"2025-08-29 13:14:44+0900","categories":["Review"],"tags":["Review","LLM Safety","Alignment Amplification","Rank-One Update","Mechanistic Interpretability","Weight Steering","Jailbreak Robustness","Fine-tuning-free","Safety Injection"],"permalink":"/ai/review/2025-8-29-Turning_the_Spell_Around_Lightweight_Alignment_Amplification_via_Rank-One_Safety_Injection/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-29-TCIA_A_Task-Centric_Instruction_Augmentation_Method_for_Instruction_Finetuning","title":"[논문리뷰] TCIA: A Task-Centric Instruction Augmentation Method for Instruction Finetuning","excerpt":"Simin Ma이 [arXiv]에 게시한 'TCIA: A Task-Centric Instruction Augmentation Method for Instruction Finetuning' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-29 13:14:44+0900","lastModifiedAt":"2025-08-29 13:14:44+0900","categories":["Review"],"tags":["Review","Instruction Augmentation","Fine-tuning","Large Language Models","Task-Centric","Data Diversity","Task Alignment","Breadth-First Search","Constraint Generation"],"permalink":"/ai/review/2025-8-29-TCIA_A_Task-Centric_Instruction_Augmentation_Method_for_Instruction_Finetuning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-29-rStar2-Agent_Agentic_Reasoning_Technical_Report","title":"[논문리뷰] rStar2-Agent: Agentic Reasoning Technical Report","excerpt":"Weijiang Xu이 [arXiv]에 게시한 'rStar2-Agent: Agentic Reasoning Technical Report' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-29 13:14:44+0900","lastModifiedAt":"2025-08-29 13:14:44+0900","categories":["Review"],"tags":["Review","Agentic Reinforcement Learning","Math Reasoning","Code Interpreter","Tool Use","GRPO-RoC","LLM Training Efficiency","Self-Reflection"],"permalink":"/ai/review/2025-8-29-rStar2-Agent_Agentic_Reasoning_Technical_Report/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-29-ROSE_Remove_Objects_with_Side_Effects_in_Videos","title":"[논문리뷰] ROSE: Remove Objects with Side Effects in Videos","excerpt":"Hantang Liu이 [arXiv]에 게시한 'ROSE: Remove Objects with Side Effects in Videos' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-29 13:14:44+0900","lastModifiedAt":"2025-08-29 13:14:44+0900","categories":["Review"],"tags":["Review","Video Object Removal","Side Effects","3D Rendering","Diffusion Transformer","Video Inpainting","Synthetic Data","Difference Mask"],"permalink":"/ai/review/2025-8-29-ROSE_Remove_Objects_with_Side_Effects_in_Videos/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-29-Provable_Benefits_of_In-Tool_Learning_for_Large_Language_Models","title":"[논문리뷰] Provable Benefits of In-Tool Learning for Large Language Models","excerpt":"Vivien Cabannes이 [arXiv]에 게시한 'Provable Benefits of In-Tool Learning for Large Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-29 13:14:44+0900","lastModifiedAt":"2025-08-29 13:14:44+0900","categories":["Review"],"tags":["Review","Large Language Models","In-Tool Learning","In-Weight Learning","Factual Recall","Retrieval-Augmented Generation","Scaling Laws","Parameter Efficiency","Catastrophic Forgetting"],"permalink":"/ai/review/2025-8-29-Provable_Benefits_of_In-Tool_Learning_for_Large_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-29-Pref-GRPO_Pairwise_Preference_Reward-based_GRPO_for_Stable_Text-to-Image_Reinforcement_Learning","title":"[논문리뷰] Pref-GRPO: Pairwise Preference Reward-based GRPO for Stable Text-to-Image Reinforcement Learning","excerpt":"Jiazi Bu이 [arXiv]에 게시한 'Pref-GRPO: Pairwise Preference Reward-based GRPO for Stable Text-to-Image Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-29 13:14:44+0900","lastModifiedAt":"2025-08-29 13:14:44+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","Text-to-Image Generation","GRPO","Reward Hacking","Pairwise Preference","Reward Model","Stable Optimization","UniGenBench"],"permalink":"/ai/review/2025-8-29-Pref-GRPO_Pairwise_Preference_Reward-based_GRPO_for_Stable_Text-to-Image_Reinforcement_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-29-Persuasion_Dynamics_in_LLMs_Investigating_Robustness_and_Adaptability_in_Knowledge_and_Safety_with_DuET-PD","title":"[논문리뷰] Persuasion Dynamics in LLMs: Investigating Robustness and Adaptability in Knowledge and Safety with DuET-PD","excerpt":"Roy Ka-Wei Lee이 [arXiv]에 게시한 'Persuasion Dynamics in LLMs: Investigating Robustness and Adaptability in Knowledge and Safety with DuET-PD' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-29 13:14:44+0900","lastModifiedAt":"2025-08-29 13:14:44+0900","categories":["Review"],"tags":["Review","Persuasion Dynamics","Large Language Models (LLMs)","Robustness","Gullibility","Receptiveness","Direct Preference Optimization (DPO)","Safety Alignment","Multi-turn Dialogue"],"permalink":"/ai/review/2025-8-29-Persuasion_Dynamics_in_LLMs_Investigating_Robustness_and_Adaptability_in_Knowledge_and_Safety_with_DuET-PD/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-29-OnGoal_Tracking_and_Visualizing_Conversational_Goals_in_Multi-Turn_Dialogue_with_Large_Language_Models","title":"[논문리뷰] OnGoal: Tracking and Visualizing Conversational Goals in Multi-Turn Dialogue with Large Language Models","excerpt":"Alex Endert이 [arXiv]에 게시한 'OnGoal: Tracking and Visualizing Conversational Goals in Multi-Turn Dialogue with Large Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-29 13:14:44+0900","lastModifiedAt":"2025-08-29 13:14:44+0900","categories":["Review"],"tags":["Review","Large Language Models (LLMs)","Human-Computer Interaction (HCI)","Conversational AI","Goal Tracking","Visualization","Multi-Turn Dialogue","User Interface Design","Sensemaking"],"permalink":"/ai/review/2025-8-29-OnGoal_Tracking_and_Visualizing_Conversational_Goals_in_Multi-Turn_Dialogue_with_Large_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-29-OneReward_Unified_Mask-Guided_Image_Generation_via_Multi-Task_Human_Preference_Learning","title":"[논문리뷰] OneReward: Unified Mask-Guided Image Generation via Multi-Task Human Preference Learning","excerpt":"Yitong Wang이 [arXiv]에 게시한 'OneReward: Unified Mask-Guided Image Generation via Multi-Task Human Preference Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-29 13:14:44+0900","lastModifiedAt":"2025-08-29 13:14:44+0900","categories":["Review"],"tags":["Review","Image Generation","Mask-Guided Editing","Reinforcement Learning","Human Preference Learning","Vision-Language Models","Multi-Task Learning","Flow Matching"],"permalink":"/ai/review/2025-8-29-OneReward_Unified_Mask-Guided_Image_Generation_via_Multi-Task_Human_Preference_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-29-Multi-View_3D_Point_Tracking","title":"[논문리뷰] Multi-View 3D Point Tracking","excerpt":"Irem Demir이 [arXiv]에 게시한 'Multi-View 3D Point Tracking' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-29 13:14:44+0900","lastModifiedAt":"2025-08-29 13:14:44+0900","categories":["Review"],"tags":["Review","3D Point Tracking","Multi-View","Transformer","kNN Correlation","Depth Estimation","Dynamic Scenes","Occlusion Handling","Feature Fusion"],"permalink":"/ai/review/2025-8-29-Multi-View_3D_Point_Tracking/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-29-Mixture_of_Contexts_for_Long_Video_Generation","title":"[논문리뷰] Mixture of Contexts for Long Video Generation","excerpt":"Junfei Xiao이 [arXiv]에 게시한 'Mixture of Contexts for Long Video Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-29 13:14:44+0900","lastModifiedAt":"2025-08-29 13:14:44+0900","categories":["Review"],"tags":["Review","Long Video Generation","Diffusion Transformers (DiT)","Sparse Attention","Context Routing","Memory Management","Generative Models","Video Synthesis"],"permalink":"/ai/review/2025-8-29-Mixture_of_Contexts_for_Long_Video_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-29-MCP-Bench_Benchmarking_Tool-Using_LLM_Agents_with_Complex_Real-World_Tasks_via_MCP_Servers","title":"[논문리뷰] MCP-Bench: Benchmarking Tool-Using LLM Agents with Complex Real-World Tasks via MCP Servers","excerpt":"Shashank Biju이 [arXiv]에 게시한 'MCP-Bench: Benchmarking Tool-Using LLM Agents with Complex Real-World Tasks via MCP Servers' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-29 13:14:44+0900","lastModifiedAt":"2025-08-29 13:14:44+0900","categories":["Review"],"tags":["Review","LLM Agents","Tool Use","Benchmarking","Model Context Protocol (MCP)","Cross-Domain Orchestration","Fuzzy Instructions","Multi-Step Tasks","Real-World Scenarios"],"permalink":"/ai/review/2025-8-29-MCP-Bench_Benchmarking_Tool-Using_LLM_Agents_with_Complex_Real-World_Tasks_via_MCP_Servers/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-29-FakeParts_a_New_Family_of_AI-Generated_DeepFakes","title":"[논문리뷰] FakeParts: a New Family of AI-Generated DeepFakes","excerpt":"Xi Wang이 [arXiv]에 게시한 'FakeParts: a New Family of AI-Generated DeepFakes' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-29 13:14:44+0900","lastModifiedAt":"2025-08-29 13:14:44+0900","categories":["Review"],"tags":["Review","Deepfake Detection","Partial Deepfakes","AI-Generated Video","Benchmark Dataset","Video Forensics","Generative Models","Manipulation Detection","Human Perception"],"permalink":"/ai/review/2025-8-29-FakeParts_a_New_Family_of_AI-Generated_DeepFakes/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-29-DressDance_Dress_up_and_Dance_as_You_Like_It_-_Technical_Preview","title":"[논문리뷰] Dress&Dance: Dress up and Dance as You Like It - Technical Preview","excerpt":"Yu-Xiong Wang이 [arXiv]에 게시한 'Dress&Dance: Dress up and Dance as You Like It - Technical Preview' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-29 13:14:44+0900","lastModifiedAt":"2025-08-29 13:14:44+0900","categories":["Review"],"tags":["Review","Virtual Try-On","Video Diffusion","Multi-modal Conditioning","Garment Transfer","Pose Animation","Generative AI","Fashion Tech","CondNet"],"permalink":"/ai/review/2025-8-29-DressDance_Dress_up_and_Dance_as_You_Like_It_-_Technical_Preview/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-29-Collaborative_Multi-Modal_Coding_for_High-Quality_3D_Generation","title":"[논문리뷰] Collaborative Multi-Modal Coding for High-Quality 3D Generation","excerpt":"Ziwei Liu이 [arXiv]에 게시한 'Collaborative Multi-Modal Coding for High-Quality 3D Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-29 13:14:44+0900","lastModifiedAt":"2025-08-29 13:14:44+0900","categories":["Review"],"tags":["Review","3D Generation","Multi-modal Learning","Diffusion Models","Triplane Representation","Collaborative Coding","Image-to-3D","Latent Space"],"permalink":"/ai/review/2025-8-29-Collaborative_Multi-Modal_Coding_for_High-Quality_3D_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-29-CogVLA_Cognition-Aligned_Vision-Language-Action_Model_via_Instruction-Driven_Routing_Sparsification","title":"[논문리뷰] CogVLA: Cognition-Aligned Vision-Language-Action Model via Instruction-Driven Routing & Sparsification","excerpt":"Liqiang Nie이 [arXiv]에 게시한 'CogVLA: Cognition-Aligned Vision-Language-Action Model via Instruction-Driven Routing & Sparsification' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-29 13:14:44+0900","lastModifiedAt":"2025-08-29 13:14:44+0900","categories":["Review"],"tags":["Review","Vision-Language-Action Model","Sparsification","Instruction-Driven Routing","Cognition-Aligned AI","Robotics","Computational Efficiency","Multimodal AI"],"permalink":"/ai/review/2025-8-29-CogVLA_Cognition-Aligned_Vision-Language-Action_Model_via_Instruction-Driven_Routing_Sparsification/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-29-AWorld_Orchestrating_the_Training_Recipe_for_Agentic_AI","title":"[논문리뷰] AWorld: Orchestrating the Training Recipe for Agentic AI","excerpt":"Qintong Wu이 [arXiv]에 게시한 'AWorld: Orchestrating the Training Recipe for Agentic AI' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-29 13:14:44+0900","lastModifiedAt":"2025-08-29 13:14:44+0900","categories":["Review"],"tags":["Review","Agentic AI","Reinforcement Learning","Distributed Systems","Experience Generation","LLM Fine-tuning","GAIA Benchmark","Scalability","AWORLD Framework"],"permalink":"/ai/review/2025-8-29-AWorld_Orchestrating_the_Training_Recipe_for_Agentic_AI/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-28-Taming_the_Chaos_Coordinated_Autoscaling_for_Heterogeneous_and_Disaggregated_LLM_Inference","title":"[논문리뷰] Taming the Chaos: Coordinated Autoscaling for Heterogeneous and Disaggregated LLM Inference","excerpt":"Chunlei Han이 [arXiv]에 게시한 'Taming the Chaos: Coordinated Autoscaling for Heterogeneous and Disaggregated LLM Inference' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-28 13:10:39+0900","lastModifiedAt":"2025-08-28 13:10:39+0900","categories":["Review"],"tags":["Review","LLM Inference","Autoscaling","Disaggregated Architecture","Heterogeneous Hardware","Resource Management","Topology-aware Scheduling","GPU Utilization"],"permalink":"/ai/review/2025-8-28-Taming_the_Chaos_Coordinated_Autoscaling_for_Heterogeneous_and_Disaggregated_LLM_Inference/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-28-StepWiser_Stepwise_Generative_Judges_for_Wiser_Reasoning","title":"[논문리뷰] StepWiser: Stepwise Generative Judges for Wiser Reasoning","excerpt":"Olga Golovneva이 [arXiv]에 게시한 'StepWiser: Stepwise Generative Judges for Wiser Reasoning' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-28 13:10:39+0900","lastModifiedAt":"2025-08-28 13:10:39+0900","categories":["Review"],"tags":["Review","LLM Reasoning","Process Reward Models","Reinforcement Learning","Generative Judges","Stepwise Feedback","Chain-of-Thought","Meta-Reasoning"],"permalink":"/ai/review/2025-8-28-StepWiser_Stepwise_Generative_Judges_for_Wiser_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-28-Self-Rewarding_Vision-Language_Model_via_Reasoning_Decomposition","title":"[논문리뷰] Self-Rewarding Vision-Language Model via Reasoning Decomposition","excerpt":"Zhenwen Liang이 [arXiv]에 게시한 'Self-Rewarding Vision-Language Model via Reasoning Decomposition' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-28 13:10:39+0900","lastModifiedAt":"2025-08-28 13:10:39+0900","categories":["Review"],"tags":["Review","Vision-Language Models","Reinforcement Learning","Self-Rewarding","Reasoning Decomposition","Visual Perception","Language Reasoning","Hallucinations","Language Shortcuts"],"permalink":"/ai/review/2025-8-28-Self-Rewarding_Vision-Language_Model_via_Reasoning_Decomposition/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-28-Predicting_the_Order_of_Upcoming_Tokens_Improves_Language_Modeling","title":"[논문리뷰] Predicting the Order of Upcoming Tokens Improves Language Modeling","excerpt":"Alham Fikri Aji이 [arXiv]에 게시한 'Predicting the Order of Upcoming Tokens Improves Language Modeling' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-28 13:10:39+0900","lastModifiedAt":"2025-08-28 13:10:39+0900","categories":["Review"],"tags":["Review","Language Modeling","Next-Token Prediction","Multi-Token Prediction","Token Order Prediction","Auxiliary Objective","Learning-to-Rank","Transformer","Large Language Models"],"permalink":"/ai/review/2025-8-28-Predicting_the_Order_of_Upcoming_Tokens_Improves_Language_Modeling/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-28-MotionFlux_Efficient_Text-Guided_Motion_Generation_through_Rectified_Flow_Matching_and_Preference_Alignment","title":"[논문리뷰] MotionFlux: Efficient Text-Guided Motion Generation through Rectified Flow Matching and Preference Alignment","excerpt":"An-An Liu이 [arXiv]에 게시한 'MotionFlux: Efficient Text-Guided Motion Generation through Rectified Flow Matching and Preference Alignment' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-28 13:10:39+0900","lastModifiedAt":"2025-08-28 13:10:39+0900","categories":["Review"],"tags":["Review","Text-Guided Motion Generation","Rectified Flow Matching","Preference Alignment","Human Motion Synthesis","Real-time AI","Transformer Architecture","Self-supervised Learning"],"permalink":"/ai/review/2025-8-28-MotionFlux_Efficient_Text-Guided_Motion_Generation_through_Rectified_Flow_Matching_and_Preference_Alignment/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-28-Mind_the_Third_Eye_Benchmarking_Privacy_Awareness_in_MLLM-powered_Smartphone_Agents","title":"[논문리뷰] Mind the Third Eye! Benchmarking Privacy Awareness in MLLM-powered Smartphone Agents","excerpt":"Yue Yao이 [arXiv]에 게시한 'Mind the Third Eye! Benchmarking Privacy Awareness in MLLM-powered Smartphone Agents' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-28 13:10:39+0900","lastModifiedAt":"2025-08-28 13:10:39+0900","categories":["Review"],"tags":["Review","Multimodal LLMs (MLLMs)","Smartphone Agents","Privacy Awareness","Benchmarking","Sensitive Data Detection","Risk Assessment","UI Automation"],"permalink":"/ai/review/2025-8-28-Mind_the_Third_Eye_Benchmarking_Privacy_Awareness_in_MLLM-powered_Smartphone_Agents/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-28-MIDAS_Multimodal_Interactive_Digital-human_Synthesis_via_Real-time_Autoregressive_Video_Generation","title":"[논문리뷰] MIDAS: Multimodal Interactive Digital-human Synthesis via Real-time Autoregressive Video Generation","excerpt":"Yan Zhou이 [arXiv]에 게시한 'MIDAS: Multimodal Interactive Digital-human Synthesis via Real-time Autoregressive Video Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-28 13:10:39+0900","lastModifiedAt":"2025-08-28 13:10:39+0900","categories":["Review"],"tags":["Review","Multimodal Generation","Digital Human Synthesis","Real-time Video Generation","Autoregressive LLM","Diffusion Models","Deep Compression Autoencoder","Exposure Bias Mitigation","Streaming Inference"],"permalink":"/ai/review/2025-8-28-MIDAS_Multimodal_Interactive_Digital-human_Synthesis_via_Real-time_Autoregressive_Video_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-28-Gaze_into_the_Heart_A_Multi-View_Video_Dataset_for_rPPG_and_Health_Biomarkers_Estimation","title":"[논문리뷰] Gaze into the Heart: A Multi-View Video Dataset for rPPG and Health Biomarkers Estimation","excerpt":"Anton Ivaschenko이 [arXiv]에 게시한 'Gaze into the Heart: A Multi-View Video Dataset for rPPG and Health Biomarkers Estimation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-28 13:10:39+0900","lastModifiedAt":"2025-08-28 13:10:39+0900","categories":["Review"],"tags":["Review","rPPG","Multi-View Video Dataset","Health Biomarkers","Physiological Monitoring","Deep Learning","Telemedicine","Biosignals"],"permalink":"/ai/review/2025-8-28-Gaze_into_the_Heart_A_Multi-View_Video_Dataset_for_rPPG_and_Health_Biomarkers_Estimation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-28-Discrete_Diffusion_VLA_Bringing_Discrete_Diffusion_to_Action_Decoding_in_Vision-Language-Action_Policies","title":"[논문리뷰] Discrete Diffusion VLA: Bringing Discrete Diffusion to Action Decoding in Vision-Language-Action Policies","excerpt":"Sitong Mao이 [arXiv]에 게시한 'Discrete Diffusion VLA: Bringing Discrete Diffusion to Action Decoding in Vision-Language-Action Policies' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-28 13:10:39+0900","lastModifiedAt":"2025-08-28 13:10:39+0900","categories":["Review"],"tags":["Review","Vision-Language-Action (VLA)","Discrete Diffusion","Action Decoding","Transformer","Robot Control","Masked Modeling","Adaptive Decoding","Reinforcement Learning"],"permalink":"/ai/review/2025-8-28-Discrete_Diffusion_VLA_Bringing_Discrete_Diffusion_to_Action_Decoding_in_Vision-Language-Action_Policies/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-28-Diffusion_Language_Models_Know_the_Answer_Before_Decoding","title":"[논문리뷰] Diffusion Language Models Know the Answer Before Decoding","excerpt":"Shilin Yan이 [arXiv]에 게시한 'Diffusion Language Models Know the Answer Before Decoding' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-28 13:10:39+0900","lastModifiedAt":"2025-08-28 13:10:39+0900","categories":["Review"],"tags":["Review","Diffusion Language Models","DLM Acceleration","Early Answer Convergence","Early Commit Decoding","Confidence Gap","Inference Speedup","Training-Free"],"permalink":"/ai/review/2025-8-28-Diffusion_Language_Models_Know_the_Answer_Before_Decoding/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-28-DeepScholar-Bench_A_Live_Benchmark_and_Automated_Evaluation_for_Generative_Research_Synthesis","title":"[논문리뷰] DeepScholar-Bench: A Live Benchmark and Automated Evaluation for Generative Research Synthesis","excerpt":"Ion Stoica이 [arXiv]에 게시한 'DeepScholar-Bench: A Live Benchmark and Automated Evaluation for Generative Research Synthesis' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-28 13:10:39+0900","lastModifiedAt":"2025-08-28 13:10:39+0900","categories":["Review"],"tags":["Review","Generative Research Synthesis","Live Benchmark","Automated Evaluation","LLM-as-a-judge","Related Work Generation","Retrieval-Augmented Generation","Verifiability"],"permalink":"/ai/review/2025-8-28-DeepScholar-Bench_A_Live_Benchmark_and_Automated_Evaluation_for_Generative_Research_Synthesis/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-28-CODA_Coordinating_the_Cerebrum_and_Cerebellum_for_a_Dual-Brain_Computer_Use_Agent_with_Decoupled_Reinforcement_Learning","title":"[논문리뷰] CODA: Coordinating the Cerebrum and Cerebellum for a Dual-Brain Computer Use Agent with Decoupled Reinforcement Learning","excerpt":"Jianze Liang이 [arXiv]에 게시한 'CODA: Coordinating the Cerebrum and Cerebellum for a Dual-Brain Computer Use Agent with Decoupled Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-28 13:10:39+0900","lastModifiedAt":"2025-08-28 13:10:39+0900","categories":["Review"],"tags":["Review","GUI Agents","Reinforcement Learning","Planner-Executor Architecture","Decoupled Training","Large Vision-Language Models","Specialization","Generalization","Computer Use Agent"],"permalink":"/ai/review/2025-8-28-CODA_Coordinating_the_Cerebrum_and_Cerebellum_for_a_Dual-Brain_Computer_Use_Agent_with_Decoupled_Reinforcement_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-28-Beyond_Transcription_Mechanistic_Interpretability_in_ASR","title":"[논문리뷰] Beyond Transcription: Mechanistic Interpretability in ASR","excerpt":"Aviv Shamsian이 [arXiv]에 게시한 'Beyond Transcription: Mechanistic Interpretability in ASR' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-28 13:10:39+0900","lastModifiedAt":"2025-08-28 13:10:39+0900","categories":["Review"],"tags":["Review","ASR","Mechanistic Interpretability","Logit Lens","Linear Probing","Activation Patching","Hallucinations","Repetitions","Encoder-Decoder"],"permalink":"/ai/review/2025-8-28-Beyond_Transcription_Mechanistic_Interpretability_in_ASR/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-28-AudioStory_Generating_Long-Form_Narrative_Audio_with_Large_Language_Models","title":"[논문리뷰] AudioStory: Generating Long-Form Narrative Audio with Large Language Models","excerpt":"Yixiao Ge이 [arXiv]에 게시한 'AudioStory: Generating Long-Form Narrative Audio with Large Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-28 13:10:39+0900","lastModifiedAt":"2025-08-28 13:10:39+0900","categories":["Review"],"tags":["Review","Text-to-Audio","Long-Form Audio Generation","Large Language Models","Narrative Reasoning","Diffusion Models","Multimodal AI","Progressive Training"],"permalink":"/ai/review/2025-8-28-AudioStory_Generating_Long-Form_Narrative_Audio_with_Large_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-27-Wan-S2V_Audio-Driven_Cinematic_Video_Generation","title":"[논문리뷰] Wan-S2V: Audio-Driven Cinematic Video Generation","excerpt":"Chaonan Ji이 [arXiv]에 게시한 'Wan-S2V: Audio-Driven Cinematic Video Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-27 13:22:18+0900","lastModifiedAt":"2025-08-27 13:22:18+0900","categories":["Review"],"tags":["Review","Audio-Driven Video Generation","Cinematic Video","Diffusion Models","Transformer Architecture","Long Video Consistency","Human Animation","Multimodal Control","Data Curation"],"permalink":"/ai/review/2025-8-27-Wan-S2V_Audio-Driven_Cinematic_Video_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-27-VoxHammer_Training-Free_Precise_and_Coherent_3D_Editing_in_Native_3D_Space","title":"[논문리뷰] VoxHammer: Training-Free Precise and Coherent 3D Editing in Native 3D Space","excerpt":"Rui Chen이 [arXiv]에 게시한 'VoxHammer: Training-Free Precise and Coherent 3D Editing in Native 3D Space' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-27 13:22:18+0900","lastModifiedAt":"2025-08-27 13:22:18+0900","categories":["Review"],"tags":["Review","3D Editing","Training-Free","Diffusion Models","Latent Space","3D Inversion","Contextual Feature Replacement","3D Consistency","Edit3D-Bench"],"permalink":"/ai/review/2025-8-27-VoxHammer_Training-Free_Precise_and_Coherent_3D_Editing_in_Native_3D_Space/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-27-VibeVoice_Technical_Report","title":"[논문리뷰] VibeVoice Technical Report","excerpt":"Yaoyao Chang이 [arXiv]에 게시한 'VibeVoice Technical Report' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-27 13:22:18+0900","lastModifiedAt":"2025-08-27 13:22:18+0900","categories":["Review"],"tags":["Review","Speech Synthesis","Long-form Audio","Multi-speaker","Next-token Diffusion","Speech Tokenizer","Large Language Model","Variational Autoencoder","Audio Compression"],"permalink":"/ai/review/2025-8-27-VibeVoice_Technical_Report/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-27-Unraveling_the_cognitive_patterns_of_Large_Language_Models_through_module_communities","title":"[논문리뷰] Unraveling the cognitive patterns of Large Language Models through module communities","excerpt":"Jianxi Gao이 [arXiv]에 게시한 'Unraveling the cognitive patterns of Large Language Models through module communities' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-27 13:22:18+0900","lastModifiedAt":"2025-08-27 13:22:18+0900","categories":["Review"],"tags":["Review","Large Language Models","Network Community Structure","Cognitive Skills","AI Interpretability","Module Communities","Fine-tuning","Neural Plasticity"],"permalink":"/ai/review/2025-8-27-Unraveling_the_cognitive_patterns_of_Large_Language_Models_through_module_communities/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-27-UltraMemV2_Memory_Networks_Scaling_to_120B_Parameters_with_Superior_Long-Context_Learning","title":"[논문리뷰] UltraMemV2: Memory Networks Scaling to 120B Parameters with Superior Long-Context Learning","excerpt":"Ran Guo이 [arXiv]에 게시한 'UltraMemV2: Memory Networks Scaling to 120B Parameters with Superior Long-Context Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-27 13:22:18+0900","lastModifiedAt":"2025-08-27 13:22:18+0900","categories":["Review"],"tags":["Review","Memory Networks","Mixture of Experts (MoE)","Long-Context Learning","Sparse Models","Transformer Architecture","LLMs","Efficient Inference"],"permalink":"/ai/review/2025-8-27-UltraMemV2_Memory_Networks_Scaling_to_120B_Parameters_with_Superior_Long-Context_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-27-TreePO_Bridging_the_Gap_of_Policy_Optimization_and_Efficacy_and_Inference_Efficiency_with_Heuristic_Tree-based_Modeling","title":"[논문리뷰] TreePO: Bridging the Gap of Policy Optimization and Efficacy and Inference Efficiency with Heuristic Tree-based Modeling","excerpt":"Zhoufutu Wen이 [arXiv]에 게시한 'TreePO: Bridging the Gap of Policy Optimization and Efficacy and Inference Efficiency with Heuristic Tree-based Modeling' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-27 13:22:18+0900","lastModifiedAt":"2025-08-27 13:22:18+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","Policy Optimization","Large Language Models","Inference Efficiency","Tree Search","Segment-level Decoding","Advantage Estimation","Reasoning"],"permalink":"/ai/review/2025-8-27-TreePO_Bridging_the_Gap_of_Policy_Optimization_and_Efficacy_and_Inference_Efficiency_with_Heuristic_Tree-based_Modeling/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-27-Training_Language_Model_Agents_to_Find_Vulnerabilities_with_CTF-Dojo","title":"[논문리뷰] Training Language Model Agents to Find Vulnerabilities with CTF-Dojo","excerpt":"Zijian Wang이 [arXiv]에 게시한 'Training Language Model Agents to Find Vulnerabilities with CTF-Dojo' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-27 13:22:18+0900","lastModifiedAt":"2025-08-27 13:22:18+0900","categories":["Review"],"tags":["Review","LLM Agents","Cybersecurity","CTF Challenges","Vulnerability Detection","Execution Environments","Docker","Automated Training","Verifiable Feedback"],"permalink":"/ai/review/2025-8-27-Training_Language_Model_Agents_to_Find_Vulnerabilities_with_CTF-Dojo/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-27-ThinkDial_An_Open_Recipe_for_Controlling_Reasoning_Effort_in_Large_Language_Models","title":"[논문리뷰] ThinkDial: An Open Recipe for Controlling Reasoning Effort in Large Language Models","excerpt":"Jiangjie Chen이 [arXiv]에 게시한 'ThinkDial: An Open Recipe for Controlling Reasoning Effort in Large Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-27 13:22:18+0900","lastModifiedAt":"2025-08-27 13:22:18+0900","categories":["Review"],"tags":["Review","LLMs","Controllable Reasoning","Computational Efficiency","Reinforcement Learning","Supervised Fine-tuning","Reasoning Compression","Budget-Aware Training"],"permalink":"/ai/review/2025-8-27-ThinkDial_An_Open_Recipe_for_Controlling_Reasoning_Effort_in_Large_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-27-Spacer_Towards_Engineered_Scientific_Inspiration","title":"[논문리뷰] Spacer: Towards Engineered Scientific Inspiration","excerpt":"zerojun48이 [arXiv]에 게시한 'Spacer: Towards Engineered Scientific Inspiration' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-27 13:22:18+0900","lastModifiedAt":"2025-08-27 13:22:18+0900","categories":["Review"],"tags":["Review","Scientific Discovery","Large Language Models (LLMs)","Decontextualization","Keyword Graph","Multi-Agent System","Scientific Ideation","Research Automation","Inspiration Engine"],"permalink":"/ai/review/2025-8-27-Spacer_Towards_Engineered_Scientific_Inspiration/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-27-ReportBench_Evaluating_Deep_Research_Agents_via_Academic_Survey_Tasks","title":"[논문리뷰] ReportBench: Evaluating Deep Research Agents via Academic Survey Tasks","excerpt":"Kai Jia이 [arXiv]에 게시한 'ReportBench: Evaluating Deep Research Agents via Academic Survey Tasks' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-27 13:22:18+0900","lastModifiedAt":"2025-08-27 13:22:18+0900","categories":["Review"],"tags":["Review","Deep Research Agents","LLM Evaluation","Academic Survey","Factual Accuracy","Citation Verification","Report Generation","Benchmark","Hallucination"],"permalink":"/ai/review/2025-8-27-ReportBench_Evaluating_Deep_Research_Agents_via_Academic_Survey_Tasks/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-27-QueryBandits_for_Hallucination_Mitigation_Exploiting_Semantic_Features_for_No-Regret_Rewriting","title":"[논문리뷰] QueryBandits for Hallucination Mitigation: Exploiting Semantic Features for No-Regret Rewriting","excerpt":"Manuela Veloso이 [arXiv]에 게시한 'QueryBandits for Hallucination Mitigation: Exploiting Semantic Features for No-Regret Rewriting' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-27 13:22:18+0900","lastModifiedAt":"2025-08-27 13:22:18+0900","categories":["Review"],"tags":["Review","Hallucination Mitigation","Large Language Models","Contextual Bandits","Query Rewriting","Semantic Features","No-Regret Learning"],"permalink":"/ai/review/2025-8-27-QueryBandits_for_Hallucination_Mitigation_Exploiting_Semantic_Features_for_No-Regret_Rewriting/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-27-Pixie_Fast_and_Generalizable_Supervised_Learning_of_3D_Physics_from_Pixels","title":"[논문리뷰] Pixie: Fast and Generalizable Supervised Learning of 3D Physics from Pixels","excerpt":"Dinesh Jayaraman이 [arXiv]에 게시한 'Pixie: Fast and Generalizable Supervised Learning of 3D Physics from Pixels' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-27 13:22:18+0900","lastModifiedAt":"2025-08-27 13:22:18+0900","categories":["Review"],"tags":["Review","3D Physics Prediction","Supervised Learning","CLIP Features","Neural Radiance Fields","Material Point Method","PIXIEVERSE Dataset","Zero-Shot Generalization"],"permalink":"/ai/review/2025-8-27-Pixie_Fast_and_Generalizable_Supervised_Learning_of_3D_Physics_from_Pixels/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-27-Optimal_Sparsity_of_Mixture-of-Experts_Language_Models_for_Reasoning_Tasks","title":"[논문리뷰] Optimal Sparsity of Mixture-of-Experts Language Models for Reasoning Tasks","excerpt":"Daisuke Nohara이 [arXiv]에 게시한 'Optimal Sparsity of Mixture-of-Experts Language Models for Reasoning Tasks' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-27 13:22:18+0900","lastModifiedAt":"2025-08-27 13:22:18+0900","categories":["Review"],"tags":["Review","Mixture-of-Experts (MoE)","Sparsity","Scaling Laws","Reasoning Tasks","Memorization","Large Language Models","Generalization Gap","Top-k Routing"],"permalink":"/ai/review/2025-8-27-Optimal_Sparsity_of_Mixture-of-Experts_Language_Models_for_Reasoning_Tasks/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-27-OmniHuman-1.5_Instilling_an_Active_Mind_in_Avatars_via_Cognitive_Simulation","title":"[논문리뷰] OmniHuman-1.5: Instilling an Active Mind in Avatars via Cognitive Simulation","excerpt":"Jiaqi Yang이 [arXiv]에 게시한 'OmniHuman-1.5: Instilling an Active Mind in Avatars via Cognitive Simulation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-27 13:22:18+0900","lastModifiedAt":"2025-08-27 13:22:18+0900","categories":["Review"],"tags":["Review","Video Avatar Generation","Cognitive Simulation","Multimodal Large Language Models (MLLMs)","Diffusion Transformers (DiT)","Multimodal Fusion","Human Motion Synthesis","Contextual Animation"],"permalink":"/ai/review/2025-8-27-OmniHuman-1.5_Instilling_an_Active_Mind_in_Avatars_via_Cognitive_Simulation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-27-ObjFiller-3D_Consistent_Multi-view_3D_Inpainting_via_Video_Diffusion_Models","title":"[논문리뷰] ObjFiller-3D: Consistent Multi-view 3D Inpainting via Video Diffusion Models","excerpt":"Beiqi Chen이 [arXiv]에 게시한 'ObjFiller-3D: Consistent Multi-view 3D Inpainting via Video Diffusion Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-27 13:22:18+0900","lastModifiedAt":"2025-08-27 13:22:18+0900","categories":["Review"],"tags":["Review","3D Inpainting","Multi-view Consistency","Video Diffusion Models","3D Object Completion","Generative Models","LoRA","3D Gaussian Splatting"],"permalink":"/ai/review/2025-8-27-ObjFiller-3D_Consistent_Multi-view_3D_Inpainting_via_Video_Diffusion_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-27-MovieCORE_COgnitive_REasoning_in_Movies","title":"[논문리뷰] MovieCORE: COgnitive REasoning in Movies","excerpt":"Hung-Ting Su이 [arXiv]에 게시한 'MovieCORE: COgnitive REasoning in Movies' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-27 13:22:18+0900","lastModifiedAt":"2025-08-27 13:22:18+0900","categories":["Review"],"tags":["Review","Video Question Answering (VQA)","Cognitive Reasoning","System-2 Thinking","Multi-agent LLMs","Dataset Creation","Movie Understanding","Cinematic Content","Agentic Enhancement"],"permalink":"/ai/review/2025-8-27-MovieCORE_COgnitive_REasoning_in_Movies/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-27-FastMeshEfficient_Artistic_Mesh_Generation_via_Component_Decoupling","title":"[논문리뷰] FastMesh:Efficient Artistic Mesh Generation via Component Decoupling","excerpt":"Xingang Pan이 [arXiv]에 게시한 'FastMesh:Efficient Artistic Mesh Generation via Component Decoupling' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-27 13:22:18+0900","lastModifiedAt":"2025-08-27 13:22:18+0900","categories":["Review"],"tags":["Review","3D Mesh Generation","Component Decoupling","Autoregressive Models","Bidirectional Transformer","Fidelity Enhancement","Prediction Filtering","Token Efficiency","Artistic Meshes"],"permalink":"/ai/review/2025-8-27-FastMeshEfficient_Artistic_Mesh_Generation_via_Component_Decoupling/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-27-Demystifying_Scientific_Problem-Solving_in_LLMs_by_Probing_Knowledge_and_Reasoning","title":"[논문리뷰] Demystifying Scientific Problem-Solving in LLMs by Probing Knowledge and Reasoning","excerpt":"Arman Cohan이 [arXiv]에 게시한 'Demystifying Scientific Problem-Solving in LLMs by Probing Knowledge and Reasoning' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-27 13:22:18+0900","lastModifiedAt":"2025-08-27 13:22:18+0900","categories":["Review"],"tags":["Review","Large Language Models","Scientific Reasoning","Knowledge Retrieval","Reasoning Probing","Benchmarks","Chain-of-Thought","Fine-tuning"],"permalink":"/ai/review/2025-8-27-Demystifying_Scientific_Problem-Solving_in_LLMs_by_Probing_Knowledge_and_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-27-CMPhysBench_A_Benchmark_for_Evaluating_Large_Language_Models_in_Condensed_Matter_Physics","title":"[논문리뷰] CMPhysBench: A Benchmark for Evaluating Large Language Models in Condensed Matter Physics","excerpt":"Dongchen Huang이 [arXiv]에 게시한 'CMPhysBench: A Benchmark for Evaluating Large Language Models in Condensed Matter Physics' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-27 13:22:18+0900","lastModifiedAt":"2025-08-27 13:22:18+0900","categories":["Review"],"tags":["Review","Large Language Models","Condensed Matter Physics","Benchmark","Scientific Reasoning","Evaluation Metric","Expression Edit Distance","Problem Solving"],"permalink":"/ai/review/2025-8-27-CMPhysBench_A_Benchmark_for_Evaluating_Large_Language_Models_in_Condensed_Matter_Physics/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-27-ClaimGen-CN_A_Large-scale_Chinese_Dataset_for_Legal_Claim_Generation","title":"[논문리뷰] ClaimGen-CN: A Large-scale Chinese Dataset for Legal Claim Generation","excerpt":"Kun Kuang이 [arXiv]에 게시한 'ClaimGen-CN: A Large-scale Chinese Dataset for Legal Claim Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-27 13:22:18+0900","lastModifiedAt":"2025-08-27 13:22:18+0900","categories":["Review"],"tags":["Review","Legal AI","Natural Language Processing","Claim Generation","Chinese Legal Dataset","Factuality","Clarity","Large Language Models","Zero-shot Evaluation"],"permalink":"/ai/review/2025-8-27-ClaimGen-CN_A_Large-scale_Chinese_Dataset_for_Legal_Claim_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-27-CineScale_Free_Lunch_in_High-Resolution_Cinematic_Visual_Generation","title":"[논문리뷰] CineScale: Free Lunch in High-Resolution Cinematic Visual Generation","excerpt":"Ziwei Liu이 [arXiv]에 게시한 'CineScale: Free Lunch in High-Resolution Cinematic Visual Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-27 13:22:18+0900","lastModifiedAt":"2025-08-27 13:22:18+0900","categories":["Review"],"tags":["Review","Diffusion Models","High-Resolution Generation","Image Generation","Video Generation","UNet Architecture","DiT Architecture","Scale Fusion","LoRA Fine-tuning"],"permalink":"/ai/review/2025-8-27-CineScale_Free_Lunch_in_High-Resolution_Cinematic_Visual_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-27-Autoregressive_Universal_Video_Segmentation_Model","title":"[논문리뷰] Autoregressive Universal Video Segmentation Model","excerpt":"Albert Gu이 [arXiv]에 게시한 'Autoregressive Universal Video Segmentation Model' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-27 13:22:18+0900","lastModifiedAt":"2025-08-27 13:22:18+0900","categories":["Review"],"tags":["Review","Video Segmentation","Autoregressive Model","Universal Model","State Space Models","Mamba","Parallel Training","Streaming Video","Deep Learning"],"permalink":"/ai/review/2025-8-27-Autoregressive_Universal_Video_Segmentation_Model/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-26-Visual-CoG_Stage-Aware_Reinforcement_Learning_with_Chain_of_Guidance_for_Text-to-Image_Generation","title":"[논문리뷰] Visual-CoG: Stage-Aware Reinforcement Learning with Chain of Guidance for Text-to-Image Generation","excerpt":"Haoxiang Shi이 [arXiv]에 게시한 'Visual-CoG: Stage-Aware Reinforcement Learning with Chain of Guidance for Text-to-Image Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-26 13:21:57+0900","lastModifiedAt":"2025-08-26 13:21:57+0900","categories":["Review"],"tags":["Review","Text-to-Image Generation","Reinforcement Learning","Chain of Thought","Multimodal LLMs","Stage-Aware Rewards","Semantic Reasoning","Generative AI"],"permalink":"/ai/review/2025-8-26-Visual-CoG_Stage-Aware_Reinforcement_Learning_with_Chain_of_Guidance_for_Text-to-Image_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-26-UQ_Assessing_Language_Models_on_Unsolved_Questions","title":"[논문리뷰] UQ: Assessing Language Models on Unsolved Questions","excerpt":"Wei Liu이 [arXiv]에 게시한 'UQ: Assessing Language Models on Unsolved Questions' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-26 13:21:57+0900","lastModifiedAt":"2025-08-26 13:21:57+0900","categories":["Review"],"tags":["Review","LLM Evaluation","Unsolved Questions","AI Benchmark","Oracle-Free Validation","Generator-Validator Gap","Community Evaluation","Stack Exchange"],"permalink":"/ai/review/2025-8-26-UQ_Assessing_Language_Models_on_Unsolved_Questions/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-26-TaDiCodec_Text-aware_Diffusion_Speech_Tokenizer_for_Speech_Language_Modeling","title":"[논문리뷰] TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling","excerpt":"Jiaqi Li이 [arXiv]에 게시한 'TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-26 13:21:57+0900","lastModifiedAt":"2025-08-26 13:21:57+0900","categories":["Review"],"tags":["Review","Speech Tokenizer","Diffusion Model","Text-to-Speech","Speech Language Modeling","Low Bitrate Codec","End-to-End Training","Binary Spherical Quantization"],"permalink":"/ai/review/2025-8-26-TaDiCodec_Text-aware_Diffusion_Speech_Tokenizer_for_Speech_Language_Modeling/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-26-T2I-ReasonBench_Benchmarking_Reasoning-Informed_Text-to-Image_Generation","title":"[논문리뷰] T2I-ReasonBench: Benchmarking Reasoning-Informed Text-to-Image Generation","excerpt":"Xihui Liu이 [arXiv]에 게시한 'T2I-ReasonBench: Benchmarking Reasoning-Informed Text-to-Image Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-26 13:21:57+0900","lastModifiedAt":"2025-08-26 13:21:57+0900","categories":["Review"],"tags":["Review","Text-to-Image Generation","Reasoning Benchmark","Idiom Interpretation","Textual Image Design","Entity Reasoning","Scientific Reasoning","Multimodal LLM Evaluation"],"permalink":"/ai/review/2025-8-26-T2I-ReasonBench_Benchmarking_Reasoning-Informed_Text-to-Image_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-26-ST-Raptor_LLM-Powered_Semi-Structured_Table_Question_Answering","title":"[논문리뷰] ST-Raptor: LLM-Powered Semi-Structured Table Question Answering","excerpt":"Wei Zhou이 [arXiv]에 게시한 'ST-Raptor: LLM-Powered Semi-Structured Table Question Answering' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-26 13:21:57+0900","lastModifiedAt":"2025-08-26 13:21:57+0900","categories":["Review"],"tags":["Review","Semi-structured Tables","Question Answering","LLMs","Hierarchical Orthogonal Tree","Table Layout Understanding","Pipeline Generation","Verification Mechanism"],"permalink":"/ai/review/2025-8-26-ST-Raptor_LLM-Powered_Semi-Structured_Table_Question_Answering/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-26-SpotEdit_Evaluating_Visually-Guided_Image_Editing_Methods","title":"[논문리뷰] SpotEdit: Evaluating Visually-Guided Image Editing Methods","excerpt":"Ersin Yumer이 [arXiv]에 게시한 'SpotEdit: Evaluating Visually-Guided Image Editing Methods' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-26 13:21:57+0900","lastModifiedAt":"2025-08-26 13:21:57+0900","categories":["Review"],"tags":["Review","Visually-Guided Image Editing","Multimodal Models","Benchmark","Hallucination","Diffusion Models","Autoregressive Models","Evaluation Metrics"],"permalink":"/ai/review/2025-8-26-SpotEdit_Evaluating_Visually-Guided_Image_Editing_Methods/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-26-PosterGen_Aesthetic-Aware_Paper-to-Poster_Generation_via_Multi-Agent_LLMs","title":"[논문리뷰] PosterGen: Aesthetic-Aware Paper-to-Poster Generation via Multi-Agent LLMs","excerpt":"Chenyu You이 [arXiv]에 게시한 'PosterGen: Aesthetic-Aware Paper-to-Poster Generation via Multi-Agent LLMs' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-26 13:21:57+0900","lastModifiedAt":"2025-08-26 13:21:57+0900","categories":["Review"],"tags":["Review","Multi-Agent LLMs","Academic Poster Generation","Aesthetic Design","Layout Optimization","Typography","Color Palette","VLM-as-Judge","Content Fidelity"],"permalink":"/ai/review/2025-8-26-PosterGen_Aesthetic-Aware_Paper-to-Poster_Generation_via_Multi-Agent_LLMs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-26-Neither_Valid_nor_Reliable_Investigating_the_Use_of_LLMs_as_Judges","title":"[논문리뷰] Neither Valid nor Reliable? Investigating the Use of LLMs as Judges","excerpt":"Golnoosh Farnadi이 [arXiv]에 게시한 'Neither Valid nor Reliable? Investigating the Use of LLMs as Judges' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-26 13:21:57+0900","lastModifiedAt":"2025-08-26 13:21:57+0900","categories":["Review"],"tags":["Review","LLMs as Judges","NLG Evaluation","Measurement Theory","Validity","Reliability","Evaluation Bias","Scalability","Responsible AI"],"permalink":"/ai/review/2025-8-26-Neither_Valid_nor_Reliable_Investigating_the_Use_of_LLMs_as_Judges/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-26-MV-RAG_Retrieval_Augmented_Multiview_Diffusion","title":"[논문리뷰] MV-RAG: Retrieval Augmented Multiview Diffusion","excerpt":"sagiebenaim이 [arXiv]에 게시한 'MV-RAG: Retrieval Augmented Multiview Diffusion' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-26 13:21:57+0900","lastModifiedAt":"2025-08-26 13:21:57+0900","categories":["Review"],"tags":["Review","Retrieval Augmented Generation","Multiview Diffusion","Text-to-3D Generation","Out-of-Domain","Image Retrieval","3D Consistency","Diffusion Models","Hybrid Training"],"permalink":"/ai/review/2025-8-26-MV-RAG_Retrieval_Augmented_Multiview_Diffusion/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-26-MeshSplat_Generalizable_Sparse-View_Surface_Reconstruction_via_Gaussian_Splatting","title":"[논문리뷰] MeshSplat: Generalizable Sparse-View Surface Reconstruction via Gaussian Splatting","excerpt":"Yanzhe Liang이 [arXiv]에 게시한 'MeshSplat: Generalizable Sparse-View Surface Reconstruction via Gaussian Splatting' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-26 13:21:57+0900","lastModifiedAt":"2025-08-26 13:21:57+0900","categories":["Review"],"tags":["Review","Sparse-View","Surface Reconstruction","Gaussian Splatting","2DGS","Novel View Synthesis","Generalizable","Mesh Extraction","3D Vision"],"permalink":"/ai/review/2025-8-26-MeshSplat_Generalizable_Sparse-View_Surface_Reconstruction_via_Gaussian_Splatting/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-26-MEENA_PersianMMMU_Multimodal-Multilingual_Educational_Exams_for_N-level_Assessment","title":"[논문리뷰] MEENA (PersianMMMU): Multimodal-Multilingual Educational Exams for N-level Assessment","excerpt":"Doratossadat Dastgheib이 [arXiv]에 게시한 'MEENA (PersianMMMU): Multimodal-Multilingual Educational Exams for N-level Assessment' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-26 13:21:57+0900","lastModifiedAt":"2025-08-26 13:21:57+0900","categories":["Review"],"tags":["Review","Multimodal Language Models","Multilingual Benchmarking","Persian Language","Educational Assessment","Vision-Language Models","Cultural Nuance","Reasoning Tasks"],"permalink":"/ai/review/2025-8-26-MEENA_PersianMMMU_Multimodal-Multilingual_Educational_Exams_for_N-level_Assessment/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-26-Limitations_of_Normalization_in_Attention_Mechanism","title":"[논문리뷰] Limitations of Normalization in Attention Mechanism","excerpt":"Radu State이 [arXiv]에 게시한 'Limitations of Normalization in Attention Mechanism' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-26 13:21:57+0900","lastModifiedAt":"2025-08-26 13:21:57+0900","categories":["Review"],"tags":["Review","Attention Mechanism","Normalization","Softmax","Transformer Models","Gradient Sensitivity","Token Separability","Context Length","GPT-2"],"permalink":"/ai/review/2025-8-26-Limitations_of_Normalization_in_Attention_Mechanism/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-26-InternVL3.5_Advancing_Open-Source_Multimodal_Models_in_Versatility_Reasoning_and_Efficiency","title":"[논문리뷰] InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency","excerpt":"jinglinglin이 [arXiv]에 게시한 'InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-26 13:21:57+0900","lastModifiedAt":"2025-08-26 13:21:57+0900","categories":["Review"],"tags":["Review","Multimodal Large Language Models","Reinforcement Learning","Inference Efficiency","Vision-Language Models","Open-Source","Versatility","Reasoning"],"permalink":"/ai/review/2025-8-26-InternVL3.5_Advancing_Open-Source_Multimodal_Models_in_Versatility_Reasoning_and_Efficiency/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-26-German4All_-_A_Dataset_and_Model_for_Readability-Controlled_Paraphrasing_in_German","title":"[논문리뷰] German4All - A Dataset and Model for Readability-Controlled Paraphrasing in German","excerpt":"Cristian-George Craciun이 [arXiv]에 게시한 'German4All - A Dataset and Model for Readability-Controlled Paraphrasing in German' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-26 13:21:57+0900","lastModifiedAt":"2025-08-26 13:21:57+0900","categories":["Review"],"tags":["Review","Text Simplification","Paraphrasing","Readability Control","German NLP","Dataset Generation","LLM Distillation","Multi-level Text Generation","Accessibility"],"permalink":"/ai/review/2025-8-26-German4All_-_A_Dataset_and_Model_for_Readability-Controlled_Paraphrasing_in_German/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-26-Explain_Before_You_Answer_A_Survey_on_Compositional_Visual_Reasoning","title":"[논문리뷰] Explain Before You Answer: A Survey on Compositional Visual Reasoning","excerpt":"Xin Zheng이 [arXiv]에 게시한 'Explain Before You Answer: A Survey on Compositional Visual Reasoning' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-26 13:21:57+0900","lastModifiedAt":"2025-08-26 13:21:57+0900","categories":["Review"],"tags":["Review","Compositional Visual Reasoning","Multimodal AI","Vision-Language Models","Large Language Models","Chain-of-Thought","Tool Learning","Agentic AI","Survey"],"permalink":"/ai/review/2025-8-26-Explain_Before_You_Answer_A_Survey_on_Compositional_Visual_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-26-Breaking_the_Exploration_Bottleneck_Rubric-Scaffolded_Reinforcement_Learning_for_General_LLM_Reasoning","title":"[논문리뷰] Breaking the Exploration Bottleneck: Rubric-Scaffolded Reinforcement Learning for General LLM Reasoning","excerpt":"Jiale Zhao이 [arXiv]에 게시한 'Breaking the Exploration Bottleneck: Rubric-Scaffolded Reinforcement Learning for General LLM Reasoning' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-26 13:21:57+0900","lastModifiedAt":"2025-08-26 13:21:57+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","Large Language Models","Exploration Bottleneck","Instructional Scaffolding","Rubric-based Rewards","General Reasoning","RL with Verifiable Rewards","Policy Optimization"],"permalink":"/ai/review/2025-8-26-Breaking_the_Exploration_Bottleneck_Rubric-Scaffolded_Reinforcement_Learning_for_General_LLM_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-26-Beyond_Memorization_Extending_Reasoning_Depth_with_Recurrence_Memory_and_Test-Time_Compute_Scaling","title":"[논문리뷰] Beyond Memorization: Extending Reasoning Depth with Recurrence, Memory and Test-Time Compute Scaling","excerpt":"Daniil Orel이 [arXiv]에 게시한 'Beyond Memorization: Extending Reasoning Depth with Recurrence, Memory and Test-Time Compute Scaling' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-26 13:21:57+0900","lastModifiedAt":"2025-08-26 13:21:57+0900","categories":["Review"],"tags":["Review","Reasoning Depth","Cellular Automata","Transformer Architectures","Recurrence","Adaptive Computation Time","Chain-of-Thought","Reinforcement Learning","Generalization"],"permalink":"/ai/review/2025-8-26-Beyond_Memorization_Extending_Reasoning_Depth_with_Recurrence_Memory_and_Test-Time_Compute_Scaling/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-25-TPLA_Tensor_Parallel_Latent_Attention_for_Efficient_Disaggregated_Prefill_Decode_Inference","title":"[논문리뷰] TPLA: Tensor Parallel Latent Attention for Efficient Disaggregated Prefill & Decode Inference","excerpt":"Di Yin이 [arXiv]에 게시한 'TPLA: Tensor Parallel Latent Attention for Efficient Disaggregated Prefill & Decode Inference' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-25 13:13:07+0900","lastModifiedAt":"2025-08-25 13:13:07+0900","categories":["Review"],"tags":["Review","LLM Inference","Tensor Parallelism","KV Cache Optimization","Latent Attention","Memory Efficiency","Decoding Speedup","Prefill/Decode Separation","Reparameterization"],"permalink":"/ai/review/2025-8-25-TPLA_Tensor_Parallel_Latent_Attention_for_Efficient_Disaggregated_Prefill_Decode_Inference/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-25-Selective_Contrastive_Learning_for_Weakly_Supervised_Affordance_Grounding","title":"[논문리뷰] Selective Contrastive Learning for Weakly Supervised Affordance Grounding","excerpt":"Jae-Pil Heo이 [arXiv]에 게시한 'Selective Contrastive Learning for Weakly Supervised Affordance Grounding' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-25 13:13:07+0900","lastModifiedAt":"2025-08-25 13:13:07+0900","categories":["Review"],"tags":["Review","Weakly Supervised Learning","Affordance Grounding","Contrastive Learning","CLIP","Part Discovery","Object Localization","DINO","Generative Models"],"permalink":"/ai/review/2025-8-25-Selective_Contrastive_Learning_for_Weakly_Supervised_Affordance_Grounding/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-25-Learnable_SMPLify_A_Neural_Solution_for_Optimization-Free_Human_Pose_Inverse_Kinematics","title":"[논문리뷰] Learnable SMPLify: A Neural Solution for Optimization-Free Human Pose Inverse Kinematics","excerpt":"Xiao Sun이 [arXiv]에 게시한 'Learnable SMPLify: A Neural Solution for Optimization-Free Human Pose Inverse Kinematics' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-25 13:13:07+0900","lastModifiedAt":"2025-08-25 13:13:07+0900","categories":["Review"],"tags":["Review","Inverse Kinematics","Human Pose Estimation","SMPL Model","Neural Networks","Optimization-Free","Residual Learning","Data-Driven"],"permalink":"/ai/review/2025-8-25-Learnable_SMPLify_A_Neural_Solution_for_Optimization-Free_Human_Pose_Inverse_Kinematics/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-25-Jailbreaking_Commercial_Black-Box_LLMs_with_Explicitly_Harmful_Prompts","title":"[논문리뷰] Jailbreaking Commercial Black-Box LLMs with Explicitly Harmful Prompts","excerpt":"Liming Fang이 [arXiv]에 게시한 'Jailbreaking Commercial Black-Box LLMs with Explicitly Harmful Prompts' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-25 13:13:07+0900","lastModifiedAt":"2025-08-25 13:13:07+0900","categories":["Review"],"tags":["Review","LLM Jailbreaking","Red Teaming","Malicious Content Detection","Developer Messages","D-Attack","DH-CoT","Adversarial Attacks","Dataset Cleaning"],"permalink":"/ai/review/2025-8-25-Jailbreaking_Commercial_Black-Box_LLMs_with_Explicitly_Harmful_Prompts/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-25-InMind_Evaluating_LLMs_in_Capturing_and_Applying_Individual_Human_Reasoning_Styles","title":"[논문리뷰] InMind: Evaluating LLMs in Capturing and Applying Individual Human Reasoning Styles","excerpt":"Diping Song이 [arXiv]에 게시한 'InMind: Evaluating LLMs in Capturing and Applying Individual Human Reasoning Styles' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-25 13:13:07+0900","lastModifiedAt":"2025-08-25 13:13:07+0900","categories":["Review"],"tags":["Review","LLM Evaluation","Human Reasoning Styles","Social Deduction Games","Theory of Mind","Adaptive Reasoning","Avalon Game","Cognitive Grounding"],"permalink":"/ai/review/2025-8-25-InMind_Evaluating_LLMs_in_Capturing_and_Applying_Individual_Human_Reasoning_Styles/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-25-End-to-End_Agentic_RAG_System_Training_for_Traceable_Diagnostic_Reasoning","title":"[논문리뷰] End-to-End Agentic RAG System Training for Traceable Diagnostic Reasoning","excerpt":"Pengcheng Qiu이 [arXiv]에 게시한 'End-to-End Agentic RAG System Training for Traceable Diagnostic Reasoning' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-25 13:13:07+0900","lastModifiedAt":"2025-08-25 13:13:07+0900","categories":["Review"],"tags":["Review","Agentic RAG","Medical Diagnosis","Reinforcement Learning","Traceable AI","Large Language Models","Clinical Decision Support","Out-of-Distribution Generalization","Reward Design"],"permalink":"/ai/review/2025-8-25-End-to-End_Agentic_RAG_System_Training_for_Traceable_Diagnostic_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-25-EgoTwin_Dreaming_Body_and_View_in_First_Person","title":"[논문리뷰] EgoTwin: Dreaming Body and View in First Person","excerpt":"Wentao Wang이 [arXiv]에 게시한 'EgoTwin: Dreaming Body and View in First Person' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-25 13:13:07+0900","lastModifiedAt":"2025-08-25 13:13:07+0900","categories":["Review"],"tags":["Review","Egocentric Video Generation","Human Motion Synthesis","Diffusion Transformers","Multimodal Generation","Viewpoint Alignment","Causal Interplay","First-Person Vision"],"permalink":"/ai/review/2025-8-25-EgoTwin_Dreaming_Body_and_View_in_First_Person/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-25-Do_What_Teaching_Vision-Language-Action_Models_to_Reject_the_Impossible","title":"[논문리뷰] Do What? Teaching Vision-Language-Action Models to Reject the Impossible","excerpt":"Roei Herzig이 [arXiv]에 게시한 'Do What? Teaching Vision-Language-Action Models to Reject the Impossible' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-25 13:13:07+0900","lastModifiedAt":"2025-08-25 13:13:07+0900","categories":["Review"],"tags":["Review","Vision-Language-Action Models","Robotics","False Premise Detection","Instruction Following","Human-Robot Interaction","Clarification","Instruction Tuning"],"permalink":"/ai/review/2025-8-25-Do_What_Teaching_Vision-Language-Action_Models_to_Reject_the_Impossible/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-25-CRISP_Persistent_Concept_Unlearning_via_Sparse_Autoencoders","title":"[논문리뷰] CRISP: Persistent Concept Unlearning via Sparse Autoencoders","excerpt":"Yonatan Belinkov이 [arXiv]에 게시한 'CRISP: Persistent Concept Unlearning via Sparse Autoencoders' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-25 13:13:07+0900","lastModifiedAt":"2025-08-25 13:13:07+0900","categories":["Review"],"tags":["Review","Concept Unlearning","Sparse Autoencoders (SAEs)","LLMs","Parameter-Efficient Fine-Tuning","Model Interpretability","Safety-Critical AI","Feature Suppression","WMDP Benchmark"],"permalink":"/ai/review/2025-8-25-CRISP_Persistent_Concept_Unlearning_via_Sparse_Autoencoders/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-25-CARFT_Boosting_LLM_Reasoning_via_Contrastive_Learning_with_Annotated_Chain-of-Thought-based_Reinforced_Fine-Tuning","title":"[논문리뷰] CARFT: Boosting LLM Reasoning via Contrastive Learning with Annotated Chain-of-Thought-based Reinforced Fine-Tuning","excerpt":"Yulun Zhang이 [arXiv]에 게시한 'CARFT: Boosting LLM Reasoning via Contrastive Learning with Annotated Chain-of-Thought-based Reinforced Fine-Tuning' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-25 13:13:07+0900","lastModifiedAt":"2025-08-25 13:13:07+0900","categories":["Review"],"tags":["Review","LLM Reasoning","Contrastive Learning","Reinforcement Learning","Fine-tuning","Chain-of-Thought (CoT)","Annotated Data","Model Stability"],"permalink":"/ai/review/2025-8-25-CARFT_Boosting_LLM_Reasoning_via_Contrastive_Learning_with_Annotated_Chain-of-Thought-based_Reinforced_Fine-Tuning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-25-Beyond_Pass1_Self-Play_with_Variational_Problem_Synthesis_Sustains_RLVR","title":"[논문리뷰] Beyond Pass@1: Self-Play with Variational Problem Synthesis Sustains RLVR","excerpt":"Ying Nian Wu이 [arXiv]에 게시한 'Beyond Pass@1: Self-Play with Variational Problem Synthesis Sustains RLVR' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-25 13:13:07+0900","lastModifiedAt":"2025-08-25 13:13:07+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","Large Language Models","Self-Play","Variational Problem Synthesis","Policy Entropy","Pass@k","Reasoning Benchmarks"],"permalink":"/ai/review/2025-8-25-Beyond_Pass1_Self-Play_with_Variational_Problem_Synthesis_Sustains_RLVR/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-25-AgentScope_1.0_A_Developer-Centric_Framework_for_Building_Agentic_Applications","title":"[논문리뷰] AgentScope 1.0: A Developer-Centric Framework for Building Agentic Applications","excerpt":"Liuyi Yao이 [arXiv]에 게시한 'AgentScope 1.0: A Developer-Centric Framework for Building Agentic Applications' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-25 13:13:07+0900","lastModifiedAt":"2025-08-25 13:13:07+0900","categories":["Review"],"tags":["Review","LLM Agents","Agentic Applications","ReAct Paradigm","Framework","Tool Use","Multi-Agent Systems","Developer Experience","Evaluation"],"permalink":"/ai/review/2025-8-25-AgentScope_1.0_A_Developer-Centric_Framework_for_Building_Agentic_Applications/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-25-AetherCode_Evaluating_LLMs_Ability_to_Win_In_Premier_Programming_Competitions","title":"[논문리뷰] AetherCode: Evaluating LLMs' Ability to Win In Premier Programming Competitions","excerpt":"Yidi Du이 [arXiv]에 게시한 'AetherCode: Evaluating LLMs' Ability to Win In Premier Programming Competitions' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-25 13:13:07+0900","lastModifiedAt":"2025-08-25 13:13:07+0900","categories":["Review"],"tags":["Review","Competitive Programming","LLM Evaluation","Code Reasoning","Benchmark","Test Case Generation","Programming Competitions","Algorithmic Problems"],"permalink":"/ai/review/2025-8-25-AetherCode_Evaluating_LLMs_Ability_to_Win_In_Premier_Programming_Competitions/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-22-When_and_What_Diffusion-Grounded_VideoLLM_with_Entity_Aware_Segmentation_for_Long_Video_Understanding","title":"[논문리뷰] When and What: Diffusion-Grounded VideoLLM with Entity Aware Segmentation for Long Video Understanding","excerpt":"Rui Guo이 [arXiv]에 게시한 'When and What: Diffusion-Grounded VideoLLM with Entity Aware Segmentation for Long Video Understanding' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-22 13:10:52+0900","lastModifiedAt":"2025-08-22 13:10:52+0900","categories":["Review"],"tags":["Review","Video-LLM","Diffusion Model","Temporal Grounding","Object Segmentation","Long Video Understanding","Multimodal AI","Video Question Answering"],"permalink":"/ai/review/2025-8-22-When_and_What_Diffusion-Grounded_VideoLLM_with_Entity_Aware_Segmentation_for_Long_Video_Understanding/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-22-Waver_Wave_Your_Way_to_Lifelike_Video_Generation","title":"[논문리뷰] Waver: Wave Your Way to Lifelike Video Generation","excerpt":"Yifu Zhang이 [arXiv]에 게시한 'Waver: Wave Your Way to Lifelike Video Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-22 13:10:52+0900","lastModifiedAt":"2025-08-22 13:10:52+0900","categories":["Review"],"tags":["Review","Video Generation","Foundation Model","Diffusion Model","Transformer","Text-to-Video","Image-to-Video","Super-Resolution","Data Curation"],"permalink":"/ai/review/2025-8-22-Waver_Wave_Your_Way_to_Lifelike_Video_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-22-Snap-Snap_Taking_Two_Images_to_Reconstruct_3D_Human_Gaussians_in_Milliseconds","title":"[논문리뷰] Snap-Snap: Taking Two Images to Reconstruct 3D Human Gaussians in Milliseconds","excerpt":"Chuiyun Wu이 [arXiv]에 게시한 'Snap-Snap: Taking Two Images to Reconstruct 3D Human Gaussians in Milliseconds' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-22 13:10:52+0900","lastModifiedAt":"2025-08-22 13:10:52+0900","categories":["Review"],"tags":["Review","3D Human Reconstruction","Gaussian Splatting","Sparse View","Two-Image Input","Real-time Inference","Point Cloud Prediction","Feed-forward Network"],"permalink":"/ai/review/2025-8-22-Snap-Snap_Taking_Two_Images_to_Reconstruct_3D_Human_Gaussians_in_Milliseconds/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-22-SceneGen_Single-Image_3D_Scene_Generation_in_One_Feedforward_Pass","title":"[논문리뷰] SceneGen: Single-Image 3D Scene Generation in One Feedforward Pass","excerpt":"Ya Zhang이 [arXiv]에 게시한 'SceneGen: Single-Image 3D Scene Generation in One Feedforward Pass' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-22 13:10:52+0900","lastModifiedAt":"2025-08-22 13:10:52+0900","categories":["Review"],"tags":["Review","3D Scene Generation","Single-Image Input","Feedforward Networks","Diffusion Models","Geometric Modeling","Texture Synthesis","Transformer","Feature Aggregation"],"permalink":"/ai/review/2025-8-22-SceneGen_Single-Image_3D_Scene_Generation_in_One_Feedforward_Pass/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-22-Mobile-Agent-v3_Foundamental_Agents_for_GUI_Automation","title":"[논문리뷰] Mobile-Agent-v3: Foundamental Agents for GUI Automation","excerpt":"Haowei Liu이 [arXiv]에 게시한 'Mobile-Agent-v3: Foundamental Agents for GUI Automation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-22 13:10:52+0900","lastModifiedAt":"2025-08-22 13:10:52+0900","categories":["Review"],"tags":["Review","GUI Automation","Multimodal Agents","Foundational Models","Reinforcement Learning","Large Language Models","Cross-Platform","Self-Supervised Learning"],"permalink":"/ai/review/2025-8-22-Mobile-Agent-v3_Foundamental_Agents_for_GUI_Automation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-22-LiveMCP-101_Stress_Testing_and_Diagnosing_MCP-enabled_Agents_on_Challenging_Queries","title":"[논문리뷰] LiveMCP-101: Stress Testing and Diagnosing MCP-enabled Agents on Challenging Queries","excerpt":"huuuyeah이 [arXiv]에 게시한 'LiveMCP-101: Stress Testing and Diagnosing MCP-enabled Agents on Challenging Queries' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-22 13:10:52+0900","lastModifiedAt":"2025-08-22 13:10:52+0900","categories":["Review"],"tags":["Review","AI Agents","Tool Use","Model Context Protocol (MCP)","Benchmarking","Large Language Models (LLMs)","Real-world Tasks","Evaluation","Error Analysis"],"permalink":"/ai/review/2025-8-22-LiveMCP-101_Stress_Testing_and_Diagnosing_MCP-enabled_Agents_on_Challenging_Queries/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-22-INTIMA_A_Benchmark_for_Human-AI_Companionship_Behavior","title":"[논문리뷰] INTIMA: A Benchmark for Human-AI Companionship Behavior","excerpt":"Yacine Jernite이 [arXiv]에 게시한 'INTIMA: A Benchmark for Human-AI Companionship Behavior' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-22 13:10:52+0900","lastModifiedAt":"2025-08-22 13:10:52+0900","categories":["Review"],"tags":["Review","AI Companionship","Benchmark","Language Models (LLMs)","Human-AI Interaction","Emotional AI","Boundary Setting","Psychological Frameworks","Evaluation Metrics"],"permalink":"/ai/review/2025-8-22-INTIMA_A_Benchmark_for_Human-AI_Companionship_Behavior/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-22-Intern-S1_A_Scientific_Multimodal_Foundation_Model","title":"[논문리뷰] Intern-S1: A Scientific Multimodal Foundation Model","excerpt":"xuhuang87이 [arXiv]에 게시한 'Intern-S1: A Scientific Multimodal Foundation Model' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-22 13:10:52+0900","lastModifiedAt":"2025-08-22 13:10:52+0900","categories":["Review"],"tags":["Review","Multimodal Foundation Model","Scientific AI","Reinforcement Learning","Mixture-of-Experts (MoE)","Dynamic Tokenizer","Data Curation","Low-Resource Learning"],"permalink":"/ai/review/2025-8-22-Intern-S1_A_Scientific_Multimodal_Foundation_Model/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-22-Fin-PRM_A_Domain-Specialized_Process_Reward_Model_for_Financial_Reasoning_in_Large_Language_Models","title":"[논문리뷰] Fin-PRM: A Domain-Specialized Process Reward Model for Financial Reasoning in Large Language Models","excerpt":"Lifan Guo이 [arXiv]에 게시한 'Fin-PRM: A Domain-Specialized Process Reward Model for Financial Reasoning in Large Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-22 13:10:52+0900","lastModifiedAt":"2025-08-22 13:10:52+0900","categories":["Review"],"tags":["Review","Large Language Models","Process Reward Models","Financial Reasoning","Domain Specialization","RLHF","Best-of-N Selection","Data Curation"],"permalink":"/ai/review/2025-8-22-Fin-PRM_A_Domain-Specialized_Process_Reward_Model_for_Financial_Reasoning_in_Large_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-22-Does_the_cafe_entrance_look_accessible_Where_is_the_door_Towards_Geospatial_AI_Agents_for_Visual_Inquiries","title":"[논문리뷰] 'Does the cafe entrance look accessible? Where is the door?' Towards Geospatial AI Agents for Visual Inquiries","excerpt":"Xia Su이 [arXiv]에 게시한 'Does the cafe entrance look accessible? Where is the door? Towards Geospatial AI Agents for Visual Inquiries' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-22 13:10:52+0900","lastModifiedAt":"2025-08-22 13:10:52+0900","categories":["Review"],"tags":["Review","Geospatial AI","Multimodal AI Agents","Visual Question Answering","Accessibility","Street View Imagery","Spatial Reasoning","Human-Computer Interaction"],"permalink":"/ai/review/2025-8-22-Does_the_cafe_entrance_look_accessible_Where_is_the_door_Towards_Geospatial_AI_Agents_for_Visual_Inquiries/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-22-Deep_Think_with_Confidence","title":"[논문리뷰] Deep Think with Confidence","excerpt":"Xuewei Wang이 [arXiv]에 게시한 'Deep Think with Confidence' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-22 13:10:52+0900","lastModifiedAt":"2025-08-22 13:10:52+0900","categories":["Review"],"tags":["Review","LLM Reasoning","Confidence Filtering","Self-Consistency","Test-Time Optimization","Computational Efficiency","Adaptive Sampling","Early Stopping","Majority Voting"],"permalink":"/ai/review/2025-8-22-Deep_Think_with_Confidence/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-22-A_Survey_on_Large_Language_Model_Benchmarks","title":"[논문리뷰] A Survey on Large Language Model Benchmarks","excerpt":"Siyi Li이 [arXiv]에 게시한 'A Survey on Large Language Model Benchmarks' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-22 13:10:52+0900","lastModifiedAt":"2025-08-22 13:10:52+0900","categories":["Review"],"tags":["Review","LLM Benchmarks","Evaluation","Systematic Review","General Capabilities","Domain-Specific Benchmarks","Target-Specific Benchmarks","Data Contamination","AI Ethics"],"permalink":"/ai/review/2025-8-22-A_Survey_on_Large_Language_Model_Benchmarks/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-22-ATLAS_Decoupling_Skeletal_and_Shape_Parameters_for_Expressive_Parametric_Human_Modeling","title":"[논문리뷰] ATLAS: Decoupling Skeletal and Shape Parameters for Expressive Parametric Human Modeling","excerpt":"Shunsuke Saito이 [arXiv]에 게시한 'ATLAS: Decoupling Skeletal and Shape Parameters for Expressive Parametric Human Modeling' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-22 13:10:52+0900","lastModifiedAt":"2025-08-22 13:10:52+0900","categories":["Review"],"tags":["Review","Parametric Human Model","3D Human Modeling","Shape-Skeleton Decoupling","Pose Correctives","Single Image Mesh Fitting","Expressive Modeling","Goliath Dataset"],"permalink":"/ai/review/2025-8-22-ATLAS_Decoupling_Skeletal_and_Shape_Parameters_for_Expressive_Parametric_Human_Modeling/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-22-aiXiv_A_Next-Generation_Open_Access_Ecosystem_for_Scientific_Discovery_Generated_by_AI_Scientists","title":"[논문리뷰] aiXiv: A Next-Generation Open Access Ecosystem for Scientific Discovery Generated by AI Scientists","excerpt":"Heng Zhang이 [arXiv]에 게시한 'aiXiv: A Next-Generation Open Access Ecosystem for Scientific Discovery Generated by AI Scientists' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-22 13:10:52+0900","lastModifiedAt":"2025-08-22 13:10:52+0900","categories":["Review"],"tags":["Review","AI Agents","Open Access","Scientific Discovery","Peer Review","LLMs","Multi-agent Systems","Prompt Injection","Iterative Refinement"],"permalink":"/ai/review/2025-8-22-aiXiv_A_Next-Generation_Open_Access_Ecosystem_for_Scientific_Discovery_Generated_by_AI_Scientists/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-21-ViExam_Are_Vision_Language_Models_Better_than_Humans_on_Vietnamese_Multimodal_Exam_Questions","title":"[논문리뷰] ViExam: Are Vision Language Models Better than Humans on Vietnamese Multimodal Exam Questions?","excerpt":"Daeyoung Kim이 [arXiv]에 게시한 'ViExam: Are Vision Language Models Better than Humans on Vietnamese Multimodal Exam Questions?' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-21 13:15:28+0900","lastModifiedAt":"2025-08-21 13:15:28+0900","categories":["Review"],"tags":["Review","Vision Language Models","Multimodal AI","Vietnamese Language","Educational Assessment","Low-Resource Languages","Cross-Lingual Reasoning","ViExam","Human-in-the-Loop"],"permalink":"/ai/review/2025-8-21-ViExam_Are_Vision_Language_Models_Better_than_Humans_on_Vietnamese_Multimodal_Exam_Questions/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-21-Tinker_Diffusions_Gift_to_3D--Multi-View_Consistent_Editing_From_Sparse_Inputs_without_Per-Scene_Optimization","title":"[논문리뷰] Tinker: Diffusion's Gift to 3D--Multi-View Consistent Editing From Sparse Inputs without Per-Scene Optimization","excerpt":"Hao Chen이 [arXiv]에 게시한 'Tinker: Diffusion's Gift to 3D--Multi-View Consistent Editing From Sparse Inputs without Per-Scene Optimization' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-21 13:15:28+0900","lastModifiedAt":"2025-08-21 13:15:28+0900","categories":["Review"],"tags":["Review","3D Editing","Multi-View Consistency","Diffusion Models","Sparse Input","Zero-Shot Learning","Scene Completion","Gaussian Splatting"],"permalink":"/ai/review/2025-8-21-Tinker_Diffusions_Gift_to_3D--Multi-View_Consistent_Editing_From_Sparse_Inputs_without_Per-Scene_Optimization/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-21-RynnEC_Bringing_MLLMs_into_Embodied_World","title":"[논문리뷰] RynnEC: Bringing MLLMs into Embodied World","excerpt":"jiangpinliu이 [arXiv]에 게시한 'RynnEC: Bringing MLLMs into Embodied World' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-21 13:15:28+0900","lastModifiedAt":"2025-08-21 13:15:28+0900","categories":["Review"],"tags":["Review","Multi-modal Large Language Models","Embodied AI","Embodied Cognition","Video Understanding","Instance Segmentation","Spatial Reasoning","Robotics"],"permalink":"/ai/review/2025-8-21-RynnEC_Bringing_MLLMs_into_Embodied_World/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-21-Refining_Contrastive_Learning_and_Homography_Relations_for_Multi-Modal_Recommendation","title":"[논문리뷰] Refining Contrastive Learning and Homography Relations for Multi-Modal Recommendation","excerpt":"Shiqing Wu이 [arXiv]에 게시한 'Refining Contrastive Learning and Homography Relations for Multi-Modal Recommendation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-21 13:15:28+0900","lastModifiedAt":"2025-08-21 13:15:28+0900","categories":["Review"],"tags":["Review","Multi-modal Recommendation","Contrastive Learning","Graph Neural Network","Homography Relations","Meta-network","Orthogonal Constraint","Data Sparsity"],"permalink":"/ai/review/2025-8-21-Refining_Contrastive_Learning_and_Homography_Relations_for_Multi-Modal_Recommendation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-21-Quantization_Meets_dLLMs_A_Systematic_Study_of_Post-training_Quantization_for_Diffusion_LLMs","title":"[논문리뷰] Quantization Meets dLLMs: A Systematic Study of Post-training Quantization for Diffusion LLMs","excerpt":"Haobo Xu이 [arXiv]에 게시한 'Quantization Meets dLLMs: A Systematic Study of Post-training Quantization for Diffusion LLMs' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-21 13:15:28+0900","lastModifiedAt":"2025-08-21 13:15:28+0900","categories":["Review"],"tags":["Review","Diffusion LLMs","Post-training Quantization (PTQ)","Model Compression","Activation Outliers","Quantization Methods","Efficient Deployment","Large Language Models"],"permalink":"/ai/review/2025-8-21-Quantization_Meets_dLLMs_A_Systematic_Study_of_Post-training_Quantization_for_Diffusion_LLMs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-21-On-Policy_RL_Meets_Off-Policy_Experts_Harmonizing_Supervised_Fine-Tuning_and_Reinforcement_Learning_via_Dynamic_Weighting","title":"[논문리뷰] On-Policy RL Meets Off-Policy Experts: Harmonizing Supervised Fine-Tuning and Reinforcement Learning via Dynamic Weighting","excerpt":"Guoyin Wang이 [arXiv]에 게시한 'On-Policy RL Meets Off-Policy Experts: Harmonizing Supervised Fine-Tuning and Reinforcement Learning via Dynamic Weighting' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-21 13:15:28+0900","lastModifiedAt":"2025-08-21 13:15:28+0900","categories":["Review"],"tags":["Review","Large Language Models","Reinforcement Learning","Supervised Fine-Tuning","On-Policy RL","Off-Policy Experts","Dynamic Weighting","LLM Alignment","Reasoning"],"permalink":"/ai/review/2025-8-21-On-Policy_RL_Meets_Off-Policy_Experts_Harmonizing_Supervised_Fine-Tuning_and_Reinforcement_Learning_via_Dynamic_Weighting/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-21-NVIDIA_Nemotron_Nano_2_An_Accurate_and_Efficient_Hybrid_Mamba-Transformer_Reasoning_Model","title":"[논문리뷰] NVIDIA Nemotron Nano 2: An Accurate and Efficient Hybrid Mamba-Transformer Reasoning Model","excerpt":"abercovich이 [arXiv]에 게시한 'NVIDIA Nemotron Nano 2: An Accurate and Efficient Hybrid Mamba-Transformer Reasoning Model' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-21 13:15:28+0900","lastModifiedAt":"2025-08-21 13:15:28+0900","categories":["Review"],"tags":["Review","Hybrid Architecture","Mamba-Transformer","Reasoning LLM","Model Compression","Knowledge Distillation","Long Context","High Throughput","FP8 Training","Instruction Following"],"permalink":"/ai/review/2025-8-21-NVIDIA_Nemotron_Nano_2_An_Accurate_and_Efficient_Hybrid_Mamba-Transformer_Reasoning_Model/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-21-mSCoRe_a_Multilingual_and_Scalable_Benchmark_for_Skill-based_Commonsense_Reasoning","title":"[논문리뷰] mSCoRe: a Multilingual and Scalable Benchmark for Skill-based Commonsense Reasoning","excerpt":"anoperson이 [arXiv]에 게시한 'mSCoRe: a Multilingual and Scalable Benchmark for Skill-based Commonsense Reasoning' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-21 13:15:28+0900","lastModifiedAt":"2025-08-21 13:15:28+0900","categories":["Review"],"tags":["Review","Multilingual Benchmark","Commonsense Reasoning","LLM Evaluation","Reasoning Taxonomy","Benchmark Scaling","Data Synthesis","Cultural Nuances"],"permalink":"/ai/review/2025-8-21-mSCoRe_a_Multilingual_and_Scalable_Benchmark_for_Skill-based_Commonsense_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-21-MeshCoder_LLM-Powered_Structured_Mesh_Code_Generation_from_Point_Clouds","title":"[논문리뷰] MeshCoder: LLM-Powered Structured Mesh Code Generation from Point Clouds","excerpt":"Jiangmiao이 [arXiv]에 게시한 'MeshCoder: LLM-Powered Structured Mesh Code Generation from Point Clouds' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-21 13:15:28+0900","lastModifiedAt":"2025-08-21 13:15:28+0900","categories":["Review"],"tags":["Review","LLM","Point Clouds","3D Reconstruction","Structured Mesh","Blender Python","Shape Editing","Part-based Representation","Large Language Model"],"permalink":"/ai/review/2025-8-21-MeshCoder_LLM-Powered_Structured_Mesh_Code_Generation_from_Point_Clouds/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-21-MCP-Universe_Benchmarking_Large_Language_Models_with_Real-World_Model_Context_Protocol_Servers","title":"[논문리뷰] MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers","excerpt":"Prathyusha Jwalapuram이 [arXiv]에 게시한 'MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-21 13:15:28+0900","lastModifiedAt":"2025-08-21 13:15:28+0900","categories":["Review"],"tags":["Review","Large Language Models","Benchmarking","Model Context Protocol","Tool Use","Real-World Applications","Agent Evaluation","Long Context","Unknown Tools"],"permalink":"/ai/review/2025-8-21-MCP-Universe_Benchmarking_Large_Language_Models_with_Real-World_Model_Context_Protocol_Servers/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-21-Local_Scale_Equivariance_with_Latent_Deep_Equilibrium_Canonicalizer","title":"[논문리뷰] Local Scale Equivariance with Latent Deep Equilibrium Canonicalizer","excerpt":"Jeremiah Jiang이 [arXiv]에 게시한 'Local Scale Equivariance with Latent Deep Equilibrium Canonicalizer' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-21 13:15:28+0900","lastModifiedAt":"2025-08-21 13:15:28+0900","categories":["Review"],"tags":["Review","Scale Equivariance","Deep Equilibrium Models","Canonicalization","Computer Vision","Image Classification","Semantic Segmentation","Latent Representation","Monotone Scaling"],"permalink":"/ai/review/2025-8-21-Local_Scale_Equivariance_with_Latent_Deep_Equilibrium_Canonicalizer/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-21-Leuvenshtein_Efficient_FHE-based_Edit_Distance_Computation_with_Single_Bootstrap_per_Cell","title":"[논문리뷰] Leuvenshtein: Efficient FHE-based Edit Distance Computation with Single Bootstrap per Cell","excerpt":"Ingrid Verbauwhede이 [arXiv]에 게시한 'Leuvenshtein: Efficient FHE-based Edit Distance Computation with Single Bootstrap per Cell' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-21 13:15:28+0900","lastModifiedAt":"2025-08-21 13:15:28+0900","categories":["Review"],"tags":["Review","Fully Homomorphic Encryption (FHE)","TFHE","Levenshtein Distance","Programmable Bootstrapping (PBS)","Privacy-Preserving Computation","String Similarity"],"permalink":"/ai/review/2025-8-21-Leuvenshtein_Efficient_FHE-based_Edit_Distance_Computation_with_Single_Bootstrap_per_Cell/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-21-FutureX_An_Advanced_Live_Benchmark_for_LLM_Agents_in_Future_Prediction","title":"[논문리뷰] FutureX: An Advanced Live Benchmark for LLM Agents in Future Prediction","excerpt":"tianlecai이 [arXiv]에 게시한 'FutureX: An Advanced Live Benchmark for LLM Agents in Future Prediction' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-21 13:15:28+0900","lastModifiedAt":"2025-08-21 13:15:28+0900","categories":["Review"],"tags":["Review","LLM Agents","Future Prediction","Live Benchmark","Dynamic Evaluation","Data Contamination","Tool Use","Web Search","Financial Forecasting","Misinformation"],"permalink":"/ai/review/2025-8-21-FutureX_An_Advanced_Live_Benchmark_for_LLM_Agents_in_Future_Prediction/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-21-From_Scores_to_Skills_A_Cognitive_Diagnosis_Framework_for_Evaluating_Financial_Large_Language_Models","title":"[논문리뷰] From Scores to Skills: A Cognitive Diagnosis Framework for Evaluating Financial Large Language Models","excerpt":"Ziyan Kuang이 [arXiv]에 게시한 'From Scores to Skills: A Cognitive Diagnosis Framework for Evaluating Financial Large Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-21 13:15:28+0900","lastModifiedAt":"2025-08-21 13:15:28+0900","categories":["Review"],"tags":["Review","Financial LLMs","Cognitive Diagnosis Model","LLM Evaluation","Knowledge Assessment","Matrix Factorization","CPA-QKA","Interpretability"],"permalink":"/ai/review/2025-8-21-From_Scores_to_Skills_A_Cognitive_Diagnosis_Framework_for_Evaluating_Financial_Large_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-21-From_AI_for_Science_to_Agentic_Science_A_Survey_on_Autonomous_Scientific_Discovery","title":"[논문리뷰] From AI for Science to Agentic Science: A Survey on Autonomous Scientific Discovery","excerpt":"zijieqiu이 [arXiv]에 게시한 'From AI for Science to Agentic Science: A Survey on Autonomous Scientific Discovery' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-21 13:15:28+0900","lastModifiedAt":"2025-08-21 13:15:28+0900","categories":["Review"],"tags":["Review","Agentic AI","Autonomous Scientific Discovery","AI for Science","Large Language Models","Multi-agent Systems","Scientific Workflow Automation","Natural Sciences"],"permalink":"/ai/review/2025-8-21-From_AI_for_Science_to_Agentic_Science_A_Survey_on_Autonomous_Scientific_Discovery/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-21-DuPO_Enabling_Reliable_LLM_Self-Verification_via_Dual_Preference_Optimization","title":"[논문리뷰] DuPO: Enabling Reliable LLM Self-Verification via Dual Preference Optimization","excerpt":"Yu Lu이 [arXiv]에 게시한 'DuPO: Enabling Reliable LLM Self-Verification via Dual Preference Optimization' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-21 13:15:28+0900","lastModifiedAt":"2025-08-21 13:15:28+0900","categories":["Review"],"tags":["Review","LLM Optimization","Self-Verification","Dual Learning","Preference Optimization","Self-Supervised Learning","Mathematical Reasoning","Multilingual Translation","RLHF"],"permalink":"/ai/review/2025-8-21-DuPO_Enabling_Reliable_LLM_Self-Verification_via_Dual_Preference_Optimization/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-20-ZARA_Zero-shot_Motion_Time-Series_Analysis_via_Knowledge_and_Retrieval_Driven_LLM_Agents","title":"[논문리뷰] ZARA: Zero-shot Motion Time-Series Analysis via Knowledge and Retrieval Driven LLM Agents","excerpt":"Flora D. Salim이 [arXiv]에 게시한 'ZARA: Zero-shot Motion Time-Series Analysis via Knowledge and Retrieval Driven LLM Agents' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-20 13:26:54+0900","lastModifiedAt":"2025-08-20 13:26:54+0900","categories":["Review"],"tags":["Review","Zero-shot HAR","LLM Agents","Time-Series Analysis","Knowledge Base","Retrieval-Augmented Generation","Multi-sensor Fusion","Interpretability"],"permalink":"/ai/review/2025-8-20-ZARA_Zero-shot_Motion_Time-Series_Analysis_via_Knowledge_and_Retrieval_Driven_LLM_Agents/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-20-Training-Free_Text-Guided_Color_Editing_with_Multi-Modal_Diffusion_Transformer","title":"[논문리뷰] Training-Free Text-Guided Color Editing with Multi-Modal Diffusion Transformer","excerpt":"Deyu Zhou이 [arXiv]에 게시한 'Training-Free Text-Guided Color Editing with Multi-Modal Diffusion Transformer' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-20 13:26:54+0900","lastModifiedAt":"2025-08-20 13:26:54+0900","categories":["Review"],"tags":["Review","Text-Guided Editing","Color Editing","Diffusion Transformers","Training-Free","Multi-Modal AI","Attention Control","Image Manipulation"],"permalink":"/ai/review/2025-8-20-Training-Free_Text-Guided_Color_Editing_with_Multi-Modal_Diffusion_Transformer/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-20-TempFlow-GRPO_When_Timing_Matters_for_GRPO_in_Flow_Models","title":"[논문리뷰] TempFlow-GRPO: When Timing Matters for GRPO in Flow Models","excerpt":"Jian Yang이 [arXiv]에 게시한 'TempFlow-GRPO: When Timing Matters for GRPO in Flow Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-20 13:26:54+0900","lastModifiedAt":"2025-08-20 13:26:54+0900","categories":["Review"],"tags":["Review","Flow Matching","Reinforcement Learning","Human Preference Alignment","GRPO","Temporal Credit Assignment","Generative AI","Text-to-Image"],"permalink":"/ai/review/2025-8-20-TempFlow-GRPO_When_Timing_Matters_for_GRPO_in_Flow_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-20-Semantic_IDs_for_Joint_Generative_Search_and_Recommendation","title":"[논문리뷰] Semantic IDs for Joint Generative Search and Recommendation","excerpt":"Enrico Palumbo이 [arXiv]에 게시한 'Semantic IDs for Joint Generative Search and Recommendation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-20 13:26:54+0900","lastModifiedAt":"2025-08-20 13:26:54+0900","categories":["Review"],"tags":["Review","Generative Models","Search and Recommendation","Semantic IDs","Bi-Encoder","Quantization","Multi-Task Learning","Retrieval Augmented Generation"],"permalink":"/ai/review/2025-8-20-Semantic_IDs_for_Joint_Generative_Search_and_Recommendation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-20-Radiance_Fields_in_XR_A_Survey_on_How_Radiance_Fields_are_Envisioned_and_Addressed_for_XR_Research","title":"[논문리뷰] Radiance Fields in XR: A Survey on How Radiance Fields are Envisioned and Addressed for XR Research","excerpt":"Susanne Schmidt이 [arXiv]에 게시한 'Radiance Fields in XR: A Survey on How Radiance Fields are Envisioned and Addressed for XR Research' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-20 13:26:54+0900","lastModifiedAt":"2025-08-20 13:26:54+0900","categories":["Review"],"tags":["Review","Radiance Fields","XR","NeRF","3D Gaussian Splatting","View Synthesis","Systematic Review","Immersive Technology"],"permalink":"/ai/review/2025-8-20-Radiance_Fields_in_XR_A_Survey_on_How_Radiance_Fields_are_Envisioned_and_Addressed_for_XR_Research/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-20-Prompt_Orchestration_Markup_Language","title":"[논문리뷰] Prompt Orchestration Markup Language","excerpt":"Yuqing Yang이 [arXiv]에 게시한 'Prompt Orchestration Markup Language' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-20 13:26:54+0900","lastModifiedAt":"2025-08-20 13:26:54+0900","categories":["Review"],"tags":["Review","Prompt Engineering","Large Language Models","Markup Language","Structured Prompting","IDE Support","Multimodal Data","Styling System","Development Toolkit"],"permalink":"/ai/review/2025-8-20-Prompt_Orchestration_Markup_Language/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-20-OmniTry_Virtual_Try-On_Anything_without_Masks","title":"[논문리뷰] OmniTry: Virtual Try-On Anything without Masks","excerpt":"Xiaoduan Feng이 [arXiv]에 게시한 'OmniTry: Virtual Try-On Anything without Masks' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-20 13:26:54+0900","lastModifiedAt":"2025-08-20 13:26:54+0900","categories":["Review"],"tags":["Review","Virtual Try-On","Diffusion Model","Mask-Free","Image Inpainting","ID Consistency","Wearable Objects","Generative AI"],"permalink":"/ai/review/2025-8-20-OmniTry_Virtual_Try-On_Anything_without_Masks/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-20-MultiRef_Controllable_Image_Generation_with_Multiple_Visual_References","title":"[논문리뷰] MultiRef: Controllable Image Generation with Multiple Visual References","excerpt":"Shiyun Lang이 [arXiv]에 게시한 'MultiRef: Controllable Image Generation with Multiple Visual References' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-20 13:26:54+0900","lastModifiedAt":"2025-08-20 13:26:54+0900","categories":["Review"],"tags":["Review","Controllable Image Generation","Multi-modal Generation","Visual References","Image-to-Image","Benchmark","Dataset","MLLM-as-a-Judge"],"permalink":"/ai/review/2025-8-20-MultiRef_Controllable_Image_Generation_with_Multiple_Visual_References/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-20-Motion2Motion_Cross-topology_Motion_Transfer_with_Sparse_Correspondence","title":"[논문리뷰] Motion2Motion: Cross-topology Motion Transfer with Sparse Correspondence","excerpt":"Xin Chen이 [arXiv]에 게시한 'Motion2Motion: Cross-topology Motion Transfer with Sparse Correspondence' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-20 13:26:54+0900","lastModifiedAt":"2025-08-20 13:26:54+0900","categories":["Review"],"tags":["Review","Motion Transfer","Cross-topology","Sparse Correspondence","Motion Matching","Animation","Training-free","Few-shot Learning"],"permalink":"/ai/review/2025-8-20-Motion2Motion_Cross-topology_Motion_Transfer_with_Sparse_Correspondence/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-20-MMAU-Pro_A_Challenging_and_Comprehensive_Benchmark_for_Holistic_Evaluation_of_Audio_General_Intelligence","title":"[논문리뷰] MMAU-Pro: A Challenging and Comprehensive Benchmark for Holistic Evaluation of Audio General Intelligence","excerpt":"Fernando López이 [arXiv]에 게시한 'MMAU-Pro: A Challenging and Comprehensive Benchmark for Holistic Evaluation of Audio General Intelligence' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-20 13:26:54+0900","lastModifiedAt":"2025-08-20 13:26:54+0900","categories":["Review"],"tags":["Review","Audio Intelligence","Multimodal AI","Benchmark","Audio-Language Models","Holistic Evaluation","Reasoning","Long-Form Audio","Multicultural Music"],"permalink":"/ai/review/2025-8-20-MMAU-Pro_A_Challenging_and_Comprehensive_Benchmark_for_Holistic_Evaluation_of_Audio_General_Intelligence/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-20-MM-BrowseComp_A_Comprehensive_Benchmark_for_Multimodal_Browsing_Agents","title":"[논문리뷰] MM-BrowseComp: A Comprehensive Benchmark for Multimodal Browsing Agents","excerpt":"Jun Dong이 [arXiv]에 게시한 'MM-BrowseComp: A Comprehensive Benchmark for Multimodal Browsing Agents' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-20 13:26:54+0900","lastModifiedAt":"2025-08-20 13:26:54+0900","categories":["Review"],"tags":["Review","Multimodal Browsing","AI Agents","Benchmark","Vision-Language Models","Reasoning","Tool Use","Deep Search"],"permalink":"/ai/review/2025-8-20-MM-BrowseComp_A_Comprehensive_Benchmark_for_Multimodal_Browsing_Agents/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-20-Mind_the_Generation_Process_Fine-Grained_Confidence_Estimation_During_LLM_Generation","title":"[논문리뷰] Mind the Generation Process: Fine-Grained Confidence Estimation During LLM Generation","excerpt":"Xinyi Wang이 [arXiv]에 게시한 'Mind the Generation Process: Fine-Grained Confidence Estimation During LLM Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-20 13:26:54+0900","lastModifiedAt":"2025-08-20 13:26:54+0900","categories":["Review"],"tags":["Review","LLMs","Confidence Estimation","Fine-Grained","Generation Process","Calibration","Monte Carlo Sampling","Backward Confidence Integration"],"permalink":"/ai/review/2025-8-20-Mind_the_Generation_Process_Fine-Grained_Confidence_Estimation_During_LLM_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-20-MedSAMix_A_Training-Free_Model_Merging_Approach_for_Medical_Image_Segmentation","title":"[논문리뷰] MedSAMix: A Training-Free Model Merging Approach for Medical Image Segmentation","excerpt":"Jonas Geiping이 [arXiv]에 게시한 'MedSAMix: A Training-Free Model Merging Approach for Medical Image Segmentation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-20 13:26:54+0900","lastModifiedAt":"2025-08-20 13:26:54+0900","categories":["Review"],"tags":["Review","Medical Image Segmentation","Model Merging","Training-Free","SAM","Generalization","Zero-Order Optimization","Bayesian Optimization"],"permalink":"/ai/review/2025-8-20-MedSAMix_A_Training-Free_Model_Merging_Approach_for_Medical_Image_Segmentation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-20-LongSplat_Robust_Unposed_3D_Gaussian_Splatting_for_Casual_Long_Videos","title":"[논문리뷰] LongSplat: Robust Unposed 3D Gaussian Splatting for Casual Long Videos","excerpt":"Yen-Yu Lin이 [arXiv]에 게시한 'LongSplat: Robust Unposed 3D Gaussian Splatting for Casual Long Videos' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-20 13:26:54+0900","lastModifiedAt":"2025-08-20 13:26:54+0900","categories":["Review"],"tags":["Review","Novel View Synthesis","3D Gaussian Splatting","Unposed Reconstruction","Camera Pose Estimation","Incremental Optimization","Octree","Long Videos"],"permalink":"/ai/review/2025-8-20-LongSplat_Robust_Unposed_3D_Gaussian_Splatting_for_Casual_Long_Videos/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-20-Leveraging_Large_Language_Models_for_Predictive_Analysis_of_Human_Misery","title":"[논문리뷰] Leveraging Large Language Models for Predictive Analysis of Human Misery","excerpt":"Abhilash Nandy이 [arXiv]에 게시한 'Leveraging Large Language Models for Predictive Analysis of Human Misery' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-20 13:26:54+0900","lastModifiedAt":"2025-08-20 13:26:54+0900","categories":["Review"],"tags":["Review","Large Language Models (LLMs)","Affective Computing","Misery Score Prediction","Prompt Engineering","Few-shot Learning","Gamified Evaluation","Feedback-driven Adaptation"],"permalink":"/ai/review/2025-8-20-Leveraging_Large_Language_Models_for_Predictive_Analysis_of_Human_Misery/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-20-Evaluating_Podcast_Recommendations_with_Profile-Aware_LLM-as-a-Judge","title":"[논문리뷰] Evaluating Podcast Recommendations with Profile-Aware LLM-as-a-Judge","excerpt":"Alice Wang이 [arXiv]에 게시한 'Evaluating Podcast Recommendations with Profile-Aware LLM-as-a-Judge' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-20 13:26:54+0900","lastModifiedAt":"2025-08-20 13:26:54+0900","categories":["Review"],"tags":["Review","Podcast Recommendation","LLM-as-a-Judge","Offline Evaluation","User Profiling","Recommender Systems","Natural Language Processing"],"permalink":"/ai/review/2025-8-20-Evaluating_Podcast_Recommendations_with_Profile-Aware_LLM-as-a-Judge/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-20-Embodied-R1_Reinforced_Embodied_Reasoning_for_General_Robotic_Manipulation","title":"[논문리뷰] Embodied-R1: Reinforced Embodied Reasoning for General Robotic Manipulation","excerpt":"Fei Ni이 [arXiv]에 게시한 'Embodied-R1: Reinforced Embodied Reasoning for General Robotic Manipulation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-20 13:26:54+0900","lastModifiedAt":"2025-08-20 13:26:54+0900","categories":["Review"],"tags":["Review","Embodied AI","Robotic Manipulation","Reinforcement Learning","Vision-Language Model","Pointing","Zero-shot Generalization"],"permalink":"/ai/review/2025-8-20-Embodied-R1_Reinforced_Embodied_Reasoning_for_General_Robotic_Manipulation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-20-Describe_What_You_See_with_Multimodal_Large_Language_Models_to_Enhance_Video_Recommendations","title":"[논문리뷰] Describe What You See with Multimodal Large Language Models to Enhance Video Recommendations","excerpt":"Mounia Lalmas이 [arXiv]에 게시한 'Describe What You See with Multimodal Large Language Models to Enhance Video Recommendations' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-20 13:26:54+0900","lastModifiedAt":"2025-08-20 13:26:54+0900","categories":["Review"],"tags":["Review","Multimodal Large Language Models","Video Recommendation","Zero-Shot Learning","Content-Based Filtering","Natural Language Processing","Foundation Models"],"permalink":"/ai/review/2025-8-20-Describe_What_You_See_with_Multimodal_Large_Language_Models_to_Enhance_Video_Recommendations/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-20-CorrSteer_Steering_Improves_Task_Performance_and_Safety_in_LLMs_through_Correlation-based_Sparse_Autoencoder_Feature_Selection","title":"[논문리뷰] CorrSteer: Steering Improves Task Performance and Safety in LLMs through Correlation-based Sparse Autoencoder Feature Selection","excerpt":"Adriano Koshiyama이 [arXiv]에 게시한 'CorrSteer: Steering Improves Task Performance and Safety in LLMs through Correlation-based Sparse Autoencoder Feature Selection' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-20 13:26:54+0900","lastModifiedAt":"2025-08-20 13:26:54+0900","categories":["Review"],"tags":["Review","Sparse Autoencoders","LLM Steering","Feature Selection","Correlation Analysis","AI Safety","Bias Mitigation","Mechanistic Interpretability"],"permalink":"/ai/review/2025-8-20-CorrSteer_Steering_Improves_Task_Performance_and_Safety_in_LLMs_through_Correlation-based_Sparse_Autoencoder_Feature_Selection/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-20-Copyright_Protection_for_Large_Language_Models_A_Survey_of_Methods_Challenges_and_Trends","title":"[논문리뷰] Copyright Protection for Large Language Models: A Survey of Methods, Challenges, and Trends","excerpt":"Xixiang Zhao이 [arXiv]에 게시한 'Copyright Protection for Large Language Models: A Survey of Methods, Challenges, and Trends' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-20 13:26:54+0900","lastModifiedAt":"2025-08-20 13:26:54+0900","categories":["Review"],"tags":["Review","LLM Copyright Protection","Model Fingerprinting","Text Watermarking","Invasive Fingerprinting","Intrinsic Fingerprinting","Intellectual Property","Digital Rights Management","Backdoor Watermarking"],"permalink":"/ai/review/2025-8-20-Copyright_Protection_for_Large_Language_Models_A_Survey_of_Methods_Challenges_and_Trends/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-20-Chain-of-Agents_End-to-End_Agent_Foundation_Models_via_Multi-Agent_Distillation_and_Agentic_RL","title":"[논문리뷰] Chain-of-Agents: End-to-End Agent Foundation Models via Multi-Agent Distillation and Agentic RL","excerpt":"Liam-Liu이 [arXiv]에 게시한 'Chain-of-Agents: End-to-End Agent Foundation Models via Multi-Agent Distillation and Agentic RL' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-20 13:26:54+0900","lastModifiedAt":"2025-08-20 13:26:54+0900","categories":["Review"],"tags":["Review","Chain-of-Agents","Agent Foundation Models","Multi-Agent Systems","Tool-Integrated Reasoning","Multi-agent Distillation","Agentic Reinforcement Learning","LLMs","End-to-End Learning"],"permalink":"/ai/review/2025-8-20-Chain-of-Agents_End-to-End_Agent_Foundation_Models_via_Multi-Agent_Distillation_and_Agentic_RL/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-20-CAMAR_Continuous_Actions_Multi-Agent_Routing","title":"[논문리뷰] CAMAR: Continuous Actions Multi-Agent Routing","excerpt":"Alexey Skrynnik이 [arXiv]에 게시한 'CAMAR: Continuous Actions Multi-Agent Routing' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-20 13:26:54+0900","lastModifiedAt":"2025-08-20 13:26:54+0900","categories":["Review"],"tags":["Review","Multi-Agent Reinforcement Learning","Continuous Control","Pathfinding","MARL Benchmark","GPU Acceleration","Robotics Simulation","Scalability","Heterogeneous Agents"],"permalink":"/ai/review/2025-8-20-CAMAR_Continuous_Actions_Multi-Agent_Routing/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-20-Beyond_Human_Judgment_A_Bayesian_Evaluation_of_LLMs_Moral_Values_Understanding","title":"[논문리뷰] Beyond Human Judgment: A Bayesian Evaluation of LLMs' Moral Values Understanding","excerpt":"Alina Landowska이 [arXiv]에 게시한 'Beyond Human Judgment: A Bayesian Evaluation of LLMs' Moral Values Understanding' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-20 13:26:54+0900","lastModifiedAt":"2025-08-20 13:26:54+0900","categories":["Review"],"tags":["Review","Large Language Models","Moral Reasoning","Bayesian Evaluation","Uncertainty Quantification","Natural Language Processing","Soft Labels"],"permalink":"/ai/review/2025-8-20-Beyond_Human_Judgment_A_Bayesian_Evaluation_of_LLMs_Moral_Values_Understanding/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-20-A_Stitch_in_Time_Saves_Nine_Proactive_Self-Refinement_for_Language_Models","title":"[논문리뷰] A Stitch in Time Saves Nine: Proactive Self-Refinement for Language Models","excerpt":"Zishang Jiang이 [arXiv]에 게시한 'A Stitch in Time Saves Nine: Proactive Self-Refinement for Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-20 13:26:54+0900","lastModifiedAt":"2025-08-20 13:26:54+0900","categories":["Review"],"tags":["Review","Self-Refinement","Language Models","Reinforcement Learning","Proactive AI","Generation Process","Markov Decision Process","Adaptive Learning","LLM Efficiency"],"permalink":"/ai/review/2025-8-20-A_Stitch_in_Time_Saves_Nine_Proactive_Self-Refinement_for_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-20-Advances_in_Speech_Separation_Techniques_Challenges_and_Future_Trends","title":"[논문리뷰] Advances in Speech Separation: Techniques, Challenges, and Future Trends","excerpt":"Zhuo Chen이 [arXiv]에 게시한 'Advances in Speech Separation: Techniques, Challenges, and Future Trends' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-20 13:26:54+0900","lastModifiedAt":"2025-08-20 13:26:54+0900","categories":["Review"],"tags":["Review","Speech Separation","Deep Neural Networks","Cocktail Party Problem","Transformer Architecture","Unsupervised Learning","Supervised Learning","Evaluation Metrics","Datasets"],"permalink":"/ai/review/2025-8-20-Advances_in_Speech_Separation_Techniques_Challenges_and_Future_Trends/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-19-When_Punctuation_Matters_A_Large-Scale_Comparison_of_Prompt_Robustness_Methods_for_LLMs","title":"[논문리뷰] When Punctuation Matters: A Large-Scale Comparison of Prompt Robustness Methods for LLMs","excerpt":"Elena Tutubalina이 [arXiv]에 게시한 'When Punctuation Matters: A Large-Scale Comparison of Prompt Robustness Methods for LLMs' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-19 13:15:01+0900","lastModifiedAt":"2025-08-19 13:15:01+0900","categories":["Review"],"tags":["Review","LLM Robustness","Prompt Sensitivity","In-Context Learning","Fine-Tuning","Batch Calibration","Template Ensembles","Distribution Shift"],"permalink":"/ai/review/2025-8-19-When_Punctuation_Matters_A_Large-Scale_Comparison_of_Prompt_Robustness_Methods_for_LLMs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-19-Speed_Always_Wins_A_Survey_on_Efficient_Architectures_for_Large_Language_Models","title":"[논문리뷰] Speed Always Wins: A Survey on Efficient Architectures for Large Language Models","excerpt":"Jusen Du이 [arXiv]에 게시한 'Speed Always Wins: A Survey on Efficient Architectures for Large Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-19 13:15:01+0900","lastModifiedAt":"2025-08-19 13:15:01+0900","categories":["Review"],"tags":["Review","Large Language Models","Efficient Architectures","Transformer Optimization","Linear Attention","State Space Models","Mixture-of-Experts","Sparse Attention","Diffusion LLMs"],"permalink":"/ai/review/2025-8-19-Speed_Always_Wins_A_Survey_on_Efficient_Architectures_for_Large_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-19-S2-Guidance_Stochastic_Self_Guidance_for_Training-Free_Enhancement_of_Diffusion_Models","title":"[논문리뷰] S^2-Guidance: Stochastic Self Guidance for Training-Free Enhancement of Diffusion Models","excerpt":"Meiqi Wu이 [arXiv]에 게시한 'S^2-Guidance: Stochastic Self Guidance for Training-Free Enhancement of Diffusion Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-19 13:15:01+0900","lastModifiedAt":"2025-08-19 13:15:01+0900","categories":["Review"],"tags":["Review","Diffusion Models","Classifier-free Guidance","Self-Guidance","Training-Free","Stochastic Block-Dropping","Generative Models","Text-to-Image"],"permalink":"/ai/review/2025-8-19-S2-Guidance_Stochastic_Self_Guidance_for_Training-Free_Enhancement_of_Diffusion_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-19-Representing_Speech_Through_Autoregressive_Prediction_of_Cochlear_Tokens","title":"[논문리뷰] Representing Speech Through Autoregressive Prediction of Cochlear Tokens","excerpt":"Daniel L. K. Yamins이 [arXiv]에 게시한 'Representing Speech Through Autoregressive Prediction of Cochlear Tokens' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-19 13:15:01+0900","lastModifiedAt":"2025-08-19 13:15:01+0900","categories":["Review"],"tags":["Review","Speech Representation Learning","Autoregressive Models","Cochlear Tokens","Biologically Inspired AI","Self-Supervised Learning","Audio Processing","Transformer Networks"],"permalink":"/ai/review/2025-8-19-Representing_Speech_Through_Autoregressive_Prediction_of_Cochlear_Tokens/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-19-Reinforcement_Learning_with_Rubric_Anchors","title":"[논문리뷰] Reinforcement Learning with Rubric Anchors","excerpt":"Haokai Xu이 [arXiv]에 게시한 'Reinforcement Learning with Rubric Anchors' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-19 13:15:01+0900","lastModifiedAt":"2025-08-19 13:15:01+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","Large Language Models","Rubric-based Reward","RLVR Extension","Human-centric AI","Controllable Generation","Reward Hacking Mitigation"],"permalink":"/ai/review/2025-8-19-Reinforcement_Learning_with_Rubric_Anchors/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-19-Precise_Action-to-Video_Generation_Through_Visual_Action_Prompts","title":"[논문리뷰] Precise Action-to-Video Generation Through Visual Action Prompts","excerpt":"Minghan Qin이 [arXiv]에 게시한 'Precise Action-to-Video Generation Through Visual Action Prompts' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-19 13:15:01+0900","lastModifiedAt":"2025-08-19 13:15:01+0900","categories":["Review"],"tags":["Review","Action-to-Video Generation","Visual Action Prompts","Skeleton Representation","Human-Object Interaction","Robotic Manipulation","Cross-Domain Transfer","Diffusion Models"],"permalink":"/ai/review/2025-8-19-Precise_Action-to-Video_Generation_Through_Visual_Action_Prompts/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-19-Ovis2.5_Technical_Report","title":"[논문리뷰] Ovis2.5 Technical Report","excerpt":"Yang Li이 [arXiv]에 게시한 'Ovis2.5 Technical Report' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-19 13:15:01+0900","lastModifiedAt":"2025-08-19 13:15:01+0900","categories":["Review"],"tags":["Review","Multimodal LLMs","Native Resolution Vision","Deep Reasoning","Chart Analysis","OCR","Visual Grounding","Training Efficiency","Preference Optimization"],"permalink":"/ai/review/2025-8-19-Ovis2.5_Technical_Report/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-19-Next_Visual_Granularity_Generation","title":"[논문리뷰] Next Visual Granularity Generation","excerpt":"Kang Liao이 [arXiv]에 게시한 'Next Visual Granularity Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-19 13:15:01+0900","lastModifiedAt":"2025-08-19 13:15:01+0900","categories":["Review"],"tags":["Review","Image Generation","Granularity Control","Structured Representation","Hierarchical Generation","Coarse-to-fine","Visual Tokenization","Latent Space"],"permalink":"/ai/review/2025-8-19-Next_Visual_Granularity_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-19-Matrix-Game_2.0_An_Open-Source_Real-Time_and_Streaming_Interactive_World_Model","title":"[논문리뷰] Matrix-Game 2.0: An Open-Source, Real-Time, and Streaming Interactive World Model","excerpt":"Yifan Zhang이 [arXiv]에 게시한 'Matrix-Game 2.0: An Open-Source, Real-Time, and Streaming Interactive World Model' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-19 13:15:01+0900","lastModifiedAt":"2025-08-19 13:15:01+0900","categories":["Review"],"tags":["Review","World Model","Interactive Video Generation","Real-Time AI","Diffusion Models","Auto-Regressive Generation","Data Pipeline","Self-Forcing","KV Caching"],"permalink":"/ai/review/2025-8-19-Matrix-Game_2.0_An_Open-Source_Real-Time_and_Streaming_Interactive_World_Model/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-19-Lumen_Consistent_Video_Relighting_and_Harmonious_Background_Replacement_with_Video_Generative_Models","title":"[논문리뷰] Lumen: Consistent Video Relighting and Harmonious Background Replacement with Video Generative Models","excerpt":"Zixiang Gao이 [arXiv]에 게시한 'Lumen: Consistent Video Relighting and Harmonious Background Replacement with Video Generative Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-19 13:15:01+0900","lastModifiedAt":"2025-08-19 13:15:01+0900","categories":["Review"],"tags":["Review","Video Relighting","Background Replacement","Generative Models","Diffusion Models","Temporal Consistency","Dataset Generation","Video Editing"],"permalink":"/ai/review/2025-8-19-Lumen_Consistent_Video_Relighting_and_Harmonious_Background_Replacement_with_Video_Generative_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-19-Inverse-LLaVA_Eliminating_Alignment_Pre-training_Through_Text-to-Vision_Mapping","title":"[논문리뷰] Inverse-LLaVA: Eliminating Alignment Pre-training Through Text-to-Vision Mapping","excerpt":"Tyler Derr이 [arXiv]에 게시한 'Inverse-LLaVA: Eliminating Alignment Pre-training Through Text-to-Vision Mapping' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-19 13:15:01+0900","lastModifiedAt":"2025-08-19 13:15:01+0900","categories":["Review"],"tags":["Review","Multimodal Learning","Vision-Language Models","Alignment Pre-training","Text-to-Vision Mapping","Continuous Representations","Computational Efficiency","LLM"],"permalink":"/ai/review/2025-8-19-Inverse-LLaVA_Eliminating_Alignment_Pre-training_Through_Text-to-Vision_Mapping/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-19-HeroBench_A_Benchmark_for_Long-Horizon_Planning_and_Structured_Reasoning_in_Virtual_Worlds","title":"[논문리뷰] HeroBench: A Benchmark for Long-Horizon Planning and Structured Reasoning in Virtual Worlds","excerpt":"Artyom Sorokin이 [arXiv]에 게시한 'HeroBench: A Benchmark for Long-Horizon Planning and Structured Reasoning in Virtual Worlds' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-19 13:15:01+0900","lastModifiedAt":"2025-08-19 13:15:01+0900","categories":["Review"],"tags":["Review","Long-Horizon Planning","Structured Reasoning","LLM Evaluation","Virtual Worlds","RPG","Benchmark","Agent Systems","Combat Simulation"],"permalink":"/ai/review/2025-8-19-HeroBench_A_Benchmark_for_Long-Horizon_Planning_and_Structured_Reasoning_in_Virtual_Worlds/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-19-Has_GPT-5_Achieved_Spatial_Intelligence_An_Empirical_Study","title":"[논문리뷰] Has GPT-5 Achieved Spatial Intelligence? An Empirical Study","excerpt":"Ruisi Wang이 [arXiv]에 게시한 'Has GPT-5 Achieved Spatial Intelligence? An Empirical Study' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-19 13:15:01+0900","lastModifiedAt":"2025-08-19 13:15:01+0900","categories":["Review"],"tags":["Review","Spatial Intelligence","Multimodal LLMs","Benchmark Evaluation","GPT-5","Cognitive AI","AGI"],"permalink":"/ai/review/2025-8-19-Has_GPT-5_Achieved_Spatial_Intelligence_An_Empirical_Study/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-19-G-CUT3R_Guided_3D_Reconstruction_with_Camera_and_Depth_Prior_Integration","title":"[논문리뷰] G-CUT3R: Guided 3D Reconstruction with Camera and Depth Prior Integration","excerpt":"Evgeny Burnaev이 [arXiv]에 게시한 'G-CUT3R: Guided 3D Reconstruction with Camera and Depth Prior Integration' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-19 13:15:01+0900","lastModifiedAt":"2025-08-19 13:15:01+0900","categories":["Review"],"tags":["Review","3D Reconstruction","Deep Learning","Multi-Modal Fusion","Camera Pose Estimation","Depth Estimation","Transformer Networks","Prior Information"],"permalink":"/ai/review/2025-8-19-G-CUT3R_Guided_3D_Reconstruction_with_Camera_and_Depth_Prior_Integration/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-19-ComoRAG_A_Cognitive-Inspired_Memory-Organized_RAG_for_Stateful_Long_Narrative_Reasoning","title":"[논문리뷰] ComoRAG: A Cognitive-Inspired Memory-Organized RAG for Stateful Long Narrative Reasoning","excerpt":"Yufeng Wang이 [arXiv]에 게시한 'ComoRAG: A Cognitive-Inspired Memory-Organized RAG for Stateful Long Narrative Reasoning' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-19 13:15:01+0900","lastModifiedAt":"2025-08-19 13:15:01+0900","categories":["Review"],"tags":["Review","Cognitive-Inspired RAG","Stateful Reasoning","Long Narrative Comprehension","Dynamic Memory","Metacognitive Regulation","Multi-step Retrieval","Hierarchical Knowledge Source"],"permalink":"/ai/review/2025-8-19-ComoRAG_A_Cognitive-Inspired_Memory-Organized_RAG_for_Stateful_Long_Narrative_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-19-Beyond_Solving_Math_Quiz_Evaluating_the_Ability_of_Large_Reasoning_Models_to_Ask_for_Information","title":"[논문리뷰] Beyond Solving Math Quiz: Evaluating the Ability of Large Reasoning Models to Ask for Information","excerpt":"Xi Yang이 [arXiv]에 게시한 'Beyond Solving Math Quiz: Evaluating the Ability of Large Reasoning Models to Ask for Information' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-19 13:15:01+0900","lastModifiedAt":"2025-08-19 13:15:01+0900","categories":["Review"],"tags":["Review","Large Reasoning Models (LRMs)","Information Seeking","Incomplete Problems","Mathematical Reasoning","Supervised Fine-tuning (SFT)","Overthinking","Hallucination","CRITIC-math"],"permalink":"/ai/review/2025-8-19-Beyond_Solving_Math_Quiz_Evaluating_the_Ability_of_Large_Reasoning_Models_to_Ask_for_Information/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-19-4DNeX_Feed-Forward_4D_Generative_Modeling_Made_Easy","title":"[논문리뷰] 4DNeX: Feed-Forward 4D Generative Modeling Made Easy","excerpt":"Zeng Tao이 [arXiv]에 게시한 '4DNeX: Feed-Forward 4D Generative Modeling Made Easy' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-19 13:15:01+0900","lastModifiedAt":"2025-08-19 13:15:01+0900","categories":["Review"],"tags":["Review","4D Generation","Dynamic 3D","Generative Models","Diffusion Models","Single Image Input","Video Synthesis","Point Clouds","Dataset"],"permalink":"/ai/review/2025-8-19-4DNeX_Feed-Forward_4D_Generative_Modeling_Made_Easy/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-18-X-Node_Self-Explanation_is_All_We_Need","title":"[논문리뷰] X-Node: Self-Explanation is All We Need","excerpt":"Islem Rekik이 [arXiv]에 게시한 'X-Node: Self-Explanation is All We Need' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-18 13:14:38+0900","lastModifiedAt":"2025-08-18 13:14:38+0900","categories":["Review"],"tags":["Review","Graph Neural Networks","Explainable AI","Self-Explanation","Node Classification","Medical Imaging","Natural Language Processing","Interpretability"],"permalink":"/ai/review/2025-8-18-X-Node_Self-Explanation_is_All_We_Need/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-18-Thyme_Think_Beyond_Images","title":"[논문리뷰] Thyme: Think Beyond Images","excerpt":"Wei Chen이 [arXiv]에 게시한 'Thyme: Think Beyond Images' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-18 13:14:38+0900","lastModifiedAt":"2025-08-18 13:14:38+0900","categories":["Review"],"tags":["Review","Multimodal LLMs","Code Generation","Image Processing","Reinforcement Learning","Supervised Fine-Tuning","Visual Reasoning","Sandbox"],"permalink":"/ai/review/2025-8-18-Thyme_Think_Beyond_Images/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-18-TexVerse_A_Universe_of_3D_Objects_with_High-Resolution_Textures","title":"[논문리뷰] TexVerse: A Universe of 3D Objects with High-Resolution Textures","excerpt":"Nan Cao이 [arXiv]에 게시한 'TexVerse: A Universe of 3D Objects with High-Resolution Textures' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-18 13:14:38+0900","lastModifiedAt":"2025-08-18 13:14:38+0900","categories":["Review"],"tags":["Review","3D Dataset","High-Resolution Textures","Physically Based Rendering (PBR)","3D Animation","Data Curation","GPT-5 Annotations","Sketchfab"],"permalink":"/ai/review/2025-8-18-TexVerse_A_Universe_of_3D_Objects_with_High-Resolution_Textures/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-18-StyleMM_Stylized_3D_Morphable_Face_Model_via_Text-Driven_Aligned_Image_Translation","title":"[논문리뷰] StyleMM: Stylized 3D Morphable Face Model via Text-Driven Aligned Image Translation","excerpt":"Junyong Noh이 [arXiv]에 게시한 'StyleMM: Stylized 3D Morphable Face Model via Text-Driven Aligned Image Translation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-18 13:14:38+0900","lastModifiedAt":"2025-08-18 13:14:38+0900","categories":["Review"],"tags":["Review","3D Morphable Model","Face Stylization","Text-to-Image Translation","Diffusion Model","Attribute Preservation","Generative AI","Computer Graphics"],"permalink":"/ai/review/2025-8-18-StyleMM_Stylized_3D_Morphable_Face_Model_via_Text-Driven_Aligned_Image_Translation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-18-SSRL_Self-Search_Reinforcement_Learning","title":"[논문리뷰] SSRL: Self-Search Reinforcement Learning","excerpt":"Yanxu Chen이 [arXiv]에 게시한 'SSRL: Self-Search Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-18 13:14:38+0900","lastModifiedAt":"2025-08-18 13:14:38+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","Large Language Models","Self-Search","Sim-to-Real Transfer","Agentic AI","Knowledge Retrieval","Reward Modeling"],"permalink":"/ai/review/2025-8-18-SSRL_Self-Search_Reinforcement_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-18-SPARSE_Data_Rich_Results_Few-Shot_Semi-Supervised_Learning_via_Class-Conditioned_Image_Translation","title":"[논문리뷰] SPARSE Data, Rich Results: Few-Shot Semi-Supervised Learning via Class-Conditioned Image Translation","excerpt":"Paolo Soda이 [arXiv]에 게시한 'SPARSE Data, Rich Results: Few-Shot Semi-Supervised Learning via Class-Conditioned Image Translation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-18 13:14:38+0900","lastModifiedAt":"2025-08-18 13:14:38+0900","categories":["Review"],"tags":["Review","Semi-supervised Learning","Few-shot Learning","Medical Imaging","GAN-based Methods","Image-to-image Translation","Pseudo-labeling","Ensemble Learning"],"permalink":"/ai/review/2025-8-18-SPARSE_Data_Rich_Results_Few-Shot_Semi-Supervised_Learning_via_Class-Conditioned_Image_Translation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-18-PaperRegister_Boosting_Flexible-grained_Paper_Search_via_Hierarchical_Register_Indexing","title":"[논문리뷰] PaperRegister: Boosting Flexible-grained Paper Search via Hierarchical Register Indexing","excerpt":"Xianpei Han이 [arXiv]에 게시한 'PaperRegister: Boosting Flexible-grained Paper Search via Hierarchical Register Indexing' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-18 13:14:38+0900","lastModifiedAt":"2025-08-18 13:14:38+0900","categories":["Review"],"tags":["Review","논문 검색","계층적 인덱싱","유연한 검색","대규모 언어 모델","정보 추출","뷰 인식","강화 학습"],"permalink":"/ai/review/2025-8-18-PaperRegister_Boosting_Flexible-grained_Paper_Search_via_Hierarchical_Register_Indexing/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-18-MAESTRO_Masked_AutoEncoders_for_Multimodal_Multitemporal_and_Multispectral_Earth_Observation_Data","title":"[논문리뷰] MAESTRO: Masked AutoEncoders for Multimodal, Multitemporal, and Multispectral Earth Observation Data","excerpt":"Nicolas Gonthier이 [arXiv]에 게시한 'MAESTRO: Masked AutoEncoders for Multimodal, Multitemporal, and Multispectral Earth Observation Data' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-18 13:14:38+0900","lastModifiedAt":"2025-08-18 13:14:38+0900","categories":["Review"],"tags":["Review","Self-supervised Learning","Masked Autoencoder","Earth Observation","Multimodal","Multitemporal","Multispectral","Fusion Strategies","Target Normalization"],"permalink":"/ai/review/2025-8-18-MAESTRO_Masked_AutoEncoders_for_Multimodal_Multitemporal_and_Multispectral_Earth_Observation_Data/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-18-FantasyTalking2_Timestep-Layer_Adaptive_Preference_Optimization_for_Audio-Driven_Portrait_Animation","title":"[논문리뷰] FantasyTalking2: Timestep-Layer Adaptive Preference Optimization for Audio-Driven Portrait Animation","excerpt":"Mu Xu이 [arXiv]에 게시한 'FantasyTalking2: Timestep-Layer Adaptive Preference Optimization for Audio-Driven Portrait Animation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-18 13:14:38+0900","lastModifiedAt":"2025-08-18 13:14:38+0900","categories":["Review"],"tags":["Review","Audio-Driven Animation","Preference Optimization","Diffusion Models","Reward Modeling","Human Feedback","Multi-Objective Optimization","Timestep-Layer Adaptive"],"permalink":"/ai/review/2025-8-18-FantasyTalking2_Timestep-Layer_Adaptive_Preference_Optimization_for_Audio-Driven_Portrait_Animation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-18-DINOv3","title":"[논문리뷰] DINOv3","excerpt":"Maxime Oquab이 [arXiv]에 게시한 'DINOv3' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-18 13:14:38+0900","lastModifiedAt":"2025-08-18 13:14:38+0900","categories":["Review"],"tags":["Review","Self-supervised Learning","Foundation Models","Vision Transformer","Dense Feature Maps","Gram Anchoring","Model Distillation","Geospatial AI"],"permalink":"/ai/review/2025-8-18-DINOv3/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-18-Controlling_Multimodal_LLMs_via_Reward-guided_Decoding","title":"[논문리뷰] Controlling Multimodal LLMs via Reward-guided Decoding","excerpt":"Michal Drozdzal이 [arXiv]에 게시한 'Controlling Multimodal LLMs via Reward-guided Decoding' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-18 13:14:38+0900","lastModifiedAt":"2025-08-18 13:14:38+0900","categories":["Review"],"tags":["Review","Multimodal LLMs","Reward Models","Guided Decoding","Visual Grounding","Hallucination Mitigation","Object Precision","Object Recall","Inference-time Control"],"permalink":"/ai/review/2025-8-18-Controlling_Multimodal_LLMs_via_Reward-guided_Decoding/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-15-We-Math_2.0_A_Versatile_MathBook_System_for_Incentivizing_Visual_Mathematical_Reasoning","title":"[논문리뷰] We-Math 2.0: A Versatile MathBook System for Incentivizing Visual Mathematical Reasoning","excerpt":"Xiaowan Wang이 [arXiv]에 게시한 'We-Math 2.0: A Versatile MathBook System for Incentivizing Visual Mathematical Reasoning' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-15 13:09:31+0900","lastModifiedAt":"2025-08-15 13:09:31+0900","categories":["Review"],"tags":["Review","Visual Mathematical Reasoning","MLLMs","Knowledge System","Reinforcement Learning","Curriculum Learning","Dataset Construction","Mathematical Benchmark"],"permalink":"/ai/review/2025-8-15-We-Math_2.0_A_Versatile_MathBook_System_for_Incentivizing_Visual_Mathematical_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-15-UI-Venus_Technical_Report_Building_High-performance_UI_Agents_with_RFT","title":"[논문리뷰] UI-Venus Technical Report: Building High-performance UI Agents with RFT","excerpt":"Shuheng Shen이 [arXiv]에 게시한 'UI-Venus Technical Report: Building High-performance UI Agents with RFT' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-15 13:09:31+0900","lastModifiedAt":"2025-08-15 13:09:31+0900","categories":["Review"],"tags":["Review","UI Agent","MLLM","RFT","UI Grounding","UI Navigation","GRPO","Data Cleaning","Self-Evolving Trajectory"],"permalink":"/ai/review/2025-8-15-UI-Venus_Technical_Report_Building_High-performance_UI_Agents_with_RFT/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-15-ToonComposer_Streamlining_Cartoon_Production_with_Generative_Post-Keyframing","title":"[논문리뷰] ToonComposer: Streamlining Cartoon Production with Generative Post-Keyframing","excerpt":"Xiaoyu Li이 [arXiv]에 게시한 'ToonComposer: Streamlining Cartoon Production with Generative Post-Keyframing' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-15 13:09:31+0900","lastModifiedAt":"2025-08-15 13:09:31+0900","categories":["Review"],"tags":["Review","Cartoon Generation","Video Diffusion Models","DiT","Post-Keyframing","Low-Rank Adaptation","Sparse Control","Generative AI","Animation"],"permalink":"/ai/review/2025-8-15-ToonComposer_Streamlining_Cartoon_Production_with_Generative_Post-Keyframing/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-15-STream3R_Scalable_Sequential_3D_Reconstruction_with_Causal_Transformer","title":"[논문리뷰] STream3R: Scalable Sequential 3D Reconstruction with Causal Transformer","excerpt":"Honghua Chen이 [arXiv]에 게시한 'STream3R: Scalable Sequential 3D Reconstruction with Causal Transformer' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-15 13:09:31+0900","lastModifiedAt":"2025-08-15 13:09:31+0900","categories":["Review"],"tags":["Review","3D Reconstruction","Causal Transformer","Sequential Modeling","Streaming Data","Pointmap Prediction","Online Perception","KVCache"],"permalink":"/ai/review/2025-8-15-STream3R_Scalable_Sequential_3D_Reconstruction_with_Causal_Transformer/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-15-Processing_and_acquisition_traces_in_visual_encoders_What_does_CLIP_know_about_your_camera","title":"[논문리뷰] Processing and acquisition traces in visual encoders: What does CLIP know about your camera?","excerpt":"Giorgos Tolias이 [arXiv]에 게시한 'Processing and acquisition traces in visual encoders: What does CLIP know about your camera?' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-15 13:09:31+0900","lastModifiedAt":"2025-08-15 13:09:31+0900","categories":["Review"],"tags":["Review","Visual Encoders","Metadata","Image Processing","Image Acquisition","Robustness","CLIP","Foundation Models","Distribution Shift"],"permalink":"/ai/review/2025-8-15-Processing_and_acquisition_traces_in_visual_encoders_What_does_CLIP_know_about_your_camera/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-15-PRELUDE_A_Benchmark_Designed_to_Require_Global_Comprehension_and_Reasoning_over_Long_Contexts","title":"[논문리뷰] PRELUDE: A Benchmark Designed to Require Global Comprehension and Reasoning over Long Contexts","excerpt":"Rui Lu이 [arXiv]에 게시한 'PRELUDE: A Benchmark Designed to Require Global Comprehension and Reasoning over Long Contexts' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-15 13:09:31+0900","lastModifiedAt":"2025-08-15 13:09:31+0900","categories":["Review"],"tags":["Review","Long-Context Understanding","Reasoning Benchmark","LLMs Evaluation","Natural Language Processing","Global Comprehension","Fluid Intelligence","Prequel Entailment","RAG"],"permalink":"/ai/review/2025-8-15-PRELUDE_A_Benchmark_Designed_to_Require_Global_Comprehension_and_Reasoning_over_Long_Contexts/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-15-Passk_Training_for_Adaptively_Balancing_Exploration_and_Exploitation_of_Large_Reasoning_Models","title":"[논문리뷰] Pass@k Training for Adaptively Balancing Exploration and Exploitation of Large Reasoning Models","excerpt":"Qinghao Ye이 [arXiv]에 게시한 'Pass@k Training for Adaptively Balancing Exploration and Exploitation of Large Reasoning Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-15 13:09:31+0900","lastModifiedAt":"2025-08-15 13:09:31+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","Large Language Models","Exploration-Exploitation","Reward Design","Reasoning Tasks","Pass@k","Policy Optimization"],"permalink":"/ai/review/2025-8-15-Passk_Training_for_Adaptively_Balancing_Exploration_and_Exploitation_of_Large_Reasoning_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-15-NextStep-1_Toward_Autoregressive_Image_Generation_with_Continuous_Tokens_at_Scale","title":"[논문리뷰] NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale","excerpt":"Quan Sun이 [arXiv]에 게시한 'NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-15 13:09:31+0900","lastModifiedAt":"2025-08-15 13:09:31+0900","categories":["Review"],"tags":["Review","Autoregressive Models","Text-to-Image Generation","Continuous Latent Tokens","Flow Matching","Image Editing","Multimodal Learning","Transformer Architecture"],"permalink":"/ai/review/2025-8-15-NextStep-1_Toward_Autoregressive_Image_Generation_with_Continuous_Tokens_at_Scale/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-15-HumanSense_From_Multimodal_Perception_to_Empathetic_Context-Aware_Responses_through_Reasoning_MLLMs","title":"[논문리뷰] HumanSense: From Multimodal Perception to Empathetic Context-Aware Responses through Reasoning MLLMs","excerpt":"Yi Yuan이 [arXiv]에 게시한 'HumanSense: From Multimodal Perception to Empathetic Context-Aware Responses through Reasoning MLLMs' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-15 13:09:31+0900","lastModifiedAt":"2025-08-15 13:09:31+0900","categories":["Review"],"tags":["Review","Multimodal LLMs","Human-Centered AI","Empathy","Context-Awareness","MLLM Benchmark","Reinforcement Learning","Reasoning"],"permalink":"/ai/review/2025-8-15-HumanSense_From_Multimodal_Perception_to_Empathetic_Context-Aware_Responses_through_Reasoning_MLLMs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-15-From_Black_Box_to_Transparency_Enhancing_Automated_Interpreting_Assessment_with_Explainable_AI_in_College_Classrooms","title":"[논문리뷰] From Black Box to Transparency: Enhancing Automated Interpreting Assessment with Explainable AI in College Classrooms","excerpt":"Ziyin Zhang이 [arXiv]에 게시한 'From Black Box to Transparency: Enhancing Automated Interpreting Assessment with Explainable AI in College Classrooms' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-15 13:09:31+0900","lastModifiedAt":"2025-08-15 13:09:31+0900","categories":["Review"],"tags":["Review","Automated Interpreting Assessment","Explainable AI","Data Augmentation","Variational Autoencoder","SHAP","Interpreting Quality","Natural Language Processing"],"permalink":"/ai/review/2025-8-15-From_Black_Box_to_Transparency_Enhancing_Automated_Interpreting_Assessment_with_Explainable_AI_in_College_Classrooms/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-15-A_Survey_on_Diffusion_Language_Models","title":"[논문리뷰] A Survey on Diffusion Language Models","excerpt":"Zhiqiang Shen이 [arXiv]에 게시한 'A Survey on Diffusion Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-15 13:09:31+0900","lastModifiedAt":"2025-08-15 13:09:31+0900","categories":["Review"],"tags":["Review","Diffusion Language Models","Generative AI","Parallel Decoding","Text Generation","Multimodal AI","Model Compression","Reinforcement Learning from Human Feedback","Inference Optimization"],"permalink":"/ai/review/2025-8-15-A_Survey_on_Diffusion_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-15-2025-8-15-Explainability_and_Privacy_in_NLP","title":"[논문리뷰] When Explainability Meets Privacy: An Investigation at the Intersection of Post-hoc Explainability and Differential Privacy in the Context of Natural Language Processing","excerpt":"Gjergji Kasneci이 [arXiv]에 게시한 'When Explainability Meets Privacy: An Investigation at the Intersection of Post-hoc Explainability and Differential Privacy in the Context of Natural Language Processing' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-15 13:09:31+0900","lastModifiedAt":"2025-08-15 13:09:31+0900","categories":["Review"],"tags":["Review","Natural Language Processing (NLP)","Explainable AI (XAI)","Post-hoc Explainability","Differential Privacy (DP)","Privacy-Utility Trade-off","Model Faithfulness","Text Privatization"],"permalink":"/ai/review/2025-8-15-2025-8-15-Explainability_and_Privacy_in_NLP/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-14-VisCodex_Unified_Multimodal_Code_Generation_via_Merging_Vision_and_Coding_Models","title":"[논문리뷰] VisCodex: Unified Multimodal Code Generation via Merging Vision and Coding Models","excerpt":"Dongdong Zhang이 [arXiv]에 게시한 'VisCodex: Unified Multimodal Code Generation via Merging Vision and Coding Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-14 13:19:02+0900","lastModifiedAt":"2025-08-14 13:19:02+0900","categories":["Review"],"tags":["Review","Multimodal LLM","Code Generation","Model Merging","Task Vectors","Vision-Language Model","Coding LLM","Instruction Tuning","Benchmark"],"permalink":"/ai/review/2025-8-14-VisCodex_Unified_Multimodal_Code_Generation_via_Merging_Vision_and_Coding_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-14-Story2Board_A_Training-Free_Approach_for_Expressive_Storyboard_Generation","title":"[논문리뷰] Story2Board: A Training-Free Approach for Expressive Storyboard Generation","excerpt":"Dani Lischinski이 [arXiv]에 게시한 'Story2Board: A Training-Free Approach for Expressive Storyboard Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-14 13:19:02+0900","lastModifiedAt":"2025-08-14 13:19:02+0900","categories":["Review"],"tags":["Review","Storyboard Generation","Text-to-Image","Diffusion Models","Training-Free","Character Consistency","Scene Diversity","Visual Storytelling"],"permalink":"/ai/review/2025-8-14-Story2Board_A_Training-Free_Approach_for_Expressive_Storyboard_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-14-Stand-In_A_Lightweight_and_Plug-and-Play_Identity_Control_for_Video_Generation","title":"[논문리뷰] Stand-In: A Lightweight and Plug-and-Play Identity Control for Video Generation","excerpt":"Chen Li이 [arXiv]에 게시한 'Stand-In: A Lightweight and Plug-and-Play Identity Control for Video Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-14 13:19:02+0900","lastModifiedAt":"2025-08-14 13:19:02+0900","categories":["Review"],"tags":["Review","Video Generation","Identity Preservation","Plug-and-Play","Diffusion Models","Self-Attention","Lightweight AI","Conditional Image Branch"],"permalink":"/ai/review/2025-8-14-Stand-In_A_Lightweight_and_Plug-and-Play_Identity_Control_for_Video_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-14-Seeing_Listening_Remembering_and_Reasoning_A_Multimodal_Agent_with_Long-Term_Memory","title":"[논문리뷰] Seeing, Listening, Remembering, and Reasoning: A Multimodal Agent with Long-Term Memory","excerpt":"Yuan Lin이 [arXiv]에 게시한 'Seeing, Listening, Remembering, and Reasoning: A Multimodal Agent with Long-Term Memory' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-14 13:19:02+0900","lastModifiedAt":"2025-08-14 13:19:02+0900","categories":["Review"],"tags":["Review","Multimodal Agent","Long-Term Memory","Episodic Memory","Semantic Memory","Reinforcement Learning","Video Question Answering","Entity-Centric Memory"],"permalink":"/ai/review/2025-8-14-Seeing_Listening_Remembering_and_Reasoning_A_Multimodal_Agent_with_Long-Term_Memory/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-14-Noise_Hypernetworks_Amortizing_Test-Time_Compute_in_Diffusion_Models","title":"[논문리뷰] Noise Hypernetworks: Amortizing Test-Time Compute in Diffusion Models","excerpt":"Zeynep Akata이 [arXiv]에 게시한 'Noise Hypernetworks: Amortizing Test-Time Compute in Diffusion Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-14 13:19:02+0900","lastModifiedAt":"2025-08-14 13:19:02+0900","categories":["Review"],"tags":["Review","Diffusion Models","Hypernetworks","Test-Time Optimization","Reward-Guided Generation","Latent Space Optimization","LoRA","Generative AI"],"permalink":"/ai/review/2025-8-14-Noise_Hypernetworks_Amortizing_Test-Time_Compute_in_Diffusion_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-14-Mol-R1_Towards_Explicit_Long-CoT_Reasoning_in_Molecule_Discovery","title":"[논문리뷰] Mol-R1: Towards Explicit Long-CoT Reasoning in Molecule Discovery","excerpt":"Di Zhang이 [arXiv]에 게시한 'Mol-R1: Towards Explicit Long-CoT Reasoning in Molecule Discovery' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-14 13:19:02+0900","lastModifiedAt":"2025-08-14 13:19:02+0900","categories":["Review"],"tags":["Review","Molecule Discovery","Chain-of-Thought","Large Language Models","Reinforcement Learning","Supervised Fine-tuning","Molecular Generation","Explainable AI"],"permalink":"/ai/review/2025-8-14-Mol-R1_Towards_Explicit_Long-CoT_Reasoning_in_Molecule_Discovery/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-14-MathReal_We_Keep_It_Real_A_Real_Scene_Benchmark_for_Evaluating_Math_Reasoning_in_Multimodal_Large_Language_Models","title":"[논문리뷰] MathReal: We Keep It Real! A Real Scene Benchmark for Evaluating Math Reasoning in Multimodal Large Language Models","excerpt":"Zhihan Zhou이 [arXiv]에 게시한 'MathReal: We Keep It Real! A Real Scene Benchmark for Evaluating Math Reasoning in Multimodal Large Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-14 13:19:02+0900","lastModifiedAt":"2025-08-14 13:19:02+0900","categories":["Review"],"tags":["Review","Multimodal Large Language Models (MLLMs)","Math Reasoning","Real-World Benchmark","Visual Perception","Robustness","K-12 Education","Dataset"],"permalink":"/ai/review/2025-8-14-MathReal_We_Keep_It_Real_A_Real_Scene_Benchmark_for_Evaluating_Math_Reasoning_in_Multimodal_Large_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-14-Learning_to_Align_Aligning_to_Learn_A_Unified_Approach_for_Self-Optimized_Alignment","title":"[논문리뷰] Learning to Align, Aligning to Learn: A Unified Approach for Self-Optimized Alignment","excerpt":"Lei Fan이 [arXiv]에 게시한 'Learning to Align, Aligning to Learn: A Unified Approach for Self-Optimized Alignment' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-14 13:19:02+0900","lastModifiedAt":"2025-08-14 13:19:02+0900","categories":["Review"],"tags":["Review","LLM Alignment","Reinforcement Learning from Human Feedback","Preference Learning","Group Relative Alignment Optimization","Self-Optimization","Mixture-of-Experts","Imitation Learning"],"permalink":"/ai/review/2025-8-14-Learning_to_Align_Aligning_to_Learn_A_Unified_Approach_for_Self-Optimized_Alignment/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-14-IAG_Input-aware_Backdoor_Attack_on_VLMs_for_Visual_Grounding","title":"[논문리뷰] IAG: Input-aware Backdoor Attack on VLMs for Visual Grounding","excerpt":"Di Zhang이 [arXiv]에 게시한 'IAG: Input-aware Backdoor Attack on VLMs for Visual Grounding' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-14 13:19:02+0900","lastModifiedAt":"2025-08-14 13:19:02+0900","categories":["Review"],"tags":["Review","Backdoor Attack","Vision-Language Models (VLMs)","Visual Grounding","Input-aware Trigger","Adversarial Attack","Security","U-Net","Open-vocabulary"],"permalink":"/ai/review/2025-8-14-IAG_Input-aware_Backdoor_Attack_on_VLMs_for_Visual_Grounding/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-14-GSFixer_Improving_3D_Gaussian_Splatting_with_Reference-Guided_Video_Diffusion_Priors","title":"[논문리뷰] GSFixer: Improving 3D Gaussian Splatting with Reference-Guided Video Diffusion Priors","excerpt":"Qingnan Fan이 [arXiv]에 게시한 'GSFixer: Improving 3D Gaussian Splatting with Reference-Guided Video Diffusion Priors' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-14 13:19:02+0900","lastModifiedAt":"2025-08-14 13:19:02+0900","categories":["Review"],"tags":["Review","3D Gaussian Splatting","Novel View Synthesis","Diffusion Model","Artifact Restoration","Sparse-view 3D Reconstruction","Reference-Guided"],"permalink":"/ai/review/2025-8-14-GSFixer_Improving_3D_Gaussian_Splatting_with_Reference-Guided_Video_Diffusion_Priors/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-14-Echo-4o_Harnessing_the_Power_of_GPT-4o_Synthetic_Images_for_Improved_Image_Generation","title":"[논문리뷰] Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation","excerpt":"Zhenghao Hu이 [arXiv]에 게시한 'Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-14 13:19:02+0900","lastModifiedAt":"2025-08-14 13:19:02+0900","categories":["Review"],"tags":["Review","Synthetic Data","Image Generation","GPT-4o","Multimodal Models","Instruction Following","Surreal Image Generation","Dataset","Benchmarking"],"permalink":"/ai/review/2025-8-14-Echo-4o_Harnessing_the_Power_of_GPT-4o_Synthetic_Images_for_Improved_Image_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-14-Diffusion_LLMs_Can_Do_Faster-Than-AR_Inference_via_Discrete_Diffusion_Forcing","title":"[논문리뷰] Diffusion LLMs Can Do Faster-Than-AR Inference via Discrete Diffusion Forcing","excerpt":"Hao Zhang이 [arXiv]에 게시한 'Diffusion LLMs Can Do Faster-Than-AR Inference via Discrete Diffusion Forcing' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-14 13:19:02+0900","lastModifiedAt":"2025-08-14 13:19:02+0900","categories":["Review"],"tags":["Review","Diffusion LLMs","Faster Inference","Discrete Diffusion Forcing (D2F)","Autoregressive Generation","KV Cache Optimization","Parallel Decoding","Text Generation","Model Distillation"],"permalink":"/ai/review/2025-8-14-Diffusion_LLMs_Can_Do_Faster-Than-AR_Inference_via_Discrete_Diffusion_Forcing/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-14-Cooper_Co-Optimizing_Policy_and_Reward_Models_in_Reinforcement_Learning_for_Large_Language_Models","title":"[논문리뷰] Cooper: Co-Optimizing Policy and Reward Models in Reinforcement Learning for Large Language Models","excerpt":"Guiyang Hou이 [arXiv]에 게시한 'Cooper: Co-Optimizing Policy and Reward Models in Reinforcement Learning for Large Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-14 13:19:02+0900","lastModifiedAt":"2025-08-14 13:19:02+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","Large Language Models","Reward Model","Policy Optimization","Reward Hacking","Hybrid Annotation","Mathematical Reasoning","Verifiable Rewards"],"permalink":"/ai/review/2025-8-14-Cooper_Co-Optimizing_Policy_and_Reward_Models_in_Reinforcement_Learning_for_Large_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-14-Can_LLM-Generated_Textual_Explanations_Enhance_Model_Classification_Performance_An_Empirical_Study","title":"[논문리뷰] Can LLM-Generated Textual Explanations Enhance Model Classification Performance? An Empirical Study","excerpt":"Gjergji Kasneci이 [arXiv]에 게시한 'Can LLM-Generated Textual Explanations Enhance Model Classification Performance? An Empirical Study' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-14 13:19:02+0900","lastModifiedAt":"2025-08-14 13:19:02+0900","categories":["Review"],"tags":["Review","Explainable NLP","Natural Language Explanations","Large Language Models","Pre-trained Language Models","Natural Language Inference","Model Performance Enhancement","Text Generation"],"permalink":"/ai/review/2025-8-14-Can_LLM-Generated_Textual_Explanations_Enhance_Model_Classification_Performance_An_Empirical_Study/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-14-AWorld_Dynamic_Multi-Agent_System_with_Stable_Maneuvering_for_Robust_GAIA_Problem_Solving","title":"[논문리뷰] AWorld: Dynamic Multi-Agent System with Stable Maneuvering for Robust GAIA Problem Solving","excerpt":"Jinjie Gu이 [arXiv]에 게시한 'AWorld: Dynamic Multi-Agent System with Stable Maneuvering for Robust GAIA Problem Solving' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-14 13:19:02+0900","lastModifiedAt":"2025-08-14 13:19:02+0900","categories":["Review"],"tags":["Review","Multi-Agent System","Agent Stability","LLM","Tool Use","GAIA Benchmark","Robustness","Dynamic Supervision","Maneuvering"],"permalink":"/ai/review/2025-8-14-AWorld_Dynamic_Multi-Agent_System_with_Stable_Maneuvering_for_Robust_GAIA_Problem_Solving/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-14-AMFT_Aligning_LLM_Reasoners_by_Meta-Learning_the_Optimal_Imitation-Exploration_Balance","title":"[논문리뷰] AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance","excerpt":"Yong Li이 [arXiv]에 게시한 'AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-14 13:19:02+0900","lastModifiedAt":"2025-08-14 13:19:02+0900","categories":["Review"],"tags":["Review","Large Language Models","Fine-tuning","Reinforcement Learning","Meta-learning","Adaptive Control","Imitation Learning","Exploration","Reasoning"],"permalink":"/ai/review/2025-8-14-AMFT_Aligning_LLM_Reasoners_by_Meta-Learning_the_Optimal_Imitation-Exploration_Balance/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-13-WGAST_Weakly-Supervised_Generative_Network_for_Daily_10_m_Land_Surface_Temperature_Estimation_via_Spatio-Temporal_Fusion","title":"[논문리뷰] WGAST: Weakly-Supervised Generative Network for Daily 10 m Land Surface Temperature Estimation via Spatio-Temporal Fusion","excerpt":"Rachid Nedjai이 [arXiv]에 게시한 'WGAST: Weakly-Supervised Generative Network for Daily 10 m Land Surface Temperature Estimation via Spatio-Temporal Fusion' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-13 13:29:23+0900","lastModifiedAt":"2025-08-13 13:29:23+0900","categories":["Review"],"tags":["Review","Spatio-Temporal Fusion","Land Surface Temperature","Generative Adversarial Network","Weakly-Supervised Learning","Remote Sensing","Deep Learning"],"permalink":"/ai/review/2025-8-13-WGAST_Weakly-Supervised_Generative_Network_for_Daily_10_m_Land_Surface_Temperature_Estimation_via_Spatio-Temporal_Fusion/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-13-VertexRegen_Mesh_Generation_with_Continuous_Level_of_Detail","title":"[논문리뷰] VertexRegen: Mesh Generation with Continuous Level of Detail","excerpt":"Jakob Engel이 [arXiv]에 게시한 'VertexRegen: Mesh Generation with Continuous Level of Detail' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-13 13:29:23+0900","lastModifiedAt":"2025-08-13 13:29:23+0900","categories":["Review"],"tags":["Review","Mesh Generation","Level of Detail (LOD)","Progressive Meshes","Vertex Split","Autoregressive Models","Transformer","3D Graphics"],"permalink":"/ai/review/2025-8-13-VertexRegen_Mesh_Generation_with_Continuous_Level_of_Detail/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-13-UNCAGE_Contrastive_Attention_Guidance_for_Masked_Generative_Transformers_in_Text-to-Image_Generation","title":"[논문리뷰] UNCAGE: Contrastive Attention Guidance for Masked Generative Transformers in Text-to-Image Generation","excerpt":"Kevin Galim이 [arXiv]에 게시한 'UNCAGE: Contrastive Attention Guidance for Masked Generative Transformers in Text-to-Image Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-13 13:29:23+0900","lastModifiedAt":"2025-08-13 13:29:23+0900","categories":["Review"],"tags":["Review","Text-to-Image Generation","Masked Generative Transformers","Compositional Generation","Attention Guidance","Unmasking Strategy","Contrastive Learning","Training-Free","Attribute Binding"],"permalink":"/ai/review/2025-8-13-UNCAGE_Contrastive_Attention_Guidance_for_Masked_Generative_Transformers_in_Text-to-Image_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-13-Train_Long_Think_Short_Curriculum_Learning_for_Efficient_Reasoning","title":"[논문리뷰] Train Long, Think Short: Curriculum Learning for Efficient Reasoning","excerpt":"Marzyeh Ghassemi이 [arXiv]에 게시한 'Train Long, Think Short: Curriculum Learning for Efficient Reasoning' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-13 13:29:23+0900","lastModifiedAt":"2025-08-13 13:29:23+0900","categories":["Review"],"tags":["Review","Curriculum Learning","Reinforcement Learning","Large Language Models","Reasoning Efficiency","Token Budget Control","Group Relative Policy Optimization","Chain-of-Thought"],"permalink":"/ai/review/2025-8-13-Train_Long_Think_Short_Curriculum_Learning_for_Efficient_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-13-Towards_Affordance-Aware_Robotic_Dexterous_Grasping_with_Human-like_Priors","title":"[논문리뷰] Towards Affordance-Aware Robotic Dexterous Grasping with Human-like Priors","excerpt":"Haoran Xu이 [arXiv]에 게시한 'Towards Affordance-Aware Robotic Dexterous Grasping with Human-like Priors' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-13 13:29:23+0900","lastModifiedAt":"2025-08-13 13:29:23+0900","categories":["Review"],"tags":["Review","Robotic Dexterous Grasping","Affordance-Aware","Human-like Priors","Reinforcement Learning","Vision-Language Models","Two-Stage Training","Manipulation"],"permalink":"/ai/review/2025-8-13-Towards_Affordance-Aware_Robotic_Dexterous_Grasping_with_Human-like_Priors/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-13-TopXGen_Topic-Diverse_Parallel_Data_Generation_for_Low-Resource_Machine_Translation","title":"[논문리뷰] TopXGen: Topic-Diverse Parallel Data Generation for Low-Resource Machine Translation","excerpt":"Rachel Bawden이 [arXiv]에 게시한 'TopXGen: Topic-Diverse Parallel Data Generation for Low-Resource Machine Translation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-13 13:29:23+0900","lastModifiedAt":"2025-08-13 13:29:23+0900","categories":["Review"],"tags":["Review","Low-Resource MT","Data Augmentation","Large Language Models (LLMs)","Back-Translation","In-Context Learning (ICL)","Fine-Tuning","Topic-Guided Generation","Parallel Data Synthesis"],"permalink":"/ai/review/2025-8-13-TopXGen_Topic-Diverse_Parallel_Data_Generation_for_Low-Resource_Machine_Translation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-13-Time_Is_a_Feature_Exploiting_Temporal_Dynamics_in_Diffusion_Language_Models","title":"[논문리뷰] Time Is a Feature: Exploiting Temporal Dynamics in Diffusion Language Models","excerpt":"Chenchen Jing이 [arXiv]에 게시한 'Time Is a Feature: Exploiting Temporal Dynamics in Diffusion Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-13 13:29:23+0900","lastModifiedAt":"2025-08-13 13:29:23+0900","categories":["Review"],"tags":["Review","Diffusion Language Models","Temporal Oscillation","Self-Consistency Voting","Reinforcement Learning","Temporal Semantic Entropy","Text Generation"],"permalink":"/ai/review/2025-8-13-Time_Is_a_Feature_Exploiting_Temporal_Dynamics_in_Diffusion_Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-13-Test-Time_Reinforcement_Learning_for_GUI_Grounding_via_Region_Consistency","title":"[논문리뷰] Test-Time Reinforcement Learning for GUI Grounding via Region Consistency","excerpt":"Zhengxi Lu이 [arXiv]에 게시한 'Test-Time Reinforcement Learning for GUI Grounding via Region Consistency' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-13 13:29:23+0900","lastModifiedAt":"2025-08-13 13:29:23+0900","categories":["Review"],"tags":["Review","GUI Grounding","Test-Time Scaling","Reinforcement Learning","Region Consistency","Spatial Voting","Self-Supervised Learning","Vision-Language Models"],"permalink":"/ai/review/2025-8-13-Test-Time_Reinforcement_Learning_for_GUI_Grounding_via_Region_Consistency/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-13-OpenCUA_Open_Foundations_for_Computer-Use_Agents","title":"[논문리뷰] OpenCUA: Open Foundations for Computer-Use Agents","excerpt":"Tianbao Xie이 [arXiv]에 게시한 'OpenCUA: Open Foundations for Computer-Use Agents' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-13 13:29:23+0900","lastModifiedAt":"2025-08-13 13:29:23+0900","categories":["Review"],"tags":["Review","Computer-Use Agents","Vision-Language Models","Chain-of-Thought Reasoning","Large-scale Dataset","Open-source Framework","Desktop Automation","Agent Evaluation"],"permalink":"/ai/review/2025-8-13-OpenCUA_Open_Foundations_for_Computer-Use_Agents/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-13-NVSpeech_An_Integrated_and_Scalable_Pipeline_for_Human-Like_Speech_Modeling_with_Paralinguistic_Vocalizations","title":"[논문리뷰] NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations","excerpt":"Haoyue Zhan이 [arXiv]에 게시한 'NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-13 13:29:23+0900","lastModifiedAt":"2025-08-13 13:29:23+0900","categories":["Review"],"tags":["Review","Paralinguistic Vocalizations","Speech Recognition","Text-to-Speech","Speech Synthesis","Data Annotation","Mandarin Speech","Expressive Speech"],"permalink":"/ai/review/2025-8-13-NVSpeech_An_Integrated_and_Scalable_Pipeline_for_Human-Like_Speech_Modeling_with_Paralinguistic_Vocalizations/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-13-Matrix-3D_Omnidirectional_Explorable_3D_World_Generation","title":"[논문리뷰] Matrix-3D: Omnidirectional Explorable 3D World Generation","excerpt":"Yuqi Li이 [arXiv]에 게시한 'Matrix-3D: Omnidirectional Explorable 3D World Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-13 13:29:23+0900","lastModifiedAt":"2025-08-13 13:29:23+0900","categories":["Review"],"tags":["Review","3D World Generation","Panoramic Video Generation","3D Reconstruction","Diffusion Models","Gaussian Splatting","Dataset","Camera Control"],"permalink":"/ai/review/2025-8-13-Matrix-3D_Omnidirectional_Explorable_3D_World_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-13-HierSearch_A_Hierarchical_Enterprise_Deep_Search_Framework_Integrating_Local_and_Web_Searches","title":"[논문리뷰] HierSearch: A Hierarchical Enterprise Deep Search Framework Integrating Local and Web Searches","excerpt":"Qiang Ju이 [arXiv]에 게시한 'HierSearch: A Hierarchical Enterprise Deep Search Framework Integrating Local and Web Searches' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-13 13:29:23+0900","lastModifiedAt":"2025-08-13 13:29:23+0900","categories":["Review"],"tags":["Review","Hierarchical Reinforcement Learning","Deep Search","Multi-source RAG","Agentic AI","Knowledge Integration","Enterprise Search","Large Reasoning Models"],"permalink":"/ai/review/2025-8-13-HierSearch_A_Hierarchical_Enterprise_Deep_Search_Framework_Integrating_Local_and_Web_Searches/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-13-GeRe_Towards_Efficient_Anti-Forgetting_in_Continual_Learning_of_LLM_via_General_Samples_Replay","title":"[논문리뷰] GeRe: Towards Efficient Anti-Forgetting in Continual Learning of LLM via General Samples Replay","excerpt":"Yang Fan이 [arXiv]에 게시한 'GeRe: Towards Efficient Anti-Forgetting in Continual Learning of LLM via General Samples Replay' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-13 13:29:23+0900","lastModifiedAt":"2025-08-13 13:29:23+0900","categories":["Review"],"tags":["Review","Continual Learning","Large Language Models (LLMs)","Catastrophic Forgetting","Replay","Knowledge Distillation","Activation States","Anti-forgetting","Threshold-based Margin Loss"],"permalink":"/ai/review/2025-8-13-GeRe_Towards_Efficient_Anti-Forgetting_in_Continual_Learning_of_LLM_via_General_Samples_Replay/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-13-Feedback-Driven_Tool-Use_Improvements_in_Large_Language_Models_via_Automated_Build_Environments","title":"[논문리뷰] Feedback-Driven Tool-Use Improvements in Large Language Models via Automated Build Environments","excerpt":"Xuesong Yao이 [arXiv]에 게시한 'Feedback-Driven Tool-Use Improvements in Large Language Models via Automated Build Environments' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-13 13:29:23+0900","lastModifiedAt":"2025-08-13 13:29:23+0900","categories":["Review"],"tags":["Review","Large Language Models (LLMs)","Tool Use","Reinforcement Learning (RL)","Automated Environment Generation","Feedback-Driven Training","Reward Mechanism","Contextual Understanding"],"permalink":"/ai/review/2025-8-13-Feedback-Driven_Tool-Use_Improvements_in_Large_Language_Models_via_Automated_Build_Environments/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-13-Democratizing_Diplomacy_A_Harness_for_Evaluating_Any_Large_Language_Model_on_Full-Press_Diplomacy","title":"[논문리뷰] Democratizing Diplomacy: A Harness for Evaluating Any Large Language Model on Full-Press Diplomacy","excerpt":"Elizabeth Karpinski이 [arXiv]에 게시한 'Democratizing Diplomacy: A Harness for Evaluating Any Large Language Model on Full-Press Diplomacy' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-13 13:29:23+0900","lastModifiedAt":"2025-08-13 13:29:23+0900","categories":["Review"],"tags":["Review","Large Language Models","Diplomacy Game","Multi-agent Systems","Strategic Reasoning","LLM Evaluation","Prompt Engineering","Behavioral Analysis","Game AI"],"permalink":"/ai/review/2025-8-13-Democratizing_Diplomacy_A_Harness_for_Evaluating_Any_Large_Language_Model_on_Full-Press_Diplomacy/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-13-DeCRED_Decoder-Centric_Regularization_for_Encoder-Decoder_Based_Speech_Recognition","title":"[논문리뷰] DeCRED: Decoder-Centric Regularization for Encoder-Decoder Based Speech Recognition","excerpt":"Lukáš Burget이 [arXiv]에 게시한 'DeCRED: Decoder-Centric Regularization for Encoder-Decoder Based Speech Recognition' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-13 13:29:23+0900","lastModifiedAt":"2025-08-13 13:29:23+0900","categories":["Review"],"tags":["Review","Speech Recognition","Encoder-Decoder","Regularization","Decoder-Centric","Intermediate Supervision","Out-of-Domain Generalization","Internal Language Model"],"permalink":"/ai/review/2025-8-13-DeCRED_Decoder-Centric_Regularization_for_Encoder-Decoder_Based_Speech_Recognition/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-13-Cut2Next_Generating_Next_Shot_via_In-Context_Tuning","title":"[논문리뷰] Cut2Next: Generating Next Shot via In-Context Tuning","excerpt":"Yu Qiao이 [arXiv]에 게시한 'Cut2Next: Generating Next Shot via In-Context Tuning' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-13 13:29:23+0900","lastModifiedAt":"2025-08-13 13:29:23+0900","categories":["Review"],"tags":["Review","Next Shot Generation","In-Context Tuning","Diffusion Transformer","Cinematic Continuity","Hierarchical Prompting","Video Generation","Shot Editing"],"permalink":"/ai/review/2025-8-13-Cut2Next_Generating_Next_Shot_via_In-Context_Tuning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-13-CharacterShot_Controllable_and_Consistent_4D_Character_Animation","title":"[논문리뷰] CharacterShot: Controllable and Consistent 4D Character Animation","excerpt":"Fei Shen이 [arXiv]에 게시한 'CharacterShot: Controllable and Consistent 4D Character Animation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-13 13:29:23+0900","lastModifiedAt":"2025-08-13 13:29:23+0900","categories":["Review"],"tags":["Review","4D Character Animation","Diffusion Models","Gaussian Splatting","Pose Control","Multi-view Synthesis","Temporal Consistency","Character Dataset"],"permalink":"/ai/review/2025-8-13-CharacterShot_Controllable_and_Consistent_4D_Character_Animation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-13-Bridging_Theory_and_Practice_in_Quantum_Game_Theory_Optimized_Implementation_of_the_Battle_of_the_Sexes_with_Error_Mitigation_on_NISQ_Hardware","title":"[논문리뷰] Bridging Theory and Practice in Quantum Game Theory: Optimized Implementation of the Battle of the Sexes with Error Mitigation on NISQ Hardware","excerpt":"Jhon Alejandro Andrade이 [arXiv]에 게시한 'Bridging Theory and Practice in Quantum Game Theory: Optimized Implementation of the Battle of the Sexes with Error Mitigation on NISQ Hardware' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-13 13:29:23+0900","lastModifiedAt":"2025-08-13 13:29:23+0900","categories":["Review"],"tags":["Review","Quantum Game Theory","NISQ Hardware","Error Mitigation","Battle of the Sexes","Qiskit","Quantum Computing","Strategic Coordination","Payoff Maximization"],"permalink":"/ai/review/2025-8-13-Bridging_Theory_and_Practice_in_Quantum_Game_Theory_Optimized_Implementation_of_the_Battle_of_the_Sexes_with_Error_Mitigation_on_NISQ_Hardware/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-13-BiasGym_Fantastic_Biases_and_How_to_Find_and_Remove_Them","title":"[논문리뷰] BiasGym: Fantastic Biases and How to Find (and Remove) Them","excerpt":"Arnav Arora이 [arXiv]에 게시한 'BiasGym: Fantastic Biases and How to Find (and Remove) Them' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-13 13:29:23+0900","lastModifiedAt":"2025-08-13 13:29:23+0900","categories":["Review"],"tags":["Review","Bias Mitigation","LLMs","Mechanistic Interpretability","Fine-tuning","Attention Steering","Stereotype Analysis","Safety Alignment"],"permalink":"/ai/review/2025-8-13-BiasGym_Fantastic_Biases_and_How_to_Find_and_Remove_Them/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-13-Beyond_Ten_Turns_Unlocking_Long-Horizon_Agentic_Search_with_Large-Scale_Asynchronous_RL","title":"[논문리뷰] Beyond Ten Turns: Unlocking Long-Horizon Agentic Search with Large-Scale Asynchronous RL","excerpt":"Chuyi He이 [arXiv]에 게시한 'Beyond Ten Turns: Unlocking Long-Horizon Agentic Search with Large-Scale Asynchronous RL' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-13 13:29:23+0900","lastModifiedAt":"2025-08-13 13:29:23+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","LLM Agents","Agentic Search","Asynchronous RL","Long-Horizon Planning","Tool Use","Data Synthesis"],"permalink":"/ai/review/2025-8-13-Beyond_Ten_Turns_Unlocking_Long-Horizon_Agentic_Search_with_Large-Scale_Asynchronous_RL/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-13-AutoCodeBench_Large_Language_Models_are_Automatic_Code_Benchmark_Generators","title":"[논문리뷰] AutoCodeBench: Large Language Models are Automatic Code Benchmark Generators","excerpt":"Tao Zhang이 [arXiv]에 게시한 'AutoCodeBench: Large Language Models are Automatic Code Benchmark Generators' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-13 13:29:23+0900","lastModifiedAt":"2025-08-13 13:29:23+0900","categories":["Review"],"tags":["Review","코드 생성","대규모 언어 모델","코드 벤치마크","다국어 프로그래밍","자동화된 데이터 생성","샌드박스 평가","멀티모달 AI"],"permalink":"/ai/review/2025-8-13-AutoCodeBench_Large_Language_Models_are_Automatic_Code_Benchmark_Generators/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-13-Aryabhata_An_exam-focused_language_model_for_JEE_Math","title":"[논문리뷰] Aryabhata: An exam-focused language model for JEE Math","excerpt":"Sandeep Varma이 [arXiv]에 게시한 'Aryabhata: An exam-focused language model for JEE Math' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-13 13:29:23+0900","lastModifiedAt":"2025-08-13 13:29:23+0900","categories":["Review"],"tags":["Review","Language Model","Math Reasoning","JEE","Supervised Fine-Tuning","Reinforcement Learning","Model Merging","Chain-of-Thought","Curriculum Learning"],"permalink":"/ai/review/2025-8-13-Aryabhata_An_exam-focused_language_model_for_JEE_Math/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-13-Adversarial_Video_Promotion_Against_Text-to-Video_Retrieval","title":"[논문리뷰] Adversarial Video Promotion Against Text-to-Video Retrieval","excerpt":"Shuai Liu이 [arXiv]에 게시한 'Adversarial Video Promotion Against Text-to-Video Retrieval' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-13 13:29:23+0900","lastModifiedAt":"2025-08-13 13:29:23+0900","categories":["Review"],"tags":["Review","Adversarial Attack","Video Promotion","Text-to-Video Retrieval","Modality Refinement","Black-box Attack","Video Manipulation","Transferability"],"permalink":"/ai/review/2025-8-13-Adversarial_Video_Promotion_Against_Text-to-Video_Retrieval/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-12-WideSearch_Benchmarking_Agentic_Broad_Info-Seeking","title":"[논문리뷰] WideSearch: Benchmarking Agentic Broad Info-Seeking","excerpt":"Yan Gao이 [arXiv]에 게시한 'WideSearch: Benchmarking Agentic Broad Info-Seeking' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-12 13:29:09+0900","lastModifiedAt":"2025-08-12 13:29:09+0900","categories":["Review"],"tags":["Review","Agentic Search","LLM","Benchmark","Information Seeking","Structured Output","Evaluation Metrics","Multi-agent Systems"],"permalink":"/ai/review/2025-8-12-WideSearch_Benchmarking_Agentic_Broad_Info-Seeking/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-12-When_Good_Sounds_Go_Adversarial_Jailbreaking_Audio-Language_Models_with_Benign_Inputs","title":"[논문리뷰] When Good Sounds Go Adversarial: Jailbreaking Audio-Language Models with Benign Inputs","excerpt":"Dasol Choi이 [arXiv]에 게시한 'When Good Sounds Go Adversarial: Jailbreaking Audio-Language Models with Benign Inputs' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-12 13:29:09+0900","lastModifiedAt":"2025-08-12 13:29:09+0900","categories":["Review"],"tags":["Review","Audio-Language Models","Jailbreak Attack","Adversarial Audio","Reinforcement Learning","Projected Gradient Descent","Native Payload Discovery","Multimodal AI Safety"],"permalink":"/ai/review/2025-8-12-When_Good_Sounds_Go_Adversarial_Jailbreaking_Audio-Language_Models_with_Benign_Inputs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-12-VisR-Bench_An_Empirical_Study_on_Visual_Retrieval-Augmented_Generation_for_Multilingual_Long_Document_Understanding","title":"[논문리뷰] VisR-Bench: An Empirical Study on Visual Retrieval-Augmented Generation for Multilingual Long Document Understanding","excerpt":"Tong Yu이 [arXiv]에 게시한 'VisR-Bench: An Empirical Study on Visual Retrieval-Augmented Generation for Multilingual Long Document Understanding' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-12 13:29:09+0900","lastModifiedAt":"2025-08-12 13:29:09+0900","categories":["Review"],"tags":["Review","Multimodal Retrieval","Retrieval-Augmented Generation","Long Document Understanding","Multilingual NLP","Visual QA","Benchmark","MLLMs","Table Understanding"],"permalink":"/ai/review/2025-8-12-VisR-Bench_An_Empirical_Study_on_Visual_Retrieval-Augmented_Generation_for_Multilingual_Long_Document_Understanding/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-12-UserBench_An_Interactive_Gym_Environment_for_User-Centric_Agents","title":"[논문리뷰] UserBench: An Interactive Gym Environment for User-Centric Agents","excerpt":"Jianguo Zhang이 [arXiv]에 게시한 'UserBench: An Interactive Gym Environment for User-Centric Agents' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-12 13:29:09+0900","lastModifiedAt":"2025-08-12 13:29:09+0900","categories":["Review"],"tags":["Review","User-Centric AI","LLM Evaluation","Interactive Agents","Gym Environment","Preference Elicitation","Multi-turn Dialogue","Tool Use"],"permalink":"/ai/review/2025-8-12-UserBench_An_Interactive_Gym_Environment_for_User-Centric_Agents/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-12-Temporal_Self-Rewarding_Language_Models_Decoupling_Chosen-Rejected_via_Past-Future","title":"[논문리뷰] Temporal Self-Rewarding Language Models: Decoupling Chosen-Rejected via Past-Future","excerpt":"Qiufeng Wang이 [arXiv]에 게시한 'Temporal Self-Rewarding Language Models: Decoupling Chosen-Rejected via Past-Future' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-12 13:29:09+0900","lastModifiedAt":"2025-08-12 13:29:09+0900","categories":["Review"],"tags":["Review","Self-Rewarding LLMs","Direct Preference Optimization (DPO)","Preference Learning","Generative AI","Gradient Collapse","LLM Alignment","Iterative Optimization"],"permalink":"/ai/review/2025-8-12-Temporal_Self-Rewarding_Language_Models_Decoupling_Chosen-Rejected_via_Past-Future/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-12-Speech-to-LaTeX_New_Models_and_Datasets_for_Converting_Spoken_Equations_and_Sentences","title":"[논문리뷰] Speech-to-LaTeX: New Models and Datasets for Converting Spoken Equations and Sentences","excerpt":"Matvey Skripkin이 [arXiv]에 게시한 'Speech-to-LaTeX: New Models and Datasets for Converting Spoken Equations and Sentences' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-12 13:29:09+0900","lastModifiedAt":"2025-08-12 13:29:09+0900","categories":["Review"],"tags":["Review","Speech-to-LaTeX","ASR","Language Models","Multimodal AI","Dataset Creation","Mathematical Expression Recognition","LaTeX Generation"],"permalink":"/ai/review/2025-8-12-Speech-to-LaTeX_New_Models_and_Datasets_for_Converting_Spoken_Equations_and_Sentences/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-12-Shortcut_Learning_in_Generalist_Robot_Policies_The_Role_of_Dataset_Diversity_and_Fragmentation","title":"[논문리뷰] Shortcut Learning in Generalist Robot Policies: The Role of Dataset Diversity and Fragmentation","excerpt":"Hengtao Shen이 [arXiv]에 게시한 'Shortcut Learning in Generalist Robot Policies: The Role of Dataset Diversity and Fragmentation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-12 13:29:09+0900","lastModifiedAt":"2025-08-12 13:29:09+0900","categories":["Review"],"tags":["Review","Robot Learning","Generalization","Shortcut Learning","Dataset Diversity","Dataset Fragmentation","Data Augmentation","Imitation Learning"],"permalink":"/ai/review/2025-8-12-Shortcut_Learning_in_Generalist_Robot_Policies_The_Role_of_Dataset_Diversity_and_Fragmentation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-12-Reinforcement_Learning_in_Vision_A_Survey","title":"[논문리뷰] Reinforcement Learning in Vision: A Survey","excerpt":"Qingwei Meng이 [arXiv]에 게시한 'Reinforcement Learning in Vision: A Survey' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-12 13:29:09+0900","lastModifiedAt":"2025-08-12 13:29:09+0900","categories":["Review"],"tags":["Review","Reinforcement Learning (RL)","Computer Vision (CV)","Multimodal Large Language Models (MLLMs)","Visual Generation","Vision-Language-Action (VLA) Models","Policy Optimization","Reward Modeling"],"permalink":"/ai/review/2025-8-12-Reinforcement_Learning_in_Vision_A_Survey/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-12-ReasonRank_Empowering_Passage_Ranking_with_Strong_Reasoning_Ability","title":"[논문리뷰] ReasonRank: Empowering Passage Ranking with Strong Reasoning Ability","excerpt":"Yuchen Li이 [arXiv]에 게시한 'ReasonRank: Empowering Passage Ranking with Strong Reasoning Ability' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-12 13:29:09+0900","lastModifiedAt":"2025-08-12 13:29:09+0900","categories":["Review"],"tags":["Review","Passage Ranking","Reasoning Models","Large Language Models","Data Synthesis","Reinforcement Learning","Listwise Reranking","Information Retrieval"],"permalink":"/ai/review/2025-8-12-ReasonRank_Empowering_Passage_Ranking_with_Strong_Reasoning_Ability/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-12-Part_I_Tricks_or_Traps_A_Deep_Dive_into_RL_for_LLM_Reasoning","title":"[논문리뷰] Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning","excerpt":"Jiaheng Liu이 [arXiv]에 게시한 'Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-12 13:29:09+0900","lastModifiedAt":"2025-08-12 13:29:09+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","Large Language Models","LLM Reasoning","Policy Optimization","Normalization","Clipping","Loss Aggregation","Overlong Filtering"],"permalink":"/ai/review/2025-8-12-Part_I_Tricks_or_Traps_A_Deep_Dive_into_RL_for_LLM_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-12-OmniEAR_Benchmarking_Agent_Reasoning_in_Embodied_Tasks","title":"[논문리뷰] OmniEAR: Benchmarking Agent Reasoning in Embodied Tasks","excerpt":"Hongxing Li이 [arXiv]에 게시한 'OmniEAR: Benchmarking Agent Reasoning in Embodied Tasks' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-12 13:29:09+0900","lastModifiedAt":"2025-08-12 13:29:09+0900","categories":["Review"],"tags":["Review","Embodied AI","Agent Reasoning","LLM","Benchmarking","Tool Use","Multi-Agent Systems","Physical Interaction","Constraint Reasoning"],"permalink":"/ai/review/2025-8-12-OmniEAR_Benchmarking_Agent_Reasoning_in_Embodied_Tasks/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-12-Omni-Effects_Unified_and_Spatially-Controllable_Visual_Effects_Generation","title":"[논문리뷰] Omni-Effects: Unified and Spatially-Controllable Visual Effects Generation","excerpt":"Xiaokun Feng이 [arXiv]에 게시한 'Omni-Effects: Unified and Spatially-Controllable Visual Effects Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-12 13:29:09+0900","lastModifiedAt":"2025-08-12 13:29:09+0900","categories":["Review"],"tags":["Review","Visual Effects","Video Generation","LoRA","Mixture of Experts","Spatial Control","Diffusion Models","Multi-VFX"],"permalink":"/ai/review/2025-8-12-Omni-Effects_Unified_and_Spatially-Controllable_Visual_Effects_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-12-MolmoAct_Action_Reasoning_Models_that_can_Reason_in_Space","title":"[논문리뷰] MolmoAct: Action Reasoning Models that can Reason in Space","excerpt":"Shuo Liu이 [arXiv]에 게시한 'MolmoAct: Action Reasoning Models that can Reason in Space' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-12 13:29:09+0900","lastModifiedAt":"2025-08-12 13:29:09+0900","categories":["Review"],"tags":["Review","Robotics","Action Reasoning","Vision-Language Models","Spatial Planning","Depth Perception","Trajectory Generation","Explainable AI"],"permalink":"/ai/review/2025-8-12-MolmoAct_Action_Reasoning_Models_that_can_Reason_in_Space/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-12-MoBE_Mixture-of-Basis-Experts_for_Compressing_MoE-based_LLMs","title":"[논문리뷰] MoBE: Mixture-of-Basis-Experts for Compressing MoE-based LLMs","excerpt":"Jianguo Li이 [arXiv]에 게시한 'MoBE: Mixture-of-Basis-Experts for Compressing MoE-based LLMs' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-12 13:29:09+0900","lastModifiedAt":"2025-08-12 13:29:09+0900","categories":["Review"],"tags":["Review","Mixture-of-Experts (MoE)","LLM Compression","Matrix Decomposition","Parameter Efficiency","Deep Learning","Memory Optimization"],"permalink":"/ai/review/2025-8-12-MoBE_Mixture-of-Basis-Experts_for_Compressing_MoE-based_LLMs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-12-Less_Is_More_Training-Free_Sparse_Attention_with_Global_Locality_for_Efficient_Reasoning","title":"[논문리뷰] Less Is More: Training-Free Sparse Attention with Global Locality for Efficient Reasoning","excerpt":"Baihong Yuan이 [arXiv]에 게시한 'Less Is More: Training-Free Sparse Attention with Global Locality for Efficient Reasoning' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-12 13:29:09+0900","lastModifiedAt":"2025-08-12 13:29:09+0900","categories":["Review"],"tags":["Review","Sparse Attention","LLMs","Reasoning Tasks","Efficiency","Training-Free","Global Locality","KV Cache Optimization"],"permalink":"/ai/review/2025-8-12-Less_Is_More_Training-Free_Sparse_Attention_with_Global_Locality_for_Efficient_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-12-Klear-Reasoner_Advancing_Reasoning_Capability_via_Gradient-Preserving_Clipping_Policy_Optimization","title":"[논문리뷰] Klear-Reasoner: Advancing Reasoning Capability via Gradient-Preserving Clipping Policy Optimization","excerpt":"Guanting Dong이 [arXiv]에 게시한 'Klear-Reasoner: Advancing Reasoning Capability via Gradient-Preserving Clipping Policy Optimization' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-12 13:29:09+0900","lastModifiedAt":"2025-08-12 13:29:09+0900","categories":["Review"],"tags":["Review","Reasoning LLMs","Reinforcement Learning","PPO","Gradient Clipping","Supervised Fine-tuning","Math Reasoning","Code Generation","Policy Optimization"],"permalink":"/ai/review/2025-8-12-Klear-Reasoner_Advancing_Reasoning_Capability_via_Gradient-Preserving_Clipping_Policy_Optimization/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-12-Grove_MoE_Towards_Efficient_and_Superior_MoE_LLMs_with_Adjugate_Experts","title":"[논문리뷰] Grove MoE: Towards Efficient and Superior MoE LLMs with Adjugate Experts","excerpt":"Tieyuan Chen이 [arXiv]에 게시한 'Grove MoE: Towards Efficient and Superior MoE LLMs with Adjugate Experts' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-12 13:29:09+0900","lastModifiedAt":"2025-08-12 13:29:09+0900","categories":["Review"],"tags":["Review","Mixture of Experts","LLMs","MoE Architecture","Dynamic Activation","Adjugate Experts","Upcycling Strategy","Load Balancing"],"permalink":"/ai/review/2025-8-12-Grove_MoE_Towards_Efficient_and_Superior_MoE_LLMs_with_Adjugate_Experts/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-12-GLiClass_Generalist_Lightweight_Model_for_Sequence_Classification_Tasks","title":"[논문리뷰] GLiClass: Generalist Lightweight Model for Sequence Classification Tasks","excerpt":"Alexander Yavorskyi이 [arXiv]에 게시한 'GLiClass: Generalist Lightweight Model for Sequence Classification Tasks' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-12 13:29:09+0900","lastModifiedAt":"2025-08-12 13:29:09+0900","categories":["Review"],"tags":["Review","Sequence Classification","Zero-shot Learning","Few-shot Learning","Transformer","Multi-label Classification","PPO","GLiNER","Computational Efficiency"],"permalink":"/ai/review/2025-8-12-GLiClass_Generalist_Lightweight_Model_for_Sequence_Classification_Tasks/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-12-Follow-Your-Shape_Shape-Aware_Image_Editing_via_Trajectory-Guided_Region_Control","title":"[논문리뷰] Follow-Your-Shape: Shape-Aware Image Editing via Trajectory-Guided Region Control","excerpt":"Hongyu Liu이 [arXiv]에 게시한 'Follow-Your-Shape: Shape-Aware Image Editing via Trajectory-Guided Region Control' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-12 13:29:09+0900","lastModifiedAt":"2025-08-12 13:29:09+0900","categories":["Review"],"tags":["Review","Image Editing","Shape Transformation","Rectified Flow","Trajectory Divergence Map","Region Control","Generative Models","Diffusion Models"],"permalink":"/ai/review/2025-8-12-Follow-Your-Shape_Shape-Aware_Image_Editing_via_Trajectory-Guided_Region_Control/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-12-Fact2Fiction_Targeted_Poisoning_Attack_to_Agentic_Fact-checking_System","title":"[논문리뷰] Fact2Fiction: Targeted Poisoning Attack to Agentic Fact-checking System","excerpt":"Reynold Cheng이 [arXiv]에 게시한 'Fact2Fiction: Targeted Poisoning Attack to Agentic Fact-checking System' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-12 13:29:09+0900","lastModifiedAt":"2025-08-12 13:29:09+0900","categories":["Review"],"tags":["Review","Adversarial Attack","Poisoning Attack","Fact-checking","LLM Agent","Retrieval Augmented Generation","Misinformation","System Security"],"permalink":"/ai/review/2025-8-12-Fact2Fiction_Targeted_Poisoning_Attack_to_Agentic_Fact-checking_System/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-12-Deep_Ignorance_Filtering_Pretraining_Data_Builds_Tamper-Resistant_Safeguards_into_Open-Weight_LLMs","title":"[논문리뷰] Deep Ignorance: Filtering Pretraining Data Builds Tamper-Resistant Safeguards into Open-Weight LLMs","excerpt":"Robert Kirk이 [arXiv]에 게시한 'Deep Ignorance: Filtering Pretraining Data Builds Tamper-Resistant Safeguards into Open-Weight LLMs' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-12 13:29:09+0900","lastModifiedAt":"2025-08-12 13:29:09+0900","categories":["Review"],"tags":["Review","LLMs","데이터 필터링","사전 학습","변조 저항성","바이오위협","AI 안전","서킷 브레이킹","머신 언러닝"],"permalink":"/ai/review/2025-8-12-Deep_Ignorance_Filtering_Pretraining_Data_Builds_Tamper-Resistant_Safeguards_into_Open-Weight_LLMs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-12-Compressing_Chain-of-Thought_in_LLMs_via_Step_Entropy","title":"[논문리뷰] Compressing Chain-of-Thought in LLMs via Step Entropy","excerpt":"Zhijian Xu이 [arXiv]에 게시한 'Compressing Chain-of-Thought in LLMs via Step Entropy' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-12 13:29:09+0900","lastModifiedAt":"2025-08-12 13:29:09+0900","categories":["Review"],"tags":["Review","LLM","Chain-of-Thought","CoT Compression","Step Entropy","Reinforcement Learning","SFT","GRPO"],"permalink":"/ai/review/2025-8-12-Compressing_Chain-of-Thought_in_LLMs_via_Step_Entropy/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-12-BrowseComp-Plus_A_More_Fair_and_Transparent_Evaluation_Benchmark_of_Deep-Research_Agent","title":"[논문리뷰] BrowseComp-Plus: A More Fair and Transparent Evaluation Benchmark of Deep-Research Agent","excerpt":"Kai Zou이 [arXiv]에 게시한 'BrowseComp-Plus: A More Fair and Transparent Evaluation Benchmark of Deep-Research Agent' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-12 13:29:09+0900","lastModifiedAt":"2025-08-12 13:29:09+0900","categories":["Review"],"tags":["Review","Benchmarking","Deep-Research Agents","LLMs","Retrieval","Curated Corpus","Evaluation","Fairness","Transparency","Reproducibility"],"permalink":"/ai/review/2025-8-12-BrowseComp-Plus_A_More_Fair_and_Transparent_Evaluation_Benchmark_of_Deep-Research_Agent/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-12-Bifrost-1_Bridging_Multimodal_LLMs_and_Diffusion_Models_with_Patch-level_CLIP_Latents","title":"[논문리뷰] Bifrost-1: Bridging Multimodal LLMs and Diffusion Models with Patch-level CLIP Latents","excerpt":"Mohit Bansal이 [arXiv]에 게시한 'Bifrost-1: Bridging Multimodal LLMs and Diffusion Models with Patch-level CLIP Latents' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-12 13:29:09+0900","lastModifiedAt":"2025-08-12 13:29:09+0900","categories":["Review"],"tags":["Review","Multimodal LLM","Diffusion Model","CLIP Latent","Image Generation","Multimodal Understanding","ControlNet","Training Efficiency"],"permalink":"/ai/review/2025-8-12-Bifrost-1_Bridging_Multimodal_LLMs_and_Diffusion_Models_with_Patch-level_CLIP_Latents/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-12-A_Comprehensive_Survey_of_Self-Evolving_AI_Agents_A_New_Paradigm_Bridging_Foundation_Models_and_Lifelong_Agentic_Systems","title":"[논문리뷰] A Comprehensive Survey of Self-Evolving AI Agents: A New Paradigm Bridging Foundation Models and Lifelong Agentic Systems","excerpt":"Xinhao Yi이 [arXiv]에 게시한 'A Comprehensive Survey of Self-Evolving AI Agents: A New Paradigm Bridging Foundation Models and Lifelong Agentic Systems' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-12 13:29:09+0900","lastModifiedAt":"2025-08-12 13:29:09+0900","categories":["Review"],"tags":["Review","Self-Evolving AI Agents","Lifelong Learning","Foundation Models","Multi-Agent Systems","Agent Optimization","Prompt Engineering","Tool Use","AI Safety","Survey"],"permalink":"/ai/review/2025-8-12-A_Comprehensive_Survey_of_Self-Evolving_AI_Agents_A_New_Paradigm_Bridging_Foundation_Models_and_Lifelong_Agentic_Systems/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-11-Voost_A_Unified_and_Scalable_Diffusion_Transformer_for_Bidirectional_Virtual_Try-On_and_Try-Off","title":"[논문리뷰] Voost: A Unified and Scalable Diffusion Transformer for Bidirectional Virtual Try-On and Try-Off","excerpt":"jgkwak이 [arXiv]에 게시한 'Voost: A Unified and Scalable Diffusion Transformer for Bidirectional Virtual Try-On and Try-Off' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-11 13:13:28+0900","lastModifiedAt":"2025-08-11 13:13:28+0900","categories":["Review"],"tags":["Review","Virtual Try-On","Virtual Try-Off","Diffusion Transformer","Bidirectional Learning","Generative AI","Fashion Synthesis","Attention Mechanism","Self-Correction"],"permalink":"/ai/review/2025-8-11-Voost_A_Unified_and_Scalable_Diffusion_Transformer_for_Bidirectional_Virtual_Try-On_and_Try-Off/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-11-UI-AGILE_Advancing_GUI_Agents_with_Effective_Reinforcement_Learning_and_Precise_Inference-Time_Grounding","title":"[논문리뷰] UI-AGILE: Advancing GUI Agents with Effective Reinforcement Learning and Precise Inference-Time Grounding","excerpt":"Bingqi Chen이 [arXiv]에 게시한 'UI-AGILE: Advancing GUI Agents with Effective Reinforcement Learning and Precise Inference-Time Grounding' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-11 13:13:28+0900","lastModifiedAt":"2025-08-11 13:13:28+0900","categories":["Review"],"tags":["Review","GUI Agents","Reinforcement Learning","Grounding","MLLMs","Reward Function","Resampling","Visual Noise Reduction"],"permalink":"/ai/review/2025-8-11-UI-AGILE_Advancing_GUI_Agents_with_Effective_Reinforcement_Learning_and_Precise_Inference-Time_Grounding/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-11-Pruning_the_Unsurprising_Efficient_Code_Reasoning_via_First-Token_Surprisal","title":"[논문리뷰] Pruning the Unsurprising: Efficient Code Reasoning via First-Token Surprisal","excerpt":"Chengcheng Wan이 [arXiv]에 게시한 'Pruning the Unsurprising: Efficient Code Reasoning via First-Token Surprisal' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-11 13:13:28+0900","lastModifiedAt":"2025-08-11 13:13:28+0900","categories":["Review"],"tags":["Review","Code Reasoning","CoT Compression","LLMs","Efficiency","Surprisal","Pruning","Fine-tuning","Large Reasoning Models"],"permalink":"/ai/review/2025-8-11-Pruning_the_Unsurprising_Efficient_Code_Reasoning_via_First-Token_Surprisal/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-11-MeshLLM_Empowering_Large_Language_Models_to_Progressively_Understand_and_Generate_3D_Mesh","title":"[논문리뷰] MeshLLM: Empowering Large Language Models to Progressively Understand and Generate 3D Mesh","excerpt":"Yi Yang이 [arXiv]에 게시한 'MeshLLM: Empowering Large Language Models to Progressively Understand and Generate 3D Mesh' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-11 13:13:28+0900","lastModifiedAt":"2025-08-11 13:13:28+0900","categories":["Review"],"tags":["Review","3D Mesh Generation","LLMs","Mesh Understanding","Text-to-3D","Primitive-Mesh Decomposition","Progressive Training","Multimodal AI"],"permalink":"/ai/review/2025-8-11-MeshLLM_Empowering_Large_Language_Models_to_Progressively_Understand_and_Generate_3D_Mesh/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-11-Memp_Exploring_Agent_Procedural_Memory","title":"[논문리뷰] Memp: Exploring Agent Procedural Memory","excerpt":"Shuofei Qiao이 [arXiv]에 게시한 'Memp: Exploring Agent Procedural Memory' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-11 13:13:28+0900","lastModifiedAt":"2025-08-11 13:13:28+0900","categories":["Review"],"tags":["Review","Procedural Memory","LLM Agents","Memory Management","Task Automation","Lifelong Learning","Experience Replay","Agent Learning"],"permalink":"/ai/review/2025-8-11-Memp_Exploring_Agent_Procedural_Memory/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-11-MELLA_Bridging_Linguistic_Capability_and_Cultural_Groundedness_for_Low-Resource_Language_MLLMs","title":"[논문리뷰] MELLA: Bridging Linguistic Capability and Cultural Groundedness for Low-Resource Language MLLMs","excerpt":"Guohang Yan이 [arXiv]에 게시한 'MELLA: Bridging Linguistic Capability and Cultural Groundedness for Low-Resource Language MLLMs' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-11 13:13:28+0900","lastModifiedAt":"2025-08-11 13:13:28+0900","categories":["Review"],"tags":["Review","Multimodal Large Language Models","Low-Resource Languages","Cultural Groundedness","Linguistic Capability","Dataset Creation","Multilingual AI"],"permalink":"/ai/review/2025-8-11-MELLA_Bridging_Linguistic_Capability_and_Cultural_Groundedness_for_Low-Resource_Language_MLLMs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-11-LightSwitch_Multi-view_Relighting_with_Material-guided_Diffusion","title":"[논문리뷰] LightSwitch: Multi-view Relighting with Material-guided Diffusion","excerpt":"Shubham Tulsiani이 [arXiv]에 게시한 'LightSwitch: Multi-view Relighting with Material-guided Diffusion' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-11 13:13:28+0900","lastModifiedAt":"2025-08-11 13:13:28+0900","categories":["Review"],"tags":["Review","Multi-view Relighting","Diffusion Models","Material-guided","Inverse Rendering","3D Scene Reconstruction","Image Synthesis","Consistent Relighting"],"permalink":"/ai/review/2025-8-11-LightSwitch_Multi-view_Relighting_with_Material-guided_Diffusion/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-11-InfiGUI-G1_Advancing_GUI_Grounding_with_Adaptive_Exploration_Policy_Optimization","title":"[논문리뷰] InfiGUI-G1: Advancing GUI Grounding with Adaptive Exploration Policy Optimization","excerpt":"Pengxiang Li이 [arXiv]에 게시한 'InfiGUI-G1: Advancing GUI Grounding with Adaptive Exploration Policy Optimization' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-11 13:13:28+0900","lastModifiedAt":"2025-08-11 13:13:28+0900","categories":["Review"],"tags":["Review","GUI Grounding","MLLMs","Reinforcement Learning","Policy Optimization","Exploration Strategy","Semantic Alignment","Adaptive Exploration Reward","Human-Computer Interaction"],"permalink":"/ai/review/2025-8-11-InfiGUI-G1_Advancing_GUI_Grounding_with_Adaptive_Exploration_Policy_Optimization/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-11-GLM-4.5_Agentic_Reasoning_and_Coding_ARC_Foundation_Models","title":"[논문리뷰] GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models","excerpt":"GLM-4. 5 Team이 [arXiv]에 게시한 'GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-11 13:13:28+0900","lastModifiedAt":"2025-08-11 13:13:28+0900","categories":["Review"],"tags":["Review","Large Language Model","Mixture-of-Experts","Agentic AI","Reasoning","Code Generation","Reinforcement Learning","Foundation Model"],"permalink":"/ai/review/2025-8-11-GLM-4.5_Agentic_Reasoning_and_Coding_ARC_Foundation_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-11-GENIE_Gaussian_Encoding_for_Neural_Radiance_Fields_Interactive_Editing","title":"[논문리뷰] GENIE: Gaussian Encoding for Neural Radiance Fields Interactive Editing","excerpt":"Przemysław Spurek이 [arXiv]에 게시한 'GENIE: Gaussian Encoding for Neural Radiance Fields Interactive Editing' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-11 13:13:28+0900","lastModifiedAt":"2025-08-11 13:13:28+0900","categories":["Review"],"tags":["Review","Neural Radiance Fields (NeRF)","Gaussian Splatting (GS)","Interactive Editing","3D Scene Representation","Physics Simulation","Hybrid Model","Real-time Rendering","Ray Tracing"],"permalink":"/ai/review/2025-8-11-GENIE_Gaussian_Encoding_for_Neural_Radiance_Fields_Interactive_Editing/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-11-Adapting_Vision-Language_Models_Without_Labels_A_Comprehensive_Survey","title":"[논문리뷰] Adapting Vision-Language Models Without Labels: A Comprehensive Survey","excerpt":"Eleni Chatzi이 [arXiv]에 게시한 'Adapting Vision-Language Models Without Labels: A Comprehensive Survey' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-11 13:13:28+0900","lastModifiedAt":"2025-08-11 13:13:28+0900","categories":["Review"],"tags":["Review","Vision-Language Models (VLMs)","Unsupervised Adaptation","Test-Time Adaptation (TTA)","Domain Transfer","Multimodal Learning","Label-Free Learning","Zero-Shot Learning"],"permalink":"/ai/review/2025-8-11-Adapting_Vision-Language_Models_Without_Labels_A_Comprehensive_Survey/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-8-Visual_Document_Understanding_and_Question_Answering_A_Multi-Agent_Collaboration_Framework_with_Test-Time_Scaling","title":"[논문리뷰] Visual Document Understanding and Question Answering: A Multi-Agent Collaboration Framework with Test-Time Scaling","excerpt":"Ruolin Shen이 [arXiv]에 게시한 'Visual Document Understanding and Question Answering: A Multi-Agent Collaboration Framework with Test-Time Scaling' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-08 13:32:22+0900","lastModifiedAt":"2025-08-08 13:32:22+0900","categories":["Review"],"tags":["Review","Visual Document Understanding","Visual Question Answering","Multi-Agent System","Test-Time Scaling","Self-Correction","Mixed Reward Modeling","Large Language Models"],"permalink":"/ai/review/2025-8-8-Visual_Document_Understanding_and_Question_Answering_A_Multi-Agent_Collaboration_Framework_with_Test-Time_Scaling/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-8-StrandDesigner_Towards_Practical_Strand_Generation_with_Sketch_Guidance","title":"[논문리뷰] StrandDesigner: Towards Practical Strand Generation with Sketch Guidance","excerpt":"Xiaobin Hu이 [arXiv]에 게시한 'StrandDesigner: Towards Practical Strand Generation with Sketch Guidance' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-08 13:32:22+0900","lastModifiedAt":"2025-08-08 13:32:22+0900","categories":["Review"],"tags":["Review","Strand Generation","Sketch Guidance","Diffusion Models","Multi-scale Learning","Adaptive Conditioning","3D Hair Modeling","Computer Graphics"],"permalink":"/ai/review/2025-8-8-StrandDesigner_Towards_Practical_Strand_Generation_with_Sketch_Guidance/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-8-Steering_One-Step_Diffusion_Model_with_Fidelity-Rich_Decoder_for_Fast_Image_Compression","title":"[논문리뷰] Steering One-Step Diffusion Model with Fidelity-Rich Decoder for Fast Image Compression","excerpt":"Yifei Ji이 [arXiv]에 게시한 'Steering One-Step Diffusion Model with Fidelity-Rich Decoder for Fast Image Compression' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-08 13:32:22+0900","lastModifiedAt":"2025-08-08 13:32:22+0900","categories":["Review"],"tags":["Review","Image Compression","Diffusion Models","One-Step Decoding","Fidelity Guidance","Rate Annealing","VAE","Perceptual Quality"],"permalink":"/ai/review/2025-8-8-Steering_One-Step_Diffusion_Model_with_Fidelity-Rich_Decoder_for_Fast_Image_Compression/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-8-RPCANet_Deep_Interpretable_Robust_PCA_for_Sparse_Object_Segmentation","title":"[논문리뷰] RPCANet++: Deep Interpretable Robust PCA for Sparse Object Segmentation","excerpt":"Jian Yang이 [arXiv]에 게시한 'RPCANet++: Deep Interpretable Robust PCA for Sparse Object Segmentation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-08 13:32:22+0900","lastModifiedAt":"2025-08-08 13:32:22+0900","categories":["Review"],"tags":["Review","Robust PCA","Deep Unfolding","Sparse Segmentation","Interpretability","Image Decomposition","Computer Vision"],"permalink":"/ai/review/2025-8-8-RPCANet_Deep_Interpretable_Robust_PCA_for_Sparse_Object_Segmentation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-8-REINA_Regularized_Entropy_Information-Based_Loss_for_Efficient_Simultaneous_Speech_Translation","title":"[논문리뷰] REINA: Regularized Entropy Information-Based Loss for Efficient Simultaneous Speech Translation","excerpt":"Xiao Yu이 [arXiv]에 게시한 'REINA: Regularized Entropy Information-Based Loss for Efficient Simultaneous Speech Translation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-08 13:32:22+0900","lastModifiedAt":"2025-08-08 13:32:22+0900","categories":["Review"],"tags":["Review","Simultaneous Speech Translation","Adaptive Policy","Entropy-based Loss","Mutual Information","Latency-Quality Trade-off","Speech-to-Text Translation","REINA"],"permalink":"/ai/review/2025-8-8-REINA_Regularized_Entropy_Information-Based_Loss_for_Efficient_Simultaneous_Speech_Translation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-8-R-Zero_Self-Evolving_Reasoning_LLM_from_Zero_Data","title":"[논문리뷰] R-Zero: Self-Evolving Reasoning LLM from Zero Data","excerpt":"Zongxia Li이 [arXiv]에 게시한 'R-Zero: Self-Evolving Reasoning LLM from Zero Data' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-08 13:32:22+0900","lastModifiedAt":"2025-08-08 13:32:22+0900","categories":["Review"],"tags":["Review","Self-Evolving LLM","Reinforcement Learning","Curriculum Learning","Reasoning","Large Language Models","Self-Play","Zero-Data Training"],"permalink":"/ai/review/2025-8-8-R-Zero_Self-Evolving_Reasoning_LLM_from_Zero_Data/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-8-PRvL_Quantifying_the_Capabilities_and_Risks_of_Large_Language_Models_for_PII_Redaction","title":"[논문리뷰] PRvL: Quantifying the Capabilities and Risks of Large Language Models for PII Redaction","excerpt":"Prajit Das이 [arXiv]에 게시한 'PRvL: Quantifying the Capabilities and Risks of Large Language Models for PII Redaction' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-08 13:32:22+0900","lastModifiedAt":"2025-08-08 13:32:22+0900","categories":["Review"],"tags":["Review","PII Redaction","Large Language Models","Instruction Tuning","Retrieval-Augmented Generation","Privacy Preservation","Model Evaluation","Cross-Domain Generalization","Open-Source LLMs"],"permalink":"/ai/review/2025-8-8-PRvL_Quantifying_the_Capabilities_and_Risks_of_Large_Language_Models_for_PII_Redaction/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-8-On_the_Generalization_of_SFT_A_Reinforcement_Learning_Perspective_with_Reward_Rectification","title":"[논문리뷰] On the Generalization of SFT: A Reinforcement Learning Perspective with Reward Rectification","excerpt":"Xinyu Ye이 [arXiv]에 게시한 'On the Generalization of SFT: A Reinforcement Learning Perspective with Reward Rectification' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-08 13:32:22+0900","lastModifiedAt":"2025-08-08 13:32:22+0900","categories":["Review"],"tags":["Review","Supervised Fine-Tuning (SFT)","Reinforcement Learning (RL)","Generalization","Reward Rectification","Dynamic Fine-Tuning (DFT)","LLM","Policy Gradient","Mathematical Reasoning"],"permalink":"/ai/review/2025-8-8-On_the_Generalization_of_SFT_A_Reinforcement_Learning_Perspective_with_Reward_Rectification/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-8-MOSEv2_A_More_Challenging_Dataset_for_Video_Object_Segmentation_in_Complex_Scenes","title":"[논문리뷰] MOSEv2: A More Challenging Dataset for Video Object Segmentation in Complex Scenes","excerpt":"Xudong Jiang이 [arXiv]에 게시한 'MOSEv2: A More Challenging Dataset for Video Object Segmentation in Complex Scenes' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-08 13:32:22+0900","lastModifiedAt":"2025-08-08 13:32:22+0900","categories":["Review"],"tags":["Review","Video Object Segmentation","Dataset","Complex Scenes","Benchmark","Object Tracking","Computer Vision","Dataset Challenges"],"permalink":"/ai/review/2025-8-8-MOSEv2_A_More_Challenging_Dataset_for_Video_Object_Segmentation_in_Complex_Scenes/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-8-Marco-Voice_Technical_Report","title":"[논문리뷰] Marco-Voice Technical Report","excerpt":"Qingjuan Li이 [arXiv]에 게시한 'Marco-Voice Technical Report' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-08 13:32:22+0900","lastModifiedAt":"2025-08-08 13:32:22+0900","categories":["Review"],"tags":["Review","Speech Synthesis","Voice Cloning","Emotion Control","Text-to-Speech","Disentanglement","Contrastive Learning","Flow Matching","Emotional Speech Dataset"],"permalink":"/ai/review/2025-8-8-Marco-Voice_Technical_Report/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-8-I_Think_Therefore_I_Am_Under-Qualified_A_Benchmark_for_Evaluating_Linguistic_Shibboleth_Detection_in_LLM_Hiring_Evaluations","title":"[논문리뷰] I Think, Therefore I Am Under-Qualified? A Benchmark for Evaluating Linguistic Shibboleth Detection in LLM Hiring Evaluations","excerpt":"Chirag Shah이 [arXiv]에 게시한 'I Think, Therefore I Am Under-Qualified? A Benchmark for Evaluating Linguistic Shibboleth Detection in LLM Hiring Evaluations' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-08 13:32:22+0900","lastModifiedAt":"2025-08-08 13:32:22+0900","categories":["Review"],"tags":["Review","LLM Bias","Hiring Evaluation","Linguistic Shibboleth","Hedging Language","Fairness","Benchmarking","Sociolinguistics"],"permalink":"/ai/review/2025-8-8-I_Think_Therefore_I_Am_Under-Qualified_A_Benchmark_for_Evaluating_Linguistic_Shibboleth_Detection_in_LLM_Hiring_Evaluations/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-8-InfiAlign_A_Scalable_and_Sample-Efficient_Framework_for_Aligning_LLMs_to_Enhance_Reasoning_Capabilities","title":"[논문리뷰] InfiAlign: A Scalable and Sample-Efficient Framework for Aligning LLMs to Enhance Reasoning Capabilities","excerpt":"Zhijie Sang이 [arXiv]에 게시한 'InfiAlign: A Scalable and Sample-Efficient Framework for Aligning LLMs to Enhance Reasoning Capabilities' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-08 13:32:22+0900","lastModifiedAt":"2025-08-08 13:32:22+0900","categories":["Review"],"tags":["Review","LLM Alignment","Reasoning","Data Curation","Supervised Fine-tuning (SFT)","Direct Preference Optimization (DPO)","Sample Efficiency","Scalability","Multi-dimensional Filtering"],"permalink":"/ai/review/2025-8-8-InfiAlign_A_Scalable_and_Sample-Efficient_Framework_for_Aligning_LLMs_to_Enhance_Reasoning_Capabilities/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-8-I2CR_Intra-_and_Inter-modal_Collaborative_Reflections_for_Multimodal_Entity_Linking","title":"[논문리뷰] I2CR: Intra- and Inter-modal Collaborative Reflections for Multimodal Entity Linking","excerpt":"Chao Wang이 [arXiv]에 게시한 'I2CR: Intra- and Inter-modal Collaborative Reflections for Multimodal Entity Linking' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-08 13:32:22+0900","lastModifiedAt":"2025-08-08 13:32:22+0900","categories":["Review"],"tags":["Review","Multimodal Entity Linking","Large Language Models","Collaborative Reflection","Iterative Reasoning","Visual Information","Text-centric"],"permalink":"/ai/review/2025-8-8-I2CR_Intra-_and_Inter-modal_Collaborative_Reflections_for_Multimodal_Entity_Linking/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-8-Hop_Skip_and_Overthink_Diagnosing_Why_Reasoning_Models_Fumble_during_Multi-Hop_Analysis","title":"[논문리뷰] Hop, Skip, and Overthink: Diagnosing Why Reasoning Models Fumble during Multi-Hop Analysis","excerpt":"Reshmi Ghosh이 [arXiv]에 게시한 'Hop, Skip, and Overthink: Diagnosing Why Reasoning Models Fumble during Multi-Hop Analysis' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-08 13:32:22+0900","lastModifiedAt":"2025-08-08 13:32:22+0900","categories":["Review"],"tags":["Review","Multi-hop Question Answering","Large Language Models","Reasoning Errors","Error Taxonomy","Human Evaluation","Automated Evaluation","Overthinking"],"permalink":"/ai/review/2025-8-8-Hop_Skip_and_Overthink_Diagnosing_Why_Reasoning_Models_Fumble_during_Multi-Hop_Analysis/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-8-Hi3DEval_Advancing_3D_Generation_Evaluation_with_Hierarchical_Validity","title":"[논문리뷰] Hi3DEval: Advancing 3D Generation Evaluation with Hierarchical Validity","excerpt":"Zhibing Li이 [arXiv]에 게시한 'Hi3DEval: Advancing 3D Generation Evaluation with Hierarchical Validity' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-08 13:32:22+0900","lastModifiedAt":"2025-08-08 13:32:22+0900","categories":["Review"],"tags":["Review","3D Generation Evaluation","Hierarchical Evaluation","Material Properties","Multi-Agent Annotation","Hybrid Scoring System","Video-based Evaluation","Part-level Analysis"],"permalink":"/ai/review/2025-8-8-Hi3DEval_Advancing_3D_Generation_Evaluation_with_Hierarchical_Validity/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-8-Genie_Envisioner_A_Unified_World_Foundation_Platform_for_Robotic_Manipulation","title":"[논문리뷰] Genie Envisioner: A Unified World Foundation Platform for Robotic Manipulation","excerpt":"Shengcong Chen이 [arXiv]에 게시한 'Genie Envisioner: A Unified World Foundation Platform for Robotic Manipulation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-08 13:32:22+0900","lastModifiedAt":"2025-08-08 13:32:22+0900","categories":["Review"],"tags":["Review","Robotic Manipulation","World Model","Video Generation","Diffusion Model","Embodied AI","Foundation Model","Robotics Simulation","Policy Learning"],"permalink":"/ai/review/2025-8-8-Genie_Envisioner_A_Unified_World_Foundation_Platform_for_Robotic_Manipulation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-8-Evaluating_Synthesizing_and_Enhancing_for_Customer_Support_Conversation","title":"[논문리뷰] Evaluating, Synthesizing, and Enhancing for Customer Support Conversation","excerpt":"Feng Chen이 [arXiv]에 게시한 'Evaluating, Synthesizing, and Enhancing for Customer Support Conversation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-08 13:32:22+0900","lastModifiedAt":"2025-08-08 13:32:22+0900","categories":["Review"],"tags":["Review","Customer Support","Dialogue Generation","Large Language Models","Role-Playing","COPC Framework","Synthetic Data","Strategy Prediction","Empathetic AI"],"permalink":"/ai/review/2025-8-8-Evaluating_Synthesizing_and_Enhancing_for_Customer_Support_Conversation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-8-Dont_Overthink_It_A_Survey_of_Efficient_R1-style_Large_Reasoning_Models","title":"[논문리뷰] Don't Overthink It: A Survey of Efficient R1-style Large Reasoning Models","excerpt":"Fangzhou Yao이 [arXiv]에 게시한 'Don't Overthink It: A Survey of Efficient R1-style Large Reasoning Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-08 13:32:22+0900","lastModifiedAt":"2025-08-08 13:32:22+0900","categories":["Review"],"tags":["Review","Large Reasoning Models","Efficient Reasoning","Chain-of-Thought","Model Optimization","Model Collaboration","Overthinking Problem","LLM Efficiency"],"permalink":"/ai/review/2025-8-8-Dont_Overthink_It_A_Survey_of_Efficient_R1-style_Large_Reasoning_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-8-DeepPHY_Benchmarking_Agentic_VLMs_on_Physical_Reasoning","title":"[논문리뷰] DeepPHY: Benchmarking Agentic VLMs on Physical Reasoning","excerpt":"Ziming Wang이 [arXiv]에 게시한 'DeepPHY: Benchmarking Agentic VLMs on Physical Reasoning' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-08 13:32:22+0900","lastModifiedAt":"2025-08-08 13:32:22+0900","categories":["Review"],"tags":["Review","Vision Language Models (VLMs)","Agentic AI","Physical Reasoning","Benchmark","Simulation Environments","Action Planning","Interactive AI"],"permalink":"/ai/review/2025-8-8-DeepPHY_Benchmarking_Agentic_VLMs_on_Physical_Reasoning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-8-CoAct-1_Computer-using_Agents_with_Coding_as_Actions","title":"[논문리뷰] CoAct-1: Computer-using Agents with Coding as Actions","excerpt":"Taiwei Shi이 [arXiv]에 게시한 'CoAct-1: Computer-using Agents with Coding as Actions' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-08 13:32:22+0900","lastModifiedAt":"2025-08-08 13:32:22+0900","categories":["Review"],"tags":["Review","AI Agent","Multi-agent System","GUI Automation","Programmatic Control","Code Generation","OSWorld Benchmark","Hybrid AI"],"permalink":"/ai/review/2025-8-8-CoAct-1_Computer-using_Agents_with_Coding_as_Actions/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-8-Can_Large_Multimodal_Models_Actively_Recognize_Faulty_Inputs_A_Systematic_Evaluation_Framework_of_Their_Input_Scrutiny_Ability","title":"[논문리뷰] Can Large Multimodal Models Actively Recognize Faulty Inputs? A Systematic Evaluation Framework of Their Input Scrutiny Ability","excerpt":"Yuan Wu이 [arXiv]에 게시한 'Can Large Multimodal Models Actively Recognize Faulty Inputs? A Systematic Evaluation Framework of Their Input Scrutiny Ability' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-08 13:32:22+0900","lastModifiedAt":"2025-08-08 13:32:22+0900","categories":["Review"],"tags":["Review","Large Multimodal Models","Input Scrutiny","Error Detection","Faulty Inputs","Evaluation Framework","Modality Preference","Cross-Modal Inconsistency"],"permalink":"/ai/review/2025-8-8-Can_Large_Multimodal_Models_Actively_Recognize_Faulty_Inputs_A_Systematic_Evaluation_Framework_of_Their_Input_Scrutiny_Ability/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-8-Are_We_on_the_Right_Way_for_Assessing_Document_Retrieval-Augmented_Generation","title":"[논문리뷰] Are We on the Right Way for Assessing Document Retrieval-Augmented Generation?","excerpt":"Junjie Yang이 [arXiv]에 게시한 'Are We on the Right Way for Assessing Document Retrieval-Augmented Generation?' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-08 13:32:22+0900","lastModifiedAt":"2025-08-08 13:32:22+0900","categories":["Review"],"tags":["Review","Retrieval-Augmented Generation","Multimodal LLMs","Benchmark Evaluation","Document Understanding","Multi-hop Reasoning","Information Retrieval","Evaluation Dataset"],"permalink":"/ai/review/2025-8-8-Are_We_on_the_Right_Way_for_Assessing_Document_Retrieval-Augmented_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-8-Are_Todays_LLMs_Ready_to_Explain_Well-Being_Concepts","title":"[논문리뷰] Are Today's LLMs Ready to Explain Well-Being Concepts?","excerpt":"Huan Liu이 [arXiv]에 게시한 'Are Today's LLMs Ready to Explain Well-Being Concepts?' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-08 13:32:22+0900","lastModifiedAt":"2025-08-08 13:32:22+0900","categories":["Review"],"tags":["Review","Large Language Models","Well-being Concepts","LLM Evaluation","Principle-Guided Evaluation","LLM-as-a-Judge","Supervised Fine-Tuning (SFT)","Direct Preference Optimization (DPO)","Explanation Generation"],"permalink":"/ai/review/2025-8-8-Are_Todays_LLMs_Ready_to_Explain_Well-Being_Concepts/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-7-Web-CogReasoner_Towards_Knowledge-Induced_Cognitive_Reasoning_for_Web_Agents","title":"[논문리뷰] Web-CogReasoner: Towards Knowledge-Induced Cognitive Reasoning for Web Agents","excerpt":"Xinyu Yang이 [arXiv]에 게시한 'Web-CogReasoner: Towards Knowledge-Induced Cognitive Reasoning for Web Agents' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-07 13:38:21+0900","lastModifiedAt":"2025-08-07 13:38:21+0900","categories":["Review"],"tags":["Review","Web Agent","Cognitive Reasoning","Knowledge-Induced","Large Multimodal Models (LMMs)","Bloom's Taxonomy","Chain-of-Thought (CoT)","Web-CogDataset","Web-CogBench"],"permalink":"/ai/review/2025-8-7-Web-CogReasoner_Towards_Knowledge-Induced_Cognitive_Reasoning_for_Web_Agents/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-7-Training_Long-Context_Multi-Turn_Software_Engineering_Agents_with_Reinforcement_Learning","title":"[논문리뷰] Training Long-Context, Multi-Turn Software Engineering Agents with Reinforcement Learning","excerpt":"Maksim Nekrashevich이 [arXiv]에 게시한 'Training Long-Context, Multi-Turn Software Engineering Agents with Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-07 13:38:21+0900","lastModifiedAt":"2025-08-07 13:38:21+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","Large Language Models","Software Engineering","Multi-Turn Interaction","Long Context","DAPO","Autonomous Agents","SWE-BENCH"],"permalink":"/ai/review/2025-8-7-Training_Long-Context_Multi-Turn_Software_Engineering_Agents_with_Reinforcement_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-7-The_Cow_of_Rembrandt_-_Analyzing_Artistic_Prompt_Interpretation_in_Text-to-Image_Models","title":"[논문리뷰] The Cow of Rembrandt - Analyzing Artistic Prompt Interpretation in Text-to-Image Models","excerpt":"Elisabetta Rocchetti이 [arXiv]에 게시한 'The Cow of Rembrandt - Analyzing Artistic Prompt Interpretation in Text-to-Image Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-07 13:38:21+0900","lastModifiedAt":"2025-08-07 13:38:21+0900","categories":["Review"],"tags":["Review","Text-to-Image Generation","Diffusion Models","Cross-Attention Analysis","Content-Style Disentanglement","Artistic Style Transfer","Explainable AI","SDXL"],"permalink":"/ai/review/2025-8-7-The_Cow_of_Rembrandt_-_Analyzing_Artistic_Prompt_Interpretation_in_Text-to-Image_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-7-Sotopia-RL_Reward_Design_for_Social_Intelligence","title":"[논문리뷰] Sotopia-RL: Reward Design for Social Intelligence","excerpt":"Keyang Xuan이 [arXiv]에 게시한 'Sotopia-RL: Reward Design for Social Intelligence' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-07 13:38:21+0900","lastModifiedAt":"2025-08-07 13:38:21+0900","categories":["Review"],"tags":["Review","Social Intelligence","Reinforcement Learning","Reward Design","Large Language Models","Utterance-level Rewards","Multi-dimensional Rewards","Partial Observability","SOTOPIA"],"permalink":"/ai/review/2025-8-7-Sotopia-RL_Reward_Design_for_Social_Intelligence/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-7-SonicMaster_Towards_Controllable_All-in-One_Music_Restoration_and_Mastering","title":"[논문리뷰] SonicMaster: Towards Controllable All-in-One Music Restoration and Mastering","excerpt":"Ambuj Mehrish이 [arXiv]에 게시한 'SonicMaster: Towards Controllable All-in-One Music Restoration and Mastering' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-07 13:38:21+0900","lastModifiedAt":"2025-08-07 13:38:21+0900","categories":["Review"],"tags":["Review","Music Restoration","Audio Mastering","Generative Models","Flow Matching","Text-to-Audio","Audio Quality Enhancement","Multi-task Learning","Dataset Creation"],"permalink":"/ai/review/2025-8-7-SonicMaster_Towards_Controllable_All-in-One_Music_Restoration_and_Mastering/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-7-Sel3DCraft_Interactive_Visual_Prompts_for_User-Friendly_Text-to-3D_Generation","title":"[논문리뷰] Sel3DCraft: Interactive Visual Prompts for User-Friendly Text-to-3D Generation","excerpt":"Hao Huang이 [arXiv]에 게시한 'Sel3DCraft: Interactive Visual Prompts for User-Friendly Text-to-3D Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-07 13:38:21+0900","lastModifiedAt":"2025-08-07 13:38:21+0900","categories":["Review"],"tags":["Review","Text-to-3D Generation","Prompt Engineering","Visual Analytics","Human-Computer Interaction","Multi-modal Large Language Models","3D Model Evaluation"],"permalink":"/ai/review/2025-8-7-Sel3DCraft_Interactive_Visual_Prompts_for_User-Friendly_Text-to-3D_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-7-SEAgent_Self-Evolving_Computer_Use_Agent_with_Autonomous_Learning_from_Experience","title":"[논문리뷰] SEAgent: Self-Evolving Computer Use Agent with Autonomous Learning from Experience","excerpt":"Xiaoyi Dong이 [arXiv]에 게시한 'SEAgent: Self-Evolving Computer Use Agent with Autonomous Learning from Experience' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-07 13:38:21+0900","lastModifiedAt":"2025-08-07 13:38:21+0900","categories":["Review"],"tags":["Review","Computer Use Agent","Self-Evolving","Reinforcement Learning","Curriculum Learning","Vision-Language Models","Experiential Learning","Specialist-to-Generalist"],"permalink":"/ai/review/2025-8-7-SEAgent_Self-Evolving_Computer_Use_Agent_with_Autonomous_Learning_from_Experience/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-7-Sculptor_Empowering_LLMs_with_Cognitive_Agency_via_Active_Context_Management","title":"[논문리뷰] Sculptor: Empowering LLMs with Cognitive Agency via Active Context Management","excerpt":"Yunxin Liu이 [arXiv]에 게시한 'Sculptor: Empowering LLMs with Cognitive Agency via Active Context Management' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-07 13:38:21+0900","lastModifiedAt":"2025-08-07 13:38:21+0900","categories":["Review"],"tags":["Review","Large Language Models","Active Context Management","Proactive Interference","Tool Augmentation","Working Memory","Context Curation","Long Context"],"permalink":"/ai/review/2025-8-7-Sculptor_Empowering_LLMs_with_Cognitive_Agency_via_Active_Context_Management/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-7-RL-PLUS_Countering_Capability_Boundary_Collapse_of_LLMs_in_Reinforcement_Learning_with_Hybrid-policy_Optimization","title":"[논문리뷰] RL-PLUS: Countering Capability Boundary Collapse of LLMs in Reinforcement Learning with Hybrid-policy Optimization","excerpt":"Kechi Zhang이 [arXiv]에 게시한 'RL-PLUS: Countering Capability Boundary Collapse of LLMs in Reinforcement Learning with Hybrid-policy Optimization' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-07 13:38:21+0900","lastModifiedAt":"2025-08-07 13:38:21+0900","categories":["Review"],"tags":["Review","Large Language Models","Reinforcement Learning","Capability Collapse","Hybrid Policy Optimization","Multiple Importance Sampling","Exploration","Math Reasoning","Out-of-Distribution"],"permalink":"/ai/review/2025-8-7-RL-PLUS_Countering_Capability_Boundary_Collapse_of_LLMs_in_Reinforcement_Learning_with_Hybrid-policy_Optimization/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-7-Reasoning_Language_Models_for_Root_Cause_Analysis_in_5G_Wireless_Networks","title":"[논문리뷰] Reasoning Language Models for Root Cause Analysis in 5G Wireless Networks","excerpt":"Haozhe Zhang이 [arXiv]에 게시한 'Reasoning Language Models for Root Cause Analysis in 5G Wireless Networks' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-07 13:38:21+0900","lastModifiedAt":"2025-08-07 13:38:21+0900","categories":["Review"],"tags":["Review","Root Cause Analysis","Large Language Models","5G Wireless Networks","Supervised Fine-Tuning","Reinforcement Learning","Chain-of-Thought","TeleLogs Dataset"],"permalink":"/ai/review/2025-8-7-Reasoning_Language_Models_for_Root_Cause_Analysis_in_5G_Wireless_Networks/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-7-Position_The_Current_AI_Conference_Model_is_Unsustainable_Diagnosing_the_Crisis_of_Centralized_AI_Conference","title":"[논문리뷰] Position: The Current AI Conference Model is Unsustainable! Diagnosing the Crisis of Centralized AI Conference","excerpt":"Jiaying Wu이 [arXiv]에 게시한 'Position: The Current AI Conference Model is Unsustainable! Diagnosing the Crisis of Centralized AI Conference' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-07 13:38:21+0900","lastModifiedAt":"2025-08-07 13:38:21+0900","categories":["Review"],"tags":["Review","AI Conferences","Sustainability","Peer Review","Community Building","Environmental Impact","Mental Health","Centralized Model","Decentralized Model"],"permalink":"/ai/review/2025-8-7-Position_The_Current_AI_Conference_Model_is_Unsustainable_Diagnosing_the_Crisis_of_Centralized_AI_Conference/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-7-OpenMed_NER_Open-Source_Domain-Adapted_State-of-the-Art_Transformers_for_Biomedical_NER_Across_12_Public_Datasets","title":"[논문리뷰] OpenMed NER: Open-Source, Domain-Adapted State-of-the-Art Transformers for Biomedical NER Across 12 Public Datasets","excerpt":"MaziyarPanahi이 [arXiv]에 게시한 'OpenMed NER: Open-Source, Domain-Adapted State-of-the-Art Transformers for Biomedical NER Across 12 Public Datasets' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-07 13:38:21+0900","lastModifiedAt":"2025-08-07 13:38:21+0900","categories":["Review"],"tags":["Review","Biomedical NER","Transformer","Domain Adaptation","LoRA","Open-Source","Named Entity Recognition","Healthcare AI"],"permalink":"/ai/review/2025-8-7-OpenMed_NER_Open-Source_Domain-Adapted_State-of-the-Art_Transformers_for_Biomedical_NER_Across_12_Public_Datasets/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-7-MiDashengLM_Efficient_Audio_Understanding_with_General_Audio_Captions","title":"[논문리뷰] MiDashengLM: Efficient Audio Understanding with General Audio Captions","excerpt":"Yadong Niu이 [arXiv]에 게시한 'MiDashengLM: Efficient Audio Understanding with General Audio Captions' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-07 13:38:21+0900","lastModifiedAt":"2025-08-07 13:38:21+0900","categories":["Review"],"tags":["Review","Audio-Language Model","General Audio Captions","Audio Understanding","Speech Recognition","Efficient Inference","Public Datasets","Multimodality","Data Curation"],"permalink":"/ai/review/2025-8-7-MiDashengLM_Efficient_Audio_Understanding_with_General_Audio_Captions/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-7-Light-IF_Endowing_LLMs_with_Generalizable_Reasoning_via_Preview_and_Self-Checking_for_Complex_Instruction_Following","title":"[논문리뷰] Light-IF: Endowing LLMs with Generalizable Reasoning via Preview and Self-Checking for Complex Instruction Following","excerpt":"Liang Xu이 [arXiv]에 게시한 'Light-IF: Endowing LLMs with Generalizable Reasoning via Preview and Self-Checking for Complex Instruction Following' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-07 13:38:21+0900","lastModifiedAt":"2025-08-07 13:38:21+0900","categories":["Review"],"tags":["Review","LLMs","Instruction Following","Reasoning","Reinforcement Learning","Supervised Fine-tuning","Entropy Regularization","Self-Checking","Previewing"],"permalink":"/ai/review/2025-8-7-Light-IF_Endowing_LLMs_with_Generalizable_Reasoning_via_Preview_and_Self-Checking_for_Complex_Instruction_Following/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-7-LeanK_Learnable_K_Cache_Channel_Pruning_for_Efficient_Decoding","title":"[논문리뷰] LeanK: Learnable K Cache Channel Pruning for Efficient Decoding","excerpt":"Yuqing Yang이 [arXiv]에 게시한 'LeanK: Learnable K Cache Channel Pruning for Efficient Decoding' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-07 13:38:21+0900","lastModifiedAt":"2025-08-07 13:38:21+0900","categories":["Review"],"tags":["Review","LLM","KV Cache Optimization","Model Pruning","Efficient Decoding","Memory Optimization","Static Sparsity","Transformer"],"permalink":"/ai/review/2025-8-7-LeanK_Learnable_K_Cache_Channel_Pruning_for_Efficient_Decoding/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-7-LaTCoder_Converting_Webpage_Design_to_Code_with_Layout-as-Thought","title":"[논문리뷰] LaTCoder: Converting Webpage Design to Code with Layout-as-Thought","excerpt":"Tianpeng Lv이 [arXiv]에 게시한 'LaTCoder: Converting Webpage Design to Code with Layout-as-Thought' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-07 13:38:21+0900","lastModifiedAt":"2025-08-07 13:38:21+0900","categories":["Review"],"tags":["Review","Design-to-Code","Webpage Generation","Multimodal Large Language Models (MLLMs)","Layout Preservation","Chain-of-Thought (CoT)","UI Automation","Code Generation"],"permalink":"/ai/review/2025-8-7-LaTCoder_Converting_Webpage_Design_to_Code_with_Layout-as-Thought/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-7-Is_Chain-of-Thought_Reasoning_of_LLMs_a_Mirage_A_Data_Distribution_Lens","title":"[논문리뷰] Is Chain-of-Thought Reasoning of LLMs a Mirage? A Data Distribution Lens","excerpt":"Zhen Tan이 [arXiv]에 게시한 'Is Chain-of-Thought Reasoning of LLMs a Mirage? A Data Distribution Lens' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-07 13:38:21+0900","lastModifiedAt":"2025-08-07 13:38:21+0900","categories":["Review"],"tags":["Review","Chain-of-Thought","LLMs","OOD Generalization","Data Distribution Shift","Reasoning","Pattern Matching","DataAlchemy"],"permalink":"/ai/review/2025-8-7-Is_Chain-of-Thought_Reasoning_of_LLMs_a_Mirage_A_Data_Distribution_Lens/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-7-IFDECORATOR_Wrapping_Instruction_Following_Reinforcement_Learning_with_Verifiable_Rewards","title":"[논문리뷰] IFDECORATOR: Wrapping Instruction Following Reinforcement Learning with Verifiable Rewards","excerpt":"Ling-I Wu이 [arXiv]에 게시한 'IFDECORATOR: Wrapping Instruction Following Reinforcement Learning with Verifiable Rewards' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-07 13:38:21+0900","lastModifiedAt":"2025-08-07 13:38:21+0900","categories":["Review"],"tags":["Review","Instruction Following","Reinforcement Learning","Reward Hacking","LLMs","Curriculum Learning","Data Flywheel","Verifiable Rewards"],"permalink":"/ai/review/2025-8-7-IFDECORATOR_Wrapping_Instruction_Following_Reinforcement_Learning_with_Verifiable_Rewards/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-7-IAUNet_Instance-Aware_U-Net","title":"[논문리뷰] IAUNet: Instance-Aware U-Net","excerpt":"Dmytro Fishman이 [arXiv]에 게시한 'IAUNet: Instance-Aware U-Net' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-07 13:38:21+0900","lastModifiedAt":"2025-08-07 13:38:21+0900","categories":["Review"],"tags":["Review","Instance Segmentation","U-Net","Query-based Model","Transformer Decoder","Biomedical Imaging","Cell Segmentation","Deep Learning"],"permalink":"/ai/review/2025-8-7-IAUNet_Instance-Aware_U-Net/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-7-HPSv3_Towards_Wide-Spectrum_Human_Preference_Score","title":"[논문리뷰] HPSv3: Towards Wide-Spectrum Human Preference Score","excerpt":"Hongsheng Li이 [arXiv]에 게시한 'HPSv3: Towards Wide-Spectrum Human Preference Score' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-07 13:38:21+0900","lastModifiedAt":"2025-08-07 13:38:21+0900","categories":["Review"],"tags":["Review","Human Preference Score","Text-to-Image Generation","Image Evaluation","Vision-Language Models (VLMs)","Uncertainty-Aware Ranking Loss","Dataset","Iterative Refinement","Chain-of-Thought"],"permalink":"/ai/review/2025-8-7-HPSv3_Towards_Wide-Spectrum_Human_Preference_Score/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-7-Gaussian_Variation_Field_Diffusion_for_High-fidelity_Video-to-4D_Synthesis","title":"[논문리뷰] Gaussian Variation Field Diffusion for High-fidelity Video-to-4D Synthesis","excerpt":"Feng Zhao이 [arXiv]에 게시한 'Gaussian Variation Field Diffusion for High-fidelity Video-to-4D Synthesis' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-07 13:38:21+0900","lastModifiedAt":"2025-08-07 13:38:21+0900","categories":["Review"],"tags":["Review","4D Generation","Video-to-3D Synthesis","Gaussian Splatting","Diffusion Models","Latent Space Modeling","Variational Autoencoder","Temporal Coherence"],"permalink":"/ai/review/2025-8-7-Gaussian_Variation_Field_Diffusion_for_High-fidelity_Video-to-4D_Synthesis/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-7-EVOC2RUST_A_Skeleton-guided_Framework_for_Project-Level_C-to-Rust_Translation","title":"[논문리뷰] EVOC2RUST: A Skeleton-guided Framework for Project-Level C-to-Rust Translation","excerpt":"Dong Chen이 [arXiv]에 게시한 'EVOC2RUST: A Skeleton-guided Framework for Project-Level C-to-Rust Translation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-07 13:38:21+0900","lastModifiedAt":"2025-08-07 13:38:21+0900","categories":["Review"],"tags":["Review","C-to-Rust Conversion","Project-Level Translation","Large Language Models","Code Synthesis","Memory Safety","Software Migration","Hybrid Translation"],"permalink":"/ai/review/2025-8-7-EVOC2RUST_A_Skeleton-guided_Framework_for_Project-Level_C-to-Rust_Translation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-7-Enhancing_Vision-Language_Model_Training_with_Reinforcement_Learning_in_Synthetic_Worlds_for_Real-World_Success","title":"[논문리뷰] Enhancing Vision-Language Model Training with Reinforcement Learning in Synthetic Worlds for Real-World Success","excerpt":"Ruslan Rakhimov이 [arXiv]에 게시한 'Enhancing Vision-Language Model Training with Reinforcement Learning in Synthetic Worlds for Real-World Success' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-07 13:38:21+0900","lastModifiedAt":"2025-08-07 13:38:21+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","Vision-Language Models","Synthetic Worlds","Transfer Learning","PPO","Actor-Critic","Embodied AI"],"permalink":"/ai/review/2025-8-7-Enhancing_Vision-Language_Model_Training_with_Reinforcement_Learning_in_Synthetic_Worlds_for_Real-World_Success/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-7-Efficient_Agents_Building_Effective_Agents_While_Reducing_Cost","title":"[논문리뷰] Efficient Agents: Building Effective Agents While Reducing Cost","excerpt":"Yue Hou이 [arXiv]에 게시한 'Efficient Agents: Building Effective Agents While Reducing Cost' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-07 13:38:21+0900","lastModifiedAt":"2025-08-07 13:38:21+0900","categories":["Review"],"tags":["Review","LLM Agents","Cost Efficiency","Performance-Cost Trade-off","Agent Frameworks","GAIA Benchmark","Optimization","Resource Management"],"permalink":"/ai/review/2025-8-7-Efficient_Agents_Building_Effective_Agents_While_Reducing_Cost/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-7-DreamVVT_Mastering_Realistic_Video_Virtual_Try-On_in_the_Wild_via_a_Stage-Wise_Diffusion_Transformer_Framework","title":"[논문리뷰] DreamVVT: Mastering Realistic Video Virtual Try-On in the Wild via a Stage-Wise Diffusion Transformer Framework","excerpt":"Chao Liang이 [arXiv]에 게시한 'DreamVVT: Mastering Realistic Video Virtual Try-On in the Wild via a Stage-Wise Diffusion Transformer Framework' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-07 13:38:21+0900","lastModifiedAt":"2025-08-07 13:38:21+0900","categories":["Review"],"tags":["Review","Video Virtual Try-On","Diffusion Transformers","Stage-Wise Framework","Vision-Language Models","LoRA","Temporal Consistency","Garment Preservation"],"permalink":"/ai/review/2025-8-7-DreamVVT_Mastering_Realistic_Video_Virtual_Try-On_in_the_Wild_via_a_Stage-Wise_Diffusion_Transformer_Framework/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-7-CoTox_Chain-of-Thought-Based_Molecular_Toxicity_Reasoning_and_Prediction","title":"[논문리뷰] CoTox: Chain-of-Thought-Based Molecular Toxicity Reasoning and Prediction","excerpt":"Donghyeon Lee이 [arXiv]에 게시한 'CoTox: Chain-of-Thought-Based Molecular Toxicity Reasoning and Prediction' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-07 13:38:21+0900","lastModifiedAt":"2025-08-07 13:38:21+0900","categories":["Review"],"tags":["Review","Toxicity Prediction","Large Language Model","Chain-of-Thought","Drug Development","Cheminformatics","Interpretable AI","IUPAC Nomenclature"],"permalink":"/ai/review/2025-8-7-CoTox_Chain-of-Thought-Based_Molecular_Toxicity_Reasoning_and_Prediction/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-7-C3D-AD_Toward_Continual_3D_Anomaly_Detection_via_Kernel_Attention_with_Learnable_Advisor","title":"[논문리뷰] C3D-AD: Toward Continual 3D Anomaly Detection via Kernel Attention with Learnable Advisor","excerpt":"Jinbao Wang이 [arXiv]에 게시한 'C3D-AD: Toward Continual 3D Anomaly Detection via Kernel Attention with Learnable Advisor' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-07 13:38:21+0900","lastModifiedAt":"2025-08-07 13:38:21+0900","categories":["Review"],"tags":["Review","3D Anomaly Detection","Continual Learning","Kernel Attention","Learnable Advisor","Parameter Perturbation","Point Cloud","Industrial AI"],"permalink":"/ai/review/2025-8-7-C3D-AD_Toward_Continual_3D_Anomaly_Detection_via_Kernel_Attention_with_Learnable_Advisor/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-7-A_Coarse-to-Fine_Approach_to_Multi-Modality_3D_Occupancy_Grounding","title":"[논문리뷰] A Coarse-to-Fine Approach to Multi-Modality 3D Occupancy Grounding","excerpt":"Jianke Zhu이 [arXiv]에 게시한 'A Coarse-to-Fine Approach to Multi-Modality 3D Occupancy Grounding' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-07 13:38:21+0900","lastModifiedAt":"2025-08-07 13:38:21+0900","categories":["Review"],"tags":["Review","3D Occupancy Grounding","Multi-modal Learning","Natural Language Understanding","Autonomous Driving","Voxel-based Prediction","Benchmark Dataset","Coarse-to-Fine"],"permalink":"/ai/review/2025-8-7-A_Coarse-to-Fine_Approach_to_Multi-Modality_3D_Occupancy_Grounding/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-7-Agent_Lightning_Train_ANY_AI_Agents_with_Reinforcement_Learning","title":"[논문리뷰] Agent Lightning: Train ANY AI Agents with Reinforcement Learning","excerpt":"Zilong Wang이 [arXiv]에 게시한 'Agent Lightning: Train ANY AI Agents with Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-07 13:38:21+0900","lastModifiedAt":"2025-08-07 13:38:21+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","Large Language Models","AI Agents","Framework","Markov Decision Process","Hierarchical RL","Training-Agent Disaggregation","Observability"],"permalink":"/ai/review/2025-8-7-Agent_Lightning_Train_ANY_AI_Agents_with_Reinforcement_Learning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-6-TRACEALIGN_--_Tracing_the_Drift_Attributing_Alignment_Failures_to_Training-Time_Belief_Sources_in_LLMs","title":"[논문리뷰] TRACEALIGN -- Tracing the Drift: Attributing Alignment Failures to Training-Time Belief Sources in LLMs","excerpt":"Aman Chadha이 [arXiv]에 게시한 'TRACEALIGN -- Tracing the Drift: Attributing Alignment Failures to Training-Time Belief Sources in LLMs' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-06 13:46:36+0900","lastModifiedAt":"2025-08-06 13:46:36+0900","categories":["Review"],"tags":["Review","LLM Alignment","Alignment Drift","Training Data Provenance","Belief Conflict Index (BCI)","Suffix Array","Safety Interventions","Reinforcement Learning from Human Feedback","Explainable AI"],"permalink":"/ai/review/2025-8-6-TRACEALIGN_--_Tracing_the_Drift_Attributing_Alignment_Failures_to_Training-Time_Belief_Sources_in_LLMs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-6-Tool-integrated_Reinforcement_Learning_for_Repo_Deep_Search","title":"[논문리뷰] Tool-integrated Reinforcement Learning for Repo Deep Search","excerpt":"Yanzhen Zou이 [arXiv]에 게시한 'Tool-integrated Reinforcement Learning for Repo Deep Search' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-06 13:46:36+0900","lastModifiedAt":"2025-08-06 13:46:36+0900","categories":["Review"],"tags":["Review","Issue Localization","Large Language Models (LLMs)","Reinforcement Learning (RL)","Supervised Fine-tuning (SFT)","Tool-integrated Agents","Software Engineering","Code Search"],"permalink":"/ai/review/2025-8-6-Tool-integrated_Reinforcement_Learning_for_Repo_Deep_Search/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-6-Skywork_UniPic_Unified_Autoregressive_Modeling_for_Visual_Understanding_and_Generation","title":"[논문리뷰] Skywork UniPic: Unified Autoregressive Modeling for Visual Understanding and Generation","excerpt":"Tianyidan Xie이 [arXiv]에 게시한 'Skywork UniPic: Unified Autoregressive Modeling for Visual Understanding and Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-06 13:46:36+0900","lastModifiedAt":"2025-08-06 13:46:36+0900","categories":["Review"],"tags":["Review","Autoregressive Models","Multimodal AI","Image Generation","Image Editing","Visual Understanding","Unified Architecture","Parameter Efficiency"],"permalink":"/ai/review/2025-8-6-Skywork_UniPic_Unified_Autoregressive_Modeling_for_Visual_Understanding_and_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-6-Seed_Diffusion_A_Large-Scale_Diffusion_Language_Model_with_High-Speed_Inference","title":"[논문리뷰] Seed Diffusion: A Large-Scale Diffusion Language Model with High-Speed Inference","excerpt":"Fan Xia이 [arXiv]에 게시한 'Seed Diffusion: A Large-Scale Diffusion Language Model with High-Speed Inference' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-06 13:46:36+0900","lastModifiedAt":"2025-08-06 13:46:36+0900","categories":["Review"],"tags":["Review","Diffusion Models","Language Models","Code Generation","Non-Autoregressive Inference","High-Speed Inference","Discrete Diffusion","LLM Inference"],"permalink":"/ai/review/2025-8-6-Seed_Diffusion_A_Large-Scale_Diffusion_Language_Model_with_High-Speed_Inference/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-6-Multi-human_Interactive_Talking_Dataset","title":"[논문리뷰] Multi-human Interactive Talking Dataset","excerpt":"Mike Zheng Shou이 [arXiv]에 게시한 'Multi-human Interactive Talking Dataset' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-06 13:46:36+0900","lastModifiedAt":"2025-08-06 13:46:36+0900","categories":["Review"],"tags":["Review","Multi-human Video Generation","Interactive Talking","Dataset","Audio-driven Animation","Pose Control","Speech Interaction","Diffusion Models"],"permalink":"/ai/review/2025-8-6-Multi-human_Interactive_Talking_Dataset/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-6-LongVie_Multimodal-Guided_Controllable_Ultra-Long_Video_Generation","title":"[논문리뷰] LongVie: Multimodal-Guided Controllable Ultra-Long Video Generation","excerpt":"Chenyang Si이 [arXiv]에 게시한 'LongVie: Multimodal-Guided Controllable Ultra-Long Video Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-06 13:46:36+0900","lastModifiedAt":"2025-08-06 13:46:36+0900","categories":["Review"],"tags":["Review","Ultra-long Video Generation","Multimodal Guidance","Controllable Video Generation","Diffusion Models","Temporal Consistency","Visual Quality","Autoregressive Generation","Degradation-aware Training"],"permalink":"/ai/review/2025-8-6-LongVie_Multimodal-Guided_Controllable_Ultra-Long_Video_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-6-LiveMCPBench_Can_Agents_Navigate_an_Ocean_of_MCP_Tools","title":"[논문리뷰] LiveMCPBench: Can Agents Navigate an Ocean of MCP Tools?","excerpt":"Yaojie Lu이 [arXiv]에 게시한 'LiveMCPBench: Can Agents Navigate an Ocean of MCP Tools?' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-06 13:46:36+0900","lastModifiedAt":"2025-08-06 13:46:36+0900","categories":["Review"],"tags":["Review","LLM Agent","Tool-use","MCP","Benchmark","Large-scale","Real-world tasks","Automated Evaluation","Meta-tool-learning"],"permalink":"/ai/review/2025-8-6-LiveMCPBench_Can_Agents_Navigate_an_Ocean_of_MCP_Tools/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-6-LAMIC_Layout-Aware_Multi-Image_Composition_via_Scalability_of_Multimodal_Diffusion_Transformer","title":"[논문리뷰] LAMIC: Layout-Aware Multi-Image Composition via Scalability of Multimodal Diffusion Transformer","excerpt":"Shunyu Yao이 [arXiv]에 게시한 'LAMIC: Layout-Aware Multi-Image Composition via Scalability of Multimodal Diffusion Transformer' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-06 13:46:36+0900","lastModifiedAt":"2025-08-06 13:46:36+0900","categories":["Review"],"tags":["Review","Multi-Image Composition","Layout Control","Diffusion Models","Transformer","Attention Mechanisms","Training-Free","Zero-Shot Generalization"],"permalink":"/ai/review/2025-8-6-LAMIC_Layout-Aware_Multi-Image_Composition_via_Scalability_of_Multimodal_Diffusion_Transformer/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-6-Goedel-Prover-V2_Scaling_Formal_Theorem_Proving_with_Scaffolded_Data_Synthesis_and_Self-Correction","title":"[논문리뷰] Goedel-Prover-V2: Scaling Formal Theorem Proving with Scaffolded Data Synthesis and Self-Correction","excerpt":"Jui-Hui Chung이 [arXiv]에 게시한 'Goedel-Prover-V2: Scaling Formal Theorem Proving with Scaffolded Data Synthesis and Self-Correction' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-06 13:46:36+0900","lastModifiedAt":"2025-08-06 13:46:36+0900","categories":["Review"],"tags":["Review","Automated Theorem Proving","Formal Verification","Language Models","Self-Correction","Data Synthesis","Reinforcement Learning","Model Averaging","Lean"],"permalink":"/ai/review/2025-8-6-Goedel-Prover-V2_Scaling_Formal_Theorem_Proving_with_Scaffolded_Data_Synthesis_and_Self-Correction/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-6-CRINN_Contrastive_Reinforcement_Learning_for_Approximate_Nearest_Neighbor_Search","title":"[논문리뷰] CRINN: Contrastive Reinforcement Learning for Approximate Nearest Neighbor Search","excerpt":"Jiwei Li이 [arXiv]에 게시한 'CRINN: Contrastive Reinforcement Learning for Approximate Nearest Neighbor Search' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-06 13:46:36+0900","lastModifiedAt":"2025-08-06 13:46:36+0900","categories":["Review"],"tags":["Review","Approximate Nearest Neighbor Search","Reinforcement Learning","Large Language Models","Code Optimization","HNSW","Retrieval-Augmented Generation","Contrastive Learning"],"permalink":"/ai/review/2025-8-6-CRINN_Contrastive_Reinforcement_Learning_for_Approximate_Nearest_Neighbor_Search/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-6-CompassVerifier_A_Unified_and_Robust_Verifier_for_LLMs_Evaluation_and_Outcome_Reward","title":"[논문리뷰] CompassVerifier: A Unified and Robust Verifier for LLMs Evaluation and Outcome Reward","excerpt":"Songyang Gao이 [arXiv]에 게시한 'CompassVerifier: A Unified and Robust Verifier for LLMs Evaluation and Outcome Reward' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-06 13:46:36+0900","lastModifiedAt":"2025-08-06 13:46:36+0900","categories":["Review"],"tags":["Review","LLM Evaluation","Answer Verification","Reward Model","Benchmarking","Data Augmentation","Reinforcement Learning","Formula Verification","Hallucination Detection"],"permalink":"/ai/review/2025-8-6-CompassVerifier_A_Unified_and_Robust_Verifier_for_LLMs_Evaluation_and_Outcome_Reward/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-6-ChartCap_Mitigating_Hallucination_of_Dense_Chart_Captioning","title":"[논문리뷰] ChartCap: Mitigating Hallucination of Dense Chart Captioning","excerpt":"Gunhee Kim이 [arXiv]에 게시한 'ChartCap: Mitigating Hallucination of Dense Chart Captioning' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-06 13:46:36+0900","lastModifiedAt":"2025-08-06 13:46:36+0900","categories":["Review"],"tags":["Review","Chart Captioning","Hallucination Mitigation","Dataset Generation","Visual Language Models","Cycle Consistency","Reference-Free Metric","Data Visualization"],"permalink":"/ai/review/2025-8-6-ChartCap_Mitigating_Hallucination_of_Dense_Chart_Captioning/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-6-AlignGuard-LoRA_Alignment-Preserving_Fine-Tuning_via_Fisher-Guided_Decomposition_and_Riemannian-Geodesic_Collision_Regularization","title":"[논문리뷰] AlignGuard-LoRA: Alignment-Preserving Fine-Tuning via Fisher-Guided Decomposition and Riemannian-Geodesic Collision Regularization","excerpt":"Aman Chadha이 [arXiv]에 게시한 'AlignGuard-LoRA: Alignment-Preserving Fine-Tuning via Fisher-Guided Decomposition and Riemannian-Geodesic Collision Regularization' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-06 13:46:36+0900","lastModifiedAt":"2025-08-06 13:46:36+0900","categories":["Review"],"tags":["Review","Alignment Preservation","Fine-Tuning","LoRA","Fisher Information Matrix","Catastrophic Forgetting","LLM Safety","Riemannian Geometry","Parameter-Efficient Learning"],"permalink":"/ai/review/2025-8-6-AlignGuard-LoRA_Alignment-Preserving_Fine-Tuning_via_Fisher-Guided_Decomposition_and_Riemannian-Geodesic_Collision_Regularization/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-5-VeOmni__Scaling_Any_Modality_Model_Training_with_Model-Centric __Distributed_Recipe_Zoo","title":"[논문리뷰] VeOmni: Scaling Any Modality Model Training with Model-Centric Distributed Recipe Zoo","excerpt":"Bin Jia이 [arXiv]에 게시한 'VeOmni: Scaling Any Modality Model Training with Model-Centric Distributed Recipe Zoo' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-05 11:40:52+0900","lastModifiedAt":"2025-08-05 11:40:52+0900","categories":["Review"],"tags":["Review","Omni-modal LLMs","Distributed Training","Model-centric","Parallelism","FSDP","Sequence Parallelism","Expert Parallelism","Mixture-of-Experts"],"permalink":"/ai/review/2025-8-5-VeOmni__Scaling_Any_Modality_Model_Training_with_Model-Centric __Distributed_Recipe_Zoo/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-5-SitEmb-v1.5__Improved_Context-Aware_Dense_Retrieval_for_Semantic __Association_and_Long_Story_Comprehension","title":"[논문리뷰] SitEmb-v1.5: Improved Context-Aware Dense Retrieval for Semantic Association and Long Story Comprehension","excerpt":"Liyan Xu이 [arXiv]에 게시한 'SitEmb-v1.5: Improved Context-Aware Dense Retrieval for Semantic Association and Long Story Comprehension' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-05 11:40:52+0900","lastModifiedAt":"2025-08-05 11:40:52+0900","categories":["Review"],"tags":["Review","Dense Retrieval","Context-Aware Embedding","RAG","Long Document Comprehension","Residual Learning","Semantic Association","Text Embedding"],"permalink":"/ai/review/2025-8-5-SitEmb-v1.5__Improved_Context-Aware_Dense_Retrieval_for_Semantic __Association_and_Long_Story_Comprehension/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-5-RoboMemory__A_Brain-inspired_Multi-memory_Agentic_Framework_for_Lifelong __Learning_in_Physical_Embodied_Systems","title":"[논문리뷰] RoboMemory: A Brain-inspired Multi-memory Agentic Framework for Lifelong Learning in Physical Embodied Systems","excerpt":"Junkun Hong이 [arXiv]에 게시한 'RoboMemory: A Brain-inspired Multi-memory Agentic Framework for Lifelong Learning in Physical Embodied Systems' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-05 11:40:52+0900","lastModifiedAt":"2025-08-05 11:40:52+0900","categories":["Review"],"tags":["Review","Brain-inspired AI","Lifelong Learning","Embodied AI","Multi-memory Systems","Knowledge Graph","Robotics","Closed-Loop Planning"],"permalink":"/ai/review/2025-8-5-RoboMemory__A_Brain-inspired_Multi-memory_Agentic_Framework_for_Lifelong __Learning_in_Physical_Embodied_Systems/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-5-Qwen-Image_Technical_Report","title":"[논문리뷰] Qwen-Image Technical Report","excerpt":"Kaiyuan Gao이 [arXiv]에 게시한 'Qwen-Image Technical Report' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-05 11:40:52+0900","lastModifiedAt":"2025-08-05 11:40:52+0900","categories":["Review"],"tags":["Review","Image Generation","Text-to-Image","Image Editing","Text Rendering","Multimodal Diffusion Transformer","Curriculum Learning","Reinforcement Learning","Foundation Model"],"permalink":"/ai/review/2025-8-5-Qwen-Image_Technical_Report/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-5-Personalized_Safety_Alignment_for_Text-to-Image_Diffusion_Models","title":"[논문리뷰] Personalized Safety Alignment for Text-to-Image Diffusion Models","excerpt":"Kaidong Yu이 [arXiv]에 게시한 'Personalized Safety Alignment for Text-to-Image Diffusion Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-05 11:40:52+0900","lastModifiedAt":"2025-08-05 11:40:52+0900","categories":["Review"],"tags":["Review","Personalized Safety Alignment","Text-to-Image Diffusion Models","DPO","User Preferences","Content Moderation","Generative AI","Cross-Attention","Safety Alignment"],"permalink":"/ai/review/2025-8-5-Personalized_Safety_Alignment_for_Text-to-Image_Diffusion_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-5-Llama-3.1-FoundationAI-SecurityLLM-8B-Instruct_Technical_Report","title":"[논문리뷰] Llama-3.1-FoundationAI-SecurityLLM-8B-Instruct Technical Report","excerpt":"Anu Vellore이 [arXiv]에 게시한 'Llama-3.1-FoundationAI-SecurityLLM-8B-Instruct Technical Report' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-05 11:40:52+0900","lastModifiedAt":"2025-08-05 11:40:52+0900","categories":["Review"],"tags":["Review","Large Language Model","Cybersecurity","Instruction Tuning","Direct Preference Optimization","Cyber Threat Intelligence","Foundation Model","Chatbot"],"permalink":"/ai/review/2025-8-5-Llama-3.1-FoundationAI-SecurityLLM-8B-Instruct_Technical_Report/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-5-InstructVLA__Vision-Language-Action_Instruction_Tuning_from __Understanding_to_Manipulation","title":"[논문리뷰] InstructVLA: Vision-Language-Action Instruction Tuning from Understanding to Manipulation","excerpt":"Yang Tian이 [arXiv]에 게시한 'InstructVLA: Vision-Language-Action Instruction Tuning from Understanding to Manipulation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-05 11:40:52+0900","lastModifiedAt":"2025-08-05 11:40:52+0900","categories":["Review"],"tags":["Review","Vision-Language-Action (VLA)","Instruction Tuning","Multimodal Reasoning","Robotic Manipulation","Catastrophic Forgetting","Mixture-of-Experts (MoE)","Flow Matching"],"permalink":"/ai/review/2025-8-5-InstructVLA__Vision-Language-Action_Instruction_Tuning_from __Understanding_to_Manipulation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-5-Exploitation_Is_All_You_Need..._for_Exploration","title":"[논문리뷰] Exploitation Is All You Need... for Exploration","excerpt":"Jesse Roberts이 [arXiv]에 게시한 'Exploitation Is All You Need... for Exploration' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-05 11:40:52+0900","lastModifiedAt":"2025-08-05 11:40:52+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","Exploration-Exploitation","Meta-RL","Transformer Architecture","Emergent Behavior","Multi-Armed Bandits","Gridworlds","Pseudo-Thompson Sampling"],"permalink":"/ai/review/2025-8-5-Exploitation_Is_All_You_Need..._for_Exploration/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-5-Cyber-Zero__Training_Cybersecurity_Agents_without_Runtime","title":"[논문리뷰] Cyber-Zero: Training Cybersecurity Agents without Runtime","excerpt":"Zijian Wang이 [arXiv]에 게시한 'Cyber-Zero: Training Cybersecurity Agents without Runtime' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-05 11:40:52+0900","lastModifiedAt":"2025-08-05 11:40:52+0900","categories":["Review"],"tags":["Review","Cybersecurity Agents","LLM Training","Trajectory Synthesis","Runtime-Free Training","CTF Challenges","LLM Simulation"],"permalink":"/ai/review/2025-8-5-Cyber-Zero__Training_Cybersecurity_Agents_without_Runtime/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-5-CellForge__Agentic_Design_of_Virtual_Cell_Models","title":"[논문리뷰] CellForge: Agentic Design of Virtual Cell Models","excerpt":"Daniel Shao이 [arXiv]에 게시한 'CellForge: Agentic Design of Virtual Cell Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-05 11:40:52+0900","lastModifiedAt":"2025-08-05 11:40:52+0900","categories":["Review"],"tags":["Review","AI Scientist","Multi-Agent System","Virtual Cell Modeling","Single-Cell Perturbation Prediction","Deep Learning","Automated Model Design","Code Generation","Retrieval-Augmented Generation"],"permalink":"/ai/review/2025-8-5-CellForge__Agentic_Design_of_Virtual_Cell_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-5-Beyond_the_Trade-off__Self-Supervised_Reinforcement_Learning_for __Reasoning_Models'_Instruction_Following","title":"[논문리뷰] Beyond the Trade-off: Self-Supervised Reinforcement Learning for Reasoning Models' Instruction Following","excerpt":"Jiaqing Liang이 [arXiv]에 게시한 'Beyond the Trade-off: Self-Supervised Reinforcement Learning for Reasoning Models' Instruction Following' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-05 11:40:52+0900","lastModifiedAt":"2025-08-05 11:40:52+0900","categories":["Review"],"tags":["Review","Self-Supervised RL","Instruction Following","Reasoning Models","Large Language Models","Reward Modeling","Curriculum Learning"],"permalink":"/ai/review/2025-8-5-Beyond_the_Trade-off__Self-Supervised_Reinforcement_Learning_for __Reasoning_Models'_Instruction_Following/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-5-A_Glimpse_to_Compress__Dynamic_Visual_Token_Pruning_for_Large __Vision-Language_Models","title":"[논문리뷰] A Glimpse to Compress: Dynamic Visual Token Pruning for Large Vision-Language Models","excerpt":"Zuxuan Wu이 [arXiv]에 게시한 'A Glimpse to Compress: Dynamic Visual Token Pruning for Large Vision-Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-05 11:40:52+0900","lastModifiedAt":"2025-08-05 11:40:52+0900","categories":["Review"],"tags":["Review","Large Vision-Language Models (LVLMs)","Visual Token Pruning","Dynamic Compression","GlimpsePrune","Computational Efficiency","VQA","Reinforcement Learning"],"permalink":"/ai/review/2025-8-5-A_Glimpse_to_Compress__Dynamic_Visual_Token_Pruning_for_Large __Vision-Language_Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-5-AgentTTS__Large_Language_Model_Agent_for_Test-time_Compute-optimal __Scaling_Strategy_in_Complex_Tasks","title":"[논문리뷰] AgentTTS: Large Language Model Agent for Test-time Compute-optimal Scaling Strategy in Complex Tasks","excerpt":"Zhiwei Zhang이 [arXiv]에 게시한 'AgentTTS: Large Language Model Agent for Test-time Compute-optimal Scaling Strategy in Complex Tasks' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-05 11:40:52+0900","lastModifiedAt":"2025-08-05 11:40:52+0900","categories":["Review"],"tags":["Review","Large Language Models","LLM Agents","Test-time Scaling","Compute Optimization","Multi-stage Tasks","Resource Allocation","Search Efficiency"],"permalink":"/ai/review/2025-8-5-AgentTTS__Large_Language_Model_Agent_for_Test-time_Compute-optimal __Scaling_Strategy_in_Complex_Tasks/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-4-SWE-Exp__Experience-Driven_Software_Issue_Resolution","title":"[논문리뷰] SWE-Exp: Experience-Driven Software Issue Resolution","excerpt":"Heng Lian이 [arXiv]에 게시한 'SWE-Exp: Experience-Driven Software Issue Resolution' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-04 12:17:01+0900","lastModifiedAt":"2025-08-04 12:17:01+0900","categories":["Review"],"tags":["Review","Software Issue Resolution","LLM Agents","Experience-Driven Learning","Automated Program Repair","Multi-Agent Systems","Knowledge Management","Continuous Learning"],"permalink":"/ai/review/2025-8-4-SWE-Exp__Experience-Driven_Software_Issue_Resolution/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-4-SWE-Debate__Competitive_Multi-Agent_Debate_for_Software_Issue_Resolution","title":"[논문리뷰] SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution","excerpt":"Heng Lian이 [arXiv]에 게시한 'SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-04 12:17:01+0900","lastModifiedAt":"2025-08-04 12:17:01+0900","categories":["Review"],"tags":["Review","Multi-Agent System","Software Engineering","Fault Localization","Issue Resolution","Large Language Models","Competitive Debate","Graph Traversal"],"permalink":"/ai/review/2025-8-4-SWE-Debate__Competitive_Multi-Agent_Debate_for_Software_Issue_Resolution/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-4-SpA2V__Harnessing_Spatial_Auditory_Cues_for_Audio-driven_Spatially-aware __Video_Generation","title":"[논문리뷰] SpA2V: Harnessing Spatial Auditory Cues for Audio-driven Spatially-aware Video Generation","excerpt":"Long Chen이 [arXiv]에 게시한 'SpA2V: Harnessing Spatial Auditory Cues for Audio-driven Spatially-aware Video Generation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-04 12:17:01+0900","lastModifiedAt":"2025-08-04 12:17:01+0900","categories":["Review"],"tags":["Review","Audio-driven Video Generation","Spatial Auditory Cues","Video Scene Layout","MLLM","Diffusion Models","Training-free"],"permalink":"/ai/review/2025-8-4-SpA2V__Harnessing_Spatial_Auditory_Cues_for_Audio-driven_Spatially-aware __Video_Generation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-4-PixNerd__Pixel_Neural_Field_Diffusion","title":"[논문리뷰] PixNerd: Pixel Neural Field Diffusion","excerpt":"Limin Wang이 [arXiv]에 게시한 'PixNerd: Pixel Neural Field Diffusion' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-04 12:17:01+0900","lastModifiedAt":"2025-08-04 12:17:01+0900","categories":["Review"],"tags":["Review","Diffusion Models","Neural Fields","Pixel Space","Generative Models","Image Synthesis","Transformer Architecture","End-to-End Learning"],"permalink":"/ai/review/2025-8-4-PixNerd__Pixel_Neural_Field_Diffusion/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-4-Multimodal_Referring_Segmentation__A_Survey","title":"[논문리뷰] Multimodal Referring Segmentation: A Survey","excerpt":"Zuxuan Wu이 [arXiv]에 게시한 'Multimodal Referring Segmentation: A Survey' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-04 12:17:01+0900","lastModifiedAt":"2025-08-04 12:17:01+0900","categories":["Review"],"tags":["Review","Multimodal Learning","Referring Segmentation","Vision-Language Models","Image Segmentation","Video Segmentation","3D Vision","Survey"],"permalink":"/ai/review/2025-8-4-Multimodal_Referring_Segmentation__A_Survey/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-4-Learning_an_Efficient_Multi-Turn_Dialogue_Evaluator_from_Multiple_Judges","title":"[논문리뷰] Learning an Efficient Multi-Turn Dialogue Evaluator from Multiple Judges","excerpt":"Chengfei Lv이 [arXiv]에 게시한 'Learning an Efficient Multi-Turn Dialogue Evaluator from Multiple Judges' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-04 12:17:01+0900","lastModifiedAt":"2025-08-04 12:17:01+0900","categories":["Review"],"tags":["Review","Multi-Turn Dialogue Evaluation","LLM-as-a-Judge","Multi-Judge Aggregation","Preference Learning","Dialogue Quality Assessment","Maximum Likelihood Estimation","Computational Efficiency"],"permalink":"/ai/review/2025-8-4-Learning_an_Efficient_Multi-Turn_Dialogue_Evaluator_from_Multiple_Judges/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-4-Investigating_Hallucination_in_Conversations_for_Low_Resource_Languages","title":"[논문리뷰] Investigating Hallucination in Conversations for Low Resource Languages","excerpt":"Fatemeh Jamshidi이 [arXiv]에 게시한 'Investigating Hallucination in Conversations for Low Resource Languages' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-04 12:17:01+0900","lastModifiedAt":"2025-08-04 12:17:01+0900","categories":["Review"],"tags":["Review","LLM Hallucination","Low-resource Languages","Conversational AI","ROUGE Score","Cross-lingual Evaluation","Factual Consistency"],"permalink":"/ai/review/2025-8-4-Investigating_Hallucination_in_Conversations_for_Low_Resource_Languages/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-4-IGL-Nav__Incremental_3D_Gaussian_Localization_for_Image-goal_Navigation","title":"[논문리뷰] IGL-Nav: Incremental 3D Gaussian Localization for Image-goal Navigation","excerpt":"Jianjiang Feng이 [arXiv]에 게시한 'IGL-Nav: Incremental 3D Gaussian Localization for Image-goal Navigation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-04 12:17:01+0900","lastModifiedAt":"2025-08-04 12:17:01+0900","categories":["Review"],"tags":["Review","Image-goal Navigation","3D Gaussian Splatting (3DGS)","Incremental Scene Representation","Coarse-to-fine Localization","Embodied AI","Robotics","Differentiable Rendering"],"permalink":"/ai/review/2025-8-4-IGL-Nav__Incremental_3D_Gaussian_Localization_for_Image-goal_Navigation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-4-Beyond_Fixed__Variable-Length_Denoising_for_Diffusion_Large_Language __Models","title":"[논문리뷰] Beyond Fixed: Variable-Length Denoising for Diffusion Large Language Models","excerpt":"Jiaqi Wang이 [arXiv]에 게시한 'Beyond Fixed: Variable-Length Denoising for Diffusion Large Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-04 12:17:01+0900","lastModifiedAt":"2025-08-04 12:17:01+0900","categories":["Review"],"tags":["Review","Diffusion Large Language Models","Variable-Length Generation","Dynamic Length Adaptation","Denoising Strategy","Inference Optimization","Computational Efficiency"],"permalink":"/ai/review/2025-8-4-Beyond_Fixed__Variable-Length_Denoising_for_Diffusion_Large_Language __Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-4-3D-R1__Enhancing_Reasoning_in_3D_VLMs_for_Unified_Scene_Understanding","title":"[논문리뷰] 3D-R1: Enhancing Reasoning in 3D VLMs for Unified Scene Understanding","excerpt":"Hao Tang이 [arXiv]에 게시한 '3D-R1: Enhancing Reasoning in 3D VLMs for Unified Scene Understanding' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-04 12:17:01+0900","lastModifiedAt":"2025-08-04 12:17:01+0900","categories":["Review"],"tags":["Review","3D Vision-Language Models","Reasoning","Scene Understanding","Reinforcement Learning","Chain-of-Thought","Dynamic View Selection","Multi-task Learning"],"permalink":"/ai/review/2025-8-4-3D-R1__Enhancing_Reasoning_in_3D_VLMs_for_Unified_Scene_Understanding/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-3-villa-X__Enhancing_Latent_Action_Modeling_in_Vision-Language-Action __Models","title":"[논문리뷰] villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models","excerpt":"Kaixin Wang이 [arXiv]에 게시한 'villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-03 07:35:17+0900","lastModifiedAt":"2025-08-03 07:35:17+0900","categories":["Review"],"tags":["Review","Vision-Language-Action Models","Latent Actions","Robot Manipulation","Pre-training","Diffusion Models","Proprioceptive Feedback","Foundation Models"],"permalink":"/ai/review/2025-8-3-villa-X__Enhancing_Latent_Action_Modeling_in_Vision-Language-Action__Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-3-TARS__MinMax_Token-Adaptive_Preference_Strategy_for_Hallucination __Reduction_in_MLLMs","title":"[논문리뷰] TARS: MinMax Token-Adaptive Preference Strategy for Hallucination Reduction in MLLMs","excerpt":"Jiasheng Tang이 [arXiv]에 게시한 'TARS: MinMax Token-Adaptive Preference Strategy for Hallucination Reduction in MLLMs' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-03 07:35:17+0900","lastModifiedAt":"2025-08-03 07:35:17+0900","categories":["Review"],"tags":["Review","MLLMs","Hallucination Reduction","Preference Optimization","Min-Max Optimization","Token-Adaptive Strategy","Spectral Regularization","Visual Grounding"],"permalink":"/ai/review/2025-8-3-TARS__MinMax_Token-Adaptive_Preference_Strategy_for_Hallucination__Reduction_in_MLLMs/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-3-Seed-Prover__Deep_and_Broad_Reasoning_for_Automated_Theorem_Proving","title":"[논문리뷰] Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving","excerpt":"Zhicheng Jiang이 [arXiv]에 게시한 'Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-03 07:35:17+0900","lastModifiedAt":"2025-08-03 07:35:17+0900","categories":["Review"],"tags":["Review","Automated Theorem Proving","Large Language Models","Formal Verification","Reinforcement Learning","Lean","Geometry Reasoning","Chain-of-Thought","Lemma-Style Proving"],"permalink":"/ai/review/2025-8-3-Seed-Prover__Deep_and_Broad_Reasoning_for_Automated_Theorem_Proving/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-3-Scalable_Multi-Task_Reinforcement_Learning_for_Generalizable_Spatial __Intelligence_in_Visuomotor_Agents","title":"[논문리뷰] Scalable Multi-Task Reinforcement Learning for Generalizable Spatial Intelligence in Visuomotor Agents","excerpt":"Anji Liu이 [arXiv]에 게시한 'Scalable Multi-Task Reinforcement Learning for Generalizable Spatial Intelligence in Visuomotor Agents' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-03 07:35:17+0900","lastModifiedAt":"2025-08-03 07:35:17+0900","categories":["Review"],"tags":["Review","Reinforcement Learning","Multi-Task Learning","Visuomotor Agents","Spatial Reasoning","Generalization","Minecraft","Cross-View Goal Specification","Automated Task Synthesis"],"permalink":"/ai/review/2025-8-3-Scalable_Multi-Task_Reinforcement_Learning_for_Generalizable_Spatial__Intelligence_in_Visuomotor_Agents/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-3-RecGPT_Technical_Report","title":"[논문리뷰] RecGPT Technical Report","excerpt":"Jian Wu이 [arXiv]에 게시한 'RecGPT Technical Report' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-03 07:35:17+0900","lastModifiedAt":"2025-08-03 07:35:17+0900","categories":["Review"],"tags":["Review","Recommender Systems","Large Language Models (LLMs)","User Intent Modeling","Multi-Stage Training","Human-in-the-Loop","E-commerce","Filter Bubble Mitigation","Matthew Effect"],"permalink":"/ai/review/2025-8-3-RecGPT_Technical_Report/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-3-Phi-Ground_Tech_Report__Advancing_Perception_in_GUI_Grounding","title":"[논문리뷰] Phi-Ground Tech Report: Advancing Perception in GUI Grounding","excerpt":"Kai Qiu이 [arXiv]에 게시한 'Phi-Ground Tech Report: Advancing Perception in GUI Grounding' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-03 07:35:17+0900","lastModifiedAt":"2025-08-03 07:35:17+0900","categories":["Review"],"tags":["Review","GUI grounding","AI agent","Large Multi-modal Model","Perception","Data Augmentation","Direct Preference Optimization","Computational Efficiency"],"permalink":"/ai/review/2025-8-3-Phi-Ground_Tech_Report__Advancing_Perception_in_GUI_Grounding/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-3-Persona_Vectors__Monitoring_and_Controlling_Character_Traits_in_Language __Models","title":"[논문리뷰] Persona Vectors: Monitoring and Controlling Character Traits in Language Models","excerpt":"Jack Lindsey이 [arXiv]에 게시한 'Persona Vectors: Monitoring and Controlling Character Traits in Language Models' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-03 07:35:17+0900","lastModifiedAt":"2025-08-03 07:35:17+0900","categories":["Review"],"tags":["Review","Large Language Models (LLMs)","Persona Control","Activation Steering","Finetuning","Behavioral Shift Detection","Interpretability","Data Filtering"],"permalink":"/ai/review/2025-8-3-Persona_Vectors__Monitoring_and_Controlling_Character_Traits_in_Language__Models/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-3-On_the_Expressiveness_of_Softmax_Attention__A_Recurrent_Neural_Network __Perspective","title":"[논문리뷰] On the Expressiveness of Softmax Attention: A Recurrent Neural Network Perspective","excerpt":"Eric C. Larson이 [arXiv]에 게시한 'On the Expressiveness of Softmax Attention: A Recurrent Neural Network Perspective' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-03 07:35:17+0900","lastModifiedAt":"2025-08-03 07:35:17+0900","categories":["Review"],"tags":["Review","Softmax Attention","Linear Attention","Recurrent Neural Networks (RNNs)","Taylor Series Expansion","Attention Mechanisms","Expressiveness","Transformer Architectures"],"permalink":"/ai/review/2025-8-3-On_the_Expressiveness_of_Softmax_Attention__A_Recurrent_Neural_Network__Perspective/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-3-NeRF_Is_a_Valuable_Assistant_for_3D_Gaussian_Splatting","title":"[논문리뷰] NeRF Is a Valuable Assistant for 3D Gaussian Splatting","excerpt":"ZeSheng Wang이 [arXiv]에 게시한 'NeRF Is a Valuable Assistant for 3D Gaussian Splatting' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-03 07:35:17+0900","lastModifiedAt":"2025-08-03 07:35:17+0900","categories":["Review"],"tags":["Review","NeRF","3D Gaussian Splatting","Hybrid Model","Joint Optimization","Scene Representation","Neural Rendering","Residual Learning","Sparse View"],"permalink":"/ai/review/2025-8-3-NeRF_Is_a_Valuable_Assistant_for_3D_Gaussian_Splatting/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-3-iLRM__An_Iterative_Large_3D_Reconstruction_Model","title":"[논문리뷰] iLRM: An Iterative Large 3D Reconstruction Model","excerpt":"Abdelrahman Mohamed이 [arXiv]에 게시한 'iLRM: An Iterative Large 3D Reconstruction Model' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-03 07:35:17+0900","lastModifiedAt":"2025-08-03 07:35:17+0900","categories":["Review"],"tags":["Review","3D Reconstruction","Gaussian Splatting","Iterative Refinement","Transformer Architecture","Multi-view Learning","Scalability","Feed-forward Models"],"permalink":"/ai/review/2025-8-3-iLRM__An_Iterative_Large_3D_Reconstruction_Model/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-3-Flow_Equivariant_Recurrent_Neural_Networks","title":"[논문리뷰] Flow Equivariant Recurrent Neural Networks","excerpt":"T. Anderson Keller이 [arXiv]에 게시한 'Flow Equivariant Recurrent Neural Networks' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-03 07:35:17+0900","lastModifiedAt":"2025-08-03 07:35:17+0900","categories":["Review"],"tags":["Review","Flow Equivariance","Recurrent Neural Networks","Sequence Models","Group Equivariance","Lie Subgroups","Generalization","Time-Parameterized Symmetries"],"permalink":"/ai/review/2025-8-3-Flow_Equivariant_Recurrent_Neural_Networks/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-3-Enhanced_Arabic_Text_Retrieval_with_Attentive_Relevance_Scoring","title":"[논문리뷰] Enhanced Arabic Text Retrieval with Attentive Relevance Scoring","excerpt":"Abdenour Hadid이 [arXiv]에 게시한 'Enhanced Arabic Text Retrieval with Attentive Relevance Scoring' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-03 07:35:17+0900","lastModifiedAt":"2025-08-03 07:35:17+0900","categories":["Review"],"tags":["Review","Arabic NLP","Dense Passage Retrieval","Attentive Relevance Scoring","Information Retrieval","Question Answering","Transformer Models","Semantic Matching"],"permalink":"/ai/review/2025-8-3-Enhanced_Arabic_Text_Retrieval_with_Attentive_Relevance_Scoring/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-3-Efficient_Machine_Unlearning_via_Influence_Approximation","title":"[논문리뷰] Efficient Machine Unlearning via Influence Approximation","excerpt":"Enhong Chen이 [arXiv]에 게시한 'Efficient Machine Unlearning via Influence Approximation' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-03 07:35:17+0900","lastModifiedAt":"2025-08-03 07:35:17+0900","categories":["Review"],"tags":["Review","Machine Unlearning","Influence Function","Incremental Learning","Privacy Protection","Gradient Optimization","Model Editing","Computational Efficiency"],"permalink":"/ai/review/2025-8-3-Efficient_Machine_Unlearning_via_Influence_Approximation/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-3-C3__A_Bilingual_Benchmark_for_Spoken_Dialogue_Models_Exploring __Challenges_in_Complex_Conversations","title":"[논문리뷰] C3: A Bilingual Benchmark for Spoken Dialogue Models Exploring Challenges in Complex Conversations","excerpt":"Yiwen Guo이 [arXiv]에 게시한 'C3: A Bilingual Benchmark for Spoken Dialogue Models Exploring Challenges in Complex Conversations' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-03 07:35:17+0900","lastModifiedAt":"2025-08-03 07:35:17+0900","categories":["Review"],"tags":["Review","Spoken Dialogue Models","Bilingual Benchmark","Complex Conversations","Ambiguity Resolution","Context Understanding","LLM Evaluation","Human-Computer Interaction"],"permalink":"/ai/review/2025-8-3-C3__A_Bilingual_Benchmark_for_Spoken_Dialogue_Models_Exploring__Challenges_in_Complex_Conversations/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-3-Beyond_Linear_Bottlenecks__Spline-Based_Knowledge_Distillation_for __Culturally_Diverse_Art_Style_Classification","title":"[논문리뷰] Beyond Linear Bottlenecks: Spline-Based Knowledge Distillation for Culturally Diverse Art Style Classification","excerpt":"Abdelmalik Taleb-Ahmed이 [arXiv]에 게시한 'Beyond Linear Bottlenecks: Spline-Based Knowledge Distillation for Culturally Diverse Art Style Classification' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-03 07:35:17+0900","lastModifiedAt":"2025-08-03 07:35:17+0900","categories":["Review"],"tags":["Review","Kolmogorov-Arnold Networks","Knowledge Distillation","Art Style Classification","Self-Supervised Learning","Spline-Based Activation","Dual-Teacher","Gram Matrix"],"permalink":"/ai/review/2025-8-3-Beyond_Linear_Bottlenecks__Spline-Based_Knowledge_Distillation_for__Culturally_Diverse_Art_Style_Classification/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-8-3-AgroBench__Vision-Language_Model_Benchmark_in_Agriculture","title":"[논문리뷰] AgroBench: Vision-Language Model Benchmark in Agriculture","excerpt":"Yoshitaka Ushiku이 [arXiv]에 게시한 'AgroBench: Vision-Language Model Benchmark in Agriculture' 논문에 대한 자세한 리뷰입니다.","date":"2025-08-03 07:35:17+0900","lastModifiedAt":"2025-08-03 07:35:17+0900","categories":["Review"],"tags":["Review","Vision-Language Models","Agriculture","Benchmarking","Disease Identification","Pest Management","Crop Management","Agronomy"],"permalink":"/ai/review/2025-8-3-AgroBench__Vision-Language_Model_Benchmark_in_Agriculture/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-03-08-Pass-Certified-Solutions-Architect-Associate","title":"[AWS] AWS Solutions Architect Associate 자격증 취득 후기","excerpt":"AWS Solutions Architect Associate(SAA) 자격증 공부 방법, 시험 후기를 정리했습니다.","date":"2025-03-08 23:10:11+0900","lastModifiedAt":"2025-03-08 23:10:14+0900","categories":["Me"],"tags":[["Me"]],"permalink":"/me/pass-certified-solutions-architect-associate/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-02-25-brain-hack-productivity","title":"뇌과학적으로 게으름과 무기력을 극복하는 방법","excerpt":"게으름과 무기력은 단순한 의지 부족이 아니라, 뇌의 작동 방식과 깊은 관련이 있습니다. 전두엽을 활성화하고, 불필요한 정보를 차단하며, 긍정적인 자기 암시를 활용하는 방법을 통해 효율적으로 극복하는 법을 알아보세요.","date":"2025-02-25 23:10:11+0900","lastModifiedAt":"2025-02-25 23:10:14+0900","categories":["Me"],"tags":[["Me"]],"permalink":"/me/brain-hack-productivity/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-02-25-aws-lambda-eventbridge","title":"[AWS] AWS Lambda와 Notion API를 활용한 15분 단위 자동 기록 시스템","excerpt":"AWS Lambda, Notion API, Slack Webhook을 활용하여 15분마다 자동으로 시간을 기록하고 Slack 알림을 받는 시스템을 구축하는 방법을 설명합니다.","date":"2025-02-25 18:57:00+0900","lastModifiedAt":"2025-02-25 19:36:00+0900","categories":["AWS"],"tags":[["AWS","Lambda","EventBridge"]],"permalink":"/devops/aws/aws-lambda-eventbridge/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-02-25-block-youtube-extention","title":"[Chrome Extention] YouTube 차단 확장 프로그램 개발하기","excerpt":"YouTube 접속을 차단하고 생산성을 높이는 크롬 확장 프로그램을 만들어보세요. 개발 과정과 설치 방법을 자세히 설명합니다.","date":"2025-02-25 18:01:00+0900","lastModifiedAt":"2025-02-25 18:10:00+0900","categories":["Chrome Extension"],"tags":[["Chrome Extension"]],"permalink":"/etc/chrome-extension/block-youtube-with-chrome-extension/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-02-15-django-makefile","title":"[Django] Makefile 사용하기","excerpt":"Django 프로젝트에서 Makefile을 사용하는 방법을 공유합니다.","date":"2025-02-15 04:20:00+0900","lastModifiedAt":"2025-02-15 04:40:00+0900","categories":["Django"],"tags":[["Django"]],"permalink":"/backend/django/makefile/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-02-15-docker-fast-build","title":"[Docker] 빠른 빌드 방법","excerpt":"Docker 빌드 속도를 높이는 방법을 공유합니다.","date":"2025-02-14 11:30:11+0900","lastModifiedAt":"2025-02-15 00:11:11+0900","categories":["Docker"],"tags":[["Docker"]],"permalink":"/devops/docker/fast-build/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-02-14-django-optimistic-locking","title":"[Django] 낙관적 락","excerpt":"Django에서 낙관적 락에 대해 알아보자","date":"2025-02-14 08:33:11+0900","lastModifiedAt":"2025-02-14 08:49:11+0900","categories":["Django"],"tags":[["Django"]],"permalink":"/backend/django/optimistic-locking/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-02-14-django-pessimistic-locking","title":"[Django] 비관적 락","excerpt":"Django에서 비관적 락에 대해 알아보자","date":"2025-02-14 08:03:11+0900","lastModifiedAt":"2025-02-14 08:31:11+0900","categories":["Django"],"tags":[["Django"]],"permalink":"/backend/django/pessimistic-locking/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-02-14-django-index","title":"[Django] index","excerpt":"Django에서 index의 사용법을 공유합니다.","date":"2025-02-14 07:30:00+0900","lastModifiedAt":"2025-02-14 07:30:00+0900","categories":["Django"],"tags":[["Django"]],"permalink":"/backend/django/index/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-02-14-django-prefetch_related","title":"[Django] prefetch_related","excerpt":"Django에서 prefetch_related의 사용법을 공유합니다.","date":"2025-02-14 06:03:11+0900","lastModifiedAt":"2025-02-14 06:03:11+0900","categories":["Django"],"tags":[["Django"]],"permalink":"/backend/django/prefetch_related/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-02-05-see-log-in-django","title":"[Django] DB 로그 확인하기","excerpt":"Django에서 ORM을 사용하여 데이터베이스에 접근하는 경우, 쿼리 로그를 확인하는 방법을 공유합니다.","date":"2025-02-05 19:03:11+0900","lastModifiedAt":"2025-02-05 19:03:11+0900","categories":["Django"],"tags":[["Django"]],"permalink":"/backend/django/see-log-in-django/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-01-18-zero-downtime-deploy-with-jenkins","title":"[Jenkins] 무중단 배포를 위한 파이프라인 구성","excerpt":"Jenkins를 이용한 무중단 배포 방법을 공유합니다.","date":"2025-01-18 19:03:11+0900","lastModifiedAt":"2025-01-18 19:03:11+0900","categories":["Jenkins"],"tags":[["Jenkins"]],"permalink":"/jenkins/zero-downtime-deploy-with-jenkins/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-01-17-get-ssl-auth-with-letsencrypt","title":"[Nginx] Let's Encrypt로 SSL 인증서 발급받기","excerpt":"Let's Encrypt로 SSL 인증서를 발급받는 방법을 공유합니다.","date":"2025-01-17 23:10:11+0900","lastModifiedAt":"2025-01-17 23:10:14+0900","categories":["Nginx"],"tags":[["Nginx"]],"permalink":"/nginx/get-ssl-auth-with-letsencrypt/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-01-14-automating-update-github-profile","title":"[GitHub Actions] 깃허브 프로필 자동 업데이트하기","excerpt":"GitHub Actions를 이용해 깃허브 프로필을 자동으로 업데이트하는 방법을 공유합니다.","date":"2025-01-14 23:10:11+0900","lastModifiedAt":"2025-01-14 23:10:14+0900","categories":["GitHub Actions"],"tags":[["GitHub Actions"]],"permalink":"/github-actions/automating-update-github-profile/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-01-07-create-pipeline-with-jenkins","title":"[Jenkins] Jenkins 파이프라인 생성","excerpt":"Jenkins 파이프라인 생성 방법을 공유합니다.","date":"2025-01-08 03:03:11+0900","lastModifiedAt":"2025-01-14 03:43:11+0900","categories":["Jenkins"],"tags":[["Jenkins"]],"permalink":"/jenkins/create-pipeline-with-jenkins/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-01-07-start-jenkins","title":"[Jenkins] Jenkins 초기 설정","excerpt":"Jenkins 초기 설정 방법을 공유합니다.","date":"2025-01-07 19:03:11+0900","lastModifiedAt":"2025-01-07 19:03:11+0900","categories":["Jenkins"],"tags":[["Jenkins"]],"permalink":"/jenkins/start-jenkins/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-01-03-code-review-with-llm","title":"[LLM] LLM을 활용한 코드 리뷰","excerpt":"github workflow를 활용해 코드 리뷰를 자동화하기","date":"2025-01-03 01:03:11+0900","lastModifiedAt":"2025-01-03 02:10:14+0900","categories":["LLM"],"tags":[["LLM"]],"permalink":"/llm/code-review-with-llm/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-01-02-loguru","title":"[Python] logging 사용법","excerpt":"Loguru 을 이용한 logging 간단하게 사용해보자","date":"2025-01-03 01:03:11+0900","lastModifiedAt":"2025-01-03 02:10:14+0900","categories":["Logging"],"tags":[["Logging"]],"permalink":"/logging/loguru/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-01-02-start-safeline","title":"[SafeLine] SafeLine 초기 설정","excerpt":"SafeLine 초기 설정 방법을 공유합니다.","date":"2025-01-02 13:03:11+0900","lastModifiedAt":"2025-01-02 14:10:14+0900","categories":["SafeLine"],"tags":[["SafeLine"]],"permalink":"/safeline/start-safeline/","toc":true,"tocSticky":true,"published":true,"contentHtml":""},{"id":"2025-01-01-first-post","title":"블로그 개발 완료","excerpt":"새해 첫날, 기술 블로그 작성을 시작하다","date":"2025-01-01 23:10:11+0900","lastModifiedAt":"2025-01-01 23:10:14+0900","categories":["Me"],"tags":[["Me"]],"permalink":"/me/first-post/","toc":true,"tocSticky":true,"published":true,"contentHtml":""}]