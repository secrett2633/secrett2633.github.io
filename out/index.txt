2:I[8573,["231","static/chunks/231-c4b666723e6aae68.js","877","static/chunks/app/%5B...slug%5D/page-62c853a235141f09.js"],"default"]
3:I[231,["231","static/chunks/231-c4b666723e6aae68.js","877","static/chunks/app/%5B...slug%5D/page-62c853a235141f09.js"],""]
4:I[8167,["231","static/chunks/231-c4b666723e6aae68.js","877","static/chunks/app/%5B...slug%5D/page-62c853a235141f09.js"],"default"]
5:I[4281,["231","static/chunks/231-c4b666723e6aae68.js","185","static/chunks/app/layout-8a03eb4f67e6fd9a.js"],"default"]
6:I[9275,[],""]
7:I[1343,[],""]
0:["QEl6I8KSnTmzUXH3R0Jbm",[[["",{"children":["__PAGE__",{}]},"$undefined","$undefined",true],["",{"children":["__PAGE__",{},[["$L1",["$","div",null,{"className":"space-y-6","children":["$","div",null,{"className":"flex flex-col lg:flex-row gap-8","children":[["$","aside",null,{"className":"lg:w-64 xl:w-72 order-1 lg:order-none","children":["$","$L2",null,{}]}],["$","main",null,{"className":"flex-1","children":[["$","h1",null,{"className":"page__title mb-6","children":"Recent Posts"}],[["$","div",null,{"className":"entries-list","children":[["$","article","2025-10-2-Why_Cant_Transformers_Learn_Multiplication_Reverse-Engineering_Reveals_Long-Range_Dependency_Pitfalls",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-Why_Cant_Transformers_Learn_Multiplication_Reverse-Engineering_Reveals_Long-Range_Dependency_Pitfalls/","children":"[논문리뷰] Why Can't Transformers Learn Multiplication? Reverse-Engineering Reveals Long-Range Dependency Pitfalls"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Stuart Shieber이 [arXiv]에 게시한 'Why Can't Transformers Learn Multiplication? Reverse-Engineering Reveals Long-Range Dependency Pitfalls' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}]}]]}],["$","article","2025-10-2-VLM-FO1_Bridging_the_Gap_Between_High-Level_Reasoning_and_Fine-Grained_Perception_in_VLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-VLM-FO1_Bridging_the_Gap_Between_High-Level_Reasoning_and_Fine-Grained_Perception_in_VLMs/","children":"[논문리뷰] VLM-FO1: Bridging the Gap Between High-Level Reasoning and Fine-Grained Perception in VLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'VLM-FO1: Bridging the Gap Between High-Level Reasoning and Fine-Grained Perception in VLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}]}]]}],["$","article","2025-10-2-VLA-RFT_Vision-Language-Action_Reinforcement_Fine-tuning_with_Verified_Rewards_in_World_Simulators",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-VLA-RFT_Vision-Language-Action_Reinforcement_Fine-tuning_with_Verified_Rewards_in_World_Simulators/","children":"[논문리뷰] VLA-RFT: Vision-Language-Action Reinforcement Fine-tuning with Verified Rewards in World Simulators"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zirui Ge이 [arXiv]에 게시한 'VLA-RFT: Vision-Language-Action Reinforcement Fine-tuning with Verified Rewards in World Simulators' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}]}]]}],["$","article","2025-10-2-Training_Vision-Language_Process_Reward_Models_for_Test-Time_Scaling_in_Multimodal_Reasoning_Key_Insights_and_Lessons_Learned",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-Training_Vision-Language_Process_Reward_Models_for_Test-Time_Scaling_in_Multimodal_Reasoning_Key_Insights_and_Lessons_Learned/","children":"[논문리뷰] Training Vision-Language Process Reward Models for Test-Time Scaling in Multimodal Reasoning: Key Insights and Lessons Learned"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Training Vision-Language Process Reward Models for Test-Time Scaling in Multimodal Reasoning: Key Insights and Lessons Learned' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}]}]]}],["$","article","2025-10-2-ReSWD_ReSTIRd_not_shaken._Combining_Reservoir_Sampling_and_Sliced_Wasserstein_Distance_for_Variance_Reduction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-ReSWD_ReSTIRd_not_shaken._Combining_Reservoir_Sampling_and_Sliced_Wasserstein_Distance_for_Variance_Reduction/","children":"[논문리뷰] ReSWD: ReSTIR'd, not shaken. Combining Reservoir Sampling and Sliced Wasserstein Distance for Variance Reduction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'ReSWD: ReSTIR'd, not shaken. Combining Reservoir Sampling and Sliced Wasserstein Distance for Variance Reduction' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}]}]]}],["$","article","2025-10-2-PIPer_On-Device_Environment_Setup_via_Online_Reinforcement_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-PIPer_On-Device_Environment_Setup_via_Online_Reinforcement_Learning/","children":"[논문리뷰] PIPer: On-Device Environment Setup via Online Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'PIPer: On-Device Environment Setup via Online Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}]}]]}],["$","article","2025-10-2-On_Predictability_of_Reinforcement_Learning_Dynamics_for_Large_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-On_Predictability_of_Reinforcement_Learning_Dynamics_for_Large_Language_Models/","children":"[논문리뷰] On Predictability of Reinforcement Learning Dynamics for Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuqing Huang이 [arXiv]에 게시한 'On Predictability of Reinforcement Learning Dynamics for Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}]}]]}],["$","article","2025-10-2-Making_not_Taking_the_Best_of_N",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-Making_not_Taking_the_Best_of_N/","children":"[논문리뷰] Making, not Taking, the Best of N"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Making, not Taking, the Best of N' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}]}]]}],["$","article","2025-10-2-Knapsack_RL_Unlocking_Exploration_of_LLMs_via_Optimizing_Budget_Allocation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-Knapsack_RL_Unlocking_Exploration_of_LLMs_via_Optimizing_Budget_Allocation/","children":"[논문리뷰] Knapsack RL: Unlocking Exploration of LLMs via Optimizing Budget Allocation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Knapsack RL: Unlocking Exploration of LLMs via Optimizing Budget Allocation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}]}]]}],["$","article","2025-10-2-JoyAgent-JDGenie_Technical_Report_on_the_GAIA",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-JoyAgent-JDGenie_Technical_Report_on_the_GAIA/","children":"[논문리뷰] JoyAgent-JDGenie: Technical Report on the GAIA"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'JoyAgent-JDGenie: Technical Report on the GAIA' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}]}]]}],["$","article","2025-10-2-Infusing_Theory_of_Mind_into_Socially_Intelligent_LLM_Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-Infusing_Theory_of_Mind_into_Socially_Intelligent_LLM_Agents/","children":"[논문리뷰] Infusing Theory of Mind into Socially Intelligent LLM Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Infusing Theory of Mind into Socially Intelligent LLM Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}]}]]}],["$","article","2025-10-2-In-Place_Feedback_A_New_Paradigm_for_Guiding_LLMs_in_Multi-Turn_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-In-Place_Feedback_A_New_Paradigm_for_Guiding_LLMs_in_Multi-Turn_Reasoning/","children":"[논문리뷰] In-Place Feedback: A New Paradigm for Guiding LLMs in Multi-Turn Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chaehyeon Chung이 [arXiv]에 게시한 'In-Place Feedback: A New Paradigm for Guiding LLMs in Multi-Turn Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}]}]]}],["$","article","2025-10-2-Hyperdimensional_Probe_Decoding_LLM_Representations_via_Vector_Symbolic_Architectures",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-Hyperdimensional_Probe_Decoding_LLM_Representations_via_Vector_Symbolic_Architectures/","children":"[논문리뷰] Hyperdimensional Probe: Decoding LLM Representations via Vector Symbolic Architectures"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Andrea Passerini이 [arXiv]에 게시한 'Hyperdimensional Probe: Decoding LLM Representations via Vector Symbolic Architectures' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}]}]]}],["$","article","2025-10-2-GUI-KV_Efficient_GUI_Agents_via_KV_Cache_with_Spatio-Temporal_Awareness",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-GUI-KV_Efficient_GUI_Agents_via_KV_Cache_with_Spatio-Temporal_Awareness/","children":"[논문리뷰] GUI-KV: Efficient GUI Agents via KV Cache with Spatio-Temporal Awareness"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chien-Sheng Wu이 [arXiv]에 게시한 'GUI-KV: Efficient GUI Agents via KV Cache with Spatio-Temporal Awareness' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}]}]]}],["$","article","2025-10-2-GEM_A_Gym_for_Agentic_LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-GEM_A_Gym_for_Agentic_LLMs/","children":"[논문리뷰] GEM: A Gym for Agentic LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'GEM: A Gym for Agentic LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}]}]]}],["$","article","2025-10-2-Flash-Searcher_Fast_and_Effective_Web_Agents_via_DAG-Based_Parallel_Execution",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-Flash-Searcher_Fast_and_Effective_Web_Agents_via_DAG-Based_Parallel_Execution/","children":"[논문리뷰] Flash-Searcher: Fast and Effective Web Agents via DAG-Based Parallel Execution"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Flash-Searcher: Fast and Effective Web Agents via DAG-Based Parallel Execution' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}]}]]}],["$","article","2025-10-2-Eliciting_Secret_Knowledge_from_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-Eliciting_Secret_Knowledge_from_Language_Models/","children":"[논문리뷰] Eliciting Secret Knowledge from Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Neel Nanda이 [arXiv]에 게시한 'Eliciting Secret Knowledge from Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}]}]]}],["$","article","2025-10-2-DeepSearch_Overcome_the_Bottleneck_of_Reinforcement_Learning_with_Verifiable_Rewards_via_Monte_Carlo_Tree_Search",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-DeepSearch_Overcome_the_Bottleneck_of_Reinforcement_Learning_with_Verifiable_Rewards_via_Monte_Carlo_Tree_Search/","children":"[논문리뷰] DeepSearch: Overcome the Bottleneck of Reinforcement Learning with Verifiable Rewards via Monte Carlo Tree Search"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DeepSearch: Overcome the Bottleneck of Reinforcement Learning with Verifiable Rewards via Monte Carlo Tree Search' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}]}]]}],["$","article","2025-10-2-CurES_From_Gradient_Analysis_to_Efficient_Curriculum_Learning_for_Reasoning_LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-CurES_From_Gradient_Analysis_to_Efficient_Curriculum_Learning_for_Reasoning_LLMs/","children":"[논문리뷰] CurES: From Gradient Analysis to Efficient Curriculum Learning for Reasoning LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hengyi Cai이 [arXiv]에 게시한 'CurES: From Gradient Analysis to Efficient Curriculum Learning for Reasoning LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}]}]]}],["$","article","2025-10-2-Code2Video_A_Code-centric_Paradigm_for_Educational_Video_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-Code2Video_A_Code-centric_Paradigm_for_Educational_Video_Generation/","children":"[논문리뷰] Code2Video: A Code-centric Paradigm for Educational Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Code2Video: A Code-centric Paradigm for Educational Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}]}]]}]]}],["$","$L4",null,{"currentPage":1,"totalPages":73,"basePath":"/"}]]]}]]}]}]],null],null]},[["$","html",null,{"lang":"ko","className":"no-js","children":[["$","head",null,{"children":[["$","link",null,{"rel":"icon","type":"image/png","sizes":"32x32","href":"/favicon-32x32.png"}],["$","link",null,{"rel":"icon","type":"image/png","sizes":"16x16","href":"/favicon-16x16.png"}],["$","meta",null,{"name":"msapplication-TileColor","content":"#ffc40d"}],["$","meta",null,{"name":"theme-color","content":"#ffffff"}],["$","script",null,{"async":true,"src":"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY"}],["$","script",null,{"dangerouslySetInnerHTML":{"__html":"\n              window.dataLayer = window.dataLayer || [];\n              function gtag(){dataLayer.push(arguments);}\n              gtag('js', new Date());\n              gtag('config', 'G-NE2W3CFPNY');\n            "}}]]}],["$","body",null,{"className":"__className_9012cf layout--default","children":["$","div",null,{"className":"min-h-screen bg-gray-50","children":[["$","$L5",null,{}],["$","main",null,{"className":"initial-content","children":["$","$L6",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L7",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","div",null,{"className":"min-h-screen flex items-center justify-center bg-gray-50","children":["$","div",null,{"className":"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center","children":[["$","h1",null,{"className":"text-6xl font-bold text-primary-600 mb-4","children":"404"}],["$","h2",null,{"className":"text-2xl font-semibold text-gray-900 mb-4","children":"페이지를 찾을 수 없습니다"}],["$","p",null,{"className":"text-gray-600 mb-8","children":"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다."}],["$","$L3",null,{"href":"/","className":"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors","children":"홈으로 돌아가기"}]]}]}],"notFoundStyles":[],"styles":null}]}],["$","div",null,{"id":"footer","className":"page__footer","children":["$","footer",null,{"className":"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8","children":["$","div",null,{"className":"text-center text-gray-500 text-sm","children":["$","p",null,{"children":"© 2025 secrett2633. All rights reserved."}]}]}]}]]}]}]]}],null],[["$","div",null,{"className":"flex items-center justify-center min-h-screen","children":["$","div",null,{"className":"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600"}]}],[],[]]],[[["$","link","0",{"rel":"stylesheet","href":"/secrett2633.github.io/_next/static/css/b9d6ec750ad82add.css","precedence":"next","crossOrigin":"$undefined"}]],[null,"$L8"]]]]]
8:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"secrett2633's blog"}],["$","meta","3",{"name":"description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","meta","4",{"name":"author","content":"secrett2633"}],["$","meta","5",{"name":"keywords","content":"Django, Python, DevOps, AI, ML, 블로그, 기술"}],["$","meta","6",{"name":"creator","content":"secrett2633"}],["$","meta","7",{"name":"publisher","content":"secrett2633"}],["$","meta","8",{"name":"robots","content":"index, follow"}],["$","meta","9",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","10",{"rel":"canonical","href":"https://secrett2633.github.io/"}],["$","meta","11",{"name":"format-detection","content":"telephone=no, address=no, email=no"}],["$","meta","12",{"property":"og:title","content":"secrett2633's blog"}],["$","meta","13",{"property":"og:description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","meta","14",{"property":"og:url","content":"https://secrett2633.github.io/"}],["$","meta","15",{"property":"og:site_name","content":"secrett2633's blog"}],["$","meta","16",{"property":"og:locale","content":"ko_KR"}],["$","meta","17",{"property":"og:type","content":"website"}],["$","meta","18",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","19",{"name":"twitter:title","content":"secrett2633's blog"}],["$","meta","20",{"name":"twitter:description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}]]
1:null
