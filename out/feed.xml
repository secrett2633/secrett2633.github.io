<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>secrett2633's blog</title>
    <description>기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트</description>
    <link>https://blog.secrett2633.site</link>
    <atom:link href="https://blog.secrett2633.site/feed.xml" rel="self" type="application/rss+xml" />
    <language>ko-KR</language>
    <lastBuildDate>Tue, 02 Dec 2025 11:34:05 GMT</lastBuildDate>
    <pubDate>Tue, 02 Dec 2025 11:34:05 GMT</pubDate>
    <ttl>60</ttl>
    <generator>Next.js RSS Generator</generator>
    <managingEditor>secrett2633@example.com (secrett2633)</managingEditor>
    <webMaster>secrett2633@example.com (secrett2633)</webMaster>
    <category>Technology</category>
    <category>Programming</category>
    <category>Django</category>
    <category>Python</category>
    <category>DevOps</category>
    <category>AI/ML</category>
    
        <item>
      <title>[논문리뷰] Z-Image: An Efficient Image Generation Foundation Model with Single-Stream Diffusion Transformer</title>
      <description>이 [arXiv]에 게시한 &#39;Z-Image: An Efficient Image Generation Foundation Model with Single-Stream Diffusion Transformer&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-01-Z-Image-An-Efficient-Image-Generation-Foundation-Model-with-Single-Stream-Diffusion-Transformer/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-01-Z-Image-An-Efficient-Image-Generation-Foundation-Model-with-Single-Stream-Diffusion-Transformer/</guid>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Diffusion Transformer</category><category>Efficient Training</category><category>Multi-Modal Learning</category><category>Text-to-Image Generation</category><category>Image Editing</category><category>RLHF</category><category>Photorealistic Rendering</category>
    </item>
    <item>
      <title>[논문리뷰] YOLO Meets Mixture-of-Experts: Adaptive Expert Routing for Robust Object Detection</title>
      <description>Avishai Weizman이 [arXiv]에 게시한 &#39;YOLO Meets Mixture-of-Experts: Adaptive Expert Routing for Robust Object Detection&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-01-YOLO-Meets-Mixture-of-Experts-Adaptive-Expert-Routing-for-Robust-Object-Detection/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-01-YOLO-Meets-Mixture-of-Experts-Adaptive-Expert-Routing-for-Robust-Object-Detection/</guid>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Object Detection</category><category>YOLOv9</category><category>Mixture-of-Experts</category><category>Adaptive Routing</category><category>Deep Learning</category><category>Computer Vision</category><category>Feature Specialization</category>
    </item>
    <item>
      <title>[논문리뷰] Xmodel-2.5: 1.3B Data-Efficient Reasoning SLM</title>
      <description>이 [arXiv]에 게시한 &#39;Xmodel-2.5: 1.3B Data-Efficient Reasoning SLM&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-01-Xmodel-2-5-1-3B-Data-Efficient-Reasoning-SLM/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-01-Xmodel-2-5-1-3B-Data-Efficient-Reasoning-SLM/</guid>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Small Language Models</category><category>Data Efficiency</category><category>Reasoning</category><category>Maximal-Update Parameterization</category><category>FP8 Mixed Precision</category><category>Optimizer Scheduling</category><category>Long-Context Adaptation</category><category>Agent AI</category>
    </item>
    <item>
      <title>[논문리뷰] World in a Frame: Understanding Culture Mixing as a New Challenge for Vision-Language Models</title>
      <description>Na Min An이 [arXiv]에 게시한 &#39;World in a Frame: Understanding Culture Mixing as a New Challenge for Vision-Language Models&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-01-World-in-a-Frame-Understanding-Culture-Mixing-as-a-New-Challenge-for-Vision-Language-Models/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-01-World-in-a-Frame-Understanding-Culture-Mixing-as-a-New-Challenge-for-Vision-Language-Models/</guid>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Vision-Language Models</category><category>Culture Mixing</category><category>VQA</category><category>Synthetic Data Generation</category><category>Multicultural Understanding</category><category>Model Robustness</category><category>Fine-tuning</category><category>Cultural Bias</category>
    </item>
    <item>
      <title>[논문리뷰] Vision Bridge Transformer at Scale</title>
      <description>Xinchao Wang이 [arXiv]에 게시한 &#39;Vision Bridge Transformer at Scale&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-01-Vision-Bridge-Transformer-at-Scale/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-01-Vision-Bridge-Transformer-at-Scale/</guid>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Vision Transformer</category><category>Bridge Models</category><category>Conditional Generation</category><category>Image Editing</category><category>Video Translation</category><category>Velocity Matching</category><category>Diffusion Models</category><category>Scalability</category>
    </item>
    <item>
      <title>[논문리뷰] The Collapse of Patches</title>
      <description>Weidong Cai이 [arXiv]에 게시한 &#39;The Collapse of Patches&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-01-The-Collapse-of-Patches/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-01-The-Collapse-of-Patches/</guid>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Patch Collapse</category><category>Image Generation</category><category>Image Classification</category><category>Masked Image Modeling</category><category>Vision Transformers</category><category>PageRank</category><category>Uncertainty Reduction</category><category>Computational Efficiency</category>
    </item>
    <item>
      <title>[논문리뷰] Test-time scaling of diffusions with flow maps</title>
      <description>Sanja Fidler이 [arXiv]에 게시한 &#39;Test-time scaling of diffusions with flow maps&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-01-Test-time-scaling-of-diffusions-with-flow-maps/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-01-Test-time-scaling-of-diffusions-with-flow-maps/</guid>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Diffusion Models</category><category>Flow Maps</category><category>Test-time Adaptation</category><category>Reward Guidance</category><category>Generative Models</category><category>SMC</category><category>Vision-Language Models</category>
    </item>
    <item>
      <title>[논문리뷰] SO-Bench: A Structural Output Evaluation of Multimodal LLMs</title>
      <description>이 [arXiv]에 게시한 &#39;SO-Bench: A Structural Output Evaluation of Multimodal LLMs&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-01-SO-Bench-A-Structural-Output-Evaluation-of-Multimodal-LLMs/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-01-SO-Bench-A-Structural-Output-Evaluation-of-Multimodal-LLMs/</guid>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Multimodal LLMs</category><category>Structural Output</category><category>Information Extraction</category><category>JSON Schema</category><category>SO-Bench</category><category>Visual Reasoning</category><category>Supervised Fine-tuning</category><category>Reinforcement Learning</category>
    </item>
    <item>
      <title>[논문리뷰] RefineBench: Evaluating Refinement Capability of Language Models via Checklists</title>
      <description>이 [arXiv]에 게시한 &#39;RefineBench: Evaluating Refinement Capability of Language Models via Checklists&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-01-RefineBench-Evaluating-Refinement-Capability-of-Language-Models-via-Checklists/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-01-RefineBench-Evaluating-Refinement-Capability-of-Language-Models-via-Checklists/</guid>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Language Models</category><category>Refinement Capability</category><category>Self-Refinement</category><category>Guided Refinement</category><category>Checklist Evaluation</category><category>Multi-turn Interaction</category><category>Benchmark</category>
    </item>
    <item>
      <title>[논문리뷰] Recognition of Abnormal Events in Surveillance Videos using Weakly Supervised Dual-Encoder Models</title>
      <description>Yehudit Aperstein이 [arXiv]에 게시한 &#39;Recognition of Abnormal Events in Surveillance Videos using Weakly Supervised Dual-Encoder Models&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-01-Recognition-of-Abnormal-Events-in-Surveillance-Videos-using-Weakly-Supervised-Dual-Encoder-Models/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-01-Recognition-of-Abnormal-Events-in-Surveillance-Videos-using-Weakly-Supervised-Dual-Encoder-Models/</guid>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Anomaly Detection</category><category>Surveillance Videos</category><category>Weakly Supervised Learning</category><category>Multiple Instance Learning</category><category>Dual-Encoder</category><category>I3D</category><category>TimeSformer</category><category>Top-k Pooling</category>
    </item>
    <item>
      <title>[논문리뷰] REASONEDIT: Towards Reasoning-Enhanced Image Editing Models</title>
      <description>이 [arXiv]에 게시한 &#39;REASONEDIT: Towards Reasoning-Enhanced Image Editing Models&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-01-REASONEDIT-Towards-Reasoning-Enhanced-Image-Editing-Models/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-01-REASONEDIT-Towards-Reasoning-Enhanced-Image-Editing-Models/</guid>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Image Editing</category><category>Reasoning-Enhanced AI</category><category>Multimodal Large Language Models</category><category>Diffusion Transformers</category><category>Thinking</category><category>Reflection</category><category>Iterative Refinement</category><category>Instruction Following</category>
    </item>
    <item>
      <title>[논문리뷰] OralGPT-Omni: A Versatile Dental Multimodal Large Language Model</title>
      <description>이 [arXiv]에 게시한 &#39;OralGPT-Omni: A Versatile Dental Multimodal Large Language Model&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-01-OralGPT-Omni-A-Versatile-Dental-Multimodal-Large-Language-Model/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-01-OralGPT-Omni-A-Versatile-Dental-Multimodal-Large-Language-Model/</guid>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Multimodal Large Language Model (MLLM)</category><category>Dental Imaging Analysis</category><category>Chain-of-Thought (CoT) Reasoning</category><category>Medical AI</category><category>Benchmark</category><category>Diagnosis</category><category>Oral Healthcare</category><category>Explainable AI</category>
    </item>
    <item>
      <title>[논문리뷰] OmniRefiner: Reinforcement-Guided Local Diffusion Refinement</title>
      <description>Yiren Song이 [arXiv]에 게시한 &#39;OmniRefiner: Reinforcement-Guided Local Diffusion Refinement&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-01-OmniRefiner-Reinforcement-Guided-Local-Diffusion-Refinement/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-01-OmniRefiner-Reinforcement-Guided-Local-Diffusion-Refinement/</guid>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Diffusion Models</category><category>Image Refinement</category><category>Reinforcement Learning</category><category>Fine-Grained Editing</category><category>Reference-Guided Generation</category><category>Latent Diffusion</category><category>Visual Fidelity</category><category>Detail Restoration</category>
    </item>
    <item>
      <title>[논문리뷰] Nemotron-Flash: Towards Latency-Optimal Hybrid Small Language Models</title>
      <description>이 [arXiv]에 게시한 &#39;Nemotron-Flash: Towards Latency-Optimal Hybrid Small Language Models&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-01-Nemotron-Flash-Towards-Latency-Optimal-Hybrid-Small-Language-Models/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-01-Nemotron-Flash-Towards-Latency-Optimal-Hybrid-Small-Language-Models/</guid>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Small Language Models (SLMs)</category><category>Latency Optimization</category><category>Hybrid Architectures</category><category>Evolutionary Search</category><category>Weight Normalization</category><category>Efficient Attention</category><category>Depth-Width Ratios</category><category>Real-device Efficiency</category>
    </item>
    <item>
      <title>[논문리뷰] MRI Super-Resolution with Deep Learning: A Comprehensive Survey</title>
      <description>이 [arXiv]에 게시한 &#39;MRI Super-Resolution with Deep Learning: A Comprehensive Survey&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-01-MRI-Super-Resolution-with-Deep-Learning-A-Comprehensive-Survey/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-01-MRI-Super-Resolution-with-Deep-Learning-A-Comprehensive-Survey/</guid>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>MRI Super-Resolution</category><category>Deep Learning</category><category>Computational Imaging</category><category>Inverse Problems</category><category>Generative AI</category><category>Medical Imaging</category><category>Survey</category>
    </item>
    <item>
      <title>[논문리뷰] Layer-Aware Video Composition via Split-then-Merge</title>
      <description>Wen-Sheng Chu이 [arXiv]에 게시한 &#39;Layer-Aware Video Composition via Split-then-Merge&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-01-Layer-Aware-Video-Composition-via-Split-then-Merge/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-01-Layer-Aware-Video-Composition-via-Split-then-Merge/</guid>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Generative Video Composition</category><category>Diffusion Models</category><category>Layer-Aware Generation</category><category>Self-Composition</category><category>Affordance Learning</category><category>Video Editing</category><category>Data Augmentation</category>
    </item>
    <item>
      <title>[논문리뷰] Geometrically-Constrained Agent for Spatial Reasoning</title>
      <description>Lehan He이 [arXiv]에 게시한 &#39;Geometrically-Constrained Agent for Spatial Reasoning&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-01-Geometrically-Constrained-Agent-for-Spatial-Reasoning/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-01-Geometrically-Constrained-Agent-for-Spatial-Reasoning/</guid>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Spatial Reasoning</category><category>Vision Language Models (VLMs)</category><category>Geometric Constraints</category><category>Agentic AI</category><category>Tool Integration</category><category>Semantic-to-Geometric Gap</category><category>Task Formalization</category>
    </item>
    <item>
      <title>[논문리뷰] From Pixels to Feelings: Aligning MLLMs with Human Cognitive Perception of Images</title>
      <description>Filippos Kokkinos이 [arXiv]에 게시한 &#39;From Pixels to Feelings: Aligning MLLMs with Human Cognitive Perception of Images&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-01-From-Pixels-to-Feelings-Aligning-MLLMs-with-Human-Cognitive-Perception-of-Images/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-01-From-Pixels-to-Feelings-Aligning-MLLMs-with-Human-Cognitive-Perception-of-Images/</guid>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Multimodal LLM</category><category>Human Cognition</category><category>Image Perception</category><category>Benchmarking</category><category>Supervised Fine-tuning</category><category>Image Generation</category><category>Aesthetics</category><category>Memorability</category>
    </item>
    <item>
      <title>[논문리뷰] Focused Chain-of-Thought: Efficient LLM Reasoning via Structured Input Information</title>
      <description>Kristian Kersting이 [arXiv]에 게시한 &#39;Focused Chain-of-Thought: Efficient LLM Reasoning via Structured Input Information&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-01-Focused-Chain-of-Thought-Efficient-LLM-Reasoning-via-Structured-Input-Information/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-01-Focused-Chain-of-Thought-Efficient-LLM-Reasoning-via-Structured-Input-Information/</guid>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>LLM Reasoning</category><category>Chain-of-Thought</category><category>Prompt Engineering</category><category>Efficiency</category><category>Structured Input</category><category>Information Extraction</category><category>Cognitive Psychology</category><category>Token Reduction</category>
    </item>
    <item>
      <title>[논문리뷰] Find the Leak, Fix the Split: Cluster-Based Method to Prevent Leakage in Video-Derived Datasets</title>
      <description>Avishai Weizman이 [arXiv]에 게시한 &#39;Find the Leak, Fix the Split: Cluster-Based Method to Prevent Leakage in Video-Derived Datasets&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-01-Find-the-Leak-Fix-the-Split-Cluster-Based-Method-to-Prevent-Leakage-in-Video-Derived-Datasets/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-01-Find-the-Leak-Fix-the-Split-Cluster-Based-Method-to-Prevent-Leakage-in-Video-Derived-Datasets/</guid>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Data Leakage</category><category>Video Datasets</category><category>Clustering</category><category>Frame Selection</category><category>Deep Learning</category><category>Object Detection</category><category>Dataset Partitioning</category><category>Dimensionality Reduction</category>
    </item>
    <item>
      <title>[논문리뷰] FedRE: A Representation Entanglement Framework for Model-Heterogeneous Federated Learning</title>
      <description>Simin Chen이 [arXiv]에 게시한 &#39;FedRE: A Representation Entanglement Framework for Model-Heterogeneous Federated Learning&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-01-FedRE-A-Representation-Entanglement-Framework-for-Model-Heterogeneous-Federated-Learning/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-01-FedRE-A-Representation-Entanglement-Framework-for-Model-Heterogeneous-Federated-Learning/</guid>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Federated Learning</category><category>Model Heterogeneity</category><category>Representation Learning</category><category>Privacy Preservation</category><category>Communication Efficiency</category><category>Entangled Representation</category><category>Knowledge Transfer</category>
    </item>
    <item>
      <title>[논문리뷰] Fast3Dcache: Training-free 3D Geometry Synthesis Acceleration</title>
      <description>이 [arXiv]에 게시한 &#39;Fast3Dcache: Training-free 3D Geometry Synthesis Acceleration&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-01-Fast3Dcache-Training-free-3D-Geometry-Synthesis-Acceleration/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-01-Fast3Dcache-Training-free-3D-Geometry-Synthesis-Acceleration/</guid>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>3D Geometry Synthesis</category><category>Diffusion Models</category><category>Acceleration</category><category>Caching</category><category>Training-free</category><category>Flow Matching</category><category>Voxel Stabilization</category><category>Computational Efficiency</category>
    </item>
    <item>
      <title>[논문리뷰] Every Token Counts: Generalizing 16M Ultra-Long Context in Large Language Models</title>
      <description>Wei Wu이 [arXiv]에 게시한 &#39;Every Token Counts: Generalizing 16M Ultra-Long Context in Large Language Models&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-01-Every-Token-Counts-Generalizing-16M-Ultra-Long-Context-in-Large-Language-Models/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-01-Every-Token-Counts-Generalizing-16M-Ultra-Long-Context-in-Large-Language-Models/</guid>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Large Language Models</category><category>Long Context</category><category>Sparse Attention</category><category>Hierarchical Sparse Attention (HSA)</category><category>Length Generalization</category><category>Mixture of Experts (MoE)</category><category>Transformer</category>
    </item>
    <item>
      <title>[논문리뷰] DualVLA: Building a Generalizable Embodied Agent via Partial Decoupling of Reasoning and Action</title>
      <description>Zhuoyang Liu이 [arXiv]에 게시한 &#39;DualVLA: Building a Generalizable Embodied Agent via Partial Decoupling of Reasoning and Action&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-01-DualVLA-Building-a-Generalizable-Embodied-Agent-via-Partial-Decoupling-of-Reasoning-and-Action/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-01-DualVLA-Building-a-Generalizable-Embodied-Agent-via-Partial-Decoupling-of-Reasoning-and-Action/</guid>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Vision-Language-Action (VLA)</category><category>Embodied AI</category><category>Action Degeneration</category><category>Data Pruning</category><category>Knowledge Distillation</category><category>Multi-modal Reasoning</category><category>Robot Learning</category><category>VLA Score</category>
    </item>
    <item>
      <title>[논문리뷰] DiP: Taming Diffusion Models in Pixel Space</title>
      <description>Xu Chen이 [arXiv]에 게시한 &#39;DiP: Taming Diffusion Models in Pixel Space&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-01-DiP-Taming-Diffusion-Models-in-Pixel-Space/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-01-DiP-Taming-Diffusion-Models-in-Pixel-Space/</guid>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Diffusion Models</category><category>Pixel Space</category><category>Latent Diffusion Models (LDMs)</category><category>Diffusion Transformer (DiT)</category><category>Patch Detailer Head</category><category>Global-Local Modeling</category><category>Computational Efficiency</category><category>ImageNet</category>
    </item>
    <item>
      <title>[논문리뷰] DeepSeekMath-V2: Towards Self-Verifiable Mathematical Reasoning</title>
      <description>이 [arXiv]에 게시한 &#39;DeepSeekMath-V2: Towards Self-Verifiable Mathematical Reasoning&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-01-DeepSeekMath-V2-Towards-Self-Verifiable-Mathematical-Reasoning/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-01-DeepSeekMath-V2-Towards-Self-Verifiable-Mathematical-Reasoning/</guid>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Mathematical Reasoning</category><category>Large Language Models (LLMs)</category><category>Proof Verification</category><category>Self-Verification</category><category>Reinforcement Learning (RL)</category><category>Theorem Proving</category><category>Meta-Verification</category><category>Iterative Refinement</category>
    </item>
    <item>
      <title>[논문리뷰] Decoupled DMD: CFG Augmentation as the Spear, Distribution Matching as the Shield</title>
      <description>이 [arXiv]에 게시한 &#39;Decoupled DMD: CFG Augmentation as the Spear, Distribution Matching as the Shield&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-01-Decoupled-DMD-CFG-Augmentation-as-the-Spear-Distribution-Matching-as-the-Shield/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-01-Decoupled-DMD-CFG-Augmentation-as-the-Spear-Distribution-Matching-as-the-Shield/</guid>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Diffusion Models</category><category>Model Distillation</category><category>Classifier-Free Guidance (CFG)</category><category>Distribution Matching</category><category>Text-to-Image Generation</category><category>Few-step Generation</category><category>Regularization</category><category>Score-based Models</category>
    </item>
    <item>
      <title>[논문리뷰] CaptionQA: Is Your Caption as Useful as the Image Itself?</title>
      <description>Zicheng Liu이 [arXiv]에 게시한 &#39;CaptionQA: Is Your Caption as Useful as the Image Itself?&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-01-CaptionQA-Is-Your-Caption-as-Useful-as-the-Image-Itself/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-01-CaptionQA-Is-Your-Caption-as-Useful-as-the-Image-Itself/</guid>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Image Captioning</category><category>Caption Evaluation</category><category>Multimodal LLM</category><category>Utility-based Benchmark</category><category>Question Answering (QA)</category><category>Domain-specific Taxonomy</category><category>Hallucination</category><category>MLLM Evaluation</category>
    </item>
    <item>
      <title>[논문리뷰] Captain Safari: A World Engine</title>
      <description>Yitong Li이 [arXiv]에 게시한 &#39;Captain Safari: A World Engine&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-01-Captain-Safari-A-World-Engine/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-01-Captain-Safari-A-World-Engine/</guid>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>World Engine</category><category>3D Consistent Video Generation</category><category>Pose-conditioned Memory</category><category>Camera Control</category><category>FPV Video Synthesis</category><category>Diffusion Models</category><category>Drone Video Dataset</category>
    </item>
    <item>
      <title>[논문리뷰] Architecture Decoupling Is Not All You Need For Unified Multimodal Model</title>
      <description>Hongyu Li이 [arXiv]에 게시한 &#39;Architecture Decoupling Is Not All You Need For Unified Multimodal Model&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-01-Architecture-Decoupling-Is-Not-All-You-Need-For-Unified-Multimodal-Model/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-01-Architecture-Decoupling-Is-Not-All-You-Need-For-Unified-Multimodal-Model/</guid>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Unified Multimodal Models</category><category>Architecture Decoupling</category><category>Cross-Modal Attention</category><category>Attention Interaction Alignment (AIA) Loss</category><category>Task Conflicts</category><category>Image Generation</category><category>Image Understanding</category>
    </item>
    
  </channel>
</rss>