<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>secrett2633's blog</title>
    <description>기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트</description>
    <link>https://blog.secrett2633.site</link>
    <atom:link href="https://blog.secrett2633.site/feed.xml" rel="self" type="application/rss+xml" />
    <language>ko-KR</language>
    <lastBuildDate>Mon, 08 Dec 2025 15:45:23 GMT</lastBuildDate>
    <pubDate>Mon, 08 Dec 2025 15:45:23 GMT</pubDate>
    <ttl>60</ttl>
    <generator>Next.js RSS Generator</generator>
    <managingEditor>secrett2633@example.com (secrett2633)</managingEditor>
    <webMaster>secrett2633@example.com (secrett2633)</webMaster>
    <category>Technology</category>
    <category>Programming</category>
    <category>Django</category>
    <category>Python</category>
    <category>DevOps</category>
    <category>AI/ML</category>
    
        <item>
      <title>[논문리뷰] UltraImage: Rethinking Resolution Extrapolation in Image Diffusion Transformers</title>
      <description>이 [arXiv]에 게시한 &#39;UltraImage: Rethinking Resolution Extrapolation in Image Diffusion Transformers&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-UltraImage-Rethinking-Resolution-Extrapolation-in-Image-Diffusion-Transformers/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-UltraImage-Rethinking-Resolution-Extrapolation-in-Image-Diffusion-Transformers/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Diffusion Transformers</category><category>Resolution Extrapolation</category><category>Positional Encoding</category><category>Frequency Analysis</category><category>Adaptive Attention</category><category>High-Resolution Image Generation</category><category>Image Quality</category><category>Content Repetition</category>
    </item>
    <item>
      <title>[논문리뷰] TV2TV: A Unified Framework for Interleaved Language and Video Generation</title>
      <description>이 [arXiv]에 게시한 &#39;TV2TV: A Unified Framework for Interleaved Language and Video Generation&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-TV2TV-A-Unified-Framework-for-Interleaved-Language-and-Video-Generation/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-TV2TV-A-Unified-Framework-for-Interleaved-Language-and-Video-Generation/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Video Generation</category><category>Language Modeling</category><category>Multimodal AI</category><category>Interleaved Generation</category><category>Flow Matching</category><category>Transformer</category><category>Controllability</category><category>World Models</category>
    </item>
    <item>
      <title>[논문리뷰] Splannequin: Freezing Monocular Mannequin-Challenge Footage with Dual-Detection Splatting</title>
      <description>Yu-Lun Liu이 [arXiv]에 게시한 &#39;Splannequin: Freezing Monocular Mannequin-Challenge Footage with Dual-Detection Splatting&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-Splannequin-Freezing-Monocular-Mannequin-Challenge-Footage-with-Dual-Detection-Splatting/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-Splannequin-Freezing-Monocular-Mannequin-Challenge-Footage-with-Dual-Detection-Splatting/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Monocular 3D Reconstruction</category><category>Mannequin Challenge</category><category>Dynamic Gaussian Splatting</category><category>Freeze-Time Video</category><category>Temporal Consistency</category><category>Artifact Suppression</category><category>Regularization</category>
    </item>
    <item>
      <title>[논문리뷰] SignRoundV2: Closing the Performance Gap in Extremely Low-Bit Post-Training Quantization for LLMs</title>
      <description>이 [arXiv]에 게시한 &#39;SignRoundV2: Closing the Performance Gap in Extremely Low-Bit Post-Training Quantization for LLMs&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-SignRoundV2-Closing-the-Performance-Gap-in-Extremely-Low-Bit-Post-Training-Quantization-for-LLMs/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-SignRoundV2-Closing-the-Performance-Gap-in-Extremely-Low-Bit-Post-Training-Quantization-for-LLMs/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Post-Training Quantization (PTQ)</category><category>Large Language Models (LLMs)</category><category>Low-Bit Quantization</category><category>Mixed-Precision Quantization</category><category>Sensitivity Metric</category><category>Quantization Scale Initialization</category><category>Accuracy Preservation</category>
    </item>
    <item>
      <title>[논문리뷰] Semantics Lead the Way: Harmonizing Semantic and Texture Modeling with Asynchronous Latent Diffusion</title>
      <description>이 [arXiv]에 게시한 &#39;Semantics Lead the Way: Harmonizing Semantic and Texture Modeling with Asynchronous Latent Diffusion&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-Semantics-Lead-the-Way-Harmonizing-Semantic-and-Texture-Modeling-with-Asynchronous-Latent-Diffusion/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-Semantics-Lead-the-Way-Harmonizing-Semantic-and-Texture-Modeling-with-Asynchronous-Latent-Diffusion/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Latent Diffusion Models</category><category>Asynchronous Denoising</category><category>Semantic Modeling</category><category>Texture Modeling</category><category>Image Generation</category><category>Vision Transformer</category><category>VAE</category><category>Fast Convergence</category>
    </item>
    <item>
      <title>[논문리뷰] SeeNav-Agent: Enhancing Vision-Language Navigation with Visual Prompt and Step-Level Policy Optimization</title>
      <description>이 [arXiv]에 게시한 &#39;SeeNav-Agent: Enhancing Vision-Language Navigation with Visual Prompt and Step-Level Policy Optimization&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-SeeNav-Agent-Enhancing-Vision-Language-Navigation-with-Visual-Prompt-and-Step-Level-Policy-Optimization/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-SeeNav-Agent-Enhancing-Vision-Language-Navigation-with-Visual-Prompt-and-Step-Level-Policy-Optimization/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Vision-Language Navigation</category><category>Large Vision-Language Models</category><category>Visual Prompt</category><category>Reinforcement Fine-Tuning</category><category>Policy Optimization</category><category>Embodied AI</category><category>Spatial Reasoning</category><category>Perception Errors</category>
    </item>
    <item>
      <title>[논문리뷰] SIMA 2: A Generalist Embodied Agent for Virtual Worlds</title>
      <description>이 [arXiv]에 게시한 &#39;SIMA 2: A Generalist Embodied Agent for Virtual Worlds&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-SIMA-2-A-Generalist-Embodied-Agent-for-Virtual-Worlds/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-SIMA-2-A-Generalist-Embodied-Agent-for-Virtual-Worlds/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Embodied AI</category><category>Generalist Agent</category><category>Virtual Worlds</category><category>Foundation Models</category><category>Gemini</category><category>Self-Improvement</category><category>Dialogue</category><category>Reasoning</category><category>Reinforcement Learning</category>
    </item>
    <item>
      <title>[논문리뷰] Reward Forcing: Efficient Streaming Video Generation with Rewarded Distribution Matching Distillation</title>
      <description>Hao Ouyang이 [arXiv]에 게시한 &#39;Reward Forcing: Efficient Streaming Video Generation with Rewarded Distribution Matching Distillation&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-Reward-Forcing-Efficient-Streaming-Video-Generation-with-Rewarded-Distribution-Matching-Distillation/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-Reward-Forcing-Efficient-Streaming-Video-Generation-with-Rewarded-Distribution-Matching-Distillation/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Streaming Video Generation</category><category>Video Diffusion Models</category><category>Distribution Matching Distillation</category><category>Reinforcement Learning</category><category>Autoregressive Models</category><category>Attention Sink</category><category>Real-time</category>
    </item>
    <item>
      <title>[논문리뷰] REFLEX: Self-Refining Explainable Fact-Checking via Disentangling Truth into Style and Substance</title>
      <description>Yaxin Fan이 [arXiv]에 게시한 &#39;REFLEX: Self-Refining Explainable Fact-Checking via Disentangling Truth into Style and Substance&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-REFLEX-Self-Refining-Explainable-Fact-Checking-via-Disentangling-Truth-into-Style-and-Substance/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-REFLEX-Self-Refining-Explainable-Fact-Checking-via-Disentangling-Truth-into-Style-and-Substance/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Fact-Checking</category><category>Explainable AI (XAI)</category><category>Large Language Models (LLMs)</category><category>Self-Refinement</category><category>Latent Space</category><category>Disentanglement</category><category>Steering Vectors</category><category>Misinformation</category>
    </item>
    <item>
      <title>[논문리뷰] QKAN-LSTM: Quantum-inspired Kolmogorov-Arnold Long Short-term Memory</title>
      <description>Nan-Yow Chen이 [arXiv]에 게시한 &#39;QKAN-LSTM: Quantum-inspired Kolmogorov-Arnold Long Short-term Memory&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-QKAN-LSTM-Quantum-inspired-Kolmogorov-Arnold-Long-Short-term-Memory/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-QKAN-LSTM-Quantum-inspired-Kolmogorov-Arnold-Long-Short-term-Memory/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Quantum Machine Learning</category><category>Kolmogorov-Arnold Networks</category><category>Long Short-Term Memory (LSTM)</category><category>Time Series Forecasting</category><category>Hybrid Quantum-Classical Learning</category><category>Quantum-inspired</category><category>Recurrent Neural Networks</category>
    </item>
    <item>
      <title>[논문리뷰] PaperDebugger: A Plugin-Based Multi-Agent System for In-Editor Academic Writing, Review, and Editing</title>
      <description>이 [arXiv]에 게시한 &#39;PaperDebugger: A Plugin-Based Multi-Agent System for In-Editor Academic Writing, Review, and Editing&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-PaperDebugger-A-Plugin-Based-Multi-Agent-System-for-In-Editor-Academic-Writing-Review-and-Editing/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-PaperDebugger-A-Plugin-Based-Multi-Agent-System-for-In-Editor-Academic-Writing-Review-and-Editing/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>LLM Agents</category><category>Academic Writing</category><category>In-editor Assistant</category><category>Multi-agent System</category><category>Overleaf Integration</category><category>Chrome Extension</category><category>Kubernetes</category><category>XtraMCP</category>
    </item>
    <item>
      <title>[논문리뷰] On GRPO Collapse in Search-R1: The Lazy Likelihood-Displacement Death Spiral</title>
      <description>Christos Thrampoulidis이 [arXiv]에 게시한 &#39;On GRPO Collapse in Search-R1: The Lazy Likelihood-Displacement Death Spiral&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-On-GRPO-Collapse-in-Search-R1-The-Lazy-Likelihood-Displacement-Death-Spiral/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-On-GRPO-Collapse-in-Search-R1-The-Lazy-Likelihood-Displacement-Death-Spiral/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Reinforcement Learning (RL)</category><category>Large Language Models (LLMs)</category><category>Tool-Integrated Reasoning (TIR)</category><category>GRPO</category><category>Training Stability</category><category>Lazy Likelihood Displacement (LLD)</category><category>Regularization</category><category>Search-R1</category>
    </item>
    <item>
      <title>[논문리뷰] Nex-N1: Agentic Models Trained via a Unified Ecosystem for Large-Scale Environment Construction</title>
      <description>이 [arXiv]에 게시한 &#39;Nex-N1: Agentic Models Trained via a Unified Ecosystem for Large-Scale Environment Construction&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-Nex-N1-Agentic-Models-Trained-via-a-Unified-Ecosystem-for-Large-Scale-Environment-Construction/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-Nex-N1-Agentic-Models-Trained-via-a-Unified-Ecosystem-for-Large-Scale-Environment-Construction/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Agentic Models</category><category>Large Language Models (LLMs)</category><category>Agentic Scaling</category><category>Environment Construction</category><category>NexAU</category><category>NexA4A</category><category>NexGAP</category><category>Interactive Environments</category>
    </item>
    <item>
      <title>[논문리뷰] NeuralRemaster: Phase-Preserving Diffusion for Structure-Aligned Generation</title>
      <description>Vitor Guizilini이 [arXiv]에 게시한 &#39;NeuralRemaster: Phase-Preserving Diffusion for Structure-Aligned Generation&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-NeuralRemaster-Phase-Preserving-Diffusion-for-Structure-Aligned-Generation/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-NeuralRemaster-Phase-Preserving-Diffusion-for-Structure-Aligned-Generation/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Diffusion Models</category><category>Phase Preservation</category><category>Frequency Domain</category><category>Structure-Aligned Generation</category><category>Image-to-Image Translation</category><category>Sim-to-Real</category><category>Generative AI</category>
    </item>
    <item>
      <title>[논문리뷰] Model-Based and Sample-Efficient AI-Assisted Math Discovery in Sphere Packing</title>
      <description>Jun Wang이 [arXiv]에 게시한 &#39;Model-Based and Sample-Efficient AI-Assisted Math Discovery in Sphere Packing&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-Model-Based-and-Sample-Efficient-AI-Assisted-Math-Discovery-in-Sphere-Packing/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-Model-Based-and-Sample-Efficient-AI-Assisted-Math-Discovery-in-Sphere-Packing/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Sphere Packing</category><category>Mathematical Discovery</category><category>Semidefinite Programming (SDP)</category><category>Bayesian Optimization (BO)</category><category>Monte Carlo Tree Search (MCTS)</category><category>Sample-Efficient AI</category><category>Model-Based Learning</category><category>Geometric Constraints</category>
    </item>
    <item>
      <title>[논문리뷰] Mitigating Object and Action Hallucinations in Multimodal LLMs via Self-Augmented Contrastive Alignment</title>
      <description>이 [arXiv]에 게시한 &#39;Mitigating Object and Action Hallucinations in Multimodal LLMs via Self-Augmented Contrastive Alignment&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-Mitigating-Object-and-Action-Hallucinations-in-Multimodal-LLMs-via-Self-Augmented-Contrastive-Alignment/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-Mitigating-Object-and-Action-Hallucinations-in-Multimodal-LLMs-via-Self-Augmented-Contrastive-Alignment/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Multimodal LLMs</category><category>Video Understanding</category><category>Hallucination Mitigation</category><category>Object Hallucination</category><category>Action Hallucination</category><category>Contrastive Learning</category><category>Self-Augmentation</category><category>Tracklet-Phrase Alignment</category>
    </item>
    <item>
      <title>[논문리뷰] Mitigating Catastrophic Forgetting in Target Language Adaptation of LLMs via Source-Shielded Updates</title>
      <description>Nikolaos Aletras이 [arXiv]에 게시한 &#39;Mitigating Catastrophic Forgetting in Target Language Adaptation of LLMs via Source-Shielded Updates&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-Mitigating-Catastrophic-Forgetting-in-Target-Language-Adaptation-of-LLMs-via-Source-Shielded-Updates/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-Mitigating-Catastrophic-Forgetting-in-Target-Language-Adaptation-of-LLMs-via-Source-Shielded-Updates/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Large Language Models (LLMs)</category><category>Catastrophic Forgetting</category><category>Language Adaptation</category><category>Continual Pre-training</category><category>Parameter Freezing</category><category>Low-Resource Languages</category><category>Source Knowledge Preservation</category>
    </item>
    <item>
      <title>[논문리뷰] Live Avatar: Streaming Real-time Audio-Driven Avatar Generation with Infinite Length</title>
      <description>Shifeng Zhang이 [arXiv]에 게시한 &#39;Live Avatar: Streaming Real-time Audio-Driven Avatar Generation with Infinite Length&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-Live-Avatar-Streaming-Real-time-Audio-Driven-Avatar-Generation-with-Infinite-Length/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-Live-Avatar-Streaming-Real-time-Audio-Driven-Avatar-Generation-with-Infinite-Length/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Audio-Driven Avatar Generation</category><category>Real-time Streaming</category><category>Diffusion Models</category><category>Infinite Length</category><category>Pipeline Parallelism</category><category>Temporal Consistency</category><category>Model Distillation</category>
    </item>
    <item>
      <title>[논문리뷰] LATTICE: Democratize High-Fidelity 3D Generation at Scale</title>
      <description>Qingxiang Lin이 [arXiv]에 게시한 &#39;LATTICE: Democratize High-Fidelity 3D Generation at Scale&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-LATTICE-Democratize-High-Fidelity-3D-Generation-at-Scale/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-LATTICE-Democratize-High-Fidelity-3D-Generation-at-Scale/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>3D Generation</category><category>High-Fidelity</category><category>Latent Representation</category><category>Voxel Grid</category><category>Diffusion Models</category><category>Transformer</category><category>Scalable AI</category><category>Asset Creation</category>
    </item>
    <item>
      <title>[논문리뷰] Generative Neural Video Compression via Video Diffusion Prior</title>
      <description>이 [arXiv]에 게시한 &#39;Generative Neural Video Compression via Video Diffusion Prior&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-Generative-Neural-Video-Compression-via-Video-Diffusion-Prior/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-Generative-Neural-Video-Compression-via-Video-Diffusion-Prior/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Neural Video Compression</category><category>Diffusion Models</category><category>Generative Models</category><category>Video Compression</category><category>Temporal Coherence</category><category>Perceptual Quality</category><category>Flow Matching</category><category>Video Diffusion Transformer (VideoDiT)</category>
    </item>
    <item>
      <title>[논문리뷰] GaussianBlender: Instant Stylization of 3D Gaussians with Disentangled Latent Spaces</title>
      <description>Sezer Karaoglu이 [arXiv]에 게시한 &#39;GaussianBlender: Instant Stylization of 3D Gaussians with Disentangled Latent Spaces&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-GaussianBlender-Instant-Stylization-of-3D-Gaussians-with-Disentangled-Latent-Spaces/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-GaussianBlender-Instant-Stylization-of-3D-Gaussians-with-Disentangled-Latent-Spaces/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>3D Gaussian Splatting</category><category>Text-to-3D Stylization</category><category>Latent Diffusion Models</category><category>Disentangled Latent Spaces</category><category>Feed-forward Editing</category><category>Geometry Preservation</category><category>Multi-view Consistency</category>
    </item>
    <item>
      <title>[논문리뷰] FMA-Net++: Motion- and Exposure-Aware Real-World Joint Video Super-Resolution and Deblurring</title>
      <description>Munchurl Kim이 [arXiv]에 게시한 &#39;FMA-Net++: Motion- and Exposure-Aware Real-World Joint Video Super-Resolution and Deblurring&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-FMA-Net-Motion-and-Exposure-Aware-Real-World-Joint-Video-Super-Resolution-and-Deblurring/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-FMA-Net-Motion-and-Exposure-Aware-Real-World-Joint-Video-Super-Resolution-and-Deblurring/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Video Super-Resolution</category><category>Video Deblurring</category><category>Joint Restoration</category><category>Exposure-Aware</category><category>Motion Compensation</category><category>Transformer Architecture</category><category>Dynamic Filtering</category><category>Real-World Degradations</category>
    </item>
    <item>
      <title>[논문리뷰] EgoLCD: Egocentric Video Generation with Long Context Diffusion</title>
      <description>이 [arXiv]에 게시한 &#39;EgoLCD: Egocentric Video Generation with Long Context Diffusion&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-EgoLCD-Egocentric-Video-Generation-with-Long-Context-Diffusion/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-EgoLCD-Egocentric-Video-Generation-with-Long-Context-Diffusion/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Egocentric Video Generation</category><category>Long-Context Diffusion</category><category>Long-Short Memory</category><category>Sparse KV Cache</category><category>Memory Regulation Loss</category><category>Structured Narrative Prompting</category><category>World Models</category><category>Embodied AI</category>
    </item>
    <item>
      <title>[논문리뷰] DynamicVerse: A Physically-Aware Multimodal Framework for 4D World Modeling</title>
      <description>이 [arXiv]에 게시한 &#39;DynamicVerse: A Physically-Aware Multimodal Framework for 4D World Modeling&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-DynamicVerse-A-Physically-Aware-Multimodal-Framework-for-4D-World-Modeling/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-DynamicVerse-A-Physically-Aware-Multimodal-Framework-for-4D-World-Modeling/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>4D World Modeling</category><category>Multimodal Data</category><category>Dynamic Scenes</category><category>Metric-Scale</category><category>Bundle Adjustment</category><category>Foundation Models</category><category>Video Analysis</category><category>Data Curation</category>
    </item>
    <item>
      <title>[논문리뷰] DraCo: Draft as CoT for Text-to-Image Preview and Rare Concept Generation</title>
      <description>Ziyu Guo이 [arXiv]에 게시한 &#39;DraCo: Draft as CoT for Text-to-Image Preview and Rare Concept Generation&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-DraCo-Draft-as-CoT-for-Text-to-Image-Preview-and-Rare-Concept-Generation/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-DraCo-Draft-as-CoT-for-Text-to-Image-Preview-and-Rare-Concept-Generation/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Text-to-Image Generation</category><category>Chain-of-Thought (CoT)</category><category>Multimodal Large Language Models (MLLMs)</category><category>Visual Planning</category><category>Rare Concept Generation</category><category>Drafting</category><category>Classifier-Free Guidance (CFG)</category><category>Image Refinement</category>
    </item>
    <item>
      <title>[논문리뷰] DAComp: Benchmarking Data Agents across the Full Data Intelligence Lifecycle</title>
      <description>이 [arXiv]에 게시한 &#39;DAComp: Benchmarking Data Agents across the Full Data Intelligence Lifecycle&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-DAComp-Benchmarking-Data-Agents-across-the-Full-Data-Intelligence-Lifecycle/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-DAComp-Benchmarking-Data-Agents-across-the-Full-Data-Intelligence-Lifecycle/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Data Agents</category><category>Benchmarking</category><category>Data Engineering</category><category>Data Analysis</category><category>LLM-as-Judge</category><category>Full Data Intelligence Lifecycle</category><category>Repository-Level</category><category>Open-Ended Tasks</category>
    </item>
    <item>
      <title>[논문리뷰] BulletTime: Decoupled Control of Time and Camera Pose for Video Generation</title>
      <description>Jan Ackermann이 [arXiv]에 게시한 &#39;BulletTime: Decoupled Control of Time and Camera Pose for Video Generation&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-BulletTime-Decoupled-Control-of-Time-and-Camera-Pose-for-Video-Generation/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-BulletTime-Decoupled-Control-of-Time-and-Camera-Pose-for-Video-Generation/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Video Generation</category><category>Diffusion Models</category><category>4D Control</category><category>Camera Pose Control</category><category>Time Control</category><category>Positional Encoding</category><category>Adaptive Normalization</category><category>Synthetic Dataset</category>
    </item>
    <item>
      <title>[논문리뷰] Aligned but Stereotypical? The Hidden Influence of System Prompts on Social Bias in LVLM-Based Text-to-Image Models</title>
      <description>이 [arXiv]에 게시한 &#39;Aligned but Stereotypical? The Hidden Influence of System Prompts on Social Bias in LVLM-Based Text-to-Image Models&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-Aligned-but-Stereotypical-The-Hidden-Influence-of-System-Prompts-on-Social-Bias-in-LVLM-Based-Text-to-Image-Models/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-Aligned-but-Stereotypical-The-Hidden-Influence-of-System-Prompts-on-Social-Bias-in-LVLM-Based-Text-to-Image-Models/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Text-to-Image</category><category>LVLM</category><category>Social Bias</category><category>System Prompts</category><category>Bias Mitigation</category><category>Meta-Prompting</category><category>Fairness</category><category>Generative AI</category>
    </item>
    <item>
      <title>[논문리뷰] ARM-Thinker: Reinforcing Multimodal Generative Reward Models with Agentic Tool Use and Visual Reasoning</title>
      <description>이 [arXiv]에 게시한 &#39;ARM-Thinker: Reinforcing Multimodal Generative Reward Models with Agentic Tool Use and Visual Reasoning&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-ARM-Thinker-Reinforcing-Multimodal-Generative-Reward-Models-with-Agentic-Tool-Use-and-Visual-Reasoning/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-ARM-Thinker-Reinforcing-Multimodal-Generative-Reward-Models-with-Agentic-Tool-Use-and-Visual-Reasoning/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Multimodal Reward Models</category><category>Agentic AI</category><category>Tool Use</category><category>Reinforcement Learning</category><category>Visual Reasoning</category><category>Multimodal LLMs</category><category>Instruction Following</category><category>Evaluation Benchmarks</category>
    </item>
    <item>
      <title>[논문리뷰] 4DLangVGGT: 4D Language-Visual Geometry Grounded Transformer</title>
      <description>이 [arXiv]에 게시한 &#39;4DLangVGGT: 4D Language-Visual Geometry Grounded Transformer&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2025-12-05-4DLangVGGT-4D-Language-Visual-Geometry-Grounded-Transformer/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2025-12-05-4DLangVGGT-4D-Language-Visual-Geometry-Grounded-Transformer/</guid>
      <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>4D Scene Understanding</category><category>Language Grounding</category><category>Transformer</category><category>Feed-forward Network</category><category>Semantic Field</category><category>Geometry Reconstruction</category><category>Embodied AI</category>
    </item>
    
  </channel>
</rss>