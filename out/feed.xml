<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>secrett2633's blog</title>
    <description>기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트</description>
    <link>https://blog.secrett2633.cloud</link>
    <atom:link href="https://blog.secrett2633.cloud/feed.xml" rel="self" type="application/rss+xml" />
    <language>ko-KR</language>
    <lastBuildDate>Thu, 29 Jan 2026 14:54:57 GMT</lastBuildDate>
    <pubDate>Thu, 29 Jan 2026 14:54:57 GMT</pubDate>
    <ttl>60</ttl>
    <generator>Next.js RSS Generator</generator>
    <managingEditor>secrett2633@example.com (secrett2633)</managingEditor>
    <webMaster>secrett2633@example.com (secrett2633)</webMaster>
    <category>Technology</category>
    <category>Programming</category>
    <category>Django</category>
    <category>Python</category>
    <category>DevOps</category>
    <category>AI/ML</category>
    
        <item>
      <title>[논문리뷰] World Craft: Agentic Framework to Create Visualizable Worlds via Text</title>
      <description>이 [arXiv]에 게시한 &#39;World Craft: Agentic Framework to Create Visualizable Worlds via Text&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-28-World-Craft-Agentic-Framework-to-Create-Visualizable-Worlds-via-Text/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-28-World-Craft-Agentic-Framework-to-Create-Visualizable-Worlds-via-Text/</guid>
      <pubDate>Wed, 28 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Generative Agents</category><category>AI Town</category><category>LLM</category><category>Environment Creation</category><category>Multi-agent System</category><category>Spatial Reasoning</category><category>Text-to-World</category><category>Reverse Synthesis</category>
    </item>
    <item>
      <title>[논문리뷰] Visual Generation Unlocks Human-Like Reasoning through Multimodal World Models</title>
      <description>이 [arXiv]에 게시한 &#39;Visual Generation Unlocks Human-Like Reasoning through Multimodal World Models&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-28-Visual-Generation-Unlocks-Human-Like-Reasoning-through-Multimodal-World-Models/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-28-Visual-Generation-Unlocks-Human-Like-Reasoning-through-Multimodal-World-Models/</guid>
      <pubDate>Wed, 28 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Multimodal AI</category><category>World Models</category><category>Visual Generation</category><category>Chain-of-Thought (CoT)</category><category>Multimodal Reasoning</category><category>Unified Multimodal Models</category><category>Spatial-Physical Reasoning</category>
    </item>
    <item>
      <title>[논문리뷰] TriPlay-RL: Tri-Role Self-Play Reinforcement Learning for LLM Safety Alignment</title>
      <description>이 [arXiv]에 게시한 &#39;TriPlay-RL: Tri-Role Self-Play Reinforcement Learning for LLM Safety Alignment&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-28-TriPlay-RL-Tri-Role-Self-Play-Reinforcement-Learning-for-LLM-Safety-Alignment/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-28-TriPlay-RL-Tri-Role-Self-Play-Reinforcement-Learning-for-LLM-Safety-Alignment/</guid>
      <pubDate>Wed, 28 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>LLM Safety Alignment</category><category>Reinforcement Learning</category><category>Self-Play</category><category>Red Teaming</category><category>Adversarial Training</category><category>Multi-Role Framework</category><category>Reward Hacking Mitigation</category>
    </item>
    <item>
      <title>[논문리뷰] Selective Steering: Norm-Preserving Control Through Discriminative Layer Selection</title>
      <description>이 [arXiv]에 게시한 &#39;Selective Steering: Norm-Preserving Control Through Discriminative Layer Selection&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-28-Selective-Steering-Norm-Preserving-Control-Through-Discriminative-Layer-Selection/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-28-Selective-Steering-Norm-Preserving-Control-Through-Discriminative-Layer-Selection/</guid>
      <pubDate>Wed, 28 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Activation Steering</category><category>Large Language Models (LLMs)</category><category>Norm Preservation</category><category>Discriminative Layer Selection</category><category>Behavior Control</category><category>Inference-time Intervention</category><category>Angular Steering</category>
    </item>
    <item>
      <title>[논문리뷰] Revisiting Parameter Server in LLM Post-Training</title>
      <description>이 [arXiv]에 게시한 &#39;Revisiting Parameter Server in LLM Post-Training&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-28-Revisiting-Parameter-Server-in-LLM-Post-Training/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-28-Revisiting-Parameter-Server-in-LLM-Post-Training/</guid>
      <pubDate>Wed, 28 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>LLM Post-Training</category><category>Parameter Server</category><category>Distributed Training</category><category>FSDP</category><category>On-Demand Communication</category><category>Workload Imbalance</category><category>Communication Optimization</category><category>Deep Learning</category>
    </item>
    <item>
      <title>[논문리뷰] Post-LayerNorm Is Back: Stable, ExpressivE, and Deep</title>
      <description>이 [arXiv]에 게시한 &#39;Post-LayerNorm Is Back: Stable, ExpressivE, and Deep&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-28-Post-LayerNorm-Is-Back-Stable-ExpressivE-and-Deep/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-28-Post-LayerNorm-Is-Back-Stable-ExpressivE-and-Deep/</guid>
      <pubDate>Wed, 28 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Transformer Architecture</category><category>Layer Normalization</category><category>Depth Scaling</category><category>Training Stability</category><category>Large Language Models</category><category>Gradient Flow</category><category>Highway Networks</category><category>Post-LayerNorm</category>
    </item>
    <item>
      <title>[논문리뷰] HalluCitation Matters: Revealing the Impact of Hallucinated References with 300 Hallucinated Papers in ACL Conferences</title>
      <description>Taro Watanabe이 [arXiv]에 게시한 &#39;HalluCitation Matters: Revealing the Impact of Hallucinated References with 300 Hallucinated Papers in ACL Conferences&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-28-HalluCitation-Matters-Revealing-the-Impact-of-Hallucinated-References-with-300-Hallucinated-Papers-in-ACL-Conferences/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-28-HalluCitation-Matters-Revealing-the-Impact-of-Hallucinated-References-with-300-Hallucinated-Papers-in-ACL-Conferences/</guid>
      <pubDate>Wed, 28 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Hallucinated Citations</category><category>NLP Conferences</category><category>Citation Detection</category><category>Academic Integrity</category><category>Peer Review</category><category>Large Language Models (LLMs)</category><category>Bibliometrics</category>
    </item>
    <item>
      <title>[논문리뷰] GPCR-Filter: a deep learning framework for efficient and precise GPCR modulator discovery</title>
      <description>이 [arXiv]에 게시한 &#39;GPCR-Filter: a deep learning framework for efficient and precise GPCR modulator discovery&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-28-GPCR-Filter-a-deep-learning-framework-for-efficient-and-precise-GPCR-modulator-discovery/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-28-GPCR-Filter-a-deep-learning-framework-for-efficient-and-precise-GPCR-modulator-discovery/</guid>
      <pubDate>Wed, 28 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>GPCR</category><category>Drug Discovery</category><category>Deep Learning</category><category>Protein Language Model</category><category>Graph Neural Network</category><category>Attention Mechanism</category><category>Drug Target Interaction</category><category>Virtual Screening</category>
    </item>
    <item>
      <title>[논문리뷰] FABLE: Forest-Based Adaptive Bi-Path LLM-Enhanced Retrieval for Multi-Document Reasoning</title>
      <description>이 [arXiv]에 게시한 &#39;FABLE: Forest-Based Adaptive Bi-Path LLM-Enhanced Retrieval for Multi-Document Reasoning&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-28-FABLE-Forest-Based-Adaptive-Bi-Path-LLM-Enhanced-Retrieval-for-Multi-Document-Reasoning/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-28-FABLE-Forest-Based-Adaptive-Bi-Path-LLM-Enhanced-Retrieval-for-Multi-Document-Reasoning/</guid>
      <pubDate>Wed, 28 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>RAG</category><category>LLM-Enhanced Retrieval</category><category>Multi-Document Reasoning</category><category>Hierarchical Indexing</category><category>Bi-Path Retrieval</category><category>Adaptive Retrieval</category><category>Knowledge Organization</category><category>Context Window Optimization</category>
    </item>
    <item>
      <title>[논문리뷰] AgentDoG: A Diagnostic Guardrail Framework for AI Agent Safety and Security</title>
      <description>이 [arXiv]에 게시한 &#39;AgentDoG: A Diagnostic Guardrail Framework for AI Agent Safety and Security&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-28-AgentDoG-A-Diagnostic-Guardrail-Framework-for-AI-Agent-Safety-and-Security/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-28-AgentDoG-A-Diagnostic-Guardrail-Framework-for-AI-Agent-Safety-and-Security/</guid>
      <pubDate>Wed, 28 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>AI Agents</category><category>Safety Guardrails</category><category>Explainable AI (XAI)</category><category>Risk Taxonomy</category><category>Benchmarking</category><category>LLM Safety</category><category>Tool Use</category><category>Agent Alignment</category>
    </item>
    <item>
      <title>[논문리뷰] AdaReasoner: Dynamic Tool Orchestration for Iterative Visual Reasoning</title>
      <description>이 [arXiv]에 게시한 &#39;AdaReasoner: Dynamic Tool Orchestration for Iterative Visual Reasoning&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-28-AdaReasoner-Dynamic-Tool-Orchestration-for-Iterative-Visual-Reasoning/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-28-AdaReasoner-Dynamic-Tool-Orchestration-for-Iterative-Visual-Reasoning/</guid>
      <pubDate>Wed, 28 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Multimodal LLMs</category><category>Tool Orchestration</category><category>Visual Reasoning</category><category>Reinforcement Learning</category><category>Adaptive Learning</category><category>Generalization</category><category>Tool Use</category>
    </item>
    <item>
      <title>[논문리뷰] AVMeme Exam: A Multimodal Multilingual Multicultural Benchmark for LLMs&#39; Contextual and Cultural Knowledge and Thinking</title>
      <description>이 [arXiv]에 게시한 &#39;AVMeme Exam: A Multimodal Multilingual Multicultural Benchmark for LLMs&#39; Contextual and Cultural Knowledge and Thinking&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-28-AVMeme-Exam-A-Multimodal-Multilingual-Multicultural-Benchmark-for-LLMs-Contextual-and-Cultural-Knowledge-and-Thinking/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-28-AVMeme-Exam-A-Multimodal-Multilingual-Multicultural-Benchmark-for-LLMs-Contextual-and-Cultural-Knowledge-and-Thinking/</guid>
      <pubDate>Wed, 28 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Multimodal LLMs</category><category>Benchmark</category><category>Cultural Understanding</category><category>Contextual Inference</category><category>Audio-Visual Memes</category><category>Multilingual</category><category>Q&amp;A Evaluation</category>
    </item>
    <item>
      <title>[논문리뷰] A Pragmatic VLA Foundation Model</title>
      <description>이 [arXiv]에 게시한 &#39;A Pragmatic VLA Foundation Model&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-28-A-Pragmatic-VLA-Foundation-Model/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-28-A-Pragmatic-VLA-Foundation-Model/</guid>
      <pubDate>Wed, 28 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Vision-Language-Action Model</category><category>Robotics</category><category>Foundation Models</category><category>Multi-Embodiment Learning</category><category>Data Scaling</category><category>Computational Efficiency</category><category>Real-world Deployment</category>
    </item>
    <item>
      <title>[논문리뷰] iFSQ: Improving FSQ for Image Generation with 1 Line of Code</title>
      <description>이 [arXiv]에 게시한 &#39;iFSQ: Improving FSQ for Image Generation with 1 Line of Code&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-27-iFSQ-Improving-FSQ-for-Image-Generation-with-1-Line-of-Code/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-27-iFSQ-Improving-FSQ-for-Image-Generation-with-1-Line-of-Code/</guid>
      <pubDate>Tue, 27 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Finite Scalar Quantization (FSQ)</category><category>Image Generation</category><category>Autoregressive Models</category><category>Diffusion Models</category><category>Quantization</category><category>Tokenization</category><category>Representation Alignment (REPA)</category><category>Latent Space</category>
    </item>
    <item>
      <title>[논문리뷰] daVinci-Dev: Agent-native Mid-training for Software Engineering</title>
      <description>이 [arXiv]에 게시한 &#39;daVinci-Dev: Agent-native Mid-training for Software Engineering&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-27-daVinci-Dev-Agent-native-Mid-training-for-Software-Engineering/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-27-daVinci-Dev-Agent-native-Mid-training-for-Software-Engineering/</guid>
      <pubDate>Tue, 27 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Agentic Software Engineering</category><category>Mid-training</category><category>Large Language Models</category><category>Agent-native Data</category><category>Contextual Trajectories</category><category>Environmental Trajectories</category><category>SWE-Bench Verified</category><category>Code Generation</category>
    </item>
    <item>
      <title>[논문리뷰] VIBEVOICE-ASR Technical Report</title>
      <description>이 [arXiv]에 게시한 &#39;VIBEVOICE-ASR Technical Report&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-27-VIBEVOICE-ASR-Technical-Report/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-27-VIBEVOICE-ASR-Technical-Report/</guid>
      <pubDate>Tue, 27 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Automatic Speech Recognition</category><category>Speaker Diarization</category><category>Long-form Audio</category><category>Large Language Models</category><category>End-to-end Speech Processing</category><category>Multilingual</category><category>Context-aware ASR</category>
    </item>
    <item>
      <title>[논문리뷰] The Script is All You Need: An Agentic Framework for Long-Horizon Dialogue-to-Cinematic Video Generation</title>
      <description>이 [arXiv]에 게시한 &#39;The Script is All You Need: An Agentic Framework for Long-Horizon Dialogue-to-Cinematic Video Generation&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-27-The-Script-is-All-You-Need-An-Agentic-Framework-for-Long-Horizon-Dialogue-to-Cinematic-Video-Generation/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-27-The-Script-is-All-You-Need-An-Agentic-Framework-for-Long-Horizon-Dialogue-to-Cinematic-Video-Generation/</guid>
      <pubDate>Tue, 27 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Dialogue-to-Video Generation</category><category>Agentic AI</category><category>Cinematic Scripting</category><category>Long-Horizon Video Synthesis</category><category>Visual Coherence</category><category>Reinforcement Learning</category><category>Multimodal LLM</category>
    </item>
    <item>
      <title>[논문리뷰] Teaching Models to Teach Themselves: Reasoning at the Edge of Learnability</title>
      <description>이 [arXiv]에 게시한 &#39;Teaching Models to Teach Themselves: Reasoning at the Edge of Learnability&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-27-Teaching-Models-to-Teach-Themselves-Reasoning-at-the-Edge-of-Learnability/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-27-Teaching-Models-to-Teach-Themselves-Reasoning-at-the-Edge-of-Learnability/</guid>
      <pubDate>Tue, 27 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Meta-RL</category><category>Curriculum Learning</category><category>Self-Play</category><category>LLM Reasoning</category><category>Sparse Rewards</category><category>Question Generation</category><category>Bilevel Optimization</category>
    </item>
    <item>
      <title>[논문리뷰] SkyReels-V3 Technique Report</title>
      <description>이 [arXiv]에 게시한 &#39;SkyReels-V3 Technique Report&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-27-SkyReels-V3-Technique-Report/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-27-SkyReels-V3-Technique-Report/</guid>
      <pubDate>Tue, 27 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Video Generation</category><category>Multimodal AI</category><category>Diffusion Models</category><category>Transformer Architecture</category><category>Reference-guided Generation</category><category>Video-to-Video</category><category>Audio-driven Animation</category><category>Temporal Consistency</category>
    </item>
    <item>
      <title>[논문리뷰] Scientific Image Synthesis: Benchmarking, Methodologies, and Downstream Utility</title>
      <description>이 [arXiv]에 게시한 &#39;Scientific Image Synthesis: Benchmarking, Methodologies, and Downstream Utility&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-27-Scientific-Image-Synthesis-Benchmarking-Methodologies-and-Downstream-Utility/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-27-Scientific-Image-Synthesis-Benchmarking-Methodologies-and-Downstream-Utility/</guid>
      <pubDate>Tue, 27 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Scientific Image Synthesis</category><category>Multimodal Reasoning</category><category>Text-to-Image</category><category>Benchmarking</category><category>Programmatic Synthesis</category><category>Large Multimodal Models</category><category>Synthetic Data</category>
    </item>
    <item>
      <title>[논문리뷰] STAR: Semantic Table Representation with Header-Aware Clustering and Adaptive Weighted Fusion</title>
      <description>이 [arXiv]에 게시한 &#39;STAR: Semantic Table Representation with Header-Aware Clustering and Adaptive Weighted Fusion&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-27-STAR-Semantic-Table-Representation-with-Header-Aware-Clustering-and-Adaptive-Weighted-Fusion/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-27-STAR-Semantic-Table-Representation-with-Header-Aware-Clustering-and-Adaptive-Weighted-Fusion/</guid>
      <pubDate>Tue, 27 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Table Retrieval</category><category>Semantic Representation</category><category>K-means Clustering</category><category>Weighted Fusion</category><category>Large Language Models</category><category>Query Generation</category><category>Information Retrieval</category>
    </item>
    <item>
      <title>[논문리뷰] SAGE: Steerable Agentic Data Generation for Deep Search with Execution Feedback</title>
      <description>이 [arXiv]에 게시한 &#39;SAGE: Steerable Agentic Data Generation for Deep Search with Execution Feedback&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-27-SAGE-Steerable-Agentic-Data-Generation-for-Deep-Search-with-Execution-Feedback/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-27-SAGE-Steerable-Agentic-Data-Generation-for-Deep-Search-with-Execution-Feedback/</guid>
      <pubDate>Tue, 27 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Deep Search</category><category>Agentic Data Generation</category><category>LLMs</category><category>Execution Feedback</category><category>Reinforcement Learning</category><category>Question Answering</category><category>Synthetic Data</category>
    </item>
    <item>
      <title>[논문리뷰] Paying Less Generalization Tax: A Cross-Domain Generalization Study of RL Training for LLM Agents</title>
      <description>이 [arXiv]에 게시한 &#39;Paying Less Generalization Tax: A Cross-Domain Generalization Study of RL Training for LLM Agents&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-27-Paying-Less-Generalization-Tax-A-Cross-Domain-Generalization-Study-of-RL-Training-for-LLM-Agents/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-27-Paying-Less-Generalization-Tax-A-Cross-Domain-Generalization-Study-of-RL-Training-for-LLM-Agents/</guid>
      <pubDate>Tue, 27 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>LLM Agents</category><category>Reinforcement Learning</category><category>Cross-Domain Generalization</category><category>State Information Richness</category><category>Planning Complexity</category><category>State Augmentation</category><category>Step-by-Step Reasoning</category><category>Mid-Training</category>
    </item>
    <item>
      <title>[논문리뷰] Less Is More -- Until It Breaks: Security Pitfalls of Vision Token Compression in Large Vision-Language Models</title>
      <description>Guanhong Tao이 [arXiv]에 게시한 &#39;Less Is More -- Until It Breaks: Security Pitfalls of Vision Token Compression in Large Vision-Language Models&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-27-Less-Is-More-Until-It-Breaks-Security-Pitfalls-of-Vision-Token-Compression-in-Large-Vision-Language-Models/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-27-Less-Is-More-Until-It-Breaks-Security-Pitfalls-of-Vision-Token-Compression-in-Large-Vision-Language-Models/</guid>
      <pubDate>Tue, 27 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>LVLM Security</category><category>Token Compression</category><category>Adversarial Attack</category><category>Robustness Degradation</category><category>Compression-Aware Attack</category><category>Efficiency-Security Trade-off</category><category>Black-box Attack</category>
    </item>
    <item>
      <title>[논문리뷰] End-to-End Joint ASR and Speaker Role Diarization with Child-Adult Interactions</title>
      <description>Shrikanth Narayanan이 [arXiv]에 게시한 &#39;End-to-End Joint ASR and Speaker Role Diarization with Child-Adult Interactions&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-27-End-to-End-Joint-ASR-and-Speaker-Role-Diarization-with-Child-Adult-Interactions/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-27-End-to-End-Joint-ASR-and-Speaker-Role-Diarization-with-Child-Adult-Interactions/</guid>
      <pubDate>Tue, 27 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>End-to-End ASR</category><category>Speaker Diarization</category><category>Child Speech Processing</category><category>Whisper Model</category><category>Serialized Output Training</category><category>Multi-task Learning</category><category>State-Machine Decoding</category>
    </item>
    <item>
      <title>[논문리뷰] Elastic Attention: Test-time Adaptive Sparsity Ratios for Efficient Transformers</title>
      <description>이 [arXiv]에 게시한 &#39;Elastic Attention: Test-time Adaptive Sparsity Ratios for Efficient Transformers&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-27-Elastic-Attention-Test-time-Adaptive-Sparsity-Ratios-for-Efficient-Transformers/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-27-Elastic-Attention-Test-time-Adaptive-Sparsity-Ratios-for-Efficient-Transformers/</guid>
      <pubDate>Tue, 27 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Transformer</category><category>Sparse Attention</category><category>Adaptive Sparsity</category><category>Efficient LLM</category><category>Attention Router</category><category>Long-Context</category><category>Hybrid Attention</category>
    </item>
    <item>
      <title>[논문리뷰] DeepPlanning: Benchmarking Long-Horizon Agentic Planning with Verifiable Constraints</title>
      <description>이 [arXiv]에 게시한 &#39;DeepPlanning: Benchmarking Long-Horizon Agentic Planning with Verifiable Constraints&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-27-DeepPlanning-Benchmarking-Long-Horizon-Agentic-Planning-with-Verifiable-Constraints/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-27-DeepPlanning-Benchmarking-Long-Horizon-Agentic-Planning-with-Verifiable-Constraints/</guid>
      <pubDate>Tue, 27 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>LLM Agents</category><category>Long-Horizon Planning</category><category>Benchmarking</category><category>Verifiable Constraints</category><category>Tool Use</category><category>Constraint Optimization</category><category>Information Acquisition</category><category>Travel Planning</category><category>Shopping Planning</category>
    </item>
    <item>
      <title>[논문리뷰] DRPG (Decompose, Retrieve, Plan, Generate): An Agentic Framework for Academic Rebuttal</title>
      <description>Jiaxuan You이 [arXiv]에 게시한 &#39;DRPG (Decompose, Retrieve, Plan, Generate): An Agentic Framework for Academic Rebuttal&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-27-DRPG-Decompose-Retrieve-Plan-Generate-An-Agentic-Framework-for-Academic-Rebuttal/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-27-DRPG-Decompose-Retrieve-Plan-Generate-An-Agentic-Framework-for-Academic-Rebuttal/</guid>
      <pubDate>Tue, 27 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Academic Rebuttal</category><category>LLM Agents</category><category>Peer Review Automation</category><category>Generative AI</category><category>Retrieval-Augmented Generation (RAG)</category><category>Strategic Planning</category><category>Persuasion</category>
    </item>
    <item>
      <title>[논문리뷰] Can LLMs Clean Up Your Mess? A Survey of Application-Ready Data Preparation with LLMs</title>
      <description>이 [arXiv]에 게시한 &#39;Can LLMs Clean Up Your Mess? A Survey of Application-Ready Data Preparation with LLMs&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-27-Can-LLMs-Clean-Up-Your-Mess-A-Survey-of-Application-Ready-Data-Preparation-with-LLMs/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-27-Can-LLMs-Clean-Up-Your-Mess-A-Survey-of-Application-Ready-Data-Preparation-with-LLMs/</guid>
      <pubDate>Tue, 27 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Data Preparation</category><category>LLMs</category><category>Data Cleaning</category><category>Data Integration</category><category>Data Enrichment</category><category>AI Agents</category><category>Semantic Reasoning</category><category>Workflow Automation</category>
    </item>
    <item>
      <title>[논문리뷰] CGPT: Cluster-Guided Partial Tables with LLM-Generated Supervision for Table Retrieval</title>
      <description>이 [arXiv]에 게시한 &#39;CGPT: Cluster-Guided Partial Tables with LLM-Generated Supervision for Table Retrieval&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-27-CGPT-Cluster-Guided-Partial-Tables-with-LLM-Generated-Supervision-for-Table-Retrieval/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-27-CGPT-Cluster-Guided-Partial-Tables-with-LLM-Generated-Supervision-for-Table-Retrieval/</guid>
      <pubDate>Tue, 27 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Table Retrieval</category><category>LLM Supervision</category><category>K-means Clustering</category><category>Partial Table</category><category>Contrastive Learning</category><category>Embedding Fine-tuning</category><category>Synthetic Query Generation</category>
    </item>
    
  </channel>
</rss>