<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>secrett2633's blog</title>
    <description>기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트</description>
    <link>https://blog.secrett2633.site</link>
    <atom:link href="https://blog.secrett2633.site/feed.xml" rel="self" type="application/rss+xml" />
    <language>ko-KR</language>
    <lastBuildDate>Mon, 12 Jan 2026 19:23:40 GMT</lastBuildDate>
    <pubDate>Mon, 12 Jan 2026 19:23:40 GMT</pubDate>
    <ttl>60</ttl>
    <generator>Next.js RSS Generator</generator>
    <managingEditor>secrett2633@example.com (secrett2633)</managingEditor>
    <webMaster>secrett2633@example.com (secrett2633)</webMaster>
    <category>Technology</category>
    <category>Programming</category>
    <category>Django</category>
    <category>Python</category>
    <category>DevOps</category>
    <category>AI/ML</category>
    
        <item>
      <title>[논문리뷰] VideoAuto-R1: Video Auto Reasoning via Thinking Once, Answering Twice</title>
      <description>이 [arXiv]에 게시한 &#39;VideoAuto-R1: Video Auto Reasoning via Thinking Once, Answering Twice&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2026-01-09-VideoAuto-R1-Video-Auto-Reasoning-via-Thinking-Once-Answering-Twice/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2026-01-09-VideoAuto-R1-Video-Auto-Reasoning-via-Thinking-Once-Answering-Twice/</guid>
      <pubDate>Fri, 09 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Video Understanding</category><category>Chain-of-Thought (CoT)</category><category>Reinforcement Learning (RL)</category><category>Adaptive Reasoning</category><category>Early Exit</category><category>Multimodal LLM</category><category>Video QA</category><category>Temporal Grounding</category>
    </item>
    <item>
      <title>[논문리뷰] VerseCrafter: Dynamic Realistic Video World Model with 4D Geometric Control</title>
      <description>Ying Shan이 [arXiv]에 게시한 &#39;VerseCrafter: Dynamic Realistic Video World Model with 4D Geometric Control&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2026-01-09-VerseCrafter-Dynamic-Realistic-Video-World-Model-with-4D-Geometric-Control/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2026-01-09-VerseCrafter-Dynamic-Realistic-Video-World-Model-with-4D-Geometric-Control/</guid>
      <pubDate>Fri, 09 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Video World Model</category><category>4D Geometric Control</category><category>Gaussian Trajectories</category><category>Video Generation</category><category>Diffusion Models</category><category>Camera Control</category><category>Object Motion Control</category><category>Data Engine</category>
    </item>
    <item>
      <title>[논문리뷰] Towards Open-Vocabulary Industrial Defect Understanding with a Large-Scale Multimodal Dataset</title>
      <description>YuanFu Yang이 [arXiv]에 게시한 &#39;Towards Open-Vocabulary Industrial Defect Understanding with a Large-Scale Multimodal Dataset&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2026-01-09-Towards-Open-Vocabulary-Industrial-Defect-Understanding-with-a-Large-Scale-Multimodal-Dataset/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2026-01-09-Towards-Open-Vocabulary-Industrial-Defect-Understanding-with-a-Large-Scale-Multimodal-Dataset/</guid>
      <pubDate>Fri, 09 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Industrial Defect Detection</category><category>Multimodal Dataset</category><category>Vision-Language Model</category><category>Diffusion Model</category><category>Open-Vocabulary Learning</category><category>Quality Inspection</category><category>Data Efficiency</category><category>Foundation Model</category>
    </item>
    <item>
      <title>[논문리뷰] Token-Level LLM Collaboration via FusionRoute</title>
      <description>Furong Huang이 [arXiv]에 게시한 &#39;Token-Level LLM Collaboration via FusionRoute&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2026-01-09-Token-Level-LLM-Collaboration-via-FusionRoute/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2026-01-09-Token-Level-LLM-Collaboration-via-FusionRoute/</guid>
      <pubDate>Fri, 09 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>LLM Collaboration</category><category>Token-level Routing</category><category>Mixture-of-Experts</category><category>Complementary Logits</category><category>Preference Optimization</category><category>FusionRoute</category><category>Domain Adaptation</category>
    </item>
    <item>
      <title>[논문리뷰] The Illusion of Specialization: Unveiling the Domain-Invariant &#39;Standing Committee&#39; in Mixture-of-Experts Models</title>
      <description>이 [arXiv]에 게시한 &#39;The Illusion of Specialization: Unveiling the Domain-Invariant &#39;Standing Committee&#39; in Mixture-of-Experts Models&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2026-01-09-The-Illusion-of-Specialization-Unveiling-the-Domain-Invariant-Standing-Committee-in-Mixture-of-Experts-Models/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2026-01-09-The-Illusion-of-Specialization-Unveiling-the-Domain-Invariant-Standing-Committee-in-Mixture-of-Experts-Models/</guid>
      <pubDate>Fri, 09 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Mixture-of-Experts (MoE)</category><category>Sparse Routing</category><category>Domain Specialization</category><category>Load Balancing</category><category>Interpretability</category><category>Standing Committee</category><category>LLM</category>
    </item>
    <item>
      <title>[논문리뷰] RoboVIP: Multi-View Video Generation with Visual Identity Prompting Augments Robot Manipulation</title>
      <description>Mingda Jia이 [arXiv]에 게시한 &#39;RoboVIP: Multi-View Video Generation with Visual Identity Prompting Augments Robot Manipulation&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2026-01-09-RoboVIP-Multi-View-Video-Generation-with-Visual-Identity-Prompting-Augments-Robot-Manipulation/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2026-01-09-RoboVIP-Multi-View-Video-Generation-with-Visual-Identity-Prompting-Augments-Robot-Manipulation/</guid>
      <pubDate>Fri, 09 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Robot Manipulation</category><category>Data Augmentation</category><category>Video Generation</category><category>Diffusion Models</category><category>Multi-View</category><category>Visual Identity Prompting</category><category>Action-Guided Segmentation</category><category>Visuomotor Policy</category>
    </item>
    <item>
      <title>[논문리뷰] RelayLLM: Efficient Reasoning via Collaborative Decoding</title>
      <description>Haolin Liu이 [arXiv]에 게시한 &#39;RelayLLM: Efficient Reasoning via Collaborative Decoding&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2026-01-09-RelayLLM-Efficient-Reasoning-via-Collaborative-Decoding/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2026-01-09-RelayLLM-Efficient-Reasoning-via-Collaborative-Decoding/</guid>
      <pubDate>Fri, 09 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>LLM</category><category>SLM</category><category>Collaborative Decoding</category><category>Token-level Intervention</category><category>Reinforcement Learning</category><category>GRPO</category><category>Efficient Reasoning</category><category>Resource Efficiency</category>
    </item>
    <item>
      <title>[논문리뷰] Re-Align: Structured Reasoning-guided Alignment for In-Context Image Generation and Editing</title>
      <description>Yu Xu이 [arXiv]에 게시한 &#39;Re-Align: Structured Reasoning-guided Alignment for In-Context Image Generation and Editing&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2026-01-09-Re-Align-Structured-Reasoning-guided-Alignment-for-In-Context-Image-Generation-and-Editing/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2026-01-09-Re-Align-Structured-Reasoning-guided-Alignment-for-In-Context-Image-Generation-and-Editing/</guid>
      <pubDate>Fri, 09 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>In-Context Image Generation</category><category>Image Editing</category><category>Multimodal Models</category><category>Chain-of-Thought</category><category>Structured Reasoning</category><category>Reinforcement Learning</category><category>Alignment</category><category>Diffusion Models</category>
    </item>
    <item>
      <title>[논문리뷰] RL-AWB: Deep Reinforcement Learning for Auto White Balance Correction in Low-Light Night-time Scenes</title>
      <description>Yu-Lun Liu이 [arXiv]에 게시한 &#39;RL-AWB: Deep Reinforcement Learning for Auto White Balance Correction in Low-Light Night-time Scenes&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2026-01-09-RL-AWB-Deep-Reinforcement-Learning-for-Auto-White-Balance-Correction-in-Low-Light-Night-time-Scenes/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2026-01-09-RL-AWB-Deep-Reinforcement-Learning-for-Auto-White-Balance-Correction-in-Low-Light-Night-time-Scenes/</guid>
      <pubDate>Fri, 09 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Auto White Balance (AWB)</category><category>Deep Reinforcement Learning (DRL)</category><category>Low-Light Imaging</category><category>Night-time Scenes</category><category>Color Constancy</category><category>Cross-Sensor Generalization</category><category>Statistical Methods</category><category>Curriculum Learning</category>
    </item>
    <item>
      <title>[논문리뷰] Plenoptic Video Generation</title>
      <description>이 [arXiv]에 게시한 &#39;Plenoptic Video Generation&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2026-01-09-Plenoptic-Video-Generation/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2026-01-09-Plenoptic-Video-Generation/</guid>
      <pubDate>Fri, 09 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Generative Video</category><category>Camera Control</category><category>Plenoptic Function</category><category>Autoregressive Model</category><category>Diffusion Transformer</category><category>3D FOV Retrieval</category><category>Spatio-Temporal Consistency</category>
    </item>
    <item>
      <title>[논문리뷰] Memorization in 3D Shape Generation: An Empirical Study</title>
      <description>이 [arXiv]에 게시한 &#39;Memorization in 3D Shape Generation: An Empirical Study&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2026-01-09-Memorization-in-3D-Shape-Generation-An-Empirical-Study/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2026-01-09-Memorization-in-3D-Shape-Generation-An-Empirical-Study/</guid>
      <pubDate>Fri, 09 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>3D Shape Generation</category><category>Memorization</category><category>Generative Models</category><category>Diffusion Models</category><category>Evaluation Framework</category><category>Generalization</category><category>Data Augmentation</category>
    </item>
    <item>
      <title>[논문리뷰] Learnable Multipliers: Freeing the Scale of Language Model Matrix Layers</title>
      <description>이 [arXiv]에 게시한 &#39;Learnable Multipliers: Freeing the Scale of Language Model Matrix Layers&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2026-01-09-Learnable-Multipliers-Freeing-the-Scale-of-Language-Model-Matrix-Layers/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2026-01-09-Learnable-Multipliers-Freeing-the-Scale-of-Language-Model-Matrix-Layers/</guid>
      <pubDate>Fri, 09 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Large Language Models</category><category>Weight Decay</category><category>Learnable Multipliers</category><category>Scale Adaptation</category><category>Optimization</category><category>µP Parametrization</category><category>Adam</category><category>Muon</category>
    </item>
    <item>
      <title>[논문리뷰] GDPO: Group reward-Decoupled Normalization Policy Optimization for Multi-reward RL Optimization</title>
      <description>이 [arXiv]에 게시한 &#39;GDPO: Group reward-Decoupled Normalization Policy Optimization for Multi-reward RL Optimization&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2026-01-09-GDPO-Group-reward-Decoupled-Normalization-Policy-Optimization-for-Multi-reward-RL-Optimization/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2026-01-09-GDPO-Group-reward-Decoupled-Normalization-Policy-Optimization-for-Multi-reward-RL-Optimization/</guid>
      <pubDate>Fri, 09 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Multi-reward RL</category><category>Policy Optimization</category><category>Reward Normalization</category><category>GRPO</category><category>GDPO</category><category>LLMs</category><category>Training Stability</category>
    </item>
    <item>
      <title>[논문리뷰] Few Tokens Matter: Entropy Guided Attacks on Vision-Language Models</title>
      <description>이 [arXiv]에 게시한 &#39;Few Tokens Matter: Entropy Guided Attacks on Vision-Language Models&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2026-01-09-Few-Tokens-Matter-Entropy-Guided-Attacks-on-Vision-Language-Models/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2026-01-09-Few-Tokens-Matter-Entropy-Guided-Attacks-on-Vision-Language-Models/</guid>
      <pubDate>Fri, 09 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Vision-Language Models</category><category>Adversarial Attacks</category><category>Entropy-Guided Attacks</category><category>Token Vulnerability</category><category>Harmful Content</category><category>Cross-Model Transferability</category><category>Autoregressive Generation</category>
    </item>
    <item>
      <title>[논문리뷰] Enhancing Object Detection with Privileged Information: A Model-Agnostic Teacher-Student Approach</title>
      <description>Carl James Debono이 [arXiv]에 게시한 &#39;Enhancing Object Detection with Privileged Information: A Model-Agnostic Teacher-Student Approach&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2026-01-09-Enhancing-Object-Detection-with-Privileged-Information-A-Model-Agnostic-Teacher-Student-Approach/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2026-01-09-Enhancing-Object-Detection-with-Privileged-Information-A-Model-Agnostic-Teacher-Student-Approach/</guid>
      <pubDate>Fri, 09 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Object Detection</category><category>Privileged Information</category><category>Teacher-Student Learning</category><category>Knowledge Distillation</category><category>Model-Agnostic</category><category>Bounding Box Masks</category><category>UAV-based Detection</category>
    </item>
    <item>
      <title>[논문리뷰] DocDancer: Towards Agentic Document-Grounded Information Seeking</title>
      <description>이 [arXiv]에 게시한 &#39;DocDancer: Towards Agentic Document-Grounded Information Seeking&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2026-01-09-DocDancer-Towards-Agentic-Document-Grounded-Information-Seeking/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2026-01-09-DocDancer-Towards-Agentic-Document-Grounded-Information-Seeking/</guid>
      <pubDate>Fri, 09 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Agentic AI</category><category>Document Question Answering</category><category>Tool-use</category><category>Information Seeking</category><category>Synthetic Data Generation</category><category>Long-context Understanding</category><category>Multimodal Documents</category>
    </item>
    <item>
      <title>[논문리뷰] DiffCoT: Diffusion-styled Chain-of-Thought Reasoning in LLMs</title>
      <description>Jing Ma이 [arXiv]에 게시한 &#39;DiffCoT: Diffusion-styled Chain-of-Thought Reasoning in LLMs&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2026-01-09-DiffCoT-Diffusion-styled-Chain-of-Thought-Reasoning-in-LLMs/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2026-01-09-DiffCoT-Diffusion-styled-Chain-of-Thought-Reasoning-in-LLMs/</guid>
      <pubDate>Fri, 09 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Chain-of-Thought</category><category>Diffusion Models</category><category>Large Language Models</category><category>Reasoning</category><category>Error Correction</category><category>Preference Optimization</category><category>Denoising</category>
    </item>
    <item>
      <title>[논문리뷰] AgentDevel: Reframing Self-Evolving LLM Agents as Release Engineering</title>
      <description>Di Zhang이 [arXiv]에 게시한 &#39;AgentDevel: Reframing Self-Evolving LLM Agents as Release Engineering&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2026-01-09-AgentDevel-Reframing-Self-Evolving-LLM-Agents-as-Release-Engineering/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2026-01-09-AgentDevel-Reframing-Self-Evolving-LLM-Agents-as-Release-Engineering/</guid>
      <pubDate>Fri, 09 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>LLM Agents</category><category>Release Engineering</category><category>Self-Improvement</category><category>Regression Testing</category><category>Continuous Integration</category><category>Flip-Centered Gating</category><category>Auditable Development</category><category>Software Engineering</category>
    </item>
    <item>
      <title>[논문리뷰] Agent-as-a-Judge</title>
      <description>Meng Liu이 [arXiv]에 게시한 &#39;Agent-as-a-Judge&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2026-01-09-Agent-as-a-Judge/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2026-01-09-Agent-as-a-Judge/</guid>
      <pubDate>Fri, 09 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Agent-as-a-Judge</category><category>LLM Evaluation</category><category>Multi-Agent Systems</category><category>Tool Integration</category><category>AI Alignment</category><category>Automated Assessment</category><category>Survey</category>
    </item>
    <item>
      <title>[논문리뷰] AT^2PO: Agentic Turn-based Policy Optimization via Tree Search</title>
      <description>이 [arXiv]에 게시한 &#39;AT^2PO: Agentic Turn-based Policy Optimization via Tree Search&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2026-01-09-AT2PO-Agentic-Turn-based-Policy-Optimization-via-Tree-Search/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2026-01-09-AT2PO-Agentic-Turn-based-Policy-Optimization-via-Tree-Search/</guid>
      <pubDate>Fri, 09 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Agentic RL</category><category>Multi-turn Tasks</category><category>Policy Optimization</category><category>Tree Search</category><category>Credit Assignment</category><category>Exploration Diversity</category><category>LLM Agents</category>
    </item>
    <item>
      <title>[논문리뷰] Why LLMs Aren&#39;t Scientists Yet: Lessons from Four Autonomous Research Attempts</title>
      <description>이 [arXiv]에 게시한 &#39;Why LLMs Aren&#39;t Scientists Yet: Lessons from Four Autonomous Research Attempts&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2026-01-08-Why-LLMs-Arent-Scientists-Yet-Lessons-from-Four-Autonomous-Research-Attempts/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2026-01-08-Why-LLMs-Arent-Scientists-Yet-Lessons-from-Four-Autonomous-Research-Attempts/</guid>
      <pubDate>Thu, 08 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Machine Learning Research</category><category>Autonomous Research</category><category>LLM Agents</category><category>Scientific Workflow</category><category>Failure Modes</category><category>Experimental Design</category><category>AI Scientist</category><category>Agentic Systems</category>
    </item>
    <item>
      <title>[논문리뷰] ThinkRL-Edit: Thinking in Reinforcement Learning for Reasoning-Centric Image Editing</title>
      <description>이 [arXiv]에 게시한 &#39;ThinkRL-Edit: Thinking in Reinforcement Learning for Reasoning-Centric Image Editing&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2026-01-08-ThinkRL-Edit-Thinking-in-Reinforcement-Learning-for-Reasoning-Centric-Image-Editing/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2026-01-08-ThinkRL-Edit-Thinking-in-Reinforcement-Learning-for-Reasoning-Centric-Image-Editing/</guid>
      <pubDate>Thu, 08 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Reinforcement Learning</category><category>Image Editing</category><category>Reasoning</category><category>Chain-of-Thought</category><category>Multimodal Generative Models</category><category>Reward Modeling</category><category>VLM</category>
    </item>
    <item>
      <title>[논문리뷰] RGS-SLAM: Robust Gaussian Splatting SLAM with One-Shot Dense Initialization</title>
      <description>이 [arXiv]에 게시한 &#39;RGS-SLAM: Robust Gaussian Splatting SLAM with One-Shot Dense Initialization&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2026-01-08-RGS-SLAM-Robust-Gaussian-Splatting-SLAM-with-One-Shot-Dense-Initialization/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2026-01-08-RGS-SLAM-Robust-Gaussian-Splatting-SLAM-with-One-Shot-Dense-Initialization/</guid>
      <pubDate>Thu, 08 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Gaussian Splatting</category><category>SLAM</category><category>Dense Initialization</category><category>Real-Time Tracking</category><category>Differentiable Rendering</category><category>DINOv3</category>
    </item>
    <item>
      <title>[논문리뷰] MDAgent2: Large Language Model for Code Generation and Knowledge Q&amp;A in Molecular Dynamics</title>
      <description>이 [arXiv]에 게시한 &#39;MDAgent2: Large Language Model for Code Generation and Knowledge Q&amp;A in Molecular Dynamics&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2026-01-08-MDAgent2-Large-Language-Model-for-Code-Generation-and-Knowledge-QA-in-Molecular-Dynamics/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2026-01-08-MDAgent2-Large-Language-Model-for-Code-Generation-and-Knowledge-QA-in-Molecular-Dynamics/</guid>
      <pubDate>Thu, 08 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Molecular Dynamics</category><category>LAMMPS</category><category>Code Generation</category><category>Knowledge Q&amp;A</category><category>Large Language Models</category><category>Reinforcement Learning</category><category>Multi-agent System</category><category>Domain Adaptation</category>
    </item>
    <item>
      <title>[논문리뷰] MAGMA: A Multi-Graph based Agentic Memory Architecture for AI Agents</title>
      <description>Bingzhe Li이 [arXiv]에 게시한 &#39;MAGMA: A Multi-Graph based Agentic Memory Architecture for AI Agents&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2026-01-08-MAGMA-A-Multi-Graph-based-Agentic-Memory-Architecture-for-AI-Agents/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2026-01-08-MAGMA-A-Multi-Graph-based-Agentic-Memory-Architecture-for-AI-Agents/</guid>
      <pubDate>Thu, 08 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Agentic Memory</category><category>Large Language Models</category><category>Retrieval-Augmented Generation</category><category>Knowledge Graphs</category><category>Multi-Graph Architecture</category><category>Long-Context Reasoning</category><category>Memory Evolution</category>
    </item>
    <item>
      <title>[논문리뷰] EpiQAL: Benchmarking Large Language Models in Epidemiological Question Answering for Enhanced Alignment and Reasoning</title>
      <description>Guanchen Wu이 [arXiv]에 게시한 &#39;EpiQAL: Benchmarking Large Language Models in Epidemiological Question Answering for Enhanced Alignment and Reasoning&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2026-01-08-EpiQAL-Benchmarking-Large-Language-Models-in-Epidemiological-Question-Answering-for-Enhanced-Alignment-and-Reasoning/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2026-01-08-EpiQAL-Benchmarking-Large-Language-Models-in-Epidemiological-Question-Answering-for-Enhanced-Alignment-and-Reasoning/</guid>
      <pubDate>Thu, 08 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Epidemiological Question Answering</category><category>Large Language Models</category><category>Benchmark</category><category>Multi-step Inference</category><category>Evidence Grounding</category><category>LLM Evaluation</category><category>Public Health AI</category><category>Chain-of-Thought</category>
    </item>
    <item>
      <title>[논문리뷰] Entropy-Adaptive Fine-Tuning: Resolving Confident Conflicts to Mitigate Forgetting</title>
      <description>이 [arXiv]에 게시한 &#39;Entropy-Adaptive Fine-Tuning: Resolving Confident Conflicts to Mitigate Forgetting&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2026-01-08-Entropy-Adaptive-Fine-Tuning-Resolving-Confident-Conflicts-to-Mitigate-Forgetting/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2026-01-08-Entropy-Adaptive-Fine-Tuning-Resolving-Confident-Conflicts-to-Mitigate-Forgetting/</guid>
      <pubDate>Thu, 08 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Supervised Fine-Tuning (SFT)</category><category>Catastrophic Forgetting</category><category>Entropy-Adaptive Fine-Tuning (EAFT)</category><category>Large Language Models (LLMs)</category><category>Domain Adaptation</category><category>Reinforcement Learning (RL)</category><category>Confident Conflicts</category>
    </item>
    <item>
      <title>[논문리뷰] E-GRPO: High Entropy Steps Drive Effective Reinforcement Learning for Flow Models</title>
      <description>이 [arXiv]에 게시한 &#39;E-GRPO: High Entropy Steps Drive Effective Reinforcement Learning for Flow Models&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2026-01-08-E-GRPO-High-Entropy-Steps-Drive-Effective-Reinforcement-Learning-for-Flow-Models/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2026-01-08-E-GRPO-High-Entropy-Steps-Drive-Effective-Reinforcement-Learning-for-Flow-Models/</guid>
      <pubDate>Thu, 08 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Reinforcement Learning</category><category>Flow Models</category><category>Entropy-aware Sampling</category><category>Group Relative Policy Optimization</category><category>SDE</category><category>Human Preference Alignment</category><category>Image Generation</category>
    </item>
    <item>
      <title>[논문리뷰] X-MuTeST: A Multilingual Benchmark for Explainable Hate Speech Detection and A Novel LLM-consulted Explanation Framework</title>
      <description>Shwetank Shekhar Singh이 [arXiv]에 게시한 &#39;X-MuTeST: A Multilingual Benchmark for Explainable Hate Speech Detection and A Novel LLM-consulted Explanation Framework&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2026-01-07-X-MuTeST-A-Multilingual-Benchmark-for-Explainable-Hate-Speech-Detection-and-A-Novel-LLM-consulted-Explanation-Framework/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2026-01-07-X-MuTeST-A-Multilingual-Benchmark-for-Explainable-Hate-Speech-Detection-and-A-Novel-LLM-consulted-Explanation-Framework/</guid>
      <pubDate>Wed, 07 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Hate Speech Detection</category><category>Explainable AI (XAI)</category><category>Multilingual NLP</category><category>Large Language Models (LLMs)</category><category>Attention Mechanism</category><category>N-gram Explanations</category><category>Human Rationales</category><category>Benchmark Dataset</category>
    </item>
    <item>
      <title>[논문리뷰] UniCorn: Towards Self-Improving Unified Multimodal Models through Self-Generated Supervision</title>
      <description>XinYu Sun이 [arXiv]에 게시한 &#39;UniCorn: Towards Self-Improving Unified Multimodal Models through Self-Generated Supervision&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.site/ai/review/2026-01-07-UniCorn-Towards-Self-Improving-Unified-Multimodal-Models-through-Self-Generated-Supervision/</link>
      <guid isPermaLink="true">https://blog.secrett2633.site/ai/review/2026-01-07-UniCorn-Towards-Self-Improving-Unified-Multimodal-Models-through-Self-Generated-Supervision/</guid>
      <pubDate>Wed, 07 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Unified Multimodal Models</category><category>Self-Supervised Learning</category><category>Text-to-Image Generation</category><category>Multi-Agent Framework</category><category>Cognitive Pattern Reconstruction</category><category>Cycle-Consistency</category><category>Conduction Aphasia</category>
    </item>
    
  </channel>
</rss>