<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>secrett2633's blog</title>
    <description>기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트</description>
    <link>https://blog.secrett2633.cloud</link>
    <atom:link href="https://blog.secrett2633.cloud/feed.xml" rel="self" type="application/rss+xml" />
    <language>ko-KR</language>
    <lastBuildDate>Mon, 02 Feb 2026 13:12:20 GMT</lastBuildDate>
    <pubDate>Mon, 02 Feb 2026 13:12:20 GMT</pubDate>
    <ttl>60</ttl>
    <generator>Next.js RSS Generator</generator>
    <managingEditor>secrett2633@example.com (secrett2633)</managingEditor>
    <webMaster>secrett2633@example.com (secrett2633)</webMaster>
    <category>Technology</category>
    <category>Programming</category>
    <category>Django</category>
    <category>Python</category>
    <category>DevOps</category>
    <category>AI/ML</category>
    
        <item>
      <title>[논문리뷰] VTC-R1: Vision-Text Compression for Efficient Long-Context Reasoning</title>
      <description>이 [arXiv]에 게시한 &#39;VTC-R1: Vision-Text Compression for Efficient Long-Context Reasoning&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-30-VTC-R1-Vision-Text-Compression-for-Efficient-Long-Context-Reasoning/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-30-VTC-R1-Vision-Text-Compression-for-Efficient-Long-Context-Reasoning/</guid>
      <pubDate>Fri, 30 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Vision-Text Compression</category><category>Long-Context Reasoning</category><category>LLM Efficiency</category><category>Vision-Language Models</category><category>Iterative Reasoning</category><category>Mathematical Problem Solving</category><category>Inference Speedup</category>
    </item>
    <item>
      <title>[논문리뷰] Typhoon-S: Minimal Open Post-Training for Sovereign Large Language Models</title>
      <description>이 [arXiv]에 게시한 &#39;Typhoon-S: Minimal Open Post-Training for Sovereign Large Language Models&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-30-Typhoon-S-Minimal-Open-Post-Training-for-Sovereign-Large-Language-Models/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-30-Typhoon-S-Minimal-Open-Post-Training-for-Sovereign-Large-Language-Models/</guid>
      <pubDate>Fri, 30 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Sovereign LLMs</category><category>Post-Training</category><category>Instruction Tuning</category><category>Supervised Fine-tuning</category><category>On-Policy Distillation</category><category>Reinforcement Learning</category><category>Knowledge Injection</category><category>Thai Language</category>
    </item>
    <item>
      <title>[논문리뷰] Self-Improving Pretraining: using post-trained models to pretrain better models</title>
      <description>이 [arXiv]에 게시한 &#39;Self-Improving Pretraining: using post-trained models to pretrain better models&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-30-Self-Improving-Pretraining-using-post-trained-models-to-pretrain-better-models/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-30-Self-Improving-Pretraining-using-post-trained-models-to-pretrain-better-models/</guid>
      <pubDate>Fri, 30 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Self-Improving Pretraining</category><category>Reinforcement Learning (RL)</category><category>Large Language Models (LLMs)</category><category>Quality Control</category><category>Factuality</category><category>Safety</category><category>Post-trained Models</category><category>Pretraining Data Augmentation</category>
    </item>
    <item>
      <title>[논문리뷰] Scaling Embeddings Outperforms Scaling Experts in Language Models</title>
      <description>이 [arXiv]에 게시한 &#39;Scaling Embeddings Outperforms Scaling Experts in Language Models&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-30-Scaling-Embeddings-Outperforms-Scaling-Experts-in-Language-Models/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-30-Scaling-Embeddings-Outperforms-Scaling-Experts-in-Language-Models/</guid>
      <pubDate>Fri, 30 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Embedding Scaling</category><category>N-gram Embedding</category><category>Mixture-of-Experts (MoE)</category><category>Large Language Models (LLMs)</category><category>Parameter Efficiency</category><category>Inference Optimization</category><category>Speculative Decoding</category>
    </item>
    <item>
      <title>[논문리뷰] Scalable Power Sampling: Unlocking Efficient, Training-Free Reasoning for LLMs via Distribution Sharpening</title>
      <description>Haitham Bou Ammar이 [arXiv]에 게시한 &#39;Scalable Power Sampling: Unlocking Efficient, Training-Free Reasoning for LLMs via Distribution Sharpening&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-30-Scalable-Power-Sampling-Unlocking-Efficient-Training-Free-Reasoning-for-LLMs-via-Distribution-Sharpening/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-30-Scalable-Power-Sampling-Unlocking-Efficient-Training-Free-Reasoning-for-LLMs-via-Distribution-Sharpening/</guid>
      <pubDate>Fri, 30 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>LLM Reasoning</category><category>Distribution Sharpening</category><category>Power Sampling</category><category>Training-Free</category><category>Monte Carlo Estimation</category><category>Jackknife Correction</category><category>Autoregressive Generation</category><category>Inference Efficiency</category>
    </item>
    <item>
      <title>[논문리뷰] Qwen3-ASR Technical Report</title>
      <description>이 [arXiv]에 게시한 &#39;Qwen3-ASR Technical Report&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-30-Qwen3-ASR-Technical-Report/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-30-Qwen3-ASR-Technical-Report/</guid>
      <pubDate>Fri, 30 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>ASR</category><category>Language Identification</category><category>Forced Alignment</category><category>Large Audio-Language Models</category><category>Multilingual Speech Recognition</category><category>Streaming Inference</category><category>Qwen3-Omni</category>
    </item>
    <item>
      <title>[논문리뷰] PLANING: A Loosely Coupled Triangle-Gaussian Framework for Streaming 3D Reconstruction</title>
      <description>이 [arXiv]에 게시한 &#39;PLANING: A Loosely Coupled Triangle-Gaussian Framework for Streaming 3D Reconstruction&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-30-PLANING-A-Loosely-Coupled-Triangle-Gaussian-Framework-for-Streaming-3D-Reconstruction/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-30-PLANING-A-Loosely-Coupled-Triangle-Gaussian-Framework-for-Streaming-3D-Reconstruction/</guid>
      <pubDate>Fri, 30 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Streaming 3D Reconstruction</category><category>Hybrid Representation</category><category>Triangle Primitives</category><category>Neural Gaussians</category><category>Geometric Accuracy</category><category>High-Fidelity Rendering</category><category>Embodied AI</category><category>Monocular SLAM</category>
    </item>
    <item>
      <title>[논문리뷰] OCRVerse: Towards Holistic OCR in End-to-End Vision-Language Models</title>
      <description>Liming Zheng이 [arXiv]에 게시한 &#39;OCRVerse: Towards Holistic OCR in End-to-End Vision-Language Models&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-30-OCRVerse-Towards-Holistic-OCR-in-End-to-End-Vision-Language-Models/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-30-OCRVerse-Towards-Holistic-OCR-in-End-to-End-Vision-Language-Models/</guid>
      <pubDate>Fri, 30 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Holistic OCR</category><category>Vision-Language Models</category><category>Multi-domain Training</category><category>Text-centric OCR</category><category>Vision-centric OCR</category><category>SFT-RL</category><category>Code Generation</category><category>Document Understanding</category>
    </item>
    <item>
      <title>[논문리뷰] MetricAnything: Scaling Metric Depth Pretraining with Noisy Heterogeneous Sources</title>
      <description>Jianxun Cui이 [arXiv]에 게시한 &#39;MetricAnything: Scaling Metric Depth Pretraining with Noisy Heterogeneous Sources&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-30-MetricAnything-Scaling-Metric-Depth-Pretraining-with-Noisy-Heterogeneous-Sources/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-30-MetricAnything-Scaling-Metric-Depth-Pretraining-with-Noisy-Heterogeneous-Sources/</guid>
      <pubDate>Fri, 30 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Metric Depth Estimation</category><category>Pretraining</category><category>Foundation Models</category><category>Sparse Prompts</category><category>Heterogeneous Data</category><category>Zero-Shot Learning</category><category>Multi-modal Learning</category>
    </item>
    <item>
      <title>[논문리뷰] MMFineReason: Closing the Multimodal Reasoning Gap via Open Data-Centric Methods</title>
      <description>이 [arXiv]에 게시한 &#39;MMFineReason: Closing the Multimodal Reasoning Gap via Open Data-Centric Methods&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-30-MMFineReason-Closing-the-Multimodal-Reasoning-Gap-via-Open-Data-Centric-Methods/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-30-MMFineReason-Closing-the-Multimodal-Reasoning-Gap-via-Open-Data-Centric-Methods/</guid>
      <pubDate>Fri, 30 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Multimodal Reasoning</category><category>Data-centric AI</category><category>Chain-of-Thought</category><category>Large Language Models</category><category>Visual Question Answering</category><category>STEM Reasoning</category><category>Dataset</category><category>Fine-tuning</category>
    </item>
    <item>
      <title>[논문리뷰] MAD: Modality-Adaptive Decoding for Mitigating Cross-Modal Hallucinations in Multimodal Large Language Models</title>
      <description>Yong Man Ro이 [arXiv]에 게시한 &#39;MAD: Modality-Adaptive Decoding for Mitigating Cross-Modal Hallucinations in Multimodal Large Language Models&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-30-MAD-Modality-Adaptive-Decoding-for-Mitigating-Cross-Modal-Hallucinations-in-Multimodal-Large-Language-Models/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-30-MAD-Modality-Adaptive-Decoding-for-Mitigating-Cross-Modal-Hallucinations-in-Multimodal-Large-Language-Models/</guid>
      <pubDate>Fri, 30 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Multimodal LLM</category><category>Cross-modal Hallucination</category><category>Contrastive Decoding</category><category>Modality-Adaptive Decoding</category><category>Self-Assessment</category><category>Audio-Visual Language Model</category><category>Training-Free</category>
    </item>
    <item>
      <title>[논문리뷰] Llama-3.1-FoundationAI-SecurityLLM-Reasoning-8B Technical Report</title>
      <description>이 [arXiv]에 게시한 &#39;Llama-3.1-FoundationAI-SecurityLLM-Reasoning-8B Technical Report&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-30-Llama-3-1-FoundationAI-SecurityLLM-Reasoning-8B-Technical-Report/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-30-Llama-3-1-FoundationAI-SecurityLLM-Reasoning-8B-Technical-Report/</guid>
      <pubDate>Fri, 30 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Cybersecurity LLM</category><category>Reasoning Model</category><category>Supervised Fine-Tuning</category><category>Reinforcement Learning</category><category>Verifiable Rewards</category><category>8B Parameters</category><category>Open-Source AI</category>
    </item>
    <item>
      <title>[논문리뷰] Language-based Trial and Error Falls Behind in the Era of Experience</title>
      <description>이 [arXiv]에 게시한 &#39;Language-based Trial and Error Falls Behind in the Era of Experience&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-30-Language-based-Trial-and-Error-Falls-Behind-in-the-Era-of-Experience/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-30-Language-based-Trial-and-Error-Falls-Behind-in-the-Era-of-Experience/</guid>
      <pubDate>Fri, 30 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Large Language Models</category><category>Reinforcement Learning</category><category>Exploration Efficiency</category><category>Sub-Scale Collaboration</category><category>Out-of-Distribution Tasks</category><category>Agentic AI</category><category>Supervised Fine-Tuning</category>
    </item>
    <item>
      <title>[논문리뷰] Idea2Story: An Automated Pipeline for Transforming Research Concepts into Complete Scientific Narratives</title>
      <description>이 [arXiv]에 게시한 &#39;Idea2Story: An Automated Pipeline for Transforming Research Concepts into Complete Scientific Narratives&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-30-Idea2Story-An-Automated-Pipeline-for-Transforming-Research-Concepts-into-Complete-Scientific-Narratives/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-30-Idea2Story-An-Automated-Pipeline-for-Transforming-Research-Concepts-into-Complete-Scientific-Narratives/</guid>
      <pubDate>Fri, 30 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Autonomous Scientific Discovery</category><category>LLM Agents</category><category>Knowledge Graph</category><category>Pre-computation</category><category>Research Pattern</category><category>Methodology</category><category>Retrieval-Augmented Generation</category><category>Review-Guided Refinement</category>
    </item>
    <item>
      <title>[논문리뷰] Exploring Reasoning Reward Model for Agents</title>
      <description>Zhixun Li이 [arXiv]에 게시한 &#39;Exploring Reasoning Reward Model for Agents&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-30-Exploring-Reasoning-Reward-Model-for-Agents/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-30-Exploring-Reasoning-Reward-Model-for-Agents/</guid>
      <pubDate>Fri, 30 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Agentic Reinforcement Learning</category><category>Reward Modeling</category><category>Reasoning-aware Feedback</category><category>Large Language Models (LLMs)</category><category>Multi-modal Agents</category><category>Fine-tuning</category><category>Critique Generation</category>
    </item>
    <item>
      <title>[논문리뷰] Everything in Its Place: Benchmarking Spatial Intelligence of Text-to-Image Models</title>
      <description>이 [arXiv]에 게시한 &#39;Everything in Its Place: Benchmarking Spatial Intelligence of Text-to-Image Models&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-30-Everything-in-Its-Place-Benchmarking-Spatial-Intelligence-of-Text-to-Image-Models/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-30-Everything-in-Its-Place-Benchmarking-Spatial-Intelligence-of-Text-to-Image-Models/</guid>
      <pubDate>Fri, 30 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Text-to-Image Models</category><category>Spatial Intelligence</category><category>Benchmark</category><category>Evaluation</category><category>Prompt Engineering</category><category>Multimodal LLMs</category><category>Fine-tuning</category><category>Spatial Reasoning</category>
    </item>
    <item>
      <title>[논문리뷰] DynamicVLA: A Vision-Language-Action Model for Dynamic Object Manipulation</title>
      <description>이 [arXiv]에 게시한 &#39;DynamicVLA: A Vision-Language-Action Model for Dynamic Object Manipulation&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-30-DynamicVLA-A-Vision-Language-Action-Model-for-Dynamic-Object-Manipulation/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-30-DynamicVLA-A-Vision-Language-Action-Model-for-Dynamic-Object-Manipulation/</guid>
      <pubDate>Fri, 30 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Vision-Language-Action (VLA) Models</category><category>Dynamic Object Manipulation</category><category>Robotics</category><category>Continuous Inference</category><category>Latent-aware Action Streaming</category><category>Real-time Control</category><category>Perception-Execution Gap</category>
    </item>
    <item>
      <title>[논문리뷰] Discovering Hidden Gems in Model Repositories</title>
      <description>Yedid Hoshen이 [arXiv]에 게시한 &#39;Discovering Hidden Gems in Model Repositories&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-30-Discovering-Hidden-Gems-in-Model-Repositories/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-30-Discovering-Hidden-Gems-in-Model-Repositories/</guid>
      <pubDate>Fri, 30 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Model Discovery</category><category>Hidden Gems</category><category>Sequential Halving</category><category>Multi-Armed Bandit</category><category>Model Repositories</category><category>Large Language Models</category><category>Performance Evaluation</category>
    </item>
    <item>
      <title>[논문리뷰] DeepSearchQA: Bridging the Comprehensiveness Gap for Deep Research Agents</title>
      <description>이 [arXiv]에 게시한 &#39;DeepSearchQA: Bridging the Comprehensiveness Gap for Deep Research Agents&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-30-DeepSearchQA-Bridging-the-Comprehensiveness-Gap-for-Deep-Research-Agents/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-30-DeepSearchQA-Bridging-the-Comprehensiveness-Gap-for-Deep-Research-Agents/</guid>
      <pubDate>Fri, 30 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>AI Agents</category><category>Deep Research</category><category>Benchmark</category><category>Information Retrieval</category><category>Comprehensiveness</category><category>Multi-step Reasoning</category><category>Evaluation</category><category>LLM-as-a-Judge</category>
    </item>
    <item>
      <title>[논문리뷰] ConceptMoE: Adaptive Token-to-Concept Compression for Implicit Compute Allocation</title>
      <description>이 [arXiv]에 게시한 &#39;ConceptMoE: Adaptive Token-to-Concept Compression for Implicit Compute Allocation&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-30-ConceptMoE-Adaptive-Token-to-Concept-Compression-for-Implicit-Compute-Allocation/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-30-ConceptMoE-Adaptive-Token-to-Concept-Compression-for-Implicit-Compute-Allocation/</guid>
      <pubDate>Fri, 30 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>MoE</category><category>LLMs</category><category>Adaptive Compression</category><category>Token Merging</category><category>Compute Allocation</category><category>Efficiency</category><category>Vision-Language Models</category><category>Continual Training</category>
    </item>
    <item>
      <title>[논문리뷰] Beyond Imitation: Reinforcement Learning for Active Latent Planning</title>
      <description>Wee Sun Lee이 [arXiv]에 게시한 &#39;Beyond Imitation: Reinforcement Learning for Active Latent Planning&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-30-Beyond-Imitation-Reinforcement-Learning-for-Active-Latent-Planning/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-30-Beyond-Imitation-Reinforcement-Learning-for-Active-Latent-Planning/</guid>
      <pubDate>Fri, 30 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Large Language Models (LLMs)</category><category>Chain-of-Thought (CoT)</category><category>Latent Reasoning</category><category>Reinforcement Learning (RL)</category><category>Variational Autoencoder (VAE)</category><category>Active Planning</category><category>Numerical Reasoning</category><category>Coherence Reward</category>
    </item>
    <item>
      <title>[논문리뷰] AgentLongBench: A Controllable Long Benchmark For Long-Contexts Agents via Environment Rollouts</title>
      <description>이 [arXiv]에 게시한 &#39;AgentLongBench: A Controllable Long Benchmark For Long-Contexts Agents via Environment Rollouts&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-30-AgentLongBench-A-Controllable-Long-Benchmark-For-Long-Contexts-Agents-via-Environment-Rollouts/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-30-AgentLongBench-A-Controllable-Long-Benchmark-For-Long-Contexts-Agents-via-Environment-Rollouts/</guid>
      <pubDate>Fri, 30 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Long-Context LLMs</category><category>Autonomous Agents</category><category>Benchmark</category><category>Environment Rollouts</category><category>State Tracking</category><category>Tool Use</category><category>Memory Evaluation</category><category>Lateral Thinking Puzzles</category>
    </item>
    <item>
      <title>[논문리뷰] UPLiFT: Efficient Pixel-Dense Feature Upsampling with Local Attenders</title>
      <description>이 [arXiv]에 게시한 &#39;UPLiFT: Efficient Pixel-Dense Feature Upsampling with Local Attenders&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-29-UPLiFT-Efficient-Pixel-Dense-Feature-Upsampling-with-Local-Attenders/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-29-UPLiFT-Efficient-Pixel-Dense-Feature-Upsampling-with-Local-Attenders/</guid>
      <pubDate>Thu, 29 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Feature Upsampling</category><category>Local Attender</category><category>Pixel-Dense Features</category><category>Iterative Upsampling</category><category>Vision Transformer</category><category>Efficiency</category><category>Generative AI</category><category>Semantic Segmentation</category>
    </item>
    <item>
      <title>[논문리뷰] Spark: Strategic Policy-Aware Exploration via Dynamic Branching for Long-Horizon Agentic Learning</title>
      <description>Shuai Zhang이 [arXiv]에 게시한 &#39;Spark: Strategic Policy-Aware Exploration via Dynamic Branching for Long-Horizon Agentic Learning&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-29-Spark-Strategic-Policy-Aware-Exploration-via-Dynamic-Branching-for-Long-Horizon-Agentic-Learning/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-29-Spark-Strategic-Policy-Aware-Exploration-via-Dynamic-Branching-for-Long-Horizon-Agentic-Learning/</guid>
      <pubDate>Thu, 29 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Agentic AI</category><category>Reinforcement Learning</category><category>Long-Horizon Tasks</category><category>Dynamic Branching</category><category>Strategic Exploration</category><category>LLM Agents</category><category>Sample Efficiency</category><category>Policy Optimization</category>
    </item>
    <item>
      <title>[논문리뷰] SketchDynamics: Exploring Free-Form Sketches for Dynamic Intent Expression in Animation Generation</title>
      <description>Hongbo Fu이 [arXiv]에 게시한 &#39;SketchDynamics: Exploring Free-Form Sketches for Dynamic Intent Expression in Animation Generation&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-29-SketchDynamics-Exploring-Free-Form-Sketches-for-Dynamic-Intent-Expression-in-Animation-Generation/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-29-SketchDynamics-Exploring-Free-Form-Sketches-for-Dynamic-Intent-Expression-in-Animation-Generation/</guid>
      <pubDate>Thu, 29 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Animation Generation</category><category>Free-Form Sketching</category><category>Human-AI Interaction</category><category>Vision-Language Models (VLMs)</category><category>Dynamic Intent Expression</category><category>Motion Graphics</category><category>Iterative Refinement</category><category>Storyboard</category>
    </item>
    <item>
      <title>[논문리뷰] Shallow-π: Knowledge Distillation for Flow-based VLAs</title>
      <description>이 [arXiv]에 게시한 &#39;Shallow-π: Knowledge Distillation for Flow-based VLAs&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-29-Shallow-π-Knowledge-Distillation-for-Flow-based-VLAs/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-29-Shallow-π-Knowledge-Distillation-for-Flow-based-VLAs/</guid>
      <pubDate>Thu, 29 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Knowledge Distillation</category><category>Flow-based VLA</category><category>Transformer Compression</category><category>Real-time Robotics</category><category>Edge AI</category><category>Vision-Language-Action Models</category><category>Inference Efficiency</category>
    </item>
    <item>
      <title>[논문리뷰] SERA: Soft-Verified Efficient Repository Agents</title>
      <description>이 [arXiv]에 게시한 &#39;SERA: Soft-Verified Efficient Repository Agents&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-29-SERA-Soft-Verified-Efficient-Repository-Agents/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-29-SERA-Soft-Verified-Efficient-Repository-Agents/</guid>
      <pubDate>Thu, 29 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Coding Agents</category><category>Synthetic Data Generation</category><category>Repository Specialization</category><category>Supervised Finetuning</category><category>Soft Verification</category><category>Cost-Efficiency</category><category>SWE-bench</category>
    </item>
    <item>
      <title>[논문리뷰] SE-DiCoW: Self-Enrolled Diarization-Conditioned Whisper</title>
      <description>이 [arXiv]에 게시한 &#39;SE-DiCoW: Self-Enrolled Diarization-Conditioned Whisper&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-29-SE-DiCoW-Self-Enrolled-Diarization-Conditioned-Whisper/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-29-SE-DiCoW-Self-Enrolled-Diarization-Conditioned-Whisper/</guid>
      <pubDate>Thu, 29 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Target-Speaker ASR</category><category>DiCoW</category><category>Whisper Model</category><category>Multi-speaker ASR</category><category>Self-enrollment</category><category>Cross-attention</category><category>Speech Diarization</category>
    </item>
    <item>
      <title>[논문리뷰] Reinforcement Learning via Self-Distillation</title>
      <description>이 [arXiv]에 게시한 &#39;Reinforcement Learning via Self-Distillation&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-29-Reinforcement-Learning-via-Self-Distillation/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-29-Reinforcement-Learning-via-Self-Distillation/</guid>
      <pubDate>Thu, 29 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Reinforcement Learning</category><category>Self-Distillation</category><category>Large Language Models (LLMs)</category><category>Rich Feedback</category><category>Credit Assignment</category><category>Policy Optimization</category><category>RLHF</category><category>Code Generation</category><category>Test-Time Training</category>
    </item>
    <item>
      <title>[논문리뷰] RIR-Mega-Speech: A Reverberant Speech Corpus with Comprehensive Acoustic Metadata and Reproducible Evaluation</title>
      <description>mandipgoswami이 [arXiv]에 게시한 &#39;RIR-Mega-Speech: A Reverberant Speech Corpus with Comprehensive Acoustic Metadata and Reproducible Evaluation&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-29-RIR-Mega-Speech-A-Reverberant-Speech-Corpus-with-Comprehensive-Acoustic-Metadata-and-Reproducible-Evaluation/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-29-RIR-Mega-Speech-A-Reverberant-Speech-Corpus-with-Comprehensive-Acoustic-Metadata-and-Reproducible-Evaluation/</guid>
      <pubDate>Thu, 29 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Reverberant Speech</category><category>Speech Corpus</category><category>Acoustic Metadata</category><category>Reproducible Research</category><category>ASR Evaluation</category><category>Room Impulse Response</category><category>Speech Recognition</category>
    </item>
    
  </channel>
</rss>