<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>secrett2633's blog</title>
    <description>기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트</description>
    <link>https://blog.secrett2633.cloud</link>
    <atom:link href="https://blog.secrett2633.cloud/feed.xml" rel="self" type="application/rss+xml" />
    <language>ko-KR</language>
    <lastBuildDate>Fri, 23 Jan 2026 20:32:36 GMT</lastBuildDate>
    <pubDate>Fri, 23 Jan 2026 20:32:36 GMT</pubDate>
    <ttl>60</ttl>
    <generator>Next.js RSS Generator</generator>
    <managingEditor>secrett2633@example.com (secrett2633)</managingEditor>
    <webMaster>secrett2633@example.com (secrett2633)</webMaster>
    <category>Technology</category>
    <category>Programming</category>
    <category>Django</category>
    <category>Python</category>
    <category>DevOps</category>
    <category>AI/ML</category>
    
        <item>
      <title>[논문리뷰] sangkuriang: A pseudo-spectral Python library for Korteweg-de Vries soliton simulation</title>
      <description>이 [arXiv]에 게시한 &#39;sangkuriang: A pseudo-spectral Python library for Korteweg-de Vries soliton simulation&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-22-sangkuriang-A-pseudo-spectral-Python-library-for-Korteweg-de-Vries-soliton-simulation/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-22-sangkuriang-A-pseudo-spectral-Python-library-for-Korteweg-de-Vries-soliton-simulation/</guid>
      <pubDate>Thu, 22 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Nonlinear Wave Physics</category><category>Soliton Simulation</category><category>Korteweg-de Vries Equation</category><category>Pseudo-spectral Methods</category><category>Adaptive Time Integration</category><category>Python Library</category><category>Computational Physics</category>
    </item>
    <item>
      <title>[논문리뷰] XR: Cross-Modal Agents for Composed Image Retrieval</title>
      <description>이 [arXiv]에 게시한 &#39;XR: Cross-Modal Agents for Composed Image Retrieval&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-22-XR-Cross-Modal-Agents-for-Composed-Image-Retrieval/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-22-XR-Cross-Modal-Agents-for-Composed-Image-Retrieval/</guid>
      <pubDate>Thu, 22 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Composed Image Retrieval</category><category>Cross-Modal Agents</category><category>Multimodal Reasoning</category><category>Training-free Framework</category><category>Information Retrieval</category><category>Agentic AI</category><category>Progressive Retrieval</category>
    </item>
    <item>
      <title>[논문리뷰] Typhoon OCR: Open Vision-Language Model For Thai Document Extraction</title>
      <description>이 [arXiv]에 게시한 &#39;Typhoon OCR: Open Vision-Language Model For Thai Document Extraction&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-22-Typhoon-OCR-Open-Vision-Language-Model-For-Thai-Document-Extraction/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-22-Typhoon-OCR-Open-Vision-Language-Model-For-Thai-Document-Extraction/</guid>
      <pubDate>Thu, 22 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Vision-Language Model</category><category>OCR</category><category>Thai Language Processing</category><category>Document Understanding</category><category>Low-Resource Language</category><category>Data Synthesis</category><category>Fine-tuning</category><category>Layout Analysis</category>
    </item>
    <item>
      <title>[논문리뷰] Typhoon ASR Real-time: FastConformer-Transducer for Thai Automatic Speech Recognition</title>
      <description>이 [arXiv]에 게시한 &#39;Typhoon ASR Real-time: FastConformer-Transducer for Thai Automatic Speech Recognition&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-22-Typhoon-ASR-Real-time-FastConformer-Transducer-for-Thai-Automatic-Speech-Recognition/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-22-Typhoon-ASR-Real-time-FastConformer-Transducer-for-Thai-Automatic-Speech-Recognition/</guid>
      <pubDate>Thu, 22 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Thai ASR</category><category>Real-time Speech Recognition</category><category>FastConformer-Transducer</category><category>Low-latency</category><category>Text Normalization</category><category>Dialect Adaptation</category><category>Data Curation</category><category>Streaming ASR</category>
    </item>
    <item>
      <title>[논문리뷰] The Responsibility Vacuum: Organizational Failure in Scaled Agent Systems</title>
      <description>Roman Bondar이 [arXiv]에 게시한 &#39;The Responsibility Vacuum: Organizational Failure in Scaled Agent Systems&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-22-The-Responsibility-Vacuum-Organizational-Failure-in-Scaled-Agent-Systems/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-22-The-Responsibility-Vacuum-Organizational-Failure-in-Scaled-Agent-Systems/</guid>
      <pubDate>Thu, 22 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Responsibility Vacuum</category><category>Scaled Agent Systems</category><category>Organizational Failure</category><category>CI/CD Pipelines</category><category>Human Verification Capacity</category><category>Authority-Capacity Mismatch</category><category>AI Governance</category><category>Ritualized Approval</category>
    </item>
    <item>
      <title>[논문리뷰] RoboBrain 2.5: Depth in Sight, Time in Mind</title>
      <description>Yuheng Ji이 [arXiv]에 게시한 &#39;RoboBrain 2.5: Depth in Sight, Time in Mind&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-22-RoboBrain-2-5-Depth-in-Sight-Time-in-Mind/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-22-RoboBrain-2-5-Depth-in-Sight-Time-in-Mind/</guid>
      <pubDate>Thu, 22 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Embodied AI</category><category>Foundation Model</category><category>3D Spatial Reasoning</category><category>Temporal Value Estimation</category><category>Robotics</category><category>Manipulation</category><category>Multimodal Learning</category>
    </item>
    <item>
      <title>[논문리뷰] Rethinking Video Generation Model for the Embodied World</title>
      <description>이 [arXiv]에 게시한 &#39;Rethinking Video Generation Model for the Embodied World&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-22-Rethinking-Video-Generation-Model-for-the-Embodied-World/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-22-Rethinking-Video-Generation-Model-for-the-Embodied-World/</guid>
      <pubDate>Thu, 22 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Video Generation</category><category>Embodied AI</category><category>Robotics Benchmark</category><category>RBench</category><category>Robotics Dataset</category><category>RoVid-X</category><category>Physical Plausibility</category><category>Task Completion</category>
    </item>
    <item>
      <title>[논문리뷰] Render-of-Thought: Rendering Textual Chain-of-Thought as Images for Visual Latent Reasoning</title>
      <description>이 [arXiv]에 게시한 &#39;Render-of-Thought: Rendering Textual Chain-of-Thought as Images for Visual Latent Reasoning&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-22-Render-of-Thought-Rendering-Textual-Chain-of-Thought-as-Images-for-Visual-Latent-Reasoning/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-22-Render-of-Thought-Rendering-Textual-Chain-of-Thought-as-Images-for-Visual-Latent-Reasoning/</guid>
      <pubDate>Thu, 22 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Chain-of-Thought (CoT)</category><category>Large Language Models (LLMs)</category><category>Vision Language Models (VLMs)</category><category>Latent Reasoning</category><category>Visual Modality</category><category>Image Rendering</category><category>Computational Efficiency</category><category>Knowledge Distillation</category>
    </item>
    <item>
      <title>[논문리뷰] Quantifying Speaker Embedding Phonological Rule Interactions in Accented Speech Synthesis</title>
      <description>Jihwan Lee이 [arXiv]에 게시한 &#39;Quantifying Speaker Embedding Phonological Rule Interactions in Accented Speech Synthesis&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-22-Quantifying-Speaker-Embedding-Phonological-Rule-Interactions-in-Accented-Speech-Synthesis/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-22-Quantifying-Speaker-Embedding-Phonological-Rule-Interactions-in-Accented-Speech-Synthesis/</guid>
      <pubDate>Thu, 22 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Text-to-Speech</category><category>Accent Control</category><category>Phonological Rules</category><category>Speaker Embeddings</category><category>Speech Synthesis</category><category>Disentanglement</category><category>Accent Classification</category>
    </item>
    <item>
      <title>[논문리뷰] Paper2Rebuttal: A Multi-Agent Framework for Transparent Author Response Assistance</title>
      <description>이 [arXiv]에 게시한 &#39;Paper2Rebuttal: A Multi-Agent Framework for Transparent Author Response Assistance&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-22-Paper2Rebuttal-A-Multi-Agent-Framework-for-Transparent-Author-Response-Assistance/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-22-Paper2Rebuttal-A-Multi-Agent-Framework-for-Transparent-Author-Response-Assistance/</guid>
      <pubDate>Thu, 22 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Multi-Agent Framework</category><category>LLM Agents</category><category>Peer Review</category><category>Rebuttal Generation</category><category>Evidence-centric Planning</category><category>Transparency</category><category>Human-in-the-loop</category>
    </item>
    <item>
      <title>[논문리뷰] Numina-Lean-Agent: An Open and General Agentic Reasoning System for Formal Mathematics</title>
      <description>이 [arXiv]에 게시한 &#39;Numina-Lean-Agent: An Open and General Agentic Reasoning System for Formal Mathematics&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-22-Numina-Lean-Agent-An-Open-and-General-Agentic-Reasoning-System-for-Formal-Mathematics/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-22-Numina-Lean-Agent-An-Open-and-General-Agentic-Reasoning-System-for-Formal-Mathematics/</guid>
      <pubDate>Thu, 22 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Agentic Systems</category><category>Formal Theorem Proving</category><category>Large Language Models (LLMs)</category><category>Lean Theorem Prover</category><category>Multi-Agent Systems</category><category>Code Generation</category><category>Automated Reasoning</category><category>Human-AI Collaboration</category>
    </item>
    <item>
      <title>[논문리뷰] MMDeepResearch-Bench: A Benchmark for Multimodal Deep Research Agents</title>
      <description>Samiul Alam이 [arXiv]에 게시한 &#39;MMDeepResearch-Bench: A Benchmark for Multimodal Deep Research Agents&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-22-MMDeepResearch-Bench-A-Benchmark-for-Multimodal-Deep-Research-Agents/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-22-MMDeepResearch-Bench-A-Benchmark-for-Multimodal-Deep-Research-Agents/</guid>
      <pubDate>Thu, 22 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Multimodal Deep Research</category><category>Research Agents</category><category>Benchmark</category><category>Evaluation Framework</category><category>Retrieval-Augmented Generation</category><category>Large Multimodal Models</category><category>Visual Grounding</category><category>Citation Analysis</category>
    </item>
    <item>
      <title>[논문리뷰] Lost in the Prompt Order: Revealing the Limitations of Causal Attention in Language Models</title>
      <description>이 [arXiv]에 게시한 &#39;Lost in the Prompt Order: Revealing the Limitations of Causal Attention in Language Models&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-22-Lost-in-the-Prompt-Order-Revealing-the-Limitations-of-Causal-Attention-in-Language-Models/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-22-Lost-in-the-Prompt-Order-Revealing-the-Limitations-of-Causal-Attention-in-Language-Models/</guid>
      <pubDate>Thu, 22 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Prompt Engineering</category><category>Large Language Models</category><category>Causal Attention</category><category>Multiple-Choice QA</category><category>Prompt Order Sensitivity</category><category>Information Bottleneck</category><category>Decoder-only Transformers</category>
    </item>
    <item>
      <title>[논문리뷰] FinVault: Benchmarking Financial Agent Safety in Execution-Grounded Environments</title>
      <description>이 [arXiv]에 게시한 &#39;FinVault: Benchmarking Financial Agent Safety in Execution-Grounded Environments&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-22-FinVault-Benchmarking-Financial-Agent-Safety-in-Execution-Grounded-Environments/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-22-FinVault-Benchmarking-Financial-Agent-Safety-in-Execution-Grounded-Environments/</guid>
      <pubDate>Thu, 22 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Financial AI Agents</category><category>Security Benchmark</category><category>Execution-Grounded</category><category>LLM Safety</category><category>Prompt Injection</category><category>Jailbreaking</category><category>Compliance</category><category>Vulnerability Assessment</category>
    </item>
    <item>
      <title>[논문리뷰] Facilitating Proactive and Reactive Guidance for Decision Making on the Web: A Design Probe with WebSeek</title>
      <description>Arpit Narechania이 [arXiv]에 게시한 &#39;Facilitating Proactive and Reactive Guidance for Decision Making on the Web: A Design Probe with WebSeek&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-22-Facilitating-Proactive-and-Reactive-Guidance-for-Decision-Making-on-the-Web-A-Design-Probe-with-WebSeek/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-22-Facilitating-Proactive-and-Reactive-Guidance-for-Decision-Making-on-the-Web-A-Design-Probe-with-WebSeek/</guid>
      <pubDate>Thu, 22 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Mixed-Initiative AI</category><category>Human-AI Collaboration</category><category>Web Data Analysis</category><category>Proactive Guidance</category><category>Large Language Models (LLMs)</category><category>Browser Extension</category><category>Data-Centric Design</category>
    </item>
    <item>
      <title>[논문리뷰] FARE: Fast-Slow Agentic Robotic Exploration</title>
      <description>Jingsong Liang이 [arXiv]에 게시한 &#39;FARE: Fast-Slow Agentic Robotic Exploration&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-22-FARE-Fast-Slow-Agentic-Robotic-Exploration/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-22-FARE-Fast-Slow-Agentic-Robotic-Exploration/</guid>
      <pubDate>Thu, 22 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Robotic Exploration</category><category>LLM</category><category>Reinforcement Learning</category><category>Fast-Slow Thinking</category><category>Hierarchical Planning</category><category>Agentic AI</category><category>Graph Reasoning</category>
    </item>
    <item>
      <title>[논문리뷰] Agentic Reasoning for Large Language Models</title>
      <description>이 [arXiv]에 게시한 &#39;Agentic Reasoning for Large Language Models&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-22-Agentic-Reasoning-for-Large-Language-Models/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-22-Agentic-Reasoning-for-Large-Language-Models/</guid>
      <pubDate>Thu, 22 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Agentic Reasoning</category><category>LLM Agents</category><category>Self-Evolving AI</category><category>Multi-Agent Systems</category><category>Planning</category><category>Tool Use</category><category>Retrieval-Augmented Generation</category><category>Reinforcement Learning</category>
    </item>
    <item>
      <title>[논문리뷰] AgentEHR: Advancing Autonomous Clinical Decision-Making via Retrospective Summarization</title>
      <description>이 [arXiv]에 게시한 &#39;AgentEHR: Advancing Autonomous Clinical Decision-Making via Retrospective Summarization&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-22-AgentEHR-Advancing-Autonomous-Clinical-Decision-Making-via-Retrospective-Summarization/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-22-AgentEHR-Advancing-Autonomous-Clinical-Decision-Making-via-Retrospective-Summarization/</guid>
      <pubDate>Thu, 22 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Clinical Decision-Making</category><category>LLM Agents</category><category>EHR</category><category>Retrospective Summarization</category><category>Long-Context Reasoning</category><category>Experience Replay</category><category>Healthcare AI</category>
    </item>
    <item>
      <title>[논문리뷰] UniX: Unifying Autoregression and Diffusion for Chest X-Ray Understanding and Generation</title>
      <description>이 [arXiv]에 게시한 &#39;UniX: Unifying Autoregression and Diffusion for Chest X-Ray Understanding and Generation&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-21-UniX-Unifying-Autoregression-and-Diffusion-for-Chest-X-Ray-Understanding-and-Generation/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-21-UniX-Unifying-Autoregression-and-Diffusion-for-Chest-X-Ray-Understanding-and-Generation/</guid>
      <pubDate>Wed, 21 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Chest X-Ray</category><category>Medical Foundation Model</category><category>Autoregressive Model</category><category>Diffusion Model</category><category>Multimodal Learning</category><category>Image Understanding</category><category>Image Generation</category><category>Cross-Modal Attention</category>
    </item>
    <item>
      <title>[논문리뷰] Toward Efficient Agents: Memory, Tool learning, and Planning</title>
      <description>이 [arXiv]에 게시한 &#39;Toward Efficient Agents: Memory, Tool learning, and Planning&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-21-Toward-Efficient-Agents-Memory-Tool-learning-and-Planning/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-21-Toward-Efficient-Agents-Memory-Tool-learning-and-Planning/</guid>
      <pubDate>Wed, 21 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>LLM Agents</category><category>Agent Efficiency</category><category>Memory Management</category><category>Tool Learning</category><category>AI Planning</category><category>Resource Optimization</category><category>Cost-Performance Trade-off</category>
    </item>
    <item>
      <title>[논문리뷰] ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents</title>
      <description>이 [arXiv]에 게시한 &#39;ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-21-ToolPRMBench-Evaluating-and-Advancing-Process-Reward-Models-for-Tool-using-Agents/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-21-ToolPRMBench-Evaluating-and-Advancing-Process-Reward-Models-for-Tool-using-Agents/</guid>
      <pubDate>Wed, 21 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Process Reward Models</category><category>Tool-using Agents</category><category>Benchmark</category><category>Reinforcement Learning</category><category>Large Language Models</category><category>Reward-guided Search</category><category>Agent Evaluation</category><category>Step-level Rewards</category>
    </item>
    <item>
      <title>[논문리뷰] Think3D: Thinking with Space for Spatial Reasoning</title>
      <description>Yuhan Wu이 [arXiv]에 게시한 &#39;Think3D: Thinking with Space for Spatial Reasoning&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-21-Think3D-Thinking-with-Space-for-Spatial-Reasoning/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-21-Think3D-Thinking-with-Space-for-Spatial-Reasoning/</guid>
      <pubDate>Wed, 21 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Spatial Reasoning</category><category>3D Reconstruction</category><category>VLM Agents</category><category>Tool Calling</category><category>Reinforcement Learning</category><category>Novel View Synthesis</category><category>Iterative Exploration</category>
    </item>
    <item>
      <title>[논문리뷰] SciCoQA: Quality Assurance for Scientific Paper--Code Alignment</title>
      <description>이 [arXiv]에 게시한 &#39;SciCoQA: Quality Assurance for Scientific Paper--Code Alignment&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-21-SciCoQA-Quality-Assurance-for-Scientific-Paper-Code-Alignment/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-21-SciCoQA-Quality-Assurance-for-Scientific-Paper-Code-Alignment/</guid>
      <pubDate>Wed, 21 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Reproducibility</category><category>Paper-Code Discrepancy</category><category>Code Alignment</category><category>LLM Evaluation</category><category>Synthetic Data Generation</category><category>Quality Assurance</category><category>Scientific Automation</category>
    </item>
    <item>
      <title>[논문리뷰] PRiSM: Benchmarking Phone Realization in Speech Models</title>
      <description>이 [arXiv]에 게시한 &#39;PRiSM: Benchmarking Phone Realization in Speech Models&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-21-PRiSM-Benchmarking-Phone-Realization-in-Speech-Models/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-21-PRiSM-Benchmarking-Phone-Realization-in-Speech-Models/</guid>
      <pubDate>Wed, 21 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Phone Recognition</category><category>Speech Models</category><category>Benchmarking</category><category>Phonetic Analysis</category><category>Cross-lingual Speech</category><category>LALMs</category><category>Intrinsic Evaluation</category><category>Extrinsic Evaluation</category>
    </item>
    <item>
      <title>[논문리뷰] On the Evidentiary Limits of Membership Inference for Copyright Auditing</title>
      <description>Marten van Dijk이 [arXiv]에 게시한 &#39;On the Evidentiary Limits of Membership Inference for Copyright Auditing&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-21-On-the-Evidentiary-Limits-of-Membership-Inference-for-Copyright-Auditing/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-21-On-the-Evidentiary-Limits-of-Membership-Inference-for-Copyright-Auditing/</guid>
      <pubDate>Wed, 21 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Membership Inference Attacks</category><category>Copyright Auditing</category><category>Large Language Models</category><category>Adversarial Robustness</category><category>Paraphrasing</category><category>Sparse Autoencoders</category><category>Semantic Preservation</category><category>LLM Security</category>
    </item>
    <item>
      <title>[논문리뷰] OmniTransfer: All-in-one Framework for Spatio-temporal Video Transfer</title>
      <description>이 [arXiv]에 게시한 &#39;OmniTransfer: All-in-one Framework for Spatio-temporal Video Transfer&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-21-OmniTransfer-All-in-one-Framework-for-Spatio-temporal-Video-Transfer/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-21-OmniTransfer-All-in-one-Framework-for-Spatio-temporal-Video-Transfer/</guid>
      <pubDate>Wed, 21 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Video Transfer</category><category>Diffusion Models</category><category>Spatio-temporal Learning</category><category>Multimodal Alignment</category><category>Appearance Consistency</category><category>Temporal Control</category><category>Video Generation</category>
    </item>
    <item>
      <title>[논문리뷰] MemoryRewardBench: Benchmarking Reward Models for Long-Term Memory Management in Large Language Models</title>
      <description>이 [arXiv]에 게시한 &#39;MemoryRewardBench: Benchmarking Reward Models for Long-Term Memory Management in Large Language Models&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-21-MemoryRewardBench-Benchmarking-Reward-Models-for-Long-Term-Memory-Management-in-Large-Language-Models/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-21-MemoryRewardBench-Benchmarking-Reward-Models-for-Long-Term-Memory-Management-in-Large-Language-Models/</guid>
      <pubDate>Wed, 21 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Reward Models</category><category>LLM Memory Management</category><category>Benchmarking</category><category>Long Context</category><category>Evaluation Metrics</category><category>Generative RMs</category><category>Memory Management Patterns</category>
    </item>
    <item>
      <title>[논문리뷰] LightOnOCR: A 1B End-to-End Multilingual Vision-Language Model for State-of-the-Art OCR</title>
      <description>이 [arXiv]에 게시한 &#39;LightOnOCR: A 1B End-to-End Multilingual Vision-Language Model for State-of-the-Art OCR&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-21-LightOnOCR-A-1B-End-to-End-Multilingual-Vision-Language-Model-for-State-of-the-Art-OCR/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-21-LightOnOCR-A-1B-End-to-End-Multilingual-Vision-Language-Model-for-State-of-the-Art-OCR/</guid>
      <pubDate>Wed, 21 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>OCR</category><category>Vision-Language Model</category><category>End-to-End Learning</category><category>Multilingual</category><category>Reinforcement Learning</category><category>Document Understanding</category><category>Bounding Box Prediction</category><category>Task Arithmetic Merging</category>
    </item>
    <item>
      <title>[논문리뷰] LIBERTy: A Causal Framework for Benchmarking Concept-Based Explanations of LLMs with Structural Counterfactuals</title>
      <description>이 [arXiv]에 게시한 &#39;LIBERTy: A Causal Framework for Benchmarking Concept-Based Explanations of LLMs with Structural Counterfactuals&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-21-LIBERTy-A-Causal-Framework-for-Benchmarking-Concept-Based-Explanations-of-LLMs-with-Structural-Counterfactuals/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-21-LIBERTy-A-Causal-Framework-for-Benchmarking-Concept-Based-Explanations-of-LLMs-with-Structural-Counterfactuals/</guid>
      <pubDate>Wed, 21 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>LLM Explainability</category><category>Causal Inference</category><category>Structural Counterfactuals</category><category>Concept-Based Explanations</category><category>Evaluation Benchmark</category><category>Faithfulness</category><category>SCM</category>
    </item>
    <item>
      <title>[논문리뷰] KAGE-Bench: Fast Known-Axis Visual Generalization Evaluation for Reinforcement Learning</title>
      <description>Aleksandr I. Panov이 [arXiv]에 게시한 &#39;KAGE-Bench: Fast Known-Axis Visual Generalization Evaluation for Reinforcement Learning&#39; 논문에 대한 자세한 리뷰입니다.</description>
      <link>https://blog.secrett2633.cloud/ai/review/2026-01-21-KAGE-Bench-Fast-Known-Axis-Visual-Generalization-Evaluation-for-Reinforcement-Learning/</link>
      <guid isPermaLink="true">https://blog.secrett2633.cloud/ai/review/2026-01-21-KAGE-Bench-Fast-Known-Axis-Visual-Generalization-Evaluation-for-Reinforcement-Learning/</guid>
      <pubDate>Wed, 21 Jan 2026 00:00:00 GMT</pubDate>
      <category>Review</category>
      <category>Review</category><category>Reinforcement Learning</category><category>Visual Generalization</category><category>Distribution Shift</category><category>Benchmarking</category><category>JAX</category><category>Controlled Environments</category><category>PPO</category>
    </item>
    
  </channel>
</rss>