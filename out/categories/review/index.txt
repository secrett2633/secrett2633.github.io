2:I[9157,["231","static/chunks/231-c27e618569e042bc.js","157","static/chunks/157-bca72c9e0551c9c1.js","257","static/chunks/app/categories/%5Bcategory%5D/page-fd52b5b723ba7c53.js"],"default"]
3:I[231,["231","static/chunks/231-c27e618569e042bc.js","157","static/chunks/157-bca72c9e0551c9c1.js","257","static/chunks/app/categories/%5Bcategory%5D/page-fd52b5b723ba7c53.js"],""]
4:I[9275,[],""]
6:I[1343,[],""]
5:["category","review","d"]
0:["JN58fahCcEs2CyeokFRnm",[[["",{"children":["categories",{"children":[["category","review","d"],{"children":["__PAGE__?{\"category\":\"review\"}",{}]}]}]},"$undefined","$undefined",true],["",{"children":["categories",{"children":[["category","review","d"],{"children":["__PAGE__",{},[["$L1",[["$","$L2",null,{}],["$","div",null,{"className":"initial-content","children":["$","div",null,{"className":"flex flex-col lg:flex-row gap-8","children":[["$","main",null,{"className":"flex-1","children":[["$","h1",null,{"className":"page__title","children":["Review"," 카테고리"]}],["$","div",null,{"className":"entries-list","children":[["$","article","2025-11-25-UltraFlux-Data-Model-Co-Design-for-High-quality-Native-4K-Text-to-Image-Generation-across-Diverse-Aspect-Ratios",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-25-UltraFlux-Data-Model-Co-Design-for-High-quality-Native-4K-Text-to-Image-Generation-across-Diverse-Aspect-Ratios/","children":"[논문리뷰] UltraFlux: Data-Model Co-Design for High-quality Native 4K Text-to-Image Generation across Diverse Aspect Ratios"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'UltraFlux: Data-Model Co-Design for High-quality Native 4K Text-to-Image Generation across Diverse Aspect Ratios' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-25 00:00:00+0900+0900","children":"2025년 11월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Diffusion Transformers",{"className":"page__taxonomy-item","children":["#","Diffusion Transformers"]}],["$","span","4K Resolution",{"className":"page__taxonomy-item","children":["#","4K Resolution"]}],["$","span","Aspect Ratio Extrapolation",{"className":"page__taxonomy-item","children":["#","Aspect Ratio Extrapolation"]}],["$","span","Data-Model Co-Design",{"className":"page__taxonomy-item","children":["#","Data-Model Co-Design"]}],["$","span","VAE Post-training",{"className":"page__taxonomy-item","children":["#","VAE Post-training"]}],["$","span","Positional Encoding",{"className":"page__taxonomy-item","children":["#","Positional Encoding"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}]]}]]}]]}],["$","article","2025-11-25-Target-Bench-Can-World-Models-Achieve-Mapless-Path-Planning-with-Semantic-Targets",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-25-Target-Bench-Can-World-Models-Achieve-Mapless-Path-Planning-with-Semantic-Targets/","children":"[논문리뷰] Target-Bench: Can World Models Achieve Mapless Path Planning with Semantic Targets?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhaowei Lu이 [arXiv]에 게시한 'Target-Bench: Can World Models Achieve Mapless Path Planning with Semantic Targets?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-25 00:00:00+0900+0900","children":"2025년 11월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","World Models",{"className":"page__taxonomy-item","children":["#","World Models"]}],["$","span","Mapless Navigation",{"className":"page__taxonomy-item","children":["#","Mapless Navigation"]}],["$","span","Semantic Path Planning",{"className":"page__taxonomy-item","children":["#","Semantic Path Planning"]}],["$","span","Robot Learning",{"className":"page__taxonomy-item","children":["#","Robot Learning"]}],["$","span","Video Prediction",{"className":"page__taxonomy-item","children":["#","Video Prediction"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Trajectory Generation",{"className":"page__taxonomy-item","children":["#","Trajectory Generation"]}]]}]]}]]}],["$","article","2025-11-25-SyncMV4D-Synchronized-Multi-view-Joint-Diffusion-of-Appearance-and-Motion-for-Hand-Object-Interaction-Synthesis",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-25-SyncMV4D-Synchronized-Multi-view-Joint-Diffusion-of-Appearance-and-Motion-for-Hand-Object-Interaction-Synthesis/","children":"[논문리뷰] SyncMV4D: Synchronized Multi-view Joint Diffusion of Appearance and Motion for Hand-Object Interaction Synthesis"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hongwen Zhang이 [arXiv]에 게시한 'SyncMV4D: Synchronized Multi-view Joint Diffusion of Appearance and Motion for Hand-Object Interaction Synthesis' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-25 00:00:00+0900+0900","children":"2025년 11월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Hand-Object Interaction",{"className":"page__taxonomy-item","children":["#","Hand-Object Interaction"]}],["$","span","Multi-view Video Generation",{"className":"page__taxonomy-item","children":["#","Multi-view Video Generation"]}],["$","span","4D Motion Synthesis",{"className":"page__taxonomy-item","children":["#","4D Motion Synthesis"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Spatio-temporal Consistency",{"className":"page__taxonomy-item","children":["#","Spatio-temporal Consistency"]}],["$","span","Geometric Consistency",{"className":"page__taxonomy-item","children":["#","Geometric Consistency"]}],["$","span","Appearance and Motion Joint Modeling",{"className":"page__taxonomy-item","children":["#","Appearance and Motion Joint Modeling"]}]]}]]}]]}],["$","article","2025-11-25-Plan-X-Instruct-Video-Generation-via-Semantic-Planning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-25-Plan-X-Instruct-Video-Generation-via-Semantic-Planning/","children":"[논문리뷰] Plan-X: Instruct Video Generation via Semantic Planning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chenxu Zhang이 [arXiv]에 게시한 'Plan-X: Instruct Video Generation via Semantic Planning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-25 00:00:00+0900+0900","children":"2025년 11월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Semantic Planning",{"className":"page__taxonomy-item","children":["#","Semantic Planning"]}],["$","span","Multimodal LLM",{"className":"page__taxonomy-item","children":["#","Multimodal LLM"]}],["$","span","Diffusion Transformer",{"className":"page__taxonomy-item","children":["#","Diffusion Transformer"]}],["$","span","Spatio-temporal Guidance",{"className":"page__taxonomy-item","children":["#","Spatio-temporal Guidance"]}],["$","span","Visual Hallucination",{"className":"page__taxonomy-item","children":["#","Visual Hallucination"]}],["$","span","Prompt Alignment",{"className":"page__taxonomy-item","children":["#","Prompt Alignment"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}]]}]]}]]}],["$","article","2025-11-25-Pillar-0-A-New-Frontier-for-Radiology-Foundation-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-25-Pillar-0-A-New-Frontier-for-Radiology-Foundation-Models/","children":"[논문리뷰] Pillar-0: A New Frontier for Radiology Foundation Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Pillar-0: A New Frontier for Radiology Foundation Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-25 00:00:00+0900+0900","children":"2025년 11월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Radiology Foundation Model",{"className":"page__taxonomy-item","children":["#","Radiology Foundation Model"]}],["$","span","Volumetric Imaging",{"className":"page__taxonomy-item","children":["#","Volumetric Imaging"]}],["$","span","Multi-window Tokenization",{"className":"page__taxonomy-item","children":["#","Multi-window Tokenization"]}],["$","span","Multi-scale Attention",{"className":"page__taxonomy-item","children":["#","Multi-scale Attention"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Clinical Evaluation",{"className":"page__taxonomy-item","children":["#","Clinical Evaluation"]}],["$","span","Data Efficiency",{"className":"page__taxonomy-item","children":["#","Data Efficiency"]}],["$","span","Medical Imaging",{"className":"page__taxonomy-item","children":["#","Medical Imaging"]}]]}]]}]]}],["$","article","2025-11-25-PRInTS-Reward-Modeling-for-Long-Horizon-Information-Seeking",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-25-PRInTS-Reward-Modeling-for-Long-Horizon-Information-Seeking/","children":"[논문리뷰] PRInTS: Reward Modeling for Long-Horizon Information Seeking"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Elias Stengel-Eskin이 [arXiv]에 게시한 'PRInTS: Reward Modeling for Long-Horizon Information Seeking' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-25 00:00:00+0900+0900","children":"2025년 11월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reward Modeling",{"className":"page__taxonomy-item","children":["#","Reward Modeling"]}],["$","span","Long-Horizon Tasks",{"className":"page__taxonomy-item","children":["#","Long-Horizon Tasks"]}],["$","span","Information Seeking",{"className":"page__taxonomy-item","children":["#","Information Seeking"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Trajectory Summarization",{"className":"page__taxonomy-item","children":["#","Trajectory Summarization"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Process Reward Models",{"className":"page__taxonomy-item","children":["#","Process Reward Models"]}]]}]]}]]}],["$","article","2025-11-25-Multi-Agent-Deep-Research-Training-Multi-Agent-Systems-with-M-GRPO",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-25-Multi-Agent-Deep-Research-Training-Multi-Agent-Systems-with-M-GRPO/","children":"[논문리뷰] Multi-Agent Deep Research: Training Multi-Agent Systems with M-GRPO"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Multi-Agent Deep Research: Training Multi-Agent Systems with M-GRPO' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-25 00:00:00+0900+0900","children":"2025년 11월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","LLM Training",{"className":"page__taxonomy-item","children":["#","LLM Training"]}],["$","span","Hierarchical Credit Assignment",{"className":"page__taxonomy-item","children":["#","Hierarchical Credit Assignment"]}],["$","span","Trajectory Alignment",{"className":"page__taxonomy-item","children":["#","Trajectory Alignment"]}],["$","span","Group Relative Policy Optimization",{"className":"page__taxonomy-item","children":["#","Group Relative Policy Optimization"]}],["$","span","Tool-Augmented Reasoning",{"className":"page__taxonomy-item","children":["#","Tool-Augmented Reasoning"]}],["$","span","Vertical Architecture",{"className":"page__taxonomy-item","children":["#","Vertical Architecture"]}]]}]]}]]}],["$","article","2025-11-25-MIST-Mutual-Information-Via-Supervised-Training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-25-MIST-Mutual-Information-Via-Supervised-Training/","children":"[논문리뷰] MIST: Mutual Information Via Supervised Training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kyunghyun Cho이 [arXiv]에 게시한 'MIST: Mutual Information Via Supervised Training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-25 00:00:00+0900+0900","children":"2025년 11월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Mutual Information Estimation",{"className":"page__taxonomy-item","children":["#","Mutual Information Estimation"]}],["$","span","Supervised Learning",{"className":"page__taxonomy-item","children":["#","Supervised Learning"]}],["$","span","Meta-Learning",{"className":"page__taxonomy-item","children":["#","Meta-Learning"]}],["$","span","Neural Networks",{"className":"page__taxonomy-item","children":["#","Neural Networks"]}],["$","span","Uncertainty Quantification",{"className":"page__taxonomy-item","children":["#","Uncertainty Quantification"]}],["$","span","SetTransformer",{"className":"page__taxonomy-item","children":["#","SetTransformer"]}],["$","span","Quantile Regression",{"className":"page__taxonomy-item","children":["#","Quantile Regression"]}]]}]]}]]}],["$","article","2025-11-25-MASS-Motion-Aware-Spatial-Temporal-Grounding-for-Physics-Reasoning-and-Comprehension-in-Vision-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-25-MASS-Motion-Aware-Spatial-Temporal-Grounding-for-Physics-Reasoning-and-Comprehension-in-Vision-Language-Models/","children":"[논문리뷰] MASS: Motion-Aware Spatial-Temporal Grounding for Physics Reasoning and Comprehension in Vision-Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'MASS: Motion-Aware Spatial-Temporal Grounding for Physics Reasoning and Comprehension in Vision-Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-25 00:00:00+0900+0900","children":"2025년 11월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Physics Reasoning",{"className":"page__taxonomy-item","children":["#","Physics Reasoning"]}],["$","span","Motion Tracking",{"className":"page__taxonomy-item","children":["#","Motion Tracking"]}],["$","span","Spatial-Temporal Grounding",{"className":"page__taxonomy-item","children":["#","Spatial-Temporal Grounding"]}],["$","span","Video QA",{"className":"page__taxonomy-item","children":["#","Video QA"]}],["$","span","AIGC Analysis",{"className":"page__taxonomy-item","children":["#","AIGC Analysis"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}]]}]]}]]}],["$","article","2025-11-25-M3-Bench-Multi-Modal-Multi-Hop-Multi-Threaded-Tool-Using-MLLM-Agent-Benchmark",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-25-M3-Bench-Multi-Modal-Multi-Hop-Multi-Threaded-Tool-Using-MLLM-Agent-Benchmark/","children":"[논문리뷰] M3-Bench: Multi-Modal, Multi-Hop, Multi-Threaded Tool-Using MLLM Agent Benchmark"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Bangwei Guo이 [arXiv]에 게시한 'M3-Bench: Multi-Modal, Multi-Hop, Multi-Threaded Tool-Using MLLM Agent Benchmark' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-25 00:00:00+0900+0900","children":"2025년 11월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLM",{"className":"page__taxonomy-item","children":["#","Multimodal LLM"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Agent Benchmark",{"className":"page__taxonomy-item","children":["#","Agent Benchmark"]}],["$","span","Model Context Protocol",{"className":"page__taxonomy-item","children":["#","Model Context Protocol"]}],["$","span","Multi-Hop Reasoning",{"className":"page__taxonomy-item","children":["#","Multi-Hop Reasoning"]}],["$","span","Multi-Threaded Execution",{"className":"page__taxonomy-item","children":["#","Multi-Threaded Execution"]}],["$","span","Evaluation Metrics",{"className":"page__taxonomy-item","children":["#","Evaluation Metrics"]}],["$","span","Similarity Alignment",{"className":"page__taxonomy-item","children":["#","Similarity Alignment"]}]]}]]}]]}],["$","article","2025-11-25-In-Video-Instructions-Visual-Signals-as-Generative-Control",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-25-In-Video-Instructions-Visual-Signals-as-Generative-Control/","children":"[논문리뷰] In-Video Instructions: Visual Signals as Generative Control"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'In-Video Instructions: Visual Signals as Generative Control' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-25 00:00:00+0900+0900","children":"2025년 11월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Controllable AI",{"className":"page__taxonomy-item","children":["#","Controllable AI"]}],["$","span","Visual Instructions",{"className":"page__taxonomy-item","children":["#","Visual Instructions"]}],["$","span","Image-to-Video",{"className":"page__taxonomy-item","children":["#","Image-to-Video"]}],["$","span","Spatial Control",{"className":"page__taxonomy-item","children":["#","Spatial Control"]}],["$","span","Zero-shot Learning",{"className":"page__taxonomy-item","children":["#","Zero-shot Learning"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}]]}]]}]]}],["$","article","2025-11-25-HunyuanVideo-1-5-Technical-Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-25-HunyuanVideo-1-5-Technical-Report/","children":"[논문리뷰] HunyuanVideo 1.5 Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Fang Yang이 [arXiv]에 게시한 'HunyuanVideo 1.5 Technical Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-25 00:00:00+0900+0900","children":"2025년 11월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Diffusion Transformer",{"className":"page__taxonomy-item","children":["#","Diffusion Transformer"]}],["$","span","Sparse Attention",{"className":"page__taxonomy-item","children":["#","Sparse Attention"]}],["$","span","Super-Resolution",{"className":"page__taxonomy-item","children":["#","Super-Resolution"]}],["$","span","Open-Source",{"className":"page__taxonomy-item","children":["#","Open-Source"]}],["$","span","Multimodal Understanding",{"className":"page__taxonomy-item","children":["#","Multimodal Understanding"]}],["$","span","Training Optimization",{"className":"page__taxonomy-item","children":["#","Training Optimization"]}],["$","span","Efficient Inference",{"className":"page__taxonomy-item","children":["#","Efficient Inference"]}]]}]]}]]}],["$","article","2025-11-25-General-Agentic-Memory-Via-Deep-Research",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-25-General-Agentic-Memory-Via-Deep-Research/","children":"[논문리뷰] General Agentic Memory Via Deep Research"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'General Agentic Memory Via Deep Research' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-25 00:00:00+0900+0900","children":"2025년 11월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Agents",{"className":"page__taxonomy-item","children":["#","AI Agents"]}],["$","span","Memory Systems",{"className":"page__taxonomy-item","children":["#","Memory Systems"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Just-in-Time (JIT) Compilation",{"className":"page__taxonomy-item","children":["#","Just-in-Time (JIT) Compilation"]}],["$","span","Memorizer",{"className":"page__taxonomy-item","children":["#","Memorizer"]}],["$","span","Researcher",{"className":"page__taxonomy-item","children":["#","Researcher"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Context Management",{"className":"page__taxonomy-item","children":["#","Context Management"]}]]}]]}]]}],["$","article","2025-11-25-Flow-Map-Distillation-Without-Data",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-25-Flow-Map-Distillation-Without-Data/","children":"[논문리뷰] Flow Map Distillation Without Data"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Tommi Jaakkola이 [arXiv]에 게시한 'Flow Map Distillation Without Data' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-25 00:00:00+0900+0900","children":"2025년 11월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Flow Map Distillation",{"className":"page__taxonomy-item","children":["#","Flow Map Distillation"]}],["$","span","Data-Free Learning",{"className":"page__taxonomy-item","children":["#","Data-Free Learning"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Teacher-Student",{"className":"page__taxonomy-item","children":["#","Teacher-Student"]}],["$","span","Diffusion Acceleration",{"className":"page__taxonomy-item","children":["#","Diffusion Acceleration"]}],["$","span","Teacher-Data Mismatch",{"className":"page__taxonomy-item","children":["#","Teacher-Data Mismatch"]}],["$","span","One-Step Sampling",{"className":"page__taxonomy-item","children":["#","One-Step Sampling"]}]]}]]}]]}],["$","article","2025-11-25-Fidelity-Aware-Recommendation-Explanations-via-Stochastic-Path-Integration",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-25-Fidelity-Aware-Recommendation-Explanations-via-Stochastic-Path-Integration/","children":"[논문리뷰] Fidelity-Aware Recommendation Explanations via Stochastic Path Integration"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Oren Barkan이 [arXiv]에 게시한 'Fidelity-Aware Recommendation Explanations via Stochastic Path Integration' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-25 00:00:00+0900+0900","children":"2025년 11월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Recommender Systems",{"className":"page__taxonomy-item","children":["#","Recommender Systems"]}],["$","span","Explainable AI (XAI)",{"className":"page__taxonomy-item","children":["#","Explainable AI (XAI)"]}],["$","span","Explanation Fidelity",{"className":"page__taxonomy-item","children":["#","Explanation Fidelity"]}],["$","span","Path Integration",{"className":"page__taxonomy-item","children":["#","Path Integration"]}],["$","span","Stochastic Sampling",{"className":"page__taxonomy-item","children":["#","Stochastic Sampling"]}],["$","span","Counterfactual Explanations",{"className":"page__taxonomy-item","children":["#","Counterfactual Explanations"]}],["$","span","Model-Agnostic",{"className":"page__taxonomy-item","children":["#","Model-Agnostic"]}],["$","span","Sparse Data",{"className":"page__taxonomy-item","children":["#","Sparse Data"]}]]}]]}]]}],["$","article","2025-11-25-Extracting-Interaction-Aware-Monosemantic-Concepts-in-Recommender-Systems",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-25-Extracting-Interaction-Aware-Monosemantic-Concepts-in-Recommender-Systems/","children":"[논문리뷰] Extracting Interaction-Aware Monosemantic Concepts in Recommender Systems"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Oren Barkan이 [arXiv]에 게시한 'Extracting Interaction-Aware Monosemantic Concepts in Recommender Systems' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-25 00:00:00+0900+0900","children":"2025년 11월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Recommender Systems",{"className":"page__taxonomy-item","children":["#","Recommender Systems"]}],["$","span","Sparse Autoencoder (SAE)",{"className":"page__taxonomy-item","children":["#","Sparse Autoencoder (SAE)"]}],["$","span","Monosemantic Neurons",{"className":"page__taxonomy-item","children":["#","Monosemantic Neurons"]}],["$","span","Interpretability",{"className":"page__taxonomy-item","children":["#","Interpretability"]}],["$","span","Prediction-Aware Loss",{"className":"page__taxonomy-item","children":["#","Prediction-Aware Loss"]}],["$","span","User-Item Interactions",{"className":"page__taxonomy-item","children":["#","User-Item Interactions"]}],["$","span","Post-hoc Control",{"className":"page__taxonomy-item","children":["#","Post-hoc Control"]}]]}]]}]]}],["$","article","2025-11-25-DeCo-Frequency-Decoupled-Pixel-Diffusion-for-End-to-End-Image-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-25-DeCo-Frequency-Decoupled-Pixel-Diffusion-for-End-to-End-Image-Generation/","children":"[논문리뷰] DeCo: Frequency-Decoupled Pixel Diffusion for End-to-End Image Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DeCo: Frequency-Decoupled Pixel Diffusion for End-to-End Image Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-25 00:00:00+0900+0900","children":"2025년 11월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Pixel Diffusion",{"className":"page__taxonomy-item","children":["#","Pixel Diffusion"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Frequency Decoupling",{"className":"page__taxonomy-item","children":["#","Frequency Decoupling"]}],["$","span","Diffusion Transformer (DiT)",{"className":"page__taxonomy-item","children":["#","Diffusion Transformer (DiT)"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","AdaLN",{"className":"page__taxonomy-item","children":["#","AdaLN"]}],["$","span","Text-to-Image Synthesis",{"className":"page__taxonomy-item","children":["#","Text-to-Image Synthesis"]}]]}]]}]]}],["$","article","2025-11-25-DR-Tulu-Reinforcement-Learning-with-Evolving-Rubrics-for-Deep-Research",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-25-DR-Tulu-Reinforcement-Learning-with-Evolving-Rubrics-for-Deep-Research/","children":"[논문리뷰] DR Tulu: Reinforcement Learning with Evolving Rubrics for Deep Research"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DR Tulu: Reinforcement Learning with Evolving Rubrics for Deep Research' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-25 00:00:00+0900+0900","children":"2025년 11월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Evolving Rubrics",{"className":"page__taxonomy-item","children":["#","Evolving Rubrics"]}],["$","span","Deep Research",{"className":"page__taxonomy-item","children":["#","Deep Research"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Long-form QA",{"className":"page__taxonomy-item","children":["#","Long-form QA"]}],["$","span","Open-source AI",{"className":"page__taxonomy-item","children":["#","Open-source AI"]}],["$","span","Dynamic Evaluation",{"className":"page__taxonomy-item","children":["#","Dynamic Evaluation"]}]]}]]}]]}],["$","article","2025-11-25-Controllable-Layer-Decomposition-for-Reversible-Multi-Layer-Image-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-25-Controllable-Layer-Decomposition-for-Reversible-Multi-Layer-Image-Generation/","children":"[논문리뷰] Controllable Layer Decomposition for Reversible Multi-Layer Image Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Controllable Layer Decomposition for Reversible Multi-Layer Image Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-25 00:00:00+0900+0900","children":"2025년 11월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Controllable Layer Decomposition",{"className":"page__taxonomy-item","children":["#","Controllable Layer Decomposition"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Multi-Layer Image Generation",{"className":"page__taxonomy-item","children":["#","Multi-Layer Image Generation"]}],["$","span","Layer Separation",{"className":"page__taxonomy-item","children":["#","Layer Separation"]}],["$","span","Bounding Box Guidance",{"className":"page__taxonomy-item","children":["#","Bounding Box Guidance"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}]]}]]}]]}],["$","article","2025-11-25-Computer-Use-Agents-as-Judges-for-Generative-User-Interface",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-25-Computer-Use-Agents-as-Judges-for-Generative-User-Interface/","children":"[논문리뷰] Computer-Use Agents as Judges for Generative User Interface"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Computer-Use Agents as Judges for Generative User Interface' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-25 00:00:00+0900+0900","children":"2025년 11월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Computer-Use Agents",{"className":"page__taxonomy-item","children":["#","Computer-Use Agents"]}],["$","span","Generative UI",{"className":"page__taxonomy-item","children":["#","Generative UI"]}],["$","span","AI-assisted Design",{"className":"page__taxonomy-item","children":["#","AI-assisted Design"]}],["$","span","Human-Computer Interaction",{"className":"page__taxonomy-item","children":["#","Human-Computer Interaction"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","AUI-Gym",{"className":"page__taxonomy-item","children":["#","AUI-Gym"]}],["$","span","Feedback Loop",{"className":"page__taxonomy-item","children":["#","Feedback Loop"]}],["$","span","Agent-centric Design",{"className":"page__taxonomy-item","children":["#","Agent-centric Design"]}]]}]]}]]}],["$","article","2025-11-25-Chain-of-Visual-Thought-Teaching-VLMs-to-See-and-Think-Better-with-Continuous-Visual-Tokens",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-25-Chain-of-Visual-Thought-Teaching-VLMs-to-See-and-Think-Better-with-Continuous-Visual-Tokens/","children":"[논문리뷰] Chain-of-Visual-Thought: Teaching VLMs to See and Think Better with Continuous Visual Tokens"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Stephanie Fu이 [arXiv]에 게시한 'Chain-of-Visual-Thought: Teaching VLMs to See and Think Better with Continuous Visual Tokens' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-25 00:00:00+0900+0900","children":"2025년 11월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision-Language Models (VLMs)"]}],["$","span","Chain-of-Thought (CoT)",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought (CoT)"]}],["$","span","Continuous Visual Tokens",{"className":"page__taxonomy-item","children":["#","Continuous Visual Tokens"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","span","Perceptual Grounding",{"className":"page__taxonomy-item","children":["#","Perceptual Grounding"]}],["$","span","Visual Thinking",{"className":"page__taxonomy-item","children":["#","Visual Thinking"]}],["$","span","Dense Prediction",{"className":"page__taxonomy-item","children":["#","Dense Prediction"]}]]}]]}]]}],["$","article","2025-11-25-Budget-Aware-Tool-Use-Enables-Effective-Agent-Scaling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-25-Budget-Aware-Tool-Use-Enables-Effective-Agent-Scaling/","children":"[논문리뷰] Budget-Aware Tool-Use Enables Effective Agent Scaling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Budget-Aware Tool-Use Enables Effective Agent Scaling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-25 00:00:00+0900+0900","children":"2025년 11월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Budget Awareness",{"className":"page__taxonomy-item","children":["#","Budget Awareness"]}],["$","span","Test-time Scaling",{"className":"page__taxonomy-item","children":["#","Test-time Scaling"]}],["$","span","Cost-Performance",{"className":"page__taxonomy-item","children":["#","Cost-Performance"]}],["$","span","Web Search Agents",{"className":"page__taxonomy-item","children":["#","Web Search Agents"]}],["$","span","Planning",{"className":"page__taxonomy-item","children":["#","Planning"]}],["$","span","Self-Verification",{"className":"page__taxonomy-item","children":["#","Self-Verification"]}]]}]]}]]}],["$","article","2025-11-25-AutoEnv-Automated-Environments-for-Measuring-Cross-Environment-Agent-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-25-AutoEnv-Automated-Environments-for-Measuring-Cross-Environment-Agent-Learning/","children":"[논문리뷰] AutoEnv: Automated Environments for Measuring Cross-Environment Agent Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Alphamasterliu이 [arXiv]에 게시한 'AutoEnv: Automated Environments for Measuring Cross-Environment Agent Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-25 00:00:00+0900+0900","children":"2025년 11월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Automated Environment Generation",{"className":"page__taxonomy-item","children":["#","Automated Environment Generation"]}],["$","span","Cross-Environment Learning",{"className":"page__taxonomy-item","children":["#","Cross-Environment Learning"]}],["$","span","Agent Learning",{"className":"page__taxonomy-item","children":["#","Agent Learning"]}],["$","span","Language Models",{"className":"page__taxonomy-item","children":["#","Language Models"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Meta-Learning",{"className":"page__taxonomy-item","children":["#","Meta-Learning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Environment Design Language",{"className":"page__taxonomy-item","children":["#","Environment Design Language"]}]]}]]}]]}],["$","article","2025-11-25-AICC-Parse-HTML-Finer-Make-Models-Better-A-7-3T-AI-Ready-Corpus-Built-by-a-Model-Based-HTML-Parser",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-25-AICC-Parse-HTML-Finer-Make-Models-Better-A-7-3T-AI-Ready-Corpus-Built-by-a-Model-Based-HTML-Parser/","children":"[논문리뷰] AICC: Parse HTML Finer, Make Models Better -- A 7.3T AI-Ready Corpus Built by a Model-Based HTML Parser"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'AICC: Parse HTML Finer, Make Models Better -- A 7.3T AI-Ready Corpus Built by a Model-Based HTML Parser' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-25 00:00:00+0900+0900","children":"2025년 11월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","HTML Extraction",{"className":"page__taxonomy-item","children":["#","HTML Extraction"]}],["$","span","Web Corpus",{"className":"page__taxonomy-item","children":["#","Web Corpus"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Structured Element Preservation",{"className":"page__taxonomy-item","children":["#","Structured Element Preservation"]}],["$","span","Sequence Labeling",{"className":"page__taxonomy-item","children":["#","Sequence Labeling"]}],["$","span","Markdown Conversion",{"className":"page__taxonomy-item","children":["#","Markdown Conversion"]}],["$","span","MainWebBench",{"className":"page__taxonomy-item","children":["#","MainWebBench"]}]]}]]}]]}],["$","article","2025-11-24-WorldGen-From-Text-to-Traversable-and-Interactive-3D-Worlds",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-24-WorldGen-From-Text-to-Traversable-and-Interactive-3D-Worlds/","children":"[논문리뷰] WorldGen: From Text to Traversable and Interactive 3D Worlds"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'WorldGen: From Text to Traversable and Interactive 3D Worlds' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-24 00:00:00+0900+0900","children":"2025년 11월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D World Generation",{"className":"page__taxonomy-item","children":["#","3D World Generation"]}],["$","span","Text-to-3D",{"className":"page__taxonomy-item","children":["#","Text-to-3D"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Procedural Generation",{"className":"page__taxonomy-item","children":["#","Procedural Generation"]}],["$","span","Scene Decomposition",{"className":"page__taxonomy-item","children":["#","Scene Decomposition"]}],["$","span","Navmesh",{"className":"page__taxonomy-item","children":["#","Navmesh"]}],["$","span","Game Engines",{"className":"page__taxonomy-item","children":["#","Game Engines"]}],["$","span","Interactive Environments",{"className":"page__taxonomy-item","children":["#","Interactive Environments"]}]]}]]}]]}],["$","article","2025-11-24-VisMem-Latent-Vision-Memory-Unlocks-Potential-of-Vision-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-24-VisMem-Latent-Vision-Memory-Unlocks-Potential-of-Vision-Language-Models/","children":"[논문리뷰] VisMem: Latent Vision Memory Unlocks Potential of Vision-Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yudong Zhang이 [arXiv]에 게시한 'VisMem: Latent Vision Memory Unlocks Potential of Vision-Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-24 00:00:00+0900+0900","children":"2025년 11월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Latent Memory",{"className":"page__taxonomy-item","children":["#","Latent Memory"]}],["$","span","Cognitive Memory",{"className":"page__taxonomy-item","children":["#","Cognitive Memory"]}],["$","span","Visual Grounding",{"className":"page__taxonomy-item","children":["#","Visual Grounding"]}],["$","span","Short-term Memory",{"className":"page__taxonomy-item","children":["#","Short-term Memory"]}],["$","span","Long-term Memory",{"className":"page__taxonomy-item","children":["#","Long-term Memory"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}]]}]]}]]}],["$","article","2025-11-24-Video-R4-Reinforcing-Text-Rich-Video-Reasoning-with-Visual-Rumination",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-24-Video-R4-Reinforcing-Text-Rich-Video-Reasoning-with-Visual-Rumination/","children":"[논문리뷰] Video-R4: Reinforcing Text-Rich Video Reasoning with Visual Rumination"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jing Bi이 [arXiv]에 게시한 'Video-R4: Reinforcing Text-Rich Video Reasoning with Visual Rumination' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-24 00:00:00+0900+0900","children":"2025년 11월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Reasoning",{"className":"page__taxonomy-item","children":["#","Video Reasoning"]}],["$","span","Large Multimodal Models",{"className":"page__taxonomy-item","children":["#","Large Multimodal Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Visual Rumination",{"className":"page__taxonomy-item","children":["#","Visual Rumination"]}],["$","span","Text-Rich Video",{"className":"page__taxonomy-item","children":["#","Text-Rich Video"]}],["$","span","Video Question Answering",{"className":"page__taxonomy-item","children":["#","Video Question Answering"]}],["$","span","Iterative Perception",{"className":"page__taxonomy-item","children":["#","Iterative Perception"]}]]}]]}]]}],["$","article","2025-11-24-VLA-4D-Embedding-4D-Awareness-into-Vision-Language-Action-Models-for-SpatioTemporally-Coherent-Robotic-Manipulation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-24-VLA-4D-Embedding-4D-Awareness-into-Vision-Language-Action-Models-for-SpatioTemporally-Coherent-Robotic-Manipulation/","children":"[논문리뷰] VLA-4D: Embedding 4D Awareness into Vision-Language-Action Models for SpatioTemporally Coherent Robotic Manipulation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Gim Hee Lee이 [arXiv]에 게시한 'VLA-4D: Embedding 4D Awareness into Vision-Language-Action Models for SpatioTemporally Coherent Robotic Manipulation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-24 00:00:00+0900+0900","children":"2025년 11월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action Models"]}],["$","span","Robotic Manipulation",{"className":"page__taxonomy-item","children":["#","Robotic Manipulation"]}],["$","span","SpatioTemporal Coherence",{"className":"page__taxonomy-item","children":["#","SpatioTemporal Coherence"]}],["$","span","4D Awareness",{"className":"page__taxonomy-item","children":["#","4D Awareness"]}],["$","span","Visual Representation",{"className":"page__taxonomy-item","children":["#","Visual Representation"]}],["$","span","Action Representation",{"className":"page__taxonomy-item","children":["#","Action Representation"]}],["$","span","Cross-Attention",{"className":"page__taxonomy-item","children":["#","Cross-Attention"]}]]}]]}]]}],["$","article","2025-11-24-Unveiling-Intrinsic-Dimension-of-Texts-from-Academic-Abstract-to-Creative-Story",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-24-Unveiling-Intrinsic-Dimension-of-Texts-from-Academic-Abstract-to-Creative-Story/","children":"[논문리뷰] Unveiling Intrinsic Dimension of Texts: from Academic Abstract to Creative Story"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kristian Kuznetsov이 [arXiv]에 게시한 'Unveiling Intrinsic Dimension of Texts: from Academic Abstract to Creative Story' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-24 00:00:00+0900+0900","children":"2025년 11월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Intrinsic Dimension",{"className":"page__taxonomy-item","children":["#","Intrinsic Dimension"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Text Complexity",{"className":"page__taxonomy-item","children":["#","Text Complexity"]}],["$","span","Sparse Autoencoders",{"className":"page__taxonomy-item","children":["#","Sparse Autoencoders"]}],["$","span","Text Semantics",{"className":"page__taxonomy-item","children":["#","Text Semantics"]}],["$","span","Genre Analysis",{"className":"page__taxonomy-item","children":["#","Genre Analysis"]}],["$","span","Embedding Space",{"className":"page__taxonomy-item","children":["#","Embedding Space"]}],["$","span","Text Generation",{"className":"page__taxonomy-item","children":["#","Text Generation"]}]]}]]}]]}],["$","article","2025-11-24-Taming-Generative-Synthetic-Data-for-X-ray-Prohibited-Item-Detection",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-24-Taming-Generative-Synthetic-Data-for-X-ray-Prohibited-Item-Detection/","children":"[논문리뷰] Taming Generative Synthetic Data for X-ray Prohibited Item Detection"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Renshuai Tao이 [arXiv]에 게시한 'Taming Generative Synthetic Data for X-ray Prohibited Item Detection' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-24 00:00:00+0900+0900","children":"2025년 11월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","X-ray Security",{"className":"page__taxonomy-item","children":["#","X-ray Security"]}],["$","span","Synthetic Data Generation",{"className":"page__taxonomy-item","children":["#","Synthetic Data Generation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Object Detection",{"className":"page__taxonomy-item","children":["#","Object Detection"]}],["$","span","Cross-Attention",{"className":"page__taxonomy-item","children":["#","Cross-Attention"]}],["$","span","Image Inpainting",{"className":"page__taxonomy-item","children":["#","Image Inpainting"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}]]}]]}]]}],["$","article","2025-11-24-SAM-3-Segment-Anything-with-Concepts",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-24-SAM-3-Segment-Anything-with-Concepts/","children":"[논문리뷰] SAM 3: Segment Anything with Concepts"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'SAM 3: Segment Anything with Concepts' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-24 00:00:00+0900+0900","children":"2025년 11월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Segment Anything Model",{"className":"page__taxonomy-item","children":["#","Segment Anything Model"]}],["$","span","Open-Vocabulary Segmentation",{"className":"page__taxonomy-item","children":["#","Open-Vocabulary Segmentation"]}],["$","span","Multimodal Foundation Model",{"className":"page__taxonomy-item","children":["#","Multimodal Foundation Model"]}],["$","span","Instance Segmentation",{"className":"page__taxonomy-item","children":["#","Instance Segmentation"]}],["$","span","Video Object Tracking",{"className":"page__taxonomy-item","children":["#","Video Object Tracking"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","Data Engine",{"className":"page__taxonomy-item","children":["#","Data Engine"]}],["$","span","Human-in-the-loop",{"className":"page__taxonomy-item","children":["#","Human-in-the-loop"]}]]}]]}]]}],["$","article","2025-11-24-RynnVLA-002-A-Unified-Vision-Language-Action-and-World-Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-24-RynnVLA-002-A-Unified-Vision-Language-Action-and-World-Model/","children":"[논문리뷰] RynnVLA-002: A Unified Vision-Language-Action and World Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'RynnVLA-002: A Unified Vision-Language-Action and World Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-24 00:00:00+0900+0900","children":"2025년 11월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action (VLA) Model",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action (VLA) Model"]}],["$","span","World Model",{"className":"page__taxonomy-item","children":["#","World Model"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Unified Framework",{"className":"page__taxonomy-item","children":["#","Unified Framework"]}],["$","span","Multi-modal Learning",{"className":"page__taxonomy-item","children":["#","Multi-modal Learning"]}],["$","span","Action Generation",{"className":"page__taxonomy-item","children":["#","Action Generation"]}],["$","span","Attention Mask",{"className":"page__taxonomy-item","children":["#","Attention Mask"]}],["$","span","Continuous Control",{"className":"page__taxonomy-item","children":["#","Continuous Control"]}]]}]]}]]}],["$","article","2025-11-24-Rethinking-Saliency-Maps-A-Cognitive-Human-Aligned-Taxonomy-and-Evaluation-Framework-for-Explanations",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-24-Rethinking-Saliency-Maps-A-Cognitive-Human-Aligned-Taxonomy-and-Evaluation-Framework-for-Explanations/","children":"[논문리뷰] Rethinking Saliency Maps: A Cognitive Human Aligned Taxonomy and Evaluation Framework for Explanations"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Noam Koenigstein이 [arXiv]에 게시한 'Rethinking Saliency Maps: A Cognitive Human Aligned Taxonomy and Evaluation Framework for Explanations' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-24 00:00:00+0900+0900","children":"2025년 11월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Saliency Maps",{"className":"page__taxonomy-item","children":["#","Saliency Maps"]}],["$","span","Explainable AI (XAI)",{"className":"page__taxonomy-item","children":["#","Explainable AI (XAI)"]}],["$","span","Taxonomy",{"className":"page__taxonomy-item","children":["#","Taxonomy"]}],["$","span","Evaluation Framework",{"className":"page__taxonomy-item","children":["#","Evaluation Framework"]}],["$","span","Faithfulness Metrics",{"className":"page__taxonomy-item","children":["#","Faithfulness Metrics"]}],["$","span","Contrastive Explanations",{"className":"page__taxonomy-item","children":["#","Contrastive Explanations"]}],["$","span","Granularity",{"className":"page__taxonomy-item","children":["#","Granularity"]}]]}]]}]]}],["$","article","2025-11-24-Planning-with-Sketch-Guided-Verification-for-Physics-Aware-Video-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-24-Planning-with-Sketch-Guided-Verification-for-Physics-Aware-Video-Generation/","children":"[논문리뷰] Planning with Sketch-Guided Verification for Physics-Aware Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shayegan Omidshafiei이 [arXiv]에 게시한 'Planning with Sketch-Guided Verification for Physics-Aware Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-24 00:00:00+0900+0900","children":"2025년 11월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Motion Planning",{"className":"page__taxonomy-item","children":["#","Motion Planning"]}],["$","span","Physics-Aware AI",{"className":"page__taxonomy-item","children":["#","Physics-Aware AI"]}],["$","span","Multimodal Verification",{"className":"page__taxonomy-item","children":["#","Multimodal Verification"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Test-Time Optimization",{"className":"page__taxonomy-item","children":["#","Test-Time Optimization"]}],["$","span","Sketch-Guided",{"className":"page__taxonomy-item","children":["#","Sketch-Guided"]}]]}]]}]]}],["$","article","2025-11-24-Parrot-Persuasion-and-Agreement-Robustness-Rating-of-Output-Truth-A-Sycophancy-Robustness-Benchmark-for-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-24-Parrot-Persuasion-and-Agreement-Robustness-Rating-of-Output-Truth-A-Sycophancy-Robustness-Benchmark-for-LLMs/","children":"[논문리뷰] Parrot: Persuasion and Agreement Robustness Rating of Output Truth -- A Sycophancy Robustness Benchmark for LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Parrot: Persuasion and Agreement Robustness Rating of Output Truth -- A Sycophancy Robustness Benchmark for LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-24 00:00:00+0900+0900","children":"2025년 11월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Sycophancy",{"className":"page__taxonomy-item","children":["#","LLM Sycophancy"]}],["$","span","Model Robustness",{"className":"page__taxonomy-item","children":["#","Model Robustness"]}],["$","span","AI Alignment",{"className":"page__taxonomy-item","children":["#","AI Alignment"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Confidence Calibration",{"className":"page__taxonomy-item","children":["#","Confidence Calibration"]}],["$","span","Behavioral Taxonomy",{"className":"page__taxonomy-item","children":["#","Behavioral Taxonomy"]}],["$","span","Social Influence",{"className":"page__taxonomy-item","children":["#","Social Influence"]}],["$","span","Epistemic Collapse",{"className":"page__taxonomy-item","children":["#","Epistemic Collapse"]}]]}]]}]]}],["$","article","2025-11-24-OpenMMReasoner-Pushing-the-Frontiers-for-Multimodal-Reasoning-with-an-Open-and-General-Recipe",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-24-OpenMMReasoner-Pushing-the-Frontiers-for-Multimodal-Reasoning-with-an-Open-and-General-Recipe/","children":"[논문리뷰] OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and General Recipe"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and General Recipe' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-24 00:00:00+0900+0900","children":"2025년 11월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","span","Large Multimodal Models",{"className":"page__taxonomy-item","children":["#","Large Multimodal Models"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Open-source",{"className":"page__taxonomy-item","children":["#","Open-source"]}],["$","span","Multimodal Benchmarks",{"className":"page__taxonomy-item","children":["#","Multimodal Benchmarks"]}]]}]]}]]}],["$","article","2025-11-24-OmniScientist-Toward-a-Co-evolving-Ecosystem-of-Human-and-AI-Scientists",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-24-OmniScientist-Toward-a-Co-evolving-Ecosystem-of-Human-and-AI-Scientists/","children":"[논문리뷰] OmniScientist: Toward a Co-evolving Ecosystem of Human and AI Scientists"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Weiquan Lin이 [arXiv]에 게시한 'OmniScientist: Toward a Co-evolving Ecosystem of Human and AI Scientists' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-24 00:00:00+0900+0900","children":"2025년 11월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Scientist",{"className":"page__taxonomy-item","children":["#","AI Scientist"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Human-AI Collaboration",{"className":"page__taxonomy-item","children":["#","Human-AI Collaboration"]}],["$","span","Scientific Ecosystem",{"className":"page__taxonomy-item","children":["#","Scientific Ecosystem"]}],["$","span","Research Automation",{"className":"page__taxonomy-item","children":["#","Research Automation"]}],["$","span","Omni Scientific Protocol (OSP)",{"className":"page__taxonomy-item","children":["#","Omni Scientific Protocol (OSP)"]}],["$","span","ScienceArena",{"className":"page__taxonomy-item","children":["#","ScienceArena"]}],["$","span","Knowledge Graph",{"className":"page__taxonomy-item","children":["#","Knowledge Graph"]}]]}]]}]]}],["$","article","2025-11-24-O-Mem-Omni-Memory-System-for-Personalized-Long-Horizon-Self-Evolving-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-24-O-Mem-Omni-Memory-System-for-Personalized-Long-Horizon-Self-Evolving-Agents/","children":"[논문리뷰] O-Mem: Omni Memory System for Personalized, Long Horizon, Self-Evolving Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'O-Mem: Omni Memory System for Personalized, Long Horizon, Self-Evolving Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-24 00:00:00+0900+0900","children":"2025년 11월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Memory System",{"className":"page__taxonomy-item","children":["#","Memory System"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Personalization",{"className":"page__taxonomy-item","children":["#","Personalization"]}],["$","span","User Profiling",{"className":"page__taxonomy-item","children":["#","User Profiling"]}],["$","span","Hierarchical Retrieval",{"className":"page__taxonomy-item","children":["#","Hierarchical Retrieval"]}],["$","span","Long-Term Interaction",{"className":"page__taxonomy-item","children":["#","Long-Term Interaction"]}],["$","span","Self-Evolving Agents",{"className":"page__taxonomy-item","children":["#","Self-Evolving Agents"]}],["$","span","Contextual Consistency",{"className":"page__taxonomy-item","children":["#","Contextual Consistency"]}]]}]]}]]}],["$","article","2025-11-24-Multi-Faceted-Attack-Exposing-Cross-Model-Vulnerabilities-in-Defense-Equipped-Vision-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-24-Multi-Faceted-Attack-Exposing-Cross-Model-Vulnerabilities-in-Defense-Equipped-Vision-Language-Models/","children":"[논문리뷰] Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-24 00:00:00+0900+0900","children":"2025년 11월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision-Language Models (VLMs)"]}],["$","span","Adversarial Attack",{"className":"page__taxonomy-item","children":["#","Adversarial Attack"]}],["$","span","Jailbreaking",{"className":"page__taxonomy-item","children":["#","Jailbreaking"]}],["$","span","Reward Hacking",{"className":"page__taxonomy-item","children":["#","Reward Hacking"]}],["$","span","Content Moderation Bypass",{"className":"page__taxonomy-item","children":["#","Content Moderation Bypass"]}],["$","span","Cross-Model Transferability",{"className":"page__taxonomy-item","children":["#","Cross-Model Transferability"]}],["$","span","Safety Vulnerabilities",{"className":"page__taxonomy-item","children":["#","Safety Vulnerabilities"]}]]}]]}]]}],["$","article","2025-11-24-MergeDNA-Context-aware-Genome-Modeling-with-Dynamic-Tokenization-through-Token-Merging",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-24-MergeDNA-Context-aware-Genome-Modeling-with-Dynamic-Tokenization-through-Token-Merging/","children":"[논문리뷰] MergeDNA: Context-aware Genome Modeling with Dynamic Tokenization through Token Merging"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'MergeDNA: Context-aware Genome Modeling with Dynamic Tokenization through Token Merging' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-24 00:00:00+0900+0900","children":"2025년 11월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Genome Modeling",{"className":"page__taxonomy-item","children":["#","Genome Modeling"]}],["$","span","Dynamic Tokenization",{"className":"page__taxonomy-item","children":["#","Dynamic Tokenization"]}],["$","span","Token Merging",{"className":"page__taxonomy-item","children":["#","Token Merging"]}],["$","span","Context-aware Learning",{"className":"page__taxonomy-item","children":["#","Context-aware Learning"]}],["$","span","DNA Foundation Models",{"className":"page__taxonomy-item","children":["#","DNA Foundation Models"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Multi-omics",{"className":"page__taxonomy-item","children":["#","Multi-omics"]}]]}]]}]]}],["$","article","2025-11-24-Mantis-A-Versatile-Vision-Language-Action-Model-with-Disentangled-Visual-Foresight",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-24-Mantis-A-Versatile-Vision-Language-Action-Model-with-Disentangled-Visual-Foresight/","children":"[논문리뷰] Mantis: A Versatile Vision-Language-Action Model with Disentangled Visual Foresight"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Mantis: A Versatile Vision-Language-Action Model with Disentangled Visual Foresight' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-24 00:00:00+0900+0900","children":"2025년 11월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action (VLA) Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action (VLA) Models"]}],["$","span","Visual Foresight",{"className":"page__taxonomy-item","children":["#","Visual Foresight"]}],["$","span","Diffusion Transformer (DiT)",{"className":"page__taxonomy-item","children":["#","Diffusion Transformer (DiT)"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Adaptive Temporal Ensemble",{"className":"page__taxonomy-item","children":["#","Adaptive Temporal Ensemble"]}],["$","span","Latent Actions",{"className":"page__taxonomy-item","children":["#","Latent Actions"]}]]}]]}]]}],["$","article","2025-11-24-Loomis-Painter-Reconstructing-the-Painting-Process",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-24-Loomis-Painter-Reconstructing-the-Painting-Process/","children":"[논문리뷰] Loomis Painter: Reconstructing the Painting Process"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Loomis Painter: Reconstructing the Painting Process' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-24 00:00:00+0900+0900","children":"2025년 11월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Painting Process Generation",{"className":"page__taxonomy-item","children":["#","Painting Process Generation"]}],["$","span","Video Diffusion Models",{"className":"page__taxonomy-item","children":["#","Video Diffusion Models"]}],["$","span","Media Transfer",{"className":"page__taxonomy-item","children":["#","Media Transfer"]}],["$","span","Reverse Painting",{"className":"page__taxonomy-item","children":["#","Reverse Painting"]}],["$","span","Dataset Curation",{"className":"page__taxonomy-item","children":["#","Dataset Curation"]}],["$","span","Perceptual Distance Profile",{"className":"page__taxonomy-item","children":["#","Perceptual Distance Profile"]}],["$","span","Artistic Workflow",{"className":"page__taxonomy-item","children":["#","Artistic Workflow"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}]]}]]}]]}],["$","article","2025-11-24-Insights-from-the-ICLR-Peer-Review-and-Rebuttal-Process",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-24-Insights-from-the-ICLR-Peer-Review-and-Rebuttal-Process/","children":"[논문리뷰] Insights from the ICLR Peer Review and Rebuttal Process"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Nedjma Ousidhoum이 [arXiv]에 게시한 'Insights from the ICLR Peer Review and Rebuttal Process' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-24 00:00:00+0900+0900","children":"2025년 11월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Peer Review",{"className":"page__taxonomy-item","children":["#","Peer Review"]}],["$","span","Rebuttal Process",{"className":"page__taxonomy-item","children":["#","Rebuttal Process"]}],["$","span","ICLR",{"className":"page__taxonomy-item","children":["#","ICLR"]}],["$","span","Score Dynamics",{"className":"page__taxonomy-item","children":["#","Score Dynamics"]}],["$","span","LLM Analysis",{"className":"page__taxonomy-item","children":["#","LLM Analysis"]}],["$","span","Reviewer Engagement",{"className":"page__taxonomy-item","children":["#","Reviewer Engagement"]}],["$","span","Academic Publishing",{"className":"page__taxonomy-item","children":["#","Academic Publishing"]}],["$","span","OpenReview",{"className":"page__taxonomy-item","children":["#","OpenReview"]}]]}]]}]]}],["$","article","2025-11-24-GeoVista-Web-Augmented-Agentic-Visual-Reasoning-for-Geolocalization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-24-GeoVista-Web-Augmented-Agentic-Visual-Reasoning-for-Geolocalization/","children":"[논문리뷰] GeoVista: Web-Augmented Agentic Visual Reasoning for Geolocalization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'GeoVista: Web-Augmented Agentic Visual Reasoning for Geolocalization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-24 00:00:00+0900+0900","children":"2025년 11월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Geolocalization",{"className":"page__taxonomy-item","children":["#","Geolocalization"]}],["$","span","Agentic Models",{"className":"page__taxonomy-item","children":["#","Agentic Models"]}],["$","span","Visual Reasoning",{"className":"page__taxonomy-item","children":["#","Visual Reasoning"]}],["$","span","Web-Augmented",{"className":"page__taxonomy-item","children":["#","Web-Augmented"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","GeoBench",{"className":"page__taxonomy-item","children":["#","GeoBench"]}]]}]]}]]}],["$","article","2025-11-24-Downscaling-Intelligence-Exploring-Perception-and-Reasoning-Bottlenecks-in-Small-Multimodal-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-24-Downscaling-Intelligence-Exploring-Perception-and-Reasoning-Bottlenecks-in-Small-Multimodal-Models/","children":"[논문리뷰] Downscaling Intelligence: Exploring Perception and Reasoning Bottlenecks in Small Multimodal Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Serena Yeung-Levy이 [arXiv]에 게시한 'Downscaling Intelligence: Exploring Perception and Reasoning Bottlenecks in Small Multimodal Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-24 00:00:00+0900+0900","children":"2025년 11월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Small Multimodal Models",{"className":"page__taxonomy-item","children":["#","Small Multimodal Models"]}],["$","span","LLM Downscaling",{"className":"page__taxonomy-item","children":["#","LLM Downscaling"]}],["$","span","Perception Bottleneck",{"className":"page__taxonomy-item","children":["#","Perception Bottleneck"]}],["$","span","Reasoning Bottleneck",{"className":"page__taxonomy-item","children":["#","Reasoning Bottleneck"]}],["$","span","Visual Extraction Tuning",{"className":"page__taxonomy-item","children":["#","Visual Extraction Tuning"]}],["$","span","Chain-of-Thought Reasoning",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought Reasoning"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}]]}]]}]]}],["$","article","2025-11-24-Diversity-Has-Always-Been-There-in-Your-Visual-Autoregressive-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-24-Diversity-Has-Always-Been-There-in-Your-Visual-Autoregressive-Models/","children":"[논문리뷰] Diversity Has Always Been There in Your Visual Autoregressive Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yaxing Wang이 [arXiv]에 게시한 'Diversity Has Always Been There in Your Visual Autoregressive Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-24 00:00:00+0900+0900","children":"2025년 11월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Visual Autoregressive Models",{"className":"page__taxonomy-item","children":["#","Visual Autoregressive Models"]}],["$","span","Diversity Collapse",{"className":"page__taxonomy-item","children":["#","Diversity Collapse"]}],["$","span","Generative Diversity",{"className":"page__taxonomy-item","children":["#","Generative Diversity"]}],["$","span","Soft-Suppression Regularization",{"className":"page__taxonomy-item","children":["#","Soft-Suppression Regularization"]}],["$","span","Soft-Amplification Regularization",{"className":"page__taxonomy-item","children":["#","Soft-Amplification Regularization"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Singular Value Decomposition",{"className":"page__taxonomy-item","children":["#","Singular Value Decomposition"]}]]}]]}]]}],["$","article","2025-11-21-Video-as-Answer-Predict-and-Generate-Next-Video-Event-with-Joint-GRPO",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-21-Video-as-Answer-Predict-and-Generate-Next-Video-Event-with-Joint-GRPO/","children":"[논문리뷰] Video-as-Answer: Predict and Generate Next Video Event with Joint-GRPO"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Video-as-Answer: Predict and Generate Next Video Event with Joint-GRPO' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-21 00:00:00+0900+0900","children":"2025년 11월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Next Event Prediction",{"className":"page__taxonomy-item","children":["#","Next Event Prediction"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Vision-Language Model",{"className":"page__taxonomy-item","children":["#","Vision-Language Model"]}],["$","span","Video Diffusion Model",{"className":"page__taxonomy-item","children":["#","Video Diffusion Model"]}],["$","span","Joint Optimization",{"className":"page__taxonomy-item","children":["#","Joint Optimization"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Procedural Learning",{"className":"page__taxonomy-item","children":["#","Procedural Learning"]}]]}]]}]]}],["$","article","2025-11-21-V-ReasonBench-Toward-Unified-Reasoning-Benchmark-Suite-for-Video-Generation-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-21-V-ReasonBench-Toward-Unified-Reasoning-Benchmark-Suite-for-Video-Generation-Models/","children":"[논문리뷰] V-ReasonBench: Toward Unified Reasoning Benchmark Suite for Video Generation Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Baijiong Lin이 [arXiv]에 게시한 'V-ReasonBench: Toward Unified Reasoning Benchmark Suite for Video Generation Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-21 00:00:00+0900+0900","children":"2025년 11월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Reasoning Benchmark",{"className":"page__taxonomy-item","children":["#","Reasoning Benchmark"]}],["$","span","Chain-of-Frame",{"className":"page__taxonomy-item","children":["#","Chain-of-Frame"]}],["$","span","Evaluation",{"className":"page__taxonomy-item","children":["#","Evaluation"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Physical Dynamics",{"className":"page__taxonomy-item","children":["#","Physical Dynamics"]}],["$","span","Spatial Cognition",{"className":"page__taxonomy-item","children":["#","Spatial Cognition"]}],["$","span","Pattern Inference",{"className":"page__taxonomy-item","children":["#","Pattern Inference"]}]]}]]}]]}],["$","article","2025-11-21-TurkColBERT-A-Benchmark-of-Dense-and-Late-Interaction-Models-for-Turkish-Information-Retrieval",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-21-TurkColBERT-A-Benchmark-of-Dense-and-Late-Interaction-Models-for-Turkish-Information-Retrieval/","children":"[논문리뷰] TurkColBERT: A Benchmark of Dense and Late-Interaction Models for Turkish Information Retrieval"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'TurkColBERT: A Benchmark of Dense and Late-Interaction Models for Turkish Information Retrieval' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-21 00:00:00+0900+0900","children":"2025년 11월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Information Retrieval",{"className":"page__taxonomy-item","children":["#","Information Retrieval"]}],["$","span","Turkish Language",{"className":"page__taxonomy-item","children":["#","Turkish Language"]}],["$","span","Late-Interaction Models",{"className":"page__taxonomy-item","children":["#","Late-Interaction Models"]}],["$","span","ColBERT",{"className":"page__taxonomy-item","children":["#","ColBERT"]}],["$","span","Dense Retrieval",{"className":"page__taxonomy-item","children":["#","Dense Retrieval"]}],["$","span","MUVERA",{"className":"page__taxonomy-item","children":["#","MUVERA"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Low-Resource NLP",{"className":"page__taxonomy-item","children":["#","Low-Resource NLP"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}]]}]]}]]}],["$","article","2025-11-21-TimeViper-A-Hybrid-Mamba-Transformer-Vision-Language-Model-for-Efficient-Long-Video-Understanding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-21-TimeViper-A-Hybrid-Mamba-Transformer-Vision-Language-Model-for-Efficient-Long-Video-Understanding/","children":"[논문리뷰] TimeViper: A Hybrid Mamba-Transformer Vision-Language Model for Efficient Long Video Understanding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'TimeViper: A Hybrid Mamba-Transformer Vision-Language Model for Efficient Long Video Understanding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-21 00:00:00+0900+0900","children":"2025년 11월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Long Video Understanding",{"className":"page__taxonomy-item","children":["#","Long Video Understanding"]}],["$","span","Hybrid Mamba-Transformer",{"className":"page__taxonomy-item","children":["#","Hybrid Mamba-Transformer"]}],["$","span","Vision-Language Model",{"className":"page__taxonomy-item","children":["#","Vision-Language Model"]}],["$","span","Token Compression",{"className":"page__taxonomy-item","children":["#","Token Compression"]}],["$","span","Vision-to-Text Aggregation",{"className":"page__taxonomy-item","children":["#","Vision-to-Text Aggregation"]}],["$","span","Efficient LLM",{"className":"page__taxonomy-item","children":["#","Efficient LLM"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}]]}]]}]]}],["$","article","2025-11-21-Thinking-while-Generating-Interleaving-Textual-Reasoning-throughout-Visual-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-21-Thinking-while-Generating-Interleaving-Textual-Reasoning-throughout-Visual-Generation/","children":"[논문리뷰] Thinking-while-Generating: Interleaving Textual Reasoning throughout Visual Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xinyan Chen이 [arXiv]에 게시한 'Thinking-while-Generating: Interleaving Textual Reasoning throughout Visual Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-21 00:00:00+0900+0900","children":"2025년 11월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Visual Generation",{"className":"page__taxonomy-item","children":["#","Visual Generation"]}],["$","span","Textual Reasoning",{"className":"page__taxonomy-item","children":["#","Textual Reasoning"]}],["$","span","Interleaving",{"className":"page__taxonomy-item","children":["#","Interleaving"]}],["$","span","Large Multimodal Models (LMMs)",{"className":"page__taxonomy-item","children":["#","Large Multimodal Models (LMMs)"]}],["$","span","Chain-of-Thought (CoT)",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought (CoT)"]}],["$","span","Zero-shot Learning",{"className":"page__taxonomy-item","children":["#","Zero-shot Learning"]}],["$","span","Supervised Fine-tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning (SFT)"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}]]}]]}]]}],["$","article","2025-11-21-Step-Audio-R1-Technical-Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-21-Step-Audio-R1-Technical-Report/","children":"[논문리뷰] Step-Audio-R1 Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Step-Audio-R1 Technical Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-21 00:00:00+0900+0900","children":"2025년 11월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Audio Reasoning",{"className":"page__taxonomy-item","children":["#","Audio Reasoning"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Modality-Grounded Reasoning Distillation (MGRD)",{"className":"page__taxonomy-item","children":["#","Modality-Grounded Reasoning Distillation (MGRD)"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Audio Understanding",{"className":"page__taxonomy-item","children":["#","Audio Understanding"]}],["$","span","Self-Distillation",{"className":"page__taxonomy-item","children":["#","Self-Distillation"]}]]}]]}]]}],["$","article","2025-11-21-Scaling-Spatial-Intelligence-with-Multimodal-Foundation-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-21-Scaling-Spatial-Intelligence-with-Multimodal-Foundation-Models/","children":"[논문리뷰] Scaling Spatial Intelligence with Multimodal Foundation Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Scaling Spatial Intelligence with Multimodal Foundation Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-21 00:00:00+0900+0900","children":"2025년 11월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Spatial Intelligence",{"className":"page__taxonomy-item","children":["#","Spatial Intelligence"]}],["$","span","Multimodal Foundation Models",{"className":"page__taxonomy-item","children":["#","Multimodal Foundation Models"]}],["$","span","Data Scaling",{"className":"page__taxonomy-item","children":["#","Data Scaling"]}],["$","span","Perspective-taking",{"className":"page__taxonomy-item","children":["#","Perspective-taking"]}],["$","span","Visual Question Answering",{"className":"page__taxonomy-item","children":["#","Visual Question Answering"]}],["$","span","Emergent Capabilities",{"className":"page__taxonomy-item","children":["#","Emergent Capabilities"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Benchmark Evaluation",{"className":"page__taxonomy-item","children":["#","Benchmark Evaluation"]}]]}]]}]]}],["$","article","2025-11-21-SRPO-Self-Referential-Policy-Optimization-for-Vision-Language-Action-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-21-SRPO-Self-Referential-Policy-Optimization-for-Vision-Language-Action-Models/","children":"[논문리뷰] SRPO: Self-Referential Policy Optimization for Vision-Language-Action Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'SRPO: Self-Referential Policy Optimization for Vision-Language-Action Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-21 00:00:00+0900+0900","children":"2025년 11월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Vision-Language-Action Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action Models"]}],["$","span","Reward Shaping",{"className":"page__taxonomy-item","children":["#","Reward Shaping"]}],["$","span","World Models",{"className":"page__taxonomy-item","children":["#","World Models"]}],["$","span","Self-Referential Learning",{"className":"page__taxonomy-item","children":["#","Self-Referential Learning"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Trajectory Optimization",{"className":"page__taxonomy-item","children":["#","Trajectory Optimization"]}]]}]]}]]}],["$","article","2025-11-21-SAM2S-Segment-Anything-in-Surgical-Videos-via-Semantic-Long-term-Tracking",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-21-SAM2S-Segment-Anything-in-Surgical-Videos-via-Semantic-Long-term-Tracking/","children":"[논문리뷰] SAM2S: Segment Anything in Surgical Videos via Semantic Long-term Tracking"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'SAM2S: Segment Anything in Surgical Videos via Semantic Long-term Tracking' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-21 00:00:00+0900+0900","children":"2025년 11월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Surgical Video Segmentation",{"className":"page__taxonomy-item","children":["#","Surgical Video Segmentation"]}],["$","span","Interactive Video Object Segmentation",{"className":"page__taxonomy-item","children":["#","Interactive Video Object Segmentation"]}],["$","span","Long-term Tracking",{"className":"page__taxonomy-item","children":["#","Long-term Tracking"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Domain Adaptation",{"className":"page__taxonomy-item","children":["#","Domain Adaptation"]}],["$","span","Semantic Learning",{"className":"page__taxonomy-item","children":["#","Semantic Learning"]}],["$","span","Prompt-based Segmentation",{"className":"page__taxonomy-item","children":["#","Prompt-based Segmentation"]}]]}]]}]]}],["$","article","2025-11-21-SAM-3D-3Dfy-Anything-in-Images",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-21-SAM-3D-3Dfy-Anything-in-Images/","children":"[논문리뷰] SAM 3D: 3Dfy Anything in Images"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'SAM 3D: 3Dfy Anything in Images' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-21 00:00:00+0900+0900","children":"2025년 11월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Reconstruction",{"className":"page__taxonomy-item","children":["#","3D Reconstruction"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Single Image 3D",{"className":"page__taxonomy-item","children":["#","Single Image 3D"]}],["$","span","Object Reconstruction",{"className":"page__taxonomy-item","children":["#","Object Reconstruction"]}],["$","span","Scene Understanding",{"className":"page__taxonomy-item","children":["#","Scene Understanding"]}],["$","span","Data Engine",{"className":"page__taxonomy-item","children":["#","Data Engine"]}],["$","span","Model-in-the-Loop",{"className":"page__taxonomy-item","children":["#","Model-in-the-Loop"]}],["$","span","Human Preference",{"className":"page__taxonomy-item","children":["#","Human Preference"]}]]}]]}]]}],["$","article","2025-11-21-PartUV-Part-Based-UV-Unwrapping-of-3D-Meshes",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-21-PartUV-Part-Based-UV-Unwrapping-of-3D-Meshes/","children":"[논문리뷰] PartUV: Part-Based UV Unwrapping of 3D Meshes"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hao Su이 [arXiv]에 게시한 'PartUV: Part-Based UV Unwrapping of 3D Meshes' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-21 00:00:00+0900+0900","children":"2025년 11월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","UV Unwrapping",{"className":"page__taxonomy-item","children":["#","UV Unwrapping"]}],["$","span","3D Meshes",{"className":"page__taxonomy-item","children":["#","3D Meshes"]}],["$","span","Part-Based Decomposition",{"className":"page__taxonomy-item","children":["#","Part-Based Decomposition"]}],["$","span","Neural Fields",{"className":"page__taxonomy-item","children":["#","Neural Fields"]}],["$","span","Geometric Heuristics",{"className":"page__taxonomy-item","children":["#","Geometric Heuristics"]}],["$","span","Parameterization",{"className":"page__taxonomy-item","children":["#","Parameterization"]}],["$","span","Texture Mapping",{"className":"page__taxonomy-item","children":["#","Texture Mapping"]}]]}]]}]]}],["$","article","2025-11-21-Nemotron-Elastic-Towards-Efficient-Many-in-One-Reasoning-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-21-Nemotron-Elastic-Towards-Efficient-Many-in-One-Reasoning-LLMs/","children":"[논문리뷰] Nemotron Elastic: Towards Efficient Many-in-One Reasoning LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Nemotron Elastic: Towards Efficient Many-in-One Reasoning LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-21 00:00:00+0900+0900","children":"2025년 11월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Compression",{"className":"page__taxonomy-item","children":["#","LLM Compression"]}],["$","span","Elastic Networks",{"className":"page__taxonomy-item","children":["#","Elastic Networks"]}],["$","span","Knowledge Distillation",{"className":"page__taxonomy-item","children":["#","Knowledge Distillation"]}],["$","span","Hybrid Mamba-Attention",{"className":"page__taxonomy-item","children":["#","Hybrid Mamba-Attention"]}],["$","span","Reasoning LLMs",{"className":"page__taxonomy-item","children":["#","Reasoning LLMs"]}],["$","span","Multi-Budget Training",{"className":"page__taxonomy-item","children":["#","Multi-Budget Training"]}],["$","span","Zero-Shot Deployment",{"className":"page__taxonomy-item","children":["#","Zero-Shot Deployment"]}]]}]]}]]}],["$","article","2025-11-21-NaTex-Seamless-Texture-Generation-as-Latent-Color-Diffusion",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-21-NaTex-Seamless-Texture-Generation-as-Latent-Color-Diffusion/","children":"[논문리뷰] NaTex: Seamless Texture Generation as Latent Color Diffusion"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'NaTex: Seamless Texture Generation as Latent Color Diffusion' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-21 00:00:00+0900+0900","children":"2025년 11월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Texture Generation",{"className":"page__taxonomy-item","children":["#","3D Texture Generation"]}],["$","span","Latent Diffusion Model",{"className":"page__taxonomy-item","children":["#","Latent Diffusion Model"]}],["$","span","Geometry-Aware VAE",{"className":"page__taxonomy-item","children":["#","Geometry-Aware VAE"]}],["$","span","Multi-Control DiT",{"className":"page__taxonomy-item","children":["#","Multi-Control DiT"]}],["$","span","Color Point Cloud",{"className":"page__taxonomy-item","children":["#","Color Point Cloud"]}],["$","span","Texture Synthesis",{"className":"page__taxonomy-item","children":["#","Texture Synthesis"]}],["$","span","3D Asset Creation",{"className":"page__taxonomy-item","children":["#","3D Asset Creation"]}]]}]]}]]}],["$","article","2025-11-21-MiMo-Embodied-X-Embodied-Foundation-Model-Technical-Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-21-MiMo-Embodied-X-Embodied-Foundation-Model-Technical-Report/","children":"[논문리뷰] MiMo-Embodied: X-Embodied Foundation Model Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'MiMo-Embodied: X-Embodied Foundation Model Technical Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-21 00:00:00+0900+0900","children":"2025년 11월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Model (VLM)",{"className":"page__taxonomy-item","children":["#","Vision-Language Model (VLM)"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Autonomous Driving",{"className":"page__taxonomy-item","children":["#","Autonomous Driving"]}],["$","span","Foundation Model",{"className":"page__taxonomy-item","children":["#","Foundation Model"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Task Planning",{"className":"page__taxonomy-item","children":["#","Task Planning"]}],["$","span","Affordance Prediction",{"className":"page__taxonomy-item","children":["#","Affordance Prediction"]}],["$","span","Spatial Understanding",{"className":"page__taxonomy-item","children":["#","Spatial Understanding"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}]]}]]}]]}],["$","article","2025-11-21-First-Frame-Is-the-Place-to-Go-for-Video-Content-Customization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-21-First-Frame-Is-the-Place-to-Go-for-Video-Content-Customization/","children":"[논문리뷰] First Frame Is the Place to Go for Video Content Customization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'First Frame Is the Place to Go for Video Content Customization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-21 00:00:00+0900+0900","children":"2025년 11월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Content Customization",{"className":"page__taxonomy-item","children":["#","Content Customization"]}],["$","span","Few-shot Learning",{"className":"page__taxonomy-item","children":["#","Few-shot Learning"]}],["$","span","LoRA",{"className":"page__taxonomy-item","children":["#","LoRA"]}],["$","span","Vision-Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision-Language Models (VLMs)"]}],["$","span","First Frame Conditioning",{"className":"page__taxonomy-item","children":["#","First Frame Conditioning"]}],["$","span","Reference-based Generation",{"className":"page__taxonomy-item","children":["#","Reference-based Generation"]}]]}]]}]]}],["$","article","2025-11-21-Draft-and-Refine-with-Visual-Experts",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-21-Draft-and-Refine-with-Visual-Experts/","children":"[논문리뷰] Draft and Refine with Visual Experts"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Draft and Refine with Visual Experts' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-21 00:00:00+0900+0900","children":"2025년 11월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Vision-Language Models (LVLMs)",{"className":"page__taxonomy-item","children":["#","Large Vision-Language Models (LVLMs)"]}],["$","span","Visual Grounding",{"className":"page__taxonomy-item","children":["#","Visual Grounding"]}],["$","span","Hallucination Mitigation",{"className":"page__taxonomy-item","children":["#","Hallucination Mitigation"]}],["$","span","Agent Framework",{"className":"page__taxonomy-item","children":["#","Agent Framework"]}],["$","span","Visual Question Answering (VQA)",{"className":"page__taxonomy-item","children":["#","Visual Question Answering (VQA)"]}],["$","span","Expert Coordination",{"className":"page__taxonomy-item","children":["#","Expert Coordination"]}],["$","span","Relevance Map",{"className":"page__taxonomy-item","children":["#","Relevance Map"]}],["$","span","Multi-modal Reasoning",{"className":"page__taxonomy-item","children":["#","Multi-modal Reasoning"]}]]}]]}]]}],["$","article","2025-11-20-What-Does-It-Take-to-Be-a-Good-AI-Research-Agent-Studying-the-Role-of-Ideation-Diversity",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-20-What-Does-It-Take-to-Be-a-Good-AI-Research-Agent-Studying-the-Role-of-Ideation-Diversity/","children":"[논문리뷰] What Does It Take to Be a Good AI Research Agent? Studying the Role of Ideation Diversity"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'What Does It Take to Be a Good AI Research Agent? Studying the Role of Ideation Diversity' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-20 00:00:00+0900+0900","children":"2025년 11월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Research Agents",{"className":"page__taxonomy-item","children":["#","AI Research Agents"]}],["$","span","Ideation Diversity",{"className":"page__taxonomy-item","children":["#","Ideation Diversity"]}],["$","span","MLE-bench",{"className":"page__taxonomy-item","children":["#","MLE-bench"]}],["$","span","LLM Backbones",{"className":"page__taxonomy-item","children":["#","LLM Backbones"]}],["$","span","Agentic Scaffolds",{"className":"page__taxonomy-item","children":["#","Agentic Scaffolds"]}],["$","span","Shannon Entropy",{"className":"page__taxonomy-item","children":["#","Shannon Entropy"]}],["$","span","Machine Learning Engineering",{"className":"page__taxonomy-item","children":["#","Machine Learning Engineering"]}],["$","span","Performance Metrics",{"className":"page__taxonomy-item","children":["#","Performance Metrics"]}]]}]]}]]}],["$","article","2025-11-20-VisPlay-Self-Evolving-Vision-Language-Models-from-Images",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-20-VisPlay-Self-Evolving-Vision-Language-Models-from-Images/","children":"[논문리뷰] VisPlay: Self-Evolving Vision-Language Models from Images"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'VisPlay: Self-Evolving Vision-Language Models from Images' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-20 00:00:00+0900+0900","children":"2025년 11월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Self-Evolving",{"className":"page__taxonomy-item","children":["#","Self-Evolving"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Self-Play",{"className":"page__taxonomy-item","children":["#","Self-Play"]}],["$","span","Unlabeled Data",{"className":"page__taxonomy-item","children":["#","Unlabeled Data"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","span","Group Relative Policy Optimization",{"className":"page__taxonomy-item","children":["#","Group Relative Policy Optimization"]}],["$","span","Hallucination Mitigation",{"className":"page__taxonomy-item","children":["#","Hallucination Mitigation"]}]]}]]}]]}],["$","article","2025-11-20-Reasoning-via-Video-The-First-Evaluation-of-Video-Models-Reasoning-Abilities-through-Maze-Solving-Tasks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-20-Reasoning-via-Video-The-First-Evaluation-of-Video-Models-Reasoning-Abilities-through-Maze-Solving-Tasks/","children":"[논문리뷰] Reasoning via Video: The First Evaluation of Video Models' Reasoning Abilities through Maze-Solving Tasks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yiran Peng이 [arXiv]에 게시한 'Reasoning via Video: The First Evaluation of Video Models' Reasoning Abilities through Maze-Solving Tasks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-20 00:00:00+0900+0900","children":"2025년 11월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Models",{"className":"page__taxonomy-item","children":["#","Video Models"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}],["$","span","Maze Solving",{"className":"page__taxonomy-item","children":["#","Maze Solving"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Test-Time Scaling",{"className":"page__taxonomy-item","children":["#","Test-Time Scaling"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}]]}]]}]]}],["$","article","2025-11-20-Mixture-of-States-Routing-Token-Level-Dynamics-for-Multimodal-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-20-Mixture-of-States-Routing-Token-Level-Dynamics-for-Multimodal-Generation/","children":"[논문리뷰] Mixture of States: Routing Token-Level Dynamics for Multimodal Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Mixture of States: Routing Token-Level Dynamics for Multimodal Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-20 00:00:00+0900+0900","children":"2025년 11월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Diffusion",{"className":"page__taxonomy-item","children":["#","Multimodal Diffusion"]}],["$","span","Mixture of States (MoS)",{"className":"page__taxonomy-item","children":["#","Mixture of States (MoS)"]}],["$","span","Token-Level Routing",{"className":"page__taxonomy-item","children":["#","Token-Level Routing"]}],["$","span","Dynamic Conditional Fusion",{"className":"page__taxonomy-item","children":["#","Dynamic Conditional Fusion"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}]]}]]}]]}],["$","article","2025-11-20-Medal-S-Spatio-Textual-Prompt-Model-for-Medical-Segmentation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-20-Medal-S-Spatio-Textual-Prompt-Model-for-Medical-Segmentation/","children":"[논문리뷰] Medal S: Spatio-Textual Prompt Model for Medical Segmentation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Tao Chen이 [arXiv]에 게시한 'Medal S: Spatio-Textual Prompt Model for Medical Segmentation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-20 00:00:00+0900+0900","children":"2025년 11월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Medical Segmentation",{"className":"page__taxonomy-item","children":["#","Medical Segmentation"]}],["$","span","Foundation Model",{"className":"page__taxonomy-item","children":["#","Foundation Model"]}],["$","span","Spatio-Textual Prompts",{"className":"page__taxonomy-item","children":["#","Spatio-Textual Prompts"]}],["$","span","3D Convolution",{"className":"page__taxonomy-item","children":["#","3D Convolution"]}],["$","span","Multi-modal Imaging",{"className":"page__taxonomy-item","children":["#","Multi-modal Imaging"]}],["$","span","Dynamic Resampling",{"className":"page__taxonomy-item","children":["#","Dynamic Resampling"]}],["$","span","Parallel Inference",{"className":"page__taxonomy-item","children":["#","Parallel Inference"]}],["$","span","Iterative Refinement",{"className":"page__taxonomy-item","children":["#","Iterative Refinement"]}]]}]]}]]}],["$","article","2025-11-20-MHR-Momentum-Human-Rig",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-20-MHR-Momentum-Human-Rig/","children":"[논문리뷰] MHR: Momentum Human Rig"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chris Twigg이 [arXiv]에 게시한 'MHR: Momentum Human Rig' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-20 00:00:00+0900+0900","children":"2025년 11월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Parametric Body Model",{"className":"page__taxonomy-item","children":["#","Parametric Body Model"]}],["$","span","Human Animation",{"className":"page__taxonomy-item","children":["#","Human Animation"]}],["$","span","Character Rigging",{"className":"page__taxonomy-item","children":["#","Character Rigging"]}],["$","span","Pose Correctives",{"className":"page__taxonomy-item","children":["#","Pose Correctives"]}],["$","span","Skeletal Decoupling",{"className":"page__taxonomy-item","children":["#","Skeletal Decoupling"]}],["$","span","Computer Graphics",{"className":"page__taxonomy-item","children":["#","Computer Graphics"]}],["$","span","AR/VR",{"className":"page__taxonomy-item","children":["#","AR/VR"]}]]}]]}]]}],["$","article","2025-11-20-Kandinsky-5-0-A-Family-of-Foundation-Models-for-Image-and-Video-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-20-Kandinsky-5-0-A-Family-of-Foundation-Models-for-Image-and-Video-Generation/","children":"[논문리뷰] Kandinsky 5.0: A Family of Foundation Models for Image and Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Vladimir Arkhipkin이 [arXiv]에 게시한 'Kandinsky 5.0: A Family of Foundation Models for Image and Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-20 00:00:00+0900+0900","children":"2025년 11월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Diffusion Transformer",{"className":"page__taxonomy-item","children":["#","Diffusion Transformer"]}],["$","span","NABLA",{"className":"page__taxonomy-item","children":["#","NABLA"]}],["$","span","RLHF",{"className":"page__taxonomy-item","children":["#","RLHF"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}]]}]]}]]}],["$","article","2025-11-20-Instruction-Guided-Lesion-Segmentation-for-Chest-X-rays-with-Automatically-Generated-Large-Scale-Dataset",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-20-Instruction-Guided-Lesion-Segmentation-for-Chest-X-rays-with-Automatically-Generated-Large-Scale-Dataset/","children":"[논문리뷰] Instruction-Guided Lesion Segmentation for Chest X-rays with Automatically Generated Large-Scale Dataset"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Instruction-Guided Lesion Segmentation for Chest X-rays with Automatically Generated Large-Scale Dataset' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-20 00:00:00+0900+0900","children":"2025년 11월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Medical Imaging",{"className":"page__taxonomy-item","children":["#","Medical Imaging"]}],["$","span","Chest X-ray",{"className":"page__taxonomy-item","children":["#","Chest X-ray"]}],["$","span","Lesion Segmentation",{"className":"page__taxonomy-item","children":["#","Lesion Segmentation"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}],["$","span","Data Generation",{"className":"page__taxonomy-item","children":["#","Data Generation"]}],["$","span","MIMIC-CXR",{"className":"page__taxonomy-item","children":["#","MIMIC-CXR"]}]]}]]}]]}],["$","article","2025-11-20-FreeAskWorld-An-Interactive-and-Closed-Loop-Simulator-for-Human-Centric-Embodied-AI",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-20-FreeAskWorld-An-Interactive-and-Closed-Loop-Simulator-for-Human-Centric-Embodied-AI/","children":"[논문리뷰] FreeAskWorld: An Interactive and Closed-Loop Simulator for Human-Centric Embodied AI"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xinyu Yin이 [arXiv]에 게시한 'FreeAskWorld: An Interactive and Closed-Loop Simulator for Human-Centric Embodied AI' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-20 00:00:00+0900+0900","children":"2025년 11월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Vision-and-Language Navigation (VLN)",{"className":"page__taxonomy-item","children":["#","Vision-and-Language Navigation (VLN)"]}],["$","span","LLM-driven Simulation",{"className":"page__taxonomy-item","children":["#","LLM-driven Simulation"]}],["$","span","Human-Agent Interaction",{"className":"page__taxonomy-item","children":["#","Human-Agent Interaction"]}],["$","span","Closed-Loop",{"className":"page__taxonomy-item","children":["#","Closed-Loop"]}],["$","span","Benchmark Dataset",{"className":"page__taxonomy-item","children":["#","Benchmark Dataset"]}],["$","span","Social Cognition",{"className":"page__taxonomy-item","children":["#","Social Cognition"]}]]}]]}]]}],["$","article","2025-11-20-Aligning-Generative-Music-AI-with-Human-Preferences-Methods-and-Challenges",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-20-Aligning-Generative-Music-AI-with-Human-Preferences-Methods-and-Challenges/","children":"[논문리뷰] Aligning Generative Music AI with Human Preferences: Methods and Challenges"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Abhinaba Roy이 [arXiv]에 게시한 'Aligning Generative Music AI with Human Preferences: Methods and Challenges' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-20 00:00:00+0900+0900","children":"2025년 11월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Generative Music AI",{"className":"page__taxonomy-item","children":["#","Generative Music AI"]}],["$","span","Preference Alignment",{"className":"page__taxonomy-item","children":["#","Preference Alignment"]}],["$","span","Reinforcement Learning from Human Feedback (RLHF)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning from Human Feedback (RLHF)"]}],["$","span","Direct Preference Optimization (DPO)",{"className":"page__taxonomy-item","children":["#","Direct Preference Optimization (DPO)"]}],["$","span","Inference-Time Optimization",{"className":"page__taxonomy-item","children":["#","Inference-Time Optimization"]}],["$","span","Music Generation",{"className":"page__taxonomy-item","children":["#","Music Generation"]}],["$","span","Human-Computer Interaction",{"className":"page__taxonomy-item","children":["#","Human-Computer Interaction"]}]]}]]}]]}],["$","article","2025-11-20-ARC-Chapter-Structuring-Hour-Long-Videos-into-Navigable-Chapters-and-Hierarchical-Summaries",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-20-ARC-Chapter-Structuring-Hour-Long-Videos-into-Navigable-Chapters-and-Hierarchical-Summaries/","children":"[논문리뷰] ARC-Chapter: Structuring Hour-Long Videos into Navigable Chapters and Hierarchical Summaries"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'ARC-Chapter: Structuring Hour-Long Videos into Navigable Chapters and Hierarchical Summaries' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-20 00:00:00+0900+0900","children":"2025년 11월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Chaptering",{"className":"page__taxonomy-item","children":["#","Video Chaptering"]}],["$","span","Long-form Video Understanding",{"className":"page__taxonomy-item","children":["#","Long-form Video Understanding"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Hierarchical Summarization",{"className":"page__taxonomy-item","children":["#","Hierarchical Summarization"]}],["$","span","Video Segmentation",{"className":"page__taxonomy-item","children":["#","Video Segmentation"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Dataset Creation",{"className":"page__taxonomy-item","children":["#","Dataset Creation"]}]]}]]}]]}],["$","article","2025-11-19-eat-Physically-Grounded-Feature-Representation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-19-eat-Physically-Grounded-Feature-Representation/","children":"[논문리뷰] Φeat: Physically-Grounded Feature Representation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Φeat: Physically-Grounded Feature Representation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-19 00:00:00+0900+0900","children":"2025년 11월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Self-supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-supervised Learning"]}],["$","span","Physically-Grounded Features",{"className":"page__taxonomy-item","children":["#","Physically-Grounded Features"]}],["$","span","Material Representation",{"className":"page__taxonomy-item","children":["#","Material Representation"]}],["$","span","Intrinsic Scene Understanding",{"className":"page__taxonomy-item","children":["#","Intrinsic Scene Understanding"]}],["$","span","Vision Transformer",{"className":"page__taxonomy-item","children":["#","Vision Transformer"]}],["$","span","Synthetic Data",{"className":"page__taxonomy-item","children":["#","Synthetic Data"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}]]}]]}]]}],["$","article","2025-11-19-VIDEOP2R-Video-Understanding-from-Perception-to-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-19-VIDEOP2R-Video-Understanding-from-Perception-to-Reasoning/","children":"[논문리뷰] VIDEOP2R: Video Understanding from Perception to Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'VIDEOP2R: Video Understanding from Perception to Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-19 00:00:00+0900+0900","children":"2025년 11월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Understanding",{"className":"page__taxonomy-item","children":["#","Video Understanding"]}],["$","span","Reinforcement Fine-Tuning (RFT)",{"className":"page__taxonomy-item","children":["#","Reinforcement Fine-Tuning (RFT)"]}],["$","span","Large Video Language Models (LVLMs)",{"className":"page__taxonomy-item","children":["#","Large Video Language Models (LVLMs)"]}],["$","span","Perception and Reasoning",{"className":"page__taxonomy-item","children":["#","Perception and Reasoning"]}],["$","span","Chain-of-Thought (CoT)",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought (CoT)"]}],["$","span","Process-Aware Learning",{"className":"page__taxonomy-item","children":["#","Process-Aware Learning"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Credit Assignment",{"className":"page__taxonomy-item","children":["#","Credit Assignment"]}]]}]]}]]}],["$","article","2025-11-19-TopoPerception-A-Shortcut-Free-Evaluation-of-Global-Visual-Perception-in-Large-Vision-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-19-TopoPerception-A-Shortcut-Free-Evaluation-of-Global-Visual-Perception-in-Large-Vision-Language-Models/","children":"[논문리뷰] TopoPerception: A Shortcut-Free Evaluation of Global Visual Perception in Large Vision-Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Rong Zhao이 [arXiv]에 게시한 'TopoPerception: A Shortcut-Free Evaluation of Global Visual Perception in Large Vision-Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-19 00:00:00+0900+0900","children":"2025년 11월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LVLM Evaluation",{"className":"page__taxonomy-item","children":["#","LVLM Evaluation"]}],["$","span","Global Visual Perception",{"className":"page__taxonomy-item","children":["#","Global Visual Perception"]}],["$","span","Topological Properties",{"className":"page__taxonomy-item","children":["#","Topological Properties"]}],["$","span","Shortcut-Free Benchmark",{"className":"page__taxonomy-item","children":["#","Shortcut-Free Benchmark"]}],["$","span","Visual Bottleneck",{"className":"page__taxonomy-item","children":["#","Visual Bottleneck"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Synthetic Data",{"className":"page__taxonomy-item","children":["#","Synthetic Data"]}]]}]]}]]}],["$","article","2025-11-19-REVISOR-Beyond-Textual-Reflection-Towards-Multimodal-Introspective-Reasoning-in-Long-Form-Video-Understanding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-19-REVISOR-Beyond-Textual-Reflection-Towards-Multimodal-Introspective-Reasoning-in-Long-Form-Video-Understanding/","children":"[논문리뷰] REVISOR: Beyond Textual Reflection, Towards Multimodal Introspective Reasoning in Long-Form Video Understanding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jingyang Chen이 [arXiv]에 게시한 'REVISOR: Beyond Textual Reflection, Towards Multimodal Introspective Reasoning in Long-Form Video Understanding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-19 00:00:00+0900+0900","children":"2025년 11월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","span","Long-Form Video Understanding",{"className":"page__taxonomy-item","children":["#","Long-Form Video Understanding"]}],["$","span","Self-Reflection",{"className":"page__taxonomy-item","children":["#","Self-Reflection"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Tool-Augmented MLLMs",{"className":"page__taxonomy-item","children":["#","Tool-Augmented MLLMs"]}],["$","span","Visual Rethinking",{"className":"page__taxonomy-item","children":["#","Visual Rethinking"]}],["$","span","Video Question Answering",{"className":"page__taxonomy-item","children":["#","Video Question Answering"]}],["$","span","Causal Attribution",{"className":"page__taxonomy-item","children":["#","Causal Attribution"]}]]}]]}]]}],["$","article","2025-11-19-Proactive-Hearing-Assistants-that-Isolate-Egocentric-Conversations",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-19-Proactive-Hearing-Assistants-that-Isolate-Egocentric-Conversations/","children":"[논문리뷰] Proactive Hearing Assistants that Isolate Egocentric Conversations"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Proactive Hearing Assistants that Isolate Egocentric Conversations' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-19 00:00:00+0900+0900","children":"2025년 11월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Proactive Hearing Assistant",{"className":"page__taxonomy-item","children":["#","Proactive Hearing Assistant"]}],["$","span","Egocentric Audio Processing",{"className":"page__taxonomy-item","children":["#","Egocentric Audio Processing"]}],["$","span","Speech Separation",{"className":"page__taxonomy-item","children":["#","Speech Separation"]}],["$","span","Turn-taking Dynamics",{"className":"page__taxonomy-item","children":["#","Turn-taking Dynamics"]}],["$","span","Dual-Model Architecture",{"className":"page__taxonomy-item","children":["#","Dual-Model Architecture"]}],["$","span","Real-time Inference",{"className":"page__taxonomy-item","children":["#","Real-time Inference"]}],["$","span","Wearable Devices",{"className":"page__taxonomy-item","children":["#","Wearable Devices"]}],["$","span","Dialogue Modeling",{"className":"page__taxonomy-item","children":["#","Dialogue Modeling"]}]]}]]}]]}],["$","article","2025-11-19-Orion-A-Unified-Visual-Agent-for-Multimodal-Perception-Advanced-Visual-Reasoning-and-Execution",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-19-Orion-A-Unified-Visual-Agent-for-Multimodal-Perception-Advanced-Visual-Reasoning-and-Execution/","children":"[논문리뷰] Orion: A Unified Visual Agent for Multimodal Perception, Advanced Visual Reasoning and Execution"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Sudeep Pillai이 [arXiv]에 게시한 'Orion: A Unified Visual Agent for Multimodal Perception, Advanced Visual Reasoning and Execution' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-19 00:00:00+0900+0900","children":"2025년 11월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Visual Agent",{"className":"page__taxonomy-item","children":["#","Visual Agent"]}],["$","span","Multimodal Perception",{"className":"page__taxonomy-item","children":["#","Multimodal Perception"]}],["$","span","Tool-Augmented LLM",{"className":"page__taxonomy-item","children":["#","Tool-Augmented LLM"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Visual Reasoning",{"className":"page__taxonomy-item","children":["#","Visual Reasoning"]}],["$","span","Computer Vision",{"className":"page__taxonomy-item","children":["#","Computer Vision"]}],["$","span","Structured Outputs",{"className":"page__taxonomy-item","children":["#","Structured Outputs"]}],["$","span","ReAct Framework",{"className":"page__taxonomy-item","children":["#","ReAct Framework"]}]]}]]}]]}],["$","article","2025-11-19-OmniZip-Audio-Guided-Dynamic-Token-Compression-for-Fast-Omnimodal-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-19-OmniZip-Audio-Guided-Dynamic-Token-Compression-for-Fast-Omnimodal-Large-Language-Models/","children":"[논문리뷰] OmniZip: Audio-Guided Dynamic Token Compression for Fast Omnimodal Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jian liu이 [arXiv]에 게시한 'OmniZip: Audio-Guided Dynamic Token Compression for Fast Omnimodal Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-19 00:00:00+0900+0900","children":"2025년 11월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Omnimodal LLMs",{"className":"page__taxonomy-item","children":["#","Omnimodal LLMs"]}],["$","span","Token Compression",{"className":"page__taxonomy-item","children":["#","Token Compression"]}],["$","span","Audio-Video Understanding",{"className":"page__taxonomy-item","children":["#","Audio-Video Understanding"]}],["$","span","Dynamic Pruning",{"className":"page__taxonomy-item","children":["#","Dynamic Pruning"]}],["$","span","Inference Acceleration",{"className":"page__taxonomy-item","children":["#","Inference Acceleration"]}],["$","span","Spatio-Temporal Compression",{"className":"page__taxonomy-item","children":["#","Spatio-Temporal Compression"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}]]}]]}]]}],["$","article","2025-11-19-Mitigating-Label-Length-Bias-in-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-19-Mitigating-Label-Length-Bias-in-Large-Language-Models/","children":"[논문리뷰] Mitigating Label Length Bias in Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Katharina von der Wense이 [arXiv]에 게시한 'Mitigating Label Length Bias in Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-19 00:00:00+0900+0900","children":"2025년 11월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Label Bias",{"className":"page__taxonomy-item","children":["#","Label Bias"]}],["$","span","Calibration",{"className":"page__taxonomy-item","children":["#","Calibration"]}],["$","span","In-Context Learning",{"className":"page__taxonomy-item","children":["#","In-Context Learning"]}],["$","span","Text Classification",{"className":"page__taxonomy-item","children":["#","Text Classification"]}],["$","span","Multi-token Labels",{"className":"page__taxonomy-item","children":["#","Multi-token Labels"]}],["$","span","Label Length Bias",{"className":"page__taxonomy-item","children":["#","Label Length Bias"]}],["$","span","Multiple Choice QA",{"className":"page__taxonomy-item","children":["#","Multiple Choice QA"]}]]}]]}]]}],["$","article","2025-11-19-MVI-Bench-A-Comprehensive-Benchmark-for-Evaluating-Robustness-to-Misleading-Visual-Inputs-in-LVLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-19-MVI-Bench-A-Comprehensive-Benchmark-for-Evaluating-Robustness-to-Misleading-Visual-Inputs-in-LVLMs/","children":"[논문리뷰] MVI-Bench: A Comprehensive Benchmark for Evaluating Robustness to Misleading Visual Inputs in LVLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kaijie Chen이 [arXiv]에 게시한 'MVI-Bench: A Comprehensive Benchmark for Evaluating Robustness to Misleading Visual Inputs in LVLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-19 00:00:00+0900+0900","children":"2025년 11월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LVLM Robustness",{"className":"page__taxonomy-item","children":["#","LVLM Robustness"]}],["$","span","Misleading Visual Inputs",{"className":"page__taxonomy-item","children":["#","Misleading Visual Inputs"]}],["$","span","VQA Benchmark",{"className":"page__taxonomy-item","children":["#","VQA Benchmark"]}],["$","span","Visual Perception",{"className":"page__taxonomy-item","children":["#","Visual Perception"]}],["$","span","Visual Reasoning",{"className":"page__taxonomy-item","children":["#","Visual Reasoning"]}],["$","span","MVI-Sensitivity",{"className":"page__taxonomy-item","children":["#","MVI-Sensitivity"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}]]}]]}]]}],["$","article","2025-11-19-Large-Language-Models-Meet-Extreme-Multi-label-Classification-Scaling-and-Multi-modal-Framework",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-19-Large-Language-Models-Meet-Extreme-Multi-label-Classification-Scaling-and-Multi-modal-Framework/","children":"[논문리뷰] Large Language Models Meet Extreme Multi-label Classification: Scaling and Multi-modal Framework"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Large Language Models Meet Extreme Multi-label Classification: Scaling and Multi-modal Framework' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-19 00:00:00+0900+0900","children":"2025년 11월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Extreme Multi-label Classification (XMC)",{"className":"page__taxonomy-item","children":["#","Extreme Multi-label Classification (XMC)"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Multi-modal Learning",{"className":"page__taxonomy-item","children":["#","Multi-modal Learning"]}],["$","span","Dual-decoder Learning",{"className":"page__taxonomy-item","children":["#","Dual-decoder Learning"]}],["$","span","Vision Transformers",{"className":"page__taxonomy-item","children":["#","Vision Transformers"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}]]}]]}]]}],["$","article","2025-11-19-LLM-Powered-Fully-Automated-Chaos-Engineering-Towards-Enabling-Anyone-to-Build-Resilient-Software-Systems-at-Low-Cost",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-19-LLM-Powered-Fully-Automated-Chaos-Engineering-Towards-Enabling-Anyone-to-Build-Resilient-Software-Systems-at-Low-Cost/","children":"[논문리뷰] LLM-Powered Fully Automated Chaos Engineering: Towards Enabling Anyone to Build Resilient Software Systems at Low Cost"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kengo Tajiri이 [arXiv]에 게시한 'LLM-Powered Fully Automated Chaos Engineering: Towards Enabling Anyone to Build Resilient Software Systems at Low Cost' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-19 00:00:00+0900+0900","children":"2025년 11월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Chaos Engineering",{"className":"page__taxonomy-item","children":["#","Chaos Engineering"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","System Resilience",{"className":"page__taxonomy-item","children":["#","System Resilience"]}],["$","span","Kubernetes",{"className":"page__taxonomy-item","children":["#","Kubernetes"]}],["$","span","Software Automation",{"className":"page__taxonomy-item","children":["#","Software Automation"]}],["$","span","AI Agents",{"className":"page__taxonomy-item","children":["#","AI Agents"]}],["$","span","Fault Injection",{"className":"page__taxonomy-item","children":["#","Fault Injection"]}]]}]]}]]}],["$","article","2025-11-19-Error-Driven-Scene-Editing-for-3D-Grounding-in-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-19-Error-Driven-Scene-Editing-for-3D-Grounding-in-Large-Language-Models/","children":"[논문리뷰] Error-Driven Scene Editing for 3D Grounding in Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Error-Driven Scene Editing for 3D Grounding in Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-19 00:00:00+0900+0900","children":"2025년 11월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Grounding",{"className":"page__taxonomy-item","children":["#","3D Grounding"]}],["$","span","3D-LLMs",{"className":"page__taxonomy-item","children":["#","3D-LLMs"]}],["$","span","Scene Editing",{"className":"page__taxonomy-item","children":["#","Scene Editing"]}],["$","span","Counterfactual Augmentation",{"className":"page__taxonomy-item","children":["#","Counterfactual Augmentation"]}],["$","span","Error-Driven Learning",{"className":"page__taxonomy-item","children":["#","Error-Driven Learning"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}],["$","span","Visual Grounding",{"className":"page__taxonomy-item","children":["#","Visual Grounding"]}]]}]]}]]}],["$","article","2025-11-19-Can-World-Simulators-Reason-Gen-ViRe-A-Generative-Visual-Reasoning-Benchmark",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-19-Can-World-Simulators-Reason-Gen-ViRe-A-Generative-Visual-Reasoning-Benchmark/","children":"[논문리뷰] Can World Simulators Reason? Gen-ViRe: A Generative Visual Reasoning Benchmark"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuzhang Shang이 [arXiv]에 게시한 'Can World Simulators Reason? Gen-ViRe: A Generative Visual Reasoning Benchmark' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-19 00:00:00+0900+0900","children":"2025년 11월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Generative Visual Reasoning",{"className":"page__taxonomy-item","children":["#","Generative Visual Reasoning"]}],["$","span","Chain-of-Frames (CoF)",{"className":"page__taxonomy-item","children":["#","Chain-of-Frames (CoF)"]}],["$","span","Video Generation Models",{"className":"page__taxonomy-item","children":["#","Video Generation Models"]}],["$","span","World Simulators",{"className":"page__taxonomy-item","children":["#","World Simulators"]}],["$","span","AI Benchmarking",{"className":"page__taxonomy-item","children":["#","AI Benchmarking"]}],["$","span","Cognitive Reasoning",{"className":"page__taxonomy-item","children":["#","Cognitive Reasoning"]}],["$","span","VLM Evaluation",{"className":"page__taxonomy-item","children":["#","VLM Evaluation"]}]]}]]}]]}],["$","article","2025-11-19-AraLingBench-A-Human-Annotated-Benchmark-for-Evaluating-Arabic-Linguistic-Capabilities-of-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-19-AraLingBench-A-Human-Annotated-Benchmark-for-Evaluating-Arabic-Linguistic-Capabilities-of-Large-Language-Models/","children":"[논문리뷰] AraLingBench A Human-Annotated Benchmark for Evaluating Arabic Linguistic Capabilities of Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'AraLingBench A Human-Annotated Benchmark for Evaluating Arabic Linguistic Capabilities of Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-19 00:00:00+0900+0900","children":"2025년 11월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Arabic LLMs",{"className":"page__taxonomy-item","children":["#","Arabic LLMs"]}],["$","span","Linguistic Benchmark",{"className":"page__taxonomy-item","children":["#","Linguistic Benchmark"]}],["$","span","Human Annotation",{"className":"page__taxonomy-item","children":["#","Human Annotation"]}],["$","span","Natural Language Understanding",{"className":"page__taxonomy-item","children":["#","Natural Language Understanding"]}],["$","span","Grammar Evaluation",{"className":"page__taxonomy-item","children":["#","Grammar Evaluation"]}],["$","span","Morphology Analysis",{"className":"page__taxonomy-item","children":["#","Morphology Analysis"]}],["$","span","Syntax Assessment",{"className":"page__taxonomy-item","children":["#","Syntax Assessment"]}],["$","span","Reading Comprehension",{"className":"page__taxonomy-item","children":["#","Reading Comprehension"]}]]}]]}]]}],["$","article","2025-11-19-Agent-READMEs-An-Empirical-Study-of-Context-Files-for-Agentic-Coding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-19-Agent-READMEs-An-Empirical-Study-of-Context-Files-for-Agentic-Coding/","children":"[논문리뷰] Agent READMEs: An Empirical Study of Context Files for Agentic Coding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kundjanasith Thonglek이 [arXiv]에 게시한 'Agent READMEs: An Empirical Study of Context Files for Agentic Coding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-19 00:00:00+0900+0900","children":"2025년 11월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic Coding",{"className":"page__taxonomy-item","children":["#","Agentic Coding"]}],["$","span","Context Files",{"className":"page__taxonomy-item","children":["#","Context Files"]}],["$","span","READMEs for Agents",{"className":"page__taxonomy-item","children":["#","READMEs for Agents"]}],["$","span","Empirical Study",{"className":"page__taxonomy-item","children":["#","Empirical Study"]}],["$","span","Software Engineering",{"className":"page__taxonomy-item","children":["#","Software Engineering"]}],["$","span","Documentation Maintenance",{"className":"page__taxonomy-item","children":["#","Documentation Maintenance"]}],["$","span","Non-functional Requirements",{"className":"page__taxonomy-item","children":["#","Non-functional Requirements"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}]]}]]}]]}],["$","article","2025-11-19-Agent-R1-Training-Powerful-LLM-Agents-with-End-to-End-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-19-Agent-R1-Training-Powerful-LLM-Agents-with-End-to-End-Reinforcement-Learning/","children":"[논문리뷰] Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yucong Luo이 [arXiv]에 게시한 'Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-19 00:00:00+0900+0900","children":"2025년 11월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Markov Decision Process",{"className":"page__taxonomy-item","children":["#","Markov Decision Process"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Multi-turn Interaction",{"className":"page__taxonomy-item","children":["#","Multi-turn Interaction"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Reward Shaping",{"className":"page__taxonomy-item","children":["#","Reward Shaping"]}],["$","span","Agent Framework",{"className":"page__taxonomy-item","children":["#","Agent Framework"]}]]}]]}]]}],["$","article","2025-11-19-ATLAS-A-High-Difficulty-Multidisciplinary-Benchmark-for-Frontier-Scientific-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-19-ATLAS-A-High-Difficulty-Multidisciplinary-Benchmark-for-Frontier-Scientific-Reasoning/","children":"[논문리뷰] ATLAS: A High-Difficulty, Multidisciplinary Benchmark for Frontier Scientific Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuqiang Li이 [arXiv]에 게시한 'ATLAS: A High-Difficulty, Multidisciplinary Benchmark for Frontier Scientific Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-19 00:00:00+0900+0900","children":"2025년 11월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Scientific Reasoning",{"className":"page__taxonomy-item","children":["#","Scientific Reasoning"]}],["$","span","Multidisciplinary",{"className":"page__taxonomy-item","children":["#","Multidisciplinary"]}],["$","span","AI4S",{"className":"page__taxonomy-item","children":["#","AI4S"]}],["$","span","Data Contamination",{"className":"page__taxonomy-item","children":["#","Data Contamination"]}],["$","span","Evaluation",{"className":"page__taxonomy-item","children":["#","Evaluation"]}],["$","span","LRM-as-Judge",{"className":"page__taxonomy-item","children":["#","LRM-as-Judge"]}]]}]]}]]}],["$","article","2025-11-19-A-Style-is-Worth-One-Code-Unlocking-Code-to-Style-Image-Generation-with-Discrete-Style-Space",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-19-A-Style-is-Worth-One-Code-Unlocking-Code-to-Style-Image-Generation-with-Discrete-Style-Space/","children":"[논문리뷰] A Style is Worth One Code: Unlocking Code-to-Style Image Generation with Discrete Style Space"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'A Style is Worth One Code: Unlocking Code-to-Style Image Generation with Discrete Style Space' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-19 00:00:00+0900+0900","children":"2025년 11월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Code-to-Style Generation",{"className":"page__taxonomy-item","children":["#","Code-to-Style Generation"]}],["$","span","Discrete Style Space",{"className":"page__taxonomy-item","children":["#","Discrete Style Space"]}],["$","span","Style Codebook",{"className":"page__taxonomy-item","children":["#","Style Codebook"]}],["$","span","Autoregressive Model",{"className":"page__taxonomy-item","children":["#","Autoregressive Model"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Visual Stylization",{"className":"page__taxonomy-item","children":["#","Visual Stylization"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}]]}]]}]]}],["$","article","2025-11-19-A-Brain-Wave-Encodes-a-Thousand-Tokens-Modeling-Inter-Cortical-Neural-Interactions-for-Effective-EEG-based-Emotion-Recognition",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-19-A-Brain-Wave-Encodes-a-Thousand-Tokens-Modeling-Inter-Cortical-Neural-Interactions-for-Effective-EEG-based-Emotion-Recognition/","children":"[논문리뷰] A Brain Wave Encodes a Thousand Tokens: Modeling Inter-Cortical Neural Interactions for Effective EEG-based Emotion Recognition"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"G. Maragatham이 [arXiv]에 게시한 'A Brain Wave Encodes a Thousand Tokens: Modeling Inter-Cortical Neural Interactions for Effective EEG-based Emotion Recognition' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-19 00:00:00+0900+0900","children":"2025년 11월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","EEG",{"className":"page__taxonomy-item","children":["#","EEG"]}],["$","span","Emotion Recognition",{"className":"page__taxonomy-item","children":["#","Emotion Recognition"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Inter-Cortical Neural Interactions",{"className":"page__taxonomy-item","children":["#","Inter-Cortical Neural Interactions"]}],["$","span","Multi-Head Attention",{"className":"page__taxonomy-item","children":["#","Multi-Head Attention"]}],["$","span","Brain-Computer Interface",{"className":"page__taxonomy-item","children":["#","Brain-Computer Interface"]}],["$","span","Affective Computing",{"className":"page__taxonomy-item","children":["#","Affective Computing"]}]]}]]}]]}],["$","article","2025-11-18-Uni-MoE-2-0-Omni-Scaling-Language-Centric-Omnimodal-Large-Model-with-Advanced-MoE-Training-and-Data",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-18-Uni-MoE-2-0-Omni-Scaling-Language-Centric-Omnimodal-Large-Model-with-Advanced-MoE-Training-and-Data/","children":"[논문리뷰] Uni-MoE-2.0-Omni: Scaling Language-Centric Omnimodal Large Model with Advanced MoE, Training and Data"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Uni-MoE-2.0-Omni: Scaling Language-Centric Omnimodal Large Model with Advanced MoE, Training and Data' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-18 00:00:00+0900+0900","children":"2025년 11월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Omnimodal Large Models",{"className":"page__taxonomy-item","children":["#","Omnimodal Large Models"]}],["$","span","Mixture-of-Experts (MoE)",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts (MoE)"]}],["$","span","Language-Centric AI",{"className":"page__taxonomy-item","children":["#","Language-Centric AI"]}],["$","span","Multimodal Understanding",{"className":"page__taxonomy-item","children":["#","Multimodal Understanding"]}],["$","span","Multimodal Generation",{"className":"page__taxonomy-item","children":["#","Multimodal Generation"]}],["$","span","Progressive Training",{"className":"page__taxonomy-item","children":["#","Progressive Training"]}],["$","span","Omni-Modality 3D RoPE",{"className":"page__taxonomy-item","children":["#","Omni-Modality 3D RoPE"]}]]}]]}]]}],["$","article","2025-11-18-UnSAMv2-Self-Supervised-Learning-Enables-Segment-Anything-at-Any-Granularity",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-18-UnSAMv2-Self-Supervised-Learning-Enables-Segment-Anything-at-Any-Granularity/","children":"[논문리뷰] UnSAMv2: Self-Supervised Learning Enables Segment Anything at Any Granularity"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'UnSAMv2: Self-Supervised Learning Enables Segment Anything at Any Granularity' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-18 00:00:00+0900+0900","children":"2025년 11월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Self-Supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-Supervised Learning"]}],["$","span","Segmentation",{"className":"page__taxonomy-item","children":["#","Segmentation"]}],["$","span","Granularity Control",{"className":"page__taxonomy-item","children":["#","Granularity Control"]}],["$","span","SAM",{"className":"page__taxonomy-item","children":["#","SAM"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Unsupervised Learning",{"className":"page__taxonomy-item","children":["#","Unsupervised Learning"]}],["$","span","Image Segmentation",{"className":"page__taxonomy-item","children":["#","Image Segmentation"]}],["$","span","Video Segmentation",{"className":"page__taxonomy-item","children":["#","Video Segmentation"]}]]}]]}]]}],["$","article","2025-11-18-UFO3-Weaving-the-Digital-Agent-Galaxy",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-18-UFO3-Weaving-the-Digital-Agent-Galaxy/","children":"[논문리뷰] UFO^3: Weaving the Digital Agent Galaxy"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'UFO^3: Weaving the Digital Agent Galaxy' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-18 00:00:00+0900+0900","children":"2025년 11월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Cross-Device Orchestration",{"className":"page__taxonomy-item","children":["#","Cross-Device Orchestration"]}],["$","span","LLM-Powered Agents",{"className":"page__taxonomy-item","children":["#","LLM-Powered Agents"]}],["$","span","Task Constellation",{"className":"page__taxonomy-item","children":["#","Task Constellation"]}],["$","span","Directed Acyclic Graph (DAG)",{"className":"page__taxonomy-item","children":["#","Directed Acyclic Graph (DAG)"]}],["$","span","Agent Interaction Protocol (AIP)",{"className":"page__taxonomy-item","children":["#","Agent Interaction Protocol (AIP)"]}],["$","span","Fault Tolerance",{"className":"page__taxonomy-item","children":["#","Fault Tolerance"]}],["$","span","Asynchronous Execution",{"className":"page__taxonomy-item","children":["#","Asynchronous Execution"]}]]}]]}]]}],["$","article","2025-11-18-TiViBench-Benchmarking-Think-in-Video-Reasoning-for-Video-Generative-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-18-TiViBench-Benchmarking-Think-in-Video-Reasoning-for-Video-Generative-Models/","children":"[논문리뷰] TiViBench: Benchmarking Think-in-Video Reasoning for Video Generative Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Qingyang Liu이 [arXiv]에 게시한 'TiViBench: Benchmarking Think-in-Video Reasoning for Video Generative Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-18 00:00:00+0900+0900","children":"2025년 11월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generative Models",{"className":"page__taxonomy-item","children":["#","Video Generative Models"]}],["$","span","Visual Reasoning",{"className":"page__taxonomy-item","children":["#","Visual Reasoning"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Image-to-Video",{"className":"page__taxonomy-item","children":["#","Image-to-Video"]}],["$","span","TiViBench",{"className":"page__taxonomy-item","children":["#","TiViBench"]}],["$","span","VideoTPO",{"className":"page__taxonomy-item","children":["#","VideoTPO"]}],["$","span","Prompt Optimization",{"className":"page__taxonomy-item","children":["#","Prompt Optimization"]}]]}]]}]]}],["$","article","2025-11-18-Test-Time-Spectrum-Aware-Latent-Steering-for-Zero-Shot-Generalization-in-Vision-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-18-Test-Time-Spectrum-Aware-Latent-Steering-for-Zero-Shot-Generalization-in-Vision-Language-Models/","children":"[논문리뷰] Test-Time Spectrum-Aware Latent Steering for Zero-Shot Generalization in Vision-Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Test-Time Spectrum-Aware Latent Steering for Zero-Shot Generalization in Vision-Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-18 00:00:00+0900+0900","children":"2025년 11월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Test-Time Adaptation",{"className":"page__taxonomy-item","children":["#","Test-Time Adaptation"]}],["$","span","Zero-Shot Generalization",{"className":"page__taxonomy-item","children":["#","Zero-Shot Generalization"]}],["$","span","Spectral Decomposition",{"className":"page__taxonomy-item","children":["#","Spectral Decomposition"]}],["$","span","Latent Space Steering",{"className":"page__taxonomy-item","children":["#","Latent Space Steering"]}],["$","span","SVD",{"className":"page__taxonomy-item","children":["#","SVD"]}],["$","span","Out-of-Distribution",{"className":"page__taxonomy-item","children":["#","Out-of-Distribution"]}]]}]]}]]}],["$","article","2025-11-18-Souper-Model-How-Simple-Arithmetic-Unlocks-State-of-the-Art-LLM-Performance",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-18-Souper-Model-How-Simple-Arithmetic-Unlocks-State-of-the-Art-LLM-Performance/","children":"[논문리뷰] Souper-Model: How Simple Arithmetic Unlocks State-of-the-Art LLM Performance"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Souper-Model: How Simple Arithmetic Unlocks State-of-the-Art LLM Performance' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-18 00:00:00+0900+0900","children":"2025년 11월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Model Souping",{"className":"page__taxonomy-item","children":["#","Model Souping"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Weighted Averaging",{"className":"page__taxonomy-item","children":["#","Weighted Averaging"]}],["$","span","Benchmark Optimization",{"className":"page__taxonomy-item","children":["#","Benchmark Optimization"]}],["$","span","State-of-the-Art",{"className":"page__taxonomy-item","children":["#","State-of-the-Art"]}],["$","span","Category Experts",{"className":"page__taxonomy-item","children":["#","Category Experts"]}],["$","span","Parameter Averaging",{"className":"page__taxonomy-item","children":["#","Parameter Averaging"]}],["$","span","Post-training",{"className":"page__taxonomy-item","children":["#","Post-training"]}]]}]]}]]}],["$","article","2025-11-18-SafeGRPO-Self-Rewarded-Multimodal-Safety-Alignment-via-Rule-Governed-Policy-Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-18-SafeGRPO-Self-Rewarded-Multimodal-Safety-Alignment-via-Rule-Governed-Policy-Optimization/","children":"[논문리뷰] SafeGRPO: Self-Rewarded Multimodal Safety Alignment via Rule-Governed Policy Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Bo Du이 [arXiv]에 게시한 'SafeGRPO: Self-Rewarded Multimodal Safety Alignment via Rule-Governed Policy Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-18 00:00:00+0900+0900","children":"2025년 11월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Safety Alignment",{"className":"page__taxonomy-item","children":["#","Multimodal Safety Alignment"]}],["$","span","Rule-Governed RL",{"className":"page__taxonomy-item","children":["#","Rule-Governed RL"]}],["$","span","Self-Rewarded Learning",{"className":"page__taxonomy-item","children":["#","Self-Rewarded Learning"]}],["$","span","MLLM Safety",{"className":"page__taxonomy-item","children":["#","MLLM Safety"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Safety Benchmarking",{"className":"page__taxonomy-item","children":["#","Safety Benchmarking"]}],["$","span","Compositional Robustness",{"className":"page__taxonomy-item","children":["#","Compositional Robustness"]}]]}]]}]]}],["$","article","2025-11-18-Part-X-MLLM-Part-aware-3D-Multimodal-Large-Language-Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-18-Part-X-MLLM-Part-aware-3D-Multimodal-Large-Language-Model/","children":"[논문리뷰] Part-X-MLLM: Part-aware 3D Multimodal Large Language Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Part-X-MLLM: Part-aware 3D Multimodal Large Language Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-18 00:00:00+0900+0900","children":"2025년 11월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Multimodal LLM",{"className":"page__taxonomy-item","children":["#","3D Multimodal LLM"]}],["$","span","Part-aware",{"className":"page__taxonomy-item","children":["#","Part-aware"]}],["$","span","3D Generation",{"className":"page__taxonomy-item","children":["#","3D Generation"]}],["$","span","3D Editing",{"className":"page__taxonomy-item","children":["#","3D Editing"]}],["$","span","3D Understanding",{"className":"page__taxonomy-item","children":["#","3D Understanding"]}],["$","span","Bounding Box",{"className":"page__taxonomy-item","children":["#","Bounding Box"]}],["$","span","Structured Program",{"className":"page__taxonomy-item","children":["#","Structured Program"]}],["$","span","Dual-encoder",{"className":"page__taxonomy-item","children":["#","Dual-encoder"]}]]}]]}]]}],["$","article","2025-11-18-P1-Mastering-Physics-Olympiads-with-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-18-P1-Mastering-Physics-Olympiads-with-Reinforcement-Learning/","children":"[논문리뷰] P1: Mastering Physics Olympiads with Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Haiyuan Wan이 [arXiv]에 게시한 'P1: Mastering Physics Olympiads with Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-18 00:00:00+0900+0900","children":"2025년 11월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Physics Reasoning",{"className":"page__taxonomy-item","children":["#","Physics Reasoning"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Olympiad Problems",{"className":"page__taxonomy-item","children":["#","Olympiad Problems"]}],["$","span","Post-Training",{"className":"page__taxonomy-item","children":["#","Post-Training"]}],["$","span","Knowledge Transfer",{"className":"page__taxonomy-item","children":["#","Knowledge Transfer"]}]]}]]}]]}],["$","article","2025-11-18-OlmoEarth-Stable-Latent-Image-Modeling-for-Multimodal-Earth-Observation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-18-OlmoEarth-Stable-Latent-Image-Modeling-for-Multimodal-Earth-Observation/","children":"[논문리뷰] OlmoEarth: Stable Latent Image Modeling for Multimodal Earth Observation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'OlmoEarth: Stable Latent Image Modeling for Multimodal Earth Observation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-18 00:00:00+0900+0900","children":"2025년 11월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Earth Observation",{"className":"page__taxonomy-item","children":["#","Earth Observation"]}],["$","span","Foundation Model",{"className":"page__taxonomy-item","children":["#","Foundation Model"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Self-supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-supervised Learning"]}],["$","span","Latent Image Modeling",{"className":"page__taxonomy-item","children":["#","Latent Image Modeling"]}],["$","span","Vision Transformer",{"className":"page__taxonomy-item","children":["#","Vision Transformer"]}],["$","span","Spatio-temporal",{"className":"page__taxonomy-item","children":["#","Spatio-temporal"]}]]}]]}]]}],["$","article","2025-11-18-NORA-1-5-A-Vision-Language-Action-Model-Trained-using-World-Model-and-Action-based-Preference-Rewards",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-18-NORA-1-5-A-Vision-Language-Action-Model-Trained-using-World-Model-and-Action-based-Preference-Rewards/","children":"[논문리뷰] NORA-1.5: A Vision-Language-Action Model Trained using World Model- and Action-based Preference Rewards"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'NORA-1.5: A Vision-Language-Action Model Trained using World Model- and Action-based Preference Rewards' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-18 00:00:00+0900+0900","children":"2025년 11월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action Model",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action Model"]}],["$","span","Direct Preference Optimization",{"className":"page__taxonomy-item","children":["#","Direct Preference Optimization"]}],["$","span","World Model",{"className":"page__taxonomy-item","children":["#","World Model"]}],["$","span","Reward Learning",{"className":"page__taxonomy-item","children":["#","Reward Learning"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Flow-Matching",{"className":"page__taxonomy-item","children":["#","Flow-Matching"]}]]}]]}]]}],["$","article","2025-11-18-MiroThinker-Pushing-the-Performance-Boundaries-of-Open-Source-Research-Agents-via-Model-Context-and-Interactive-Scaling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-18-MiroThinker-Pushing-the-Performance-Boundaries-of-Open-Source-Research-Agents-via-Model-Context-and-Interactive-Scaling/","children":"[논문리뷰] MiroThinker: Pushing the Performance Boundaries of Open-Source Research Agents via Model, Context, and Interactive Scaling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"cyyang822이 [arXiv]에 게시한 'MiroThinker: Pushing the Performance Boundaries of Open-Source Research Agents via Model, Context, and Interactive Scaling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-18 00:00:00+0900+0900","children":"2025년 11월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Research Agent",{"className":"page__taxonomy-item","children":["#","Research Agent"]}],["$","span","Tool-Augmented Reasoning",{"className":"page__taxonomy-item","children":["#","Tool-Augmented Reasoning"]}],["$","span","Interaction Scaling",{"className":"page__taxonomy-item","children":["#","Interaction Scaling"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Context Management",{"className":"page__taxonomy-item","children":["#","Context Management"]}],["$","span","Open-Source AI",{"className":"page__taxonomy-item","children":["#","Open-Source AI"]}]]}]]}]]}],["$","article","2025-11-18-MicroVQA-High-Quality-Microscopy-Reasoning-Dataset-with-Weakly-Supervised-Graphs-for-Multimodal-Large-Language-Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-18-MicroVQA-High-Quality-Microscopy-Reasoning-Dataset-with-Weakly-Supervised-Graphs-for-Multimodal-Large-Language-Model/","children":"[논문리뷰] MicroVQA++: High-Quality Microscopy Reasoning Dataset with Weakly Supervised Graphs for Multimodal Large Language Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Bo Yan이 [arXiv]에 게시한 'MicroVQA++: High-Quality Microscopy Reasoning Dataset with Weakly Supervised Graphs for Multimodal Large Language Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-18 00:00:00+0900+0900","children":"2025년 11월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Microscopy VQA",{"className":"page__taxonomy-item","children":["#","Microscopy VQA"]}],["$","span","Multimodal LLM",{"className":"page__taxonomy-item","children":["#","Multimodal LLM"]}],["$","span","Weak Supervision",{"className":"page__taxonomy-item","children":["#","Weak Supervision"]}],["$","span","Graph Neural Networks",{"className":"page__taxonomy-item","children":["#","Graph Neural Networks"]}],["$","span","Dataset Generation",{"className":"page__taxonomy-item","children":["#","Dataset Generation"]}],["$","span","Biomedical Imaging",{"className":"page__taxonomy-item","children":["#","Biomedical Imaging"]}],["$","span","Scientific Reasoning",{"className":"page__taxonomy-item","children":["#","Scientific Reasoning"]}],["$","span","Cross-Modal Consistency",{"className":"page__taxonomy-item","children":["#","Cross-Modal Consistency"]}]]}]]}]]}],["$","article","2025-11-18-LoCoBench-Agent-An-Interactive-Benchmark-for-LLM-Agents-in-Long-Context-Software-Engineering",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-18-LoCoBench-Agent-An-Interactive-Benchmark-for-LLM-Agents-in-Long-Context-Software-Engineering/","children":"[논문리뷰] LoCoBench-Agent: An Interactive Benchmark for LLM Agents in Long-Context Software Engineering"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'LoCoBench-Agent: An Interactive Benchmark for LLM Agents in Long-Context Software Engineering' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-18 00:00:00+0900+0900","children":"2025년 11월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Software Engineering",{"className":"page__taxonomy-item","children":["#","Software Engineering"]}],["$","span","Long-Context",{"className":"page__taxonomy-item","children":["#","Long-Context"]}],["$","span","Interactive Benchmark",{"className":"page__taxonomy-item","children":["#","Interactive Benchmark"]}],["$","span","Tool Usage",{"className":"page__taxonomy-item","children":["#","Tool Usage"]}],["$","span","Memory Management",{"className":"page__taxonomy-item","children":["#","Memory Management"]}],["$","span","Bias-Free Evaluation",{"className":"page__taxonomy-item","children":["#","Bias-Free Evaluation"]}],["$","span","Multi-Turn",{"className":"page__taxonomy-item","children":["#","Multi-Turn"]}]]}]]}]]}],["$","article","2025-11-18-Live-SWE-agent-Can-Software-Engineering-Agents-Self-Evolve-on-the-Fly",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-18-Live-SWE-agent-Can-Software-Engineering-Agents-Self-Evolve-on-the-Fly/","children":"[논문리뷰] Live-SWE-agent: Can Software Engineering Agents Self-Evolve on the Fly?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Lingming Zhang이 [arXiv]에 게시한 'Live-SWE-agent: Can Software Engineering Agents Self-Evolve on the Fly?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-18 00:00:00+0900+0900","children":"2025년 11월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Software Engineering Agents",{"className":"page__taxonomy-item","children":["#","Software Engineering Agents"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Self-Evolution",{"className":"page__taxonomy-item","children":["#","Self-Evolution"]}],["$","span","On-the-Fly Learning",{"className":"page__taxonomy-item","children":["#","On-the-Fly Learning"]}],["$","span","Tool Creation",{"className":"page__taxonomy-item","children":["#","Tool Creation"]}],["$","span","SWE-bench",{"className":"page__taxonomy-item","children":["#","SWE-bench"]}],["$","span","Autonomous Systems",{"className":"page__taxonomy-item","children":["#","Autonomous Systems"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}]]}]]}]]}],["$","article","2025-11-18-Genomic-Next-Token-Predictors-are-In-Context-Learners",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-18-Genomic-Next-Token-Predictors-are-In-Context-Learners/","children":"[논문리뷰] Genomic Next-Token Predictors are In-Context Learners"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Genomic Next-Token Predictors are In-Context Learners' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-18 00:00:00+0900+0900","children":"2025년 11월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","In-Context Learning (ICL)",{"className":"page__taxonomy-item","children":["#","In-Context Learning (ICL)"]}],["$","span","Genomic Sequences",{"className":"page__taxonomy-item","children":["#","Genomic Sequences"]}],["$","span","Next-Token Prediction",{"className":"page__taxonomy-item","children":["#","Next-Token Prediction"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Modality-Agnostic AI",{"className":"page__taxonomy-item","children":["#","Modality-Agnostic AI"]}],["$","span","Meta-Learning",{"className":"page__taxonomy-item","children":["#","Meta-Learning"]}],["$","span","Bitstring Program Synthesis",{"className":"page__taxonomy-item","children":["#","Bitstring Program Synthesis"]}],["$","span","Evo2",{"className":"page__taxonomy-item","children":["#","Evo2"]}]]}]]}]]}],["$","article","2025-11-18-Assessing-LLMs-for-Serendipity-Discovery-in-Knowledge-Graphs-A-Case-for-Drug-Repurposing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-18-Assessing-LLMs-for-Serendipity-Discovery-in-Knowledge-Graphs-A-Case-for-Drug-Repurposing/","children":"[논문리뷰] Assessing LLMs for Serendipity Discovery in Knowledge Graphs: A Case for Drug Repurposing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Assessing LLMs for Serendipity Discovery in Knowledge Graphs: A Case for Drug Repurposing' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-18 00:00:00+0900+0900","children":"2025년 11월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Serendipity Discovery",{"className":"page__taxonomy-item","children":["#","Serendipity Discovery"]}],["$","span","Knowledge Graphs",{"className":"page__taxonomy-item","children":["#","Knowledge Graphs"]}],["$","span","Drug Repurposing",{"className":"page__taxonomy-item","children":["#","Drug Repurposing"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","KGQA",{"className":"page__taxonomy-item","children":["#","KGQA"]}],["$","span","RNS Metric",{"className":"page__taxonomy-item","children":["#","RNS Metric"]}],["$","span","Biomedical AI",{"className":"page__taxonomy-item","children":["#","Biomedical AI"]}]]}]]}]]}],["$","article","2025-11-18-AI-Salesman-Towards-Reliable-Large-Language-Model-Driven-Telemarketing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-18-AI-Salesman-Towards-Reliable-Large-Language-Model-Driven-Telemarketing/","children":"[논문리뷰] AI-Salesman: Towards Reliable Large Language Model Driven Telemarketing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hongyu Lin이 [arXiv]에 게시한 'AI-Salesman: Towards Reliable Large Language Model Driven Telemarketing' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-18 00:00:00+0900+0900","children":"2025년 11월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Telemarketing",{"className":"page__taxonomy-item","children":["#","Telemarketing"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Persuasive Dialogue",{"className":"page__taxonomy-item","children":["#","Persuasive Dialogue"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Bayesian Optimization",{"className":"page__taxonomy-item","children":["#","Bayesian Optimization"]}],["$","span","Dynamic Prompting",{"className":"page__taxonomy-item","children":["#","Dynamic Prompting"]}],["$","span","Dialogue Systems",{"className":"page__taxonomy-item","children":["#","Dialogue Systems"]}]]}]]}]]}],["$","article","2025-11-18-A-Decentralized-Retrieval-Augmented-Generation-System-with-Source-Reliabilities-Secured-on-Blockchain",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-18-A-Decentralized-Retrieval-Augmented-Generation-System-with-Source-Reliabilities-Secured-on-Blockchain/","children":"[논문리뷰] A Decentralized Retrieval Augmented Generation System with Source Reliabilities Secured on Blockchain"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Meng Jiang이 [arXiv]에 게시한 'A Decentralized Retrieval Augmented Generation System with Source Reliabilities Secured on Blockchain' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-18 00:00:00+0900+0900","children":"2025년 11월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Decentralized RAG",{"className":"page__taxonomy-item","children":["#","Decentralized RAG"]}],["$","span","Blockchain",{"className":"page__taxonomy-item","children":["#","Blockchain"]}],["$","span","Smart Contracts",{"className":"page__taxonomy-item","children":["#","Smart Contracts"]}],["$","span","Source Reliability",{"className":"page__taxonomy-item","children":["#","Source Reliability"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Retrieval Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval Augmented Generation"]}],["$","span","Trustworthy AI",{"className":"page__taxonomy-item","children":["#","Trustworthy AI"]}]]}]]}]]}],["$","article","2025-11-17-miniF2F-Lean-Revisited-Reviewing-Limitations-and-Charting-a-Path-Forward",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-17-miniF2F-Lean-Revisited-Reviewing-Limitations-and-Charting-a-Path-Forward/","children":"[논문리뷰] miniF2F-Lean Revisited: Reviewing Limitations and Charting a Path Forward"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Farzan Farnia이 [arXiv]에 게시한 'miniF2F-Lean Revisited: Reviewing Limitations and Charting a Path Forward' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-17 00:00:00+0900+0900","children":"2025년 11월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Automated Theorem Proving",{"className":"page__taxonomy-item","children":["#","Automated Theorem Proving"]}],["$","span","Autoformalization",{"className":"page__taxonomy-item","children":["#","Autoformalization"]}],["$","span","Benchmark Dataset",{"className":"page__taxonomy-item","children":["#","Benchmark Dataset"]}],["$","span","miniF2F",{"className":"page__taxonomy-item","children":["#","miniF2F"]}],["$","span","Lean Language",{"className":"page__taxonomy-item","children":["#","Lean Language"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Formal Verification",{"className":"page__taxonomy-item","children":["#","Formal Verification"]}]]}]]}]]}],["$","article","2025-11-17-Workload-Schedulers-Genesis-Algorithms-and-Differences",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-17-Workload-Schedulers-Genesis-Algorithms-and-Differences/","children":"[논문리뷰] Workload Schedulers -- Genesis, Algorithms and Differences"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Vladimir Getov이 [arXiv]에 게시한 'Workload Schedulers -- Genesis, Algorithms and Differences' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-17 00:00:00+0900+0900","children":"2025년 11월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Workload Scheduling",{"className":"page__taxonomy-item","children":["#","Workload Scheduling"]}],["$","span","Process Scheduling",{"className":"page__taxonomy-item","children":["#","Process Scheduling"]}],["$","span","Job Scheduling",{"className":"page__taxonomy-item","children":["#","Job Scheduling"]}],["$","span","Big Data Processing",{"className":"page__taxonomy-item","children":["#","Big Data Processing"]}],["$","span","Resource Management",{"className":"page__taxonomy-item","children":["#","Resource Management"]}],["$","span","Distributed Systems",{"className":"page__taxonomy-item","children":["#","Distributed Systems"]}],["$","span","Scheduling Algorithms",{"className":"page__taxonomy-item","children":["#","Scheduling Algorithms"]}],["$","span","Performance Optimization",{"className":"page__taxonomy-item","children":["#","Performance Optimization"]}]]}]]}]]}],["$","article","2025-11-17-Virtual-Width-Networks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-17-Virtual-Width-Networks/","children":"[논문리뷰] Virtual Width Networks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Virtual Width Networks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-17 00:00:00+0900+0900","children":"2025년 11월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Virtual Width Networks",{"className":"page__taxonomy-item","children":["#","Virtual Width Networks"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Mixture-of-Experts (MoE)",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts (MoE)"]}],["$","span","Scaling Laws",{"className":"page__taxonomy-item","children":["#","Scaling Laws"]}],["$","span","Representation Learning",{"className":"page__taxonomy-item","children":["#","Representation Learning"]}],["$","span","Model Efficiency",{"className":"page__taxonomy-item","children":["#","Model Efficiency"]}],["$","span","Multi-Token Prediction",{"className":"page__taxonomy-item","children":["#","Multi-Token Prediction"]}],["$","span","Hyper-Connections",{"className":"page__taxonomy-item","children":["#","Hyper-Connections"]}]]}]]}]]}],["$","article","2025-11-17-UI2CodeN-A-Visual-Language-Model-for-Test-Time-Scalable-Interactive-UI-to-Code-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-17-UI2CodeN-A-Visual-Language-Model-for-Test-Time-Scalable-Interactive-UI-to-Code-Generation/","children":"[논문리뷰] UI2Code^N: A Visual Language Model for Test-Time Scalable Interactive UI-to-Code Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Weihan Wang이 [arXiv]에 게시한 'UI2Code^N: A Visual Language Model for Test-Time Scalable Interactive UI-to-Code Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-17 00:00:00+0900+0900","children":"2025년 11월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Visual Language Model",{"className":"page__taxonomy-item","children":["#","Visual Language Model"]}],["$","span","UI-to-Code Generation",{"className":"page__taxonomy-item","children":["#","UI-to-Code Generation"]}],["$","span","Interactive UI",{"className":"page__taxonomy-item","children":["#","Interactive UI"]}],["$","span","UI Editing",{"className":"page__taxonomy-item","children":["#","UI Editing"]}],["$","span","UI Polishing",{"className":"page__taxonomy-item","children":["#","UI Polishing"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Multimodal Coding",{"className":"page__taxonomy-item","children":["#","Multimodal Coding"]}],["$","span","Test-Time Scaling",{"className":"page__taxonomy-item","children":["#","Test-Time Scaling"]}]]}]]}]]}],["$","article","2025-11-17-Simulating-the-Visual-World-with-Artificial-Intelligence-A-Roadmap",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-17-Simulating-the-Visual-World-with-Artificial-Intelligence-A-Roadmap/","children":"[논문리뷰] Simulating the Visual World with Artificial Intelligence: A Roadmap"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Pengfei Wan이 [arXiv]에 게시한 'Simulating the Visual World with Artificial Intelligence: A Roadmap' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-17 00:00:00+0900+0900","children":"2025년 11월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","World Models",{"className":"page__taxonomy-item","children":["#","World Models"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","AI Simulation",{"className":"page__taxonomy-item","children":["#","AI Simulation"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Physical Plausibility",{"className":"page__taxonomy-item","children":["#","Physical Plausibility"]}],["$","span","Interactive AI",{"className":"page__taxonomy-item","children":["#","Interactive AI"]}],["$","span","Planning",{"className":"page__taxonomy-item","children":["#","Planning"]}],["$","span","Roadmap",{"className":"page__taxonomy-item","children":["#","Roadmap"]}]]}]]}]]}],["$","article","2025-11-17-MarsRL-Advancing-Multi-Agent-Reasoning-System-via-Reinforcement-Learning-with-Agentic-Pipeline-Parallelism",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-17-MarsRL-Advancing-Multi-Agent-Reasoning-System-via-Reinforcement-Learning-with-Agentic-Pipeline-Parallelism/","children":"[논문리뷰] MarsRL: Advancing Multi-Agent Reasoning System via Reinforcement Learning with Agentic Pipeline Parallelism"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'MarsRL: Advancing Multi-Agent Reasoning System via Reinforcement Learning with Agentic Pipeline Parallelism' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-17 00:00:00+0900+0900","children":"2025년 11월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Pipeline Parallelism",{"className":"page__taxonomy-item","children":["#","Pipeline Parallelism"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Reward Shaping",{"className":"page__taxonomy-item","children":["#","Reward Shaping"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}]]}]]}]]}],["$","article","2025-11-17-LiteAttention-A-Temporal-Sparse-Attention-for-Diffusion-Transformers",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-17-LiteAttention-A-Temporal-Sparse-Attention-for-Diffusion-Transformers/","children":"[논문리뷰] LiteAttention: A Temporal Sparse Attention for Diffusion Transformers"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'LiteAttention: A Temporal Sparse Attention for Diffusion Transformers' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-17 00:00:00+0900+0900","children":"2025년 11월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Transformers",{"className":"page__taxonomy-item","children":["#","Diffusion Transformers"]}],["$","span","Sparse Attention",{"className":"page__taxonomy-item","children":["#","Sparse Attention"]}],["$","span","Temporal Coherence",{"className":"page__taxonomy-item","children":["#","Temporal Coherence"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}],["$","span","FlashAttention",{"className":"page__taxonomy-item","children":["#","FlashAttention"]}],["$","span","CUDA Kernels",{"className":"page__taxonomy-item","children":["#","CUDA Kernels"]}]]}]]}]]}],["$","article","2025-11-17-Large-Language-Models-for-Scientific-Idea-Generation-A-Creativity-Centered-Survey",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-17-Large-Language-Models-for-Scientific-Idea-Generation-A-Creativity-Centered-Survey/","children":"[논문리뷰] Large Language Models for Scientific Idea Generation: A Creativity-Centered Survey"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Mohammad Hossein Rohban이 [arXiv]에 게시한 'Large Language Models for Scientific Idea Generation: A Creativity-Centered Survey' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-17 00:00:00+0900+0900","children":"2025년 11월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Scientific Discovery",{"className":"page__taxonomy-item","children":["#","Scientific Discovery"]}],["$","span","Idea Generation",{"className":"page__taxonomy-item","children":["#","Idea Generation"]}],["$","span","Creativity",{"className":"page__taxonomy-item","children":["#","Creativity"]}],["$","span","Survey",{"className":"page__taxonomy-item","children":["#","Survey"]}],["$","span","AI in Science",{"className":"page__taxonomy-item","children":["#","AI in Science"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","Multi-agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-agent Systems"]}],["$","span","Evaluation Metrics",{"className":"page__taxonomy-item","children":["#","Evaluation Metrics"]}]]}]]}]]}],["$","article","2025-11-17-HI-TransPA-Hearing-Impairments-Translation-Personal-Assistant",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-17-HI-TransPA-Hearing-Impairments-Translation-Personal-Assistant/","children":"[논문리뷰] HI-TransPA: Hearing Impairments Translation Personal Assistant"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'HI-TransPA: Hearing Impairments Translation Personal Assistant' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-17 00:00:00+0900+0900","children":"2025년 11월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Hearing Impairment",{"className":"page__taxonomy-item","children":["#","Hearing Impairment"]}],["$","span","Audio-Visual Speech Recognition",{"className":"page__taxonomy-item","children":["#","Audio-Visual Speech Recognition"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Omni-Models",{"className":"page__taxonomy-item","children":["#","Omni-Models"]}],["$","span","Assistive Technology",{"className":"page__taxonomy-item","children":["#","Assistive Technology"]}],["$","span","Lip Reading",{"className":"page__taxonomy-item","children":["#","Lip Reading"]}],["$","span","Speech Translation",{"className":"page__taxonomy-item","children":["#","Speech Translation"]}]]}]]}]]}],["$","article","2025-11-17-GGBench-A-Geometric-Generative-Reasoning-Benchmark-for-Unified-Multimodal-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-17-GGBench-A-Geometric-Generative-Reasoning-Benchmark-for-Unified-Multimodal-Models/","children":"[논문리뷰] GGBench: A Geometric Generative Reasoning Benchmark for Unified Multimodal Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Siyuan Li이 [arXiv]에 게시한 'GGBench: A Geometric Generative Reasoning Benchmark for Unified Multimodal Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-17 00:00:00+0900+0900","children":"2025년 11월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Generative Reasoning",{"className":"page__taxonomy-item","children":["#","Generative Reasoning"]}],["$","span","Geometric Construction",{"className":"page__taxonomy-item","children":["#","Geometric Construction"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","GeoGebra",{"className":"page__taxonomy-item","children":["#","GeoGebra"]}],["$","span","Code-based Evaluation",{"className":"page__taxonomy-item","children":["#","Code-based Evaluation"]}],["$","span","Unified Models",{"className":"page__taxonomy-item","children":["#","Unified Models"]}]]}]]}]]}],["$","article","2025-11-17-From-Proof-to-Program-Characterizing-Tool-Induced-Reasoning-Hallucinations-in-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-17-From-Proof-to-Program-Characterizing-Tool-Induced-Reasoning-Hallucinations-in-Large-Language-Models/","children":"[논문리뷰] From Proof to Program: Characterizing Tool-Induced Reasoning Hallucinations in Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'From Proof to Program: Characterizing Tool-Induced Reasoning Hallucinations in Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-17 00:00:00+0900+0900","children":"2025년 11월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Tool-augmented LLMs",{"className":"page__taxonomy-item","children":["#","Tool-augmented LLMs"]}],["$","span","Reasoning Hallucinations",{"className":"page__taxonomy-item","children":["#","Reasoning Hallucinations"]}],["$","span","Tool-Induced Myopia (TIM)",{"className":"page__taxonomy-item","children":["#","Tool-Induced Myopia (TIM)"]}],["$","span","Code Interpreter",{"className":"page__taxonomy-item","children":["#","Code Interpreter"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Preference Optimization",{"className":"page__taxonomy-item","children":["#","Preference Optimization"]}]]}]]}]]}],["$","article","2025-11-17-Experience-Guided-Adaptation-of-Inference-Time-Reasoning-Strategies",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-17-Experience-Guided-Adaptation-of-Inference-Time-Reasoning-Strategies/","children":"[논문리뷰] Experience-Guided Adaptation of Inference-Time Reasoning Strategies"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Experience-Guided Adaptation of Inference-Time Reasoning Strategies' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-17 00:00:00+0900+0900","children":"2025년 11월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Adaptive AI",{"className":"page__taxonomy-item","children":["#","Adaptive AI"]}],["$","span","Inference-Time Adaptation",{"className":"page__taxonomy-item","children":["#","Inference-Time Adaptation"]}],["$","span","Reasoning Strategies",{"className":"page__taxonomy-item","children":["#","Reasoning Strategies"]}],["$","span","Meta-Learning",{"className":"page__taxonomy-item","children":["#","Meta-Learning"]}],["$","span","LLM-based Agents",{"className":"page__taxonomy-item","children":["#","LLM-based Agents"]}],["$","span","Dynamic Strategy Generation",{"className":"page__taxonomy-item","children":["#","Dynamic Strategy Generation"]}],["$","span","Continual Learning",{"className":"page__taxonomy-item","children":["#","Continual Learning"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}]]}]]}]]}],["$","article","2025-11-17-EmoVid-A-Multimodal-Emotion-Video-Dataset-for-Emotion-Centric-Video-Understanding-and-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-17-EmoVid-A-Multimodal-Emotion-Video-Dataset-for-Emotion-Centric-Video-Understanding-and-Generation/","children":"[논문리뷰] EmoVid: A Multimodal Emotion Video Dataset for Emotion-Centric Video Understanding and Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zeyu Wang이 [arXiv]에 게시한 'EmoVid: A Multimodal Emotion Video Dataset for Emotion-Centric Video Understanding and Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-17 00:00:00+0900+0900","children":"2025년 11월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Dataset",{"className":"page__taxonomy-item","children":["#","Multimodal Dataset"]}],["$","span","Emotion Recognition",{"className":"page__taxonomy-item","children":["#","Emotion Recognition"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Affective Computing",{"className":"page__taxonomy-item","children":["#","Affective Computing"]}],["$","span","Stylized Media",{"className":"page__taxonomy-item","children":["#","Stylized Media"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Video Understanding",{"className":"page__taxonomy-item","children":["#","Video Understanding"]}],["$","span","Text-to-Video",{"className":"page__taxonomy-item","children":["#","Text-to-Video"]}]]}]]}]]}],["$","article","2025-11-17-Dont-Waste-It-Guiding-Generative-Recommenders-with-Structured-Human-Priors-via-Multi-head-Decoding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-17-Dont-Waste-It-Guiding-Generative-Recommenders-with-Structured-Human-Priors-via-Multi-head-Decoding/","children":"[논문리뷰] Don't Waste It: Guiding Generative Recommenders with Structured Human Priors via Multi-head Decoding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Don't Waste It: Guiding Generative Recommenders with Structured Human Priors via Multi-head Decoding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-17 00:00:00+0900+0900","children":"2025년 11월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Generative Recommenders",{"className":"page__taxonomy-item","children":["#","Generative Recommenders"]}],["$","span","Human Priors",{"className":"page__taxonomy-item","children":["#","Human Priors"]}],["$","span","Multi-head Decoding",{"className":"page__taxonomy-item","children":["#","Multi-head Decoding"]}],["$","span","Disentangled Representation Learning",{"className":"page__taxonomy-item","children":["#","Disentangled Representation Learning"]}],["$","span","Sequential Recommendation",{"className":"page__taxonomy-item","children":["#","Sequential Recommendation"]}],["$","span","Adapter Networks",{"className":"page__taxonomy-item","children":["#","Adapter Networks"]}],["$","span","Hierarchical Modeling",{"className":"page__taxonomy-item","children":["#","Hierarchical Modeling"]}]]}]]}]]}],["$","article","2025-11-17-DoPE-Denoising-Rotary-Position-Embedding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-17-DoPE-Denoising-Rotary-Position-Embedding/","children":"[논문리뷰] DoPE: Denoising Rotary Position Embedding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Min Yang이 [arXiv]에 게시한 'DoPE: Denoising Rotary Position Embedding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-17 00:00:00+0900+0900","children":"2025년 11월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Rotary Position Embedding",{"className":"page__taxonomy-item","children":["#","Rotary Position Embedding"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Length Extrapolation",{"className":"page__taxonomy-item","children":["#","Length Extrapolation"]}],["$","span","Attention Sink",{"className":"page__taxonomy-item","children":["#","Attention Sink"]}],["$","span","Matrix Entropy",{"className":"page__taxonomy-item","children":["#","Matrix Entropy"]}],["$","span","Denoising",{"className":"page__taxonomy-item","children":["#","Denoising"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}]]}]]}]]}],["$","article","2025-11-17-DiscoX-Benchmarking-Discourse-Level-Translation-task-in-Expert-Domains",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-17-DiscoX-Benchmarking-Discourse-Level-Translation-task-in-Expert-Domains/","children":"[논문리뷰] DiscoX: Benchmarking Discourse-Level Translation task in Expert Domains"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DiscoX: Benchmarking Discourse-Level Translation task in Expert Domains' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-17 00:00:00+0900+0900","children":"2025년 11월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Discourse-Level Translation",{"className":"page__taxonomy-item","children":["#","Discourse-Level Translation"]}],["$","span","Expert Domains",{"className":"page__taxonomy-item","children":["#","Expert Domains"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Reference-Free Metric",{"className":"page__taxonomy-item","children":["#","Reference-Free Metric"]}],["$","span","Chinese-English Translation",{"className":"page__taxonomy-item","children":["#","Chinese-English Translation"]}],["$","span","Contextual Coherence",{"className":"page__taxonomy-item","children":["#","Contextual Coherence"]}],["$","span","Domain-Specific Terminology",{"className":"page__taxonomy-item","children":["#","Domain-Specific Terminology"]}]]}]]}]]}],["$","article","2025-11-17-CATS-V2V-A-Real-World-Vehicle-to-Vehicle-Cooperative-Perception-Dataset-with-Complex-Adverse-Traffic-Scenarios",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-17-CATS-V2V-A-Real-World-Vehicle-to-Vehicle-Cooperative-Perception-Dataset-with-Complex-Adverse-Traffic-Scenarios/","children":"[논문리뷰] CATS-V2V: A Real-World Vehicle-to-Vehicle Cooperative Perception Dataset with Complex Adverse Traffic Scenarios"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Juyoung Oh이 [arXiv]에 게시한 'CATS-V2V: A Real-World Vehicle-to-Vehicle Cooperative Perception Dataset with Complex Adverse Traffic Scenarios' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-17 00:00:00+0900+0900","children":"2025년 11월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Cooperative Perception",{"className":"page__taxonomy-item","children":["#","Cooperative Perception"]}],["$","span","Vehicle-to-Vehicle (V2V)",{"className":"page__taxonomy-item","children":["#","Vehicle-to-Vehicle (V2V)"]}],["$","span","Autonomous Driving",{"className":"page__taxonomy-item","children":["#","Autonomous Driving"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}],["$","span","Adverse Traffic Scenarios",{"className":"page__taxonomy-item","children":["#","Adverse Traffic Scenarios"]}],["$","span","Sensor Fusion",{"className":"page__taxonomy-item","children":["#","Sensor Fusion"]}],["$","span","Temporal Alignment",{"className":"page__taxonomy-item","children":["#","Temporal Alignment"]}],["$","span","3D Bounding Box Annotation",{"className":"page__taxonomy-item","children":["#","3D Bounding Box Annotation"]}]]}]]}]]}],["$","article","2025-11-17-A-Meta-Heuristic-Load-Balancer-for-Cloud-Computing-Systems",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-17-A-Meta-Heuristic-Load-Balancer-for-Cloud-Computing-Systems/","children":"[논문리뷰] A Meta-Heuristic Load Balancer for Cloud Computing Systems"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Vladimir Getov이 [arXiv]에 게시한 'A Meta-Heuristic Load Balancer for Cloud Computing Systems' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-17 00:00:00+0900+0900","children":"2025년 11월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Cloud Computing",{"className":"page__taxonomy-item","children":["#","Cloud Computing"]}],["$","span","Load Balancing",{"className":"page__taxonomy-item","children":["#","Load Balancing"]}],["$","span","Meta-Heuristic",{"className":"page__taxonomy-item","children":["#","Meta-Heuristic"]}],["$","span","Genetic Algorithm",{"className":"page__taxonomy-item","children":["#","Genetic Algorithm"]}],["$","span","Simulated Annealing",{"className":"page__taxonomy-item","children":["#","Simulated Annealing"]}],["$","span","Tabu Search",{"className":"page__taxonomy-item","children":["#","Tabu Search"]}],["$","span","Resource Management",{"className":"page__taxonomy-item","children":["#","Resource Management"]}],["$","span","Service Migration",{"className":"page__taxonomy-item","children":["#","Service Migration"]}]]}]]}]]}],["$","article","2025-11-14-UniVA-Universal-Video-Agent-towards-Open-Source-Next-Generation-Video-Generalist",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-14-UniVA-Universal-Video-Agent-towards-Open-Source-Next-Generation-Video-Generalist/","children":"[논문리뷰] UniVA: Universal Video Agent towards Open-Source Next-Generation Video Generalist"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'UniVA: Universal Video Agent towards Open-Source Next-Generation Video Generalist' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-14 00:00:00+0900+0900","children":"2025년 11월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Agents",{"className":"page__taxonomy-item","children":["#","Video Agents"]}],["$","span","Multi-modal AI",{"className":"page__taxonomy-item","children":["#","Multi-modal AI"]}],["$","span","Plan-Act Architecture",{"className":"page__taxonomy-item","children":["#","Plan-Act Architecture"]}],["$","span","Tool-Use",{"className":"page__taxonomy-item","children":["#","Tool-Use"]}],["$","span","Long-horizon Reasoning",{"className":"page__taxonomy-item","children":["#","Long-horizon Reasoning"]}],["$","span","Open-source",{"className":"page__taxonomy-item","children":["#","Open-source"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Video Understanding",{"className":"page__taxonomy-item","children":["#","Video Understanding"]}]]}]]}]]}],["$","article","2025-11-14-Superpositional-Gradient-Descent-Harnessing-Quantum-Principles-for-Model-Training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-14-Superpositional-Gradient-Descent-Harnessing-Quantum-Principles-for-Model-Training/","children":"[논문리뷰] Superpositional Gradient Descent: Harnessing Quantum Principles for   Model Training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"suayptalha이 [arXiv]에 게시한 'Superpositional Gradient Descent: Harnessing Quantum Principles for   Model Training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-14 00:00:00+0900+0900","children":"2025년 11월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Quantum Computing",{"className":"page__taxonomy-item","children":["#","Quantum Computing"]}],["$","span","Optimization",{"className":"page__taxonomy-item","children":["#","Optimization"]}],["$","span","Machine Learning",{"className":"page__taxonomy-item","children":["#","Machine Learning"]}],["$","span","Transformers",{"className":"page__taxonomy-item","children":["#","Transformers"]}],["$","span","Gradient Descent",{"className":"page__taxonomy-item","children":["#","Gradient Descent"]}],["$","span","Superposition",{"className":"page__taxonomy-item","children":["#","Superposition"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Hybrid Quantum-Classical",{"className":"page__taxonomy-item","children":["#","Hybrid Quantum-Classical"]}]]}]]}]]}],["$","article","2025-11-14-SliderEdit-Continuous-Image-Editing-with-Fine-Grained-Instruction-Control",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-14-SliderEdit-Continuous-Image-Editing-with-Fine-Grained-Instruction-Control/","children":"[논문리뷰] SliderEdit: Continuous Image Editing with Fine-Grained Instruction Control"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ryan Rossi이 [arXiv]에 게시한 'SliderEdit: Continuous Image Editing with Fine-Grained Instruction Control' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-14 00:00:00+0900+0900","children":"2025년 11월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Continuous Control",{"className":"page__taxonomy-item","children":["#","Continuous Control"]}],["$","span","Fine-Grained Control",{"className":"page__taxonomy-item","children":["#","Fine-Grained Control"]}],["$","span","Instruction-based",{"className":"page__taxonomy-item","children":["#","Instruction-based"]}],["$","span","Low-Rank Adaptation",{"className":"page__taxonomy-item","children":["#","Low-Rank Adaptation"]}],["$","span","Disentanglement",{"className":"page__taxonomy-item","children":["#","Disentanglement"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}]]}]]}]]}],["$","article","2025-11-14-Rubric-Based-Benchmarking-and-Reinforcement-Learning-for-Advancing-LLM-Instruction-Following",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-14-Rubric-Based-Benchmarking-and-Reinforcement-Learning-for-Advancing-LLM-Instruction-Following/","children":"[논문리뷰] Rubric-Based Benchmarking and Reinforcement Learning for Advancing LLM Instruction Following"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Karishma Mandyam이 [arXiv]에 게시한 'Rubric-Based Benchmarking and Reinforcement Learning for Advancing LLM Instruction Following' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-14 00:00:00+0900+0900","children":"2025년 11월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Rubric-based Evaluation",{"className":"page__taxonomy-item","children":["#","Rubric-based Evaluation"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Reward Shaping",{"className":"page__taxonomy-item","children":["#","Reward Shaping"]}],["$","span","Rubric Verifier",{"className":"page__taxonomy-item","children":["#","Rubric Verifier"]}],["$","span","AdvancedIF",{"className":"page__taxonomy-item","children":["#","AdvancedIF"]}]]}]]}]]}],["$","article","2025-11-14-ResearchRubrics-A-Benchmark-of-Prompts-and-Rubrics-For-Evaluating-Deep-Research-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-14-ResearchRubrics-A-Benchmark-of-Prompts-and-Rubrics-For-Evaluating-Deep-Research-Agents/","children":"[논문리뷰] ResearchRubrics: A Benchmark of Prompts and Rubrics For Evaluating Deep Research Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'ResearchRubrics: A Benchmark of Prompts and Rubrics For Evaluating Deep Research Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-14 00:00:00+0900+0900","children":"2025년 11월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Deep Research Agents",{"className":"page__taxonomy-item","children":["#","Deep Research Agents"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Rubrics",{"className":"page__taxonomy-item","children":["#","Rubrics"]}],["$","span","Multi-step Reasoning",{"className":"page__taxonomy-item","children":["#","Multi-step Reasoning"]}],["$","span","Cross-document Synthesis",{"className":"page__taxonomy-item","children":["#","Cross-document Synthesis"]}],["$","span","AI Performance",{"className":"page__taxonomy-item","children":["#","AI Performance"]}],["$","span","Task Complexity",{"className":"page__taxonomy-item","children":["#","Task Complexity"]}]]}]]}]]}],["$","article","2025-11-14-One-Small-Step-in-Latent-One-Giant-Leap-for-Pixels-Fast-Latent-Upscale-Adapter-for-Your-Diffusion-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-14-One-Small-Step-in-Latent-One-Giant-Leap-for-Pixels-Fast-Latent-Upscale-Adapter-for-Your-Diffusion-Models/","children":"[논문리뷰] One Small Step in Latent, One Giant Leap for Pixels: Fast Latent Upscale Adapter for Your Diffusion Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ilya Makarov이 [arXiv]에 게시한 'One Small Step in Latent, One Giant Leap for Pixels: Fast Latent Upscale Adapter for Your Diffusion Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-14 00:00:00+0900+0900","children":"2025년 11월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Latent Diffusion Models",{"className":"page__taxonomy-item","children":["#","Latent Diffusion Models"]}],["$","span","Super-Resolution",{"className":"page__taxonomy-item","children":["#","Super-Resolution"]}],["$","span","Upscaling Adapter",{"className":"page__taxonomy-item","children":["#","Upscaling Adapter"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Latent Space",{"className":"page__taxonomy-item","children":["#","Latent Space"]}],["$","span","Multi-scale Learning",{"className":"page__taxonomy-item","children":["#","Multi-scale Learning"]}],["$","span","Cross-VAE",{"className":"page__taxonomy-item","children":["#","Cross-VAE"]}]]}]]}]]}],["$","article","2025-11-14-Music-Flamingo-Scaling-Music-Understanding-in-Audio-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-14-Music-Flamingo-Scaling-Music-Understanding-in-Audio-Language-Models/","children":"[논문리뷰] Music Flamingo: Scaling Music Understanding in Audio Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Music Flamingo: Scaling Music Understanding in Audio Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-14 00:00:00+0900+0900","children":"2025년 11월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Audio Language Models",{"className":"page__taxonomy-item","children":["#","Audio Language Models"]}],["$","span","Music Understanding",{"className":"page__taxonomy-item","children":["#","Music Understanding"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Music Information Retrieval",{"className":"page__taxonomy-item","children":["#","Music Information Retrieval"]}]]}]]}]]}],["$","article","2025-11-14-MuSc-V2-Zero-Shot-Multimodal-Industrial-Anomaly-Classification-and-Segmentation-with-Mutual-Scoring-of-Unlabeled-Samples",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-14-MuSc-V2-Zero-Shot-Multimodal-Industrial-Anomaly-Classification-and-Segmentation-with-Mutual-Scoring-of-Unlabeled-Samples/","children":"[논문리뷰] MuSc-V2: Zero-Shot Multimodal Industrial Anomaly Classification and Segmentation with Mutual Scoring of Unlabeled Samples"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'MuSc-V2: Zero-Shot Multimodal Industrial Anomaly Classification and Segmentation with Mutual Scoring of Unlabeled Samples' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-14 00:00:00+0900+0900","children":"2025년 11월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Zero-Shot Learning",{"className":"page__taxonomy-item","children":["#","Zero-Shot Learning"]}],["$","span","Anomaly Detection",{"className":"page__taxonomy-item","children":["#","Anomaly Detection"]}],["$","span","Anomaly Segmentation",{"className":"page__taxonomy-item","children":["#","Anomaly Segmentation"]}],["$","span","Multimodal",{"className":"page__taxonomy-item","children":["#","Multimodal"]}],["$","span","Industrial Inspection",{"className":"page__taxonomy-item","children":["#","Industrial Inspection"]}],["$","span","Mutual Scoring",{"className":"page__taxonomy-item","children":["#","Mutual Scoring"]}],["$","span","Unsupervised Learning",{"className":"page__taxonomy-item","children":["#","Unsupervised Learning"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}]]}]]}]]}],["$","article","2025-11-14-MM-CRITIC-A-Holistic-Evaluation-of-Large-Multimodal-Models-as-Multimodal-Critique",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-14-MM-CRITIC-A-Holistic-Evaluation-of-Large-Multimodal-Models-as-Multimodal-Critique/","children":"[논문리뷰] MM-CRITIC: A Holistic Evaluation of Large Multimodal Models as Multimodal Critique"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'MM-CRITIC: A Holistic Evaluation of Large Multimodal Models as Multimodal Critique' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-14 00:00:00+0900+0900","children":"2025년 11월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LMMs",{"className":"page__taxonomy-item","children":["#","LMMs"]}],["$","span","Multimodal Critique",{"className":"page__taxonomy-item","children":["#","Multimodal Critique"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Evaluation",{"className":"page__taxonomy-item","children":["#","Evaluation"]}],["$","span","Reward Model",{"className":"page__taxonomy-item","children":["#","Reward Model"]}],["$","span","GPT-4o",{"className":"page__taxonomy-item","children":["#","GPT-4o"]}],["$","span","Scaling Law",{"className":"page__taxonomy-item","children":["#","Scaling Law"]}]]}]]}]]}],["$","article","2025-11-14-Hail-to-the-Thief-Exploring-Attacks-and-Defenses-in-Decentralised-GRPO",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-14-Hail-to-the-Thief-Exploring-Attacks-and-Defenses-in-Decentralised-GRPO/","children":"[논문리뷰] Hail to the Thief: Exploring Attacks and Defenses in Decentralised GRPO"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Hail to the Thief: Exploring Attacks and Defenses in Decentralised GRPO' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-14 00:00:00+0900+0900","children":"2025년 11월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Decentralized RL",{"className":"page__taxonomy-item","children":["#","Decentralized RL"]}],["$","span","GRPO",{"className":"page__taxonomy-item","children":["#","GRPO"]}],["$","span","LLM Post-training",{"className":"page__taxonomy-item","children":["#","LLM Post-training"]}],["$","span","Adversarial Attacks",{"className":"page__taxonomy-item","children":["#","Adversarial Attacks"]}],["$","span","Data Poisoning",{"className":"page__taxonomy-item","children":["#","Data Poisoning"]}],["$","span","Defense Mechanisms",{"className":"page__taxonomy-item","children":["#","Defense Mechanisms"]}],["$","span","In-context Attack",{"className":"page__taxonomy-item","children":["#","In-context Attack"]}],["$","span","Out-of-context Attack",{"className":"page__taxonomy-item","children":["#","Out-of-context Attack"]}]]}]]}]]}],["$","article","2025-11-14-Depth-Anything-3-Recovering-the-Visual-Space-from-Any-Views",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-14-Depth-Anything-3-Recovering-the-Visual-Space-from-Any-Views/","children":"[논문리뷰] Depth Anything 3: Recovering the Visual Space from Any Views"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Depth Anything 3: Recovering the Visual Space from Any Views' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-14 00:00:00+0900+0900","children":"2025년 11월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Depth Estimation",{"className":"page__taxonomy-item","children":["#","Depth Estimation"]}],["$","span","Multi-view Geometry",{"className":"page__taxonomy-item","children":["#","Multi-view Geometry"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Teacher-Student Learning",{"className":"page__taxonomy-item","children":["#","Teacher-Student Learning"]}],["$","span","Pose Estimation",{"className":"page__taxonomy-item","children":["#","Pose Estimation"]}],["$","span","3D Reconstruction",{"className":"page__taxonomy-item","children":["#","3D Reconstruction"]}],["$","span","Novel View Synthesis",{"className":"page__taxonomy-item","children":["#","Novel View Synthesis"]}],["$","span","Visual Space Recovery",{"className":"page__taxonomy-item","children":["#","Visual Space Recovery"]}]]}]]}]]}],["$","article","2025-11-14-CC30k-A-Citation-Contexts-Dataset-for-Reproducibility-Oriented-Sentiment-Analysis",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-14-CC30k-A-Citation-Contexts-Dataset-for-Reproducibility-Oriented-Sentiment-Analysis/","children":"[논문리뷰] CC30k: A Citation Contexts Dataset for Reproducibility-Oriented Sentiment Analysis"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jian Wu이 [arXiv]에 게시한 'CC30k: A Citation Contexts Dataset for Reproducibility-Oriented Sentiment Analysis' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-14 00:00:00+0900+0900","children":"2025년 11월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Citation Contexts",{"className":"page__taxonomy-item","children":["#","Citation Contexts"]}],["$","span","Reproducibility",{"className":"page__taxonomy-item","children":["#","Reproducibility"]}],["$","span","Sentiment Analysis",{"className":"page__taxonomy-item","children":["#","Sentiment Analysis"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Crowdsourcing",{"className":"page__taxonomy-item","children":["#","Crowdsourcing"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}],["$","span","Machine Learning",{"className":"page__taxonomy-item","children":["#","Machine Learning"]}],["$","span","Science of Science",{"className":"page__taxonomy-item","children":["#","Science of Science"]}]]}]]}]]}],["$","article","2025-11-14-Black-Box-On-Policy-Distillation-of-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-14-Black-Box-On-Policy-Distillation-of-Large-Language-Models/","children":"[논문리뷰] Black-Box On-Policy Distillation of Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Black-Box On-Policy Distillation of Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-14 00:00:00+0900+0900","children":"2025년 11월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Knowledge Distillation (KD)",{"className":"page__taxonomy-item","children":["#","Knowledge Distillation (KD)"]}],["$","span","Black-box Distillation",{"className":"page__taxonomy-item","children":["#","Black-box Distillation"]}],["$","span","Generative Adversarial Networks (GANs)",{"className":"page__taxonomy-item","children":["#","Generative Adversarial Networks (GANs)"]}],["$","span","On-policy Learning",{"className":"page__taxonomy-item","children":["#","On-policy Learning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Minimax Game",{"className":"page__taxonomy-item","children":["#","Minimax Game"]}],["$","span","Model Compression",{"className":"page__taxonomy-item","children":["#","Model Compression"]}]]}]]}]]}],["$","article","2025-11-14-Benchmarking-Diversity-in-Image-Generation-via-Attribute-Conditional-Human-Evaluation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-14-Benchmarking-Diversity-in-Image-Generation-via-Attribute-Conditional-Human-Evaluation/","children":"[논문리뷰] Benchmarking Diversity in Image Generation via Attribute-Conditional Human Evaluation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Benchmarking Diversity in Image Generation via Attribute-Conditional Human Evaluation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-14 00:00:00+0900+0900","children":"2025년 11월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Image Models",{"className":"page__taxonomy-item","children":["#","Text-to-Image Models"]}],["$","span","Diversity Evaluation",{"className":"page__taxonomy-item","children":["#","Diversity Evaluation"]}],["$","span","Human Evaluation",{"className":"page__taxonomy-item","children":["#","Human Evaluation"]}],["$","span","Attribute-Conditional",{"className":"page__taxonomy-item","children":["#","Attribute-Conditional"]}],["$","span","Vendi Score",{"className":"page__taxonomy-item","children":["#","Vendi Score"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}]]}]]}]]}],["$","article","2025-11-14-AffordBot-3D-Fine-grained-Embodied-Reasoning-via-Multimodal-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-14-AffordBot-3D-Fine-grained-Embodied-Reasoning-via-Multimodal-Large-Language-Models/","children":"[논문리뷰] AffordBot: 3D Fine-grained Embodied Reasoning via Multimodal Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhen Li이 [arXiv]에 게시한 'AffordBot: 3D Fine-grained Embodied Reasoning via Multimodal Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-14 00:00:00+0900+0900","children":"2025년 11월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Embodied Reasoning",{"className":"page__taxonomy-item","children":["#","3D Embodied Reasoning"]}],["$","span","Multimodal Large Language Models (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models (MLLMs)"]}],["$","span","Chain-of-Thought (CoT)",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought (CoT)"]}],["$","span","Affordance Grounding",{"className":"page__taxonomy-item","children":["#","Affordance Grounding"]}],["$","span","Motion Estimation",{"className":"page__taxonomy-item","children":["#","Motion Estimation"]}],["$","span","View Synthesis",{"className":"page__taxonomy-item","children":["#","View Synthesis"]}],["$","span","Active Perception",{"className":"page__taxonomy-item","children":["#","Active Perception"]}]]}]]}]]}],["$","article","2025-11-13-WebVIA-A-Web-based-Vision-Language-Agentic-Framework-for-Interactive-and-Verifiable-UI-to-Code-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-13-WebVIA-A-Web-based-Vision-Language-Agentic-Framework-for-Interactive-and-Verifiable-UI-to-Code-Generation/","children":"[논문리뷰] WebVIA: A Web-based Vision-Language Agentic Framework for Interactive and Verifiable UI-to-Code Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'WebVIA: A Web-based Vision-Language Agentic Framework for Interactive and Verifiable UI-to-Code Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-13 00:00:00+0900+0900","children":"2025년 11월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","UI-to-Code",{"className":"page__taxonomy-item","children":["#","UI-to-Code"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Agentic Framework",{"className":"page__taxonomy-item","children":["#","Agentic Framework"]}],["$","span","Interactive UI",{"className":"page__taxonomy-item","children":["#","Interactive UI"]}],["$","span","Web Automation",{"className":"page__taxonomy-item","children":["#","Web Automation"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","UI Verification",{"className":"page__taxonomy-item","children":["#","UI Verification"]}],["$","span","Supervised Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning"]}]]}]]}]]}],["$","article","2025-11-13-WMPO-World-Model-based-Policy-Optimization-for-Vision-Language-Action-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-13-WMPO-World-Model-based-Policy-Optimization-for-Vision-Language-Action-Models/","children":"[논문리뷰] WMPO: World Model-based Policy Optimization for Vision-Language-Action Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'WMPO: World Model-based Policy Optimization for Vision-Language-Action Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-13 00:00:00+0900+0900","children":"2025년 11월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action (VLA)",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action (VLA)"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Model-based RL",{"className":"page__taxonomy-item","children":["#","Model-based RL"]}],["$","span","World Models",{"className":"page__taxonomy-item","children":["#","World Models"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Sample Efficiency",{"className":"page__taxonomy-item","children":["#","Sample Efficiency"]}],["$","span","Self-correction",{"className":"page__taxonomy-item","children":["#","Self-correction"]}]]}]]}]]}],["$","article","2025-11-13-Toward-the-Frontiers-of-Reliable-Diffusion-Sampling-via-Adversarial-Sinkhorn-Attention-Guidance",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-13-Toward-the-Frontiers-of-Reliable-Diffusion-Sampling-via-Adversarial-Sinkhorn-Attention-Guidance/","children":"[논문리뷰] Toward the Frontiers of Reliable Diffusion Sampling via Adversarial Sinkhorn Attention Guidance"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kwanyoung Kim이 [arXiv]에 게시한 'Toward the Frontiers of Reliable Diffusion Sampling via Adversarial Sinkhorn Attention Guidance' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-13 00:00:00+0900+0900","children":"2025년 11월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Guidance Sampling",{"className":"page__taxonomy-item","children":["#","Guidance Sampling"]}],["$","span","Optimal Transport",{"className":"page__taxonomy-item","children":["#","Optimal Transport"]}],["$","span","Sinkhorn Algorithm",{"className":"page__taxonomy-item","children":["#","Sinkhorn Algorithm"]}],["$","span","Self-Attention",{"className":"page__taxonomy-item","children":["#","Self-Attention"]}],["$","span","Adversarial Perturbation",{"className":"page__taxonomy-item","children":["#","Adversarial Perturbation"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","ControlNet",{"className":"page__taxonomy-item","children":["#","ControlNet"]}]]}]]}]]}],["$","article","2025-11-13-TiDAR-Think-in-Diffusion-Talk-in-Autoregression",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-13-TiDAR-Think-in-Diffusion-Talk-in-Autoregression/","children":"[논문리뷰] TiDAR: Think in Diffusion, Talk in Autoregression"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'TiDAR: Think in Diffusion, Talk in Autoregression' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-13 00:00:00+0900+0900","children":"2025년 11월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Hybrid LLM Architecture",{"className":"page__taxonomy-item","children":["#","Hybrid LLM Architecture"]}],["$","span","Diffusion-Autoregressive",{"className":"page__taxonomy-item","children":["#","Diffusion-Autoregressive"]}],["$","span","Parallel Token Generation",{"className":"page__taxonomy-item","children":["#","Parallel Token Generation"]}],["$","span","Speculative Decoding",{"className":"page__taxonomy-item","children":["#","Speculative Decoding"]}],["$","span","Structured Attention Masks",{"className":"page__taxonomy-item","children":["#","Structured Attention Masks"]}],["$","span","LLM Inference Acceleration",{"className":"page__taxonomy-item","children":["#","LLM Inference Acceleration"]}],["$","span","KV Cache",{"className":"page__taxonomy-item","children":["#","KV Cache"]}]]}]]}]]}],["$","article","2025-11-13-Stemming-Hallucination-in-Language-Models-Using-a-Licensing-Oracle",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-13-Stemming-Hallucination-in-Language-Models-Using-a-Licensing-Oracle/","children":"[논문리뷰] Stemming Hallucination in Language Models Using a Licensing Oracle"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Richard Ackermann이 [arXiv]에 게시한 'Stemming Hallucination in Language Models Using a Licensing Oracle' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-13 00:00:00+0900+0900","children":"2025년 11월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Hallucination Mitigation",{"className":"page__taxonomy-item","children":["#","Hallucination Mitigation"]}],["$","span","Language Models",{"className":"page__taxonomy-item","children":["#","Language Models"]}],["$","span","Knowledge Graphs",{"className":"page__taxonomy-item","children":["#","Knowledge Graphs"]}],["$","span","SHACL Validation",{"className":"page__taxonomy-item","children":["#","SHACL Validation"]}],["$","span","Epistemic Grounding",{"className":"page__taxonomy-item","children":["#","Epistemic Grounding"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","Neuro-symbolic AI",{"className":"page__taxonomy-item","children":["#","Neuro-symbolic AI"]}]]}]]}]]}],["$","article","2025-11-13-Motif-2-12-7B-technical-report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-13-Motif-2-12-7B-technical-report/","children":"[논문리뷰] Motif 2 12.7B technical report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Motif 2 12.7B technical report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-13 00:00:00+0900+0900","children":"2025년 11월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Model",{"className":"page__taxonomy-item","children":["#","Large Language Model"]}],["$","span","LLM Efficiency",{"className":"page__taxonomy-item","children":["#","LLM Efficiency"]}],["$","span","Grouped Differential Attention",{"className":"page__taxonomy-item","children":["#","Grouped Differential Attention"]}],["$","span","Kernel Fusion",{"className":"page__taxonomy-item","children":["#","Kernel Fusion"]}],["$","span","Parallel Muon",{"className":"page__taxonomy-item","children":["#","Parallel Muon"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Architectural Scaling",{"className":"page__taxonomy-item","children":["#","Architectural Scaling"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}]]}]]}]]}],["$","article","2025-11-13-MathSE-Improving-Multimodal-Mathematical-Reasoning-via-Self-Evolving-Iterative-Reflection-and-Reward-Guided-Fine-Tuning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-13-MathSE-Improving-Multimodal-Mathematical-Reasoning-via-Self-Evolving-Iterative-Reflection-and-Reward-Guided-Fine-Tuning/","children":"[논문리뷰] MathSE: Improving Multimodal Mathematical Reasoning via Self-Evolving Iterative Reflection and Reward-Guided Fine-Tuning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'MathSE: Improving Multimodal Mathematical Reasoning via Self-Evolving Iterative Reflection and Reward-Guided Fine-Tuning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-13 00:00:00+0900+0900","children":"2025년 11월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","span","Mathematical Problem Solving",{"className":"page__taxonomy-item","children":["#","Mathematical Problem Solving"]}],["$","span","Self-Evolving",{"className":"page__taxonomy-item","children":["#","Self-Evolving"]}],["$","span","Iterative Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Iterative Fine-Tuning"]}],["$","span","Reward Models",{"className":"page__taxonomy-item","children":["#","Reward Models"]}],["$","span","Reflection",{"className":"page__taxonomy-item","children":["#","Reflection"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}]]}]]}]]}],["$","article","2025-11-13-MADD-Multi-Agent-Drug-Discovery-Orchestra",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-13-MADD-Multi-Agent-Drug-Discovery-Orchestra/","children":"[논문리뷰] MADD: Multi-Agent Drug Discovery Orchestra"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'MADD: Multi-Agent Drug Discovery Orchestra' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-13 00:00:00+0900+0900","children":"2025년 11월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-Agent System",{"className":"page__taxonomy-item","children":["#","Multi-Agent System"]}],["$","span","Drug Discovery",{"className":"page__taxonomy-item","children":["#","Drug Discovery"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Hit Identification",{"className":"page__taxonomy-item","children":["#","Hit Identification"]}],["$","span","Virtual Screening",{"className":"page__taxonomy-item","children":["#","Virtual Screening"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Property Prediction",{"className":"page__taxonomy-item","children":["#","Property Prediction"]}],["$","span","Automated Machine Learning",{"className":"page__taxonomy-item","children":["#","Automated Machine Learning"]}]]}]]}]]}],["$","article","2025-11-13-Lumine-An-Open-Recipe-for-Building-Generalist-Agents-in-3D-Open-Worlds",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-13-Lumine-An-Open-Recipe-for-Building-Generalist-Agents-in-3D-Open-Worlds/","children":"[논문리뷰] Lumine: An Open Recipe for Building Generalist Agents in 3D Open Worlds"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Lumine: An Open Recipe for Building Generalist Agents in 3D Open Worlds' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-13 00:00:00+0900+0900","children":"2025년 11월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Generalist Agent",{"className":"page__taxonomy-item","children":["#","Generalist Agent"]}],["$","span","3D Open World",{"className":"page__taxonomy-item","children":["#","3D Open World"]}],["$","span","Vision-Language Model",{"className":"page__taxonomy-item","children":["#","Vision-Language Model"]}],["$","span","Imitation Learning",{"className":"page__taxonomy-item","children":["#","Imitation Learning"]}],["$","span","Real-time Inference",{"className":"page__taxonomy-item","children":["#","Real-time Inference"]}],["$","span","Hybrid Thinking",{"className":"page__taxonomy-item","children":["#","Hybrid Thinking"]}],["$","span","Action Chunking",{"className":"page__taxonomy-item","children":["#","Action Chunking"]}],["$","span","Genshin Impact",{"className":"page__taxonomy-item","children":["#","Genshin Impact"]}]]}]]}]]}],["$","article","2025-11-13-LoopTool-Closing-the-Data-Training-Loop-for-Robust-LLM-Tool-Calls",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-13-LoopTool-Closing-the-Data-Training-Loop-for-Robust-LLM-Tool-Calls/","children":"[논문리뷰] LoopTool: Closing the Data-Training Loop for Robust LLM Tool Calls"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'LoopTool: Closing the Data-Training Loop for Robust LLM Tool Calls' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-13 00:00:00+0900+0900","children":"2025년 11월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Tool Learning",{"className":"page__taxonomy-item","children":["#","Tool Learning"]}],["$","span","Data Generation",{"className":"page__taxonomy-item","children":["#","Data Generation"]}],["$","span","Model Training",{"className":"page__taxonomy-item","children":["#","Model Training"]}],["$","span","Closed-Loop Framework",{"className":"page__taxonomy-item","children":["#","Closed-Loop Framework"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Data Refinement",{"className":"page__taxonomy-item","children":["#","Data Refinement"]}],["$","span","Self-Correction",{"className":"page__taxonomy-item","children":["#","Self-Correction"]}]]}]]}]]}],["$","article","2025-11-13-Agentic-Refactoring-An-Empirical-Study-of-AI-Coding-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-13-Agentic-Refactoring-An-Empirical-Study-of-AI-Coding-Agents/","children":"[논문리뷰] Agentic Refactoring: An Empirical Study of AI Coding Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hajimu Iida이 [arXiv]에 게시한 'Agentic Refactoring: An Empirical Study of AI Coding Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-13 00:00:00+0900+0900","children":"2025년 11월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Agents",{"className":"page__taxonomy-item","children":["#","AI Agents"]}],["$","span","Code Refactoring",{"className":"page__taxonomy-item","children":["#","Code Refactoring"]}],["$","span","Software Engineering",{"className":"page__taxonomy-item","children":["#","Software Engineering"]}],["$","span","Empirical Study",{"className":"page__taxonomy-item","children":["#","Empirical Study"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Code Quality",{"className":"page__taxonomy-item","children":["#","Code Quality"]}],["$","span","Agentic Software Development",{"className":"page__taxonomy-item","children":["#","Agentic Software Development"]}],["$","span","Maintainability",{"className":"page__taxonomy-item","children":["#","Maintainability"]}]]}]]}]]}],["$","article","2025-11-13-Adapting-Web-Agents-with-Synthetic-Supervision",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-13-Adapting-Web-Agents-with-Synthetic-Supervision/","children":"[논문리뷰] Adapting Web Agents with Synthetic Supervision"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Siwei Han이 [arXiv]에 게시한 'Adapting Web Agents with Synthetic Supervision' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-13 00:00:00+0900+0900","children":"2025년 11월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Web Agents",{"className":"page__taxonomy-item","children":["#","Web Agents"]}],["$","span","Synthetic Data Generation",{"className":"page__taxonomy-item","children":["#","Synthetic Data Generation"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Task Refinement",{"className":"page__taxonomy-item","children":["#","Task Refinement"]}],["$","span","Trajectory Refinement",{"className":"page__taxonomy-item","children":["#","Trajectory Refinement"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Web Automation",{"className":"page__taxonomy-item","children":["#","Web Automation"]}],["$","span","Environment Adaptation",{"className":"page__taxonomy-item","children":["#","Environment Adaptation"]}]]}]]}]]}],["$","article","2025-11-12-Wasm-A-Pipeline-for-Constructing-Structured-Arabic-Interleaved-Multimodal-Corpora",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-12-Wasm-A-Pipeline-for-Constructing-Structured-Arabic-Interleaved-Multimodal-Corpora/","children":"[논문리뷰] Wasm: A Pipeline for Constructing Structured Arabic Interleaved   Multimodal Corpora"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Mohamed Motasim Hamed이 [arXiv]에 게시한 'Wasm: A Pipeline for Constructing Structured Arabic Interleaved   Multimodal Corpora' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-12 00:00:00+0900+0900","children":"2025년 11월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Arabic Language",{"className":"page__taxonomy-item","children":["#","Arabic Language"]}],["$","span","Multimodal Corpus",{"className":"page__taxonomy-item","children":["#","Multimodal Corpus"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Web Scraping",{"className":"page__taxonomy-item","children":["#","Web Scraping"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Document Structure",{"className":"page__taxonomy-item","children":["#","Document Structure"]}],["$","span","Markdown",{"className":"page__taxonomy-item","children":["#","Markdown"]}],["$","span","Perplexity Filtering",{"className":"page__taxonomy-item","children":["#","Perplexity Filtering"]}]]}]]}]]}],["$","article","2025-11-12-Walking-the-Tightrope-of-LLMs-for-Software-Development-A-Practitioners-Perspective",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-12-Walking-the-Tightrope-of-LLMs-for-Software-Development-A-Practitioners-Perspective/","children":"[논문리뷰] Walking the Tightrope of LLMs for Software Development: A Practitioners' Perspective"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Christoph Treude이 [arXiv]에 게시한 'Walking the Tightrope of LLMs for Software Development: A Practitioners' Perspective' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-12 00:00:00+0900+0900","children":"2025년 11월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Software Engineering",{"className":"page__taxonomy-item","children":["#","Software Engineering"]}],["$","span","Developer Productivity",{"className":"page__taxonomy-item","children":["#","Developer Productivity"]}],["$","span","Socio-Technical Grounded Theory",{"className":"page__taxonomy-item","children":["#","Socio-Technical Grounded Theory"]}],["$","span","Practitioner Insights",{"className":"page__taxonomy-item","children":["#","Practitioner Insights"]}],["$","span","AI Adoption",{"className":"page__taxonomy-item","children":["#","AI Adoption"]}],["$","span","Benefits and Risks",{"className":"page__taxonomy-item","children":["#","Benefits and Risks"]}],["$","span","Balanced Use",{"className":"page__taxonomy-item","children":["#","Balanced Use"]}]]}]]}]]}],["$","article","2025-11-12-VideoSSR-Video-Self-Supervised-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-12-VideoSSR-Video-Self-Supervised-Reinforcement-Learning/","children":"[논문리뷰] VideoSSR: Video Self-Supervised Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'VideoSSR: Video Self-Supervised Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-12 00:00:00+0900+0900","children":"2025년 11월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Understanding",{"className":"page__taxonomy-item","children":["#","Video Understanding"]}],["$","span","Self-Supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-Supervised Learning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","MLLMs",{"className":"page__taxonomy-item","children":["#","MLLMs"]}],["$","span","Pretext Tasks",{"className":"page__taxonomy-item","children":["#","Pretext Tasks"]}],["$","span","Verifiable Rewards",{"className":"page__taxonomy-item","children":["#","Verifiable Rewards"]}],["$","span","Data Generation",{"className":"page__taxonomy-item","children":["#","Data Generation"]}],["$","span","Temporal Grounding",{"className":"page__taxonomy-item","children":["#","Temporal Grounding"]}]]}]]}]]}],["$","article","2025-11-12-Tiny-Model-Big-Logic-Diversity-Driven-Optimization-Elicits-Large-Model-Reasoning-Ability-in-VibeThinker-1-5B",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-12-Tiny-Model-Big-Logic-Diversity-Driven-Optimization-Elicits-Large-Model-Reasoning-Ability-in-VibeThinker-1-5B/","children":"[논문리뷰] Tiny Model, Big Logic: Diversity-Driven Optimization Elicits Large-Model   Reasoning Ability in VibeThinker-1.5B"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Tiny Model, Big Logic: Diversity-Driven Optimization Elicits Large-Model   Reasoning Ability in VibeThinker-1.5B' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-12 00:00:00+0900+0900","children":"2025년 11월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Small Language Models",{"className":"page__taxonomy-item","children":["#","Small Language Models"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Diversity Optimization",{"className":"page__taxonomy-item","children":["#","Diversity Optimization"]}],["$","span","Supervised Fine-Tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning (SFT)"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Spectrum-to-Signal Principle (SSP)",{"className":"page__taxonomy-item","children":["#","Spectrum-to-Signal Principle (SSP)"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}]]}]]}]]}],["$","article","2025-11-12-TimeSearch-R-Adaptive-Temporal-Search-for-Long-Form-Video-Understanding-via-Self-Verification-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-12-TimeSearch-R-Adaptive-Temporal-Search-for-Long-Form-Video-Understanding-via-Self-Verification-Reinforcement-Learning/","children":"[논문리뷰] TimeSearch-R: Adaptive Temporal Search for Long-Form Video Understanding via Self-Verification Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'TimeSearch-R: Adaptive Temporal Search for Long-Form Video Understanding via Self-Verification Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-12 00:00:00+0900+0900","children":"2025년 11월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Long-form Video Understanding",{"className":"page__taxonomy-item","children":["#","Long-form Video Understanding"]}],["$","span","Temporal Search",{"className":"page__taxonomy-item","children":["#","Temporal Search"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Self-Verification",{"className":"page__taxonomy-item","children":["#","Self-Verification"]}],["$","span","Video-Language Models",{"className":"page__taxonomy-item","children":["#","Video-Language Models"]}],["$","span","Adaptive Search",{"className":"page__taxonomy-item","children":["#","Adaptive Search"]}],["$","span","Interleaved Reasoning",{"className":"page__taxonomy-item","children":["#","Interleaved Reasoning"]}]]}]]}]]}],["$","article","2025-11-12-The-Path-Not-Taken-RLVR-Provably-Learns-Off-the-Principals",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-12-The-Path-Not-Taken-RLVR-Provably-Learns-Off-the-Principals/","children":"[논문리뷰] The Path Not Taken: RLVR Provably Learns Off the Principals"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'The Path Not Taken: RLVR Provably Learns Off the Principals' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-12 00:00:00+0900+0900","children":"2025년 11월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Parameter-Efficient Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Parameter-Efficient Fine-Tuning"]}],["$","span","Optimization Bias",{"className":"page__taxonomy-item","children":["#","Optimization Bias"]}],["$","span","Spectral Geometry",{"className":"page__taxonomy-item","children":["#","Spectral Geometry"]}],["$","span","Model Sparsity",{"className":"page__taxonomy-item","children":["#","Model Sparsity"]}],["$","span","LoRA",{"className":"page__taxonomy-item","children":["#","LoRA"]}]]}]]}]]}],["$","article","2025-11-12-Optimizing-Diversity-and-Quality-through-Base-Aligned-Model-Collaboration",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-12-Optimizing-Diversity-and-Quality-through-Base-Aligned-Model-Collaboration/","children":"[논문리뷰] Optimizing Diversity and Quality through Base-Aligned Model Collaboration"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jonathan May이 [arXiv]에 게시한 'Optimizing Diversity and Quality through Base-Aligned Model Collaboration' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-12 00:00:00+0900+0900","children":"2025년 11월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Diversity-Quality Trade-off",{"className":"page__taxonomy-item","children":["#","Diversity-Quality Trade-off"]}],["$","span","Model Collaboration",{"className":"page__taxonomy-item","children":["#","Model Collaboration"]}],["$","span","Inference Optimization",{"className":"page__taxonomy-item","children":["#","Inference Optimization"]}],["$","span","Routing Strategy",{"className":"page__taxonomy-item","children":["#","Routing Strategy"]}],["$","span","Text Generation",{"className":"page__taxonomy-item","children":["#","Text Generation"]}]]}]]}]]}],["$","article","2025-11-12-KLASS-KL-Guided-Fast-Inference-in-Masked-Diffusion-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-12-KLASS-KL-Guided-Fast-Inference-in-Masked-Diffusion-Models/","children":"[논문리뷰] KLASS: KL-Guided Fast Inference in Masked Diffusion Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'KLASS: KL-Guided Fast Inference in Masked Diffusion Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-12 00:00:00+0900+0900","children":"2025년 11월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Masked Diffusion Models",{"className":"page__taxonomy-item","children":["#","Masked Diffusion Models"]}],["$","span","Fast Inference",{"className":"page__taxonomy-item","children":["#","Fast Inference"]}],["$","span","Adaptive Sampling",{"className":"page__taxonomy-item","children":["#","Adaptive Sampling"]}],["$","span","KL Divergence",{"className":"page__taxonomy-item","children":["#","KL Divergence"]}],["$","span","Confidence Score",{"className":"page__taxonomy-item","children":["#","Confidence Score"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Efficient Sampling",{"className":"page__taxonomy-item","children":["#","Efficient Sampling"]}]]}]]}]]}],["$","article","2025-11-12-Intelligence-per-Watt-Measuring-Intelligence-Efficiency-of-Local-AI",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-12-Intelligence-per-Watt-Measuring-Intelligence-Efficiency-of-Local-AI/","children":"[논문리뷰] Intelligence per Watt: Measuring Intelligence Efficiency of Local AI"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Intelligence per Watt: Measuring Intelligence Efficiency of Local AI' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-12 00:00:00+0900+0900","children":"2025년 11월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Local AI",{"className":"page__taxonomy-item","children":["#","Local AI"]}],["$","span","LLM Inference",{"className":"page__taxonomy-item","children":["#","LLM Inference"]}],["$","span","Intelligence per Watt",{"className":"page__taxonomy-item","children":["#","Intelligence per Watt"]}],["$","span","Edge Computing",{"className":"page__taxonomy-item","children":["#","Edge Computing"]}],["$","span","Hybrid Cloud",{"className":"page__taxonomy-item","children":["#","Hybrid Cloud"]}],["$","span","AI Efficiency",{"className":"page__taxonomy-item","children":["#","AI Efficiency"]}],["$","span","Hardware Benchmarking",{"className":"page__taxonomy-item","children":["#","Hardware Benchmarking"]}],["$","span","Query Routing",{"className":"page__taxonomy-item","children":["#","Query Routing"]}]]}]]}]]}],["$","article","2025-11-12-Grounding-Computer-Use-Agents-on-Human-Demonstrations",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-12-Grounding-Computer-Use-Agents-on-Human-Demonstrations/","children":"[논문리뷰] Grounding Computer Use Agents on Human Demonstrations"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Grounding Computer Use Agents on Human Demonstrations' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-12 00:00:00+0900+0900","children":"2025년 11월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Computer Use Agents",{"className":"page__taxonomy-item","children":["#","Computer Use Agents"]}],["$","span","UI Grounding",{"className":"page__taxonomy-item","children":["#","UI Grounding"]}],["$","span","Desktop Applications",{"className":"page__taxonomy-item","children":["#","Desktop Applications"]}],["$","span","Human Demonstrations",{"className":"page__taxonomy-item","children":["#","Human Demonstrations"]}],["$","span","Large-Scale Dataset",{"className":"page__taxonomy-item","children":["#","Large-Scale Dataset"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}]]}]]}]]}],["$","article","2025-11-12-DynaAct-Large-Language-Model-Reasoning-with-Dynamic-Action-Spaces",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-12-DynaAct-Large-Language-Model-Reasoning-with-Dynamic-Action-Spaces/","children":"[논문리뷰] DynaAct: Large Language Model Reasoning with Dynamic Action Spaces"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Lingpeng Kong이 [arXiv]에 게시한 'DynaAct: Large Language Model Reasoning with Dynamic Action Spaces' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-12 00:00:00+0900+0900","children":"2025년 11월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Sequential Reasoning",{"className":"page__taxonomy-item","children":["#","Sequential Reasoning"]}],["$","span","Action Space Construction",{"className":"page__taxonomy-item","children":["#","Action Space Construction"]}],["$","span","Submodular Optimization",{"className":"page__taxonomy-item","children":["#","Submodular Optimization"]}],["$","span","Markov Decision Process",{"className":"page__taxonomy-item","children":["#","Markov Decision Process"]}],["$","span","Monte Carlo Tree Search",{"className":"page__taxonomy-item","children":["#","Monte Carlo Tree Search"]}],["$","span","Utility-Diversity Trade-off",{"className":"page__taxonomy-item","children":["#","Utility-Diversity Trade-off"]}]]}]]}]]}],["$","article","2025-11-12-BiCA-Effective-Biomedical-Dense-Retrieval-with-Citation-Aware-Hard-Negatives",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-12-BiCA-Effective-Biomedical-Dense-Retrieval-with-Citation-Aware-Hard-Negatives/","children":"[논문리뷰] BiCA: Effective Biomedical Dense Retrieval with Citation-Aware Hard Negatives"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'BiCA: Effective Biomedical Dense Retrieval with Citation-Aware Hard Negatives' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-12 00:00:00+0900+0900","children":"2025년 11월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Dense Retrieval",{"className":"page__taxonomy-item","children":["#","Dense Retrieval"]}],["$","span","Biomedical IR",{"className":"page__taxonomy-item","children":["#","Biomedical IR"]}],["$","span","Hard Negative Mining",{"className":"page__taxonomy-item","children":["#","Hard Negative Mining"]}],["$","span","Citation Networks",{"className":"page__taxonomy-item","children":["#","Citation Networks"]}],["$","span","PubMed",{"className":"page__taxonomy-item","children":["#","PubMed"]}],["$","span","Zero-shot Retrieval",{"className":"page__taxonomy-item","children":["#","Zero-shot Retrieval"]}],["$","span","Transformer Models",{"className":"page__taxonomy-item","children":["#","Transformer Models"]}]]}]]}]]}],["$","article","2025-11-12-Beyond-Fact-Retrieval-Episodic-Memory-for-RAG-with-Generative-Semantic-Workspaces",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-12-Beyond-Fact-Retrieval-Episodic-Memory-for-RAG-with-Generative-Semantic-Workspaces/","children":"[논문리뷰] Beyond Fact Retrieval: Episodic Memory for RAG with Generative Semantic Workspaces"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Vwani Roychowdhury이 [arXiv]에 게시한 'Beyond Fact Retrieval: Episodic Memory for RAG with Generative Semantic Workspaces' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-12 00:00:00+0900+0900","children":"2025년 11월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Retrieval-Augmented Generation (RAG)",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation (RAG)"]}],["$","span","Episodic Memory",{"className":"page__taxonomy-item","children":["#","Episodic Memory"]}],["$","span","Generative Semantic Workspaces (GSW)",{"className":"page__taxonomy-item","children":["#","Generative Semantic Workspaces (GSW)"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Question Answering (QA)",{"className":"page__taxonomy-item","children":["#","Question Answering (QA)"]}],["$","span","Semantic Modeling",{"className":"page__taxonomy-item","children":["#","Semantic Modeling"]}],["$","span","Knowledge Graph",{"className":"page__taxonomy-item","children":["#","Knowledge Graph"]}]]}]]}]]}],["$","article","2025-11-12-Beyond-English-Toward-Inclusive-and-Scalable-Multilingual-Machine-Translation-with-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-12-Beyond-English-Toward-Inclusive-and-Scalable-Multilingual-Machine-Translation-with-LLMs/","children":"[논문리뷰] Beyond English: Toward Inclusive and Scalable Multilingual Machine Translation with LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Beyond English: Toward Inclusive and Scalable Multilingual Machine Translation with LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-12 00:00:00+0900+0900","children":"2025년 11월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multilingual Machine Translation",{"className":"page__taxonomy-item","children":["#","Multilingual Machine Translation"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Directional Degeneration",{"className":"page__taxonomy-item","children":["#","Directional Degeneration"]}],["$","span","Strategic Downsampling",{"className":"page__taxonomy-item","children":["#","Strategic Downsampling"]}],["$","span","Parallel Multilingual Prompting",{"className":"page__taxonomy-item","children":["#","Parallel Multilingual Prompting"]}],["$","span","Chinese-centric MT",{"className":"page__taxonomy-item","children":["#","Chinese-centric MT"]}],["$","span","Cross-lingual Transfer",{"className":"page__taxonomy-item","children":["#","Cross-lingual Transfer"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}]]}]]}]]}],["$","article","2025-11-12-Adaptive-Multi-Agent-Response-Refinement-in-Conversational-Systems",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-12-Adaptive-Multi-Agent-Response-Refinement-in-Conversational-Systems/","children":"[논문리뷰] Adaptive Multi-Agent Response Refinement in Conversational Systems"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Adaptive Multi-Agent Response Refinement in Conversational Systems' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-12 00:00:00+0900+0900","children":"2025년 11월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Conversational AI",{"className":"page__taxonomy-item","children":["#","Conversational AI"]}],["$","span","Response Refinement",{"className":"page__taxonomy-item","children":["#","Response Refinement"]}],["$","span","Dynamic Agent Selection",{"className":"page__taxonomy-item","children":["#","Dynamic Agent Selection"]}],["$","span","Persona Alignment",{"className":"page__taxonomy-item","children":["#","Persona Alignment"]}],["$","span","Factual Grounding",{"className":"page__taxonomy-item","children":["#","Factual Grounding"]}],["$","span","Coherence",{"className":"page__taxonomy-item","children":["#","Coherence"]}]]}]]}]]}],["$","article","2025-11-11-VADER-Towards-Causal-Video-Anomaly-Understanding-with-Relation-Aware-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-VADER-Towards-Causal-Video-Anomaly-Understanding-with-Relation-Aware-Large-Language-Models/","children":"[논문리뷰] VADER: Towards Causal Video Anomaly Understanding with Relation-Aware   Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'VADER: Towards Causal Video Anomaly Understanding with Relation-Aware   Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-11 00:00:00+0900+0900","children":"2025년 11월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Anomaly Understanding",{"className":"page__taxonomy-item","children":["#","Video Anomaly Understanding"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Causal Reasoning",{"className":"page__taxonomy-item","children":["#","Causal Reasoning"]}],["$","span","Relation-Aware",{"className":"page__taxonomy-item","children":["#","Relation-Aware"]}],["$","span","Keyframe Sampling",{"className":"page__taxonomy-item","children":["#","Keyframe Sampling"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Scene Graphs",{"className":"page__taxonomy-item","children":["#","Scene Graphs"]}]]}]]}]]}],["$","article","2025-11-11-The-Station-An-Open-World-Environment-for-AI-Driven-Discovery",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-The-Station-An-Open-World-Environment-for-AI-Driven-Discovery/","children":"[논문리뷰] The Station: An Open-World Environment for AI-Driven Discovery"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"wydu이 [arXiv]에 게시한 'The Station: An Open-World Environment for AI-Driven Discovery' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-11 00:00:00+0900+0900","children":"2025년 11월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-Agent System",{"className":"page__taxonomy-item","children":["#","Multi-Agent System"]}],["$","span","Open-World Environment",{"className":"page__taxonomy-item","children":["#","Open-World Environment"]}],["$","span","Scientific Discovery",{"className":"page__taxonomy-item","children":["#","Scientific Discovery"]}],["$","span","AI-Driven Research",{"className":"page__taxonomy-item","children":["#","AI-Driven Research"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Emergent Behavior",{"className":"page__taxonomy-item","children":["#","Emergent Behavior"]}],["$","span","State-of-the-Art (SOTA)",{"className":"page__taxonomy-item","children":["#","State-of-the-Art (SOTA)"]}]]}]]}]]}],["$","article","2025-11-11-Teaching-Pretrained-Language-Models-to-Think-Deeper-with-Retrofitted-Recurrence",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-Teaching-Pretrained-Language-Models-to-Think-Deeper-with-Retrofitted-Recurrence/","children":"[논문리뷰] Teaching Pretrained Language Models to Think Deeper with Retrofitted   Recurrence"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Teaching Pretrained Language Models to Think Deeper with Retrofitted   Recurrence' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-11 00:00:00+0900+0900","children":"2025년 11월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Recurrent Language Models",{"className":"page__taxonomy-item","children":["#","Recurrent Language Models"]}],["$","span","Pretrained Models",{"className":"page__taxonomy-item","children":["#","Pretrained Models"]}],["$","span","Model Surgery",{"className":"page__taxonomy-item","children":["#","Model Surgery"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Test-Time Compute Scaling",{"className":"page__taxonomy-item","children":["#","Test-Time Compute Scaling"]}],["$","span","Mathematics Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematics Reasoning"]}],["$","span","Efficient Training",{"className":"page__taxonomy-item","children":["#","Efficient Training"]}],["$","span","Depth Recurrence",{"className":"page__taxonomy-item","children":["#","Depth Recurrence"]}]]}]]}]]}],["$","article","2025-11-11-SofT-GRPO-Surpassing-Discrete-Token-LLM-Reinforcement-Learning-via-Gumbel-Reparameterized-Soft-Thinking-Policy-Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-SofT-GRPO-Surpassing-Discrete-Token-LLM-Reinforcement-Learning-via-Gumbel-Reparameterized-Soft-Thinking-Policy-Optimization/","children":"[논문리뷰] SofT-GRPO: Surpassing Discrete-Token LLM Reinforcement Learning via   Gumbel-Reparameterized Soft-Thinking Policy Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'SofT-GRPO: Surpassing Discrete-Token LLM Reinforcement Learning via   Gumbel-Reparameterized Soft-Thinking Policy Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-11 00:00:00+0900+0900","children":"2025년 11월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Soft-Thinking",{"className":"page__taxonomy-item","children":["#","Soft-Thinking"]}],["$","span","Gumbel Reparameterization",{"className":"page__taxonomy-item","children":["#","Gumbel Reparameterization"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Chain-of-Thought (CoT)",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought (CoT)"]}],["$","span","GRPO",{"className":"page__taxonomy-item","children":["#","GRPO"]}]]}]]}]]}],["$","article","2025-11-11-SWE-fficiency-Can-Language-Models-Optimize-Real-World-Repositories-on-Real-Workloads",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-SWE-fficiency-Can-Language-Models-Optimize-Real-World-Repositories-on-Real-Workloads/","children":"[논문리뷰] SWE-fficiency: Can Language Models Optimize Real-World Repositories on Real Workloads?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ofir Press이 [arXiv]에 게시한 'SWE-fficiency: Can Language Models Optimize Real-World Repositories on Real Workloads?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-11 00:00:00+0900+0900","children":"2025년 11월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","소프트웨어 성능 최적화",{"className":"page__taxonomy-item","children":["#","소프트웨어 성능 최적화"]}],["$","span","언어 모델",{"className":"page__taxonomy-item","children":["#","언어 모델"]}],["$","span","저장소 수준 추론",{"className":"page__taxonomy-item","children":["#","저장소 수준 추론"]}],["$","span","벤치마크",{"className":"page__taxonomy-item","children":["#","벤치마크"]}],["$","span","실제 워크로드",{"className":"page__taxonomy-item","children":["#","실제 워크로드"]}],["$","span","코드 정확성",{"className":"page__taxonomy-item","children":["#","코드 정확성"]}],["$","span","속도 향상",{"className":"page__taxonomy-item","children":["#","속도 향상"]}],["$","span","코드 최적화",{"className":"page__taxonomy-item","children":["#","코드 최적화"]}]]}]]}]]}],["$","article","2025-11-11-Routing-Manifold-Alignment-Improves-Generalization-of-Mixture-of-Experts-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-Routing-Manifold-Alignment-Improves-Generalization-of-Mixture-of-Experts-LLMs/","children":"[논문리뷰] Routing Manifold Alignment Improves Generalization of Mixture-of-Experts   LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ziyue Li이 [arXiv]에 게시한 'Routing Manifold Alignment Improves Generalization of Mixture-of-Experts   LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-11 00:00:00+0900+0900","children":"2025년 11월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Mixture-of-Experts (MoE)",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts (MoE)"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Router Optimization",{"className":"page__taxonomy-item","children":["#","Router Optimization"]}],["$","span","Manifold Regularization",{"className":"page__taxonomy-item","children":["#","Manifold Regularization"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Post-training Fine-tuning",{"className":"page__taxonomy-item","children":["#","Post-training Fine-tuning"]}],["$","span","Task Embedding Alignment",{"className":"page__taxonomy-item","children":["#","Task Embedding Alignment"]}]]}]]}]]}],["$","article","2025-11-11-Robot-Learning-from-a-Physical-World-Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-Robot-Learning-from-a-Physical-World-Model/","children":"[논문리뷰] Robot Learning from a Physical World Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Robot Learning from a Physical World Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-11 00:00:00+0900+0900","children":"2025년 11월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Robot Learning",{"className":"page__taxonomy-item","children":["#","Robot Learning"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Physical World Model",{"className":"page__taxonomy-item","children":["#","Physical World Model"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Zero-shot Manipulation",{"className":"page__taxonomy-item","children":["#","Zero-shot Manipulation"]}],["$","span","Object-Centric Learning",{"className":"page__taxonomy-item","children":["#","Object-Centric Learning"]}],["$","span","Sim-to-Real",{"className":"page__taxonomy-item","children":["#","Sim-to-Real"]}]]}]]}]]}],["$","article","2025-11-11-Reinforcement-Learning-Improves-Traversal-of-Hierarchical-Knowledge-in-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-Reinforcement-Learning-Improves-Traversal-of-Hierarchical-Knowledge-in-LLMs/","children":"[논문리뷰] Reinforcement Learning Improves Traversal of Hierarchical Knowledge in LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Reinforcement Learning Improves Traversal of Hierarchical Knowledge in LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-11 00:00:00+0900+0900","children":"2025년 11월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Hierarchical Knowledge",{"className":"page__taxonomy-item","children":["#","Hierarchical Knowledge"]}],["$","span","Knowledge Traversal",{"className":"page__taxonomy-item","children":["#","Knowledge Traversal"]}],["$","span","Structured Prompting",{"className":"page__taxonomy-item","children":["#","Structured Prompting"]}],["$","span","Internal Representations",{"className":"page__taxonomy-item","children":["#","Internal Representations"]}],["$","span","Alignment Tax",{"className":"page__taxonomy-item","children":["#","Alignment Tax"]}]]}]]}]]}],["$","article","2025-11-11-RedOne-2-0-Rethinking-Domain-specific-LLM-Post-Training-in-Social-Networking-Services",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-RedOne-2-0-Rethinking-Domain-specific-LLM-Post-Training-in-Social-Networking-Services/","children":"[논문리뷰] RedOne 2.0: Rethinking Domain-specific LLM Post-Training in Social   Networking Services"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zijie Meng이 [arXiv]에 게시한 'RedOne 2.0: Rethinking Domain-specific LLM Post-Training in Social   Networking Services' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-11 00:00:00+0900+0900","children":"2025년 11월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Post-Training",{"className":"page__taxonomy-item","children":["#","LLM Post-Training"]}],["$","span","Domain Adaptation",{"className":"page__taxonomy-item","children":["#","Domain Adaptation"]}],["$","span","Social Networking Services",{"className":"page__taxonomy-item","children":["#","Social Networking Services"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Supervised Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning"]}],["$","span","Catastrophic Forgetting",{"className":"page__taxonomy-item","children":["#","Catastrophic Forgetting"]}],["$","span","Data Efficiency",{"className":"page__taxonomy-item","children":["#","Data Efficiency"]}]]}]]}]]}],["$","article","2025-11-11-Reasoning-with-Confidence-Efficient-Verification-of-LLM-Reasoning-Steps-via-Uncertainty-Heads",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-Reasoning-with-Confidence-Efficient-Verification-of-LLM-Reasoning-Steps-via-Uncertainty-Heads/","children":"[논문리뷰] Reasoning with Confidence: Efficient Verification of LLM Reasoning Steps   via Uncertainty Heads"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiaheng Zhang이 [arXiv]에 게시한 'Reasoning with Confidence: Efficient Verification of LLM Reasoning Steps   via Uncertainty Heads' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-11 00:00:00+0900+0900","children":"2025년 11월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Reasoning Verification",{"className":"page__taxonomy-item","children":["#","LLM Reasoning Verification"]}],["$","span","Uncertainty Quantification (UQ)",{"className":"page__taxonomy-item","children":["#","Uncertainty Quantification (UQ)"]}],["$","span","UHeads",{"className":"page__taxonomy-item","children":["#","UHeads"]}],["$","span","Process Reward Models (PRMs)",{"className":"page__taxonomy-item","children":["#","Process Reward Models (PRMs)"]}],["$","span","Chain-of-Thought (CoT)",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought (CoT)"]}],["$","span","Self-Supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-Supervised Learning"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}],["$","span","Domain Generalization",{"className":"page__taxonomy-item","children":["#","Domain Generalization"]}]]}]]}]]}],["$","article","2025-11-11-RLoop-An-Self-Improving-Framework-for-Reinforcement-Learning-with-Iterative-Policy-Initialization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-RLoop-An-Self-Improving-Framework-for-Reinforcement-Learning-with-Iterative-Policy-Initialization/","children":"[논문리뷰] RLoop: An Self-Improving Framework for Reinforcement Learning with   Iterative Policy Initialization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wenhao Huang이 [arXiv]에 게시한 'RLoop: An Self-Improving Framework for Reinforcement Learning with   Iterative Policy Initialization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-11 00:00:00+0900+0900","children":"2025년 11월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Overfitting",{"className":"page__taxonomy-item","children":["#","Overfitting"]}],["$","span","Catastrophic Forgetting",{"className":"page__taxonomy-item","children":["#","Catastrophic Forgetting"]}],["$","span","Iterative Policy Optimization",{"className":"page__taxonomy-item","children":["#","Iterative Policy Optimization"]}],["$","span","Policy Diversity",{"className":"page__taxonomy-item","children":["#","Policy Diversity"]}]]}]]}]]}],["$","article","2025-11-11-RLVE-Scaling-Up-Reinforcement-Learning-for-Language-Models-with-Adaptive-Verifiable-Environments",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-RLVE-Scaling-Up-Reinforcement-Learning-for-Language-Models-with-Adaptive-Verifiable-Environments/","children":"[논문리뷰] RLVE: Scaling Up Reinforcement Learning for Language Models with   Adaptive Verifiable Environments"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shuyue Stella Li이 [arXiv]에 게시한 'RLVE: Scaling Up Reinforcement Learning for Language Models with   Adaptive Verifiable Environments' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-11 00:00:00+0900+0900","children":"2025년 11월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Language Models",{"className":"page__taxonomy-item","children":["#","Language Models"]}],["$","span","Adaptive Environments",{"className":"page__taxonomy-item","children":["#","Adaptive Environments"]}],["$","span","Verifiable Environments",{"className":"page__taxonomy-item","children":["#","Verifiable Environments"]}],["$","span","Procedural Generation",{"className":"page__taxonomy-item","children":["#","Procedural Generation"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}]]}]]}]]}],["$","article","2025-11-11-Omni-AVSR-Towards-Unified-Multimodal-Speech-Recognition-with-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-Omni-AVSR-Towards-Unified-Multimodal-Speech-Recognition-with-Large-Language-Models/","children":"[논문리뷰] Omni-AVSR: Towards Unified Multimodal Speech Recognition with Large   Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Omni-AVSR: Towards Unified Multimodal Speech Recognition with Large   Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-11 00:00:00+0900+0900","children":"2025년 11월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Speech Recognition",{"className":"page__taxonomy-item","children":["#","Multimodal Speech Recognition"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Audio-Visual Speech Recognition",{"className":"page__taxonomy-item","children":["#","Audio-Visual Speech Recognition"]}],["$","span","LoRA",{"className":"page__taxonomy-item","children":["#","LoRA"]}],["$","span","Matryoshka Representation Learning",{"className":"page__taxonomy-item","children":["#","Matryoshka Representation Learning"]}],["$","span","Elastic Inference",{"className":"page__taxonomy-item","children":["#","Elastic Inference"]}],["$","span","Parameter-Efficient Adaptation",{"className":"page__taxonomy-item","children":["#","Parameter-Efficient Adaptation"]}]]}]]}]]}],["$","article","2025-11-11-NURBGen-High-Fidelity-Text-to-CAD-Generation-through-LLM-Driven-NURBS-Modeling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-NURBGen-High-Fidelity-Text-to-CAD-Generation-through-LLM-Driven-NURBS-Modeling/","children":"[논문리뷰] NURBGen: High-Fidelity Text-to-CAD Generation through LLM-Driven NURBS   Modeling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'NURBGen: High-Fidelity Text-to-CAD Generation through LLM-Driven NURBS   Modeling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-11 00:00:00+0900+0900","children":"2025년 11월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-CAD",{"className":"page__taxonomy-item","children":["#","Text-to-CAD"]}],["$","span","NURBS Modeling",{"className":"page__taxonomy-item","children":["#","NURBS Modeling"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Geometric Deep Learning",{"className":"page__taxonomy-item","children":["#","Geometric Deep Learning"]}],["$","span","Boundary Representation",{"className":"page__taxonomy-item","children":["#","Boundary Representation"]}],["$","span","Hybrid Representation",{"className":"page__taxonomy-item","children":["#","Hybrid Representation"]}],["$","span","CAD Generation",{"className":"page__taxonomy-item","children":["#","CAD Generation"]}]]}]]}]]}],["$","article","2025-11-11-MVU-Eval-Towards-Multi-Video-Understanding-Evaluation-for-Multimodal-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-MVU-Eval-Towards-Multi-Video-Understanding-Evaluation-for-Multimodal-LLMs/","children":"[논문리뷰] MVU-Eval: Towards Multi-Video Understanding Evaluation for Multimodal   LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'MVU-Eval: Towards Multi-Video Understanding Evaluation for Multimodal   LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-11 00:00:00+0900+0900","children":"2025년 11월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models (MLLMs)"]}],["$","span","Multi-Video Understanding",{"className":"page__taxonomy-item","children":["#","Multi-Video Understanding"]}],["$","span","Evaluation Benchmark",{"className":"page__taxonomy-item","children":["#","Evaluation Benchmark"]}],["$","span","Video Perception",{"className":"page__taxonomy-item","children":["#","Video Perception"]}],["$","span","Video Reasoning",{"className":"page__taxonomy-item","children":["#","Video Reasoning"]}],["$","span","Sports Analytics",{"className":"page__taxonomy-item","children":["#","Sports Analytics"]}],["$","span","Autonomous Driving",{"className":"page__taxonomy-item","children":["#","Autonomous Driving"]}]]}]]}]]}],["$","article","2025-11-11-MPJudge-Towards-Perceptual-Assessment-of-Music-Induced-Paintings",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-MPJudge-Towards-Perceptual-Assessment-of-Music-Induced-Paintings/","children":"[논문리뷰] MPJudge: Towards Perceptual Assessment of Music-Induced Paintings"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'MPJudge: Towards Perceptual Assessment of Music-Induced Paintings' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-11 00:00:00+0900+0900","children":"2025년 11월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Music-Painting Cross-Modal",{"className":"page__taxonomy-item","children":["#","Music-Painting Cross-Modal"]}],["$","span","Perceptual Assessment",{"className":"page__taxonomy-item","children":["#","Perceptual Assessment"]}],["$","span","Modality-Adaptive Normalization",{"className":"page__taxonomy-item","children":["#","Modality-Adaptive Normalization"]}],["$","span","Direct Preference Optimization",{"className":"page__taxonomy-item","children":["#","Direct Preference Optimization"]}],["$","span","Cross-Modal Fusion",{"className":"page__taxonomy-item","children":["#","Cross-Modal Fusion"]}],["$","span","Dataset Annotation",{"className":"page__taxonomy-item","children":["#","Dataset Annotation"]}],["$","span","Affective Computing",{"className":"page__taxonomy-item","children":["#","Affective Computing"]}]]}]]}]]}],["$","article","2025-11-11-Long-Grounded-Thoughts-Distilling-Compositional-Visual-Reasoning-Chains-at-Scale",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-Long-Grounded-Thoughts-Distilling-Compositional-Visual-Reasoning-Chains-at-Scale/","children":"[논문리뷰] Long Grounded Thoughts: Distilling Compositional Visual Reasoning Chains at Scale"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Long Grounded Thoughts: Distilling Compositional Visual Reasoning Chains at Scale' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-11 00:00:00+0900+0900","children":"2025년 11월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Visual Reasoning",{"className":"page__taxonomy-item","children":["#","Visual Reasoning"]}],["$","span","Compositional AI",{"className":"page__taxonomy-item","children":["#","Compositional AI"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Data Synthesis",{"className":"page__taxonomy-item","children":["#","Data Synthesis"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Multimodal Transfer",{"className":"page__taxonomy-item","children":["#","Multimodal Transfer"]}],["$","span","Grounded Reasoning",{"className":"page__taxonomy-item","children":["#","Grounded Reasoning"]}]]}]]}]]}],["$","article","2025-11-11-Llama-Embed-Nemotron-8B-A-Universal-Text-Embedding-Model-for-Multilingual-and-Cross-Lingual-Tasks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-Llama-Embed-Nemotron-8B-A-Universal-Text-Embedding-Model-for-Multilingual-and-Cross-Lingual-Tasks/","children":"[논문리뷰] Llama-Embed-Nemotron-8B: A Universal Text Embedding Model for   Multilingual and Cross-Lingual Tasks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Llama-Embed-Nemotron-8B: A Universal Text Embedding Model for   Multilingual and Cross-Lingual Tasks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-11 00:00:00+0900+0900","children":"2025년 11월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text Embedding",{"className":"page__taxonomy-item","children":["#","Text Embedding"]}],["$","span","Multilingual",{"className":"page__taxonomy-item","children":["#","Multilingual"]}],["$","span","Cross-Lingual",{"className":"page__taxonomy-item","children":["#","Cross-Lingual"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Model Merging",{"className":"page__taxonomy-item","children":["#","Model Merging"]}],["$","span","Synthetic Data Generation",{"className":"page__taxonomy-item","children":["#","Synthetic Data Generation"]}],["$","span","Instruction-Tuning",{"className":"page__taxonomy-item","children":["#","Instruction-Tuning"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}]]}]]}]]}],["$","article","2025-11-11-LUT-LLM-Efficient-Large-Language-Model-Inference-with-Memory-based-Computations-on-FPGAs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-LUT-LLM-Efficient-Large-Language-Model-Inference-with-Memory-based-Computations-on-FPGAs/","children":"[논문리뷰] LUT-LLM: Efficient Large Language Model Inference with Memory-based   Computations on FPGAs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jason Cong이 [arXiv]에 게시한 'LUT-LLM: Efficient Large Language Model Inference with Memory-based   Computations on FPGAs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-11 00:00:00+0900+0900","children":"2025년 11월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","FPGA",{"className":"page__taxonomy-item","children":["#","FPGA"]}],["$","span","Large Language Models (LLM)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLM)"]}],["$","span","Inference Optimization",{"className":"page__taxonomy-item","children":["#","Inference Optimization"]}],["$","span","Memory-based Computation",{"className":"page__taxonomy-item","children":["#","Memory-based Computation"]}],["$","span","Vector Quantization",{"className":"page__taxonomy-item","children":["#","Vector Quantization"]}],["$","span","Table Lookup",{"className":"page__taxonomy-item","children":["#","Table Lookup"]}],["$","span","Hardware Acceleration",{"className":"page__taxonomy-item","children":["#","Hardware Acceleration"]}]]}]]}]]}],["$","article","2025-11-11-IterResearch-Rethinking-Long-Horizon-Agents-via-Markovian-State-Reconstruction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-IterResearch-Rethinking-Long-Horizon-Agents-via-Markovian-State-Reconstruction/","children":"[논문리뷰] IterResearch: Rethinking Long-Horizon Agents via Markovian State   Reconstruction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Haotian Xu이 [arXiv]에 게시한 'IterResearch: Rethinking Long-Horizon Agents via Markovian State   Reconstruction' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-11 00:00:00+0900+0900","children":"2025년 11월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Long-Horizon Agents",{"className":"page__taxonomy-item","children":["#","Long-Horizon Agents"]}],["$","span","Markov Decision Process",{"className":"page__taxonomy-item","children":["#","Markov Decision Process"]}],["$","span","Workspace Reconstruction",{"className":"page__taxonomy-item","children":["#","Workspace Reconstruction"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Context Management",{"className":"page__taxonomy-item","children":["#","Context Management"]}],["$","span","Iterative Deep Research",{"className":"page__taxonomy-item","children":["#","Iterative Deep Research"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Efficiency-Aware Policy Optimization",{"className":"page__taxonomy-item","children":["#","Efficiency-Aware Policy Optimization"]}]]}]]}]]}],["$","article","2025-11-11-HaluMem-Evaluating-Hallucinations-in-Memory-Systems-of-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-HaluMem-Evaluating-Hallucinations-in-Memory-Systems-of-Agents/","children":"[논문리뷰] HaluMem: Evaluating Hallucinations in Memory Systems of Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'HaluMem: Evaluating Hallucinations in Memory Systems of Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-11 00:00:00+0900+0900","children":"2025년 11월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Memory Systems",{"className":"page__taxonomy-item","children":["#","Memory Systems"]}],["$","span","AI Agents",{"className":"page__taxonomy-item","children":["#","AI Agents"]}],["$","span","Hallucination Detection",{"className":"page__taxonomy-item","children":["#","Hallucination Detection"]}],["$","span","Evaluation Benchmark",{"className":"page__taxonomy-item","children":["#","Evaluation Benchmark"]}],["$","span","Long-term Memory",{"className":"page__taxonomy-item","children":["#","Long-term Memory"]}],["$","span","Memory Extraction",{"className":"page__taxonomy-item","children":["#","Memory Extraction"]}],["$","span","Memory Updating",{"className":"page__taxonomy-item","children":["#","Memory Updating"]}],["$","span","Question Answering",{"className":"page__taxonomy-item","children":["#","Question Answering"]}]]}]]}]]}],["$","article","2025-11-11-Generating-an-Image-From-1000-Words-Enhancing-Text-to-Image-With-Structured-Captions",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-Generating-an-Image-From-1000-Words-Enhancing-Text-to-Image-With-Structured-Captions/","children":"[논문리뷰] Generating an Image From 1,000 Words: Enhancing Text-to-Image With   Structured Captions"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Generating an Image From 1,000 Words: Enhancing Text-to-Image With   Structured Captions' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-11 00:00:00+0900+0900","children":"2025년 11월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Structured Captions",{"className":"page__taxonomy-item","children":["#","Structured Captions"]}],["$","span","LLM Fusion",{"className":"page__taxonomy-item","children":["#","LLM Fusion"]}],["$","span","Controllability",{"className":"page__taxonomy-item","children":["#","Controllability"]}],["$","span","Image Generation Evaluation",{"className":"page__taxonomy-item","children":["#","Image Generation Evaluation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","DimFusion",{"className":"page__taxonomy-item","children":["#","DimFusion"]}],["$","span","TaBR",{"className":"page__taxonomy-item","children":["#","TaBR"]}]]}]]}]]}],["$","article","2025-11-11-FLEX-Continuous-Agent-Evolution-via-Forward-Learning-from-Experience",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-FLEX-Continuous-Agent-Evolution-via-Forward-Learning-from-Experience/","children":"[논문리뷰] FLEX: Continuous Agent Evolution via Forward Learning from Experience"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiangjie Chen이 [arXiv]에 게시한 'FLEX: Continuous Agent Evolution via Forward Learning from Experience' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-11 00:00:00+0900+0900","children":"2025년 11월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Continuous Learning",{"className":"page__taxonomy-item","children":["#","Continuous Learning"]}],["$","span","Experience Library",{"className":"page__taxonomy-item","children":["#","Experience Library"]}],["$","span","Forward Learning",{"className":"page__taxonomy-item","children":["#","Forward Learning"]}],["$","span","Meta-MDP",{"className":"page__taxonomy-item","children":["#","Meta-MDP"]}],["$","span","Knowledge Distillation",{"className":"page__taxonomy-item","children":["#","Knowledge Distillation"]}],["$","span","Non-parametric Adaptation",{"className":"page__taxonomy-item","children":["#","Non-parametric Adaptation"]}]]}]]}]]}],["$","article","2025-11-11-Do-LLMs-Feel-Teaching-Emotion-Recognition-with-Prompts-Retrieval-and-Curriculum-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-Do-LLMs-Feel-Teaching-Emotion-Recognition-with-Prompts-Retrieval-and-Curriculum-Learning/","children":"[논문리뷰] Do LLMs Feel? Teaching Emotion Recognition with Prompts, Retrieval, and   Curriculum Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Do LLMs Feel? Teaching Emotion Recognition with Prompts, Retrieval, and   Curriculum Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-11 00:00:00+0900+0900","children":"2025년 11월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Emotion Recognition in Conversation",{"className":"page__taxonomy-item","children":["#","Emotion Recognition in Conversation"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","Demonstration Retrieval",{"className":"page__taxonomy-item","children":["#","Demonstration Retrieval"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Affective Computing",{"className":"page__taxonomy-item","children":["#","Affective Computing"]}],["$","span","SOTA",{"className":"page__taxonomy-item","children":["#","SOTA"]}]]}]]}]]}],["$","article","2025-11-11-DigiData-Training-and-Evaluating-General-Purpose-Mobile-Control-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-DigiData-Training-and-Evaluating-General-Purpose-Mobile-Control-Agents/","children":"[논문리뷰] DigiData: Training and Evaluating General-Purpose Mobile Control Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DigiData: Training and Evaluating General-Purpose Mobile Control Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-11 00:00:00+0900+0900","children":"2025년 11월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Mobile Control Agents",{"className":"page__taxonomy-item","children":["#","Mobile Control Agents"]}],["$","span","User Interface Automation",{"className":"page__taxonomy-item","children":["#","User Interface Automation"]}],["$","span","Large-Scale Dataset",{"className":"page__taxonomy-item","children":["#","Large-Scale Dataset"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","LLM Judges",{"className":"page__taxonomy-item","children":["#","LLM Judges"]}],["$","span","Data Diversity",{"className":"page__taxonomy-item","children":["#","Data Diversity"]}],["$","span","Task Success Rate",{"className":"page__taxonomy-item","children":["#","Task Success Rate"]}]]}]]}]]}],["$","article","2025-11-11-Diffusion-SDPO-Safeguarded-Direct-Preference-Optimization-for-Diffusion-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-Diffusion-SDPO-Safeguarded-Direct-Preference-Optimization-for-Diffusion-Models/","children":"[논문리뷰] Diffusion-SDPO: Safeguarded Direct Preference Optimization for Diffusion   Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhao Xu이 [arXiv]에 게시한 'Diffusion-SDPO: Safeguarded Direct Preference Optimization for Diffusion   Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-11 00:00:00+0900+0900","children":"2025년 11월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Direct Preference Optimization (DPO)",{"className":"page__taxonomy-item","children":["#","Direct Preference Optimization (DPO)"]}],["$","span","Safeguarded Learning",{"className":"page__taxonomy-item","children":["#","Safeguarded Learning"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Preference Alignment",{"className":"page__taxonomy-item","children":["#","Preference Alignment"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Stable Diffusion",{"className":"page__taxonomy-item","children":["#","Stable Diffusion"]}]]}]]}]]}],["$","article","2025-11-11-DRIVE-Data-Curation-Best-Practices-for-Reinforcement-Learning-with-Verifiable-Reward-in-Competitive-Code-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-DRIVE-Data-Curation-Best-Practices-for-Reinforcement-Learning-with-Verifiable-Reward-in-Competitive-Code-Generation/","children":"[논문리뷰] DRIVE: Data Curation Best Practices for Reinforcement Learning with   Verifiable Reward in Competitive Code Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DRIVE: Data Curation Best Practices for Reinforcement Learning with   Verifiable Reward in Competitive Code Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-11 00:00:00+0900+0900","children":"2025년 11월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning with Verifiable Reward",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning with Verifiable Reward"]}],["$","span","Competitive Programming",{"className":"page__taxonomy-item","children":["#","Competitive Programming"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Entropy Expansion",{"className":"page__taxonomy-item","children":["#","Entropy Expansion"]}]]}]]}]]}],["$","article","2025-11-11-DIMO-Diverse-3D-Motion-Generation-for-Arbitrary-Objects",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-DIMO-Diverse-3D-Motion-Generation-for-Arbitrary-Objects/","children":"[논문리뷰] DIMO: Diverse 3D Motion Generation for Arbitrary Objects"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kostas Daniilidis이 [arXiv]에 게시한 'DIMO: Diverse 3D Motion Generation for Arbitrary Objects' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-11 00:00:00+0900+0900","children":"2025년 11월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Motion Generation",{"className":"page__taxonomy-item","children":["#","3D Motion Generation"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Arbitrary Objects",{"className":"page__taxonomy-item","children":["#","Arbitrary Objects"]}],["$","span","Neural Key Points",{"className":"page__taxonomy-item","children":["#","Neural Key Points"]}],["$","span","Latent Space",{"className":"page__taxonomy-item","children":["#","Latent Space"]}],["$","span","4D Content Generation",{"className":"page__taxonomy-item","children":["#","4D Content Generation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","3D Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","3D Gaussian Splatting"]}]]}]]}]]}],["$","article","2025-11-11-Ariadne-A-Controllable-Framework-for-Probing-and-Extending-VLM-Reasoning-Boundaries",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-Ariadne-A-Controllable-Framework-for-Probing-and-Extending-VLM-Reasoning-Boundaries/","children":"[논문리뷰] Ariadne: A Controllable Framework for Probing and Extending VLM   Reasoning Boundaries"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhengzhong Tu이 [arXiv]에 게시한 'Ariadne: A Controllable Framework for Probing and Extending VLM   Reasoning Boundaries' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-11 00:00:00+0900+0900","children":"2025년 11월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision-Language Models (VLMs)"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}],["$","span","Controllable Framework",{"className":"page__taxonomy-item","children":["#","Controllable Framework"]}],["$","span","RLVR",{"className":"page__taxonomy-item","children":["#","RLVR"]}],["$","span","GRPO",{"className":"page__taxonomy-item","children":["#","GRPO"]}],["$","span","Maze Navigation",{"className":"page__taxonomy-item","children":["#","Maze Navigation"]}],["$","span","Generalization Boundaries",{"className":"page__taxonomy-item","children":["#","Generalization Boundaries"]}]]}]]}]]}],["$","article","2025-11-11-10-Open-Challenges-Steering-the-Future-of-Vision-Language-Action-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-11-10-Open-Challenges-Steering-the-Future-of-Vision-Language-Action-Models/","children":"[논문리뷰] 10 Open Challenges Steering the Future of Vision-Language-Action Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 '10 Open Challenges Steering the Future of Vision-Language-Action Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-11 00:00:00+0900+0900","children":"2025년 11월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action Models"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Multimodal Perception",{"className":"page__taxonomy-item","children":["#","Multimodal Perception"]}],["$","span","Cross-Robot Generalization",{"className":"page__taxonomy-item","children":["#","Cross-Robot Generalization"]}],["$","span","Hierarchical Planning",{"className":"page__taxonomy-item","children":["#","Hierarchical Planning"]}],["$","span","World Models",{"className":"page__taxonomy-item","children":["#","World Models"]}],["$","span","Robot Safety",{"className":"page__taxonomy-item","children":["#","Robot Safety"]}]]}]]}]]}],["$","article","2025-11-10-Visual-Spatial-Tuning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-10-Visual-Spatial-Tuning/","children":"[논문리뷰] Visual Spatial Tuning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Visual Spatial Tuning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-10 00:00:00+0900+0900","children":"2025년 11월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}],["$","span","Spatial Perception",{"className":"page__taxonomy-item","children":["#","Spatial Perception"]}],["$","span","Dataset Creation",{"className":"page__taxonomy-item","children":["#","Dataset Creation"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Visuospatial AI",{"className":"page__taxonomy-item","children":["#","Visuospatial AI"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}]]}]]}]]}],["$","article","2025-11-10-VeriCoT-Neuro-symbolic-Chain-of-Thought-Validation-via-Logical-Consistency-Checks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-10-VeriCoT-Neuro-symbolic-Chain-of-Thought-Validation-via-Logical-Consistency-Checks/","children":"[논문리뷰] VeriCoT: Neuro-symbolic Chain-of-Thought Validation via Logical Consistency Checks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'VeriCoT: Neuro-symbolic Chain-of-Thought Validation via Logical Consistency Checks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-10 00:00:00+0900+0900","children":"2025년 11월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Neuro-symbolic AI",{"className":"page__taxonomy-item","children":["#","Neuro-symbolic AI"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Logical Consistency",{"className":"page__taxonomy-item","children":["#","Logical Consistency"]}],["$","span","Automated Verification",{"className":"page__taxonomy-item","children":["#","Automated Verification"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","SMT Solvers",{"className":"page__taxonomy-item","children":["#","SMT Solvers"]}],["$","span","Self-Reflection",{"className":"page__taxonomy-item","children":["#","Self-Reflection"]}]]}]]}]]}],["$","article","2025-11-10-Towards-Mitigating-Hallucinations-in-Large-Vision-Language-Models-by-Refining-Textual-Embeddings",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-10-Towards-Mitigating-Hallucinations-in-Large-Vision-Language-Models-by-Refining-Textual-Embeddings/","children":"[논문리뷰] Towards Mitigating Hallucinations in Large Vision-Language Models by Refining Textual Embeddings"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiaxin Yuan이 [arXiv]에 게시한 'Towards Mitigating Hallucinations in Large Vision-Language Models by Refining Textual Embeddings' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-10 00:00:00+0900+0900","children":"2025년 11월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Hallucination Mitigation",{"className":"page__taxonomy-item","children":["#","Hallucination Mitigation"]}],["$","span","Large Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Large Vision-Language Models"]}],["$","span","Textual Embeddings",{"className":"page__taxonomy-item","children":["#","Textual Embeddings"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","span","Attention Mechanism",{"className":"page__taxonomy-item","children":["#","Attention Mechanism"]}],["$","span","Visual Grounding",{"className":"page__taxonomy-item","children":["#","Visual Grounding"]}],["$","span","Modality Imbalance",{"className":"page__taxonomy-item","children":["#","Modality Imbalance"]}]]}]]}]]}],["$","article","2025-11-10-Too-Good-to-be-Bad-On-the-Failure-of-LLMs-to-Role-Play-Villains",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-10-Too-Good-to-be-Bad-On-the-Failure-of-LLMs-to-Role-Play-Villains/","children":"[논문리뷰] Too Good to be Bad: On the Failure of LLMs to Role-Play Villains"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Too Good to be Bad: On the Failure of LLMs to Role-Play Villains' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-10 00:00:00+0900+0900","children":"2025년 11월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Role-playing",{"className":"page__taxonomy-item","children":["#","Role-playing"]}],["$","span","Safety Alignment",{"className":"page__taxonomy-item","children":["#","Safety Alignment"]}],["$","span","Villain",{"className":"page__taxonomy-item","children":["#","Villain"]}],["$","span","Persona Simulation",{"className":"page__taxonomy-item","children":["#","Persona Simulation"]}],["$","span","Moral Alignment",{"className":"page__taxonomy-item","children":["#","Moral Alignment"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Character Fidelity",{"className":"page__taxonomy-item","children":["#","Character Fidelity"]}]]}]]}]]}],["$","article","2025-11-10-Real-Time-Reasoning-Agents-in-Evolving-Environments",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-10-Real-Time-Reasoning-Agents-in-Evolving-Environments/","children":"[논문리뷰] Real-Time Reasoning Agents in Evolving Environments"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Real-Time Reasoning Agents in Evolving Environments' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-10 00:00:00+0900+0900","children":"2025년 11월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Real-time Reasoning",{"className":"page__taxonomy-item","children":["#","Real-time Reasoning"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Dynamic Environments",{"className":"page__taxonomy-item","children":["#","Dynamic Environments"]}],["$","span","Dual-System AI",{"className":"page__taxonomy-item","children":["#","Dual-System AI"]}],["$","span","AgileThinker",{"className":"page__taxonomy-item","children":["#","AgileThinker"]}],["$","span","Reactive Planning",{"className":"page__taxonomy-item","children":["#","Reactive Planning"]}],["$","span","Cognitive Load",{"className":"page__taxonomy-item","children":["#","Cognitive Load"]}],["$","span","Time Pressure",{"className":"page__taxonomy-item","children":["#","Time Pressure"]}]]}]]}]]}],["$","article","2025-11-10-Jailbreaking-in-the-Haystack",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-10-Jailbreaking-in-the-Haystack/","children":"[논문리뷰] Jailbreaking in the Haystack"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Alexander Robey이 [arXiv]에 게시한 'Jailbreaking in the Haystack' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-10 00:00:00+0900+0900","children":"2025년 11월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Jailbreaking",{"className":"page__taxonomy-item","children":["#","Jailbreaking"]}],["$","span","LLM Safety",{"className":"page__taxonomy-item","children":["#","LLM Safety"]}],["$","span","Long-Context Models",{"className":"page__taxonomy-item","children":["#","Long-Context Models"]}],["$","span","Positional Bias",{"className":"page__taxonomy-item","children":["#","Positional Bias"]}],["$","span","Attack Success Rate (ASR)",{"className":"page__taxonomy-item","children":["#","Attack Success Rate (ASR)"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","Compute Efficiency",{"className":"page__taxonomy-item","children":["#","Compute Efficiency"]}],["$","span","AI Agents",{"className":"page__taxonomy-item","children":["#","AI Agents"]}]]}]]}]]}],["$","article","2025-11-10-HAFixAgent-History-Aware-Automated-Program-Repair-Agent",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-10-HAFixAgent-History-Aware-Automated-Program-Repair-Agent/","children":"[논문리뷰] HAFixAgent: History-Aware Automated Program Repair Agent"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ahmed E. Hassan이 [arXiv]에 게시한 'HAFixAgent: History-Aware Automated Program Repair Agent' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-10 00:00:00+0900+0900","children":"2025년 11월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Automated Program Repair",{"className":"page__taxonomy-item","children":["#","Automated Program Repair"]}],["$","span","AI Agent",{"className":"page__taxonomy-item","children":["#","AI Agent"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Repository Mining",{"className":"page__taxonomy-item","children":["#","Repository Mining"]}],["$","span","Historical Context",{"className":"page__taxonomy-item","children":["#","Historical Context"]}],["$","span","Bug Fixing",{"className":"page__taxonomy-item","children":["#","Bug Fixing"]}],["$","span","Defects4J",{"className":"page__taxonomy-item","children":["#","Defects4J"]}]]}]]}]]}],["$","article","2025-11-10-Dense-Motion-Captioning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-10-Dense-Motion-Captioning/","children":"[논문리뷰] Dense Motion Captioning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Paolo Rota이 [arXiv]에 게시한 'Dense Motion Captioning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-10 00:00:00+0900+0900","children":"2025년 11월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Human Motion",{"className":"page__taxonomy-item","children":["#","3D Human Motion"]}],["$","span","Dense Captioning",{"className":"page__taxonomy-item","children":["#","Dense Captioning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Motion Understanding",{"className":"page__taxonomy-item","children":["#","Motion Understanding"]}],["$","span","Temporal Localization",{"className":"page__taxonomy-item","children":["#","Temporal Localization"]}],["$","span","Human-Language Datasets",{"className":"page__taxonomy-item","children":["#","Human-Language Datasets"]}],["$","span","Motion Generation",{"className":"page__taxonomy-item","children":["#","Motion Generation"]}]]}]]}]]}],["$","article","2025-11-10-DeepEyesV2-Toward-Agentic-Multimodal-Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-10-DeepEyesV2-Toward-Agentic-Multimodal-Model/","children":"[논문리뷰] DeepEyesV2: Toward Agentic Multimodal Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Guohai Xu이 [arXiv]에 게시한 'DeepEyesV2: Toward Agentic Multimodal Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-10 00:00:00+0900+0900","children":"2025년 11월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Multimodal Models",{"className":"page__taxonomy-item","children":["#","Multimodal Models"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","span","Web Search",{"className":"page__taxonomy-item","children":["#","Web Search"]}],["$","span","Code Execution",{"className":"page__taxonomy-item","children":["#","Code Execution"]}]]}]]}]]}],["$","article","2025-11-10-CritiCal-Can-Critique-Help-LLM-Uncertainty-or-Confidence-Calibration",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-10-CritiCal-Can-Critique-Help-LLM-Uncertainty-or-Confidence-Calibration/","children":"[논문리뷰] CritiCal: Can Critique Help LLM Uncertainty or Confidence Calibration?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Baixuan Xu이 [arXiv]에 게시한 'CritiCal: Can Critique Help LLM Uncertainty or Confidence Calibration?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-10 00:00:00+0900+0900","children":"2025년 11월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Calibration",{"className":"page__taxonomy-item","children":["#","LLM Calibration"]}],["$","span","Confidence Calibration",{"className":"page__taxonomy-item","children":["#","Confidence Calibration"]}],["$","span","Uncertainty Estimation",{"className":"page__taxonomy-item","children":["#","Uncertainty Estimation"]}],["$","span","Critique Learning",{"className":"page__taxonomy-item","children":["#","Critique Learning"]}],["$","span","Supervised Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning"]}],["$","span","Natural Language Processing",{"className":"page__taxonomy-item","children":["#","Natural Language Processing"]}],["$","span","Self-Critique",{"className":"page__taxonomy-item","children":["#","Self-Critique"]}]]}]]}]]}],["$","article","2025-11-7-V-Thinker-Interactive-Thinking-with-Images",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-7-V-Thinker-Interactive-Thinking-with-Images/","children":"[논문리뷰] V-Thinker: Interactive Thinking with Images"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Peiqing Yang이 [arXiv]에 게시한 'V-Thinker: Interactive Thinking with Images' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 22:08:24+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Multimodal Models",{"className":"page__taxonomy-item","children":["#","Large Multimodal Models"]}],["$","span","Interactive Reasoning",{"className":"page__taxonomy-item","children":["#","Interactive Reasoning"]}],["$","span","Vision-Centric Thinking",{"className":"page__taxonomy-item","children":["#","Vision-Centric Thinking"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Data Synthesis",{"className":"page__taxonomy-item","children":["#","Data Synthesis"]}],["$","span","Visual Tools",{"className":"page__taxonomy-item","children":["#","Visual Tools"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}]]}]]}]]}],["$","article","2025-11-7-Thinking-with-Video-Video-Generation-as-a-Promising-Multimodal-Reasoning-Paradigm",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-7-Thinking-with-Video-Video-Generation-as-a-Promising-Multimodal-Reasoning-Paradigm/","children":"[논문리뷰] Thinking with Video: Video Generation as a Promising Multimodal Reasoning Paradigm"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Thinking with Video: Video Generation as a Promising Multimodal Reasoning Paradigm' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 22:08:24+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","span","Temporal Understanding",{"className":"page__taxonomy-item","children":["#","Temporal Understanding"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","AI Benchmarking",{"className":"page__taxonomy-item","children":["#","AI Benchmarking"]}],["$","span","In-Context Learning",{"className":"page__taxonomy-item","children":["#","In-Context Learning"]}],["$","span","Self-Consistency",{"className":"page__taxonomy-item","children":["#","Self-Consistency"]}]]}]]}]]}],["$","article","2025-11-7-The-Strong-Lottery-Ticket-Hypothesis-for-Multi-Head-Attention-Mechanisms",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-7-The-Strong-Lottery-Ticket-Hypothesis-for-Multi-Head-Attention-Mechanisms/","children":"[논문리뷰] The Strong Lottery Ticket Hypothesis for Multi-Head Attention Mechanisms"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Susumu Takeuchi이 [arXiv]에 게시한 'The Strong Lottery Ticket Hypothesis for Multi-Head Attention Mechanisms' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 22:08:24+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Strong Lottery Ticket Hypothesis",{"className":"page__taxonomy-item","children":["#","Strong Lottery Ticket Hypothesis"]}],["$","span","Multi-Head Attention",{"className":"page__taxonomy-item","children":["#","Multi-Head Attention"]}],["$","span","Transformers",{"className":"page__taxonomy-item","children":["#","Transformers"]}],["$","span","Neural Network Pruning",{"className":"page__taxonomy-item","children":["#","Neural Network Pruning"]}],["$","span","Overparameterization",{"className":"page__taxonomy-item","children":["#","Overparameterization"]}],["$","span","Weight Initialization",{"className":"page__taxonomy-item","children":["#","Weight Initialization"]}],["$","span","Model Compression",{"className":"page__taxonomy-item","children":["#","Model Compression"]}]]}]]}]]}],["$","article","2025-11-7-Scaling-Agent-Learning-via-Experience-Synthesis",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-7-Scaling-Agent-Learning-via-Experience-Synthesis/","children":"[논문리뷰] Scaling Agent Learning via Experience Synthesis"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Scaling Agent Learning via Experience Synthesis' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 22:08:24+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Experience Synthesis",{"className":"page__taxonomy-item","children":["#","Experience Synthesis"]}],["$","span","World Models",{"className":"page__taxonomy-item","children":["#","World Models"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Sim-to-Real Transfer",{"className":"page__taxonomy-item","children":["#","Sim-to-Real Transfer"]}],["$","span","Web Agents",{"className":"page__taxonomy-item","children":["#","Web Agents"]}]]}]]}]]}],["$","article","2025-11-7-SIMS-V-Simulated-Instruction-Tuning-for-Spatial-Video-Understanding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-7-SIMS-V-Simulated-Instruction-Tuning-for-Spatial-Video-Understanding/","children":"[논문리뷰] SIMS-V: Simulated Instruction-Tuning for Spatial Video Understanding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'SIMS-V: Simulated Instruction-Tuning for Spatial Video Understanding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 22:08:24+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}],["$","span","Video Understanding",{"className":"page__taxonomy-item","children":["#","Video Understanding"]}],["$","span","Simulated Data",{"className":"page__taxonomy-item","children":["#","Simulated Data"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Sim-to-Real Transfer",{"className":"page__taxonomy-item","children":["#","Sim-to-Real Transfer"]}],["$","span","AI2-THOR",{"className":"page__taxonomy-item","children":["#","AI2-THOR"]}]]}]]}]]}],["$","article","2025-11-7-SAIL-RL-Guiding-MLLMs-in-When-and-How-to-Think-via-Dual-Reward-RL-Tuning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-7-SAIL-RL-Guiding-MLLMs-in-When-and-How-to-Think-via-Dual-Reward-RL-Tuning/","children":"[논문리뷰] SAIL-RL: Guiding MLLMs in When and How to Think via Dual-Reward RL Tuning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'SAIL-RL: Guiding MLLMs in When and How to Think via Dual-Reward RL Tuning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 22:08:24+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Post-training",{"className":"page__taxonomy-item","children":["#","Post-training"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Dual-Reward System",{"className":"page__taxonomy-item","children":["#","Dual-Reward System"]}],["$","span","Thinking Reward",{"className":"page__taxonomy-item","children":["#","Thinking Reward"]}],["$","span","Judging Reward",{"className":"page__taxonomy-item","children":["#","Judging Reward"]}],["$","span","Hallucination Reduction",{"className":"page__taxonomy-item","children":["#","Hallucination Reduction"]}]]}]]}]]}],["$","article","2025-11-7-RDMA-Point-to-Point-Communication-for-LLM-Systems",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-7-RDMA-Point-to-Point-Communication-for-LLM-Systems/","children":"[논문리뷰] RDMA Point-to-Point Communication for LLM Systems"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'RDMA Point-to-Point Communication for LLM Systems' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 22:08:24+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","RDMA",{"className":"page__taxonomy-item","children":["#","RDMA"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Point-to-Point Communication",{"className":"page__taxonomy-item","children":["#","Point-to-Point Communication"]}],["$","span","Disaggregated Inference",{"className":"page__taxonomy-item","children":["#","Disaggregated Inference"]}],["$","span","MoE Routing",{"className":"page__taxonomy-item","children":["#","MoE Routing"]}],["$","span","KvCache",{"className":"page__taxonomy-item","children":["#","KvCache"]}],["$","span","AWS EFA",{"className":"page__taxonomy-item","children":["#","AWS EFA"]}],["$","span","NVIDIA ConnectX",{"className":"page__taxonomy-item","children":["#","NVIDIA ConnectX"]}]]}]]}]]}],["$","article","2025-11-7-NVIDIA-Nemotron-Nano-V2-VL",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-7-NVIDIA-Nemotron-Nano-V2-VL/","children":"[논문리뷰] NVIDIA Nemotron Nano V2 VL"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'NVIDIA Nemotron Nano V2 VL' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 22:08:24+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Model",{"className":"page__taxonomy-item","children":["#","Vision-Language Model"]}],["$","span","Hybrid Architecture",{"className":"page__taxonomy-item","children":["#","Hybrid Architecture"]}],["$","span","Mamba-Transformer",{"className":"page__taxonomy-item","children":["#","Mamba-Transformer"]}],["$","span","Long-Context Understanding",{"className":"page__taxonomy-item","children":["#","Long-Context Understanding"]}],["$","span","Quantization",{"className":"page__taxonomy-item","children":["#","Quantization"]}],["$","span","Efficient Inference",{"className":"page__taxonomy-item","children":["#","Efficient Inference"]}],["$","span","Document AI",{"className":"page__taxonomy-item","children":["#","Document AI"]}],["$","span","Video AI",{"className":"page__taxonomy-item","children":["#","Video AI"]}]]}]]}]]}],["$","article","2025-11-7-Learning-Vision-Driven-Reactive-Soccer-Skills-for-Humanoid-Robots",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-7-Learning-Vision-Driven-Reactive-Soccer-Skills-for-Humanoid-Robots/","children":"[논문리뷰] Learning Vision-Driven Reactive Soccer Skills for Humanoid Robots"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Learning Vision-Driven Reactive Soccer Skills for Humanoid Robots' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 22:08:24+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Humanoid Robot",{"className":"page__taxonomy-item","children":["#","Humanoid Robot"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","RoboCup",{"className":"page__taxonomy-item","children":["#","RoboCup"]}],["$","span","Soccer Skills",{"className":"page__taxonomy-item","children":["#","Soccer Skills"]}],["$","span","Vision-Driven Control",{"className":"page__taxonomy-item","children":["#","Vision-Driven Control"]}],["$","span","Adversarial Motion Priors",{"className":"page__taxonomy-item","children":["#","Adversarial Motion Priors"]}],["$","span","Sim-to-Real",{"className":"page__taxonomy-item","children":["#","Sim-to-Real"]}],["$","span","Perception-Action Coordination",{"className":"page__taxonomy-item","children":["#","Perception-Action Coordination"]}]]}]]}]]}],["$","article","2025-11-7-How-to-Evaluate-Speech-Translation-with-Source-Aware-Neural-MT-Metrics",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-7-How-to-Evaluate-Speech-Translation-with-Source-Aware-Neural-MT-Metrics/","children":"[논문리뷰] How to Evaluate Speech Translation with Source-Aware Neural MT Metrics"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Luisa Bentivogli이 [arXiv]에 게시한 'How to Evaluate Speech Translation with Source-Aware Neural MT Metrics' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 22:08:24+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Speech Translation",{"className":"page__taxonomy-item","children":["#","Speech Translation"]}],["$","span","Neural MT Metrics",{"className":"page__taxonomy-item","children":["#","Neural MT Metrics"]}],["$","span","Source-Aware Evaluation",{"className":"page__taxonomy-item","children":["#","Source-Aware Evaluation"]}],["$","span","Automatic Speech Recognition (ASR)",{"className":"page__taxonomy-item","children":["#","Automatic Speech Recognition (ASR)"]}],["$","span","Back-Translation (BT)",{"className":"page__taxonomy-item","children":["#","Back-Translation (BT)"]}],["$","span","Cross-lingual Re-segmentation",{"className":"page__taxonomy-item","children":["#","Cross-lingual Re-segmentation"]}],["$","span","COMET",{"className":"page__taxonomy-item","children":["#","COMET"]}],["$","span","MetricX",{"className":"page__taxonomy-item","children":["#","MetricX"]}]]}]]}]]}],["$","article","2025-11-7-GUI-360-A-Comprehensive-Dataset-and-Benchmark-for-Computer-Using-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-7-GUI-360-A-Comprehensive-Dataset-and-Benchmark-for-Computer-Using-Agents/","children":"[논문리뷰] GUI-360: A Comprehensive Dataset and Benchmark for Computer-Using Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'GUI-360: A Comprehensive Dataset and Benchmark for Computer-Using Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 22:08:24+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Computer-Using Agents",{"className":"page__taxonomy-item","children":["#","Computer-Using Agents"]}],["$","span","GUI Grounding",{"className":"page__taxonomy-item","children":["#","GUI Grounding"]}],["$","span","Screen Parsing",{"className":"page__taxonomy-item","children":["#","Screen Parsing"]}],["$","span","Action Prediction",{"className":"page__taxonomy-item","children":["#","Action Prediction"]}],["$","span","Desktop Automation",{"className":"page__taxonomy-item","children":["#","Desktop Automation"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","LLM-augmented Data",{"className":"page__taxonomy-item","children":["#","LLM-augmented Data"]}]]}]]}]]}],["$","article","2025-11-7-EVTAR-End-to-End-Try-on-with-Additional-Unpaired-Visual-Reference",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-7-EVTAR-End-to-End-Try-on-with-Additional-Unpaired-Visual-Reference/","children":"[논문리뷰] EVTAR: End-to-End Try on with Additional Unpaired Visual Reference"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'EVTAR: End-to-End Try on with Additional Unpaired Visual Reference' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 22:08:24+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Virtual Try-on",{"className":"page__taxonomy-item","children":["#","Virtual Try-on"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","End-to-End Learning",{"className":"page__taxonomy-item","children":["#","End-to-End Learning"]}],["$","span","Reference Images",{"className":"page__taxonomy-item","children":["#","Reference Images"]}],["$","span","Unpaired Data",{"className":"page__taxonomy-item","children":["#","Unpaired Data"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}]]}]]}]]}],["$","article","2025-11-7-Contamination-Detection-for-VLMs-using-Multi-Modal-Semantic-Perturbation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-7-Contamination-Detection-for-VLMs-using-Multi-Modal-Semantic-Perturbation/","children":"[논문리뷰] Contamination Detection for VLMs using Multi-Modal Semantic Perturbation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Contamination Detection for VLMs using Multi-Modal Semantic Perturbation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 22:08:24+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","VLM Contamination",{"className":"page__taxonomy-item","children":["#","VLM Contamination"]}],["$","span","Test-set Leakage",{"className":"page__taxonomy-item","children":["#","Test-set Leakage"]}],["$","span","Multi-modal Perturbation",{"className":"page__taxonomy-item","children":["#","Multi-modal Perturbation"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Model Memorization",{"className":"page__taxonomy-item","children":["#","Model Memorization"]}],["$","span","VLMs",{"className":"page__taxonomy-item","children":["#","VLMs"]}]]}]]}]]}],["$","article","2025-11-7-Cambrian-S-Towards-Spatial-Supersensing-in-Video",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-7-Cambrian-S-Towards-Spatial-Supersensing-in-Video/","children":"[논문리뷰] Cambrian-S: Towards Spatial Supersensing in Video"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zihao Yang이 [arXiv]에 게시한 'Cambrian-S: Towards Spatial Supersensing in Video' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 22:08:24+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Spatial Supersensing",{"className":"page__taxonomy-item","children":["#","Spatial Supersensing"]}],["$","span","Video Understanding",{"className":"page__taxonomy-item","children":["#","Video Understanding"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Predictive Sensing",{"className":"page__taxonomy-item","children":["#","Predictive Sensing"]}],["$","span","Memory Management",{"className":"page__taxonomy-item","children":["#","Memory Management"]}],["$","span","Event Segmentation",{"className":"page__taxonomy-item","children":["#","Event Segmentation"]}],["$","span","VSI-SUPER",{"className":"page__taxonomy-item","children":["#","VSI-SUPER"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}]]}]]}]]}],["$","article","2025-11-7-Benchmark-Designers-Should-Train-on-the-Test-Set-to-Expose-Exploitable-Non-Visual-Shortcuts",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-7-Benchmark-Designers-Should-Train-on-the-Test-Set-to-Expose-Exploitable-Non-Visual-Shortcuts/","children":"[논문리뷰] Benchmark Designers Should 'Train on the Test Set' to Expose Exploitable Non-Visual Shortcuts"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Benchmark Designers Should 'Train on the Test Set' to Expose Exploitable Non-Visual Shortcuts' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 22:08:24+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Benchmark Design",{"className":"page__taxonomy-item","children":["#","Benchmark Design"]}],["$","span","Non-Visual Shortcuts",{"className":"page__taxonomy-item","children":["#","Non-Visual Shortcuts"]}],["$","span","Test-Set Stress-Test",{"className":"page__taxonomy-item","children":["#","Test-Set Stress-Test"]}],["$","span","Bias Mitigation",{"className":"page__taxonomy-item","children":["#","Bias Mitigation"]}],["$","span","Model Evaluation",{"className":"page__taxonomy-item","children":["#","Model Evaluation"]}],["$","span","Benchmark Robustness",{"className":"page__taxonomy-item","children":["#","Benchmark Robustness"]}]]}]]}]]}],["$","article","2025-11-6-UniAVGen-Unified-Audio-and-Video-Generation-with-Asymmetric-Cross-Modal-Interactions",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-6-UniAVGen-Unified-Audio-and-Video-Generation-with-Asymmetric-Cross-Modal-Interactions/","children":"[논문리뷰] UniAVGen: Unified Audio and Video Generation with Asymmetric Cross-Modal Interactions"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'UniAVGen: Unified Audio and Video Generation with Asymmetric Cross-Modal Interactions' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 21:54:30+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Joint Audio-Video Generation",{"className":"page__taxonomy-item","children":["#","Joint Audio-Video Generation"]}],["$","span","Cross-Modal Interaction",{"className":"page__taxonomy-item","children":["#","Cross-Modal Interaction"]}],["$","span","Diffusion Transformer",{"className":"page__taxonomy-item","children":["#","Diffusion Transformer"]}],["$","span","Face-Aware Modulation",{"className":"page__taxonomy-item","children":["#","Face-Aware Modulation"]}],["$","span","Classifier-Free Guidance",{"className":"page__taxonomy-item","children":["#","Classifier-Free Guidance"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}]]}]]}]]}],["$","article","2025-11-6-The-Sequential-Edge-Inverse-Entropy-Voting-Beats-Parallel-Self-Consistency-at-Matched-Compute",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-6-The-Sequential-Edge-Inverse-Entropy-Voting-Beats-Parallel-Self-Consistency-at-Matched-Compute/","children":"[논문리뷰] The Sequential Edge: Inverse-Entropy Voting Beats Parallel Self-Consistency at Matched Compute"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'The Sequential Edge: Inverse-Entropy Voting Beats Parallel Self-Consistency at Matched Compute' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 21:54:30+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Sequential Reasoning",{"className":"page__taxonomy-item","children":["#","Sequential Reasoning"]}],["$","span","Parallel Self-Consistency",{"className":"page__taxonomy-item","children":["#","Parallel Self-Consistency"]}],["$","span","Inverse-Entropy Voting",{"className":"page__taxonomy-item","children":["#","Inverse-Entropy Voting"]}],["$","span","LLM Reasoning",{"className":"page__taxonomy-item","children":["#","LLM Reasoning"]}],["$","span","Test-Time Scaling",{"className":"page__taxonomy-item","children":["#","Test-Time Scaling"]}],["$","span","Inference Optimization",{"className":"page__taxonomy-item","children":["#","Inference Optimization"]}],["$","span","Iterative Refinement",{"className":"page__taxonomy-item","children":["#","Iterative Refinement"]}],["$","span","Error Correction",{"className":"page__taxonomy-item","children":["#","Error Correction"]}]]}]]}]]}],["$","article","2025-11-6-TabTune-A-Unified-Library-for-Inference-and-Fine-Tuning-Tabular-Foundation-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-6-TabTune-A-Unified-Library-for-Inference-and-Fine-Tuning-Tabular-Foundation-Models/","children":"[논문리뷰] TabTune: A Unified Library for Inference and Fine-Tuning Tabular Foundation Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'TabTune: A Unified Library for Inference and Fine-Tuning Tabular Foundation Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 21:54:30+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Tabular Foundation Models",{"className":"page__taxonomy-item","children":["#","Tabular Foundation Models"]}],["$","span","Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Fine-Tuning"]}],["$","span","PEFT",{"className":"page__taxonomy-item","children":["#","PEFT"]}],["$","span","Meta-Learning",{"className":"page__taxonomy-item","children":["#","Meta-Learning"]}],["$","span","Calibration",{"className":"page__taxonomy-item","children":["#","Calibration"]}],["$","span","Fairness",{"className":"page__taxonomy-item","children":["#","Fairness"]}],["$","span","Unified Library",{"className":"page__taxonomy-item","children":["#","Unified Library"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}]]}]]}]]}],["$","article","2025-11-6-Orion-MSP-Multi-Scale-Sparse-Attention-for-Tabular-In-Context-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-6-Orion-MSP-Multi-Scale-Sparse-Attention-for-Tabular-In-Context-Learning/","children":"[논문리뷰] Orion-MSP: Multi-Scale Sparse Attention for Tabular In-Context Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Orion-MSP: Multi-Scale Sparse Attention for Tabular In-Context Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 21:54:30+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Tabular Data",{"className":"page__taxonomy-item","children":["#","Tabular Data"]}],["$","span","In-Context Learning",{"className":"page__taxonomy-item","children":["#","In-Context Learning"]}],["$","span","Multi-Scale Attention",{"className":"page__taxonomy-item","children":["#","Multi-Scale Attention"]}],["$","span","Sparse Attention",{"className":"page__taxonomy-item","children":["#","Sparse Attention"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Perceiver Architecture",{"className":"page__taxonomy-item","children":["#","Perceiver Architecture"]}]]}]]}]]}],["$","article","2025-11-6-MME-CC-A-Challenging-Multi-Modal-Evaluation-Benchmark-of-Cognitive-Capacity",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-6-MME-CC-A-Challenging-Multi-Modal-Evaluation-Benchmark-of-Cognitive-Capacity/","children":"[논문리뷰] MME-CC: A Challenging Multi-Modal Evaluation Benchmark of Cognitive Capacity"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'MME-CC: A Challenging Multi-Modal Evaluation Benchmark of Cognitive Capacity' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 21:54:30+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Cognitive Capacity",{"className":"page__taxonomy-item","children":["#","Cognitive Capacity"]}],["$","span","Visual Reasoning",{"className":"page__taxonomy-item","children":["#","Visual Reasoning"]}],["$","span","MLLM Evaluation",{"className":"page__taxonomy-item","children":["#","MLLM Evaluation"]}],["$","span","Error Analysis",{"className":"page__taxonomy-item","children":["#","Error Analysis"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}]]}]]}]]}],["$","article","2025-11-6-LiveTradeBench-Seeking-Real-World-Alpha-with-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-6-LiveTradeBench-Seeking-Real-World-Alpha-with-Large-Language-Models/","children":"[논문리뷰] LiveTradeBench: Seeking Real-World Alpha with Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiaxuan You이 [arXiv]에 게시한 'LiveTradeBench: Seeking Real-World Alpha with Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 21:54:30+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Live Trading",{"className":"page__taxonomy-item","children":["#","Live Trading"]}],["$","span","Portfolio Management",{"className":"page__taxonomy-item","children":["#","Portfolio Management"]}],["$","span","Financial AI",{"className":"page__taxonomy-item","children":["#","Financial AI"]}],["$","span","Prediction Markets",{"className":"page__taxonomy-item","children":["#","Prediction Markets"]}],["$","span","Real-World Uncertainty",{"className":"page__taxonomy-item","children":["#","Real-World Uncertainty"]}],["$","span","Agent Benchmarking",{"className":"page__taxonomy-item","children":["#","Agent Benchmarking"]}]]}]]}]]}],["$","article","2025-11-6-Let-Multimodal-Embedders-Learn-When-to-Augment-Query-via-Adaptive-Query-Augmentation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-6-Let-Multimodal-Embedders-Learn-When-to-Augment-Query-via-Adaptive-Query-Augmentation/","children":"[논문리뷰] Let Multimodal Embedders Learn When to Augment Query via Adaptive Query Augmentation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jaehyun Park이 [arXiv]에 게시한 'Let Multimodal Embedders Learn When to Augment Query via Adaptive Query Augmentation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 21:54:30+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Embedders",{"className":"page__taxonomy-item","children":["#","Multimodal Embedders"]}],["$","span","Query Augmentation",{"className":"page__taxonomy-item","children":["#","Query Augmentation"]}],["$","span","Adaptive Learning",{"className":"page__taxonomy-item","children":["#","Adaptive Learning"]}],["$","span","Multimodal LLM",{"className":"page__taxonomy-item","children":["#","Multimodal LLM"]}],["$","span","Information Retrieval",{"className":"page__taxonomy-item","children":["#","Information Retrieval"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Embedding Latency",{"className":"page__taxonomy-item","children":["#","Embedding Latency"]}]]}]]}]]}],["$","article","2025-11-6-LEGO-Eval-Towards-Fine-Grained-Evaluation-on-Synthesizing-3D-Embodied-Environments-with-Tool-Augmentation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-6-LEGO-Eval-Towards-Fine-Grained-Evaluation-on-Synthesizing-3D-Embodied-Environments-with-Tool-Augmentation/","children":"[논문리뷰] LEGO-Eval: Towards Fine-Grained Evaluation on Synthesizing 3D Embodied Environments with Tool Augmentation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Soohyun Oh이 [arXiv]에 게시한 'LEGO-Eval: Towards Fine-Grained Evaluation on Synthesizing 3D Embodied Environments with Tool Augmentation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 21:54:30+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Scene Synthesis",{"className":"page__taxonomy-item","children":["#","3D Scene Synthesis"]}],["$","span","Fine-Grained Evaluation",{"className":"page__taxonomy-item","children":["#","Fine-Grained Evaluation"]}],["$","span","Tool-Augmented LLMs",{"className":"page__taxonomy-item","children":["#","Tool-Augmented LLMs"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Multi-Hop Grounding",{"className":"page__taxonomy-item","children":["#","Multi-Hop Grounding"]}]]}]]}]]}],["$","article","2025-11-6-Kinematify-Open-Vocabulary-Synthesis-of-High-DoF-Articulated-Objects",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-6-Kinematify-Open-Vocabulary-Synthesis-of-High-DoF-Articulated-Objects/","children":"[논문리뷰] Kinematify: Open-Vocabulary Synthesis of High-DoF Articulated Objects"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Kinematify: Open-Vocabulary Synthesis of High-DoF Articulated Objects' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 21:54:30+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Articulated Objects",{"className":"page__taxonomy-item","children":["#","Articulated Objects"]}],["$","span","Kinematics Inference",{"className":"page__taxonomy-item","children":["#","Kinematics Inference"]}],["$","span","High-DoF",{"className":"page__taxonomy-item","children":["#","High-DoF"]}],["$","span","Monte Carlo Tree Search",{"className":"page__taxonomy-item","children":["#","Monte Carlo Tree Search"]}],["$","span","Joint Parameter Optimization",{"className":"page__taxonomy-item","children":["#","Joint Parameter Optimization"]}],["$","span","SDF",{"className":"page__taxonomy-item","children":["#","SDF"]}],["$","span","Open-Vocabulary Synthesis",{"className":"page__taxonomy-item","children":["#","Open-Vocabulary Synthesis"]}],["$","span","Robot Self-Modeling",{"className":"page__taxonomy-item","children":["#","Robot Self-Modeling"]}]]}]]}]]}],["$","article","2025-11-6-Jr-AI-Scientist-and-Its-Risk-Report-Autonomous-Scientific-Exploration-from-a-Baseline-Paper",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-6-Jr-AI-Scientist-and-Its-Risk-Report-Autonomous-Scientific-Exploration-from-a-Baseline-Paper/","children":"[논문리뷰] Jr. AI Scientist and Its Risk Report: Autonomous Scientific Exploration from a Baseline Paper"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Jr. AI Scientist and Its Risk Report: Autonomous Scientific Exploration from a Baseline Paper' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 21:54:30+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Scientist",{"className":"page__taxonomy-item","children":["#","AI Scientist"]}],["$","span","Autonomous Research",{"className":"page__taxonomy-item","children":["#","Autonomous Research"]}],["$","span","Scientific Automation",{"className":"page__taxonomy-item","children":["#","Scientific Automation"]}],["$","span","LLM for Research",{"className":"page__taxonomy-item","children":["#","LLM for Research"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","Experimental Design",{"className":"page__taxonomy-item","children":["#","Experimental Design"]}],["$","span","Risk Assessment",{"className":"page__taxonomy-item","children":["#","Risk Assessment"]}]]}]]}]]}],["$","article","2025-11-6-Grounded-Misunderstandings-in-Asymmetric-Dialogue-A-Perspectivist-Annotation-Scheme-for-MapTask",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-6-Grounded-Misunderstandings-in-Asymmetric-Dialogue-A-Perspectivist-Annotation-Scheme-for-MapTask/","children":"[논문리뷰] Grounded Misunderstandings in Asymmetric Dialogue: A Perspectivist Annotation Scheme for MapTask"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Grounded Misunderstandings in Asymmetric Dialogue: A Perspectivist Annotation Scheme for MapTask' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 21:54:30+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Dialogue Systems",{"className":"page__taxonomy-item","children":["#","Dialogue Systems"]}],["$","span","Common Ground",{"className":"page__taxonomy-item","children":["#","Common Ground"]}],["$","span","Misunderstanding",{"className":"page__taxonomy-item","children":["#","Misunderstanding"]}],["$","span","Annotation Scheme",{"className":"page__taxonomy-item","children":["#","Annotation Scheme"]}],["$","span","MapTask Corpus",{"className":"page__taxonomy-item","children":["#","MapTask Corpus"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Perspective Taking",{"className":"page__taxonomy-item","children":["#","Perspective Taking"]}],["$","span","Reference Resolution",{"className":"page__taxonomy-item","children":["#","Reference Resolution"]}]]}]]}]]}],["$","article","2025-11-6-Diffusion-Language-Models-are-Super-Data-Learners",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-6-Diffusion-Language-Models-are-Super-Data-Learners/","children":"[논문리뷰] Diffusion Language Models are Super Data Learners"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Diffusion Language Models are Super Data Learners' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 21:54:30+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Language Models",{"className":"page__taxonomy-item","children":["#","Diffusion Language Models"]}],["$","span","Autoregressive Models",{"className":"page__taxonomy-item","children":["#","Autoregressive Models"]}],["$","span","Data Efficiency",{"className":"page__taxonomy-item","children":["#","Data Efficiency"]}],["$","span","Scaling Laws",{"className":"page__taxonomy-item","children":["#","Scaling Laws"]}],["$","span","Data-Constrained Learning",{"className":"page__taxonomy-item","children":["#","Data-Constrained Learning"]}],["$","span","Crossover Phenomenon",{"className":"page__taxonomy-item","children":["#","Crossover Phenomenon"]}],["$","span","Pre-training",{"className":"page__taxonomy-item","children":["#","Pre-training"]}],["$","span","Masked Diffusion",{"className":"page__taxonomy-item","children":["#","Masked Diffusion"]}]]}]]}]]}],["$","article","2025-11-6-CostBench-Evaluating-Multi-Turn-Cost-Optimal-Planning-and-Adaptation-in-Dynamic-Environments-for-LLM-Tool-Use-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-6-CostBench-Evaluating-Multi-Turn-Cost-Optimal-Planning-and-Adaptation-in-Dynamic-Environments-for-LLM-Tool-Use-Agents/","children":"[논문리뷰] CostBench: Evaluating Multi-Turn Cost-Optimal Planning and Adaptation in Dynamic Environments for LLM Tool-Use Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shijue Huang이 [arXiv]에 게시한 'CostBench: Evaluating Multi-Turn Cost-Optimal Planning and Adaptation in Dynamic Environments for LLM Tool-Use Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 21:54:30+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Cost-Optimal Planning",{"className":"page__taxonomy-item","children":["#","Cost-Optimal Planning"]}],["$","span","Dynamic Environments",{"className":"page__taxonomy-item","children":["#","Dynamic Environments"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Multi-Turn Interaction",{"className":"page__taxonomy-item","children":["#","Multi-Turn Interaction"]}],["$","span","Economic Reasoning",{"className":"page__taxonomy-item","children":["#","Economic Reasoning"]}]]}]]}]]}],["$","article","2025-11-5-iFlyBot-VLA-Technical-Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-5-iFlyBot-VLA-Technical-Report/","children":"[논문리뷰] iFlyBot-VLA Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiajia wu이 [arXiv]에 게시한 'iFlyBot-VLA Technical Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:35:02+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action Models"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Imitation Learning",{"className":"page__taxonomy-item","children":["#","Imitation Learning"]}],["$","span","Latent Actions",{"className":"page__taxonomy-item","children":["#","Latent Actions"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Dual-Arm Manipulation",{"className":"page__taxonomy-item","children":["#","Dual-Arm Manipulation"]}],["$","span","Pretraining",{"className":"page__taxonomy-item","children":["#","Pretraining"]}],["$","span","Flow-Matching",{"className":"page__taxonomy-item","children":["#","Flow-Matching"]}]]}]]}]]}],["$","article","2025-11-5-When-Visualizing-is-the-First-Step-to-Reasoning-MIRA-a-Benchmark-for-Visual-Chain-of-Thought",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-5-When-Visualizing-is-the-First-Step-to-Reasoning-MIRA-a-Benchmark-for-Visual-Chain-of-Thought/","children":"[논문리뷰] When Visualizing is the First Step to Reasoning: MIRA, a Benchmark for Visual Chain-of-Thought"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'When Visualizing is the First Step to Reasoning: MIRA, a Benchmark for Visual Chain-of-Thought' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:35:02+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Visual Reasoning",{"className":"page__taxonomy-item","children":["#","Visual Reasoning"]}],["$","span","Chain-of-Thought (CoT)",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought (CoT)"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","MLLMs",{"className":"page__taxonomy-item","children":["#","MLLMs"]}],["$","span","Visual-CoT",{"className":"page__taxonomy-item","children":["#","Visual-CoT"]}]]}]]}]]}],["$","article","2025-11-5-When-Modalities-Conflict-How-Unimodal-Reasoning-Uncertainty-Governs-Preference-Dynamics-in-MLLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-5-When-Modalities-Conflict-How-Unimodal-Reasoning-Uncertainty-Governs-Preference-Dynamics-in-MLLMs/","children":"[논문리뷰] When Modalities Conflict: How Unimodal Reasoning Uncertainty Governs Preference Dynamics in MLLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Haotian Wang이 [arXiv]에 게시한 'When Modalities Conflict: How Unimodal Reasoning Uncertainty Governs Preference Dynamics in MLLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:35:02+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models (MLLMs)"]}],["$","span","Modality Following",{"className":"page__taxonomy-item","children":["#","Modality Following"]}],["$","span","Unimodal Uncertainty",{"className":"page__taxonomy-item","children":["#","Unimodal Uncertainty"]}],["$","span","Modality Preference",{"className":"page__taxonomy-item","children":["#","Modality Preference"]}],["$","span","Conflict Resolution",{"className":"page__taxonomy-item","children":["#","Conflict Resolution"]}],["$","span","Internal Mechanism",{"className":"page__taxonomy-item","children":["#","Internal Mechanism"]}],["$","span","Entropy",{"className":"page__taxonomy-item","children":["#","Entropy"]}],["$","span","Controllable Dataset",{"className":"page__taxonomy-item","children":["#","Controllable Dataset"]}]]}]]}]]}],["$","article","2025-11-5-VidEmo-Affective-Tree-Reasoning-for-Emotion-Centric-Video-Foundation-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-5-VidEmo-Affective-Tree-Reasoning-for-Emotion-Centric-Video-Foundation-Models/","children":"[논문리뷰] VidEmo: Affective-Tree Reasoning for Emotion-Centric Video Foundation Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Pengfei Wan이 [arXiv]에 게시한 'VidEmo: Affective-Tree Reasoning for Emotion-Centric Video Foundation Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:35:02+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","VideoLLMs",{"className":"page__taxonomy-item","children":["#","VideoLLMs"]}],["$","span","Emotion Understanding",{"className":"page__taxonomy-item","children":["#","Emotion Understanding"]}],["$","span","Affective-Tree Reasoning",{"className":"page__taxonomy-item","children":["#","Affective-Tree Reasoning"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Fine-Grained Emotion",{"className":"page__taxonomy-item","children":["#","Fine-Grained Emotion"]}],["$","span","Attribute Perception",{"className":"page__taxonomy-item","children":["#","Attribute Perception"]}],["$","span","Expression Analysis",{"className":"page__taxonomy-item","children":["#","Expression Analysis"]}]]}]]}]]}],["$","article","2025-11-5-VCode-a-Multimodal-Coding-Benchmark-with-SVG-as-Symbolic-Visual-Representation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-5-VCode-a-Multimodal-Coding-Benchmark-with-SVG-as-Symbolic-Visual-Representation/","children":"[논문리뷰] VCode: a Multimodal Coding Benchmark with SVG as Symbolic Visual Representation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'VCode: a Multimodal Coding Benchmark with SVG as Symbolic Visual Representation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:35:02+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","SVG",{"className":"page__taxonomy-item","children":["#","SVG"]}],["$","span","Visual Representation",{"className":"page__taxonomy-item","children":["#","Visual Representation"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Large Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Large Vision-Language Models"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}]]}]]}]]}],["$","article","2025-11-5-The-Collaboration-Gap",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-5-The-Collaboration-Gap/","children":"[논문리뷰] The Collaboration Gap"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'The Collaboration Gap' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:35:02+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Collaboration",{"className":"page__taxonomy-item","children":["#","AI Collaboration"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Maze Solving",{"className":"page__taxonomy-item","children":["#","Maze Solving"]}],["$","span","Heterogeneous Agents",{"className":"page__taxonomy-item","children":["#","Heterogeneous Agents"]}],["$","span","Collaboration Gap",{"className":"page__taxonomy-item","children":["#","Collaboration Gap"]}],["$","span","Relay Inference",{"className":"page__taxonomy-item","children":["#","Relay Inference"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}]]}]]}]]}],["$","article","2025-11-5-TabDSR-Decompose-Sanitize-and-Reason-for-Complex-Numerical-Reasoning-in-Tabular-Data",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-5-TabDSR-Decompose-Sanitize-and-Reason-for-Complex-Numerical-Reasoning-in-Tabular-Data/","children":"[논문리뷰] TabDSR: Decompose, Sanitize, and Reason for Complex Numerical Reasoning in Tabular Data"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jin Zeng이 [arXiv]에 게시한 'TabDSR: Decompose, Sanitize, and Reason for Complex Numerical Reasoning in Tabular Data' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:35:02+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Tabular Data",{"className":"page__taxonomy-item","children":["#","Tabular Data"]}],["$","span","Numerical Reasoning",{"className":"page__taxonomy-item","children":["#","Numerical Reasoning"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Table Question Answering (TQA)",{"className":"page__taxonomy-item","children":["#","Table Question Answering (TQA)"]}],["$","span","Program-of-Thoughts (PoT)",{"className":"page__taxonomy-item","children":["#","Program-of-Thoughts (PoT)"]}],["$","span","Data Sanitization",{"className":"page__taxonomy-item","children":["#","Data Sanitization"]}],["$","span","Query Decomposition",{"className":"page__taxonomy-item","children":["#","Query Decomposition"]}],["$","span","Multi-hop Reasoning",{"className":"page__taxonomy-item","children":["#","Multi-hop Reasoning"]}]]}]]}]]}],["$","article","2025-11-5-TWIST2-Scalable-Portable-and-Holistic-Humanoid-Data-Collection-System",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-5-TWIST2-Scalable-Portable-and-Holistic-Humanoid-Data-Collection-System/","children":"[논문리뷰] TWIST2: Scalable, Portable, and Holistic Humanoid Data Collection System"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Rocky Duan이 [arXiv]에 게시한 'TWIST2: Scalable, Portable, and Holistic Humanoid Data Collection System' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:35:02+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Humanoid Robotics",{"className":"page__taxonomy-item","children":["#","Humanoid Robotics"]}],["$","span","Data Collection",{"className":"page__taxonomy-item","children":["#","Data Collection"]}],["$","span","Teleoperation",{"className":"page__taxonomy-item","children":["#","Teleoperation"]}],["$","span","Full-Body Control",{"className":"page__taxonomy-item","children":["#","Full-Body Control"]}],["$","span","Visuomotor Policy Learning",{"className":"page__taxonomy-item","children":["#","Visuomotor Policy Learning"]}],["$","span","VR",{"className":"page__taxonomy-item","children":["#","VR"]}],["$","span","Portable MoCap-Free",{"className":"page__taxonomy-item","children":["#","Portable MoCap-Free"]}]]}]]}]]}],["$","article","2025-11-5-Step-Audio-EditX-Technical-Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-5-Step-Audio-EditX-Technical-Report/","children":"[논문리뷰] Step-Audio-EditX Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Step-Audio-EditX Technical Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:35:02+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM-based Audio Model",{"className":"page__taxonomy-item","children":["#","LLM-based Audio Model"]}],["$","span","Audio Editing",{"className":"page__taxonomy-item","children":["#","Audio Editing"]}],["$","span","Text-to-Speech (TTS)",{"className":"page__taxonomy-item","children":["#","Text-to-Speech (TTS)"]}],["$","span","Zero-shot Learning",{"className":"page__taxonomy-item","children":["#","Zero-shot Learning"]}],["$","span","Large-Margin Data",{"className":"page__taxonomy-item","children":["#","Large-Margin Data"]}],["$","span","Reinforcement Learning (RLHF)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RLHF)"]}],["$","span","Emotion Control",{"className":"page__taxonomy-item","children":["#","Emotion Control"]}],["$","span","Speaking Style Transfer",{"className":"page__taxonomy-item","children":["#","Speaking Style Transfer"]}]]}]]}]]}],["$","article","2025-11-5-Shorter-but-not-Worse-Frugal-Reasoning-via-Easy-Samples-as-Length-Regularizers-in-Math-RLVR",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-5-Shorter-but-not-Worse-Frugal-Reasoning-via-Easy-Samples-as-Length-Regularizers-in-Math-RLVR/","children":"[논문리뷰] Shorter but not Worse: Frugal Reasoning via Easy Samples as Length Regularizers in Math RLVR"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Shorter but not Worse: Frugal Reasoning via Easy Samples as Length Regularizers in Math RLVR' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:35:02+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","RLVR",{"className":"page__taxonomy-item","children":["#","RLVR"]}],["$","span","Length Regularization",{"className":"page__taxonomy-item","children":["#","Length Regularization"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Model Efficiency",{"className":"page__taxonomy-item","children":["#","Model Efficiency"]}],["$","span","Emergent Brevity",{"className":"page__taxonomy-item","children":["#","Emergent Brevity"]}]]}]]}]]}],["$","article","2025-11-5-RoboChallenge-Large-scale-Real-robot-Evaluation-of-Embodied-Policies",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-5-RoboChallenge-Large-scale-Real-robot-Evaluation-of-Embodied-Policies/","children":"[논문리뷰] RoboChallenge: Large-scale Real-robot Evaluation of Embodied Policies"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'RoboChallenge: Large-scale Real-robot Evaluation of Embodied Policies' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:35:02+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Real-robot Evaluation",{"className":"page__taxonomy-item","children":["#","Real-robot Evaluation"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Vision-Language-Action Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action Models"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Online Testing System",{"className":"page__taxonomy-item","children":["#","Online Testing System"]}],["$","span","Robotics Control",{"className":"page__taxonomy-item","children":["#","Robotics Control"]}],["$","span","Large-scale Evaluation",{"className":"page__taxonomy-item","children":["#","Large-scale Evaluation"]}]]}]]}]]}],["$","article","2025-11-5-RiddleBench-A-New-Generative-Reasoning-Benchmark-for-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-5-RiddleBench-A-New-Generative-Reasoning-Benchmark-for-LLMs/","children":"[논문리뷰] RiddleBench: A New Generative Reasoning Benchmark for LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'RiddleBench: A New Generative Reasoning Benchmark for LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:35:02+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Reasoning",{"className":"page__taxonomy-item","children":["#","LLM Reasoning"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Logical Deduction",{"className":"page__taxonomy-item","children":["#","Logical Deduction"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}],["$","span","Constraint Satisfaction",{"className":"page__taxonomy-item","children":["#","Constraint Satisfaction"]}],["$","span","Hallucination Cascade",{"className":"page__taxonomy-item","children":["#","Hallucination Cascade"]}],["$","span","Self-Correction",{"className":"page__taxonomy-item","children":["#","Self-Correction"]}]]}]]}]]}],["$","article","2025-11-5-Reg-DPO-SFT-Regularized-Direct-Preference-Optimization-with-GT-Pair-for-Improving-Video-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-5-Reg-DPO-SFT-Regularized-Direct-Preference-Optimization-with-GT-Pair-for-Improving-Video-Generation/","children":"[논문리뷰] Reg-DPO: SFT-Regularized Direct Preference Optimization with GT-Pair for Improving Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Reg-DPO: SFT-Regularized Direct Preference Optimization with GT-Pair for Improving Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:35:02+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Direct Preference Optimization",{"className":"page__taxonomy-item","children":["#","Direct Preference Optimization"]}],["$","span","SFT Regularization",{"className":"page__taxonomy-item","children":["#","SFT Regularization"]}],["$","span","GT-Pair",{"className":"page__taxonomy-item","children":["#","GT-Pair"]}],["$","span","Memory Optimization",{"className":"page__taxonomy-item","children":["#","Memory Optimization"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","I2V",{"className":"page__taxonomy-item","children":["#","I2V"]}],["$","span","T2V",{"className":"page__taxonomy-item","children":["#","T2V"]}]]}]]}]]}],["$","article","2025-11-5-LiveSecBench-A-Dynamic-and-Culturally-Relevant-AI-Safety-Benchmark-for-LLMs-in-Chinese-Context",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-5-LiveSecBench-A-Dynamic-and-Culturally-Relevant-AI-Safety-Benchmark-for-LLMs-in-Chinese-Context/","children":"[논문리뷰] LiveSecBench: A Dynamic and Culturally-Relevant AI Safety Benchmark for LLMs in Chinese Context"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Tianxin Zhang이 [arXiv]에 게시한 'LiveSecBench: A Dynamic and Culturally-Relevant AI Safety Benchmark for LLMs in Chinese Context' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:35:02+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Safety",{"className":"page__taxonomy-item","children":["#","LLM Safety"]}],["$","span","AI Safety Benchmark",{"className":"page__taxonomy-item","children":["#","AI Safety Benchmark"]}],["$","span","Chinese Context",{"className":"page__taxonomy-item","children":["#","Chinese Context"]}],["$","span","Dynamic Evaluation",{"className":"page__taxonomy-item","children":["#","Dynamic Evaluation"]}],["$","span","Cultural Relevance",{"className":"page__taxonomy-item","children":["#","Cultural Relevance"]}],["$","span","Adversarial Robustness",{"className":"page__taxonomy-item","children":["#","Adversarial Robustness"]}],["$","span","ELO Rating System",{"className":"page__taxonomy-item","children":["#","ELO Rating System"]}]]}]]}]]}],["$","article","2025-11-5-LTD-Bench-Evaluating-Large-Language-Models-by-Letting-Them-Draw",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-5-LTD-Bench-Evaluating-Large-Language-Models-by-Letting-Them-Draw/","children":"[논문리뷰] LTD-Bench: Evaluating Large Language Models by Letting Them Draw"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'LTD-Bench: Evaluating Large Language Models by Letting Them Draw' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:35:02+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Visual Perception",{"className":"page__taxonomy-item","children":["#","Visual Perception"]}],["$","span","Spatial Imagination",{"className":"page__taxonomy-item","children":["#","Spatial Imagination"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}]]}]]}]]}],["$","article","2025-11-5-Forget-BIT-It-is-All-about-TOKEN-Towards-Semantic-Information-Theory-for-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-5-Forget-BIT-It-is-All-about-TOKEN-Towards-Semantic-Information-Theory-for-LLMs/","children":"[논문리뷰] Forget BIT, It is All about TOKEN: Towards Semantic Information Theory for LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Bo Bai이 [arXiv]에 게시한 'Forget BIT, It is All about TOKEN: Towards Semantic Information Theory for LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:35:02+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Semantic Information Theory",{"className":"page__taxonomy-item","children":["#","Semantic Information Theory"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Directed Information",{"className":"page__taxonomy-item","children":["#","Directed Information"]}],["$","span","Rate-Distortion Function",{"className":"page__taxonomy-item","children":["#","Rate-Distortion Function"]}],["$","span","Granger Causality",{"className":"page__taxonomy-item","children":["#","Granger Causality"]}],["$","span","Token Embedding",{"className":"page__taxonomy-item","children":["#","Token Embedding"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Variational Inference",{"className":"page__taxonomy-item","children":["#","Variational Inference"]}]]}]]}]]}],["$","article","2025-11-5-Dont-Blind-Your-VLA-Aligning-Visual-Representations-for-OOD-Generalization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-5-Dont-Blind-Your-VLA-Aligning-Visual-Representations-for-OOD-Generalization/","children":"[논문리뷰] Don't Blind Your VLA: Aligning Visual Representations for OOD Generalization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Aleksandr I. Panov이 [arXiv]에 게시한 'Don't Blind Your VLA: Aligning Visual Representations for OOD Generalization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:35:02+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action Models"]}],["$","span","OOD Generalization",{"className":"page__taxonomy-item","children":["#","OOD Generalization"]}],["$","span","Representation Alignment",{"className":"page__taxonomy-item","children":["#","Representation Alignment"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Visual Representations",{"className":"page__taxonomy-item","children":["#","Visual Representations"]}],["$","span","Attention Maps",{"className":"page__taxonomy-item","children":["#","Attention Maps"]}],["$","span","t-SNE",{"className":"page__taxonomy-item","children":["#","t-SNE"]}]]}]]}]]}],["$","article","2025-11-5-Discriminately-Treating-Motion-Components-Evolves-Joint-Depth-and-Ego-Motion-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-5-Discriminately-Treating-Motion-Components-Evolves-Joint-Depth-and-Ego-Motion-Learning/","children":"[논문리뷰] Discriminately Treating Motion Components Evolves Joint Depth and Ego-Motion Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zuyi Xiong이 [arXiv]에 게시한 'Discriminately Treating Motion Components Evolves Joint Depth and Ego-Motion Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:35:02+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Self-supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-supervised Learning"]}],["$","span","Depth Estimation",{"className":"page__taxonomy-item","children":["#","Depth Estimation"]}],["$","span","Ego-Motion Estimation",{"className":"page__taxonomy-item","children":["#","Ego-Motion Estimation"]}],["$","span","Motion Component Discrimination",{"className":"page__taxonomy-item","children":["#","Motion Component Discrimination"]}],["$","span","Geometric Constraints",{"className":"page__taxonomy-item","children":["#","Geometric Constraints"]}],["$","span","Optical Flow",{"className":"page__taxonomy-item","children":["#","Optical Flow"]}],["$","span","PoseNet",{"className":"page__taxonomy-item","children":["#","PoseNet"]}],["$","span","DepthNet",{"className":"page__taxonomy-item","children":["#","DepthNet"]}]]}]]}]]}],["$","article","2025-11-5-CodeClash-Benchmarking-Goal-Oriented-Software-Engineering",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-5-CodeClash-Benchmarking-Goal-Oriented-Software-Engineering/","children":"[논문리뷰] CodeClash: Benchmarking Goal-Oriented Software Engineering"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'CodeClash: Benchmarking Goal-Oriented Software Engineering' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:35:02+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Software Engineering Benchmarking",{"className":"page__taxonomy-item","children":["#","Software Engineering Benchmarking"]}],["$","span","Language Models",{"className":"page__taxonomy-item","children":["#","Language Models"]}],["$","span","AI Agents",{"className":"page__taxonomy-item","children":["#","AI Agents"]}],["$","span","Goal-Oriented Development",{"className":"page__taxonomy-item","children":["#","Goal-Oriented Development"]}],["$","span","Competitive Programming",{"className":"page__taxonomy-item","children":["#","Competitive Programming"]}],["$","span","Code Evolution",{"className":"page__taxonomy-item","children":["#","Code Evolution"]}],["$","span","Strategic Reasoning",{"className":"page__taxonomy-item","children":["#","Strategic Reasoning"]}],["$","span","Autonomous Systems",{"className":"page__taxonomy-item","children":["#","Autonomous Systems"]}]]}]]}]]}],["$","article","2025-11-5-ChartM3-A-Multi-Stage-Code-Driven-Pipeline-for-Constructing-Multi-Dimensional-and-Multi-Step-Visual-Reasoning-Data-in-Chart-Comprehension",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-5-ChartM3-A-Multi-Stage-Code-Driven-Pipeline-for-Constructing-Multi-Dimensional-and-Multi-Step-Visual-Reasoning-Data-in-Chart-Comprehension/","children":"[논문리뷰] ChartM^3: A Multi-Stage Code-Driven Pipeline for Constructing Multi-Dimensional and Multi-Step Visual Reasoning Data in Chart Comprehension"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hao Wang이 [arXiv]에 게시한 'ChartM^3: A Multi-Stage Code-Driven Pipeline for Constructing Multi-Dimensional and Multi-Step Visual Reasoning Data in Chart Comprehension' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:35:02+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Chart Comprehension",{"className":"page__taxonomy-item","children":["#","Chart Comprehension"]}],["$","span","Visual Reasoning",{"className":"page__taxonomy-item","children":["#","Visual Reasoning"]}],["$","span","Data Generation",{"className":"page__taxonomy-item","children":["#","Data Generation"]}],["$","span","Code-Driven Pipeline",{"className":"page__taxonomy-item","children":["#","Code-Driven Pipeline"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Synthetic Data",{"className":"page__taxonomy-item","children":["#","Synthetic Data"]}]]}]]}]]}],["$","article","2025-11-5-Can-Visual-Input-Be-Compressed-A-Visual-Token-Compression-Benchmark-for-Large-Multimodal-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-5-Can-Visual-Input-Be-Compressed-A-Visual-Token-Compression-Benchmark-for-Large-Multimodal-Models/","children":"[논문리뷰] Can Visual Input Be Compressed? A Visual Token Compression Benchmark for Large Multimodal Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shijie Dong이 [arXiv]에 게시한 'Can Visual Input Be Compressed? A Visual Token Compression Benchmark for Large Multimodal Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:35:02+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Multimodal Models",{"className":"page__taxonomy-item","children":["#","Large Multimodal Models"]}],["$","span","Visual Token Compression",{"className":"page__taxonomy-item","children":["#","Visual Token Compression"]}],["$","span","Token Pruning",{"className":"page__taxonomy-item","children":["#","Token Pruning"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Efficiency",{"className":"page__taxonomy-item","children":["#","Efficiency"]}],["$","span","Inference Latency",{"className":"page__taxonomy-item","children":["#","Inference Latency"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}]]}]]}]]}],["$","article","2025-11-5-Brain-IT-Image-Reconstruction-from-fMRI-via-Brain-Interaction-Transformer",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-5-Brain-IT-Image-Reconstruction-from-fMRI-via-Brain-Interaction-Transformer/","children":"[논문리뷰] Brain-IT: Image Reconstruction from fMRI via Brain-Interaction Transformer"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Brain-IT: Image Reconstruction from fMRI via Brain-Interaction Transformer' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:35:02+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","fMRI",{"className":"page__taxonomy-item","children":["#","fMRI"]}],["$","span","Image Reconstruction",{"className":"page__taxonomy-item","children":["#","Image Reconstruction"]}],["$","span","Brain-Computer Interface",{"className":"page__taxonomy-item","children":["#","Brain-Computer Interface"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Neural Decoding",{"className":"page__taxonomy-item","children":["#","Neural Decoding"]}],["$","span","Cross-Subject Learning",{"className":"page__taxonomy-item","children":["#","Cross-Subject Learning"]}],["$","span","Deep Image Prior",{"className":"page__taxonomy-item","children":["#","Deep Image Prior"]}]]}]]}]]}],["$","article","2025-11-5-BRAINS-A-Retrieval-Augmented-System-for-Alzheimers-Detection-and-Monitoring",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-5-BRAINS-A-Retrieval-Augmented-System-for-Alzheimers-Detection-and-Monitoring/","children":"[논문리뷰] BRAINS: A Retrieval-Augmented System for Alzheimer's Detection and Monitoring"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'BRAINS: A Retrieval-Augmented System for Alzheimer's Detection and Monitoring' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:35:02+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Alzheimer's Disease",{"className":"page__taxonomy-item","children":["#","Alzheimer's Disease"]}],["$","span","Retrieval-Augmented Generation (RAG)",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation (RAG)"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Clinical Decision Support",{"className":"page__taxonomy-item","children":["#","Clinical Decision Support"]}],["$","span","Multimodal Data Fusion",{"className":"page__taxonomy-item","children":["#","Multimodal Data Fusion"]}],["$","span","Cognitive Decline Detection",{"className":"page__taxonomy-item","children":["#","Cognitive Decline Detection"]}],["$","span","Early Diagnosis",{"className":"page__taxonomy-item","children":["#","Early Diagnosis"]}]]}]]}]]}],["$","article","2025-11-5-AyurParam-A-State-of-the-Art-Bilingual-Language-Model-for-Ayurveda",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-5-AyurParam-A-State-of-the-Art-Bilingual-Language-Model-for-Ayurveda/","children":"[논문리뷰] AyurParam: A State-of-the-Art Bilingual Language Model for Ayurveda"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'AyurParam: A State-of-the-Art Bilingual Language Model for Ayurveda' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:35:02+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Ayurveda LLM",{"className":"page__taxonomy-item","children":["#","Ayurveda LLM"]}],["$","span","Domain Adaptation",{"className":"page__taxonomy-item","children":["#","Domain Adaptation"]}],["$","span","Bilingual Language Model",{"className":"page__taxonomy-item","children":["#","Bilingual Language Model"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}],["$","span","Medical AI",{"className":"page__taxonomy-item","children":["#","Medical AI"]}],["$","span","Knowledge-Grounded QA",{"className":"page__taxonomy-item","children":["#","Knowledge-Grounded QA"]}],["$","span","Traditional Medicine",{"className":"page__taxonomy-item","children":["#","Traditional Medicine"]}]]}]]}]]}],["$","article","2025-11-4-leftcirclearrowrighttextBUSright-A-Large-and-Diverse-Multimodal-Benchmark-for-evaluating-the-ability-of-Vision-Language-Models-to-understand-Rebus-Puzzles",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-leftcirclearrowrighttextBUSright-A-Large-and-Diverse-Multimodal-Benchmark-for-evaluating-the-ability-of-Vision-Language-Models-to-understand-Rebus-Puzzles/","children":"[논문리뷰] left|,circlearrowright,text{BUS},right|: A Large and Diverse Multimodal Benchmark for evaluating the ability of Vision-Language Models to understand Rebus Puzzles"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Deepiha S이 [arXiv]에 게시한 'left|,circlearrowright,text{BUS},right|: A Large and Diverse Multimodal Benchmark for evaluating the ability of Vision-Language Models to understand Rebus Puzzles' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:22:42+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Multimodal Benchmark",{"className":"page__taxonomy-item","children":["#","Multimodal Benchmark"]}],["$","span","Rebus Puzzles",{"className":"page__taxonomy-item","children":["#","Rebus Puzzles"]}],["$","span","In-Context Learning",{"className":"page__taxonomy-item","children":["#","In-Context Learning"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","ControlNet",{"className":"page__taxonomy-item","children":["#","ControlNet"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}]]}]]}]]}],["$","article","2025-11-4-World-Simulation-with-Video-Foundation-Models-for-Physical-AI",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-World-Simulation-with-Video-Foundation-Models-for-Physical-AI/","children":"[논문리뷰] World Simulation with Video Foundation Models for Physical AI"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Junjie Bai이 [arXiv]에 게시한 'World Simulation with Video Foundation Models for Physical AI' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:22:42+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Physical AI",{"className":"page__taxonomy-item","children":["#","Physical AI"]}],["$","span","World Simulation",{"className":"page__taxonomy-item","children":["#","World Simulation"]}],["$","span","Video Foundation Models",{"className":"page__taxonomy-item","children":["#","Video Foundation Models"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Autonomous Driving",{"className":"page__taxonomy-item","children":["#","Autonomous Driving"]}],["$","span","Synthetic Data Generation",{"className":"page__taxonomy-item","children":["#","Synthetic Data Generation"]}]]}]]}]]}],["$","article","2025-11-4-Vote-in-Context-Turning-VLMs-into-Zero-Shot-Rank-Fusers",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-Vote-in-Context-Turning-VLMs-into-Zero-Shot-Rank-Fusers/","children":"[논문리뷰] Vote-in-Context: Turning VLMs into Zero-Shot Rank Fusers"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Vote-in-Context: Turning VLMs into Zero-Shot Rank Fusers' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:22:42+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Retrieval",{"className":"page__taxonomy-item","children":["#","Video Retrieval"]}],["$","span","Vision-Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision-Language Models (VLMs)"]}],["$","span","Zero-Shot Learning",{"className":"page__taxonomy-item","children":["#","Zero-Shot Learning"]}],["$","span","List-wise Reranking",{"className":"page__taxonomy-item","children":["#","List-wise Reranking"]}],["$","span","Rank Fusion",{"className":"page__taxonomy-item","children":["#","Rank Fusion"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","S-Grid",{"className":"page__taxonomy-item","children":["#","S-Grid"]}],["$","span","Multimodal Retrieval",{"className":"page__taxonomy-item","children":["#","Multimodal Retrieval"]}]]}]]}]]}],["$","article","2025-11-4-Unified-Diffusion-VLA-Vision-Language-Action-Model-via-Joint-Discrete-Denoising-Diffusion-Process",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-Unified-Diffusion-VLA-Vision-Language-Action-Model-via-Joint-Discrete-Denoising-Diffusion-Process/","children":"[논문리뷰] Unified Diffusion VLA: Vision-Language-Action Model via Joint Discrete Denoising Diffusion Process"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Unified Diffusion VLA: Vision-Language-Action Model via Joint Discrete Denoising Diffusion Process' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:22:42+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action (VLA)",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action (VLA)"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Discrete Denoising",{"className":"page__taxonomy-item","children":["#","Discrete Denoising"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Joint Generation",{"className":"page__taxonomy-item","children":["#","Joint Generation"]}],["$","span","Action Prediction",{"className":"page__taxonomy-item","children":["#","Action Prediction"]}]]}]]}]]}],["$","article","2025-11-4-UniREditBench-A-Unified-Reasoning-based-Image-Editing-Benchmark",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-UniREditBench-A-Unified-Reasoning-based-Image-Editing-Benchmark/","children":"[논문리뷰] UniREditBench: A Unified Reasoning-based Image Editing Benchmark"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'UniREditBench: A Unified Reasoning-based Image Editing Benchmark' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:22:42+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Reasoning-based AI",{"className":"page__taxonomy-item","children":["#","Reasoning-based AI"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Chain-of-Thought (CoT)",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought (CoT)"]}],["$","span","Dual-Reference Evaluation",{"className":"page__taxonomy-item","children":["#","Dual-Reference Evaluation"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Game AI",{"className":"page__taxonomy-item","children":["#","Game AI"]}]]}]]}]]}],["$","article","2025-11-4-UniLumos-Fast-and-Unified-Image-and-Video-Relighting-with-Physics-Plausible-Feedback",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-UniLumos-Fast-and-Unified-Image-and-Video-Relighting-with-Physics-Plausible-Feedback/","children":"[논문리뷰] UniLumos: Fast and Unified Image and Video Relighting with Physics-Plausible Feedback"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'UniLumos: Fast and Unified Image and Video Relighting with Physics-Plausible Feedback' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:22:42+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Relighting",{"className":"page__taxonomy-item","children":["#","Relighting"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Physics-Plausible Feedback",{"className":"page__taxonomy-item","children":["#","Physics-Plausible Feedback"]}],["$","span","Image-to-Video",{"className":"page__taxonomy-item","children":["#","Image-to-Video"]}],["$","span","Geometric Supervision",{"className":"page__taxonomy-item","children":["#","Geometric Supervision"]}],["$","span","Path Consistency Learning",{"className":"page__taxonomy-item","children":["#","Path Consistency Learning"]}],["$","span","LumosBench",{"className":"page__taxonomy-item","children":["#","LumosBench"]}]]}]]}]]}],["$","article","2025-11-4-UME-R1-Exploring-Reasoning-Driven-Generative-Multimodal-Embeddings",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-UME-R1-Exploring-Reasoning-Driven-Generative-Multimodal-Embeddings/","children":"[논문리뷰] UME-R1: Exploring Reasoning-Driven Generative Multimodal Embeddings"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jinsong Su이 [arXiv]에 게시한 'UME-R1: Exploring Reasoning-Driven Generative Multimodal Embeddings' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:22:42+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Embeddings",{"className":"page__taxonomy-item","children":["#","Multimodal Embeddings"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","MLLMs",{"className":"page__taxonomy-item","children":["#","MLLMs"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Information Retrieval",{"className":"page__taxonomy-item","children":["#","Information Retrieval"]}],["$","span","Unified Embeddings",{"className":"page__taxonomy-item","children":["#","Unified Embeddings"]}]]}]]}]]}],["$","article","2025-11-4-Trove-A-Flexible-Toolkit-for-Dense-Retrieval",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-Trove-A-Flexible-Toolkit-for-Dense-Retrieval/","children":"[논문리뷰] Trove: A Flexible Toolkit for Dense Retrieval"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Trove: A Flexible Toolkit for Dense Retrieval' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:22:42+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Dense Retrieval",{"className":"page__taxonomy-item","children":["#","Dense Retrieval"]}],["$","span","Retrieval Toolkit",{"className":"page__taxonomy-item","children":["#","Retrieval Toolkit"]}],["$","span","Data Management",{"className":"page__taxonomy-item","children":["#","Data Management"]}],["$","span","Distributed Training",{"className":"page__taxonomy-item","children":["#","Distributed Training"]}],["$","span","Model Customization",{"className":"page__taxonomy-item","children":["#","Model Customization"]}],["$","span","Hard Negative Mining",{"className":"page__taxonomy-item","children":["#","Hard Negative Mining"]}],["$","span","Hugging Face Integration",{"className":"page__taxonomy-item","children":["#","Hugging Face Integration"]}],["$","span","Performance Optimization",{"className":"page__taxonomy-item","children":["#","Performance Optimization"]}]]}]]}]]}],["$","article","2025-11-4-Towards-Universal-Video-Retrieval-Generalizing-Video-Embedding-via-Synthesized-Multimodal-Pyramid-Curriculum",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-Towards-Universal-Video-Retrieval-Generalizing-Video-Embedding-via-Synthesized-Multimodal-Pyramid-Curriculum/","children":"[논문리뷰] Towards Universal Video Retrieval: Generalizing Video Embedding via Synthesized Multimodal Pyramid Curriculum"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Towards Universal Video Retrieval: Generalizing Video Embedding via Synthesized Multimodal Pyramid Curriculum' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:22:42+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Retrieval",{"className":"page__taxonomy-item","children":["#","Video Retrieval"]}],["$","span","Multimodal Embedding",{"className":"page__taxonomy-item","children":["#","Multimodal Embedding"]}],["$","span","Data Synthesis",{"className":"page__taxonomy-item","children":["#","Data Synthesis"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Zero-shot Generalization",{"className":"page__taxonomy-item","children":["#","Zero-shot Generalization"]}],["$","span","Benchmark Design",{"className":"page__taxonomy-item","children":["#","Benchmark Design"]}],["$","span","MLLM",{"className":"page__taxonomy-item","children":["#","MLLM"]}],["$","span","Video-Text Retrieval",{"className":"page__taxonomy-item","children":["#","Video-Text Retrieval"]}]]}]]}]]}],["$","article","2025-11-4-Towards-Robust-Mathematical-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-Towards-Robust-Mathematical-Reasoning/","children":"[논문리뷰] Towards Robust Mathematical Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuri Chervonyi이 [arXiv]에 게시한 'Towards Robust Mathematical Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:22:42+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","AI Benchmarks",{"className":"page__taxonomy-item","children":["#","AI Benchmarks"]}],["$","span","International Mathematical Olympiad (IMO)",{"className":"page__taxonomy-item","children":["#","International Mathematical Olympiad (IMO)"]}],["$","span","Proof Verification",{"className":"page__taxonomy-item","children":["#","Proof Verification"]}],["$","span","Automatic Grading",{"className":"page__taxonomy-item","children":["#","Automatic Grading"]}],["$","span","Robustness",{"className":"page__taxonomy-item","children":["#","Robustness"]}]]}]]}]]}],["$","article","2025-11-4-ToolScope-An-Agentic-Framework-for-Vision-Guided-and-Long-Horizon-Tool-Use",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-ToolScope-An-Agentic-Framework-for-Vision-Guided-and-Long-Horizon-Tool-Use/","children":"[논문리뷰] ToolScope: An Agentic Framework for Vision-Guided and Long-Horizon Tool Use"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Guanting Dong이 [arXiv]에 게시한 'ToolScope: An Agentic Framework for Vision-Guided and Long-Horizon Tool Use' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:22:42+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Agents",{"className":"page__taxonomy-item","children":["#","Multimodal Agents"]}],["$","span","Tool-Augmented LLMs",{"className":"page__taxonomy-item","children":["#","Tool-Augmented LLMs"]}],["$","span","Vision-Guided Reasoning",{"className":"page__taxonomy-item","children":["#","Vision-Guided Reasoning"]}],["$","span","Long-Horizon Tasks",{"className":"page__taxonomy-item","children":["#","Long-Horizon Tasks"]}],["$","span","VQA",{"className":"page__taxonomy-item","children":["#","VQA"]}],["$","span","Global Planning",{"className":"page__taxonomy-item","children":["#","Global Planning"]}],["$","span","Context Preservation",{"className":"page__taxonomy-item","children":["#","Context Preservation"]}],["$","span","Perceive Tool",{"className":"page__taxonomy-item","children":["#","Perceive Tool"]}]]}]]}]]}],["$","article","2025-11-4-The-Underappreciated-Power-of-Vision-Models-for-Graph-Structural-Understanding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-The-Underappreciated-Power-of-Vision-Models-for-Graph-Structural-Understanding/","children":"[논문리뷰] The Underappreciated Power of Vision Models for Graph Structural Understanding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Lei Zhang이 [arXiv]에 게시한 'The Underappreciated Power of Vision Models for Graph Structural Understanding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:22:42+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Graph Neural Networks",{"className":"page__taxonomy-item","children":["#","Graph Neural Networks"]}],["$","span","Vision Models",{"className":"page__taxonomy-item","children":["#","Vision Models"]}],["$","span","Graph Understanding",{"className":"page__taxonomy-item","children":["#","Graph Understanding"]}],["$","span","Topological Perception",{"className":"page__taxonomy-item","children":["#","Topological Perception"]}],["$","span","GraphAbstract Benchmark",{"className":"page__taxonomy-item","children":["#","GraphAbstract Benchmark"]}],["$","span","OOD Generalization",{"className":"page__taxonomy-item","children":["#","OOD Generalization"]}],["$","span","Graph Visualization",{"className":"page__taxonomy-item","children":["#","Graph Visualization"]}]]}]]}]]}],["$","article","2025-11-4-TIR-Bench-A-Comprehensive-Benchmark-for-Agentic-Thinking-with-Images-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-TIR-Bench-A-Comprehensive-Benchmark-for-Agentic-Thinking-with-Images-Reasoning/","children":"[논문리뷰] TIR-Bench: A Comprehensive Benchmark for Agentic Thinking-with-Images Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shaoheng Lin이 [arXiv]에 게시한 'TIR-Bench: A Comprehensive Benchmark for Agentic Thinking-with-Images Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:22:42+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Agentic Reasoning",{"className":"page__taxonomy-item","children":["#","Agentic Reasoning"]}],["$","span","Thinking-with-Images",{"className":"page__taxonomy-item","children":["#","Thinking-with-Images"]}],["$","span","Visual Reasoning Benchmark",{"className":"page__taxonomy-item","children":["#","Visual Reasoning Benchmark"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Image Manipulation",{"className":"page__taxonomy-item","children":["#","Image Manipulation"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}]]}]]}]]}],["$","article","2025-11-4-ROVER-Benchmarking-Reciprocal-Cross-Modal-Reasoning-for-Omnimodal-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-ROVER-Benchmarking-Reciprocal-Cross-Modal-Reasoning-for-Omnimodal-Generation/","children":"[논문리뷰] ROVER: Benchmarking Reciprocal Cross-Modal Reasoning for Omnimodal Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Feng Li이 [arXiv]에 게시한 'ROVER: Benchmarking Reciprocal Cross-Modal Reasoning for Omnimodal Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:22:42+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Cross-Modal Reasoning",{"className":"page__taxonomy-item","children":["#","Cross-Modal Reasoning"]}],["$","span","Omnimodal Generation",{"className":"page__taxonomy-item","children":["#","Omnimodal Generation"]}],["$","span","Visual Generation",{"className":"page__taxonomy-item","children":["#","Visual Generation"]}],["$","span","Verbal Generation",{"className":"page__taxonomy-item","children":["#","Verbal Generation"]}],["$","span","Unified Multimodal Models",{"className":"page__taxonomy-item","children":["#","Unified Multimodal Models"]}]]}]]}]]}],["$","article","2025-11-4-PHUMA-Physically-Grounded-Humanoid-Locomotion-Dataset",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-PHUMA-Physically-Grounded-Humanoid-Locomotion-Dataset/","children":"[논문리뷰] PHUMA: Physically-Grounded Humanoid Locomotion Dataset"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'PHUMA: Physically-Grounded Humanoid Locomotion Dataset' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:22:42+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Humanoid Locomotion",{"className":"page__taxonomy-item","children":["#","Humanoid Locomotion"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}],["$","span","Motion Imitation",{"className":"page__taxonomy-item","children":["#","Motion Imitation"]}],["$","span","Physics-based Control",{"className":"page__taxonomy-item","children":["#","Physics-based Control"]}],["$","span","Motion Retargeting",{"className":"page__taxonomy-item","children":["#","Motion Retargeting"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Inverse Kinematics",{"className":"page__taxonomy-item","children":["#","Inverse Kinematics"]}]]}]]}]]}],["$","article","2025-11-4-OpenSIR-Open-Ended-Self-Improving-Reasoner",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-OpenSIR-Open-Ended-Self-Improving-Reasoner/","children":"[논문리뷰] OpenSIR: Open-Ended Self-Improving Reasoner"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'OpenSIR: Open-Ended Self-Improving Reasoner' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:22:42+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Open-Ended Learning",{"className":"page__taxonomy-item","children":["#","Open-Ended Learning"]}],["$","span","Self-Play",{"className":"page__taxonomy-item","children":["#","Self-Play"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Problem Generation",{"className":"page__taxonomy-item","children":["#","Problem Generation"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Reward Shaping",{"className":"page__taxonomy-item","children":["#","Reward Shaping"]}]]}]]}]]}],["$","article","2025-11-4-NaviTrace-Evaluating-Embodied-Navigation-of-Vision-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-NaviTrace-Evaluating-Embodied-Navigation-of-Vision-Language-Models/","children":"[논문리뷰] NaviTrace: Evaluating Embodied Navigation of Vision-Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'NaviTrace: Evaluating Embodied Navigation of Vision-Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:22:42+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Embodied Navigation",{"className":"page__taxonomy-item","children":["#","Embodied Navigation"]}],["$","span","VQA Benchmark",{"className":"page__taxonomy-item","children":["#","VQA Benchmark"]}],["$","span","Robotic Navigation",{"className":"page__taxonomy-item","children":["#","Robotic Navigation"]}],["$","span","Semantic-aware Score",{"className":"page__taxonomy-item","children":["#","Semantic-aware Score"]}],["$","span","Dynamic Time Warping",{"className":"page__taxonomy-item","children":["#","Dynamic Time Warping"]}],["$","span","Real-world Scenarios",{"className":"page__taxonomy-item","children":["#","Real-world Scenarios"]}]]}]]}]]}],["$","article","2025-11-4-Multi-Step-Knowledge-Interaction-Analysis-via-Rank-2-Subspace-Disentanglement",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-Multi-Step-Knowledge-Interaction-Analysis-via-Rank-2-Subspace-Disentanglement/","children":"[논문리뷰] Multi-Step Knowledge Interaction Analysis via Rank-2 Subspace Disentanglement"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Isabelle Augenstein이 [arXiv]에 게시한 'Multi-Step Knowledge Interaction Analysis via Rank-2 Subspace Disentanglement' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:22:42+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Knowledge Interaction",{"className":"page__taxonomy-item","children":["#","Knowledge Interaction"]}],["$","span","Parametric Knowledge",{"className":"page__taxonomy-item","children":["#","Parametric Knowledge"]}],["$","span","Contextual Knowledge",{"className":"page__taxonomy-item","children":["#","Contextual Knowledge"]}],["$","span","Subspace Disentanglement",{"className":"page__taxonomy-item","children":["#","Subspace Disentanglement"]}],["$","span","NLE Generation",{"className":"page__taxonomy-item","children":["#","NLE Generation"]}],["$","span","Hallucination Detection",{"className":"page__taxonomy-item","children":["#","Hallucination Detection"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}]]}]]}]]}],["$","article","2025-11-4-MotionStream-Real-Time-Video-Generation-with-Interactive-Motion-Controls",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-MotionStream-Real-Time-Video-Generation-with-Interactive-Motion-Controls/","children":"[논문리뷰] MotionStream: Real-Time Video Generation with Interactive Motion Controls"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'MotionStream: Real-Time Video Generation with Interactive Motion Controls' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:22:42+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Real-Time Video Generation",{"className":"page__taxonomy-item","children":["#","Real-Time Video Generation"]}],["$","span","Motion Control",{"className":"page__taxonomy-item","children":["#","Motion Control"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Autoregressive Generation",{"className":"page__taxonomy-item","children":["#","Autoregressive Generation"]}],["$","span","Self-Forcing",{"className":"page__taxonomy-item","children":["#","Self-Forcing"]}],["$","span","Attention Sink",{"className":"page__taxonomy-item","children":["#","Attention Sink"]}],["$","span","Streaming Inference",{"className":"page__taxonomy-item","children":["#","Streaming Inference"]}],["$","span","Video Distillation",{"className":"page__taxonomy-item","children":["#","Video Distillation"]}]]}]]}]]}],["$","article","2025-11-4-MR-Align-Meta-Reasoning-Informed-Factuality-Alignment-for-Large-Reasoning-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-MR-Align-Meta-Reasoning-Informed-Factuality-Alignment-for-Large-Reasoning-Models/","children":"[논문리뷰] MR-Align: Meta-Reasoning Informed Factuality Alignment for Large Reasoning Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Bin Yu이 [arXiv]에 게시한 'MR-Align: Meta-Reasoning Informed Factuality Alignment for Large Reasoning Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:22:42+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Reasoning Models",{"className":"page__taxonomy-item","children":["#","Large Reasoning Models"]}],["$","span","Factuality Alignment",{"className":"page__taxonomy-item","children":["#","Factuality Alignment"]}],["$","span","Meta-Reasoning",{"className":"page__taxonomy-item","children":["#","Meta-Reasoning"]}],["$","span","Kahneman-Tversky Optimization",{"className":"page__taxonomy-item","children":["#","Kahneman-Tversky Optimization"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Hallucination",{"className":"page__taxonomy-item","children":["#","Hallucination"]}],["$","span","Process-Level Alignment",{"className":"page__taxonomy-item","children":["#","Process-Level Alignment"]}]]}]]}]]}],["$","article","2025-11-4-LongCat-Flash-Omni-Technical-Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-LongCat-Flash-Omni-Technical-Report/","children":"[논문리뷰] LongCat-Flash-Omni Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Bin Xiao이 [arXiv]에 게시한 'LongCat-Flash-Omni Technical Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:22:42+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Omni-modal AI",{"className":"page__taxonomy-item","children":["#","Omni-modal AI"]}],["$","span","Multimodal LLM",{"className":"page__taxonomy-item","children":["#","Multimodal LLM"]}],["$","span","Real-time Interaction",{"className":"page__taxonomy-item","children":["#","Real-time Interaction"]}],["$","span","Mixture-of-Experts (MoE)",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts (MoE)"]}],["$","span","Streaming Inference",{"className":"page__taxonomy-item","children":["#","Streaming Inference"]}],["$","span","Distributed Training",{"className":"page__taxonomy-item","children":["#","Distributed Training"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Audio-Visual Perception",{"className":"page__taxonomy-item","children":["#","Audio-Visual Perception"]}]]}]]}]]}],["$","article","2025-11-4-How-Far-Are-Surgeons-from-Surgical-World-Models-A-Pilot-Study-on-Zero-shot-Surgical-Video-Generation-with-Expert-Assessment",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-How-Far-Are-Surgeons-from-Surgical-World-Models-A-Pilot-Study-on-Zero-shot-Surgical-Video-Generation-with-Expert-Assessment/","children":"[논문리뷰] How Far Are Surgeons from Surgical World Models? A Pilot Study on Zero-shot Surgical Video Generation with Expert Assessment"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuhao Zhai이 [arXiv]에 게시한 'How Far Are Surgeons from Surgical World Models? A Pilot Study on Zero-shot Surgical Video Generation with Expert Assessment' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:22:42+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","World Models",{"className":"page__taxonomy-item","children":["#","World Models"]}],["$","span","Surgical AI",{"className":"page__taxonomy-item","children":["#","Surgical AI"]}],["$","span","Zero-shot Prediction",{"className":"page__taxonomy-item","children":["#","Zero-shot Prediction"]}],["$","span","Expert Evaluation",{"className":"page__taxonomy-item","children":["#","Expert Evaluation"]}],["$","span","Plausibility Gap",{"className":"page__taxonomy-item","children":["#","Plausibility Gap"]}],["$","span","Medical Simulation",{"className":"page__taxonomy-item","children":["#","Medical Simulation"]}]]}]]}]]}],["$","article","2025-11-4-Generalizing-Test-time-Compute-optimal-Scaling-as-an-Optimizable-Graph",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-Generalizing-Test-time-Compute-optimal-Scaling-as-an-Optimizable-Graph/","children":"[논문리뷰] Generalizing Test-time Compute-optimal Scaling as an Optimizable Graph"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Generalizing Test-time Compute-optimal Scaling as an Optimizable Graph' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:22:42+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Test-Time Scaling",{"className":"page__taxonomy-item","children":["#","Test-Time Scaling"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Graph Optimization",{"className":"page__taxonomy-item","children":["#","Graph Optimization"]}],["$","span","REINFORCE",{"className":"page__taxonomy-item","children":["#","REINFORCE"]}],["$","span","Multi-agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-agent Systems"]}],["$","span","Adaptive Architectures",{"className":"page__taxonomy-item","children":["#","Adaptive Architectures"]}],["$","span","Compute-optimal Scaling",{"className":"page__taxonomy-item","children":["#","Compute-optimal Scaling"]}],["$","span","Probabilistic Graphs",{"className":"page__taxonomy-item","children":["#","Probabilistic Graphs"]}]]}]]}]]}],["$","article","2025-11-4-GUI-AIMA-Aligning-Intrinsic-Multimodal-Attention-with-a-Context-Anchor-for-GUI-Grounding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-GUI-AIMA-Aligning-Intrinsic-Multimodal-Attention-with-a-Context-Anchor-for-GUI-Grounding/","children":"[논문리뷰] GUI-AIMA: Aligning Intrinsic Multimodal Attention with a Context Anchor for GUI Grounding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wanrong Zhu이 [arXiv]에 게시한 'GUI-AIMA: Aligning Intrinsic Multimodal Attention with a Context Anchor for GUI Grounding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:22:42+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","GUI Grounding",{"className":"page__taxonomy-item","children":["#","GUI Grounding"]}],["$","span","Multimodal Attention",{"className":"page__taxonomy-item","children":["#","Multimodal Attention"]}],["$","span","MLLMs",{"className":"page__taxonomy-item","children":["#","MLLMs"]}],["$","span","Coordinate-Free",{"className":"page__taxonomy-item","children":["#","Coordinate-Free"]}],["$","span","Visual Grounding",{"className":"page__taxonomy-item","children":["#","Visual Grounding"]}],["$","span","Attention Weighting",{"className":"page__taxonomy-item","children":["#","Attention Weighting"]}],["$","span","Anchor Token",{"className":"page__taxonomy-item","children":["#","Anchor Token"]}]]}]]}]]}],["$","article","2025-11-4-Every-Activation-Boosted-Scaling-General-Reasoner-to-1-Trillion-Open-Language-Foundation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-Every-Activation-Boosted-Scaling-General-Reasoner-to-1-Trillion-Open-Language-Foundation/","children":"[논문리뷰] Every Activation Boosted: Scaling General Reasoner to 1 Trillion Open Language Foundation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Every Activation Boosted: Scaling General Reasoner to 1 Trillion Open Language Foundation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:22:42+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Mixture-of-Experts",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts"]}],["$","span","Reasoning Capability",{"className":"page__taxonomy-item","children":["#","Reasoning Capability"]}],["$","span","Sparse Activation",{"className":"page__taxonomy-item","children":["#","Sparse Activation"]}],["$","span","Scaling Laws",{"className":"page__taxonomy-item","children":["#","Scaling Laws"]}],["$","span","FP8 Training",{"className":"page__taxonomy-item","children":["#","FP8 Training"]}],["$","span","Efficient Training",{"className":"page__taxonomy-item","children":["#","Efficient Training"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}]]}]]}]]}],["$","article","2025-11-4-EBT-Policy-Energy-Unlocks-Emergent-Physical-Reasoning-Capabilities",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-EBT-Policy-Energy-Unlocks-Emergent-Physical-Reasoning-Capabilities/","children":"[논문리뷰] EBT-Policy: Energy Unlocks Emergent Physical Reasoning Capabilities"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yunxin Liu이 [arXiv]에 게시한 'EBT-Policy: Energy Unlocks Emergent Physical Reasoning Capabilities' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:22:42+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Energy-Based Models (EBMs)",{"className":"page__taxonomy-item","children":["#","Energy-Based Models (EBMs)"]}],["$","span","Diffusion Policy",{"className":"page__taxonomy-item","children":["#","Diffusion Policy"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Behavior Cloning",{"className":"page__taxonomy-item","children":["#","Behavior Cloning"]}],["$","span","Physical Reasoning",{"className":"page__taxonomy-item","children":["#","Physical Reasoning"]}],["$","span","Uncertainty Modeling",{"className":"page__taxonomy-item","children":["#","Uncertainty Modeling"]}],["$","span","Emergent Behavior",{"className":"page__taxonomy-item","children":["#","Emergent Behavior"]}],["$","span","Robot Manipulation",{"className":"page__taxonomy-item","children":["#","Robot Manipulation"]}]]}]]}]]}],["$","article","2025-11-4-Do-Vision-Language-Models-Measure-Up-Benchmarking-Visual-Measurement-Reading-with-MeasureBench",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-Do-Vision-Language-Models-Measure-Up-Benchmarking-Visual-Measurement-Reading-with-MeasureBench/","children":"[논문리뷰] Do Vision-Language Models Measure Up? Benchmarking Visual Measurement Reading with MeasureBench"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Do Vision-Language Models Measure Up? Benchmarking Visual Measurement Reading with MeasureBench' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:22:42+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Visual Measurement Reading",{"className":"page__taxonomy-item","children":["#","Visual Measurement Reading"]}],["$","span","Synthetic Data Generation",{"className":"page__taxonomy-item","children":["#","Synthetic Data Generation"]}],["$","span","Fine-grained Perception",{"className":"page__taxonomy-item","children":["#","Fine-grained Perception"]}],["$","span","Spatial Grounding",{"className":"page__taxonomy-item","children":["#","Spatial Grounding"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}]]}]]}]]}],["$","article","2025-11-4-Data-Efficient-RLVR-via-Off-Policy-Influence-Guidance",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-Data-Efficient-RLVR-via-Off-Policy-Influence-Guidance/","children":"[논문리뷰] Data-Efficient RLVR via Off-Policy Influence Guidance"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiale Cheng이 [arXiv]에 게시한 'Data-Efficient RLVR via Off-Policy Influence Guidance' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:22:42+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning with Verifiable Rewards (RLVR)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning with Verifiable Rewards (RLVR)"]}],["$","span","Influence Functions",{"className":"page__taxonomy-item","children":["#","Influence Functions"]}],["$","span","Data Selection",{"className":"page__taxonomy-item","children":["#","Data Selection"]}],["$","span","Off-Policy Learning",{"className":"page__taxonomy-item","children":["#","Off-Policy Learning"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Sparse Random Projection",{"className":"page__taxonomy-item","children":["#","Sparse Random Projection"]}],["$","span","Data Efficiency",{"className":"page__taxonomy-item","children":["#","Data Efficiency"]}]]}]]}]]}],["$","article","2025-11-4-AthenaBench-A-Dynamic-Benchmark-for-Evaluating-LLMs-in-Cyber-Threat-Intelligence",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-AthenaBench-A-Dynamic-Benchmark-for-Evaluating-LLMs-in-Cyber-Threat-Intelligence/","children":"[논문리뷰] AthenaBench: A Dynamic Benchmark for Evaluating LLMs in Cyber Threat Intelligence"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Peter Worth이 [arXiv]에 게시한 'AthenaBench: A Dynamic Benchmark for Evaluating LLMs in Cyber Threat Intelligence' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:22:42+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Benchmarking",{"className":"page__taxonomy-item","children":["#","LLM Benchmarking"]}],["$","span","Cyber Threat Intelligence (CTI)",{"className":"page__taxonomy-item","children":["#","Cyber Threat Intelligence (CTI)"]}],["$","span","Dynamic Evaluation",{"className":"page__taxonomy-item","children":["#","Dynamic Evaluation"]}],["$","span","CTI Reasoning",{"className":"page__taxonomy-item","children":["#","CTI Reasoning"]}],["$","span","Vulnerability Prediction",{"className":"page__taxonomy-item","children":["#","Vulnerability Prediction"]}],["$","span","Threat Actor Attribution",{"className":"page__taxonomy-item","children":["#","Threat Actor Attribution"]}],["$","span","Risk Mitigation",{"className":"page__taxonomy-item","children":["#","Risk Mitigation"]}],["$","span","Natural Language Processing",{"className":"page__taxonomy-item","children":["#","Natural Language Processing"]}]]}]]}]]}],["$","article","2025-11-4-Actial-Activate-Spatial-Reasoning-Ability-of-Multimodal-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-4-Actial-Activate-Spatial-Reasoning-Ability-of-Multimodal-Large-Language-Models/","children":"[논문리뷰] Actial: Activate Spatial Reasoning Ability of Multimodal Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Changfeng Ma이 [arXiv]에 게시한 'Actial: Activate Spatial Reasoning Ability of Multimodal Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:22:42+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}],["$","span","Viewpoint Learning",{"className":"page__taxonomy-item","children":["#","Viewpoint Learning"]}],["$","span","Two-Stage Fine-tuning",{"className":"page__taxonomy-item","children":["#","Two-Stage Fine-tuning"]}],["$","span","3D Consistency",{"className":"page__taxonomy-item","children":["#","3D Consistency"]}],["$","span","Viewpoint-100K",{"className":"page__taxonomy-item","children":["#","Viewpoint-100K"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}]]}]]}]]}],["$","article","2025-11-3-pi-RL-Online-RL-Fine-tuning-for-Flow-based-Vision-Language-Action-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-3-pi-RL-Online-RL-Fine-tuning-for-Flow-based-Vision-Language-Action-Models/","children":"[논문리뷰] π_RL: Online RL Fine-tuning for Flow-based Vision-Language-Action Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'π_RL: Online RL Fine-tuning for Flow-based Vision-Language-Action Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:01:31+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Vision-Language-Action Models (VLAs)",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action Models (VLAs)"]}],["$","span","Flow-based Models",{"className":"page__taxonomy-item","children":["#","Flow-based Models"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","SDE",{"className":"page__taxonomy-item","children":["#","SDE"]}],["$","span","MDP",{"className":"page__taxonomy-item","children":["#","MDP"]}]]}]]}]]}],["$","article","2025-11-3-Visual-Backdoor-Attacks-on-MLLM-Embodied-Decision-Making-via-Contrastive-Trigger-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-3-Visual-Backdoor-Attacks-on-MLLM-Embodied-Decision-Making-via-Contrastive-Trigger-Learning/","children":"[논문리뷰] Visual Backdoor Attacks on MLLM Embodied Decision Making via Contrastive Trigger Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hanyang Chen이 [arXiv]에 게시한 'Visual Backdoor Attacks on MLLM Embodied Decision Making via Contrastive Trigger Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:01:31+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Visual Backdoor Attacks",{"className":"page__taxonomy-item","children":["#","Visual Backdoor Attacks"]}],["$","span","MLLM Embodied Agents",{"className":"page__taxonomy-item","children":["#","MLLM Embodied Agents"]}],["$","span","Contrastive Trigger Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Trigger Learning"]}],["$","span","Policy Manipulation",{"className":"page__taxonomy-item","children":["#","Policy Manipulation"]}],["$","span","Adversarial AI",{"className":"page__taxonomy-item","children":["#","Adversarial AI"]}],["$","span","Embodied AI Security",{"className":"page__taxonomy-item","children":["#","Embodied AI Security"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}]]}]]}]]}],["$","article","2025-11-3-Value-Drifts-Tracing-Value-Alignment-During-LLM-Post-Training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-3-Value-Drifts-Tracing-Value-Alignment-During-LLM-Post-Training/","children":"[논문리뷰] Value Drifts: Tracing Value Alignment During LLM Post-Training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Value Drifts: Tracing Value Alignment During LLM Post-Training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:01:31+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Alignment",{"className":"page__taxonomy-item","children":["#","LLM Alignment"]}],["$","span","Value Drift",{"className":"page__taxonomy-item","children":["#","Value Drift"]}],["$","span","Supervised Fine-Tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning (SFT)"]}],["$","span","Preference Optimization",{"className":"page__taxonomy-item","children":["#","Preference Optimization"]}],["$","span","RLHF",{"className":"page__taxonomy-item","children":["#","RLHF"]}],["$","span","Llama-3",{"className":"page__taxonomy-item","children":["#","Llama-3"]}],["$","span","Qwen-3",{"className":"page__taxonomy-item","children":["#","Qwen-3"]}],["$","span","Human Values",{"className":"page__taxonomy-item","children":["#","Human Values"]}]]}]]}]]}],["$","article","2025-11-3-Spatial-SSRL-Enhancing-Spatial-Understanding-via-Self-Supervised-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-3-Spatial-SSRL-Enhancing-Spatial-Understanding-via-Self-Supervised-Reinforcement-Learning/","children":"[논문리뷰] Spatial-SSRL: Enhancing Spatial Understanding via Self-Supervised Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Spatial-SSRL: Enhancing Spatial Understanding via Self-Supervised Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:01:31+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Self-supervised learning",{"className":"page__taxonomy-item","children":["#","Self-supervised learning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Spatial Understanding",{"className":"page__taxonomy-item","children":["#","Spatial Understanding"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Pretext Tasks",{"className":"page__taxonomy-item","children":["#","Pretext Tasks"]}],["$","span","RGB-D Images",{"className":"page__taxonomy-item","children":["#","RGB-D Images"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}]]}]]}]]}],["$","article","2025-11-3-SemCoT-Accelerating-Chain-of-Thought-Reasoning-through-Semantically-Aligned-Implicit-Tokens",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-3-SemCoT-Accelerating-Chain-of-Thought-Reasoning-through-Semantically-Aligned-Implicit-Tokens/","children":"[논문리뷰] SemCoT: Accelerating Chain-of-Thought Reasoning through Semantically-Aligned Implicit Tokens"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'SemCoT: Accelerating Chain-of-Thought Reasoning through Semantically-Aligned Implicit Tokens' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:01:31+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Chain-of-Thought (CoT)",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought (CoT)"]}],["$","span","Implicit Reasoning",{"className":"page__taxonomy-item","children":["#","Implicit Reasoning"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Semantic Alignment",{"className":"page__taxonomy-item","children":["#","Semantic Alignment"]}],["$","span","Efficiency Optimization",{"className":"page__taxonomy-item","children":["#","Efficiency Optimization"]}],["$","span","Knowledge Distillation",{"className":"page__taxonomy-item","children":["#","Knowledge Distillation"]}]]}]]}]]}],["$","article","2025-11-3-Revisiting-Multimodal-Positional-Encoding-in-Vision-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-3-Revisiting-Multimodal-Positional-Encoding-in-Vision-Language-Models/","children":"[논문리뷰] Revisiting Multimodal Positional Encoding in Vision-Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Revisiting Multimodal Positional Encoding in Vision-Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:01:31+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Positional Encoding",{"className":"page__taxonomy-item","children":["#","Multimodal Positional Encoding"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Rotary Positional Embedding (RoPE)",{"className":"page__taxonomy-item","children":["#","Rotary Positional Embedding (RoPE)"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Multimodal Understanding",{"className":"page__taxonomy-item","children":["#","Multimodal Understanding"]}],["$","span","Visual Grounding",{"className":"page__taxonomy-item","children":["#","Visual Grounding"]}],["$","span","Frequency Allocation",{"className":"page__taxonomy-item","children":["#","Frequency Allocation"]}],["$","span","Position Design",{"className":"page__taxonomy-item","children":["#","Position Design"]}]]}]]}]]}],["$","article","2025-11-3-Rank-GRPO-Training-LLM-based-Conversational-Recommender-Systems-with-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-3-Rank-GRPO-Training-LLM-based-Conversational-Recommender-Systems-with-Reinforcement-Learning/","children":"[논문리뷰] Rank-GRPO: Training LLM-based Conversational Recommender Systems with Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Rank-GRPO: Training LLM-based Conversational Recommender Systems with Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:01:31+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Conversational Recommender Systems",{"className":"page__taxonomy-item","children":["#","Conversational Recommender Systems"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Group Relative Policy Optimization",{"className":"page__taxonomy-item","children":["#","Group Relative Policy Optimization"]}],["$","span","Rank-based Learning",{"className":"page__taxonomy-item","children":["#","Rank-based Learning"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Reward Shaping",{"className":"page__taxonomy-item","children":["#","Reward Shaping"]}]]}]]}]]}],["$","article","2025-11-3-Phased-DMD-Few-step-Distribution-Matching-Distillation-via-Score-Matching-within-Subintervals",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-3-Phased-DMD-Few-step-Distribution-Matching-Distillation-via-Score-Matching-within-Subintervals/","children":"[논문리뷰] Phased DMD: Few-step Distribution Matching Distillation via Score Matching within Subintervals"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Phased DMD: Few-step Distribution Matching Distillation via Score Matching within Subintervals' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:01:31+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Distribution Matching Distillation",{"className":"page__taxonomy-item","children":["#","Distribution Matching Distillation"]}],["$","span","Few-step Diffusion",{"className":"page__taxonomy-item","children":["#","Few-step Diffusion"]}],["$","span","Score Matching",{"className":"page__taxonomy-item","children":["#","Score Matching"]}],["$","span","Mixture-of-Experts",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Model Distillation",{"className":"page__taxonomy-item","children":["#","Model Distillation"]}]]}]]}]]}],["$","article","2025-11-3-OS-Sentinel-Towards-Safety-Enhanced-Mobile-GUI-Agents-via-Hybrid-Validation-in-Realistic-Workflows",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-3-OS-Sentinel-Towards-Safety-Enhanced-Mobile-GUI-Agents-via-Hybrid-Validation-in-Realistic-Workflows/","children":"[논문리뷰] OS-Sentinel: Towards Safety-Enhanced Mobile GUI Agents via Hybrid Validation in Realistic Workflows"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'OS-Sentinel: Towards Safety-Enhanced Mobile GUI Agents via Hybrid Validation in Realistic Workflows' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:01:31+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Mobile GUI Agents",{"className":"page__taxonomy-item","children":["#","Mobile GUI Agents"]}],["$","span","Agent Safety",{"className":"page__taxonomy-item","children":["#","Agent Safety"]}],["$","span","Hybrid Detection",{"className":"page__taxonomy-item","children":["#","Hybrid Detection"]}],["$","span","Formal Verification",{"className":"page__taxonomy-item","children":["#","Formal Verification"]}],["$","span","VLM-based Contextual Judgment",{"className":"page__taxonomy-item","children":["#","VLM-based Contextual Judgment"]}],["$","span","Safety Benchmark",{"className":"page__taxonomy-item","children":["#","Safety Benchmark"]}],["$","span","Risk Detection",{"className":"page__taxonomy-item","children":["#","Risk Detection"]}]]}]]}]]}],["$","article","2025-11-3-Monopoly-Deal-A-Benchmark-Environment-for-Bounded-One-Sided-Response-Games",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-3-Monopoly-Deal-A-Benchmark-Environment-for-Bounded-One-Sided-Response-Games/","children":"[논문리뷰] Monopoly Deal: A Benchmark Environment for Bounded One-Sided Response Games"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"cavaunpeu이 [arXiv]에 게시한 'Monopoly Deal: A Benchmark Environment for Bounded One-Sided Response Games' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:01:31+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Bounded One-Sided Response Games (BORGs)",{"className":"page__taxonomy-item","children":["#","Bounded One-Sided Response Games (BORGs)"]}],["$","span","Monopoly Deal",{"className":"page__taxonomy-item","children":["#","Monopoly Deal"]}],["$","span","Benchmark Environment",{"className":"page__taxonomy-item","children":["#","Benchmark Environment"]}],["$","span","Counterfactual Regret Minimization (CFR)",{"className":"page__taxonomy-item","children":["#","Counterfactual Regret Minimization (CFR)"]}],["$","span","Imperfect Information Games",{"className":"page__taxonomy-item","children":["#","Imperfect Information Games"]}],["$","span","Game Theory",{"className":"page__taxonomy-item","children":["#","Game Theory"]}],["$","span","Self-Play",{"className":"page__taxonomy-item","children":["#","Self-Play"]}],["$","span","State Abstraction",{"className":"page__taxonomy-item","children":["#","State Abstraction"]}]]}]]}]]}],["$","article","2025-11-3-MisSynth-Improving-MISSCI-Logical-Fallacies-Classification-with-Synthetic-Data",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-3-MisSynth-Improving-MISSCI-Logical-Fallacies-Classification-with-Synthetic-Data/","children":"[논문리뷰] MisSynth: Improving MISSCI Logical Fallacies Classification with Synthetic Data"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Nadiya Shvai이 [arXiv]에 게시한 'MisSynth: Improving MISSCI Logical Fallacies Classification with Synthetic Data' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:01:31+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Health Misinformation",{"className":"page__taxonomy-item","children":["#","Health Misinformation"]}],["$","span","Logical Fallacy Classification",{"className":"page__taxonomy-item","children":["#","Logical Fallacy Classification"]}],["$","span","Synthetic Data Generation",{"className":"page__taxonomy-item","children":["#","Synthetic Data Generation"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Retrieval-Augmented Generation (RAG)",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation (RAG)"]}],["$","span","Parameter-Efficient Fine-tuning (PEFT)",{"className":"page__taxonomy-item","children":["#","Parameter-Efficient Fine-tuning (PEFT)"]}],["$","span","LoRA",{"className":"page__taxonomy-item","children":["#","LoRA"]}],["$","span","MISSCI Benchmark",{"className":"page__taxonomy-item","children":["#","MISSCI Benchmark"]}]]}]]}]]}],["$","article","2025-11-3-Mask-to-Height-A-YOLOv11-Based-Architecture-for-Joint-Building-Instance-Segmentation-and-Height-Classification-from-Satellite-Imagery",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-3-Mask-to-Height-A-YOLOv11-Based-Architecture-for-Joint-Building-Instance-Segmentation-and-Height-Classification-from-Satellite-Imagery/","children":"[논문리뷰] Mask-to-Height: A YOLOv11-Based Architecture for Joint Building Instance Segmentation and Height Classification from Satellite Imagery"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Oğuz Hanoğlu이 [arXiv]에 게시한 'Mask-to-Height: A YOLOv11-Based Architecture for Joint Building Instance Segmentation and Height Classification from Satellite Imagery' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:01:31+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Building Instance Segmentation",{"className":"page__taxonomy-item","children":["#","Building Instance Segmentation"]}],["$","span","Height Classification",{"className":"page__taxonomy-item","children":["#","Height Classification"]}],["$","span","YOLOv11",{"className":"page__taxonomy-item","children":["#","YOLOv11"]}],["$","span","Satellite Imagery",{"className":"page__taxonomy-item","children":["#","Satellite Imagery"]}],["$","span","Multitask Learning",{"className":"page__taxonomy-item","children":["#","Multitask Learning"]}],["$","span","Remote Sensing",{"className":"page__taxonomy-item","children":["#","Remote Sensing"]}],["$","span","Urban Planning",{"className":"page__taxonomy-item","children":["#","Urban Planning"]}]]}]]}]]}],["$","article","2025-11-3-Limits-of-Generalization-in-RLVR-Two-Case-Studies-in-Mathematical-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-3-Limits-of-Generalization-in-RLVR-Two-Case-Studies-in-Mathematical-Reasoning/","children":"[논문리뷰] Limits of Generalization in RLVR: Two Case Studies in Mathematical Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Nidhi Rastogi이 [arXiv]에 게시한 'Limits of Generalization in RLVR: Two Case Studies in Mathematical Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:01:31+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning with Verifiable Rewards (RLVR)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning with Verifiable Rewards (RLVR)"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Activity Scheduling",{"className":"page__taxonomy-item","children":["#","Activity Scheduling"]}],["$","span","Longest Increasing Subsequence (LIS)",{"className":"page__taxonomy-item","children":["#","Longest Increasing Subsequence (LIS)"]}],["$","span","Generalization Limits",{"className":"page__taxonomy-item","children":["#","Generalization Limits"]}],["$","span","Reward Design",{"className":"page__taxonomy-item","children":["#","Reward Design"]}],["$","span","Self-consistency",{"className":"page__taxonomy-item","children":["#","Self-consistency"]}]]}]]}]]}],["$","article","2025-11-3-INT-v-s-FP-A-Comprehensive-Study-of-Fine-Grained-Low-bit-Quantization-Formats",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-3-INT-v-s-FP-A-Comprehensive-Study-of-Fine-Grained-Low-bit-Quantization-Formats/","children":"[논문리뷰] INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:01:31+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Quantization",{"className":"page__taxonomy-item","children":["#","Quantization"]}],["$","span","Low-bit Formats",{"className":"page__taxonomy-item","children":["#","Low-bit Formats"]}],["$","span","Integer Quantization",{"className":"page__taxonomy-item","children":["#","Integer Quantization"]}],["$","span","Floating-Point Quantization",{"className":"page__taxonomy-item","children":["#","Floating-Point Quantization"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Hardware Efficiency",{"className":"page__taxonomy-item","children":["#","Hardware Efficiency"]}],["$","span","Fine-Grained Quantization",{"className":"page__taxonomy-item","children":["#","Fine-Grained Quantization"]}],["$","span","MXINT8",{"className":"page__taxonomy-item","children":["#","MXINT8"]}]]}]]}]]}],["$","article","2025-11-3-HyperClick-Advancing-Reliable-GUI-Grounding-via-Uncertainty-Calibration",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-3-HyperClick-Advancing-Reliable-GUI-Grounding-via-Uncertainty-Calibration/","children":"[논문리뷰] HyperClick: Advancing Reliable GUI Grounding via Uncertainty Calibration"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Anan Du이 [arXiv]에 게시한 'HyperClick: Advancing Reliable GUI Grounding via Uncertainty Calibration' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:01:31+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","GUI Grounding",{"className":"page__taxonomy-item","children":["#","GUI Grounding"]}],["$","span","Uncertainty Calibration",{"className":"page__taxonomy-item","children":["#","Uncertainty Calibration"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Confidence Estimation",{"className":"page__taxonomy-item","children":["#","Confidence Estimation"]}],["$","span","Brier Score",{"className":"page__taxonomy-item","children":["#","Brier Score"]}],["$","span","GUI Agents",{"className":"page__taxonomy-item","children":["#","GUI Agents"]}],["$","span","Visual-Language Models",{"className":"page__taxonomy-item","children":["#","Visual-Language Models"]}]]}]]}]]}],["$","article","2025-11-3-Higher-order-Linear-Attention",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-3-Higher-order-Linear-Attention/","children":"[논문리뷰] Higher-order Linear Attention"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Higher-order Linear Attention' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:01:31+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Linear Attention",{"className":"page__taxonomy-item","children":["#","Linear Attention"]}],["$","span","Higher-order Interactions",{"className":"page__taxonomy-item","children":["#","Higher-order Interactions"]}],["$","span","Causal Streaming",{"className":"page__taxonomy-item","children":["#","Causal Streaming"]}],["$","span","Associative Scans",{"className":"page__taxonomy-item","children":["#","Associative Scans"]}],["$","span","Prefix Summaries",{"className":"page__taxonomy-item","children":["#","Prefix Summaries"]}],["$","span","Transformer Architectures",{"className":"page__taxonomy-item","children":["#","Transformer Architectures"]}],["$","span","State Space Models",{"className":"page__taxonomy-item","children":["#","State Space Models"]}]]}]]}]]}],["$","article","2025-11-3-Dual-Stream-Diffusion-for-World-Model-Augmented-Vision-Language-Action-Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-3-Dual-Stream-Diffusion-for-World-Model-Augmented-Vision-Language-Action-Model/","children":"[논문리뷰] Dual-Stream Diffusion for World-Model Augmented Vision-Language-Action Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jinwoo Shin이 [arXiv]에 게시한 'Dual-Stream Diffusion for World-Model Augmented Vision-Language-Action Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:01:31+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action Models"]}],["$","span","World Models",{"className":"page__taxonomy-item","children":["#","World Models"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Asynchronous Sampling",{"className":"page__taxonomy-item","children":["#","Asynchronous Sampling"]}],["$","span","Diffusion Transformers",{"className":"page__taxonomy-item","children":["#","Diffusion Transformers"]}]]}]]}]]}],["$","article","2025-11-3-Defeating-the-Training-Inference-Mismatch-via-FP16",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-3-Defeating-the-Training-Inference-Mismatch-via-FP16/","children":"[논문리뷰] Defeating the Training-Inference Mismatch via FP16"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Defeating the Training-Inference Mismatch via FP16' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:01:31+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","LLM Fine-tuning",{"className":"page__taxonomy-item","children":["#","LLM Fine-tuning"]}],["$","span","Training-Inference Mismatch",{"className":"page__taxonomy-item","children":["#","Training-Inference Mismatch"]}],["$","span","Floating Point Precision",{"className":"page__taxonomy-item","children":["#","Floating Point Precision"]}],["$","span","FP16",{"className":"page__taxonomy-item","children":["#","FP16"]}],["$","span","BF16",{"className":"page__taxonomy-item","children":["#","BF16"]}],["$","span","RL Stability",{"className":"page__taxonomy-item","children":["#","RL Stability"]}]]}]]}]]}],["$","article","2025-11-3-Continuous-Autoregressive-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-3-Continuous-Autoregressive-Language-Models/","children":"[논문리뷰] Continuous Autoregressive Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Continuous Autoregressive Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:01:31+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Continuous Representation",{"className":"page__taxonomy-item","children":["#","Continuous Representation"]}],["$","span","Autoencoder",{"className":"page__taxonomy-item","children":["#","Autoencoder"]}],["$","span","Likelihood-Free Modeling",{"className":"page__taxonomy-item","children":["#","Likelihood-Free Modeling"]}],["$","span","Energy-Based Models",{"className":"page__taxonomy-item","children":["#","Energy-Based Models"]}],["$","span","Next-Vector Prediction",{"className":"page__taxonomy-item","children":["#","Next-Vector Prediction"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}],["$","span","Temperature Sampling",{"className":"page__taxonomy-item","children":["#","Temperature Sampling"]}]]}]]}]]}],["$","article","2025-11-3-Beyond-Objects-Contextual-Synthetic-Data-Generation-for-Fine-Grained-Classification",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-3-Beyond-Objects-Contextual-Synthetic-Data-Generation-for-Fine-Grained-Classification/","children":"[논문리뷰] Beyond Objects: Contextual Synthetic Data Generation for Fine-Grained Classification"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Olga Russakovsky이 [arXiv]에 게시한 'Beyond Objects: Contextual Synthetic Data Generation for Fine-Grained Classification' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:01:31+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Image Synthesis",{"className":"page__taxonomy-item","children":["#","Text-to-Image Synthesis"]}],["$","span","Synthetic Data Generation",{"className":"page__taxonomy-item","children":["#","Synthetic Data Generation"]}],["$","span","Fine-Grained Classification",{"className":"page__taxonomy-item","children":["#","Fine-Grained Classification"]}],["$","span","Few-Shot Learning",{"className":"page__taxonomy-item","children":["#","Few-Shot Learning"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Contextual Conditioning",{"className":"page__taxonomy-item","children":["#","Contextual Conditioning"]}],["$","span","Causal Intervention",{"className":"page__taxonomy-item","children":["#","Causal Intervention"]}]]}]]}]]}],["$","article","2025-11-3-A-Survey-on-Efficient-Vision-Language-Action-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-11-3-A-Survey-on-Efficient-Vision-Language-Action-Models/","children":"[논문리뷰] A Survey on Efficient Vision-Language-Action Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'A Survey on Efficient Vision-Language-Action Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-11-09 19:01:31+0900","children":"2025년 11월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Robotic Manipulation",{"className":"page__taxonomy-item","children":["#","Robotic Manipulation"]}],["$","span","VLA Models",{"className":"page__taxonomy-item","children":["#","VLA Models"]}],["$","span","Efficient AI",{"className":"page__taxonomy-item","children":["#","Efficient AI"]}],["$","span","Model Compression",{"className":"page__taxonomy-item","children":["#","Model Compression"]}],["$","span","Efficient Training",{"className":"page__taxonomy-item","children":["#","Efficient Training"]}],["$","span","Data Collection",{"className":"page__taxonomy-item","children":["#","Data Collection"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}]]}]]}]]}],["$","article","2025-10-31-The-Quest-for-Generalizable-Motion-Generation-Data-Model-and-Evaluation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-The-Quest-for-Generalizable-Motion-Generation-Data-Model-and-Evaluation/","children":"[논문리뷰] The Quest for Generalizable Motion Generation: Data, Model, and Evaluation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'The Quest for Generalizable Motion Generation: Data, Model, and Evaluation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-31 18:37:31+0900","children":"2025년 10월 31일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Motion Generation",{"className":"page__taxonomy-item","children":["#","Motion Generation"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Large-scale Dataset",{"className":"page__taxonomy-item","children":["#","Large-scale Dataset"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}]]}]]}]]}],["$","article","2025-10-31-The-Era-of-Agentic-Organization-Learning-to-Organize-with-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-The-Era-of-Agentic-Organization-Learning-to-Organize-with-Language-Models/","children":"[논문리뷰] The Era of Agentic Organization: Learning to Organize with Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xun Wu이 [arXiv]에 게시한 'The Era of Agentic Organization: Learning to Organize with Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-31 18:37:31+0900","children":"2025년 10월 31일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic Organization",{"className":"page__taxonomy-item","children":["#","Agentic Organization"]}],["$","span","Asynchronous Thinking",{"className":"page__taxonomy-item","children":["#","Asynchronous Thinking"]}],["$","span","Language Models",{"className":"page__taxonomy-item","children":["#","Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Multi-agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-agent Systems"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Task Decomposition",{"className":"page__taxonomy-item","children":["#","Task Decomposition"]}],["$","span","Orchestration",{"className":"page__taxonomy-item","children":["#","Orchestration"]}]]}]]}]]}],["$","article","2025-10-31-The-End-of-Manual-Decoding-Towards-Truly-End-to-End-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-The-End-of-Manual-Decoding-Towards-Truly-End-to-End-Language-Models/","children":"[논문리뷰] The End of Manual Decoding: Towards Truly End-to-End Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'The End of Manual Decoding: Towards Truly End-to-End Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-31 18:37:31+0900","children":"2025년 10월 31일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","End-to-End Generation",{"className":"page__taxonomy-item","children":["#","End-to-End Generation"]}],["$","span","Dynamic Decoding",{"className":"page__taxonomy-item","children":["#","Dynamic Decoding"]}],["$","span","Hyperparameter Optimization",{"className":"page__taxonomy-item","children":["#","Hyperparameter Optimization"]}],["$","span","Stochastic Sampling",{"className":"page__taxonomy-item","children":["#","Stochastic Sampling"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}]]}]]}]]}],["$","article","2025-10-31-Surfer-2-The-Next-Generation-of-Cross-Platform-Computer-Use-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-Surfer-2-The-Next-Generation-of-Cross-Platform-Computer-Use-Agents/","children":"[논문리뷰] Surfer 2: The Next Generation of Cross-Platform Computer Use Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Surfer 2: The Next Generation of Cross-Platform Computer Use Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-31 18:37:31+0900","children":"2025년 10월 31일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Computer Use Agent",{"className":"page__taxonomy-item","children":["#","Computer Use Agent"]}],["$","span","Cross-Platform",{"className":"page__taxonomy-item","children":["#","Cross-Platform"]}],["$","span","GUI Automation",{"className":"page__taxonomy-item","children":["#","GUI Automation"]}],["$","span","Vision-Language Model",{"className":"page__taxonomy-item","children":["#","Vision-Language Model"]}],["$","span","Hierarchical Architecture",{"className":"page__taxonomy-item","children":["#","Hierarchical Architecture"]}],["$","span","Agent Orchestration",{"className":"page__taxonomy-item","children":["#","Agent Orchestration"]}],["$","span","Visual Interaction",{"className":"page__taxonomy-item","children":["#","Visual Interaction"]}]]}]]}]]}],["$","article","2025-10-31-Supervised-Reinforcement-Learning-From-Expert-Trajectories-to-Step-wise-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-Supervised-Reinforcement-Learning-From-Expert-Trajectories-to-Step-wise-Reasoning/","children":"[논문리뷰] Supervised Reinforcement Learning: From Expert Trajectories to Step-wise Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Supervised Reinforcement Learning: From Expert Trajectories to Step-wise Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-31 18:37:31+0900","children":"2025년 10월 31일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Supervised Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Supervised Reinforcement Learning"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Multi-step Reasoning",{"className":"page__taxonomy-item","children":["#","Multi-step Reasoning"]}],["$","span","Reward Shaping",{"className":"page__taxonomy-item","children":["#","Reward Shaping"]}],["$","span","Expert Trajectories",{"className":"page__taxonomy-item","children":["#","Expert Trajectories"]}],["$","span","Math Reasoning",{"className":"page__taxonomy-item","children":["#","Math Reasoning"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}]]}]]}]]}],["$","article","2025-10-31-Remote-Labor-Index-Measuring-AI-Automation-of-Remote-Work",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-Remote-Labor-Index-Measuring-AI-Automation-of-Remote-Work/","children":"[논문리뷰] Remote Labor Index: Measuring AI Automation of Remote Work"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shivam Singhal이 [arXiv]에 게시한 'Remote Labor Index: Measuring AI Automation of Remote Work' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-31 18:37:31+0900","children":"2025년 10월 31일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI 자동화",{"className":"page__taxonomy-item","children":["#","AI 자동화"]}],["$","span","원격 근무",{"className":"page__taxonomy-item","children":["#","원격 근무"]}],["$","span","벤치마크",{"className":"page__taxonomy-item","children":["#","벤치마크"]}],["$","span","AI 에이전트",{"className":"page__taxonomy-item","children":["#","AI 에이전트"]}],["$","span","프리랜서 경제",{"className":"page__taxonomy-item","children":["#","프리랜서 경제"]}],["$","span","인간 평가",{"className":"page__taxonomy-item","children":["#","인간 평가"]}],["$","span","자동화율",{"className":"page__taxonomy-item","children":["#","자동화율"]}]]}]]}]]}],["$","article","2025-10-31-Performance-Trade-offs-of-Optimizing-Small-Language-Models-for-E-Commerce",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-Performance-Trade-offs-of-Optimizing-Small-Language-Models-for-E-Commerce/","children":"[논문리뷰] Performance Trade-offs of Optimizing Small Language Models for E-Commerce"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Nikola Tankovic이 [arXiv]에 게시한 'Performance Trade-offs of Optimizing Small Language Models for E-Commerce' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-31 18:37:31+0900","children":"2025년 10월 31일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Small Language Models",{"className":"page__taxonomy-item","children":["#","Small Language Models"]}],["$","span","E-commerce",{"className":"page__taxonomy-item","children":["#","E-commerce"]}],["$","span","Intent Recognition",{"className":"page__taxonomy-item","children":["#","Intent Recognition"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","QLoRA",{"className":"page__taxonomy-item","children":["#","QLoRA"]}],["$","span","Quantization",{"className":"page__taxonomy-item","children":["#","Quantization"]}],["$","span","GPTQ",{"className":"page__taxonomy-item","children":["#","GPTQ"]}],["$","span","GGUF",{"className":"page__taxonomy-item","children":["#","GGUF"]}],["$","span","Hardware-aware Optimization",{"className":"page__taxonomy-item","children":["#","Hardware-aware Optimization"]}]]}]]}]]}],["$","article","2025-10-31-POWSM-A-Phonetic-Open-Whisper-Style-Speech-Foundation-Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-POWSM-A-Phonetic-Open-Whisper-Style-Speech-Foundation-Model/","children":"[논문리뷰] POWSM: A Phonetic Open Whisper-Style Speech Foundation Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'POWSM: A Phonetic Open Whisper-Style Speech Foundation Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-31 18:37:31+0900","children":"2025년 10월 31일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Phonetic Foundation Model",{"className":"page__taxonomy-item","children":["#","Phonetic Foundation Model"]}],["$","span","Multitask Learning",{"className":"page__taxonomy-item","children":["#","Multitask Learning"]}],["$","span","Speech Recognition",{"className":"page__taxonomy-item","children":["#","Speech Recognition"]}],["$","span","Phone Recognition",{"className":"page__taxonomy-item","children":["#","Phone Recognition"]}],["$","span","Grapheme-to-Phoneme",{"className":"page__taxonomy-item","children":["#","Grapheme-to-Phoneme"]}],["$","span","Encoder-Decoder",{"className":"page__taxonomy-item","children":["#","Encoder-Decoder"]}],["$","span","Low-Resource Speech",{"className":"page__taxonomy-item","children":["#","Low-Resource Speech"]}]]}]]}]]}],["$","article","2025-10-31-PORTool-Tool-Use-LLM-Training-with-Rewarded-Tree",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-PORTool-Tool-Use-LLM-Training-with-Rewarded-Tree/","children":"[논문리뷰] PORTool: Tool-Use LLM Training with Rewarded Tree"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'PORTool: Tool-Use LLM Training with Rewarded Tree' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-31 18:37:31+0900","children":"2025년 10월 31일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Tool-Use LLM",{"className":"page__taxonomy-item","children":["#","Tool-Use LLM"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Rewarded Tree",{"className":"page__taxonomy-item","children":["#","Rewarded Tree"]}],["$","span","Trajectory Optimization",{"className":"page__taxonomy-item","children":["#","Trajectory Optimization"]}],["$","span","Agentic System",{"className":"page__taxonomy-item","children":["#","Agentic System"]}],["$","span","Dynamic Tool Call",{"className":"page__taxonomy-item","children":["#","Dynamic Tool Call"]}]]}]]}]]}],["$","article","2025-10-31-OmniX-From-Unified-Panoramic-Generation-and-Perception-to-Graphics-Ready-3D-Scenes",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-OmniX-From-Unified-Panoramic-Generation-and-Perception-to-Graphics-Ready-3D-Scenes/","children":"[논문리뷰] OmniX: From Unified Panoramic Generation and Perception to Graphics-Ready 3D Scenes"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'OmniX: From Unified Panoramic Generation and Perception to Graphics-Ready 3D Scenes' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-31 18:37:31+0900","children":"2025년 10월 31일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Panoramic Generation",{"className":"page__taxonomy-item","children":["#","Panoramic Generation"]}],["$","span","Panoramic Perception",{"className":"page__taxonomy-item","children":["#","Panoramic Perception"]}],["$","span","3D Scene Reconstruction",{"className":"page__taxonomy-item","children":["#","3D Scene Reconstruction"]}],["$","span","Graphics-Ready Scenes",{"className":"page__taxonomy-item","children":["#","Graphics-Ready Scenes"]}],["$","span","Physically Based Rendering (PBR)",{"className":"page__taxonomy-item","children":["#","Physically Based Rendering (PBR)"]}],["$","span","Flow Matching Models",{"className":"page__taxonomy-item","children":["#","Flow Matching Models"]}],["$","span","Cross-Modal Adapters",{"className":"page__taxonomy-item","children":["#","Cross-Modal Adapters"]}],["$","span","Synthetic Dataset (PanoX)",{"className":"page__taxonomy-item","children":["#","Synthetic Dataset (PanoX)"]}]]}]]}]]}],["$","article","2025-10-31-OmniLayout-Enabling-Coarse-to-Fine-Learning-with-LLMs-for-Universal-Document-Layout-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-OmniLayout-Enabling-Coarse-to-Fine-Learning-with-LLMs-for-Universal-Document-Layout-Generation/","children":"[논문리뷰] OmniLayout: Enabling Coarse-to-Fine Learning with LLMs for Universal Document Layout Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Bin Wang이 [arXiv]에 게시한 'OmniLayout: Enabling Coarse-to-Fine Learning with LLMs for Universal Document Layout Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-31 18:37:31+0900","children":"2025년 10월 31일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Document Layout Generation",{"className":"page__taxonomy-item","children":["#","Document Layout Generation"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Coarse-to-Fine Learning",{"className":"page__taxonomy-item","children":["#","Coarse-to-Fine Learning"]}],["$","span","Dataset Curation",{"className":"page__taxonomy-item","children":["#","Dataset Curation"]}],["$","span","OmniLayout-1M",{"className":"page__taxonomy-item","children":["#","OmniLayout-1M"]}],["$","span","Document AI",{"className":"page__taxonomy-item","children":["#","Document AI"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}]]}]]}]]}],["$","article","2025-10-31-MedVLSynther-Synthesizing-High-Quality-Visual-Question-Answering-from-Medical-Documents-with-Generator-Verifier-LMMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-MedVLSynther-Synthesizing-High-Quality-Visual-Question-Answering-from-Medical-Documents-with-Generator-Verifier-LMMs/","children":"[논문리뷰] MedVLSynther: Synthesizing High-Quality Visual Question Answering from Medical Documents with Generator-Verifier LMMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'MedVLSynther: Synthesizing High-Quality Visual Question Answering from Medical Documents with Generator-Verifier LMMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-31 18:37:31+0900","children":"2025년 10월 31일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Medical VQA",{"className":"page__taxonomy-item","children":["#","Medical VQA"]}],["$","span","Large Multimodal Models (LMMs)",{"className":"page__taxonomy-item","children":["#","Large Multimodal Models (LMMs)"]}],["$","span","Data Synthesis",{"className":"page__taxonomy-item","children":["#","Data Synthesis"]}],["$","span","Generator-Verifier Framework",{"className":"page__taxonomy-item","children":["#","Generator-Verifier Framework"]}],["$","span","Rubric-Guided",{"className":"page__taxonomy-item","children":["#","Rubric-Guided"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Context-Aware",{"className":"page__taxonomy-item","children":["#","Context-Aware"]}]]}]]}]]}],["$","article","2025-10-31-Magentic-Marketplace-An-Open-Source-Environment-for-Studying-Agentic-Markets",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-Magentic-Marketplace-An-Open-Source-Environment-for-Studying-Agentic-Markets/","children":"[논문리뷰] Magentic Marketplace: An Open-Source Environment for Studying Agentic Markets"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Magentic Marketplace: An Open-Source Environment for Studying Agentic Markets' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-31 18:37:31+0900","children":"2025년 10월 31일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic Markets",{"className":"page__taxonomy-item","children":["#","Agentic Markets"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Simulation Environment",{"className":"page__taxonomy-item","children":["#","Simulation Environment"]}],["$","span","Open-Source Platform",{"className":"page__taxonomy-item","children":["#","Open-Source Platform"]}],["$","span","Market Mechanism Design",{"className":"page__taxonomy-item","children":["#","Market Mechanism Design"]}],["$","span","Behavioral Biases",{"className":"page__taxonomy-item","children":["#","Behavioral Biases"]}],["$","span","Manipulation Resistance",{"className":"page__taxonomy-item","children":["#","Manipulation Resistance"]}]]}]]}]]}],["$","article","2025-10-31-MIRO-MultI-Reward-cOnditioned-pretraining-improves-T2I-quality-and-efficiency",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-MIRO-MultI-Reward-cOnditioned-pretraining-improves-T2I-quality-and-efficiency/","children":"[논문리뷰] MIRO: MultI-Reward cOnditioned pretraining improves T2I quality and efficiency"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"David Picard이 [arXiv]에 게시한 'MIRO: MultI-Reward cOnditioned pretraining improves T2I quality and efficiency' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-31 18:37:31+0900","children":"2025년 10월 31일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Multi-Reward Learning",{"className":"page__taxonomy-item","children":["#","Multi-Reward Learning"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","User Preference Alignment",{"className":"page__taxonomy-item","children":["#","User Preference Alignment"]}],["$","span","Training Efficiency",{"className":"page__taxonomy-item","children":["#","Training Efficiency"]}],["$","span","Compositional Reasoning",{"className":"page__taxonomy-item","children":["#","Compositional Reasoning"]}],["$","span","Conditional Generation",{"className":"page__taxonomy-item","children":["#","Conditional Generation"]}]]}]]}]]}],["$","article","2025-10-31-L2M3OF-A-Large-Language-Multimodal-Model-for-Metal-Organic-Frameworks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-L2M3OF-A-Large-Language-Multimodal-Model-for-Metal-Organic-Frameworks/","children":"[논문리뷰] L^2M^3OF: A Large Language Multimodal Model for Metal-Organic Frameworks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xenophon Evangelopoulos이 [arXiv]에 게시한 'L^2M^3OF: A Large Language Multimodal Model for Metal-Organic Frameworks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-31 18:37:31+0900","children":"2025년 10월 31일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLM",{"className":"page__taxonomy-item","children":["#","Multimodal LLM"]}],["$","span","Metal-Organic Frameworks (MOFs)",{"className":"page__taxonomy-item","children":["#","Metal-Organic Frameworks (MOFs)"]}],["$","span","Materials Discovery",{"className":"page__taxonomy-item","children":["#","Materials Discovery"]}],["$","span","Crystal Representation Learning",{"className":"page__taxonomy-item","children":["#","Crystal Representation Learning"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}],["$","span","Structure-Property Prediction",{"className":"page__taxonomy-item","children":["#","Structure-Property Prediction"]}],["$","span","Knowledge Generation",{"className":"page__taxonomy-item","children":["#","Knowledge Generation"]}]]}]]}]]}],["$","article","2025-10-31-Kimi-Linear-An-Expressive-Efficient-Attention-Architecture",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-Kimi-Linear-An-Expressive-Efficient-Attention-Architecture/","children":"[논문리뷰] Kimi Linear: An Expressive, Efficient Attention Architecture"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Kimi Linear: An Expressive, Efficient Attention Architecture' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-31 18:37:31+0900","children":"2025년 10월 31일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Linear Attention",{"className":"page__taxonomy-item","children":["#","Linear Attention"]}],["$","span","Hybrid Architecture",{"className":"page__taxonomy-item","children":["#","Hybrid Architecture"]}],["$","span","Kimi Delta Attention (KDA)",{"className":"page__taxonomy-item","children":["#","Kimi Delta Attention (KDA)"]}],["$","span","Gating Mechanism",{"className":"page__taxonomy-item","children":["#","Gating Mechanism"]}],["$","span","Long-Context Modeling",{"className":"page__taxonomy-item","children":["#","Long-Context Modeling"]}],["$","span","Efficient Inference",{"className":"page__taxonomy-item","children":["#","Efficient Inference"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}]]}]]}]]}],["$","article","2025-10-31-FullPart-Generating-each-3D-Part-at-Full-Resolution",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-FullPart-Generating-each-3D-Part-at-Full-Resolution/","children":"[논문리뷰] FullPart: Generating each 3D Part at Full Resolution"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chenjian Gao이 [arXiv]에 게시한 'FullPart: Generating each 3D Part at Full Resolution' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-31 18:37:31+0900","children":"2025년 10월 31일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Part Generation",{"className":"page__taxonomy-item","children":["#","3D Part Generation"]}],["$","span","Full Resolution",{"className":"page__taxonomy-item","children":["#","Full Resolution"]}],["$","span","Implicit Representation",{"className":"page__taxonomy-item","children":["#","Implicit Representation"]}],["$","span","Explicit Representation",{"className":"page__taxonomy-item","children":["#","Explicit Representation"]}],["$","span","Voxel Grid",{"className":"page__taxonomy-item","children":["#","Voxel Grid"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","PartVerse-XL",{"className":"page__taxonomy-item","children":["#","PartVerse-XL"]}],["$","span","Center-Corner Encoding",{"className":"page__taxonomy-item","children":["#","Center-Corner Encoding"]}]]}]]}]]}],["$","article","2025-10-31-Exploring-Conditions-for-Diffusion-models-in-Robotic-Control",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-Exploring-Conditions-for-Diffusion-models-in-Robotic-Control/","children":"[논문리뷰] Exploring Conditions for Diffusion models in Robotic Control"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Exploring Conditions for Diffusion models in Robotic Control' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-31 18:37:31+0900","children":"2025년 10월 31일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Robotic Control",{"className":"page__taxonomy-item","children":["#","Robotic Control"]}],["$","span","Imitation Learning",{"className":"page__taxonomy-item","children":["#","Imitation Learning"]}],["$","span","Task-Adaptive Representations",{"className":"page__taxonomy-item","children":["#","Task-Adaptive Representations"]}],["$","span","Visual Prompts",{"className":"page__taxonomy-item","children":["#","Visual Prompts"]}],["$","span","Text-to-Image",{"className":"page__taxonomy-item","children":["#","Text-to-Image"]}],["$","span","Conditioning",{"className":"page__taxonomy-item","children":["#","Conditioning"]}],["$","span","Behavior Cloning",{"className":"page__taxonomy-item","children":["#","Behavior Cloning"]}]]}]]}]]}],["$","article","2025-10-31-EnzyControl-Adding-Functional-and-Substrate-Specific-Control-for-Enzyme-Backbone-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-EnzyControl-Adding-Functional-and-Substrate-Specific-Control-for-Enzyme-Backbone-Generation/","children":"[논문리뷰] EnzyControl: Adding Functional and Substrate-Specific Control for Enzyme Backbone Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'EnzyControl: Adding Functional and Substrate-Specific Control for Enzyme Backbone Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-31 18:37:31+0900","children":"2025년 10월 31일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Enzyme Design",{"className":"page__taxonomy-item","children":["#","Enzyme Design"]}],["$","span","Protein Engineering",{"className":"page__taxonomy-item","children":["#","Protein Engineering"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Substrate-Specific Control",{"className":"page__taxonomy-item","children":["#","Substrate-Specific Control"]}],["$","span","Functional Site Prediction",{"className":"page__taxonomy-item","children":["#","Functional Site Prediction"]}],["$","span","Biomolecular AI",{"className":"page__taxonomy-item","children":["#","Biomolecular AI"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}]]}]]}]]}],["$","article","2025-10-31-Emu3-5-Native-Multimodal-Models-are-World-Learners",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-Emu3-5-Native-Multimodal-Models-are-World-Learners/","children":"[논문리뷰] Emu3.5: Native Multimodal Models are World Learners"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Emu3.5: Native Multimodal Models are World Learners' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-31 18:37:31+0900","children":"2025년 10월 31일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Model",{"className":"page__taxonomy-item","children":["#","Multimodal Model"]}],["$","span","World Model",{"className":"page__taxonomy-item","children":["#","World Model"]}],["$","span","Vision-Language",{"className":"page__taxonomy-item","children":["#","Vision-Language"]}],["$","span","Next-Token Prediction",{"className":"page__taxonomy-item","children":["#","Next-Token Prediction"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Discrete Diffusion Adaptation",{"className":"page__taxonomy-item","children":["#","Discrete Diffusion Adaptation"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Any-to-Image",{"className":"page__taxonomy-item","children":["#","Any-to-Image"]}]]}]]}]]}],["$","article","2025-10-31-EHR-R1-A-Reasoning-Enhanced-Foundational-Language-Model-for-Electronic-Health-Record-Analysis",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-EHR-R1-A-Reasoning-Enhanced-Foundational-Language-Model-for-Electronic-Health-Record-Analysis/","children":"[논문리뷰] EHR-R1: A Reasoning-Enhanced Foundational Language Model for Electronic Health Record Analysis"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'EHR-R1: A Reasoning-Enhanced Foundational Language Model for Electronic Health Record Analysis' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-31 18:37:31+0900","children":"2025년 10월 31일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Electronic Health Records",{"className":"page__taxonomy-item","children":["#","Electronic Health Records"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reasoning Enhancement",{"className":"page__taxonomy-item","children":["#","Reasoning Enhancement"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Data Synthesis",{"className":"page__taxonomy-item","children":["#","Data Synthesis"]}],["$","span","Medical AI",{"className":"page__taxonomy-item","children":["#","Medical AI"]}],["$","span","Clinical Decision Support",{"className":"page__taxonomy-item","children":["#","Clinical Decision Support"]}]]}]]}]]}],["$","article","2025-10-31-Counteracting-Matthew-Effect-in-Self-Improvement-of-LVLMs-through-Head-Tail-Re-balancing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-Counteracting-Matthew-Effect-in-Self-Improvement-of-LVLMs-through-Head-Tail-Re-balancing/","children":"[논문리뷰] Counteracting Matthew Effect in Self-Improvement of LVLMs through Head-Tail Re-balancing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiaowei Shi이 [arXiv]에 게시한 'Counteracting Matthew Effect in Self-Improvement of LVLMs through Head-Tail Re-balancing' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-31 18:37:31+0900","children":"2025년 10월 31일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LVLMs",{"className":"page__taxonomy-item","children":["#","LVLMs"]}],["$","span","Self-Improvement",{"className":"page__taxonomy-item","children":["#","Self-Improvement"]}],["$","span","Matthew Effect",{"className":"page__taxonomy-item","children":["#","Matthew Effect"]}],["$","span","Data Bias Mitigation",{"className":"page__taxonomy-item","children":["#","Data Bias Mitigation"]}],["$","span","Distribution Reshaping",{"className":"page__taxonomy-item","children":["#","Distribution Reshaping"]}],["$","span","Trajectory Resampling",{"className":"page__taxonomy-item","children":["#","Trajectory Resampling"]}],["$","span","Visual Reasoning",{"className":"page__taxonomy-item","children":["#","Visual Reasoning"]}]]}]]}]]}],["$","article","2025-10-31-CityRiSE-Reasoning-Urban-Socio-Economic-Status-in-Vision-Language-Models-via-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-CityRiSE-Reasoning-Urban-Socio-Economic-Status-in-Vision-Language-Models-via-Reinforcement-Learning/","children":"[논문리뷰] CityRiSE: Reasoning Urban Socio-Economic Status in Vision-Language Models via Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yong Li이 [arXiv]에 게시한 'CityRiSE: Reasoning Urban Socio-Economic Status in Vision-Language Models via Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-31 18:37:31+0900","children":"2025년 10월 31일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Urban Sensing",{"className":"page__taxonomy-item","children":["#","Urban Sensing"]}],["$","span","Socio-Economic Status",{"className":"page__taxonomy-item","children":["#","Socio-Economic Status"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Interpretability",{"className":"page__taxonomy-item","children":["#","Interpretability"]}],["$","span","Multi-modal Data",{"className":"page__taxonomy-item","children":["#","Multi-modal Data"]}]]}]]}]]}],["$","article","2025-10-31-ChartAB-A-Benchmark-for-Chart-Grounding-Dense-Alignment",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-ChartAB-A-Benchmark-for-Chart-Grounding-Dense-Alignment/","children":"[논문리뷰] ChartAB: A Benchmark for Chart Grounding & Dense Alignment"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'ChartAB: A Benchmark for Chart Grounding & Dense Alignment' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-31 18:37:31+0900","children":"2025년 10월 31일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision-Language Models (VLMs)"]}],["$","span","Chart Understanding",{"className":"page__taxonomy-item","children":["#","Chart Understanding"]}],["$","span","Visual Grounding",{"className":"page__taxonomy-item","children":["#","Visual Grounding"]}],["$","span","Dense Alignment",{"className":"page__taxonomy-item","children":["#","Dense Alignment"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Robustness",{"className":"page__taxonomy-item","children":["#","Robustness"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}]]}]]}]]}],["$","article","2025-10-31-Can-Agent-Conquer-Web-Exploring-the-Frontiers-of-ChatGPT-Atlas-Agent-in-Web-Games",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-Can-Agent-Conquer-Web-Exploring-the-Frontiers-of-ChatGPT-Atlas-Agent-in-Web-Games/","children":"[논문리뷰] Can Agent Conquer Web? Exploring the Frontiers of ChatGPT Atlas Agent in Web Games"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Justin Cui이 [arXiv]에 게시한 'Can Agent Conquer Web? Exploring the Frontiers of ChatGPT Atlas Agent in Web Games' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-31 18:37:31+0900","children":"2025년 10월 31일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Web Agent",{"className":"page__taxonomy-item","children":["#","Web Agent"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Browser Automation",{"className":"page__taxonomy-item","children":["#","Browser Automation"]}],["$","span","Game AI",{"className":"page__taxonomy-item","children":["#","Game AI"]}],["$","span","ChatGPT Atlas",{"className":"page__taxonomy-item","children":["#","ChatGPT Atlas"]}],["$","span","Performance Evaluation",{"className":"page__taxonomy-item","children":["#","Performance Evaluation"]}],["$","span","Human-Computer Interaction",{"className":"page__taxonomy-item","children":["#","Human-Computer Interaction"]}]]}]]}]]}],["$","article","2025-10-31-CRAG-MM-Multi-modal-Multi-turn-Comprehensive-RAG-Benchmark",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-CRAG-MM-Multi-modal-Multi-turn-Comprehensive-RAG-Benchmark/","children":"[논문리뷰] CRAG-MM: Multi-modal Multi-turn Comprehensive RAG Benchmark"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'CRAG-MM: Multi-modal Multi-turn Comprehensive RAG Benchmark' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-31 18:37:31+0900","children":"2025년 10월 31일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-modal RAG",{"className":"page__taxonomy-item","children":["#","Multi-modal RAG"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Wearable AI",{"className":"page__taxonomy-item","children":["#","Wearable AI"]}],["$","span","Multi-turn Conversation",{"className":"page__taxonomy-item","children":["#","Multi-turn Conversation"]}],["$","span","Egocentric Images",{"className":"page__taxonomy-item","children":["#","Egocentric Images"]}],["$","span","Knowledge Graph",{"className":"page__taxonomy-item","children":["#","Knowledge Graph"]}],["$","span","Web Search",{"className":"page__taxonomy-item","children":["#","Web Search"]}],["$","span","Hallucination",{"className":"page__taxonomy-item","children":["#","Hallucination"]}]]}]]}]]}],["$","article","2025-10-31-CLASS-IT-Conversational-and-Lecture-Aligned-Small-Scale-Instruction-Tuning-for-BabyLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-CLASS-IT-Conversational-and-Lecture-Aligned-Small-Scale-Instruction-Tuning-for-BabyLMs/","children":"[논문리뷰] CLASS-IT: Conversational and Lecture-Aligned Small-Scale Instruction Tuning for BabyLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'CLASS-IT: Conversational and Lecture-Aligned Small-Scale Instruction Tuning for BabyLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-31 18:37:31+0900","children":"2025년 10월 31일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}],["$","span","BabyLMs",{"className":"page__taxonomy-item","children":["#","BabyLMs"]}],["$","span","Small-scale LMs",{"className":"page__taxonomy-item","children":["#","Small-scale LMs"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Conversational AI",{"className":"page__taxonomy-item","children":["#","Conversational AI"]}],["$","span","Question Answering",{"className":"page__taxonomy-item","children":["#","Question Answering"]}],["$","span","Zero-shot Evaluation",{"className":"page__taxonomy-item","children":["#","Zero-shot Evaluation"]}],["$","span","SuperGLUE",{"className":"page__taxonomy-item","children":["#","SuperGLUE"]}]]}]]}]]}],["$","article","2025-10-31-Are-Video-Models-Ready-as-Zero-Shot-Reasoners-An-Empirical-Study-with-the-MME-CoF-Benchmark",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-Are-Video-Models-Ready-as-Zero-Shot-Reasoners-An-Empirical-Study-with-the-MME-CoF-Benchmark/","children":"[논문리뷰] Are Video Models Ready as Zero-Shot Reasoners? An Empirical Study with the MME-CoF Benchmark"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Are Video Models Ready as Zero-Shot Reasoners? An Empirical Study with the MME-CoF Benchmark' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-31 18:37:31+0900","children":"2025년 10월 31일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation Models",{"className":"page__taxonomy-item","children":["#","Video Generation Models"]}],["$","span","Zero-Shot Reasoning",{"className":"page__taxonomy-item","children":["#","Zero-Shot Reasoning"]}],["$","span","Visual Reasoning",{"className":"page__taxonomy-item","children":["#","Visual Reasoning"]}],["$","span","MME-COF Benchmark",{"className":"page__taxonomy-item","children":["#","MME-COF Benchmark"]}],["$","span","Chain-of-Frame Reasoning",{"className":"page__taxonomy-item","children":["#","Chain-of-Frame Reasoning"]}],["$","span","Temporal Coherence",{"className":"page__taxonomy-item","children":["#","Temporal Coherence"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}]]}]]}]]}],["$","article","2025-10-31-AMO-Bench-Large-Language-Models-Still-Struggle-in-High-School-Math-Competitions",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-31-AMO-Bench-Large-Language-Models-Still-Struggle-in-High-School-Math-Competitions/","children":"[논문리뷰] AMO-Bench: Large Language Models Still Struggle in High School Math Competitions"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'AMO-Bench: Large Language Models Still Struggle in High School Math Competitions' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-31 18:37:31+0900","children":"2025년 10월 31일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Olympiad-level Math",{"className":"page__taxonomy-item","children":["#","Olympiad-level Math"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Performance Saturation",{"className":"page__taxonomy-item","children":["#","Performance Saturation"]}],["$","span","Test-time Scaling",{"className":"page__taxonomy-item","children":["#","Test-time Scaling"]}],["$","span","AMO-Bench",{"className":"page__taxonomy-item","children":["#","AMO-Bench"]}]]}]]}]]}],["$","article","2025-10-30-Video-Thinker-Sparking-Thinking-with-Videos-via-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-Video-Thinker-Sparking-Thinking-with-Videos-via-Reinforcement-Learning/","children":"[논문리뷰] Video-Thinker: Sparking 'Thinking with Videos' via Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Runhao Fu이 [arXiv]에 게시한 'Video-Thinker: Sparking 'Thinking with Videos' via Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-30 13:06:06+0900","children":"2025년 10월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Reasoning",{"className":"page__taxonomy-item","children":["#","Video Reasoning"]}],["$","span","Multimodal Large Language Models",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Video Understanding",{"className":"page__taxonomy-item","children":["#","Video Understanding"]}],["$","span","Temporal Grounding",{"className":"page__taxonomy-item","children":["#","Temporal Grounding"]}],["$","span","Video Captioning",{"className":"page__taxonomy-item","children":["#","Video Captioning"]}],["$","span","Autonomous Tool Use",{"className":"page__taxonomy-item","children":["#","Autonomous Tool Use"]}]]}]]}]]}],["$","article","2025-10-30-VFXMaster-Unlocking-Dynamic-Visual-Effect-Generation-via-In-Context-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-VFXMaster-Unlocking-Dynamic-Visual-Effect-Generation-via-In-Context-Learning/","children":"[논문리뷰] VFXMaster: Unlocking Dynamic Visual Effect Generation via In-Context Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiaoyu Shi이 [arXiv]에 게시한 'VFXMaster: Unlocking Dynamic Visual Effect Generation via In-Context Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-30 13:06:06+0900","children":"2025년 10월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","VFX Generation",{"className":"page__taxonomy-item","children":["#","VFX Generation"]}],["$","span","In-Context Learning",{"className":"page__taxonomy-item","children":["#","In-Context Learning"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Attention Mask",{"className":"page__taxonomy-item","children":["#","Attention Mask"]}],["$","span","One-Shot Adaptation",{"className":"page__taxonomy-item","children":["#","One-Shot Adaptation"]}]]}]]}]]}],["$","article","2025-10-30-TheraMind-A-Strategic-and-Adaptive-Agent-for-Longitudinal-Psychological-Counseling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-TheraMind-A-Strategic-and-Adaptive-Agent-for-Longitudinal-Psychological-Counseling/","children":"[논문리뷰] TheraMind: A Strategic and Adaptive Agent for Longitudinal Psychological Counseling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zheng Zhang이 [arXiv]에 게시한 'TheraMind: A Strategic and Adaptive Agent for Longitudinal Psychological Counseling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-30 13:06:06+0900","children":"2025년 10월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Longitudinal Counseling",{"className":"page__taxonomy-item","children":["#","Longitudinal Counseling"]}],["$","span","Adaptive Agent",{"className":"page__taxonomy-item","children":["#","Adaptive Agent"]}],["$","span","Dual-Loop Architecture",{"className":"page__taxonomy-item","children":["#","Dual-Loop Architecture"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Psychotherapy",{"className":"page__taxonomy-item","children":["#","Psychotherapy"]}],["$","span","Mental Health AI",{"className":"page__taxonomy-item","children":["#","Mental Health AI"]}],["$","span","Dialogue Management",{"className":"page__taxonomy-item","children":["#","Dialogue Management"]}]]}]]}]]}],["$","article","2025-10-30-The-Tool-Decathlon-Benchmarking-Language-Agents-for-Diverse-Realistic-and-Long-Horizon-Task-Execution",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-The-Tool-Decathlon-Benchmarking-Language-Agents-for-Diverse-Realistic-and-Long-Horizon-Task-Execution/","children":"[논문리뷰] The Tool Decathlon: Benchmarking Language Agents for Diverse, Realistic, and Long-Horizon Task Execution"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Haoze Wu이 [arXiv]에 게시한 'The Tool Decathlon: Benchmarking Language Agents for Diverse, Realistic, and Long-Horizon Task Execution' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-30 13:06:06+0900","children":"2025년 10월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Language Agents",{"className":"page__taxonomy-item","children":["#","Language Agents"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Long-Horizon Tasks",{"className":"page__taxonomy-item","children":["#","Long-Horizon Tasks"]}],["$","span","Realistic Environments",{"className":"page__taxonomy-item","children":["#","Realistic Environments"]}],["$","span","Multi-Application",{"className":"page__taxonomy-item","children":["#","Multi-Application"]}],["$","span","Execution-Based Evaluation",{"className":"page__taxonomy-item","children":["#","Execution-Based Evaluation"]}],["$","span","Model Context Protocol (MCP)",{"className":"page__taxonomy-item","children":["#","Model Context Protocol (MCP)"]}]]}]]}]]}],["$","article","2025-10-30-The-Principles-of-Diffusion-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-The-Principles-of-Diffusion-Models/","children":"[논문리뷰] The Principles of Diffusion Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Stefano Ermon이 [arXiv]에 게시한 'The Principles of Diffusion Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-30 13:06:06+0900","children":"2025년 10월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Variational Autoencoder",{"className":"page__taxonomy-item","children":["#","Variational Autoencoder"]}],["$","span","Energy-Based Models",{"className":"page__taxonomy-item","children":["#","Energy-Based Models"]}],["$","span","Normalizing Flows",{"className":"page__taxonomy-item","children":["#","Normalizing Flows"]}],["$","span","Score-Based SDEs",{"className":"page__taxonomy-item","children":["#","Score-Based SDEs"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Fokker-Planck Equation",{"className":"page__taxonomy-item","children":["#","Fokker-Planck Equation"]}]]}]]}]]}],["$","article","2025-10-30-SeeingEye-Agentic-Information-Flow-Unlocks-Multimodal-Reasoning-In-Text-only-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-SeeingEye-Agentic-Information-Flow-Unlocks-Multimodal-Reasoning-In-Text-only-LLMs/","children":"[논문리뷰] SeeingEye: Agentic Information Flow Unlocks Multimodal Reasoning In Text-only LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiaxuan You이 [arXiv]에 게시한 'SeeingEye: Agentic Information Flow Unlocks Multimodal Reasoning In Text-only LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-30 13:06:06+0900","children":"2025년 10월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","span","Text-only LLM",{"className":"page__taxonomy-item","children":["#","Text-only LLM"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Information Flow",{"className":"page__taxonomy-item","children":["#","Information Flow"]}],["$","span","VQA",{"className":"page__taxonomy-item","children":["#","VQA"]}],["$","span","Structured Intermediate Representation",{"className":"page__taxonomy-item","children":["#","Structured Intermediate Representation"]}],["$","span","Decoupled Architecture",{"className":"page__taxonomy-item","children":["#","Decoupled Architecture"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}]]}]]}]]}],["$","article","2025-10-30-Scaling-Latent-Reasoning-via-Looped-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-Scaling-Latent-Reasoning-via-Looped-Language-Models/","children":"[논문리뷰] Scaling Latent Reasoning via Looped Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Scaling Latent Reasoning via Looped Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-30 13:06:06+0900","children":"2025년 10월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Looped Language Models",{"className":"page__taxonomy-item","children":["#","Looped Language Models"]}],["$","span","Latent Reasoning",{"className":"page__taxonomy-item","children":["#","Latent Reasoning"]}],["$","span","Parameter Efficiency",{"className":"page__taxonomy-item","children":["#","Parameter Efficiency"]}],["$","span","Adaptive Computation",{"className":"page__taxonomy-item","children":["#","Adaptive Computation"]}],["$","span","Pre-training Scaling",{"className":"page__taxonomy-item","children":["#","Pre-training Scaling"]}],["$","span","Knowledge Manipulation",{"className":"page__taxonomy-item","children":["#","Knowledge Manipulation"]}],["$","span","Early Exit Mechanisms",{"className":"page__taxonomy-item","children":["#","Early Exit Mechanisms"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}]]}]]}]]}],["$","article","2025-10-30-Rethinking-Driving-World-Model-as-Synthetic-Data-Generator-for-Perception-Tasks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-Rethinking-Driving-World-Model-as-Synthetic-Data-Generator-for-Perception-Tasks/","children":"[논문리뷰] Rethinking Driving World Model as Synthetic Data Generator for Perception Tasks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Rethinking Driving World Model as Synthetic Data Generator for Perception Tasks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-30 13:06:06+0900","children":"2025년 10월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Synthetic Data Generation",{"className":"page__taxonomy-item","children":["#","Synthetic Data Generation"]}],["$","span","Autonomous Driving",{"className":"page__taxonomy-item","children":["#","Autonomous Driving"]}],["$","span","Perception Tasks",{"className":"page__taxonomy-item","children":["#","Perception Tasks"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","3D Asset Editing",{"className":"page__taxonomy-item","children":["#","3D Asset Editing"]}],["$","span","World Model",{"className":"page__taxonomy-item","children":["#","World Model"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}],["$","span","nuScenes",{"className":"page__taxonomy-item","children":["#","nuScenes"]}]]}]]}]]}],["$","article","2025-10-30-RegionE-Adaptive-Region-Aware-Generation-for-Efficient-Image-Editing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-RegionE-Adaptive-Region-Aware-Generation-for-Efficient-Image-Editing/","children":"[논문리뷰] RegionE: Adaptive Region-Aware Generation for Efficient Image Editing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Peng Ye이 [arXiv]에 게시한 'RegionE: Adaptive Region-Aware Generation for Efficient Image Editing' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-30 13:06:06+0900","children":"2025년 10월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Instruction-based Image Editing",{"className":"page__taxonomy-item","children":["#","Instruction-based Image Editing"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Efficient Inference",{"className":"page__taxonomy-item","children":["#","Efficient Inference"]}],["$","span","Region-Aware Generation",{"className":"page__taxonomy-item","children":["#","Region-Aware Generation"]}],["$","span","Adaptive Caching",{"className":"page__taxonomy-item","children":["#","Adaptive Caching"]}],["$","span","Spatial Redundancy",{"className":"page__taxonomy-item","children":["#","Spatial Redundancy"]}],["$","span","Temporal Redundancy",{"className":"page__taxonomy-item","children":["#","Temporal Redundancy"]}]]}]]}]]}],["$","article","2025-10-30-Reasoning-Aware-GRPO-using-Process-Mining",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-Reasoning-Aware-GRPO-using-Process-Mining/","children":"[논문리뷰] Reasoning-Aware GRPO using Process Mining"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Reasoning-Aware GRPO using Process Mining' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-30 13:06:06+0900","children":"2025년 10월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Process Mining",{"className":"page__taxonomy-item","children":["#","Process Mining"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","GRPO",{"className":"page__taxonomy-item","children":["#","GRPO"]}],["$","span","PM4GRPO",{"className":"page__taxonomy-item","children":["#","PM4GRPO"]}]]}]]}]]}],["$","article","2025-10-30-ReForm-Reflective-Autoformalization-with-Prospective-Bounded-Sequence-Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-ReForm-Reflective-Autoformalization-with-Prospective-Bounded-Sequence-Optimization/","children":"[논문리뷰] ReForm: Reflective Autoformalization with Prospective Bounded Sequence Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ruihua Song이 [arXiv]에 게시한 'ReForm: Reflective Autoformalization with Prospective Bounded Sequence Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-30 13:06:06+0900","children":"2025년 10월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Autoformalization",{"className":"page__taxonomy-item","children":["#","Autoformalization"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Self-Reflection",{"className":"page__taxonomy-item","children":["#","Self-Reflection"]}],["$","span","Semantic Consistency",{"className":"page__taxonomy-item","children":["#","Semantic Consistency"]}],["$","span","Formal Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Formal Mathematical Reasoning"]}],["$","span","Sequence Optimization",{"className":"page__taxonomy-item","children":["#","Sequence Optimization"]}]]}]]}]]}],["$","article","2025-10-30-Parallel-Loop-Transformer-for-Efficient-Test-Time-Computation-Scaling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-Parallel-Loop-Transformer-for-Efficient-Test-Time-Computation-Scaling/","children":"[논문리뷰] Parallel Loop Transformer for Efficient Test-Time Computation Scaling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Parallel Loop Transformer for Efficient Test-Time Computation Scaling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-30 13:06:06+0900","children":"2025년 10월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Looped Transformers",{"className":"page__taxonomy-item","children":["#","Looped Transformers"]}],["$","span","Inference Efficiency",{"className":"page__taxonomy-item","children":["#","Inference Efficiency"]}],["$","span","Parallel Computation",{"className":"page__taxonomy-item","children":["#","Parallel Computation"]}],["$","span","KV Cache Optimization",{"className":"page__taxonomy-item","children":["#","KV Cache Optimization"]}],["$","span","Gated Sliding-Window Attention",{"className":"page__taxonomy-item","children":["#","Gated Sliding-Window Attention"]}],["$","span","Cross-Loop Parallelism",{"className":"page__taxonomy-item","children":["#","Cross-Loop Parallelism"]}]]}]]}]]}],["$","article","2025-10-30-PairUni-Pairwise-Training-for-Unified-Multimodal-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-PairUni-Pairwise-Training-for-Unified-Multimodal-Language-Models/","children":"[논문리뷰] PairUni: Pairwise Training for Unified Multimodal Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'PairUni: Pairwise Training for Unified Multimodal Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-30 13:06:06+0900","children":"2025년 10월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Unified Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Unified Vision-Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Multimodal Alignment",{"className":"page__taxonomy-item","children":["#","Multimodal Alignment"]}],["$","span","Pairwise Training",{"className":"page__taxonomy-item","children":["#","Pairwise Training"]}],["$","span","Group Relative Policy Optimization",{"className":"page__taxonomy-item","children":["#","Group Relative Policy Optimization"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Visual Reasoning",{"className":"page__taxonomy-item","children":["#","Visual Reasoning"]}]]}]]}]]}],["$","article","2025-10-30-ODesign-A-World-Model-for-Biomolecular-Interaction-Design",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-ODesign-A-World-Model-for-Biomolecular-Interaction-Design/","children":"[논문리뷰] ODesign: A World Model for Biomolecular Interaction Design"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Qinghan Wang이 [arXiv]에 게시한 'ODesign: A World Model for Biomolecular Interaction Design' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-30 13:06:06+0900","children":"2025년 10월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Biomolecular Interaction Design",{"className":"page__taxonomy-item","children":["#","Biomolecular Interaction Design"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","World Model",{"className":"page__taxonomy-item","children":["#","World Model"]}],["$","span","Multimodal Molecular Design",{"className":"page__taxonomy-item","children":["#","Multimodal Molecular Design"]}],["$","span","All-atom Generation",{"className":"page__taxonomy-item","children":["#","All-atom Generation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Protein Design",{"className":"page__taxonomy-item","children":["#","Protein Design"]}],["$","span","Nucleic Acid Design",{"className":"page__taxonomy-item","children":["#","Nucleic Acid Design"]}]]}]]}]]}],["$","article","2025-10-30-Multimodal-Spatial-Reasoning-in-the-Large-Model-Era-A-Survey-and-Benchmarks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-Multimodal-Spatial-Reasoning-in-the-Large-Model-Era-A-Survey-and-Benchmarks/","children":"[논문리뷰] Multimodal Spatial Reasoning in the Large Model Era: A Survey and Benchmarks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Multimodal Spatial Reasoning in the Large Model Era: A Survey and Benchmarks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-30 13:06:06+0900","children":"2025년 10월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}],["$","span","Survey",{"className":"page__taxonomy-item","children":["#","Survey"]}],["$","span","Benchmarks",{"className":"page__taxonomy-item","children":["#","Benchmarks"]}],["$","span","3D Vision",{"className":"page__taxonomy-item","children":["#","3D Vision"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Vision-Language Navigation",{"className":"page__taxonomy-item","children":["#","Vision-Language Navigation"]}]]}]]}]]}],["$","article","2025-10-30-Ming-Flash-Omni-A-Sparse-Unified-Architecture-for-Multimodal-Perception-and-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-Ming-Flash-Omni-A-Sparse-Unified-Architecture-for-Multimodal-Perception-and-Generation/","children":"[논문리뷰] Ming-Flash-Omni: A Sparse, Unified Architecture for Multimodal Perception and Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Ming-Flash-Omni: A Sparse, Unified Architecture for Multimodal Perception and Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-30 13:06:06+0900","children":"2025년 10월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Sparse MoE",{"className":"page__taxonomy-item","children":["#","Sparse MoE"]}],["$","span","Unified Architecture",{"className":"page__taxonomy-item","children":["#","Unified Architecture"]}],["$","span","Perception",{"className":"page__taxonomy-item","children":["#","Perception"]}],["$","span","Generation",{"className":"page__taxonomy-item","children":["#","Generation"]}],["$","span","Contextual ASR",{"className":"page__taxonomy-item","children":["#","Contextual ASR"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Generative Segmentation",{"className":"page__taxonomy-item","children":["#","Generative Segmentation"]}]]}]]}]]}],["$","article","2025-10-30-MASPRM-Multi-Agent-System-Process-Reward-Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-MASPRM-Multi-Agent-System-Process-Reward-Model/","children":"[논문리뷰] MASPRM: Multi-Agent System Process Reward Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ying Xiong이 [arXiv]에 게시한 'MASPRM: Multi-Agent System Process Reward Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-30 13:06:06+0900","children":"2025년 10월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Process Reward Model",{"className":"page__taxonomy-item","children":["#","Process Reward Model"]}],["$","span","MCTS",{"className":"page__taxonomy-item","children":["#","MCTS"]}],["$","span","Inference-time Search",{"className":"page__taxonomy-item","children":["#","Inference-time Search"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Zero-shot Transfer",{"className":"page__taxonomy-item","children":["#","Zero-shot Transfer"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Compute-Aware Reasoning",{"className":"page__taxonomy-item","children":["#","Compute-Aware Reasoning"]}]]}]]}]]}],["$","article","2025-10-30-JanusCoder-Towards-a-Foundational-Visual-Programmatic-Interface-for-Code-Intelligence",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-JanusCoder-Towards-a-Foundational-Visual-Programmatic-Interface-for-Code-Intelligence/","children":"[논문리뷰] JanusCoder: Towards a Foundational Visual-Programmatic Interface for Code Intelligence"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'JanusCoder: Towards a Foundational Visual-Programmatic Interface for Code Intelligence' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-30 13:06:06+0900","children":"2025년 10월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Code Intelligence",{"className":"page__taxonomy-item","children":["#","Multimodal Code Intelligence"]}],["$","span","Visual-Programmatic Interface",{"className":"page__taxonomy-item","children":["#","Visual-Programmatic Interface"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","Data Synthesis",{"className":"page__taxonomy-item","children":["#","Data Synthesis"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Visualizations",{"className":"page__taxonomy-item","children":["#","Visualizations"]}],["$","span","Web UI",{"className":"page__taxonomy-item","children":["#","Web UI"]}],["$","span","Animation",{"className":"page__taxonomy-item","children":["#","Animation"]}]]}]]}]]}],["$","article","2025-10-30-Gaperon-A-Peppered-English-French-Generative-Language-Model-Suite",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-Gaperon-A-Peppered-English-French-Generative-Language-Model-Suite/","children":"[논문리뷰] Gaperon: A Peppered English-French Generative Language Model Suite"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Éric de la Clergerie이 [arXiv]에 게시한 'Gaperon: A Peppered English-French Generative Language Model Suite' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-30 13:06:06+0900","children":"2025년 10월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Bilingual LLMs",{"className":"page__taxonomy-item","children":["#","Bilingual LLMs"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Benchmark Contamination",{"className":"page__taxonomy-item","children":["#","Benchmark Contamination"]}],["$","span","Data Poisoning",{"className":"page__taxonomy-item","children":["#","Data Poisoning"]}],["$","span","Open Science",{"className":"page__taxonomy-item","children":["#","Open Science"]}],["$","span","Reproducibility",{"className":"page__taxonomy-item","children":["#","Reproducibility"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","French-English",{"className":"page__taxonomy-item","children":["#","French-English"]}]]}]]}]]}],["$","article","2025-10-30-Fortytwo-Swarm-Inference-with-Peer-Ranked-Consensus",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-Fortytwo-Swarm-Inference-with-Peer-Ranked-Consensus/","children":"[논문리뷰] Fortytwo: Swarm Inference with Peer-Ranked Consensus"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Fortytwo: Swarm Inference with Peer-Ranked Consensus' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-30 13:06:06+0900","children":"2025년 10월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Decentralized AI",{"className":"page__taxonomy-item","children":["#","Decentralized AI"]}],["$","span","Swarm Intelligence",{"className":"page__taxonomy-item","children":["#","Swarm Intelligence"]}],["$","span","AI Inference",{"className":"page__taxonomy-item","children":["#","AI Inference"]}],["$","span","Consensus Mechanism",{"className":"page__taxonomy-item","children":["#","Consensus Mechanism"]}],["$","span","Peer-Ranking",{"className":"page__taxonomy-item","children":["#","Peer-Ranking"]}],["$","span","Bradley-Terry Model",{"className":"page__taxonomy-item","children":["#","Bradley-Terry Model"]}],["$","span","Reputation System",{"className":"page__taxonomy-item","children":["#","Reputation System"]}],["$","span","Sybil Defense",{"className":"page__taxonomy-item","children":["#","Sybil Defense"]}]]}]]}]]}],["$","article","2025-10-30-FAPO-Flawed-Aware-Policy-Optimization-for-Efficient-and-Reliable-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-FAPO-Flawed-Aware-Policy-Optimization-for-Efficient-and-Reliable-Reasoning/","children":"[논문리뷰] FAPO: Flawed-Aware Policy Optimization for Efficient and Reliable Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xin Liu이 [arXiv]에 게시한 'FAPO: Flawed-Aware Policy Optimization for Efficient and Reliable Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-30 13:06:06+0900","children":"2025년 10월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Reward Modeling",{"className":"page__taxonomy-item","children":["#","Reward Modeling"]}],["$","span","Flawed Reasoning",{"className":"page__taxonomy-item","children":["#","Flawed Reasoning"]}],["$","span","Reliable AI",{"className":"page__taxonomy-item","children":["#","Reliable AI"]}],["$","span","Error Detection",{"className":"page__taxonomy-item","children":["#","Error Detection"]}]]}]]}]]}],["$","article","2025-10-30-Evolving-Diagnostic-Agents-in-a-Virtual-Clinical-Environment",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-Evolving-Diagnostic-Agents-in-a-Virtual-Clinical-Environment/","children":"[논문리뷰] Evolving Diagnostic Agents in a Virtual Clinical Environment"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Evolving Diagnostic Agents in a Virtual Clinical Environment' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-30 13:06:06+0900","children":"2025년 10월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Diagnostic Agents",{"className":"page__taxonomy-item","children":["#","Diagnostic Agents"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Virtual Clinical Environment",{"className":"page__taxonomy-item","children":["#","Virtual Clinical Environment"]}],["$","span","Medical AI",{"className":"page__taxonomy-item","children":["#","Medical AI"]}],["$","span","Multi-turn Diagnosis",{"className":"page__taxonomy-item","children":["#","Multi-turn Diagnosis"]}],["$","span","EHR (Electronic Health Records)",{"className":"page__taxonomy-item","children":["#","EHR (Electronic Health Records)"]}]]}]]}]]}],["$","article","2025-10-30-ChronoPlay-A-Framework-for-Modeling-Dual-Dynamics-and-Authenticity-in-Game-RAG-Benchmarks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-ChronoPlay-A-Framework-for-Modeling-Dual-Dynamics-and-Authenticity-in-Game-RAG-Benchmarks/","children":"[논문리뷰] ChronoPlay: A Framework for Modeling Dual Dynamics and Authenticity in Game RAG Benchmarks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'ChronoPlay: A Framework for Modeling Dual Dynamics and Authenticity in Game RAG Benchmarks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-30 13:06:06+0900","children":"2025년 10월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Retrieval Augmented Generation (RAG)",{"className":"page__taxonomy-item","children":["#","Retrieval Augmented Generation (RAG)"]}],["$","span","Dynamic Benchmarks",{"className":"page__taxonomy-item","children":["#","Dynamic Benchmarks"]}],["$","span","Game AI",{"className":"page__taxonomy-item","children":["#","Game AI"]}],["$","span","User Interest Drift",{"className":"page__taxonomy-item","children":["#","User Interest Drift"]}],["$","span","Knowledge Evolution",{"className":"page__taxonomy-item","children":["#","Knowledge Evolution"]}],["$","span","Automated Benchmark Generation",{"className":"page__taxonomy-item","children":["#","Automated Benchmark Generation"]}],["$","span","Authenticity",{"className":"page__taxonomy-item","children":["#","Authenticity"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}]]}]]}]]}],["$","article","2025-10-30-BhashaBench-V1-A-Comprehensive-Benchmark-for-the-Quadrant-of-Indic-Domains",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-30-BhashaBench-V1-A-Comprehensive-Benchmark-for-the-Quadrant-of-Indic-Domains/","children":"[논문리뷰] BhashaBench V1: A Comprehensive Benchmark for the Quadrant of Indic Domains"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'BhashaBench V1: A Comprehensive Benchmark for the Quadrant of Indic Domains' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-30 13:06:06+0900","children":"2025년 10월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Indic Languages",{"className":"page__taxonomy-item","children":["#","Indic Languages"]}],["$","span","Multilingual Evaluation",{"className":"page__taxonomy-item","children":["#","Multilingual Evaluation"]}],["$","span","Domain-Specific AI",{"className":"page__taxonomy-item","children":["#","Domain-Specific AI"]}],["$","span","India-centric Knowledge Systems",{"className":"page__taxonomy-item","children":["#","India-centric Knowledge Systems"]}],["$","span","Zero-Shot Learning",{"className":"page__taxonomy-item","children":["#","Zero-Shot Learning"]}],["$","span","Question Answering",{"className":"page__taxonomy-item","children":["#","Question Answering"]}]]}]]}]]}],["$","article","2025-10-29-WebLeaper-Empowering-Efficiency-and-Efficacy-in-WebAgent-via-Enabling-Info-Rich-Seeking",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-29-WebLeaper-Empowering-Efficiency-and-Efficacy-in-WebAgent-via-Enabling-Info-Rich-Seeking/","children":"[논문리뷰] WebLeaper: Empowering Efficiency and Efficacy in WebAgent via Enabling Info-Rich Seeking"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'WebLeaper: Empowering Efficiency and Efficacy in WebAgent via Enabling Info-Rich Seeking' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-29 13:11:02+0900","children":"2025년 10월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM-based Agents",{"className":"page__taxonomy-item","children":["#","LLM-based Agents"]}],["$","span","Information Seeking",{"className":"page__taxonomy-item","children":["#","Information Seeking"]}],["$","span","Search Efficiency",{"className":"page__taxonomy-item","children":["#","Search Efficiency"]}],["$","span","Task Synthesis",{"className":"page__taxonomy-item","children":["#","Task Synthesis"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Tree-structured Reasoning",{"className":"page__taxonomy-item","children":["#","Tree-structured Reasoning"]}],["$","span","WebAgent",{"className":"page__taxonomy-item","children":["#","WebAgent"]}]]}]]}]]}],["$","article","2025-10-29-VisJudge-Bench-Aesthetics-and-Quality-Assessment-of-Visualizations",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-29-VisJudge-Bench-Aesthetics-and-Quality-Assessment-of-Visualizations/","children":"[논문리뷰] VisJudge-Bench: Aesthetics and Quality Assessment of Visualizations"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiayi Zhang이 [arXiv]에 게시한 'VisJudge-Bench: Aesthetics and Quality Assessment of Visualizations' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-29 13:11:02+0900","children":"2025년 10월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Visualization Quality Assessment",{"className":"page__taxonomy-item","children":["#","Visualization Quality Assessment"]}],["$","span","MLLMs",{"className":"page__taxonomy-item","children":["#","MLLMs"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Aesthetics",{"className":"page__taxonomy-item","children":["#","Aesthetics"]}],["$","span","Fidelity",{"className":"page__taxonomy-item","children":["#","Fidelity"]}],["$","span","Expressiveness",{"className":"page__taxonomy-item","children":["#","Expressiveness"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}]]}]]}]]}],["$","article","2025-10-29-VisCoder2-Building-Multi-Language-Visualization-Coding-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-29-VisCoder2-Building-Multi-Language-Visualization-Coding-Agents/","children":"[논문리뷰] VisCoder2: Building Multi-Language Visualization Coding Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'VisCoder2: Building Multi-Language Visualization Coding Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-29 13:11:02+0900","children":"2025년 10월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-Language Visualization",{"className":"page__taxonomy-item","children":["#","Multi-Language Visualization"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","Self-Debugging",{"className":"page__taxonomy-item","children":["#","Self-Debugging"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Visualization Benchmark",{"className":"page__taxonomy-item","children":["#","Visualization Benchmark"]}],["$","span","Coding Agents",{"className":"page__taxonomy-item","children":["#","Coding Agents"]}],["$","span","Code-Feedback",{"className":"page__taxonomy-item","children":["#","Code-Feedback"]}]]}]]}]]}],["$","article","2025-10-29-VL-SAE-Interpreting-and-Enhancing-Vision-Language-Alignment-with-a-Unified-Concept-Set",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-29-VL-SAE-Interpreting-and-Enhancing-Vision-Language-Alignment-with-a-Unified-Concept-Set/","children":"[논문리뷰] VL-SAE: Interpreting and Enhancing Vision-Language Alignment with a Unified Concept Set"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'VL-SAE: Interpreting and Enhancing Vision-Language Alignment with a Unified Concept Set' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-29 13:11:02+0900","children":"2025년 10월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision-Language Models (VLMs)"]}],["$","span","Model Interpretability",{"className":"page__taxonomy-item","children":["#","Model Interpretability"]}],["$","span","Sparse Autoencoder (SAE)",{"className":"page__taxonomy-item","children":["#","Sparse Autoencoder (SAE)"]}],["$","span","Multi-modal Alignment",{"className":"page__taxonomy-item","children":["#","Multi-modal Alignment"]}],["$","span","Concept Learning",{"className":"page__taxonomy-item","children":["#","Concept Learning"]}],["$","span","Hallucination Elimination",{"className":"page__taxonomy-item","children":["#","Hallucination Elimination"]}],["$","span","Zero-shot Classification",{"className":"page__taxonomy-item","children":["#","Zero-shot Classification"]}]]}]]}]]}],["$","article","2025-10-29-Uniform-Discrete-Diffusion-with-Metric-Path-for-Video-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-29-Uniform-Discrete-Diffusion-with-Metric-Path-for-Video-Generation/","children":"[논문리뷰] Uniform Discrete Diffusion with Metric Path for Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Uniform Discrete Diffusion with Metric Path for Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-29 13:11:02+0900","children":"2025년 10월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Discrete Diffusion",{"className":"page__taxonomy-item","children":["#","Discrete Diffusion"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Metric Path",{"className":"page__taxonomy-item","children":["#","Metric Path"]}],["$","span","Long Video Generation",{"className":"page__taxonomy-item","children":["#","Long Video Generation"]}],["$","span","Asynchronous Scheduling",{"className":"page__taxonomy-item","children":["#","Asynchronous Scheduling"]}],["$","span","Text-to-Video",{"className":"page__taxonomy-item","children":["#","Text-to-Video"]}],["$","span","Multimodal Generation",{"className":"page__taxonomy-item","children":["#","Multimodal Generation"]}]]}]]}]]}],["$","article","2025-10-29-UltraHR-100K-Enhancing-UHR-Image-Synthesis-with-A-Large-Scale-High-Quality-Dataset",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-29-UltraHR-100K-Enhancing-UHR-Image-Synthesis-with-A-Large-Scale-High-Quality-Dataset/","children":"[논문리뷰] UltraHR-100K: Enhancing UHR Image Synthesis with A Large-Scale High-Quality Dataset"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'UltraHR-100K: Enhancing UHR Image Synthesis with A Large-Scale High-Quality Dataset' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-29 13:11:02+0900","children":"2025년 10월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Ultra-High-Resolution",{"className":"page__taxonomy-item","children":["#","Ultra-High-Resolution"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Large-Scale Dataset",{"className":"page__taxonomy-item","children":["#","Large-Scale Dataset"]}],["$","span","Frequency-Aware Training",{"className":"page__taxonomy-item","children":["#","Frequency-Aware Training"]}],["$","span","Detail Enhancement",{"className":"page__taxonomy-item","children":["#","Detail Enhancement"]}],["$","span","Image Synthesis",{"className":"page__taxonomy-item","children":["#","Image Synthesis"]}]]}]]}]]}],["$","article","2025-10-29-Tongyi-DeepResearch-Technical-Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-29-Tongyi-DeepResearch-Technical-Report/","children":"[논문리뷰] Tongyi DeepResearch Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Tongyi DeepResearch Technical Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-29 13:11:02+0900","children":"2025년 10월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic LLM",{"className":"page__taxonomy-item","children":["#","Agentic LLM"]}],["$","span","Deep Research",{"className":"page__taxonomy-item","children":["#","Deep Research"]}],["$","span","Information Seeking",{"className":"page__taxonomy-item","children":["#","Information Seeking"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Synthetic Data",{"className":"page__taxonomy-item","children":["#","Synthetic Data"]}],["$","span","Context Management",{"className":"page__taxonomy-item","children":["#","Context Management"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Open-source AI",{"className":"page__taxonomy-item","children":["#","Open-source AI"]}]]}]]}]]}],["$","article","2025-10-29-STAR-Bench-Probing-Deep-Spatio-Temporal-Reasoning-as-Audio-4D-Intelligence",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-29-STAR-Bench-Probing-Deep-Spatio-Temporal-Reasoning-as-Audio-4D-Intelligence/","children":"[논문리뷰] STAR-Bench: Probing Deep Spatio-Temporal Reasoning as Audio 4D Intelligence"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'STAR-Bench: Probing Deep Spatio-Temporal Reasoning as Audio 4D Intelligence' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-29 13:11:02+0900","children":"2025년 10월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Audio Intelligence",{"className":"page__taxonomy-item","children":["#","Audio Intelligence"]}],["$","span","Spatio-Temporal Reasoning",{"className":"page__taxonomy-item","children":["#","Spatio-Temporal Reasoning"]}],["$","span","4D Audio",{"className":"page__taxonomy-item","children":["#","4D Audio"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Large Audio-Language Models",{"className":"page__taxonomy-item","children":["#","Large Audio-Language Models"]}],["$","span","Perceptual Reasoning",{"className":"page__taxonomy-item","children":["#","Perceptual Reasoning"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}]]}]]}]]}],["$","article","2025-10-29-Routing-Matters-in-MoE-Scaling-Diffusion-Transformers-with-Explicit-Routing-Guidance",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-29-Routing-Matters-in-MoE-Scaling-Diffusion-Transformers-with-Explicit-Routing-Guidance/","children":"[논문리뷰] Routing Matters in MoE: Scaling Diffusion Transformers with Explicit Routing Guidance"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Routing Matters in MoE: Scaling Diffusion Transformers with Explicit Routing Guidance' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-29 13:11:02+0900","children":"2025년 10월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Mixture-of-Experts (MoE)",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts (MoE)"]}],["$","span","Diffusion Transformers (DiTs)",{"className":"page__taxonomy-item","children":["#","Diffusion Transformers (DiTs)"]}],["$","span","Routing Guidance",{"className":"page__taxonomy-item","children":["#","Routing Guidance"]}],["$","span","Semantic Specialization",{"className":"page__taxonomy-item","children":["#","Semantic Specialization"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}]]}]]}]]}],["$","article","2025-10-29-RoboOmni-Proactive-Robot-Manipulation-in-Omni-modal-Context",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-29-RoboOmni-Proactive-Robot-Manipulation-in-Omni-modal-Context/","children":"[논문리뷰] RoboOmni: Proactive Robot Manipulation in Omni-modal Context"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'RoboOmni: Proactive Robot Manipulation in Omni-modal Context' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-29 13:11:02+0900","children":"2025년 10월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Robotic Manipulation",{"className":"page__taxonomy-item","children":["#","Robotic Manipulation"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Vision-Language-Action",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action"]}],["$","span","Proactive AI",{"className":"page__taxonomy-item","children":["#","Proactive AI"]}],["$","span","Omni-modal Learning",{"className":"page__taxonomy-item","children":["#","Omni-modal Learning"]}],["$","span","Intent Recognition",{"className":"page__taxonomy-item","children":["#","Intent Recognition"]}],["$","span","Contextual Instructions",{"className":"page__taxonomy-item","children":["#","Contextual Instructions"]}]]}]]}]]}],["$","article","2025-10-29-Rethinking-Visual-Intelligence-Insights-from-Video-Pretraining",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-29-Rethinking-Visual-Intelligence-Insights-from-Video-Pretraining/","children":"[논문리뷰] Rethinking Visual Intelligence: Insights from Video Pretraining"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ahmad Rahimi이 [arXiv]에 게시한 'Rethinking Visual Intelligence: Insights from Video Pretraining' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-29 13:11:02+0900","children":"2025년 10월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Diffusion Models",{"className":"page__taxonomy-item","children":["#","Video Diffusion Models"]}],["$","span","Visual Intelligence",{"className":"page__taxonomy-item","children":["#","Visual Intelligence"]}],["$","span","Pretraining",{"className":"page__taxonomy-item","children":["#","Pretraining"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Low-resource Learning",{"className":"page__taxonomy-item","children":["#","Low-resource Learning"]}],["$","span","Inductive Biases",{"className":"page__taxonomy-item","children":["#","Inductive Biases"]}],["$","span","Visual Reasoning",{"className":"page__taxonomy-item","children":["#","Visual Reasoning"]}],["$","span","Image-to-Image Tasks",{"className":"page__taxonomy-item","children":["#","Image-to-Image Tasks"]}]]}]]}]]}],["$","article","2025-10-29-Repurposing-Synthetic-Data-for-Fine-grained-Search-Agent-Supervision",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-29-Repurposing-Synthetic-Data-for-Fine-grained-Search-Agent-Supervision/","children":"[논문리뷰] Repurposing Synthetic Data for Fine-grained Search Agent Supervision"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Repurposing Synthetic Data for Fine-grained Search Agent Supervision' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-29 13:11:02+0900","children":"2025년 10월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Search Agents",{"className":"page__taxonomy-item","children":["#","Search Agents"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Synthetic Data",{"className":"page__taxonomy-item","children":["#","Synthetic Data"]}],["$","span","Reward Shaping",{"className":"page__taxonomy-item","children":["#","Reward Shaping"]}],["$","span","Entity-aware Reward",{"className":"page__taxonomy-item","children":["#","Entity-aware Reward"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Knowledge-intensive Tasks",{"className":"page__taxonomy-item","children":["#","Knowledge-intensive Tasks"]}]]}]]}]]}],["$","article","2025-10-29-ReplicationBench-Can-AI-Agents-Replicate-Astrophysics-Research-Papers",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-29-ReplicationBench-Can-AI-Agents-Replicate-Astrophysics-Research-Papers/","children":"[논문리뷰] ReplicationBench: Can AI Agents Replicate Astrophysics Research Papers?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ian L. V. Roque이 [arXiv]에 게시한 'ReplicationBench: Can AI Agents Replicate Astrophysics Research Papers?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-29 13:11:02+0900","children":"2025년 10월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Agents",{"className":"page__taxonomy-item","children":["#","AI Agents"]}],["$","span","Astrophysics Research",{"className":"page__taxonomy-item","children":["#","Astrophysics Research"]}],["$","span","Reproducibility Benchmark",{"className":"page__taxonomy-item","children":["#","Reproducibility Benchmark"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Scientific Workflow",{"className":"page__taxonomy-item","children":["#","Scientific Workflow"]}],["$","span","Code Execution",{"className":"page__taxonomy-item","children":["#","Code Execution"]}],["$","span","Evaluation Framework",{"className":"page__taxonomy-item","children":["#","Evaluation Framework"]}]]}]]}]]}],["$","article","2025-10-29-PatenTEB-A-Comprehensive-Benchmark-and-Model-Family-for-Patent-Text-Embedding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-29-PatenTEB-A-Comprehensive-Benchmark-and-Model-Family-for-Patent-Text-Embedding/","children":"[논문리뷰] PatenTEB: A Comprehensive Benchmark and Model Family for Patent Text Embedding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Denis Cavallucci이 [arXiv]에 게시한 'PatenTEB: A Comprehensive Benchmark and Model Family for Patent Text Embedding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-29 13:11:02+0900","children":"2025년 10월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Patent Text Embedding",{"className":"page__taxonomy-item","children":["#","Patent Text Embedding"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Multi-task Learning",{"className":"page__taxonomy-item","children":["#","Multi-task Learning"]}],["$","span","Patent Retrieval",{"className":"page__taxonomy-item","children":["#","Patent Retrieval"]}],["$","span","Sentence Embeddings",{"className":"page__taxonomy-item","children":["#","Sentence Embeddings"]}],["$","span","Knowledge Distillation",{"className":"page__taxonomy-item","children":["#","Knowledge Distillation"]}],["$","span","Cross-Domain Retrieval",{"className":"page__taxonomy-item","children":["#","Cross-Domain Retrieval"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}]]}]]}]]}],["$","article","2025-10-29-PartNeXt-A-Next-Generation-Dataset-for-Fine-Grained-and-Hierarchical-3D-Part-Understanding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-29-PartNeXt-A-Next-Generation-Dataset-for-Fine-Grained-and-Hierarchical-3D-Part-Understanding/","children":"[논문리뷰] PartNeXt: A Next-Generation Dataset for Fine-Grained and Hierarchical 3D Part Understanding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Lan Xu이 [arXiv]에 게시한 'PartNeXt: A Next-Generation Dataset for Fine-Grained and Hierarchical 3D Part Understanding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-29 13:11:02+0900","children":"2025년 10월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Part Segmentation",{"className":"page__taxonomy-item","children":["#","3D Part Segmentation"]}],["$","span","3D Dataset",{"className":"page__taxonomy-item","children":["#","3D Dataset"]}],["$","span","Hierarchical Annotation",{"className":"page__taxonomy-item","children":["#","Hierarchical Annotation"]}],["$","span","Fine-Grained Segmentation",{"className":"page__taxonomy-item","children":["#","Fine-Grained Segmentation"]}],["$","span","Textured Meshes",{"className":"page__taxonomy-item","children":["#","Textured Meshes"]}],["$","span","3D Part Understanding",{"className":"page__taxonomy-item","children":["#","3D Part Understanding"]}],["$","span","Part-Centric Question Answering",{"className":"page__taxonomy-item","children":["#","Part-Centric Question Answering"]}],["$","span","Crowdsourcing",{"className":"page__taxonomy-item","children":["#","Crowdsourcing"]}]]}]]}]]}],["$","article","2025-10-29-ParallelMuse-Agentic-Parallel-Thinking-for-Deep-Information-Seeking",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-29-ParallelMuse-Agentic-Parallel-Thinking-for-Deep-Information-Seeking/","children":"[논문리뷰] ParallelMuse: Agentic Parallel Thinking for Deep Information Seeking"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'ParallelMuse: Agentic Parallel Thinking for Deep Information Seeking' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-29 13:11:02+0900","children":"2025년 10월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Parallel Thinking",{"className":"page__taxonomy-item","children":["#","Parallel Thinking"]}],["$","span","Information Seeking",{"className":"page__taxonomy-item","children":["#","Information Seeking"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Context Window Optimization",{"className":"page__taxonomy-item","children":["#","Context Window Optimization"]}],["$","span","Exploration Efficiency",{"className":"page__taxonomy-item","children":["#","Exploration Efficiency"]}],["$","span","Reasoning Aggregation",{"className":"page__taxonomy-item","children":["#","Reasoning Aggregation"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}]]}]]}]]}],["$","article","2025-10-29-OSWorld-MCP-Benchmarking-MCP-Tool-Invocation-In-Computer-Use-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-29-OSWorld-MCP-Benchmarking-MCP-Tool-Invocation-In-Computer-Use-Agents/","children":"[논문리뷰] OSWorld-MCP: Benchmarking MCP Tool Invocation In Computer-Use Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'OSWorld-MCP: Benchmarking MCP Tool Invocation In Computer-Use Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-29 13:11:02+0900","children":"2025년 10월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Agents",{"className":"page__taxonomy-item","children":["#","Multimodal Agents"]}],["$","span","Tool Invocation",{"className":"page__taxonomy-item","children":["#","Tool Invocation"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Model Context Protocol (MCP)",{"className":"page__taxonomy-item","children":["#","Model Context Protocol (MCP)"]}],["$","span","GUI Automation",{"className":"page__taxonomy-item","children":["#","GUI Automation"]}],["$","span","Computer-Use Agents",{"className":"page__taxonomy-item","children":["#","Computer-Use Agents"]}],["$","span","Evaluation Metrics",{"className":"page__taxonomy-item","children":["#","Evaluation Metrics"]}]]}]]}]]}],["$","article","2025-10-29-Latent-Sketchpad-Sketching-Visual-Thoughts-to-Elicit-Multimodal-Reasoning-in-MLLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-29-Latent-Sketchpad-Sketching-Visual-Thoughts-to-Elicit-Multimodal-Reasoning-in-MLLMs/","children":"[논문리뷰] Latent Sketchpad: Sketching Visual Thoughts to Elicit Multimodal Reasoning in MLLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Latent Sketchpad: Sketching Visual Thoughts to Elicit Multimodal Reasoning in MLLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-29 13:11:02+0900","children":"2025년 10월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Visual Reasoning",{"className":"page__taxonomy-item","children":["#","Visual Reasoning"]}],["$","span","Latent Space",{"className":"page__taxonomy-item","children":["#","Latent Space"]}],["$","span","Sketch Generation",{"className":"page__taxonomy-item","children":["#","Sketch Generation"]}],["$","span","Visual Thinking",{"className":"page__taxonomy-item","children":["#","Visual Thinking"]}],["$","span","Autoregressive Generation",{"className":"page__taxonomy-item","children":["#","Autoregressive Generation"]}],["$","span","Interpretability",{"className":"page__taxonomy-item","children":["#","Interpretability"]}]]}]]}]]}],["$","article","2025-10-29-InteractComp-Evaluating-Search-Agents-With-Ambiguous-Queries",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-29-InteractComp-Evaluating-Search-Agents-With-Ambiguous-Queries/","children":"[논문리뷰] InteractComp: Evaluating Search Agents With Ambiguous Queries"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yani Fan이 [arXiv]에 게시한 'InteractComp: Evaluating Search Agents With Ambiguous Queries' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-29 13:11:02+0900","children":"2025년 10월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Search Agents",{"className":"page__taxonomy-item","children":["#","Search Agents"]}],["$","span","Interactive AI",{"className":"page__taxonomy-item","children":["#","Interactive AI"]}],["$","span","Ambiguous Queries",{"className":"page__taxonomy-item","children":["#","Ambiguous Queries"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Language Agents",{"className":"page__taxonomy-item","children":["#","Language Agents"]}],["$","span","Information Retrieval",{"className":"page__taxonomy-item","children":["#","Information Retrieval"]}],["$","span","Overconfidence",{"className":"page__taxonomy-item","children":["#","Overconfidence"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}]]}]]}]]}],["$","article","2025-10-29-Group-Relative-Attention-Guidance-for-Image-Editing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-29-Group-Relative-Attention-Guidance-for-Image-Editing/","children":"[논문리뷰] Group Relative Attention Guidance for Image Editing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Group Relative Attention Guidance for Image Editing' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-29 13:11:02+0900","children":"2025년 10월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Diffusion Transformers",{"className":"page__taxonomy-item","children":["#","Diffusion Transformers"]}],["$","span","Attention Mechanism",{"className":"page__taxonomy-item","children":["#","Attention Mechanism"]}],["$","span","Guidance Mechanism",{"className":"page__taxonomy-item","children":["#","Guidance Mechanism"]}],["$","span","Controllability",{"className":"page__taxonomy-item","children":["#","Controllability"]}],["$","span","Fine-grained Control",{"className":"page__taxonomy-item","children":["#","Fine-grained Control"]}],["$","span","GRAG",{"className":"page__taxonomy-item","children":["#","GRAG"]}]]}]]}]]}],["$","article","2025-10-29-Generalization-or-Memorization-Dynamic-Decoding-for-Mode-Steering",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-29-Generalization-or-Memorization-Dynamic-Decoding-for-Mode-Steering/","children":"[논문리뷰] Generalization or Memorization: Dynamic Decoding for Mode Steering"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Generalization or Memorization: Dynamic Decoding for Mode Steering' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-29 13:11:02+0900","children":"2025년 10월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Memorization",{"className":"page__taxonomy-item","children":["#","Memorization"]}],["$","span","Information Bottleneck (IB)",{"className":"page__taxonomy-item","children":["#","Information Bottleneck (IB)"]}],["$","span","Activation Steering",{"className":"page__taxonomy-item","children":["#","Activation Steering"]}],["$","span","Decoding Strategy",{"className":"page__taxonomy-item","children":["#","Decoding Strategy"]}],["$","span","Causal Intervention",{"className":"page__taxonomy-item","children":["#","Causal Intervention"]}],["$","span","LLM Reliability",{"className":"page__taxonomy-item","children":["#","LLM Reliability"]}]]}]]}]]}],["$","article","2025-10-29-Game-TARS-Pretrained-Foundation-Models-for-Scalable-Generalist-Multimodal-Game-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-29-Game-TARS-Pretrained-Foundation-Models-for-Scalable-Generalist-Multimodal-Game-Agents/","children":"[논문리뷰] Game-TARS: Pretrained Foundation Models for Scalable Generalist Multimodal Game Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Game-TARS: Pretrained Foundation Models for Scalable Generalist Multimodal Game Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-29 13:11:02+0900","children":"2025년 10월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Generalist AI",{"className":"page__taxonomy-item","children":["#","Generalist AI"]}],["$","span","Game Agents",{"className":"page__taxonomy-item","children":["#","Game Agents"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","ReAct",{"className":"page__taxonomy-item","children":["#","ReAct"]}],["$","span","Sparse Thinking",{"className":"page__taxonomy-item","children":["#","Sparse Thinking"]}],["$","span","Continual Pre-training",{"className":"page__taxonomy-item","children":["#","Continual Pre-training"]}],["$","span","Human-Native Interaction",{"className":"page__taxonomy-item","children":["#","Human-Native Interaction"]}]]}]]}]]}],["$","article","2025-10-29-FunReason-MT-Technical-Report-Overcoming-the-Complexity-Barrier-in-Multi-Turn-Function-Calling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-29-FunReason-MT-Technical-Report-Overcoming-the-Complexity-Barrier-in-Multi-Turn-Function-Calling/","children":"[논문리뷰] FunReason-MT Technical Report: Overcoming the Complexity Barrier in Multi-Turn Function Calling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'FunReason-MT Technical Report: Overcoming the Complexity Barrier in Multi-Turn Function Calling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-29 13:11:02+0900","children":"2025년 10월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Function Calling",{"className":"page__taxonomy-item","children":["#","Function Calling"]}],["$","span","Multi-Turn Interaction",{"className":"page__taxonomy-item","children":["#","Multi-Turn Interaction"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Data Synthesis",{"className":"page__taxonomy-item","children":["#","Data Synthesis"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Chain-of-Thought (CoT)",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought (CoT)"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}]]}]]}]]}],["$","article","2025-10-29-From-Spatial-to-Actions-Grounding-Vision-Language-Action-Model-in-Spatial-Foundation-Priors",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-29-From-Spatial-to-Actions-Grounding-Vision-Language-Action-Model-in-Spatial-Foundation-Priors/","children":"[논문리뷰] From Spatial to Actions: Grounding Vision-Language-Action Model in Spatial Foundation Priors"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'From Spatial to Actions: Grounding Vision-Language-Action Model in Spatial Foundation Priors' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-29 13:11:02+0900","children":"2025년 10월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action (VLA)",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action (VLA)"]}],["$","span","3D Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","3D Spatial Reasoning"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Multimodal Fusion",{"className":"page__taxonomy-item","children":["#","Multimodal Fusion"]}],["$","span","Robot Manipulation",{"className":"page__taxonomy-item","children":["#","Robot Manipulation"]}],["$","span","Modality Transferability",{"className":"page__taxonomy-item","children":["#","Modality Transferability"]}],["$","span","Action Grounding",{"className":"page__taxonomy-item","children":["#","Action Grounding"]}]]}]]}]]}],["$","article","2025-10-29-Critique-RL-Training-Language-Models-for-Critiquing-through-Two-Stage-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-29-Critique-RL-Training-Language-Models-for-Critiquing-through-Two-Stage-Reinforcement-Learning/","children":"[논문리뷰] Critique-RL: Training Language Models for Critiquing through Two-Stage Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Critique-RL: Training Language Models for Critiquing through Two-Stage Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-29 13:11:02+0900","children":"2025년 10월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Language Models",{"className":"page__taxonomy-item","children":["#","Language Models"]}],["$","span","Critiquing",{"className":"page__taxonomy-item","children":["#","Critiquing"]}],["$","span","Two-Stage Optimization",{"className":"page__taxonomy-item","children":["#","Two-Stage Optimization"]}],["$","span","Actor-Critic",{"className":"page__taxonomy-item","children":["#","Actor-Critic"]}],["$","span","Scalable Oversight",{"className":"page__taxonomy-item","children":["#","Scalable Oversight"]}],["$","span","Discriminability",{"className":"page__taxonomy-item","children":["#","Discriminability"]}],["$","span","Helpfulness",{"className":"page__taxonomy-item","children":["#","Helpfulness"]}]]}]]}]]}],["$","article","2025-10-29-AgentFrontier-Expanding-the-Capability-Frontier-of-LLM-Agents-with-ZPD-Guided-Data-Synthesis",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-29-AgentFrontier-Expanding-the-Capability-Frontier-of-LLM-Agents-with-ZPD-Guided-Data-Synthesis/","children":"[논문리뷰] AgentFrontier: Expanding the Capability Frontier of LLM Agents with ZPD-Guided Data Synthesis"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'AgentFrontier: Expanding the Capability Frontier of LLM Agents with ZPD-Guided Data Synthesis' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-29 13:11:02+0900","children":"2025년 10월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Data Synthesis",{"className":"page__taxonomy-item","children":["#","Data Synthesis"]}],["$","span","Zone of Proximal Development (ZPD)",{"className":"page__taxonomy-item","children":["#","Zone of Proximal Development (ZPD)"]}],["$","span","Complex Reasoning",{"className":"page__taxonomy-item","children":["#","Complex Reasoning"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Automated Benchmarking",{"className":"page__taxonomy-item","children":["#","Automated Benchmarking"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Rejection Sampling Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Rejection Sampling Fine-Tuning"]}]]}]]}]]}],["$","article","2025-10-29-AgentFold-Long-Horizon-Web-Agents-with-Proactive-Context-Management",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-29-AgentFold-Long-Horizon-Web-Agents-with-Proactive-Context-Management/","children":"[논문리뷰] AgentFold: Long-Horizon Web Agents with Proactive Context Management"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'AgentFold: Long-Horizon Web Agents with Proactive Context Management' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-29 13:11:02+0900","children":"2025년 10월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Web Agents",{"className":"page__taxonomy-item","children":["#","Web Agents"]}],["$","span","Context Management",{"className":"page__taxonomy-item","children":["#","Context Management"]}],["$","span","Long-Horizon Tasks",{"className":"page__taxonomy-item","children":["#","Long-Horizon Tasks"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Deep Consolidation",{"className":"page__taxonomy-item","children":["#","Deep Consolidation"]}],["$","span","Granular Condensation",{"className":"page__taxonomy-item","children":["#","Granular Condensation"]}],["$","span","ReAct Paradigm",{"className":"page__taxonomy-item","children":["#","ReAct Paradigm"]}]]}]]}]]}],["$","article","2025-10-29-ATLAS-Adaptive-Transfer-Scaling-Laws-for-Multilingual-Pretraining-Finetuning-and-Decoding-the-Curse-of-Multilinguality",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-29-ATLAS-Adaptive-Transfer-Scaling-Laws-for-Multilingual-Pretraining-Finetuning-and-Decoding-the-Curse-of-Multilinguality/","children":"[논문리뷰] ATLAS: Adaptive Transfer Scaling Laws for Multilingual Pretraining, Finetuning, and Decoding the Curse of Multilinguality"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'ATLAS: Adaptive Transfer Scaling Laws for Multilingual Pretraining, Finetuning, and Decoding the Curse of Multilinguality' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-29 13:11:02+0900","children":"2025년 10월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multilingual LLMs",{"className":"page__taxonomy-item","children":["#","Multilingual LLMs"]}],["$","span","Scaling Laws",{"className":"page__taxonomy-item","children":["#","Scaling Laws"]}],["$","span","Transfer Learning",{"className":"page__taxonomy-item","children":["#","Transfer Learning"]}],["$","span","Curse of Multilinguality",{"className":"page__taxonomy-item","children":["#","Curse of Multilinguality"]}],["$","span","Pretraining",{"className":"page__taxonomy-item","children":["#","Pretraining"]}],["$","span","Finetuning",{"className":"page__taxonomy-item","children":["#","Finetuning"]}],["$","span","Language Models",{"className":"page__taxonomy-item","children":["#","Language Models"]}],["$","span","Adaptive Scaling",{"className":"page__taxonomy-item","children":["#","Adaptive Scaling"]}]]}]]}]]}],["$","article","2025-10-28-VoMP-Predicting-Volumetric-Mechanical-Property-Fields",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-28-VoMP-Predicting-Volumetric-Mechanical-Property-Fields/","children":"[논문리뷰] VoMP: Predicting Volumetric Mechanical Property Fields"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'VoMP: Predicting Volumetric Mechanical Property Fields' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-28 13:07:54+0900","children":"2025년 10월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Volumetric Properties",{"className":"page__taxonomy-item","children":["#","Volumetric Properties"]}],["$","span","Mechanical Simulation",{"className":"page__taxonomy-item","children":["#","Mechanical Simulation"]}],["$","span","Material Prediction",{"className":"page__taxonomy-item","children":["#","Material Prediction"]}],["$","span","3D Representation",{"className":"page__taxonomy-item","children":["#","3D Representation"]}],["$","span","Physics-based AI",{"className":"page__taxonomy-item","children":["#","Physics-based AI"]}],["$","span","Variational Autoencoder",{"className":"page__taxonomy-item","children":["#","Variational Autoencoder"]}],["$","span","Geometry Transformer",{"className":"page__taxonomy-item","children":["#","Geometry Transformer"]}],["$","span","Gaussian Splats",{"className":"page__taxonomy-item","children":["#","Gaussian Splats"]}]]}]]}]]}],["$","article","2025-10-28-VITA-E-Natural-Embodied-Interaction-with-Concurrent-Seeing-Hearing-Speaking-and-Acting",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-28-VITA-E-Natural-Embodied-Interaction-with-Concurrent-Seeing-Hearing-Speaking-and-Acting/","children":"[논문리뷰] VITA-E: Natural Embodied Interaction with Concurrent Seeing, Hearing, Speaking, and Acting"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Haihan Gao이 [arXiv]에 게시한 'VITA-E: Natural Embodied Interaction with Concurrent Seeing, Hearing, Speaking, and Acting' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-28 13:07:54+0900","children":"2025년 10월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Human-Robot Interaction",{"className":"page__taxonomy-item","children":["#","Human-Robot Interaction"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Concurrency",{"className":"page__taxonomy-item","children":["#","Concurrency"]}],["$","span","Interruption",{"className":"page__taxonomy-item","children":["#","Interruption"]}],["$","span","Robotics Control",{"className":"page__taxonomy-item","children":["#","Robotics Control"]}],["$","span","Dual-Model Architecture",{"className":"page__taxonomy-item","children":["#","Dual-Model Architecture"]}],["$","span","Special Tokens",{"className":"page__taxonomy-item","children":["#","Special Tokens"]}]]}]]}]]}],["$","article","2025-10-28-Track-Inpaint-Resplat-Subject-driven-3D-and-4D-Generation-with-Progressive-Texture-Infilling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-28-Track-Inpaint-Resplat-Subject-driven-3D-and-4D-Generation-with-Progressive-Texture-Infilling/","children":"[논문리뷰] Track, Inpaint, Resplat: Subject-driven 3D and 4D Generation with Progressive Texture Infilling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Igor Gilitschenski이 [arXiv]에 게시한 'Track, Inpaint, Resplat: Subject-driven 3D and 4D Generation with Progressive Texture Infilling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-28 13:07:54+0900","children":"2025년 10월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Subject-driven 3D/4D Generation",{"className":"page__taxonomy-item","children":["#","Subject-driven 3D/4D Generation"]}],["$","span","Texture Infilling",{"className":"page__taxonomy-item","children":["#","Texture Infilling"]}],["$","span","Video Tracking",{"className":"page__taxonomy-item","children":["#","Video Tracking"]}],["$","span","Image Inpainting",{"className":"page__taxonomy-item","children":["#","Image Inpainting"]}],["$","span","Multi-view Consistency",{"className":"page__taxonomy-item","children":["#","Multi-view Consistency"]}],["$","span","Identity Preservation",{"className":"page__taxonomy-item","children":["#","Identity Preservation"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","3D Gaussians",{"className":"page__taxonomy-item","children":["#","3D Gaussians"]}]]}]]}]]}],["$","article","2025-10-28-The-Best-of-N-Worlds-Aligning-Reinforcement-Learning-with-Best-of-N-Sampling-via-maxk-Optimisation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-28-The-Best-of-N-Worlds-Aligning-Reinforcement-Learning-with-Best-of-N-Sampling-via-maxk-Optimisation/","children":"[논문리뷰] The Best of N Worlds: Aligning Reinforcement Learning with Best-of-N Sampling via max@k Optimisation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'The Best of N Worlds: Aligning Reinforcement Learning with Best-of-N Sampling via max@k Optimisation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-28 13:07:54+0900","children":"2025년 10월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Best-of-N Sampling",{"className":"page__taxonomy-item","children":["#","Best-of-N Sampling"]}],["$","span","Max@k Optimization",{"className":"page__taxonomy-item","children":["#","Max@k Optimization"]}],["$","span","Policy Gradients",{"className":"page__taxonomy-item","children":["#","Policy Gradients"]}],["$","span","Off-policy Learning",{"className":"page__taxonomy-item","children":["#","Off-policy Learning"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}]]}]]}]]}],["$","article","2025-10-28-RobotArena-infty-Scalable-Robot-Benchmarking-via-Real-to-Sim-Translation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-28-RobotArena-infty-Scalable-Robot-Benchmarking-via-Real-to-Sim-Translation/","children":"[논문리뷰] RobotArena infty: Scalable Robot Benchmarking via Real-to-Sim Translation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kuan-Hsun Tu이 [arXiv]에 게시한 'RobotArena infty: Scalable Robot Benchmarking via Real-to-Sim Translation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-28 13:07:54+0900","children":"2025년 10월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Robot Benchmarking",{"className":"page__taxonomy-item","children":["#","Robot Benchmarking"]}],["$","span","Real-to-Sim Translation",{"className":"page__taxonomy-item","children":["#","Real-to-Sim Translation"]}],["$","span","Vision-Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision-Language Models (VLMs)"]}],["$","span","Human Preference Learning",{"className":"page__taxonomy-item","children":["#","Human Preference Learning"]}],["$","span","Domain Randomization",{"className":"page__taxonomy-item","children":["#","Domain Randomization"]}],["$","span","Robot Manipulation",{"className":"page__taxonomy-item","children":["#","Robot Manipulation"]}],["$","span","Simulation Environments",{"className":"page__taxonomy-item","children":["#","Simulation Environments"]}],["$","span","Policy Evaluation",{"className":"page__taxonomy-item","children":["#","Policy Evaluation"]}]]}]]}]]}],["$","article","2025-10-28-ReCode-Unify-Plan-and-Action-for-Universal-Granularity-Control",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-28-ReCode-Unify-Plan-and-Action-for-Universal-Granularity-Control/","children":"[논문리뷰] ReCode: Unify Plan and Action for Universal Granularity Control"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yifan Wu이 [arXiv]에 게시한 'ReCode: Unify Plan and Action for Universal Granularity Control' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-28 13:07:54+0900","children":"2025년 10월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Decision Granularity Control",{"className":"page__taxonomy-item","children":["#","Decision Granularity Control"]}],["$","span","Recursive Code Generation",{"className":"page__taxonomy-item","children":["#","Recursive Code Generation"]}],["$","span","Hierarchical Planning",{"className":"page__taxonomy-item","children":["#","Hierarchical Planning"]}],["$","span","Action Unification",{"className":"page__taxonomy-item","children":["#","Action Unification"]}],["$","span","Program Synthesis",{"className":"page__taxonomy-item","children":["#","Program Synthesis"]}],["$","span","Data Efficiency",{"className":"page__taxonomy-item","children":["#","Data Efficiency"]}]]}]]}]]}],["$","article","2025-10-28-PixelRefer-A-Unified-Framework-for-Spatio-Temporal-Object-Referring-with-Arbitrary-Granularity",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-28-PixelRefer-A-Unified-Framework-for-Spatio-Temporal-Object-Referring-with-Arbitrary-Granularity/","children":"[논문리뷰] PixelRefer: A Unified Framework for Spatio-Temporal Object Referring with Arbitrary Granularity"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kehan Li이 [arXiv]에 게시한 'PixelRefer: A Unified Framework for Spatio-Temporal Object Referring with Arbitrary Granularity' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-28 13:07:54+0900","children":"2025년 10월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","MLLM",{"className":"page__taxonomy-item","children":["#","MLLM"]}],["$","span","Region-level Understanding",{"className":"page__taxonomy-item","children":["#","Region-level Understanding"]}],["$","span","Object-centric Reasoning",{"className":"page__taxonomy-item","children":["#","Object-centric Reasoning"]}],["$","span","Spatio-temporal Referring",{"className":"page__taxonomy-item","children":["#","Spatio-temporal Referring"]}],["$","span","Video Understanding",{"className":"page__taxonomy-item","children":["#","Video Understanding"]}],["$","span","Scale-Adaptive Tokenizer",{"className":"page__taxonomy-item","children":["#","Scale-Adaptive Tokenizer"]}],["$","span","Efficiency",{"className":"page__taxonomy-item","children":["#","Efficiency"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}]]}]]}]]}],["$","article","2025-10-28-Omni-Reward-Towards-Generalist-Omni-Modal-Reward-Modeling-with-Free-Form-Preferences",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-28-Omni-Reward-Towards-Generalist-Omni-Modal-Reward-Modeling-with-Free-Form-Preferences/","children":"[논문리뷰] Omni-Reward: Towards Generalist Omni-Modal Reward Modeling with Free-Form Preferences"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Omni-Reward: Towards Generalist Omni-Modal Reward Modeling with Free-Form Preferences' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-28 13:07:54+0900","children":"2025년 10월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reward Modeling",{"className":"page__taxonomy-item","children":["#","Reward Modeling"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Human Preferences",{"className":"page__taxonomy-item","children":["#","Human Preferences"]}],["$","span","RLHF",{"className":"page__taxonomy-item","children":["#","RLHF"]}],["$","span","Generalist AI",{"className":"page__taxonomy-item","children":["#","Generalist AI"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}],["$","span","Free-Form Preferences",{"className":"page__taxonomy-item","children":["#","Free-Form Preferences"]}]]}]]}]]}],["$","article","2025-10-28-Mitigating-Attention-Sinks-and-Massive-Activations-in-Audio-Visual-Speech-Recognition-with-LLMS",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-28-Mitigating-Attention-Sinks-and-Massive-Activations-in-Audio-Visual-Speech-Recognition-with-LLMS/","children":"[논문리뷰] Mitigating Attention Sinks and Massive Activations in Audio-Visual Speech Recognition with LLMS"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Mitigating Attention Sinks and Massive Activations in Audio-Visual Speech Recognition with LLMS' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-28 13:07:54+0900","children":"2025년 10월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Audio-Visual Speech Recognition",{"className":"page__taxonomy-item","children":["#","Audio-Visual Speech Recognition"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Attention Sinks",{"className":"page__taxonomy-item","children":["#","Attention Sinks"]}],["$","span","Massive Activations",{"className":"page__taxonomy-item","children":["#","Massive Activations"]}],["$","span","Decorrelation Loss",{"className":"page__taxonomy-item","children":["#","Decorrelation Loss"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}]]}]]}]]}],["$","article","2025-10-28-Memory-based-Language-Models-An-Efficient-Explainable-and-Eco-friendly-Approach-to-Large-Language-Modeling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-28-Memory-based-Language-Models-An-Efficient-Explainable-and-Eco-friendly-Approach-to-Large-Language-Modeling/","children":"[논문리뷰] Memory-based Language Models: An Efficient, Explainable, and Eco-friendly Approach to Large Language Modeling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Memory-based Language Models: An Efficient, Explainable, and Eco-friendly Approach to Large Language Modeling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-28 13:07:54+0900","children":"2025년 10월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Memory-based Language Model",{"className":"page__taxonomy-item","children":["#","Memory-based Language Model"]}],["$","span","k-Nearest Neighbor",{"className":"page__taxonomy-item","children":["#","k-Nearest Neighbor"]}],["$","span","Eco-friendly AI",{"className":"page__taxonomy-item","children":["#","Eco-friendly AI"]}],["$","span","Explainable AI",{"className":"page__taxonomy-item","children":["#","Explainable AI"]}],["$","span","Next-token Prediction",{"className":"page__taxonomy-item","children":["#","Next-token Prediction"]}],["$","span","Prefix Trie",{"className":"page__taxonomy-item","children":["#","Prefix Trie"]}],["$","span","Low-latency Inference",{"className":"page__taxonomy-item","children":["#","Low-latency Inference"]}],["$","span","CPU-based AI",{"className":"page__taxonomy-item","children":["#","CPU-based AI"]}]]}]]}]]}],["$","article","2025-10-28-MARS-M-When-Variance-Reduction-Meets-Matrices",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-28-MARS-M-When-Variance-Reduction-Meets-Matrices/","children":"[논문리뷰] MARS-M: When Variance Reduction Meets Matrices"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'MARS-M: When Variance Reduction Meets Matrices' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-28 13:07:54+0900","children":"2025년 10월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Variance Reduction",{"className":"page__taxonomy-item","children":["#","Variance Reduction"]}],["$","span","Matrix-based Optimizer",{"className":"page__taxonomy-item","children":["#","Matrix-based Optimizer"]}],["$","span","LLM Training",{"className":"page__taxonomy-item","children":["#","LLM Training"]}],["$","span","Deep Learning Optimization",{"className":"page__taxonomy-item","children":["#","Deep Learning Optimization"]}],["$","span","Moonlight",{"className":"page__taxonomy-item","children":["#","Moonlight"]}],["$","span","MARS-M",{"className":"page__taxonomy-item","children":["#","MARS-M"]}],["$","span","Stochastic Gradient Descent",{"className":"page__taxonomy-item","children":["#","Stochastic Gradient Descent"]}]]}]]}]]}],["$","article","2025-10-28-Lookahead-Anchoring-Preserving-Character-Identity-in-Audio-Driven-Human-Animation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-28-Lookahead-Anchoring-Preserving-Character-Identity-in-Audio-Driven-Human-Animation/","children":"[논문리뷰] Lookahead Anchoring: Preserving Character Identity in Audio-Driven Human Animation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Honglie Chen이 [arXiv]에 게시한 'Lookahead Anchoring: Preserving Character Identity in Audio-Driven Human Animation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-28 13:07:54+0900","children":"2025년 10월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Audio-driven Animation",{"className":"page__taxonomy-item","children":["#","Audio-driven Animation"]}],["$","span","Identity Preservation",{"className":"page__taxonomy-item","children":["#","Identity Preservation"]}],["$","span","Diffusion Transformers",{"className":"page__taxonomy-item","children":["#","Diffusion Transformers"]}],["$","span","Long-form Video Generation",{"className":"page__taxonomy-item","children":["#","Long-form Video Generation"]}],["$","span","Temporal Autoregression",{"className":"page__taxonomy-item","children":["#","Temporal Autoregression"]}],["$","span","Keyframe Anchoring",{"className":"page__taxonomy-item","children":["#","Keyframe Anchoring"]}],["$","span","Self-keyframing",{"className":"page__taxonomy-item","children":["#","Self-keyframing"]}]]}]]}]]}],["$","article","2025-10-28-LongCat-Video-Technical-Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-28-LongCat-Video-Technical-Report/","children":"[논문리뷰] LongCat-Video Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hongyu Li이 [arXiv]에 게시한 'LongCat-Video Technical Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-28 13:07:54+0900","children":"2025년 10월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Diffusion Transformer",{"className":"page__taxonomy-item","children":["#","Diffusion Transformer"]}],["$","span","RLHF",{"className":"page__taxonomy-item","children":["#","RLHF"]}],["$","span","Sparse Attention",{"className":"page__taxonomy-item","children":["#","Sparse Attention"]}],["$","span","Long Video Generation",{"className":"page__taxonomy-item","children":["#","Long Video Generation"]}],["$","span","Coarse-to-Fine Generation",{"className":"page__taxonomy-item","children":["#","Coarse-to-Fine Generation"]}],["$","span","Multi-task Learning",{"className":"page__taxonomy-item","children":["#","Multi-task Learning"]}],["$","span","World Models",{"className":"page__taxonomy-item","children":["#","World Models"]}]]}]]}]]}],["$","article","2025-10-28-LimRank-Less-is-More-for-Reasoning-Intensive-Information-Reranking",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-28-LimRank-Less-is-More-for-Reasoning-Intensive-Information-Reranking/","children":"[논문리뷰] LimRank: Less is More for Reasoning-Intensive Information Reranking"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Arman Cohan이 [arXiv]에 게시한 'LimRank: Less is More for Reasoning-Intensive Information Reranking' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-28 13:07:54+0900","children":"2025년 10월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Information Reranking",{"className":"page__taxonomy-item","children":["#","Information Reranking"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Data Synthesis",{"className":"page__taxonomy-item","children":["#","Data Synthesis"]}],["$","span","Reasoning-Intensive Retrieval",{"className":"page__taxonomy-item","children":["#","Reasoning-Intensive Retrieval"]}],["$","span","Low-Resource Learning",{"className":"page__taxonomy-item","children":["#","Low-Resource Learning"]}],["$","span","Data Efficiency",{"className":"page__taxonomy-item","children":["#","Data Efficiency"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}]]}]]}]]}],["$","article","2025-10-28-LightBagel-A-Light-weighted-Double-Fusion-Framework-for-Unified-Multimodal-Understanding-and-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-28-LightBagel-A-Light-weighted-Double-Fusion-Framework-for-Unified-Multimodal-Understanding-and-Generation/","children":"[논문리뷰] LightBagel: A Light-weighted, Double Fusion Framework for Unified Multimodal Understanding and Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chaorui Deng이 [arXiv]에 게시한 'LightBagel: A Light-weighted, Double Fusion Framework for Unified Multimodal Understanding and Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-28 13:07:54+0900","children":"2025년 10월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Unified Multimodal Models",{"className":"page__taxonomy-item","children":["#","Unified Multimodal Models"]}],["$","span","Double Fusion",{"className":"page__taxonomy-item","children":["#","Double Fusion"]}],["$","span","Lightweight AI",{"className":"page__taxonomy-item","children":["#","Lightweight AI"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Model Architecture",{"className":"page__taxonomy-item","children":["#","Model Architecture"]}],["$","span","Efficient Training",{"className":"page__taxonomy-item","children":["#","Efficient Training"]}],["$","span","Cross-modal Interaction",{"className":"page__taxonomy-item","children":["#","Cross-modal Interaction"]}]]}]]}]]}],["$","article","2025-10-28-Language-Server-CLI-Empowers-Language-Agents-with-Process-Rewards",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-28-Language-Server-CLI-Empowers-Language-Agents-with-Process-Rewards/","children":"[논문리뷰] Language Server CLI Empowers Language Agents with Process Rewards"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Lanser Contributors이 [arXiv]에 게시한 'Language Server CLI Empowers Language Agents with Process Rewards' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-28 13:07:54+0900","children":"2025년 10월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Language Agents",{"className":"page__taxonomy-item","children":["#","Language Agents"]}],["$","span","Language Server Protocol (LSP)",{"className":"page__taxonomy-item","children":["#","Language Server Protocol (LSP)"]}],["$","span","CLI",{"className":"page__taxonomy-item","children":["#","CLI"]}],["$","span","Process Rewards",{"className":"page__taxonomy-item","children":["#","Process Rewards"]}],["$","span","Code Refactoring",{"className":"page__taxonomy-item","children":["#","Code Refactoring"]}],["$","span","Static Analysis",{"className":"page__taxonomy-item","children":["#","Static Analysis"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Deterministic Execution",{"className":"page__taxonomy-item","children":["#","Deterministic Execution"]}]]}]]}]]}],["$","article","2025-10-28-Knocking-Heads-Attention",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-28-Knocking-Heads-Attention/","children":"[논문리뷰] Knocking-Heads Attention"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jianguo Li이 [arXiv]에 게시한 'Knocking-Heads Attention' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-28 13:07:54+0900","children":"2025년 10월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-Head Attention",{"className":"page__taxonomy-item","children":["#","Multi-Head Attention"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Inter-Head Communication",{"className":"page__taxonomy-item","children":["#","Inter-Head Communication"]}],["$","span","Parameter Sharing",{"className":"page__taxonomy-item","children":["#","Parameter Sharing"]}],["$","span","Training Stability",{"className":"page__taxonomy-item","children":["#","Training Stability"]}],["$","span","Diagonal Initialization",{"className":"page__taxonomy-item","children":["#","Diagonal Initialization"]}]]}]]}]]}],["$","article","2025-10-28-IGGT-Instance-Grounded-Geometry-Transformer-for-Semantic-3D-Reconstruction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-28-IGGT-Instance-Grounded-Geometry-Transformer-for-Semantic-3D-Reconstruction/","children":"[논문리뷰] IGGT: Instance-Grounded Geometry Transformer for Semantic 3D Reconstruction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Fangzhou Hong이 [arXiv]에 게시한 'IGGT: Instance-Grounded Geometry Transformer for Semantic 3D Reconstruction' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-28 13:07:54+0900","children":"2025년 10월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Semantic 3D Reconstruction",{"className":"page__taxonomy-item","children":["#","Semantic 3D Reconstruction"]}],["$","span","Instance Grounding",{"className":"page__taxonomy-item","children":["#","Instance Grounding"]}],["$","span","Geometry Transformer",{"className":"page__taxonomy-item","children":["#","Geometry Transformer"]}],["$","span","Multi-view Consistency",{"className":"page__taxonomy-item","children":["#","Multi-view Consistency"]}],["$","span","Scene Understanding",{"className":"page__taxonomy-item","children":["#","Scene Understanding"]}],["$","span","InsScene-15K",{"className":"page__taxonomy-item","children":["#","InsScene-15K"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Cross-Modal Fusion",{"className":"page__taxonomy-item","children":["#","Cross-Modal Fusion"]}]]}]]}]]}],["$","article","2025-10-28-FARMER-Flow-AutoRegressive-Transformer-over-Pixels",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-28-FARMER-Flow-AutoRegressive-Transformer-over-Pixels/","children":"[논문리뷰] FARMER: Flow AutoRegressive Transformer over Pixels"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhijie Lin이 [arXiv]에 게시한 'FARMER: Flow AutoRegressive Transformer over Pixels' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-28 13:07:54+0900","children":"2025년 10월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Normalizing Flows",{"className":"page__taxonomy-item","children":["#","Normalizing Flows"]}],["$","span","Autoregressive Models",{"className":"page__taxonomy-item","children":["#","Autoregressive Models"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Image Synthesis",{"className":"page__taxonomy-item","children":["#","Image Synthesis"]}],["$","span","Tractable Likelihood",{"className":"page__taxonomy-item","children":["#","Tractable Likelihood"]}],["$","span","Dimension Reduction",{"className":"page__taxonomy-item","children":["#","Dimension Reduction"]}],["$","span","Distillation",{"className":"page__taxonomy-item","children":["#","Distillation"]}],["$","span","Classifier-Free Guidance",{"className":"page__taxonomy-item","children":["#","Classifier-Free Guidance"]}]]}]]}]]}],["$","article","2025-10-28-EchoDistill-Bidirectional-Concept-Distillation-for-One-Step-Diffusion-Personalization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-28-EchoDistill-Bidirectional-Concept-Distillation-for-One-Step-Diffusion-Personalization/","children":"[논문리뷰] EchoDistill: Bidirectional Concept Distillation for One-Step Diffusion Personalization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yaxing Wang이 [arXiv]에 게시한 'EchoDistill: Bidirectional Concept Distillation for One-Step Diffusion Personalization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-28 13:07:54+0900","children":"2025년 10월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","One-Step Generation",{"className":"page__taxonomy-item","children":["#","One-Step Generation"]}],["$","span","Model Personalization",{"className":"page__taxonomy-item","children":["#","Model Personalization"]}],["$","span","Knowledge Distillation",{"className":"page__taxonomy-item","children":["#","Knowledge Distillation"]}],["$","span","Bidirectional Learning",{"className":"page__taxonomy-item","children":["#","Bidirectional Learning"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Concept Learning",{"className":"page__taxonomy-item","children":["#","Concept Learning"]}]]}]]}]]}],["$","article","2025-10-28-E2Rank-Your-Text-Embedding-can-Also-be-an-Effective-and-Efficient-Listwise-Reranker",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-28-E2Rank-Your-Text-Embedding-can-Also-be-an-Effective-and-Efficient-Listwise-Reranker/","children":"[논문리뷰] E^2Rank: Your Text Embedding can Also be an Effective and Efficient Listwise Reranker"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'E^2Rank: Your Text Embedding can Also be an Effective and Efficient Listwise Reranker' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-28 13:07:54+0900","children":"2025년 10월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text Embedding",{"className":"page__taxonomy-item","children":["#","Text Embedding"]}],["$","span","Listwise Reranking",{"className":"page__taxonomy-item","children":["#","Listwise Reranking"]}],["$","span","Information Retrieval",{"className":"page__taxonomy-item","children":["#","Information Retrieval"]}],["$","span","Pseudo Relevance Feedback",{"className":"page__taxonomy-item","children":["#","Pseudo Relevance Feedback"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Multi-task Learning",{"className":"page__taxonomy-item","children":["#","Multi-task Learning"]}],["$","span","Efficiency",{"className":"page__taxonomy-item","children":["#","Efficiency"]}],["$","span","LLM-based Ranking",{"className":"page__taxonomy-item","children":["#","LLM-based Ranking"]}]]}]]}]]}],["$","article","2025-10-28-Distilled-Decoding-2-One-step-Sampling-of-Image-Auto-regressive-Models-with-Conditional-Score-Distillation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-28-Distilled-Decoding-2-One-step-Sampling-of-Image-Auto-regressive-Models-with-Conditional-Score-Distillation/","children":"[논문리뷰] Distilled Decoding 2: One-step Sampling of Image Auto-regressive Models with Conditional Score Distillation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Guohao Dai이 [arXiv]에 게시한 'Distilled Decoding 2: One-step Sampling of Image Auto-regressive Models with Conditional Score Distillation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-28 13:07:54+0900","children":"2025년 10월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Auto-regressive Models",{"className":"page__taxonomy-item","children":["#","Auto-regressive Models"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","One-step Sampling",{"className":"page__taxonomy-item","children":["#","One-step Sampling"]}],["$","span","Model Distillation",{"className":"page__taxonomy-item","children":["#","Model Distillation"]}],["$","span","Conditional Score Distillation",{"className":"page__taxonomy-item","children":["#","Conditional Score Distillation"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}]]}]]}]]}],["$","article","2025-10-28-DiffusionLane-Diffusion-Model-for-Lane-Detection",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-28-DiffusionLane-Diffusion-Model-for-Lane-Detection/","children":"[논문리뷰] DiffusionLane: Diffusion Model for Lane Detection"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DiffusionLane: Diffusion Model for Lane Detection' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-28 13:07:54+0900","children":"2025년 10월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Lane Detection",{"className":"page__taxonomy-item","children":["#","Lane Detection"]}],["$","span","Diffusion Model",{"className":"page__taxonomy-item","children":["#","Diffusion Model"]}],["$","span","Denoising Diffusion",{"className":"page__taxonomy-item","children":["#","Denoising Diffusion"]}],["$","span","Hybrid Decoding",{"className":"page__taxonomy-item","children":["#","Hybrid Decoding"]}],["$","span","Anchor-based",{"className":"page__taxonomy-item","children":["#","Anchor-based"]}],["$","span","Domain Adaptation",{"className":"page__taxonomy-item","children":["#","Domain Adaptation"]}],["$","span","Computer Vision",{"className":"page__taxonomy-item","children":["#","Computer Vision"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}]]}]]}]]}],["$","article","2025-10-28-Concerto-Joint-2D-3D-Self-Supervised-Learning-Emerges-Spatial-Representations",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-28-Concerto-Joint-2D-3D-Self-Supervised-Learning-Emerges-Spatial-Representations/","children":"[논문리뷰] Concerto: Joint 2D-3D Self-Supervised Learning Emerges Spatial Representations"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Concerto: Joint 2D-3D Self-Supervised Learning Emerges Spatial Representations' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-28 13:07:54+0900","children":"2025년 10월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Self-Supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-Supervised Learning"]}],["$","span","2D-3D Fusion",{"className":"page__taxonomy-item","children":["#","2D-3D Fusion"]}],["$","span","Spatial Representation",{"className":"page__taxonomy-item","children":["#","Spatial Representation"]}],["$","span","Point Cloud",{"className":"page__taxonomy-item","children":["#","Point Cloud"]}],["$","span","Image Features",{"className":"page__taxonomy-item","children":["#","Image Features"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Semantic Segmentation",{"className":"page__taxonomy-item","children":["#","Semantic Segmentation"]}],["$","span","LoRA",{"className":"page__taxonomy-item","children":["#","LoRA"]}]]}]]}]]}],["$","article","2025-10-28-Code-Aesthetics-with-Agentic-Reward-Feedback",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-28-Code-Aesthetics-with-Agentic-Reward-Feedback/","children":"[논문리뷰] Code Aesthetics with Agentic Reward Feedback"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yupan Huang이 [arXiv]에 게시한 'Code Aesthetics with Agentic Reward Feedback' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-28 13:07:54+0900","children":"2025년 10월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Code Aesthetics",{"className":"page__taxonomy-item","children":["#","Code Aesthetics"]}],["$","span","Agentic Reward Feedback",{"className":"page__taxonomy-item","children":["#","Agentic Reward Feedback"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}],["$","span","Webpage Design",{"className":"page__taxonomy-item","children":["#","Webpage Design"]}],["$","span","Multimodal Evaluation",{"className":"page__taxonomy-item","children":["#","Multimodal Evaluation"]}]]}]]}]]}],["$","article","2025-10-28-ACG-Action-Coherence-Guidance-for-Flow-based-VLA-models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-28-ACG-Action-Coherence-Guidance-for-Flow-based-VLA-models/","children":"[논문리뷰] ACG: Action Coherence Guidance for Flow-based VLA models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'ACG: Action Coherence Guidance for Flow-based VLA models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-28 13:07:54+0900","children":"2025년 10월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Action Coherence",{"className":"page__taxonomy-item","children":["#","Action Coherence"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","VLA Models",{"className":"page__taxonomy-item","children":["#","VLA Models"]}],["$","span","Guidance",{"className":"page__taxonomy-item","children":["#","Guidance"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Imitation Learning",{"className":"page__taxonomy-item","children":["#","Imitation Learning"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Self-Attention",{"className":"page__taxonomy-item","children":["#","Self-Attention"]}]]}]]}]]}],["$","article","2025-10-28-A-Survey-of-Data-Agents-Emerging-Paradigm-or-Overstated-Hype",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-28-A-Survey-of-Data-Agents-Emerging-Paradigm-or-Overstated-Hype/","children":"[논문리뷰] A Survey of Data Agents: Emerging Paradigm or Overstated Hype?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Boyan Li이 [arXiv]에 게시한 'A Survey of Data Agents: Emerging Paradigm or Overstated Hype?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-28 13:07:54+0900","children":"2025년 10월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Data Agents",{"className":"page__taxonomy-item","children":["#","Data Agents"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Autonomy Levels",{"className":"page__taxonomy-item","children":["#","Autonomy Levels"]}],["$","span","Hierarchical Taxonomy",{"className":"page__taxonomy-item","children":["#","Hierarchical Taxonomy"]}],["$","span","SAE J3016",{"className":"page__taxonomy-item","children":["#","SAE J3016"]}],["$","span","Data Management",{"className":"page__taxonomy-item","children":["#","Data Management"]}],["$","span","Data Preparation",{"className":"page__taxonomy-item","children":["#","Data Preparation"]}],["$","span","Data Analysis",{"className":"page__taxonomy-item","children":["#","Data Analysis"]}],["$","span","Autonomous Orchestration",{"className":"page__taxonomy-item","children":["#","Autonomous Orchestration"]}]]}]]}]]}],["$","article","2025-10-27-WorldGrow-Generating-Infinite-3D-World",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-27-WorldGrow-Generating-Infinite-3D-World/","children":"[논문리뷰] WorldGrow: Generating Infinite 3D World"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jia Lu이 [arXiv]에 게시한 'WorldGrow: Generating Infinite 3D World' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-27 13:07:36+0900","children":"2025년 10월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D World Generation",{"className":"page__taxonomy-item","children":["#","3D World Generation"]}],["$","span","Infinite Scene Synthesis",{"className":"page__taxonomy-item","children":["#","Infinite Scene Synthesis"]}],["$","span","Block-wise Generation",{"className":"page__taxonomy-item","children":["#","Block-wise Generation"]}],["$","span","Coarse-to-Fine",{"className":"page__taxonomy-item","children":["#","Coarse-to-Fine"]}],["$","span","3D Inpainting",{"className":"page__taxonomy-item","children":["#","3D Inpainting"]}],["$","span","Structured Latent Representation",{"className":"page__taxonomy-item","children":["#","Structured Latent Representation"]}],["$","span","Virtual Environments",{"className":"page__taxonomy-item","children":["#","Virtual Environments"]}],["$","span","World Models",{"className":"page__taxonomy-item","children":["#","World Models"]}]]}]]}]]}],["$","article","2025-10-27-Visual-Diffusion-Models-are-Geometric-Solvers",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-27-Visual-Diffusion-Models-are-Geometric-Solvers/","children":"[논문리뷰] Visual Diffusion Models are Geometric Solvers"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Or Patashnik이 [arXiv]에 게시한 'Visual Diffusion Models are Geometric Solvers' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-27 13:07:36+0900","children":"2025년 10월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Geometric Problem Solving",{"className":"page__taxonomy-item","children":["#","Geometric Problem Solving"]}],["$","span","Inscribed Square Problem",{"className":"page__taxonomy-item","children":["#","Inscribed Square Problem"]}],["$","span","Steiner Tree Problem",{"className":"page__taxonomy-item","children":["#","Steiner Tree Problem"]}],["$","span","Maximum Area Polygonization",{"className":"page__taxonomy-item","children":["#","Maximum Area Polygonization"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Pixel Space",{"className":"page__taxonomy-item","children":["#","Pixel Space"]}]]}]]}]]}],["$","article","2025-10-27-Video-As-Prompt-Unified-Semantic-Control-for-Video-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-27-Video-As-Prompt-Unified-Semantic-Control-for-Video-Generation/","children":"[논문리뷰] Video-As-Prompt: Unified Semantic Control for Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Video-As-Prompt: Unified Semantic Control for Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-27 13:07:36+0900","children":"2025년 10월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Semantic Control",{"className":"page__taxonomy-item","children":["#","Semantic Control"]}],["$","span","Diffusion Transformers",{"className":"page__taxonomy-item","children":["#","Diffusion Transformers"]}],["$","span","In-Context Learning",{"className":"page__taxonomy-item","children":["#","In-Context Learning"]}],["$","span","Mixture-of-Transformers",{"className":"page__taxonomy-item","children":["#","Mixture-of-Transformers"]}],["$","span","Video-As-Prompt",{"className":"page__taxonomy-item","children":["#","Video-As-Prompt"]}],["$","span","Controllable Generation",{"className":"page__taxonomy-item","children":["#","Controllable Generation"]}],["$","span","Large-scale Dataset",{"className":"page__taxonomy-item","children":["#","Large-scale Dataset"]}]]}]]}]]}],["$","article","2025-10-27-UI-Ins-Enhancing-GUI-Grounding-with-Multi-Perspective-Instruction-as-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-27-UI-Ins-Enhancing-GUI-Grounding-with-Multi-Perspective-Instruction-as-Reasoning/","children":"[논문리뷰] UI-Ins: Enhancing GUI Grounding with Multi-Perspective Instruction-as-Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'UI-Ins: Enhancing GUI Grounding with Multi-Perspective Instruction-as-Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-27 13:07:36+0900","children":"2025년 10월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","GUI Grounding",{"className":"page__taxonomy-item","children":["#","GUI Grounding"]}],["$","span","Natural Language Instructions",{"className":"page__taxonomy-item","children":["#","Natural Language Instructions"]}],["$","span","Multi-Perspective Reasoning",{"className":"page__taxonomy-item","children":["#","Multi-Perspective Reasoning"]}],["$","span","Supervised Fine-Tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning (SFT)"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Policy Collapse Mitigation",{"className":"page__taxonomy-item","children":["#","Policy Collapse Mitigation"]}],["$","span","GUI Agents",{"className":"page__taxonomy-item","children":["#","GUI Agents"]}]]}]]}]]}],["$","article","2025-10-27-Taming-Modality-Entanglement-in-Continual-Audio-Visual-Segmentation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-27-Taming-Modality-Entanglement-in-Continual-Audio-Visual-Segmentation/","children":"[논문리뷰] Taming Modality Entanglement in Continual Audio-Visual Segmentation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhaojin Fu이 [arXiv]에 게시한 'Taming Modality Entanglement in Continual Audio-Visual Segmentation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-27 13:07:36+0900","children":"2025년 10월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Continual Learning",{"className":"page__taxonomy-item","children":["#","Continual Learning"]}],["$","span","Audio-Visual Segmentation",{"className":"page__taxonomy-item","children":["#","Audio-Visual Segmentation"]}],["$","span","Modality Entanglement",{"className":"page__taxonomy-item","children":["#","Modality Entanglement"]}],["$","span","Semantic Drift",{"className":"page__taxonomy-item","children":["#","Semantic Drift"]}],["$","span","Co-occurrence Confusion",{"className":"page__taxonomy-item","children":["#","Co-occurrence Confusion"]}],["$","span","Rehearsal Strategy",{"className":"page__taxonomy-item","children":["#","Rehearsal Strategy"]}],["$","span","Sample Selection",{"className":"page__taxonomy-item","children":["#","Sample Selection"]}]]}]]}]]}],["$","article","2025-10-27-Stabilizing-MoE-Reinforcement-Learning-by-Aligning-Training-and-Inference-Routers",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-27-Stabilizing-MoE-Reinforcement-Learning-by-Aligning-Training-and-Inference-Routers/","children":"[논문리뷰] Stabilizing MoE Reinforcement Learning by Aligning Training and Inference Routers"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Stabilizing MoE Reinforcement Learning by Aligning Training and Inference Routers' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-27 13:07:36+0900","children":"2025년 10월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","MoE",{"className":"page__taxonomy-item","children":["#","MoE"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Training Stability",{"className":"page__taxonomy-item","children":["#","Training Stability"]}],["$","span","Routing",{"className":"page__taxonomy-item","children":["#","Routing"]}],["$","span","Policy Alignment",{"className":"page__taxonomy-item","children":["#","Policy Alignment"]}],["$","span","Rollout Routing Replay",{"className":"page__taxonomy-item","children":["#","Rollout Routing Replay"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}]]}]]}]]}],["$","article","2025-10-27-Sparser-Block-Sparse-Attention-via-Token-Permutation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-27-Sparser-Block-Sparse-Attention-via-Token-Permutation/","children":"[논문리뷰] Sparser Block-Sparse Attention via Token Permutation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Sparser Block-Sparse Attention via Token Permutation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-27 13:07:36+0900","children":"2025년 10월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Self-Attention",{"className":"page__taxonomy-item","children":["#","Self-Attention"]}],["$","span","Block-Sparse Attention",{"className":"page__taxonomy-item","children":["#","Block-Sparse Attention"]}],["$","span","Token Permutation",{"className":"page__taxonomy-item","children":["#","Token Permutation"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}],["$","span","Prefilling",{"className":"page__taxonomy-item","children":["#","Prefilling"]}],["$","span","Long Context",{"className":"page__taxonomy-item","children":["#","Long Context"]}],["$","span","Causal Attention",{"className":"page__taxonomy-item","children":["#","Causal Attention"]}]]}]]}]]}],["$","article","2025-10-27-Soft-Instruction-De-escalation-Defense",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-27-Soft-Instruction-De-escalation-Defense/","children":"[논문리뷰] Soft Instruction De-escalation Defense"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Soft Instruction De-escalation Defense' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-27 13:07:36+0900","children":"2025년 10월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Prompt Injection",{"className":"page__taxonomy-item","children":["#","Prompt Injection"]}],["$","span","LLM Security",{"className":"page__taxonomy-item","children":["#","LLM Security"]}],["$","span","Agentic Systems",{"className":"page__taxonomy-item","children":["#","Agentic Systems"]}],["$","span","Iterative Sanitization",{"className":"page__taxonomy-item","children":["#","Iterative Sanitization"]}],["$","span","Instruction Control",{"className":"page__taxonomy-item","children":["#","Instruction Control"]}],["$","span","Adversarial Robustness",{"className":"page__taxonomy-item","children":["#","Adversarial Robustness"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}]]}]]}]]}],["$","article","2025-10-27-Sample-By-Step-Optimize-By-Chunk-Chunk-Level-GRPO-For-Text-to-Image-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-27-Sample-By-Step-Optimize-By-Chunk-Chunk-Level-GRPO-For-Text-to-Image-Generation/","children":"[논문리뷰] Sample By Step, Optimize By Chunk: Chunk-Level GRPO For Text-to-Image Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Sample By Step, Optimize By Chunk: Chunk-Level GRPO For Text-to-Image Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-27 13:07:36+0900","children":"2025년 10월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","GRPO",{"className":"page__taxonomy-item","children":["#","GRPO"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Chunk-level Optimization",{"className":"page__taxonomy-item","children":["#","Chunk-level Optimization"]}],["$","span","Temporal Dynamics",{"className":"page__taxonomy-item","children":["#","Temporal Dynamics"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}]]}]]}]]}],["$","article","2025-10-27-Reasoning-with-Sampling-Your-Base-Model-is-Smarter-Than-You-Think",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-27-Reasoning-with-Sampling-Your-Base-Model-is-Smarter-Than-You-Think/","children":"[논문리뷰] Reasoning with Sampling: Your Base Model is Smarter Than You Think"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Reasoning with Sampling: Your Base Model is Smarter Than You Think' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-27 13:07:36+0900","children":"2025년 10월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","MCMC",{"className":"page__taxonomy-item","children":["#","MCMC"]}],["$","span","Sampling",{"className":"page__taxonomy-item","children":["#","Sampling"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Distribution Sharpening",{"className":"page__taxonomy-item","children":["#","Distribution Sharpening"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Inference-time Optimization",{"className":"page__taxonomy-item","children":["#","Inference-time Optimization"]}],["$","span","Training-free",{"className":"page__taxonomy-item","children":["#","Training-free"]}]]}]]}]]}],["$","article","2025-10-27-RECALL-REpresentation-aligned-Catastrophic-forgetting-ALLeviation-via-Hierarchical-Model-Merging",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-27-RECALL-REpresentation-aligned-Catastrophic-forgetting-ALLeviation-via-Hierarchical-Model-Merging/","children":"[논문리뷰] RECALL: REpresentation-aligned Catastrophic-forgetting ALLeviation via Hierarchical Model Merging"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'RECALL: REpresentation-aligned Catastrophic-forgetting ALLeviation via Hierarchical Model Merging' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-27 13:07:36+0900","children":"2025년 10월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Catastrophic Forgetting",{"className":"page__taxonomy-item","children":["#","Catastrophic Forgetting"]}],["$","span","Continual Learning",{"className":"page__taxonomy-item","children":["#","Continual Learning"]}],["$","span","Model Merging",{"className":"page__taxonomy-item","children":["#","Model Merging"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Representation Learning",{"className":"page__taxonomy-item","children":["#","Representation Learning"]}],["$","span","Data-free Learning",{"className":"page__taxonomy-item","children":["#","Data-free Learning"]}],["$","span","Hierarchical Parameter Fusion",{"className":"page__taxonomy-item","children":["#","Hierarchical Parameter Fusion"]}]]}]]}]]}],["$","article","2025-10-27-RAPO-Cross-Stage-Prompt-Optimization-for-Text-to-Video-Generation-via-Data-Alignment-and-Test-Time-Scaling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-27-RAPO-Cross-Stage-Prompt-Optimization-for-Text-to-Video-Generation-via-Data-Alignment-and-Test-Time-Scaling/","children":"[논문리뷰] RAPO++: Cross-Stage Prompt Optimization for Text-to-Video Generation via Data Alignment and Test-Time Scaling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'RAPO++: Cross-Stage Prompt Optimization for Text-to-Video Generation via Data Alignment and Test-Time Scaling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-27 13:07:36+0900","children":"2025년 10월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Video Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Video Generation"]}],["$","span","Prompt Optimization",{"className":"page__taxonomy-item","children":["#","Prompt Optimization"]}],["$","span","Large Language Models (LLM)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLM)"]}],["$","span","Test-Time Scaling",{"className":"page__taxonomy-item","children":["#","Test-Time Scaling"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Data Alignment",{"className":"page__taxonomy-item","children":["#","Data Alignment"]}]]}]]}]]}],["$","article","2025-10-27-PhysWorld-From-Real-Videos-to-World-Models-of-Deformable-Objects-via-Physics-Aware-Demonstration-Synthesis",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-27-PhysWorld-From-Real-Videos-to-World-Models-of-Deformable-Objects-via-Physics-Aware-Demonstration-Synthesis/","children":"[논문리뷰] PhysWorld: From Real Videos to World Models of Deformable Objects via Physics-Aware Demonstration Synthesis"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hui Li이 [arXiv]에 게시한 'PhysWorld: From Real Videos to World Models of Deformable Objects via Physics-Aware Demonstration Synthesis' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-27 13:07:36+0900","children":"2025년 10월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","World Models",{"className":"page__taxonomy-item","children":["#","World Models"]}],["$","span","Deformable Objects",{"className":"page__taxonomy-item","children":["#","Deformable Objects"]}],["$","span","Physics Simulation",{"className":"page__taxonomy-item","children":["#","Physics Simulation"]}],["$","span","GNN",{"className":"page__taxonomy-item","children":["#","GNN"]}],["$","span","Digital Twin",{"className":"page__taxonomy-item","children":["#","Digital Twin"]}],["$","span","Data Synthesis",{"className":"page__taxonomy-item","children":["#","Data Synthesis"]}],["$","span","Real-to-Sim",{"className":"page__taxonomy-item","children":["#","Real-to-Sim"]}],["$","span","Physics-Aware Learning",{"className":"page__taxonomy-item","children":["#","Physics-Aware Learning"]}]]}]]}]]}],["$","article","2025-10-27-PhysVLM-AVR-Active-Visual-Reasoning-for-Multimodal-Large-Language-Models-in-Physical-Environments",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-27-PhysVLM-AVR-Active-Visual-Reasoning-for-Multimodal-Large-Language-Models-in-Physical-Environments/","children":"[논문리뷰] PhysVLM-AVR: Active Visual Reasoning for Multimodal Large Language Models in Physical Environments"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chaoyang Zhao이 [arXiv]에 게시한 'PhysVLM-AVR: Active Visual Reasoning for Multimodal Large Language Models in Physical Environments' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-27 13:07:36+0900","children":"2025년 10월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Active Visual Reasoning",{"className":"page__taxonomy-item","children":["#","Active Visual Reasoning"]}],["$","span","MLLM",{"className":"page__taxonomy-item","children":["#","MLLM"]}],["$","span","Physical Environments",{"className":"page__taxonomy-item","children":["#","Physical Environments"]}],["$","span","Partially Observable",{"className":"page__taxonomy-item","children":["#","Partially Observable"]}],["$","span","Markov Decision Process",{"className":"page__taxonomy-item","children":["#","Markov Decision Process"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","CLEVR-AVR",{"className":"page__taxonomy-item","children":["#","CLEVR-AVR"]}]]}]]}]]}],["$","article","2025-10-27-Model-Merging-with-Functional-Dual-Anchors",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-27-Model-Merging-with-Functional-Dual-Anchors/","children":"[논문리뷰] Model Merging with Functional Dual Anchors"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Model Merging with Functional Dual Anchors' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-27 13:07:36+0900","children":"2025년 10월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Model Merging",{"className":"page__taxonomy-item","children":["#","Model Merging"]}],["$","span","Functional Dual Anchors",{"className":"page__taxonomy-item","children":["#","Functional Dual Anchors"]}],["$","span","Input-Representation Space",{"className":"page__taxonomy-item","children":["#","Input-Representation Space"]}],["$","span","Task Vectors",{"className":"page__taxonomy-item","children":["#","Task Vectors"]}],["$","span","Knowledge Integration",{"className":"page__taxonomy-item","children":["#","Knowledge Integration"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Gradient Matching",{"className":"page__taxonomy-item","children":["#","Gradient Matching"]}],["$","span","Post-training Strategy",{"className":"page__taxonomy-item","children":["#","Post-training Strategy"]}]]}]]}]]}],["$","article","2025-10-27-Map-the-Flow-Revealing-Hidden-Pathways-of-Information-in-VideoLLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-27-Map-the-Flow-Revealing-Hidden-Pathways-of-Information-in-VideoLLMs/","children":"[논문리뷰] Map the Flow: Revealing Hidden Pathways of Information in VideoLLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Bohyung Han이 [arXiv]에 게시한 'Map the Flow: Revealing Hidden Pathways of Information in VideoLLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-27 13:07:36+0900","children":"2025년 10월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Large Language Models",{"className":"page__taxonomy-item","children":["#","Video Large Language Models"]}],["$","span","VideoQA",{"className":"page__taxonomy-item","children":["#","VideoQA"]}],["$","span","Mechanistic Interpretability",{"className":"page__taxonomy-item","children":["#","Mechanistic Interpretability"]}],["$","span","Attention Knockout",{"className":"page__taxonomy-item","children":["#","Attention Knockout"]}],["$","span","Temporal Reasoning",{"className":"page__taxonomy-item","children":["#","Temporal Reasoning"]}],["$","span","Information Flow",{"className":"page__taxonomy-item","children":["#","Information Flow"]}],["$","span","Model Interpretability",{"className":"page__taxonomy-item","children":["#","Model Interpretability"]}],["$","span","Logit Lens",{"className":"page__taxonomy-item","children":["#","Logit Lens"]}]]}]]}]]}],["$","article","2025-10-27-From-Denoising-to-Refining-A-Corrective-Framework-for-Vision-Language-Diffusion-Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-27-From-Denoising-to-Refining-A-Corrective-Framework-for-Vision-Language-Diffusion-Model/","children":"[논문리뷰] From Denoising to Refining: A Corrective Framework for Vision-Language Diffusion Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'From Denoising to Refining: A Corrective Framework for Vision-Language Diffusion Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-27 13:07:36+0900","children":"2025년 10월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Discrete Diffusion Models",{"className":"page__taxonomy-item","children":["#","Discrete Diffusion Models"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Error Cascades",{"className":"page__taxonomy-item","children":["#","Error Cascades"]}],["$","span","Self-Correction",{"className":"page__taxonomy-item","children":["#","Self-Correction"]}],["$","span","Refinement Framework",{"className":"page__taxonomy-item","children":["#","Refinement Framework"]}],["$","span","Parallel Generation",{"className":"page__taxonomy-item","children":["#","Parallel Generation"]}],["$","span","Image Captioning",{"className":"page__taxonomy-item","children":["#","Image Captioning"]}],["$","span","Hallucination Mitigation",{"className":"page__taxonomy-item","children":["#","Hallucination Mitigation"]}]]}]]}]]}],["$","article","2025-10-27-Foley-Control-Aligning-a-Frozen-Latent-Text-to-Audio-Model-to-Video",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-27-Foley-Control-Aligning-a-Frozen-Latent-Text-to-Audio-Model-to-Video/","children":"[논문리뷰] Foley Control: Aligning a Frozen Latent Text-to-Audio Model to Video"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Foley Control: Aligning a Frozen Latent Text-to-Audio Model to Video' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-27 13:07:36+0900","children":"2025년 10월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Audio",{"className":"page__taxonomy-item","children":["#","Text-to-Audio"]}],["$","span","Video-to-Audio",{"className":"page__taxonomy-item","children":["#","Video-to-Audio"]}],["$","span","Foley Synthesis",{"className":"page__taxonomy-item","children":["#","Foley Synthesis"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Cross-Attention",{"className":"page__taxonomy-item","children":["#","Cross-Attention"]}],["$","span","Frozen Backbones",{"className":"page__taxonomy-item","children":["#","Frozen Backbones"]}],["$","span","Video Embeddings",{"className":"page__taxonomy-item","children":["#","Video Embeddings"]}],["$","span","Rotary Position Embeddings",{"className":"page__taxonomy-item","children":["#","Rotary Position Embeddings"]}]]}]]}]]}],["$","article","2025-10-27-Document-Understanding-Measurement-and-Manipulation-Using-Category-Theory",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-27-Document-Understanding-Measurement-and-Manipulation-Using-Category-Theory/","children":"[논문리뷰] Document Understanding, Measurement, and Manipulation Using Category Theory"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Document Understanding, Measurement, and Manipulation Using Category Theory' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-27 13:07:36+0900","children":"2025년 10월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Category Theory",{"className":"page__taxonomy-item","children":["#","Category Theory"]}],["$","span","Document Understanding",{"className":"page__taxonomy-item","children":["#","Document Understanding"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Information Theory",{"className":"page__taxonomy-item","children":["#","Information Theory"]}],["$","span","Rhetorical Structure Theory",{"className":"page__taxonomy-item","children":["#","Rhetorical Structure Theory"]}],["$","span","Document Summarization",{"className":"page__taxonomy-item","children":["#","Document Summarization"]}],["$","span","Rate Distortion Analysis",{"className":"page__taxonomy-item","children":["#","Rate Distortion Analysis"]}],["$","span","Self-supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-supervised Learning"]}]]}]]}]]}],["$","article","2025-10-27-DeepAgent-A-General-Reasoning-Agent-with-Scalable-Toolsets",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-27-DeepAgent-A-General-Reasoning-Agent-with-Scalable-Toolsets/","children":"[논문리뷰] DeepAgent: A General Reasoning Agent with Scalable Toolsets"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiajie Jin이 [arXiv]에 게시한 'DeepAgent: A General Reasoning Agent with Scalable Toolsets' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-27 13:07:36+0900","children":"2025년 10월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Autonomous Agents",{"className":"page__taxonomy-item","children":["#","Autonomous Agents"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Memory Management",{"className":"page__taxonomy-item","children":["#","Memory Management"]}],["$","span","Tool Retrieval",{"className":"page__taxonomy-item","children":["#","Tool Retrieval"]}],["$","span","Agentic Reasoning",{"className":"page__taxonomy-item","children":["#","Agentic Reasoning"]}]]}]]}]]}],["$","article","2025-10-27-AstaBench-Rigorous-Benchmarking-of-AI-Agents-with-a-Scientific-Research-Suite",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-27-AstaBench-Rigorous-Benchmarking-of-AI-Agents-with-a-Scientific-Research-Suite/","children":"[논문리뷰] AstaBench: Rigorous Benchmarking of AI Agents with a Scientific Research Suite"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Bhavana Dalvi이 [arXiv]에 게시한 'AstaBench: Rigorous Benchmarking of AI Agents with a Scientific Research Suite' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-27 13:07:36+0900","children":"2025년 10월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Agents",{"className":"page__taxonomy-item","children":["#","AI Agents"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Scientific Research",{"className":"page__taxonomy-item","children":["#","Scientific Research"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Reproducibility",{"className":"page__taxonomy-item","children":["#","Reproducibility"]}],["$","span","Cost-Aware Evaluation",{"className":"page__taxonomy-item","children":["#","Cost-Aware Evaluation"]}]]}]]}]]}],["$","article","2025-10-27-Are-Large-Reasoning-Models-Good-Translation-Evaluators-Analysis-and-Performance-Boost",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-27-Are-Large-Reasoning-Models-Good-Translation-Evaluators-Analysis-and-Performance-Boost/","children":"[논문리뷰] Are Large Reasoning Models Good Translation Evaluators? Analysis and Performance Boost"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Min Yang이 [arXiv]에 게시한 'Are Large Reasoning Models Good Translation Evaluators? Analysis and Performance Boost' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-27 13:07:36+0900","children":"2025년 10월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Machine Translation Evaluation",{"className":"page__taxonomy-item","children":["#","Machine Translation Evaluation"]}],["$","span","Large Reasoning Models",{"className":"page__taxonomy-item","children":["#","Large Reasoning Models"]}],["$","span","LLM-as-a-judge",{"className":"page__taxonomy-item","children":["#","LLM-as-a-judge"]}],["$","span","MQM",{"className":"page__taxonomy-item","children":["#","MQM"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Thinking Calibration",{"className":"page__taxonomy-item","children":["#","Thinking Calibration"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}],["$","span","Meta-evaluation",{"className":"page__taxonomy-item","children":["#","Meta-evaluation"]}]]}]]}]]}],["$","article","2025-10-27-ARC-Encoder-learning-compressed-text-representations-for-large-language-models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-27-ARC-Encoder-learning-compressed-text-representations-for-large-language-models/","children":"[논문리뷰] ARC-Encoder: learning compressed text representations for large language models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'ARC-Encoder: learning compressed text representations for large language models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-27 13:07:36+0900","children":"2025년 10월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Context Compression",{"className":"page__taxonomy-item","children":["#","Context Compression"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Encoder-Decoder Architecture",{"className":"page__taxonomy-item","children":["#","Encoder-Decoder Architecture"]}],["$","span","Text Representation",{"className":"page__taxonomy-item","children":["#","Text Representation"]}],["$","span","In-Context Learning",{"className":"page__taxonomy-item","children":["#","In-Context Learning"]}],["$","span","Parameter Efficiency",{"className":"page__taxonomy-item","children":["#","Parameter Efficiency"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}]]}]]}]]}],["$","article","2025-10-27-ALICE-LRI-A-General-Method-for-Lossless-Range-Image-Generation-for-Spinning-LiDAR-Sensors-without-Calibration-Metadata",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-27-ALICE-LRI-A-General-Method-for-Lossless-Range-Image-Generation-for-Spinning-LiDAR-Sensors-without-Calibration-Metadata/","children":"[논문리뷰] ALICE-LRI: A General Method for Lossless Range Image Generation for Spinning LiDAR Sensors without Calibration Metadata"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"José C. Cabaleiro이 [arXiv]에 게시한 'ALICE-LRI: A General Method for Lossless Range Image Generation for Spinning LiDAR Sensors without Calibration Metadata' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-27 13:07:36+0900","children":"2025년 10월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LiDAR",{"className":"page__taxonomy-item","children":["#","LiDAR"]}],["$","span","Range Image",{"className":"page__taxonomy-item","children":["#","Range Image"]}],["$","span","Lossless Projection",{"className":"page__taxonomy-item","children":["#","Lossless Projection"]}],["$","span","Sensor Calibration",{"className":"page__taxonomy-item","children":["#","Sensor Calibration"]}],["$","span","Intrinsic Parameters",{"className":"page__taxonomy-item","children":["#","Intrinsic Parameters"]}],["$","span","Point Cloud Reconstruction",{"className":"page__taxonomy-item","children":["#","Point Cloud Reconstruction"]}],["$","span","Hough Transform",{"className":"page__taxonomy-item","children":["#","Hough Transform"]}],["$","span","Weighted Least Squares",{"className":"page__taxonomy-item","children":["#","Weighted Least Squares"]}]]}]]}]]}],["$","article","2025-10-27-A-Definition-of-AGI",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-27-A-Definition-of-AGI/","children":"[논문리뷰] A Definition of AGI"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yarin Gal이 [arXiv]에 게시한 'A Definition of AGI' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-27 13:07:36+0900","children":"2025년 10월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AGI Definition",{"className":"page__taxonomy-item","children":["#","AGI Definition"]}],["$","span","Cognitive Assessment",{"className":"page__taxonomy-item","children":["#","Cognitive Assessment"]}],["$","span","Cattell-Horn-Carroll Theory",{"className":"page__taxonomy-item","children":["#","Cattell-Horn-Carroll Theory"]}],["$","span","AI Evaluation",{"className":"page__taxonomy-item","children":["#","AI Evaluation"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Cognitive Domains",{"className":"page__taxonomy-item","children":["#","Cognitive Domains"]}],["$","span","Psychometrics",{"className":"page__taxonomy-item","children":["#","Psychometrics"]}]]}]]}]]}],["$","article","2025-10-24-Thought-Communication-in-Multiagent-Collaboration",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-Thought-Communication-in-Multiagent-Collaboration/","children":"[논문리뷰] Thought Communication in Multiagent Collaboration"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Mingze Gao이 [arXiv]에 게시한 'Thought Communication in Multiagent Collaboration' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multiagent Systems",{"className":"page__taxonomy-item","children":["#","Multiagent Systems"]}],["$","span","LLM Communication",{"className":"page__taxonomy-item","children":["#","LLM Communication"]}],["$","span","Latent Variable Models",{"className":"page__taxonomy-item","children":["#","Latent Variable Models"]}],["$","span","Identifiability Theory",{"className":"page__taxonomy-item","children":["#","Identifiability Theory"]}],["$","span","Thought Communication",{"className":"page__taxonomy-item","children":["#","Thought Communication"]}],["$","span","Sparse Autoencoder",{"className":"page__taxonomy-item","children":["#","Sparse Autoencoder"]}],["$","span","Prefix Tuning",{"className":"page__taxonomy-item","children":["#","Prefix Tuning"]}]]}]]}]]}],["$","article","2025-10-24-The-Massive-Legal-Embedding-Benchmark-MLEB",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-The-Massive-Legal-Embedding-Benchmark-MLEB/","children":"[논문리뷰] The Massive Legal Embedding Benchmark (MLEB)"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'The Massive Legal Embedding Benchmark (MLEB)' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Legal Information Retrieval",{"className":"page__taxonomy-item","children":["#","Legal Information Retrieval"]}],["$","span","Embedding Models",{"className":"page__taxonomy-item","children":["#","Embedding Models"]}],["$","span","Benchmark Dataset",{"className":"page__taxonomy-item","children":["#","Benchmark Dataset"]}],["$","span","Natural Language Processing",{"className":"page__taxonomy-item","children":["#","Natural Language Processing"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","Jurisdictional Diversity",{"className":"page__taxonomy-item","children":["#","Jurisdictional Diversity"]}],["$","span","Legal Tech",{"className":"page__taxonomy-item","children":["#","Legal Tech"]}]]}]]}]]}],["$","article","2025-10-24-Seed3D-1-0-From-Images-to-High-Fidelity-Simulation-Ready-3D-Assets",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-Seed3D-1-0-From-Images-to-High-Fidelity-Simulation-Ready-3D-Assets/","children":"[논문리뷰] Seed3D 1.0: From Images to High-Fidelity Simulation-Ready 3D Assets"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Seed3D 1.0: From Images to High-Fidelity Simulation-Ready 3D Assets' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Asset Generation",{"className":"page__taxonomy-item","children":["#","3D Asset Generation"]}],["$","span","Simulation-Ready Assets",{"className":"page__taxonomy-item","children":["#","Simulation-Ready Assets"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Physically Based Rendering (PBR)",{"className":"page__taxonomy-item","children":["#","Physically Based Rendering (PBR)"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Robotic Simulation",{"className":"page__taxonomy-item","children":["#","Robotic Simulation"]}],["$","span","Image-to-3D",{"className":"page__taxonomy-item","children":["#","Image-to-3D"]}],["$","span","Foundation Model",{"className":"page__taxonomy-item","children":["#","Foundation Model"]}]]}]]}]]}],["$","article","2025-10-24-Search-Self-play-Pushing-the-Frontier-of-Agent-Capability-without-Supervision",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-Search-Self-play-Pushing-the-Frontier-of-Agent-Capability-without-Supervision/","children":"[논문리뷰] Search Self-play: Pushing the Frontier of Agent Capability without Supervision"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Search Self-play: Pushing the Frontier of Agent Capability without Supervision' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Self-play",{"className":"page__taxonomy-item","children":["#","Self-play"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Search Agents",{"className":"page__taxonomy-item","children":["#","Search Agents"]}],["$","span","Supervision-Free Training",{"className":"page__taxonomy-item","children":["#","Supervision-Free Training"]}],["$","span","Retrieval-Augmented Generation (RAG)",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation (RAG)"]}],["$","span","Task Generation",{"className":"page__taxonomy-item","children":["#","Task Generation"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}]]}]]}]]}],["$","article","2025-10-24-SAKE-Towards-Editing-Auditory-Attribute-Knowledge-of-Large-Audio-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-SAKE-Towards-Editing-Auditory-Attribute-Knowledge-of-Large-Audio-Language-Models/","children":"[논문리뷰] SAKE: Towards Editing Auditory Attribute Knowledge of Large Audio-Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'SAKE: Towards Editing Auditory Attribute Knowledge of Large Audio-Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Knowledge Editing",{"className":"page__taxonomy-item","children":["#","Knowledge Editing"]}],["$","span","Audio-Language Models",{"className":"page__taxonomy-item","children":["#","Audio-Language Models"]}],["$","span","Auditory Attributes",{"className":"page__taxonomy-item","children":["#","Auditory Attributes"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Reliability",{"className":"page__taxonomy-item","children":["#","Reliability"]}],["$","span","Generality",{"className":"page__taxonomy-item","children":["#","Generality"]}],["$","span","Locality",{"className":"page__taxonomy-item","children":["#","Locality"]}],["$","span","Portability",{"className":"page__taxonomy-item","children":["#","Portability"]}]]}]]}]]}],["$","article","2025-10-24-Open-o3-Video-Grounded-Video-Reasoning-with-Explicit-Spatio-Temporal-Evidence",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-Open-o3-Video-Grounded-Video-Reasoning-with-Explicit-Spatio-Temporal-Evidence/","children":"[논문리뷰] Open-o3 Video: Grounded Video Reasoning with Explicit Spatio-Temporal Evidence"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Open-o3 Video: Grounded Video Reasoning with Explicit Spatio-Temporal Evidence' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Reasoning",{"className":"page__taxonomy-item","children":["#","Video Reasoning"]}],["$","span","Spatio-Temporal Grounding",{"className":"page__taxonomy-item","children":["#","Spatio-Temporal Grounding"]}],["$","span","Large Multimodal Models",{"className":"page__taxonomy-item","children":["#","Large Multimodal Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Visual Evidence",{"className":"page__taxonomy-item","children":["#","Visual Evidence"]}],["$","span","Dataset Curation",{"className":"page__taxonomy-item","children":["#","Dataset Curation"]}]]}]]}]]}],["$","article","2025-10-24-Loopholing-Discrete-Diffusion-Deterministic-Bypass-of-the-Sampling-Wall",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-Loopholing-Discrete-Diffusion-Deterministic-Bypass-of-the-Sampling-Wall/","children":"[논문리뷰] Loopholing Discrete Diffusion: Deterministic Bypass of the Sampling Wall"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Sungjin Ahn이 [arXiv]에 게시한 'Loopholing Discrete Diffusion: Deterministic Bypass of the Sampling Wall' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Discrete Diffusion Models",{"className":"page__taxonomy-item","children":["#","Discrete Diffusion Models"]}],["$","span","Sampling Wall",{"className":"page__taxonomy-item","children":["#","Sampling Wall"]}],["$","span","Loopholing",{"className":"page__taxonomy-item","children":["#","Loopholing"]}],["$","span","Self-Conditioning",{"className":"page__taxonomy-item","children":["#","Self-Conditioning"]}],["$","span","Non-Autoregressive Generation",{"className":"page__taxonomy-item","children":["#","Non-Autoregressive Generation"]}],["$","span","Text Generation",{"className":"page__taxonomy-item","children":["#","Text Generation"]}],["$","span","Language Modeling",{"className":"page__taxonomy-item","children":["#","Language Modeling"]}],["$","span","Reasoning Tasks",{"className":"page__taxonomy-item","children":["#","Reasoning Tasks"]}]]}]]}]]}],["$","article","2025-10-24-LayerComposer-Interactive-Personalized-T2I-via-Spatially-Aware-Layered-Canvas",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-LayerComposer-Interactive-Personalized-T2I-via-Spatially-Aware-Layered-Canvas/","children":"[논문리뷰] LayerComposer: Interactive Personalized T2I via Spatially-Aware Layered Canvas"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'LayerComposer: Interactive Personalized T2I via Spatially-Aware Layered Canvas' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Personalization",{"className":"page__taxonomy-item","children":["#","Personalization"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Interactive Control",{"className":"page__taxonomy-item","children":["#","Interactive Control"]}],["$","span","Multi-Subject Composition",{"className":"page__taxonomy-item","children":["#","Multi-Subject Composition"]}],["$","span","Layered Canvas",{"className":"page__taxonomy-item","children":["#","Layered Canvas"]}],["$","span","Spatial Control",{"className":"page__taxonomy-item","children":["#","Spatial Control"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}]]}]]}]]}],["$","article","2025-10-24-Investigating-Safety-Vulnerabilities-of-Large-Audio-Language-Models-Under-Speaker-Emotional-Variations",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-Investigating-Safety-Vulnerabilities-of-Large-Audio-Language-Models-Under-Speaker-Emotional-Variations/","children":"[논문리뷰] Investigating Safety Vulnerabilities of Large Audio-Language Models Under Speaker Emotional Variations"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Investigating Safety Vulnerabilities of Large Audio-Language Models Under Speaker Emotional Variations' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LALM Safety",{"className":"page__taxonomy-item","children":["#","LALM Safety"]}],["$","span","Speaker Emotion",{"className":"page__taxonomy-item","children":["#","Speaker Emotion"]}],["$","span","Safety Alignment",{"className":"page__taxonomy-item","children":["#","Safety Alignment"]}],["$","span","Jailbreaking",{"className":"page__taxonomy-item","children":["#","Jailbreaking"]}],["$","span","Audio-Language Models",{"className":"page__taxonomy-item","children":["#","Audio-Language Models"]}],["$","span","Emotional Variation",{"className":"page__taxonomy-item","children":["#","Emotional Variation"]}],["$","span","Unsafe Rate",{"className":"page__taxonomy-item","children":["#","Unsafe Rate"]}],["$","span","Non-refusal Rate",{"className":"page__taxonomy-item","children":["#","Non-refusal Rate"]}]]}]]}]]}],["$","article","2025-10-24-ImpossibleBench-Measuring-LLMs-Propensity-of-Exploiting-Test-Cases",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-ImpossibleBench-Measuring-LLMs-Propensity-of-Exploiting-Test-Cases/","children":"[논문리뷰] ImpossibleBench: Measuring LLMs' Propensity of Exploiting Test Cases"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Nicholas Carlini이 [arXiv]에 게시한 'ImpossibleBench: Measuring LLMs' Propensity of Exploiting Test Cases' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Reward Hacking",{"className":"page__taxonomy-item","children":["#","Reward Hacking"]}],["$","span","Benchmark Reliability",{"className":"page__taxonomy-item","children":["#","Benchmark Reliability"]}],["$","span","Test Exploitation",{"className":"page__taxonomy-item","children":["#","Test Exploitation"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","LLM Safety",{"className":"page__taxonomy-item","children":["#","LLM Safety"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}]]}]]}]]}],["$","article","2025-10-24-Human-Agent-Collaborative-Paper-to-Page-Crafting-for-Under-0-1",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-Human-Agent-Collaborative-Paper-to-Page-Crafting-for-Under-0-1/","children":"[논문리뷰] Human-Agent Collaborative Paper-to-Page Crafting for Under $0.1"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Human-Agent Collaborative Paper-to-Page Crafting for Under $0.1' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Human-Agent Collaboration",{"className":"page__taxonomy-item","children":["#","Human-Agent Collaboration"]}],["$","span","Project Page Generation",{"className":"page__taxonomy-item","children":["#","Project Page Generation"]}],["$","span","Multi-Agent System",{"className":"page__taxonomy-item","children":["#","Multi-Agent System"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","VLM",{"className":"page__taxonomy-item","children":["#","VLM"]}],["$","span","Webpage Automation",{"className":"page__taxonomy-item","children":["#","Webpage Automation"]}],["$","span","PageBench",{"className":"page__taxonomy-item","children":["#","PageBench"]}],["$","span","Scientific Communication",{"className":"page__taxonomy-item","children":["#","Scientific Communication"]}],["$","span","Cost-Effective AI",{"className":"page__taxonomy-item","children":["#","Cost-Effective AI"]}]]}]]}]]}],["$","article","2025-10-24-HoloCine-Holistic-Generation-of-Cinematic-Multi-Shot-Long-Video-Narratives",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-HoloCine-Holistic-Generation-of-Cinematic-Multi-Shot-Long-Video-Narratives/","children":"[논문리뷰] HoloCine: Holistic Generation of Cinematic Multi-Shot Long Video Narratives"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'HoloCine: Holistic Generation of Cinematic Multi-Shot Long Video Narratives' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Video Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Video Generation"]}],["$","span","Multi-Shot Video",{"className":"page__taxonomy-item","children":["#","Multi-Shot Video"]}],["$","span","Narrative Coherence",{"className":"page__taxonomy-item","children":["#","Narrative Coherence"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Self-Attention",{"className":"page__taxonomy-item","children":["#","Self-Attention"]}],["$","span","Cinematic AI",{"className":"page__taxonomy-item","children":["#","Cinematic AI"]}],["$","span","Video Consistency",{"className":"page__taxonomy-item","children":["#","Video Consistency"]}],["$","span","Directorial Control",{"className":"page__taxonomy-item","children":["#","Directorial Control"]}]]}]]}]]}],["$","article","2025-10-24-From-Masks-to-Worlds-A-Hitchhikers-Guide-to-World-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-From-Masks-to-Worlds-A-Hitchhikers-Guide-to-World-Models/","children":"[논문리뷰] From Masks to Worlds: A Hitchhiker's Guide to World Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shufan Li이 [arXiv]에 게시한 'From Masks to Worlds: A Hitchhiker's Guide to World Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","World Models",{"className":"page__taxonomy-item","children":["#","World Models"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Masked Modeling",{"className":"page__taxonomy-item","children":["#","Masked Modeling"]}],["$","span","Interactive AI",{"className":"page__taxonomy-item","children":["#","Interactive AI"]}],["$","span","Memory Systems",{"className":"page__taxonomy-item","children":["#","Memory Systems"]}],["$","span","Autonomous Agents",{"className":"page__taxonomy-item","children":["#","Autonomous Agents"]}],["$","span","AI Roadmap",{"className":"page__taxonomy-item","children":["#","AI Roadmap"]}]]}]]}]]}],["$","article","2025-10-24-Every-Question-Has-Its-Own-Value-Reinforcement-Learning-with-Explicit-Human-Values",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-Every-Question-Has-Its-Own-Value-Reinforcement-Learning-with-Explicit-Human-Values/","children":"[논문리뷰] Every Question Has Its Own Value: Reinforcement Learning with Explicit Human Values"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Every Question Has Its Own Value: Reinforcement Learning with Explicit Human Values' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","LLM Alignment",{"className":"page__taxonomy-item","children":["#","LLM Alignment"]}],["$","span","Human Values",{"className":"page__taxonomy-item","children":["#","Human Values"]}],["$","span","Reward Shaping",{"className":"page__taxonomy-item","children":["#","Reward Shaping"]}],["$","span","Value-Weighted Reward",{"className":"page__taxonomy-item","children":["#","Value-Weighted Reward"]}],["$","span","Termination Policy",{"className":"page__taxonomy-item","children":["#","Termination Policy"]}],["$","span","RLVR",{"className":"page__taxonomy-item","children":["#","RLVR"]}]]}]]}]]}],["$","article","2025-10-24-Emergence-of-Linear-Truth-Encodings-in-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-Emergence-of-Linear-Truth-Encodings-in-Language-Models/","children":"[논문리뷰] Emergence of Linear Truth Encodings in Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Alberto Bietti이 [arXiv]에 게시한 'Emergence of Linear Truth Encodings in Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Language Models",{"className":"page__taxonomy-item","children":["#","Language Models"]}],["$","span","Truth Encoding",{"className":"page__taxonomy-item","children":["#","Truth Encoding"]}],["$","span","Linear Subspaces",{"className":"page__taxonomy-item","children":["#","Linear Subspaces"]}],["$","span","Mechanistic Interpretability",{"className":"page__taxonomy-item","children":["#","Mechanistic Interpretability"]}],["$","span","Transformer Models",{"className":"page__taxonomy-item","children":["#","Transformer Models"]}],["$","span","Learning Dynamics",{"className":"page__taxonomy-item","children":["#","Learning Dynamics"]}],["$","span","Truth Co-occurrence Hypothesis",{"className":"page__taxonomy-item","children":["#","Truth Co-occurrence Hypothesis"]}],["$","span","Hallucinations",{"className":"page__taxonomy-item","children":["#","Hallucinations"]}]]}]]}]]}],["$","article","2025-10-24-DyPE-Dynamic-Position-Extrapolation-for-Ultra-High-Resolution-Diffusion",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-DyPE-Dynamic-Position-Extrapolation-for-Ultra-High-Resolution-Diffusion/","children":"[논문리뷰] DyPE: Dynamic Position Extrapolation for Ultra High Resolution Diffusion"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DyPE: Dynamic Position Extrapolation for Ultra High Resolution Diffusion' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Positional Encoding",{"className":"page__taxonomy-item","children":["#","Positional Encoding"]}],["$","span","High-Resolution Image Generation",{"className":"page__taxonomy-item","children":["#","High-Resolution Image Generation"]}],["$","span","Extrapolation",{"className":"page__taxonomy-item","children":["#","Extrapolation"]}],["$","span","Dynamic Adaptation",{"className":"page__taxonomy-item","children":["#","Dynamic Adaptation"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}]]}]]}]]}],["$","article","2025-10-24-Diff-XYZ-A-Benchmark-for-Evaluating-Diff-Understanding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-Diff-XYZ-A-Benchmark-for-Evaluating-Diff-Understanding/","children":"[논문리뷰] Diff-XYZ: A Benchmark for Evaluating Diff Understanding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Diff-XYZ: A Benchmark for Evaluating Diff Understanding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diff Understanding",{"className":"page__taxonomy-item","children":["#","Diff Understanding"]}],["$","span","Code Diff",{"className":"page__taxonomy-item","children":["#","Code Diff"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Code Editing",{"className":"page__taxonomy-item","children":["#","Code Editing"]}],["$","span","Software Engineering",{"className":"page__taxonomy-item","children":["#","Software Engineering"]}],["$","span","Unified Diff Format",{"className":"page__taxonomy-item","children":["#","Unified Diff Format"]}],["$","span","Search-Replace",{"className":"page__taxonomy-item","children":["#","Search-Replace"]}]]}]]}]]}],["$","article","2025-10-24-Conan-Progressive-Learning-to-Reason-Like-a-Detective-over-Multi-Scale-Visual-Evidence",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-Conan-Progressive-Learning-to-Reason-Like-a-Detective-over-Multi-Scale-Visual-Evidence/","children":"[논문리뷰] Conan: Progressive Learning to Reason Like a Detective over Multi-Scale Visual Evidence"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Conan: Progressive Learning to Reason Like a Detective over Multi-Scale Visual Evidence' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Reasoning",{"className":"page__taxonomy-item","children":["#","Video Reasoning"]}],["$","span","Multimodal Large Language Models (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models (MLLMs)"]}],["$","span","Reinforcement Learning (RLVR)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RLVR)"]}],["$","span","Evidence Grounding",{"className":"page__taxonomy-item","children":["#","Evidence Grounding"]}],["$","span","Multi-step Reasoning",{"className":"page__taxonomy-item","children":["#","Multi-step Reasoning"]}],["$","span","Frame Retrieval",{"className":"page__taxonomy-item","children":["#","Frame Retrieval"]}],["$","span","Dataset Construction",{"className":"page__taxonomy-item","children":["#","Dataset Construction"]}],["$","span","Progressive Learning",{"className":"page__taxonomy-item","children":["#","Progressive Learning"]}]]}]]}]]}],["$","article","2025-10-24-ComProScanner-A-multi-agent-based-framework-for-composition-property-structured-data-extraction-from-scientific-literature",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-ComProScanner-A-multi-agent-based-framework-for-composition-property-structured-data-extraction-from-scientific-literature/","children":"[논문리뷰] ComProScanner: A multi-agent based framework for composition-property structured data extraction from scientific literature"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'ComProScanner: A multi-agent based framework for composition-property structured data extraction from scientific literature' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-agent Systems"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Information Extraction",{"className":"page__taxonomy-item","children":["#","Information Extraction"]}],["$","span","Scientific Literature",{"className":"page__taxonomy-item","children":["#","Scientific Literature"]}],["$","span","Materials Science",{"className":"page__taxonomy-item","children":["#","Materials Science"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Piezoelectric Materials",{"className":"page__taxonomy-item","children":["#","Piezoelectric Materials"]}],["$","span","RAG (Retrieval-Augmented Generation)",{"className":"page__taxonomy-item","children":["#","RAG (Retrieval-Augmented Generation)"]}]]}]]}]]}],["$","article","2025-10-24-AlphaFlow-Understanding-and-Improving-MeanFlow-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-AlphaFlow-Understanding-and-Improving-MeanFlow-Models/","children":"[논문리뷰] AlphaFlow: Understanding and Improving MeanFlow Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'AlphaFlow: Understanding and Improving MeanFlow Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Consistency Models",{"className":"page__taxonomy-item","children":["#","Consistency Models"]}],["$","span","MeanFlow",{"className":"page__taxonomy-item","children":["#","MeanFlow"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Few-Step Generation",{"className":"page__taxonomy-item","children":["#","Few-Step Generation"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}]]}]]}]]}],["$","article","2025-10-24-AdaSPEC-Selective-Knowledge-Distillation-for-Efficient-Speculative-Decoders",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-AdaSPEC-Selective-Knowledge-Distillation-for-Efficient-Speculative-Decoders/","children":"[논문리뷰] AdaSPEC: Selective Knowledge Distillation for Efficient Speculative Decoders"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'AdaSPEC: Selective Knowledge Distillation for Efficient Speculative Decoders' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Speculative Decoding",{"className":"page__taxonomy-item","children":["#","Speculative Decoding"]}],["$","span","Knowledge Distillation",{"className":"page__taxonomy-item","children":["#","Knowledge Distillation"]}],["$","span","LLM Inference",{"className":"page__taxonomy-item","children":["#","LLM Inference"]}],["$","span","Model Acceleration",{"className":"page__taxonomy-item","children":["#","Model Acceleration"]}],["$","span","Token Filtering",{"className":"page__taxonomy-item","children":["#","Token Filtering"]}],["$","span","Draft Model",{"className":"page__taxonomy-item","children":["#","Draft Model"]}],["$","span","Acceptance Rate",{"className":"page__taxonomy-item","children":["#","Acceptance Rate"]}]]}]]}]]}],["$","article","2025-10-24-ARGenSeg-Image-Segmentation-with-Autoregressive-Image-Generation-Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-ARGenSeg-Image-Segmentation-with-Autoregressive-Image-Generation-Model/","children":"[논문리뷰] ARGenSeg: Image Segmentation with Autoregressive Image Generation Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'ARGenSeg: Image Segmentation with Autoregressive Image Generation Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Segmentation",{"className":"page__taxonomy-item","children":["#","Image Segmentation"]}],["$","span","Autoregressive Generation",{"className":"page__taxonomy-item","children":["#","Autoregressive Generation"]}],["$","span","Multimodal Large Language Models (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models (MLLMs)"]}],["$","span","Visual Understanding",{"className":"page__taxonomy-item","children":["#","Visual Understanding"]}],["$","span","VQ-VAE",{"className":"page__taxonomy-item","children":["#","VQ-VAE"]}],["$","span","Multi-scale Prediction",{"className":"page__taxonomy-item","children":["#","Multi-scale Prediction"]}],["$","span","Referring Expression Segmentation",{"className":"page__taxonomy-item","children":["#","Referring Expression Segmentation"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}]]}]]}]]}],["$","article","2025-10-23-olmOCR-2-Unit-Test-Rewards-for-Document-OCR",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-olmOCR-2-Unit-Test-Rewards-for-Document-OCR/","children":"[논문리뷰] olmOCR 2: Unit Test Rewards for Document OCR"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'olmOCR 2: Unit Test Rewards for Document OCR' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Document OCR",{"className":"page__taxonomy-item","children":["#","Document OCR"]}],["$","span","Vision Language Model",{"className":"page__taxonomy-item","children":["#","Vision Language Model"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Unit Tests",{"className":"page__taxonomy-item","children":["#","Unit Tests"]}],["$","span","Synthetic Data Generation",{"className":"page__taxonomy-item","children":["#","Synthetic Data Generation"]}],["$","span","RLVR",{"className":"page__taxonomy-item","children":["#","RLVR"]}],["$","span","Document Parsing",{"className":"page__taxonomy-item","children":["#","Document Parsing"]}],["$","span","State-of-the-Art OCR",{"className":"page__taxonomy-item","children":["#","State-of-the-Art OCR"]}]]}]]}]]}],["$","article","2025-10-23-VideoAgentTrek-Computer-Use-Pretraining-from-Unlabeled-Videos",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-VideoAgentTrek-Computer-Use-Pretraining-from-Unlabeled-Videos/","children":"[논문리뷰] VideoAgentTrek: Computer Use Pretraining from Unlabeled Videos"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xinyuan Wang이 [arXiv]에 게시한 'VideoAgentTrek: Computer Use Pretraining from Unlabeled Videos' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","GUI Agents",{"className":"page__taxonomy-item","children":["#","GUI Agents"]}],["$","span","Video Pretraining",{"className":"page__taxonomy-item","children":["#","Video Pretraining"]}],["$","span","Inverse Dynamics",{"className":"page__taxonomy-item","children":["#","Inverse Dynamics"]}],["$","span","Action Recognition",{"className":"page__taxonomy-item","children":["#","Action Recognition"]}],["$","span","Computer Use Automation",{"className":"page__taxonomy-item","children":["#","Computer Use Automation"]}],["$","span","Data Synthesis",{"className":"page__taxonomy-item","children":["#","Data Synthesis"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}]]}]]}]]}],["$","article","2025-10-23-Unified-Reinforcement-and-Imitation-Learning-for-Vision-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-Unified-Reinforcement-and-Imitation-Learning-for-Vision-Language-Models/","children":"[논문리뷰] Unified Reinforcement and Imitation Learning for Vision-Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Unified Reinforcement and Imitation Learning for Vision-Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Imitation Learning",{"className":"page__taxonomy-item","children":["#","Imitation Learning"]}],["$","span","Model Distillation",{"className":"page__taxonomy-item","children":["#","Model Distillation"]}],["$","span","Lightweight VLMs",{"className":"page__taxonomy-item","children":["#","Lightweight VLMs"]}],["$","span","LLM-as-a-Judge",{"className":"page__taxonomy-item","children":["#","LLM-as-a-Judge"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}]]}]]}]]}],["$","article","2025-10-23-RIR-Mega-a-large-scale-simulated-room-impulse-response-dataset-for-machine-learning-and-room-acoustics-modeling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-RIR-Mega-a-large-scale-simulated-room-impulse-response-dataset-for-machine-learning-and-room-acoustics-modeling/","children":"[논문리뷰] RIR-Mega: a large-scale simulated room impulse response dataset for machine learning and room acoustics modeling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Mandip Goswami이 [arXiv]에 게시한 'RIR-Mega: a large-scale simulated room impulse response dataset for machine learning and room acoustics modeling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Room Impulse Response",{"className":"page__taxonomy-item","children":["#","Room Impulse Response"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}],["$","span","Room Acoustics",{"className":"page__taxonomy-item","children":["#","Room Acoustics"]}],["$","span","Machine Learning",{"className":"page__taxonomy-item","children":["#","Machine Learning"]}],["$","span","Dereverberation",{"className":"page__taxonomy-item","children":["#","Dereverberation"]}],["$","span","Speech Recognition",{"className":"page__taxonomy-item","children":["#","Speech Recognition"]}],["$","span","Simulation",{"className":"page__taxonomy-item","children":["#","Simulation"]}],["$","span","Hugging Face",{"className":"page__taxonomy-item","children":["#","Hugging Face"]}]]}]]}]]}],["$","article","2025-10-23-ProfBench-Multi-Domain-Rubrics-requiring-Professional-Knowledge-to-Answer-and-Judge",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-ProfBench-Multi-Domain-Rubrics-requiring-Professional-Knowledge-to-Answer-and-Judge/","children":"[논문리뷰] ProfBench: Multi-Domain Rubrics requiring Professional Knowledge to Answer and Judge"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'ProfBench: Multi-Domain Rubrics requiring Professional Knowledge to Answer and Judge' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Rubric-based Benchmark",{"className":"page__taxonomy-item","children":["#","Rubric-based Benchmark"]}],["$","span","Professional Knowledge",{"className":"page__taxonomy-item","children":["#","Professional Knowledge"]}],["$","span","Multi-domain Tasks",{"className":"page__taxonomy-item","children":["#","Multi-domain Tasks"]}],["$","span","LLM-Judge Bias Mitigation",{"className":"page__taxonomy-item","children":["#","LLM-Judge Bias Mitigation"]}],["$","span","Cost Reduction",{"className":"page__taxonomy-item","children":["#","Cost Reduction"]}],["$","span","Reasoning Assessment",{"className":"page__taxonomy-item","children":["#","Reasoning Assessment"]}],["$","span","Open-weight Models",{"className":"page__taxonomy-item","children":["#","Open-weight Models"]}]]}]]}]]}],["$","article","2025-10-23-Pico-Banana-400K-A-Large-Scale-Dataset-for-Text-Guided-Image-Editing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-Pico-Banana-400K-A-Large-Scale-Dataset-for-Text-Guided-Image-Editing/","children":"[논문리뷰] Pico-Banana-400K: A Large-Scale Dataset for Text-Guided Image Editing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Pico-Banana-400K: A Large-Scale Dataset for Text-Guided Image Editing' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-Guided Image Editing",{"className":"page__taxonomy-item","children":["#","Text-Guided Image Editing"]}],["$","span","Large-Scale Dataset",{"className":"page__taxonomy-item","children":["#","Large-Scale Dataset"]}],["$","span","Multimodal Models",{"className":"page__taxonomy-item","children":["#","Multimodal Models"]}],["$","span","Dataset Curation",{"className":"page__taxonomy-item","children":["#","Dataset Curation"]}],["$","span","Quality Control",{"className":"page__taxonomy-item","children":["#","Quality Control"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","Preference Learning",{"className":"page__taxonomy-item","children":["#","Preference Learning"]}],["$","span","Multi-Turn Editing",{"className":"page__taxonomy-item","children":["#","Multi-Turn Editing"]}]]}]]}]]}],["$","article","2025-10-23-OmniNWM-Omniscient-Driving-Navigation-World-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-OmniNWM-Omniscient-Driving-Navigation-World-Models/","children":"[논문리뷰] OmniNWM: Omniscient Driving Navigation World Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhujin Liang이 [arXiv]에 게시한 'OmniNWM: Omniscient Driving Navigation World Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Autonomous Driving",{"className":"page__taxonomy-item","children":["#","Autonomous Driving"]}],["$","span","World Models",{"className":"page__taxonomy-item","children":["#","World Models"]}],["$","span","Multi-modal Generation",{"className":"page__taxonomy-item","children":["#","Multi-modal Generation"]}],["$","span","3D Occupancy",{"className":"page__taxonomy-item","children":["#","3D Occupancy"]}],["$","span","Plücker Ray-maps",{"className":"page__taxonomy-item","children":["#","Plücker Ray-maps"]}],["$","span","Action Control",{"className":"page__taxonomy-item","children":["#","Action Control"]}],["$","span","Dense Rewards",{"className":"page__taxonomy-item","children":["#","Dense Rewards"]}],["$","span","Long-term Forecasting",{"className":"page__taxonomy-item","children":["#","Long-term Forecasting"]}]]}]]}]]}],["$","article","2025-10-23-Machine-Text-Detectors-are-Membership-Inference-Attacks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-Machine-Text-Detectors-are-Membership-Inference-Attacks/","children":"[논문리뷰] Machine Text Detectors are Membership Inference Attacks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Naoaki Okazaki이 [arXiv]에 게시한 'Machine Text Detectors are Membership Inference Attacks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Membership Inference Attacks",{"className":"page__taxonomy-item","children":["#","Membership Inference Attacks"]}],["$","span","Machine-Generated Text Detection",{"className":"page__taxonomy-item","children":["#","Machine-Generated Text Detection"]}],["$","span","Transferability",{"className":"page__taxonomy-item","children":["#","Transferability"]}],["$","span","Likelihood Ratio Test",{"className":"page__taxonomy-item","children":["#","Likelihood Ratio Test"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Zero-Shot Detection",{"className":"page__taxonomy-item","children":["#","Zero-Shot Detection"]}],["$","span","Model Security",{"className":"page__taxonomy-item","children":["#","Model Security"]}],["$","span","AI Safety",{"className":"page__taxonomy-item","children":["#","AI Safety"]}]]}]]}]]}],["$","article","2025-10-23-MINED-Probing-and-Updating-with-Multimodal-Time-Sensitive-Knowledge-for-Large-Multimodal-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-MINED-Probing-and-Updating-with-Multimodal-Time-Sensitive-Knowledge-for-Large-Multimodal-Models/","children":"[논문리뷰] MINED: Probing and Updating with Multimodal Time-Sensitive Knowledge for Large Multimodal Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yifan Gao이 [arXiv]에 게시한 'MINED: Probing and Updating with Multimodal Time-Sensitive Knowledge for Large Multimodal Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Multimodal Models (LMMs)",{"className":"page__taxonomy-item","children":["#","Large Multimodal Models (LMMs)"]}],["$","span","Time-Sensitive Knowledge",{"className":"page__taxonomy-item","children":["#","Time-Sensitive Knowledge"]}],["$","span","Temporal Reasoning",{"className":"page__taxonomy-item","children":["#","Temporal Reasoning"]}],["$","span","Knowledge Editing",{"className":"page__taxonomy-item","children":["#","Knowledge Editing"]}],["$","span","Multimodal Benchmarking",{"className":"page__taxonomy-item","children":["#","Multimodal Benchmarking"]}],["$","span","Temporal Awareness",{"className":"page__taxonomy-item","children":["#","Temporal Awareness"]}],["$","span","Dynamic Knowledge",{"className":"page__taxonomy-item","children":["#","Dynamic Knowledge"]}]]}]]}]]}],["$","article","2025-10-23-LoongRLReinforcement-Learning-for-Advanced-Reasoning-over-Long-Contexts",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-LoongRLReinforcement-Learning-for-Advanced-Reasoning-over-Long-Contexts/","children":"[논문리뷰] LoongRL:Reinforcement Learning for Advanced Reasoning over Long Contexts"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'LoongRL:Reinforcement Learning for Advanced Reasoning over Long Contexts' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Long Context Reasoning",{"className":"page__taxonomy-item","children":["#","Long Context Reasoning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Multi-hop QA",{"className":"page__taxonomy-item","children":["#","Multi-hop QA"]}],["$","span","Data Synthesis",{"className":"page__taxonomy-item","children":["#","Data Synthesis"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}]]}]]}]]}],["$","article","2025-10-23-Learning-from-the-Best-Differently-A-Diversity-Driven-Rethinking-on-Data-Selection",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-Learning-from-the-Best-Differently-A-Diversity-Driven-Rethinking-on-Data-Selection/","children":"[논문리뷰] Learning from the Best, Differently: A Diversity-Driven Rethinking on Data Selection"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yi Cheng이 [arXiv]에 게시한 'Learning from the Best, Differently: A Diversity-Driven Rethinking on Data Selection' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Data Selection",{"className":"page__taxonomy-item","children":["#","Data Selection"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Data Diversity",{"className":"page__taxonomy-item","children":["#","Data Diversity"]}],["$","span","Data Quality",{"className":"page__taxonomy-item","children":["#","Data Quality"]}],["$","span","Principal Component Analysis (PCA)",{"className":"page__taxonomy-item","children":["#","Principal Component Analysis (PCA)"]}],["$","span","Orthogonal Dimensions",{"className":"page__taxonomy-item","children":["#","Orthogonal Dimensions"]}],["$","span","Pre-training",{"className":"page__taxonomy-item","children":["#","Pre-training"]}]]}]]}]]}],["$","article","2025-10-23-Language-Models-are-Injective-and-Hence-Invertible",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-Language-Models-are-Injective-and-Hence-Invertible/","children":"[논문리뷰] Language Models are Injective and Hence Invertible"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Language Models are Injective and Hence Invertible' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Language Models",{"className":"page__taxonomy-item","children":["#","Language Models"]}],["$","span","Injectivity",{"className":"page__taxonomy-item","children":["#","Injectivity"]}],["$","span","Invertibility",{"className":"page__taxonomy-item","children":["#","Invertibility"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Representation Learning",{"className":"page__taxonomy-item","children":["#","Representation Learning"]}],["$","span","Exact Recovery",{"className":"page__taxonomy-item","children":["#","Exact Recovery"]}],["$","span","SIPIT Algorithm",{"className":"page__taxonomy-item","children":["#","SIPIT Algorithm"]}],["$","span","Real Analysis",{"className":"page__taxonomy-item","children":["#","Real Analysis"]}]]}]]}]]}],["$","article","2025-10-23-KORE-Enhancing-Knowledge-Injection-for-Large-Multimodal-Models-via-Knowledge-Oriented-Augmentations-and-Constraints",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-KORE-Enhancing-Knowledge-Injection-for-Large-Multimodal-Models-via-Knowledge-Oriented-Augmentations-and-Constraints/","children":"[논문리뷰] KORE: Enhancing Knowledge Injection for Large Multimodal Models via Knowledge-Oriented Augmentations and Constraints"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jinhe Bi이 [arXiv]에 게시한 'KORE: Enhancing Knowledge Injection for Large Multimodal Models via Knowledge-Oriented Augmentations and Constraints' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Knowledge Injection",{"className":"page__taxonomy-item","children":["#","Knowledge Injection"]}],["$","span","Large Multimodal Models",{"className":"page__taxonomy-item","children":["#","Large Multimodal Models"]}],["$","span","Catastrophic Forgetting",{"className":"page__taxonomy-item","children":["#","Catastrophic Forgetting"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}],["$","span","Parameter-Efficient Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Parameter-Efficient Fine-Tuning"]}],["$","span","Null Space",{"className":"page__taxonomy-item","children":["#","Null Space"]}],["$","span","Continual Learning",{"className":"page__taxonomy-item","children":["#","Continual Learning"]}]]}]]}]]}],["$","article","2025-10-23-GigaBrain-0-A-World-Model-Powered-Vision-Language-Action-Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-GigaBrain-0-A-World-Model-Powered-Vision-Language-Action-Model/","children":"[논문리뷰] GigaBrain-0: A World Model-Powered Vision-Language-Action Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'GigaBrain-0: A World Model-Powered Vision-Language-Action Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action Model",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action Model"]}],["$","span","World Model",{"className":"page__taxonomy-item","children":["#","World Model"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}],["$","span","Robot Generalization",{"className":"page__taxonomy-item","children":["#","Robot Generalization"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","RGBD",{"className":"page__taxonomy-item","children":["#","RGBD"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}]]}]]}]]}],["$","article","2025-10-23-From-Charts-to-Code-A-Hierarchical-Benchmark-for-Multimodal-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-From-Charts-to-Code-A-Hierarchical-Benchmark-for-Multimodal-Models/","children":"[논문리뷰] From Charts to Code: A Hierarchical Benchmark for Multimodal Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Dongxing Mao이 [arXiv]에 게시한 'From Charts to Code: A Hierarchical Benchmark for Multimodal Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Chart-to-Code",{"className":"page__taxonomy-item","children":["#","Chart-to-Code"]}],["$","span","Multimodal Models",{"className":"page__taxonomy-item","children":["#","Multimodal Models"]}],["$","span","Hierarchical Benchmark",{"className":"page__taxonomy-item","children":["#","Hierarchical Benchmark"]}],["$","span","Chart Understanding",{"className":"page__taxonomy-item","children":["#","Chart Understanding"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","Evaluation Metrics",{"className":"page__taxonomy-item","children":["#","Evaluation Metrics"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}]]}]]}]]}],["$","article","2025-10-23-FinSight-Towards-Real-World-Financial-Deep-Research",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-FinSight-Towards-Real-World-Financial-Deep-Research/","children":"[논문리뷰] FinSight: Towards Real-World Financial Deep Research"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yutao Zhu이 [arXiv]에 게시한 'FinSight: Towards Real-World Financial Deep Research' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Financial Research",{"className":"page__taxonomy-item","children":["#","Financial Research"]}],["$","span","Multi-Agent System",{"className":"page__taxonomy-item","children":["#","Multi-Agent System"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","Multimodal Reports",{"className":"page__taxonomy-item","children":["#","Multimodal Reports"]}],["$","span","Iterative Visualization",{"className":"page__taxonomy-item","children":["#","Iterative Visualization"]}],["$","span","Variable Memory",{"className":"page__taxonomy-item","children":["#","Variable Memory"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}]]}]]}]]}],["$","article","2025-10-23-Every-Attention-Matters-An-Efficient-Hybrid-Architecture-for-Long-Context-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-Every-Attention-Matters-An-Efficient-Hybrid-Architecture-for-Long-Context-Reasoning/","children":"[논문리뷰] Every Attention Matters: An Efficient Hybrid Architecture for Long-Context Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Every Attention Matters: An Efficient Hybrid Architecture for Long-Context Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Long-Context LLM",{"className":"page__taxonomy-item","children":["#","Long-Context LLM"]}],["$","span","Hybrid Attention",{"className":"page__taxonomy-item","children":["#","Hybrid Attention"]}],["$","span","Linear Attention",{"className":"page__taxonomy-item","children":["#","Linear Attention"]}],["$","span","Mixture-of-Experts",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts"]}],["$","span","FP8 Training",{"className":"page__taxonomy-item","children":["#","FP8 Training"]}],["$","span","GPU Optimization",{"className":"page__taxonomy-item","children":["#","GPU Optimization"]}],["$","span","Training-Inference Alignment",{"className":"page__taxonomy-item","children":["#","Training-Inference Alignment"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}]]}]]}]]}],["$","article","2025-10-23-Directional-Reasoning-Injection-for-Fine-Tuning-MLLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-Directional-Reasoning-Injection-for-Fine-Tuning-MLLMs/","children":"[논문리뷰] Directional Reasoning Injection for Fine-Tuning MLLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jialian Wu이 [arXiv]에 게시한 'Directional Reasoning Injection for Fine-Tuning MLLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Reasoning Transfer",{"className":"page__taxonomy-item","children":["#","Reasoning Transfer"]}],["$","span","Gradient-based Fine-tuning",{"className":"page__taxonomy-item","children":["#","Gradient-based Fine-tuning"]}],["$","span","Model Merging",{"className":"page__taxonomy-item","children":["#","Model Merging"]}],["$","span","Parameter-Efficient Learning",{"className":"page__taxonomy-item","children":["#","Parameter-Efficient Learning"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Directional Prior",{"className":"page__taxonomy-item","children":["#","Directional Prior"]}]]}]]}]]}],["$","article","2025-10-23-DeLeaker-Dynamic-Inference-Time-Reweighting-For-Semantic-Leakage-Mitigation-in-Text-to-Image-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-DeLeaker-Dynamic-Inference-Time-Reweighting-For-Semantic-Leakage-Mitigation-in-Text-to-Image-Models/","children":"[논문리뷰] DeLeaker: Dynamic Inference-Time Reweighting For Semantic Leakage Mitigation in Text-to-Image Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Roi Reichart이 [arXiv]에 게시한 'DeLeaker: Dynamic Inference-Time Reweighting For Semantic Leakage Mitigation in Text-to-Image Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Semantic Leakage",{"className":"page__taxonomy-item","children":["#","Semantic Leakage"]}],["$","span","Text-to-Image Models",{"className":"page__taxonomy-item","children":["#","Text-to-Image Models"]}],["$","span","Attention Control",{"className":"page__taxonomy-item","children":["#","Attention Control"]}],["$","span","Inference-time Mitigation",{"className":"page__taxonomy-item","children":["#","Inference-time Mitigation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Evaluation Dataset",{"className":"page__taxonomy-item","children":["#","Evaluation Dataset"]}],["$","span","Self-Attention",{"className":"page__taxonomy-item","children":["#","Self-Attention"]}]]}]]}]]}],["$","article","2025-10-23-DaMo-Data-Mixing-Optimizer-in-Fine-tuning-Multimodal-LLMs-for-Mobile-Phone-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-DaMo-Data-Mixing-Optimizer-in-Fine-tuning-Multimodal-LLMs-for-Mobile-Phone-Agents/","children":"[논문리뷰] DaMo: Data Mixing Optimizer in Fine-tuning Multimodal LLMs for Mobile Phone Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DaMo: Data Mixing Optimizer in Fine-tuning Multimodal LLMs for Mobile Phone Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Data Mixing Optimization",{"className":"page__taxonomy-item","children":["#","Data Mixing Optimization"]}],["$","span","Mobile Phone Agents",{"className":"page__taxonomy-item","children":["#","Mobile Phone Agents"]}],["$","span","Downstream Task Prediction",{"className":"page__taxonomy-item","children":["#","Downstream Task Prediction"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Neural Networks",{"className":"page__taxonomy-item","children":["#","Neural Networks"]}]]}]]}]]}],["$","article","2025-10-23-ColorAgent-Building-A-Robust-Personalized-and-Interactive-OS-Agent",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-ColorAgent-Building-A-Robust-Personalized-and-Interactive-OS-Agent/","children":"[논문리뷰] ColorAgent: Building A Robust, Personalized, and Interactive OS Agent"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Weiming Zhang이 [arXiv]에 게시한 'ColorAgent: Building A Robust, Personalized, and Interactive OS Agent' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","OS Agent",{"className":"page__taxonomy-item","children":["#","OS Agent"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Multi-agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-agent Systems"]}],["$","span","Personalization",{"className":"page__taxonomy-item","children":["#","Personalization"]}],["$","span","Proactive Interaction",{"className":"page__taxonomy-item","children":["#","Proactive Interaction"]}],["$","span","GUI Agents",{"className":"page__taxonomy-item","children":["#","GUI Agents"]}],["$","span","Self-Evolving Training",{"className":"page__taxonomy-item","children":["#","Self-Evolving Training"]}]]}]]}]]}],["$","article","2025-10-23-BAPO-Stabilizing-Off-Policy-Reinforcement-Learning-for-LLMs-via-Balanced-Policy-Optimization-with-Adaptive-Clipping",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-BAPO-Stabilizing-Off-Policy-Reinforcement-Learning-for-LLMs-via-Balanced-Policy-Optimization-with-Adaptive-Clipping/","children":"[논문리뷰] BAPO: Stabilizing Off-Policy Reinforcement Learning for LLMs via Balanced Policy Optimization with Adaptive Clipping"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Junrui Shen이 [arXiv]에 게시한 'BAPO: Stabilizing Off-Policy Reinforcement Learning for LLMs via Balanced Policy Optimization with Adaptive Clipping' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Off-Policy Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Off-Policy Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Adaptive Clipping",{"className":"page__taxonomy-item","children":["#","Adaptive Clipping"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","PPO",{"className":"page__taxonomy-item","children":["#","PPO"]}],["$","span","Entropy Preservation",{"className":"page__taxonomy-item","children":["#","Entropy Preservation"]}],["$","span","RL Stabilization",{"className":"page__taxonomy-item","children":["#","RL Stabilization"]}]]}]]}]]}],["$","article","2025-10-23-Attention-Sinks-in-Diffusion-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-Attention-Sinks-in-Diffusion-Language-Models/","children":"[논문리뷰] Attention Sinks in Diffusion Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Simone Scardapane이 [arXiv]에 게시한 'Attention Sinks in Diffusion Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Language Models",{"className":"page__taxonomy-item","children":["#","Diffusion Language Models"]}],["$","span","Attention Sinks",{"className":"page__taxonomy-item","children":["#","Attention Sinks"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Masked Language Modeling",{"className":"page__taxonomy-item","children":["#","Masked Language Modeling"]}],["$","span","Bidirectional Attention",{"className":"page__taxonomy-item","children":["#","Bidirectional Attention"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Robustness",{"className":"page__taxonomy-item","children":["#","Robustness"]}],["$","span","Dynamic Attention",{"className":"page__taxonomy-item","children":["#","Dynamic Attention"]}]]}]]}]]}],["$","article","2025-10-23-AlphaOPT-Formulating-Optimization-Programs-with-Self-Improving-LLM-Experience-Library",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-AlphaOPT-Formulating-Optimization-Programs-with-Self-Improving-LLM-Experience-Library/","children":"[논문리뷰] AlphaOPT: Formulating Optimization Programs with Self-Improving LLM Experience Library"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chonghe Jiang이 [arXiv]에 게시한 'AlphaOPT: Formulating Optimization Programs with Self-Improving LLM Experience Library' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Optimization Modeling",{"className":"page__taxonomy-item","children":["#","Optimization Modeling"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Experience Library",{"className":"page__taxonomy-item","children":["#","Experience Library"]}],["$","span","Self-Improving Systems",{"className":"page__taxonomy-item","children":["#","Self-Improving Systems"]}],["$","span","Continual Learning",{"className":"page__taxonomy-item","children":["#","Continual Learning"]}],["$","span","Out-of-Distribution Generalization",{"className":"page__taxonomy-item","children":["#","Out-of-Distribution Generalization"]}],["$","span","Operations Research",{"className":"page__taxonomy-item","children":["#","Operations Research"]}],["$","span","Knowledge Representation",{"className":"page__taxonomy-item","children":["#","Knowledge Representation"]}]]}]]}]]}],["$","article","2025-10-22-World-in-World-World-Models-in-a-Closed-Loop-World",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-World-in-World-World-Models-in-a-Closed-Loop-World/","children":"[논문리뷰] World-in-World: World Models in a Closed-Loop World"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Arda Uzunoglu이 [arXiv]에 게시한 'World-in-World: World Models in a Closed-Loop World' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","World Models",{"className":"page__taxonomy-item","children":["#","World Models"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Closed-Loop Evaluation",{"className":"page__taxonomy-item","children":["#","Closed-Loop Evaluation"]}],["$","span","Online Planning",{"className":"page__taxonomy-item","children":["#","Online Planning"]}],["$","span","Data Scaling",{"className":"page__taxonomy-item","children":["#","Data Scaling"]}],["$","span","Controllability",{"className":"page__taxonomy-item","children":["#","Controllability"]}],["$","span","Robotic Manipulation",{"className":"page__taxonomy-item","children":["#","Robotic Manipulation"]}]]}]]}]]}],["$","article","2025-10-22-Video-Reasoning-without-Training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-Video-Reasoning-without-Training/","children":"[논문리뷰] Video Reasoning without Training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Video Reasoning without Training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Reasoning",{"className":"page__taxonomy-item","children":["#","Video Reasoning"]}],["$","span","Large Multimodal Models (LMMs)",{"className":"page__taxonomy-item","children":["#","Large Multimodal Models (LMMs)"]}],["$","span","Inference-Time Optimization",{"className":"page__taxonomy-item","children":["#","Inference-Time Optimization"]}],["$","span","Entropy-Based Objective",{"className":"page__taxonomy-item","children":["#","Entropy-Based Objective"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}],["$","span","KV-Cache Steering",{"className":"page__taxonomy-item","children":["#","KV-Cache Steering"]}],["$","span","Micro-Exploration",{"className":"page__taxonomy-item","children":["#","Micro-Exploration"]}],["$","span","Macro-Exploitation",{"className":"page__taxonomy-item","children":["#","Macro-Exploitation"]}]]}]]}]]}],["$","article","2025-10-22-Unleashing-Scientific-Reasoning-for-Bio-experimental-Protocol-Generation-via-Structured-Component-based-Reward-Mechanism",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-Unleashing-Scientific-Reasoning-for-Bio-experimental-Protocol-Generation-via-Structured-Component-based-Reward-Mechanism/","children":"[논문리뷰] Unleashing Scientific Reasoning for Bio-experimental Protocol Generation via Structured Component-based Reward Mechanism"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shuang Gu이 [arXiv]에 게시한 'Unleashing Scientific Reasoning for Bio-experimental Protocol Generation via Structured Component-based Reward Mechanism' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Scientific Reasoning",{"className":"page__taxonomy-item","children":["#","Scientific Reasoning"]}],["$","span","Bio-experimental Protocol Generation",{"className":"page__taxonomy-item","children":["#","Bio-experimental Protocol Generation"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Structured Reward",{"className":"page__taxonomy-item","children":["#","Structured Reward"]}],["$","span","SciRecipe Dataset",{"className":"page__taxonomy-item","children":["#","SciRecipe Dataset"]}],["$","span","Sketch-and-Fill",{"className":"page__taxonomy-item","children":["#","Sketch-and-Fill"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Thoth",{"className":"page__taxonomy-item","children":["#","Thoth"]}]]}]]}]]}],["$","article","2025-10-22-UniGenBench-A-Unified-Semantic-Evaluation-Benchmark-for-Text-to-Image-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-UniGenBench-A-Unified-Semantic-Evaluation-Benchmark-for-Text-to-Image-Generation/","children":"[논문리뷰] UniGenBench++: A Unified Semantic Evaluation Benchmark for Text-to-Image Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yujie Zhou이 [arXiv]에 게시한 'UniGenBench++: A Unified Semantic Evaluation Benchmark for Text-to-Image Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Semantic Evaluation",{"className":"page__taxonomy-item","children":["#","Semantic Evaluation"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Multilingual Evaluation",{"className":"page__taxonomy-item","children":["#","Multilingual Evaluation"]}],["$","span","Fine-grained Assessment",{"className":"page__taxonomy-item","children":["#","Fine-grained Assessment"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Model Evaluation",{"className":"page__taxonomy-item","children":["#","Model Evaluation"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}]]}]]}]]}],["$","article","2025-10-22-UltraGen-High-Resolution-Video-Generation-with-Hierarchical-Attention",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-UltraGen-High-Resolution-Video-Generation-with-Hierarchical-Attention/","children":"[논문리뷰] UltraGen: High-Resolution Video Generation with Hierarchical Attention"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ran Yi이 [arXiv]에 게시한 'UltraGen: High-Resolution Video Generation with Hierarchical Attention' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","High-Resolution",{"className":"page__taxonomy-item","children":["#","High-Resolution"]}],["$","span","Diffusion Transformer",{"className":"page__taxonomy-item","children":["#","Diffusion Transformer"]}],["$","span","Hierarchical Attention",{"className":"page__taxonomy-item","children":["#","Hierarchical Attention"]}],["$","span","Global-Local Attention",{"className":"page__taxonomy-item","children":["#","Global-Local Attention"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}],["$","span","4K Synthesis",{"className":"page__taxonomy-item","children":["#","4K Synthesis"]}]]}]]}]]}],["$","article","2025-10-22-Towards-Faithful-and-Controllable-Personalization-via-Critique-Post-Edit-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-Towards-Faithful-and-Controllable-Personalization-via-Critique-Post-Edit-Reinforcement-Learning/","children":"[논문리뷰] Towards Faithful and Controllable Personalization via Critique-Post-Edit Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuchen Eleanor Jiang이 [arXiv]에 게시한 'Towards Faithful and Controllable Personalization via Critique-Post-Edit Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Personalization",{"className":"page__taxonomy-item","children":["#","LLM Personalization"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Generative Reward Model",{"className":"page__taxonomy-item","children":["#","Generative Reward Model"]}],["$","span","Critique-Post-Edit",{"className":"page__taxonomy-item","children":["#","Critique-Post-Edit"]}],["$","span","Reward Hacking",{"className":"page__taxonomy-item","children":["#","Reward Hacking"]}],["$","span","Controllable AI",{"className":"page__taxonomy-item","children":["#","Controllable AI"]}]]}]]}]]}],["$","article","2025-10-22-ProCLIP-Progressive-Vision-Language-Alignment-via-LLM-based-Embedder",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-ProCLIP-Progressive-Vision-Language-Alignment-via-LLM-based-Embedder/","children":"[논문리뷰] ProCLIP: Progressive Vision-Language Alignment via LLM-based Embedder"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zonghao Guo이 [arXiv]에 게시한 'ProCLIP: Progressive Vision-Language Alignment via LLM-based Embedder' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","CLIP",{"className":"page__taxonomy-item","children":["#","CLIP"]}],["$","span","LLM-based Embedder",{"className":"page__taxonomy-item","children":["#","LLM-based Embedder"]}],["$","span","Knowledge Distillation",{"className":"page__taxonomy-item","children":["#","Knowledge Distillation"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Multimodal Alignment",{"className":"page__taxonomy-item","children":["#","Multimodal Alignment"]}],["$","span","Progressive Alignment",{"className":"page__taxonomy-item","children":["#","Progressive Alignment"]}]]}]]}]]}],["$","article","2025-10-22-PokeeResearch-Effective-Deep-Research-via-Reinforcement-Learning-from-AI-Feedback-and-Robust-Reasoning-Scaffold",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-PokeeResearch-Effective-Deep-Research-via-Reinforcement-Learning-from-AI-Feedback-and-Robust-Reasoning-Scaffold/","children":"[논문리뷰] PokeeResearch: Effective Deep Research via Reinforcement Learning from AI Feedback and Robust Reasoning Scaffold"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'PokeeResearch: Effective Deep Research via Reinforcement Learning from AI Feedback and Robust Reasoning Scaffold' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Deep Research Agent",{"className":"page__taxonomy-item","children":["#","Deep Research Agent"]}],["$","span","Reinforcement Learning from AI Feedback",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning from AI Feedback"]}],["$","span","RLOO Algorithm",{"className":"page__taxonomy-item","children":["#","RLOO Algorithm"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Self-Correction",{"className":"page__taxonomy-item","children":["#","Self-Correction"]}],["$","span","Reasoning Scaffold",{"className":"page__taxonomy-item","children":["#","Reasoning Scaffold"]}],["$","span","Agent Alignment",{"className":"page__taxonomy-item","children":["#","Agent Alignment"]}]]}]]}]]}],["$","article","2025-10-22-PRISMM-Bench-A-Benchmark-of-Peer-Review-Grounded-Multimodal-Inconsistencies",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-PRISMM-Bench-A-Benchmark-of-Peer-Review-Grounded-Multimodal-Inconsistencies/","children":"[논문리뷰] PRISMM-Bench: A Benchmark of Peer-Review Grounded Multimodal Inconsistencies"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"James Glass이 [arXiv]에 게시한 'PRISMM-Bench: A Benchmark of Peer-Review Grounded Multimodal Inconsistencies' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Multimodal Models (LMMs)",{"className":"page__taxonomy-item","children":["#","Large Multimodal Models (LMMs)"]}],["$","span","Scientific Document Analysis",{"className":"page__taxonomy-item","children":["#","Scientific Document Analysis"]}],["$","span","Multimodal Inconsistencies",{"className":"page__taxonomy-item","children":["#","Multimodal Inconsistencies"]}],["$","span","Peer Review",{"className":"page__taxonomy-item","children":["#","Peer Review"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Debiasing",{"className":"page__taxonomy-item","children":["#","Debiasing"]}],["$","span","JSON-based Representation",{"className":"page__taxonomy-item","children":["#","JSON-based Representation"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}]]}]]}]]}],["$","article","2025-10-22-MoGA-Mixture-of-Groups-Attention-for-End-to-End-Long-Video-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-MoGA-Mixture-of-Groups-Attention-for-End-to-End-Long-Video-Generation/","children":"[논문리뷰] MoGA: Mixture-of-Groups Attention for End-to-End Long Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'MoGA: Mixture-of-Groups Attention for End-to-End Long Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Long Video Generation",{"className":"page__taxonomy-item","children":["#","Long Video Generation"]}],["$","span","Sparse Attention",{"className":"page__taxonomy-item","children":["#","Sparse Attention"]}],["$","span","Diffusion Transformers",{"className":"page__taxonomy-item","children":["#","Diffusion Transformers"]}],["$","span","Mixture-of-Groups Attention",{"className":"page__taxonomy-item","children":["#","Mixture-of-Groups Attention"]}],["$","span","Token Routing",{"className":"page__taxonomy-item","children":["#","Token Routing"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}],["$","span","Context Length",{"className":"page__taxonomy-item","children":["#","Context Length"]}]]}]]}]]}],["$","article","2025-10-22-MUG-V-10B-High-efficiency-Training-Pipeline-for-Large-Video-Generation-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-MUG-V-10B-High-efficiency-Training-Pipeline-for-Large-Video-Generation-Models/","children":"[논문리뷰] MUG-V 10B: High-efficiency Training Pipeline for Large Video Generation Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'MUG-V 10B: High-efficiency Training Pipeline for Large Video Generation Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Diffusion Transformer",{"className":"page__taxonomy-item","children":["#","Diffusion Transformer"]}],["$","span","Large-scale Training",{"className":"page__taxonomy-item","children":["#","Large-scale Training"]}],["$","span","Megatron-Core",{"className":"page__taxonomy-item","children":["#","Megatron-Core"]}],["$","span","Video VAE",{"className":"page__taxonomy-item","children":["#","Video VAE"]}],["$","span","E-commerce AI",{"className":"page__taxonomy-item","children":["#","E-commerce AI"]}],["$","span","High-efficiency Pipeline",{"className":"page__taxonomy-item","children":["#","High-efficiency Pipeline"]}],["$","span","Preference Optimization",{"className":"page__taxonomy-item","children":["#","Preference Optimization"]}]]}]]}]]}],["$","article","2025-10-22-MT-Video-Bench-A-Holistic-Video-Understanding-Benchmark-for-Evaluating-Multimodal-LLMs-in-Multi-Turn-Dialogues",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-MT-Video-Bench-A-Holistic-Video-Understanding-Benchmark-for-Evaluating-Multimodal-LLMs-in-Multi-Turn-Dialogues/","children":"[논문리뷰] MT-Video-Bench: A Holistic Video Understanding Benchmark for Evaluating Multimodal LLMs in Multi-Turn Dialogues"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'MT-Video-Bench: A Holistic Video Understanding Benchmark for Evaluating Multimodal LLMs in Multi-Turn Dialogues' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Video Understanding",{"className":"page__taxonomy-item","children":["#","Video Understanding"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Multi-Turn Dialogues",{"className":"page__taxonomy-item","children":["#","Multi-Turn Dialogues"]}],["$","span","Perceptivity",{"className":"page__taxonomy-item","children":["#","Perceptivity"]}],["$","span","Interactivity",{"className":"page__taxonomy-item","children":["#","Interactivity"]}],["$","span","Evaluation",{"className":"page__taxonomy-item","children":["#","Evaluation"]}]]}]]}]]}],["$","article","2025-10-22-IF-VidCap-Can-Video-Caption-Models-Follow-Instructions",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-IF-VidCap-Can-Video-Caption-Models-Follow-Instructions/","children":"[논문리뷰] IF-VidCap: Can Video Caption Models Follow Instructions?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'IF-VidCap: Can Video Caption Models Follow Instructions?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Captioning",{"className":"page__taxonomy-item","children":["#","Video Captioning"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}],["$","span","MLLMs",{"className":"page__taxonomy-item","children":["#","MLLMs"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Controllable Generation",{"className":"page__taxonomy-item","children":["#","Controllable Generation"]}],["$","span","Multimodal Evaluation",{"className":"page__taxonomy-item","children":["#","Multimodal Evaluation"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}]]}]]}]]}],["$","article","2025-10-22-Grasp-Any-Region-Towards-Precise-Contextual-Pixel-Understanding-for-Multimodal-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-Grasp-Any-Region-Towards-Precise-Contextual-Pixel-Understanding-for-Multimodal-LLMs/","children":"[논문리뷰] Grasp Any Region: Towards Precise, Contextual Pixel Understanding for Multimodal LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Grasp Any Region: Towards Precise, Contextual Pixel Understanding for Multimodal LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Region Understanding",{"className":"page__taxonomy-item","children":["#","Region Understanding"]}],["$","span","Contextual Pixel Understanding",{"className":"page__taxonomy-item","children":["#","Contextual Pixel Understanding"]}],["$","span","RoI-aligned Feature Replay",{"className":"page__taxonomy-item","children":["#","RoI-aligned Feature Replay"]}],["$","span","Compositional Reasoning",{"className":"page__taxonomy-item","children":["#","Compositional Reasoning"]}],["$","span","GAR-Bench",{"className":"page__taxonomy-item","children":["#","GAR-Bench"]}],["$","span","Zero-shot Video Understanding",{"className":"page__taxonomy-item","children":["#","Zero-shot Video Understanding"]}]]}]]}]]}],["$","article","2025-10-22-Extracting-alignment-data-in-open-models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-Extracting-alignment-data-in-open-models/","children":"[논문리뷰] Extracting alignment data in open models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Extracting alignment data in open models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Alignment Data Extraction",{"className":"page__taxonomy-item","children":["#","Alignment Data Extraction"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Memorization",{"className":"page__taxonomy-item","children":["#","Memorization"]}],["$","span","Neural Embeddings",{"className":"page__taxonomy-item","children":["#","Neural Embeddings"]}],["$","span","Semantic Similarity",{"className":"page__taxonomy-item","children":["#","Semantic Similarity"]}],["$","span","Chat Templates",{"className":"page__taxonomy-item","children":["#","Chat Templates"]}],["$","span","Model Distillation",{"className":"page__taxonomy-item","children":["#","Model Distillation"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Supervised Finetuning",{"className":"page__taxonomy-item","children":["#","Supervised Finetuning"]}]]}]]}]]}],["$","article","2025-10-22-EvoSyn-Generalizable-Evolutionary-Data-Synthesis-for-Verifiable-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-EvoSyn-Generalizable-Evolutionary-Data-Synthesis-for-Verifiable-Learning/","children":"[논문리뷰] EvoSyn: Generalizable Evolutionary Data Synthesis for Verifiable Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Qipeng Guo이 [arXiv]에 게시한 'EvoSyn: Generalizable Evolutionary Data Synthesis for Verifiable Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Verifiable Learning",{"className":"page__taxonomy-item","children":["#","Verifiable Learning"]}],["$","span","Data Synthesis",{"className":"page__taxonomy-item","children":["#","Data Synthesis"]}],["$","span","Evolutionary Algorithm",{"className":"page__taxonomy-item","children":["#","Evolutionary Algorithm"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Model Distillation",{"className":"page__taxonomy-item","children":["#","Model Distillation"]}],["$","span","Test Generation",{"className":"page__taxonomy-item","children":["#","Test Generation"]}]]}]]}]]}],["$","article","2025-10-22-DSI-Bench-A-Benchmark-for-Dynamic-Spatial-Intelligence",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-DSI-Bench-A-Benchmark-for-Dynamic-Spatial-Intelligence/","children":"[논문리뷰] DSI-Bench: A Benchmark for Dynamic Spatial Intelligence"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DSI-Bench: A Benchmark for Dynamic Spatial Intelligence' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Dynamic Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Dynamic Spatial Reasoning"]}],["$","span","Vision-Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision-Language Models (VLMs)"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Video Understanding",{"className":"page__taxonomy-item","children":["#","Video Understanding"]}],["$","span","Motion Perception",{"className":"page__taxonomy-item","children":["#","Motion Perception"]}],["$","span","3D Spatial Intelligence",{"className":"page__taxonomy-item","children":["#","3D Spatial Intelligence"]}],["$","span","Hallucinations",{"className":"page__taxonomy-item","children":["#","Hallucinations"]}],["$","span","Bias",{"className":"page__taxonomy-item","children":["#","Bias"]}]]}]]}]]}],["$","article","2025-10-22-Chem-R-Learning-to-Reason-as-a-Chemist",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-Chem-R-Learning-to-Reason-as-a-Chemist/","children":"[논문리뷰] Chem-R: Learning to Reason as a Chemist"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Chem-R: Learning to Reason as a Chemist' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Chemical Reasoning",{"className":"page__taxonomy-item","children":["#","Chemical Reasoning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Chem-R",{"className":"page__taxonomy-item","children":["#","Chem-R"]}],["$","span","Structured Reasoning",{"className":"page__taxonomy-item","children":["#","Structured Reasoning"]}],["$","span","Multi-task Optimization",{"className":"page__taxonomy-item","children":["#","Multi-task Optimization"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Chemical Discovery",{"className":"page__taxonomy-item","children":["#","Chemical Discovery"]}]]}]]}]]}],["$","article","2025-10-22-AlphaQuanter-An-End-to-End-Tool-Orchestrated-Agentic-Reinforcement-Learning-Framework-for-Stock-Trading",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-AlphaQuanter-An-End-to-End-Tool-Orchestrated-Agentic-Reinforcement-Learning-Framework-for-Stock-Trading/","children":"[논문리뷰] AlphaQuanter: An End-to-End Tool-Orchestrated Agentic Reinforcement Learning Framework for Stock Trading"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiashu Wang이 [arXiv]에 게시한 'AlphaQuanter: An End-to-End Tool-Orchestrated Agentic Reinforcement Learning Framework for Stock Trading' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Automated Trading",{"className":"page__taxonomy-item","children":["#","Automated Trading"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Tool Orchestration",{"className":"page__taxonomy-item","children":["#","Tool Orchestration"]}],["$","span","Financial Markets",{"className":"page__taxonomy-item","children":["#","Financial Markets"]}],["$","span","Algorithmic Trading",{"className":"page__taxonomy-item","children":["#","Algorithmic Trading"]}],["$","span","Interpretable AI",{"className":"page__taxonomy-item","children":["#","Interpretable AI"]}],["$","span","ReAct",{"className":"page__taxonomy-item","children":["#","ReAct"]}]]}]]}]]}],["$","article","2025-10-21-When-to-Ensemble-Identifying-Token-Level-Points-for-Stable-and-Fast-LLM-Ensembling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-When-to-Ensemble-Identifying-Token-Level-Points-for-Stable-and-Fast-LLM-Ensembling/","children":"[논문리뷰] When to Ensemble: Identifying Token-Level Points for Stable and Fast LLM Ensembling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'When to Ensemble: Identifying Token-Level Points for Stable and Fast LLM Ensembling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Ensembling",{"className":"page__taxonomy-item","children":["#","LLM Ensembling"]}],["$","span","Token-level Ensembling",{"className":"page__taxonomy-item","children":["#","Token-level Ensembling"]}],["$","span","Speculative Decoding",{"className":"page__taxonomy-item","children":["#","Speculative Decoding"]}],["$","span","Tokenization Mismatch",{"className":"page__taxonomy-item","children":["#","Tokenization Mismatch"]}],["$","span","Probability Sharpening",{"className":"page__taxonomy-item","children":["#","Probability Sharpening"]}],["$","span","Long-form Generation",{"className":"page__taxonomy-item","children":["#","Long-form Generation"]}],["$","span","KV Cache Management",{"className":"page__taxonomy-item","children":["#","KV Cache Management"]}]]}]]}]]}],["$","article","2025-10-21-Visual-Autoregressive-Models-Beat-Diffusion-Models-on-Inference-Time-Scaling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-Visual-Autoregressive-Models-Beat-Diffusion-Models-on-Inference-Time-Scaling/","children":"[논문리뷰] Visual Autoregressive Models Beat Diffusion Models on Inference Time Scaling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Dim P. Papadopoulos이 [arXiv]에 게시한 'Visual Autoregressive Models Beat Diffusion Models on Inference Time Scaling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Visual Autoregressive Models",{"className":"page__taxonomy-item","children":["#","Visual Autoregressive Models"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Inference Time Scaling",{"className":"page__taxonomy-item","children":["#","Inference Time Scaling"]}],["$","span","Beam Search",{"className":"page__taxonomy-item","children":["#","Beam Search"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Text-to-Image Synthesis",{"className":"page__taxonomy-item","children":["#","Text-to-Image Synthesis"]}],["$","span","Discrete Latent Space",{"className":"page__taxonomy-item","children":["#","Discrete Latent Space"]}]]}]]}]]}],["$","article","2025-10-21-Uniworld-V2-Reinforce-Image-Editing-with-Diffusion-Negative-aware-Finetuning-and-MLLM-Implicit-Feedback",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-Uniworld-V2-Reinforce-Image-Editing-with-Diffusion-Negative-aware-Finetuning-and-MLLM-Implicit-Feedback/","children":"[논문리뷰] Uniworld-V2: Reinforce Image Editing with Diffusion Negative-aware Finetuning and MLLM Implicit Feedback"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Uniworld-V2: Reinforce Image Editing with Diffusion Negative-aware Finetuning and MLLM Implicit Feedback' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","MLLM",{"className":"page__taxonomy-item","children":["#","MLLM"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Finetuning",{"className":"page__taxonomy-item","children":["#","Finetuning"]}],["$","span","Reward Modeling",{"className":"page__taxonomy-item","children":["#","Reward Modeling"]}],["$","span","Human Alignment",{"className":"page__taxonomy-item","children":["#","Human Alignment"]}]]}]]}]]}],["$","article","2025-10-21-UltraCUA-A-Foundation-Model-for-Computer-Use-Agents-with-Hybrid-Action",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-UltraCUA-A-Foundation-Model-for-Computer-Use-Agents-with-Hybrid-Action/","children":"[논문리뷰] UltraCUA: A Foundation Model for Computer Use Agents with Hybrid Action"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'UltraCUA: A Foundation Model for Computer Use Agents with Hybrid Action' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Computer Use Agents",{"className":"page__taxonomy-item","children":["#","Computer Use Agents"]}],["$","span","Hybrid Action",{"className":"page__taxonomy-item","children":["#","Hybrid Action"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Synthetic Data Generation",{"className":"page__taxonomy-item","children":["#","Synthetic Data Generation"]}],["$","span","Tool Learning",{"className":"page__taxonomy-item","children":["#","Tool Learning"]}],["$","span","GUI Automation",{"className":"page__taxonomy-item","children":["#","GUI Automation"]}]]}]]}]]}],["$","article","2025-10-21-Towards-Mixed-Modal-Retrieval-for-Universal-Retrieval-Augmented-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-Towards-Mixed-Modal-Retrieval-for-Universal-Retrieval-Augmented-Generation/","children":"[논문리뷰] Towards Mixed-Modal Retrieval for Universal Retrieval-Augmented Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Towards Mixed-Modal Retrieval for Universal Retrieval-Augmented Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Universal RAG",{"className":"page__taxonomy-item","children":["#","Universal RAG"]}],["$","span","Multimodal Retrieval",{"className":"page__taxonomy-item","children":["#","Multimodal Retrieval"]}],["$","span","Mixed-Modal Data Generation",{"className":"page__taxonomy-item","children":["#","Mixed-Modal Data Generation"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Matryoshka Representation Learning",{"className":"page__taxonomy-item","children":["#","Matryoshka Representation Learning"]}]]}]]}]]}],["$","article","2025-10-21-RL-makes-MLLMs-see-better-than-SFT",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-RL-makes-MLLMs-see-better-than-SFT/","children":"[논문리뷰] RL makes MLLMs see better than SFT"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'RL makes MLLMs see better than SFT' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Language Models",{"className":"page__taxonomy-item","children":["#","Multimodal Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Supervised Finetuning",{"className":"page__taxonomy-item","children":["#","Supervised Finetuning"]}],["$","span","Vision Encoder",{"className":"page__taxonomy-item","children":["#","Vision Encoder"]}],["$","span","Visual Representations",{"className":"page__taxonomy-item","children":["#","Visual Representations"]}],["$","span","Direct Preference Optimization",{"className":"page__taxonomy-item","children":["#","Direct Preference Optimization"]}],["$","span","Preference Alignment",{"className":"page__taxonomy-item","children":["#","Preference Alignment"]}],["$","span","PIVOT",{"className":"page__taxonomy-item","children":["#","PIVOT"]}]]}]]}]]}],["$","article","2025-10-21-QueST-Incentivizing-LLMs-to-Generate-Difficult-Problems",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-QueST-Incentivizing-LLMs-to-Generate-Difficult-Problems/","children":"[논문리뷰] QueST: Incentivizing LLMs to Generate Difficult Problems"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'QueST: Incentivizing LLMs to Generate Difficult Problems' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Problem Generation",{"className":"page__taxonomy-item","children":["#","Problem Generation"]}],["$","span","Competitive Programming",{"className":"page__taxonomy-item","children":["#","Competitive Programming"]}],["$","span","Synthetic Data",{"className":"page__taxonomy-item","children":["#","Synthetic Data"]}],["$","span","Difficulty Estimation",{"className":"page__taxonomy-item","children":["#","Difficulty Estimation"]}],["$","span","Rejection Fine-tuning",{"className":"page__taxonomy-item","children":["#","Rejection Fine-tuning"]}],["$","span","Graph Sampling",{"className":"page__taxonomy-item","children":["#","Graph Sampling"]}]]}]]}]]}],["$","article","2025-10-21-PICABench-How-Far-Are-We-from-Physically-Realistic-Image-Editing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-PICABench-How-Far-Are-We-from-Physically-Realistic-Image-Editing/","children":"[논문리뷰] PICABench: How Far Are We from Physically Realistic Image Editing?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kaiwen Zhu이 [arXiv]에 게시한 'PICABench: How Far Are We from Physically Realistic Image Editing?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Physical Realism",{"className":"page__taxonomy-item","children":["#","Physical Realism"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","VLM-as-a-Judge",{"className":"page__taxonomy-item","children":["#","VLM-as-a-Judge"]}],["$","span","Synthetic Data",{"className":"page__taxonomy-item","children":["#","Synthetic Data"]}],["$","span","Physics-Aware AI",{"className":"page__taxonomy-item","children":["#","Physics-Aware AI"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Evaluation Metrics",{"className":"page__taxonomy-item","children":["#","Evaluation Metrics"]}]]}]]}]]}],["$","article","2025-10-21-On-Non-interactive-Evaluation-of-Animal-Communication-Translators",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-On-Non-interactive-Evaluation-of-Animal-Communication-Translators/","children":"[논문리뷰] On Non-interactive Evaluation of Animal Communication Translators"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Adam Tauman Kalai이 [arXiv]에 게시한 'On Non-interactive Evaluation of Animal Communication Translators' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Machine Translation Quality Evaluation",{"className":"page__taxonomy-item","children":["#","Machine Translation Quality Evaluation"]}],["$","span","Reference-Free Evaluation",{"className":"page__taxonomy-item","children":["#","Reference-Free Evaluation"]}],["$","span","Animal Communication",{"className":"page__taxonomy-item","children":["#","Animal Communication"]}],["$","span","Language Models",{"className":"page__taxonomy-item","children":["#","Language Models"]}],["$","span","Shuffle Test",{"className":"page__taxonomy-item","children":["#","Shuffle Test"]}],["$","span","Conlangs",{"className":"page__taxonomy-item","children":["#","Conlangs"]}],["$","span","Non-interactive Evaluation",{"className":"page__taxonomy-item","children":["#","Non-interactive Evaluation"]}]]}]]}]]}],["$","article","2025-10-21-MultiVerse-A-Multi-Turn-Conversation-Benchmark-for-Evaluating-Large-Vision-and-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-MultiVerse-A-Multi-Turn-Conversation-Benchmark-for-Evaluating-Large-Vision-and-Language-Models/","children":"[논문리뷰] MultiVerse: A Multi-Turn Conversation Benchmark for Evaluating Large Vision and Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'MultiVerse: A Multi-Turn Conversation Benchmark for Evaluating Large Vision and Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-Turn Conversation",{"className":"page__taxonomy-item","children":["#","Multi-Turn Conversation"]}],["$","span","VLM Evaluation",{"className":"page__taxonomy-item","children":["#","VLM Evaluation"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Vision and Language Models",{"className":"page__taxonomy-item","children":["#","Vision and Language Models"]}],["$","span","Contextual Understanding",{"className":"page__taxonomy-item","children":["#","Contextual Understanding"]}],["$","span","Checklist-based Evaluation",{"className":"page__taxonomy-item","children":["#","Checklist-based Evaluation"]}],["$","span","Interactive AI",{"className":"page__taxonomy-item","children":["#","Interactive AI"]}]]}]]}]]}],["$","article","2025-10-21-Knowledge-based-Visual-Question-Answer-with-Multimodal-Processing-Retrieval-and-Filtering",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-Knowledge-based-Visual-Question-Answer-with-Multimodal-Processing-Retrieval-and-Filtering/","children":"[논문리뷰] Knowledge-based Visual Question Answer with Multimodal Processing, Retrieval and Filtering"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Knowledge-based Visual Question Answer with Multimodal Processing, Retrieval and Filtering' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Visual Question Answering",{"className":"page__taxonomy-item","children":["#","Visual Question Answering"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Knowledge Base",{"className":"page__taxonomy-item","children":["#","Knowledge Base"]}],["$","span","Tool Learning",{"className":"page__taxonomy-item","children":["#","Tool Learning"]}],["$","span","Information Filtering",{"className":"page__taxonomy-item","children":["#","Information Filtering"]}]]}]]}]]}],["$","article","2025-10-21-GuideFlow3D-Optimization-Guided-Rectified-Flow-For-Appearance-Transfer",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-GuideFlow3D-Optimization-Guided-Rectified-Flow-For-Appearance-Transfer/","children":"[논문리뷰] GuideFlow3D: Optimization-Guided Rectified Flow For Appearance Transfer"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'GuideFlow3D: Optimization-Guided Rectified Flow For Appearance Transfer' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Appearance Transfer",{"className":"page__taxonomy-item","children":["#","3D Appearance Transfer"]}],["$","span","Rectified Flow",{"className":"page__taxonomy-item","children":["#","Rectified Flow"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Optimization-Guided Sampling",{"className":"page__taxonomy-item","children":["#","Optimization-Guided Sampling"]}],["$","span","Neural Latent Representations",{"className":"page__taxonomy-item","children":["#","Neural Latent Representations"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}],["$","span","GPT-Based Evaluation",{"className":"page__taxonomy-item","children":["#","GPT-Based Evaluation"]}]]}]]}]]}],["$","article","2025-10-21-Glyph-Scaling-Context-Windows-via-Visual-Text-Compression",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-Glyph-Scaling-Context-Windows-via-Visual-Text-Compression/","children":"[논문리뷰] Glyph: Scaling Context Windows via Visual-Text Compression"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wenyi Hong이 [arXiv]에 게시한 'Glyph: Scaling Context Windows via Visual-Text Compression' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Long-Context Modeling",{"className":"page__taxonomy-item","children":["#","Long-Context Modeling"]}],["$","span","Visual Compression",{"className":"page__taxonomy-item","children":["#","Visual Compression"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Token Efficiency",{"className":"page__taxonomy-item","children":["#","Token Efficiency"]}],["$","span","Genetic Algorithms",{"className":"page__taxonomy-item","children":["#","Genetic Algorithms"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","LLM Scaling",{"className":"page__taxonomy-item","children":["#","LLM Scaling"]}]]}]]}]]}],["$","article","2025-10-21-FineVision-Open-Data-Is-All-You-Need",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-FineVision-Open-Data-Is-All-You-Need/","children":"[논문리뷰] FineVision: Open Data Is All You Need"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'FineVision: Open Data Is All You Need' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Datasets",{"className":"page__taxonomy-item","children":["#","Multimodal Datasets"]}],["$","span","VLM",{"className":"page__taxonomy-item","children":["#","VLM"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Data Hygiene",{"className":"page__taxonomy-item","children":["#","Data Hygiene"]}],["$","span","De-duplication",{"className":"page__taxonomy-item","children":["#","De-duplication"]}],["$","span","Human-in-the-loop",{"className":"page__taxonomy-item","children":["#","Human-in-the-loop"]}],["$","span","GUI Automation",{"className":"page__taxonomy-item","children":["#","GUI Automation"]}],["$","span","Test-set Decontamination",{"className":"page__taxonomy-item","children":["#","Test-set Decontamination"]}]]}]]}]]}],["$","article","2025-10-21-Executable-Knowledge-Graphs-for-Replicating-AI-Research",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-Executable-Knowledge-Graphs-for-Replicating-AI-Research/","children":"[논문리뷰] Executable Knowledge Graphs for Replicating AI Research"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Executable Knowledge Graphs for Replicating AI Research' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Research Replication",{"className":"page__taxonomy-item","children":["#","AI Research Replication"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Knowledge Graphs (KGs)",{"className":"page__taxonomy-item","children":["#","Knowledge Graphs (KGs)"]}],["$","span","Executable Code Generation",{"className":"page__taxonomy-item","children":["#","Executable Code Generation"]}],["$","span","Retrieval-Augmented Generation (RAG)",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation (RAG)"]}],["$","span","PaperBench",{"className":"page__taxonomy-item","children":["#","PaperBench"]}],["$","span","Automated AI Research",{"className":"page__taxonomy-item","children":["#","Automated AI Research"]}]]}]]}]]}],["$","article","2025-10-21-Enterprise-Deep-Research-Steerable-Multi-Agent-Deep-Research-for-Enterprise-Analytics",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-Enterprise-Deep-Research-Steerable-Multi-Agent-Deep-Research-for-Enterprise-Analytics/","children":"[논문리뷰] Enterprise Deep Research: Steerable Multi-Agent Deep Research for Enterprise Analytics"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Enterprise Deep Research: Steerable Multi-Agent Deep Research for Enterprise Analytics' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Deep Research",{"className":"page__taxonomy-item","children":["#","Deep Research"]}],["$","span","Enterprise AI",{"className":"page__taxonomy-item","children":["#","Enterprise AI"]}],["$","span","Human-in-the-Loop",{"className":"page__taxonomy-item","children":["#","Human-in-the-Loop"]}],["$","span","Steerable AI",{"className":"page__taxonomy-item","children":["#","Steerable AI"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Context Engineering",{"className":"page__taxonomy-item","children":["#","Context Engineering"]}],["$","span","Enterprise Analytics",{"className":"page__taxonomy-item","children":["#","Enterprise Analytics"]}]]}]]}]]}],["$","article","2025-10-21-Embody-3D-A-Large-scale-Multimodal-Motion-and-Behavior-Dataset",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-Embody-3D-A-Large-scale-Multimodal-Motion-and-Behavior-Dataset/","children":"[논문리뷰] Embody 3D: A Large-scale Multimodal Motion and Behavior Dataset"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Embody 3D: A Large-scale Multimodal Motion and Behavior Dataset' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Motion Dataset",{"className":"page__taxonomy-item","children":["#","3D Motion Dataset"]}],["$","span","Multimodal Data",{"className":"page__taxonomy-item","children":["#","Multimodal Data"]}],["$","span","Human Behavior",{"className":"page__taxonomy-item","children":["#","Human Behavior"]}],["$","span","Pose Tracking",{"className":"page__taxonomy-item","children":["#","Pose Tracking"]}],["$","span","Hand Tracking",{"className":"page__taxonomy-item","children":["#","Hand Tracking"]}],["$","span","Audio-Visual Data",{"className":"page__taxonomy-item","children":["#","Audio-Visual Data"]}],["$","span","Large-scale Dataset",{"className":"page__taxonomy-item","children":["#","Large-scale Dataset"]}],["$","span","SMPL-X",{"className":"page__taxonomy-item","children":["#","SMPL-X"]}]]}]]}]]}],["$","article","2025-10-21-Distractor-Injection-Attacks-on-Large-Reasoning-Models-Characterization-and-Defense",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-Distractor-Injection-Attacks-on-Large-Reasoning-Models-Characterization-and-Defense/","children":"[논문리뷰] Distractor Injection Attacks on Large Reasoning Models: Characterization and Defense"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Distractor Injection Attacks on Large Reasoning Models: Characterization and Defense' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Reasoning Models (LRMs)",{"className":"page__taxonomy-item","children":["#","Large Reasoning Models (LRMs)"]}],["$","span","Prompt Injection",{"className":"page__taxonomy-item","children":["#","Prompt Injection"]}],["$","span","Adversarial Attack",{"className":"page__taxonomy-item","children":["#","Adversarial Attack"]}],["$","span","Reasoning Distraction",{"className":"page__taxonomy-item","children":["#","Reasoning Distraction"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Robustness",{"className":"page__taxonomy-item","children":["#","Robustness"]}],["$","span","Supervised Fine-Tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning (SFT)"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}]]}]]}]]}],["$","article","2025-10-21-DeepAnalyze-Agentic-Large-Language-Models-for-Autonomous-Data-Science",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-DeepAnalyze-Agentic-Large-Language-Models-for-Autonomous-Data-Science/","children":"[논문리뷰] DeepAnalyze: Agentic Large Language Models for Autonomous Data Science"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DeepAnalyze: Agentic Large Language Models for Autonomous Data Science' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Autonomous Data Science",{"className":"page__taxonomy-item","children":["#","Autonomous Data Science"]}],["$","span","Agentic LLM",{"className":"page__taxonomy-item","children":["#","Agentic LLM"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Data Agents",{"className":"page__taxonomy-item","children":["#","Data Agents"]}],["$","span","End-to-end Data Science",{"className":"page__taxonomy-item","children":["#","End-to-end Data Science"]}]]}]]}]]}],["$","article","2025-10-21-Deep-Self-Evolving-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-Deep-Self-Evolving-Reasoning/","children":"[논문리뷰] Deep Self-Evolving Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Deep Self-Evolving Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Deep Self-Evolving Reasoning",{"className":"page__taxonomy-item","children":["#","Deep Self-Evolving Reasoning"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Iterative Reasoning",{"className":"page__taxonomy-item","children":["#","Iterative Reasoning"]}],["$","span","Markov Chain",{"className":"page__taxonomy-item","children":["#","Markov Chain"]}],["$","span","Self-Verification",{"className":"page__taxonomy-item","children":["#","Self-Verification"]}],["$","span","Self-Refinement",{"className":"page__taxonomy-item","children":["#","Self-Refinement"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","AIME Benchmark",{"className":"page__taxonomy-item","children":["#","AIME Benchmark"]}]]}]]}]]}],["$","article","2025-10-21-ConsistEdit-Highly-Consistent-and-Precise-Training-free-Visual-Editing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-ConsistEdit-Highly-Consistent-and-Precise-Training-free-Visual-Editing/","children":"[논문리뷰] ConsistEdit: Highly Consistent and Precise Training-free Visual Editing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xili Dai이 [arXiv]에 게시한 'ConsistEdit: Highly Consistent and Precise Training-free Visual Editing' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Video Editing",{"className":"page__taxonomy-item","children":["#","Video Editing"]}],["$","span","Diffusion Transformer",{"className":"page__taxonomy-item","children":["#","Diffusion Transformer"]}],["$","span","Attention Control",{"className":"page__taxonomy-item","children":["#","Attention Control"]}],["$","span","Training-free",{"className":"page__taxonomy-item","children":["#","Training-free"]}],["$","span","Multi-modal Diffusion Transformer (MM-DiT)",{"className":"page__taxonomy-item","children":["#","Multi-modal Diffusion Transformer (MM-DiT)"]}],["$","span","Consistency Preservation",{"className":"page__taxonomy-item","children":["#","Consistency Preservation"]}]]}]]}]]}],["$","article","2025-10-21-Chronos-2-From-Univariate-to-Universal-Forecasting",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-Chronos-2-From-Univariate-to-Universal-Forecasting/","children":"[논문리뷰] Chronos-2: From Univariate to Universal Forecasting"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Chronos-2: From Univariate to Universal Forecasting' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Time Series Forecasting",{"className":"page__taxonomy-item","children":["#","Time Series Forecasting"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Pretrained Models",{"className":"page__taxonomy-item","children":["#","Pretrained Models"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","In-Context Learning",{"className":"page__taxonomy-item","children":["#","In-Context Learning"]}],["$","span","Multivariate Forecasting",{"className":"page__taxonomy-item","children":["#","Multivariate Forecasting"]}],["$","span","Covariates",{"className":"page__taxonomy-item","children":["#","Covariates"]}],["$","span","Group Attention",{"className":"page__taxonomy-item","children":["#","Group Attention"]}]]}]]}]]}],["$","article","2025-10-21-Balanced-Multi-Task-Attention-for-Satellite-Image-Classification-A-Systematic-Approach-to-Achieving-97-23-Accuracy-on-EuroSAT-Without-Pre-Training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-Balanced-Multi-Task-Attention-for-Satellite-Image-Classification-A-Systematic-Approach-to-Achieving-97-23-Accuracy-on-EuroSAT-Without-Pre-Training/","children":"[논문리뷰] Balanced Multi-Task Attention for Satellite Image Classification: A Systematic Approach to Achieving 97.23% Accuracy on EuroSAT Without Pre-Training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Aditya Vir이 [arXiv]에 게시한 'Balanced Multi-Task Attention for Satellite Image Classification: A Systematic Approach to Achieving 97.23% Accuracy on EuroSAT Without Pre-Training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Satellite Image Classification",{"className":"page__taxonomy-item","children":["#","Satellite Image Classification"]}],["$","span","Multi-Task Attention",{"className":"page__taxonomy-item","children":["#","Multi-Task Attention"]}],["$","span","From-Scratch Training",{"className":"page__taxonomy-item","children":["#","From-Scratch Training"]}],["$","span","EuroSAT Dataset",{"className":"page__taxonomy-item","children":["#","EuroSAT Dataset"]}],["$","span","Squeeze-Excitation Networks",{"className":"page__taxonomy-item","children":["#","Squeeze-Excitation Networks"]}],["$","span","Coordinate Attention",{"className":"page__taxonomy-item","children":["#","Coordinate Attention"]}],["$","span","CNN",{"className":"page__taxonomy-item","children":["#","CNN"]}],["$","span","Deep Learning Architecture",{"className":"page__taxonomy-item","children":["#","Deep Learning Architecture"]}]]}]]}]]}],["$","article","2025-10-21-AsyncVoice-Agent-Real-Time-Explanation-for-LLM-Planning-and-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-AsyncVoice-Agent-Real-Time-Explanation-for-LLM-Planning-and-Reasoning/","children":"[논문리뷰] AsyncVoice Agent: Real-Time Explanation for LLM Planning and Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Nikos Vlassis이 [arXiv]에 게시한 'AsyncVoice Agent: Real-Time Explanation for LLM Planning and Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Real-Time Interaction",{"className":"page__taxonomy-item","children":["#","Real-Time Interaction"]}],["$","span","Asynchronous Agents",{"className":"page__taxonomy-item","children":["#","Asynchronous Agents"]}],["$","span","LLM Explanation",{"className":"page__taxonomy-item","children":["#","LLM Explanation"]}],["$","span","Human-AI Collaboration",{"className":"page__taxonomy-item","children":["#","Human-AI Collaboration"]}],["$","span","Voice Interface",{"className":"page__taxonomy-item","children":["#","Voice Interface"]}],["$","span","Planning and Reasoning",{"className":"page__taxonomy-item","children":["#","Planning and Reasoning"]}],["$","span","Context Management",{"className":"page__taxonomy-item","children":["#","Context Management"]}],["$","span","Interruption Handling",{"className":"page__taxonomy-item","children":["#","Interruption Handling"]}]]}]]}]]}],["$","article","2025-10-21-Annotation-Efficient-Universal-Honesty-Alignment",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-Annotation-Efficient-Universal-Honesty-Alignment/","children":"[논문리뷰] Annotation-Efficient Universal Honesty Alignment"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jingtong Wu이 [arXiv]에 게시한 'Annotation-Efficient Universal Honesty Alignment' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Honesty Alignment",{"className":"page__taxonomy-item","children":["#","LLM Honesty Alignment"]}],["$","span","Confidence Calibration",{"className":"page__taxonomy-item","children":["#","Confidence Calibration"]}],["$","span","Annotation Efficiency",{"className":"page__taxonomy-item","children":["#","Annotation Efficiency"]}],["$","span","Self-Consistency",{"className":"page__taxonomy-item","children":["#","Self-Consistency"]}],["$","span","Elicitation-Then-Calibration (EliCal)",{"className":"page__taxonomy-item","children":["#","Elicitation-Then-Calibration (EliCal)"]}],["$","span","HonestyBench",{"className":"page__taxonomy-item","children":["#","HonestyBench"]}],["$","span","LoRA",{"className":"page__taxonomy-item","children":["#","LoRA"]}],["$","span","Trustworthy AI",{"className":"page__taxonomy-item","children":["#","Trustworthy AI"]}]]}]]}]]}],["$","article","2025-10-21-Agentic-Reinforcement-Learning-for-Search-is-Unsafe",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-Agentic-Reinforcement-Learning-for-Search-is-Unsafe/","children":"[논문리뷰] Agentic Reinforcement Learning for Search is Unsafe"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Agentic Reinforcement Learning for Search is Unsafe' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Agentic Reinforcement Learning"]}],["$","span","LLM Safety",{"className":"page__taxonomy-item","children":["#","LLM Safety"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Search Models",{"className":"page__taxonomy-item","children":["#","Search Models"]}],["$","span","Jailbreaking",{"className":"page__taxonomy-item","children":["#","Jailbreaking"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}],["$","span","Vulnerability",{"className":"page__taxonomy-item","children":["#","Vulnerability"]}]]}]]}]]}],["$","article","2025-10-20-VISTA-A-Test-Time-Self-Improving-Video-Generation-Agent",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-VISTA-A-Test-Time-Self-Improving-Video-Generation-Agent/","children":"[논문리뷰] VISTA: A Test-Time Self-Improving Video Generation Agent"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Tomas Pfister이 [arXiv]에 게시한 'VISTA: A Test-Time Self-Improving Video Generation Agent' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Video Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Video Generation"]}],["$","span","Prompt Optimization",{"className":"page__taxonomy-item","children":["#","Prompt Optimization"]}],["$","span","Multi-Agent System",{"className":"page__taxonomy-item","children":["#","Multi-Agent System"]}],["$","span","Test-Time Improvement",{"className":"page__taxonomy-item","children":["#","Test-Time Improvement"]}],["$","span","MLLM-as-a-Judge",{"className":"page__taxonomy-item","children":["#","MLLM-as-a-Judge"]}],["$","span","Video Evaluation",{"className":"page__taxonomy-item","children":["#","Video Evaluation"]}],["$","span","Audio-Video Synthesis",{"className":"page__taxonomy-item","children":["#","Audio-Video Synthesis"]}]]}]]}]]}],["$","article","2025-10-20-Train-a-Unified-Multimodal-Data-Quality-Classifier-with-Synthetic-Data",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-Train-a-Unified-Multimodal-Data-Quality-Classifier-with-Synthetic-Data/","children":"[논문리뷰] Train a Unified Multimodal Data Quality Classifier with Synthetic Data"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ritesh Sarkhel이 [arXiv]에 게시한 'Train a Unified Multimodal Data Quality Classifier with Synthetic Data' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Data Quality",{"className":"page__taxonomy-item","children":["#","Multimodal Data Quality"]}],["$","span","MLLM",{"className":"page__taxonomy-item","children":["#","MLLM"]}],["$","span","Synthetic Data",{"className":"page__taxonomy-item","children":["#","Synthetic Data"]}],["$","span","Data Filtering",{"className":"page__taxonomy-item","children":["#","Data Filtering"]}],["$","span","Image-Text Captioning",{"className":"page__taxonomy-item","children":["#","Image-Text Captioning"]}],["$","span","Interleaved Document Analysis",{"className":"page__taxonomy-item","children":["#","Interleaved Document Analysis"]}],["$","span","Pre-training",{"className":"page__taxonomy-item","children":["#","Pre-training"]}]]}]]}]]}],["$","article","2025-10-20-Skyfall-GS-Synthesizing-Immersive-3D-Urban-Scenes-from-Satellite-Imagery",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-Skyfall-GS-Synthesizing-Immersive-3D-Urban-Scenes-from-Satellite-Imagery/","children":"[논문리뷰] Skyfall-GS: Synthesizing Immersive 3D Urban Scenes from Satellite Imagery"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chung-Ho Wu이 [arXiv]에 게시한 'Skyfall-GS: Synthesizing Immersive 3D Urban Scenes from Satellite Imagery' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Scene Synthesis",{"className":"page__taxonomy-item","children":["#","3D Scene Synthesis"]}],["$","span","Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","Gaussian Splatting"]}],["$","span","Satellite Imagery",{"className":"page__taxonomy-item","children":["#","Satellite Imagery"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Urban Modeling",{"className":"page__taxonomy-item","children":["#","Urban Modeling"]}],["$","span","Novel View Synthesis",{"className":"page__taxonomy-item","children":["#","Novel View Synthesis"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Real-time Rendering",{"className":"page__taxonomy-item","children":["#","Real-time Rendering"]}]]}]]}]]}],["$","article","2025-10-20-Scaling-Instruction-Based-Video-Editing-with-a-High-Quality-Synthetic-Dataset",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-Scaling-Instruction-Based-Video-Editing-with-a-High-Quality-Synthetic-Dataset/","children":"[논문리뷰] Scaling Instruction-Based Video Editing with a High-Quality Synthetic Dataset"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hao Ouyang이 [arXiv]에 게시한 'Scaling Instruction-Based Video Editing with a High-Quality Synthetic Dataset' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Editing",{"className":"page__taxonomy-item","children":["#","Video Editing"]}],["$","span","Instruction-Based Editing",{"className":"page__taxonomy-item","children":["#","Instruction-Based Editing"]}],["$","span","Synthetic Data Generation",{"className":"page__taxonomy-item","children":["#","Synthetic Data Generation"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}]]}]]}]]}],["$","article","2025-10-20-Robust-Layerwise-Scaling-Rules-by-Proper-Weight-Decay-Tuning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-Robust-Layerwise-Scaling-Rules-by-Proper-Weight-Decay-Tuning/","children":"[논문리뷰] Robust Layerwise Scaling Rules by Proper Weight Decay Tuning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Robust Layerwise Scaling Rules by Proper Weight Decay Tuning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Weight Decay Scaling",{"className":"page__taxonomy-item","children":["#","Weight Decay Scaling"]}],["$","span","Maximal-Update Parameterization (µP)",{"className":"page__taxonomy-item","children":["#","Maximal-Update Parameterization (µP)"]}],["$","span","AdamW",{"className":"page__taxonomy-item","children":["#","AdamW"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Hyperparameter Transfer",{"className":"page__taxonomy-item","children":["#","Hyperparameter Transfer"]}],["$","span","Scaling Laws",{"className":"page__taxonomy-item","children":["#","Scaling Laws"]}],["$","span","Singular Value Spectrum",{"className":"page__taxonomy-item","children":["#","Singular Value Spectrum"]}],["$","span","Steady State Training",{"className":"page__taxonomy-item","children":["#","Steady State Training"]}]]}]]}]]}],["$","article","2025-10-20-Rewiring-Experts-on-the-FlyContinuous-Rerouting-for-Better-Online-Adaptation-in-Mixture-of-Expert-models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-Rewiring-Experts-on-the-FlyContinuous-Rerouting-for-Better-Online-Adaptation-in-Mixture-of-Expert-models/","children":"[논문리뷰] Rewiring Experts on the Fly:Continuous Rerouting for Better Online Adaptation in Mixture-of-Expert models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shiwei Liu이 [arXiv]에 게시한 'Rewiring Experts on the Fly:Continuous Rerouting for Better Online Adaptation in Mixture-of-Expert models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Mixture-of-Experts (MoE)",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts (MoE)"]}],["$","span","Online Adaptation",{"className":"page__taxonomy-item","children":["#","Online Adaptation"]}],["$","span","Test-Time Adaptation (TTA)",{"className":"page__taxonomy-item","children":["#","Test-Time Adaptation (TTA)"]}],["$","span","Expert Routing",{"className":"page__taxonomy-item","children":["#","Expert Routing"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Self-Supervision",{"className":"page__taxonomy-item","children":["#","Self-Supervision"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}],["$","span","Context Shift Robustness",{"className":"page__taxonomy-item","children":["#","Context Shift Robustness"]}]]}]]}]]}],["$","article","2025-10-20-Paper2Web-Lets-Make-Your-Paper-Alive",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-Paper2Web-Lets-Make-Your-Paper-Alive/","children":"[논문리뷰] Paper2Web: Let's Make Your Paper Alive!"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yao Wan이 [arXiv]에 게시한 'Paper2Web: Let's Make Your Paper Alive!' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Academic Webpage Generation",{"className":"page__taxonomy-item","children":["#","Academic Webpage Generation"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Model Context Protocol",{"className":"page__taxonomy-item","children":["#","Model Context Protocol"]}],["$","span","Interactive Content",{"className":"page__taxonomy-item","children":["#","Interactive Content"]}],["$","span","Multimedia Dissemination",{"className":"page__taxonomy-item","children":["#","Multimedia Dissemination"]}],["$","span","Evaluation Benchmark",{"className":"page__taxonomy-item","children":["#","Evaluation Benchmark"]}],["$","span","Human-Computer Interaction",{"className":"page__taxonomy-item","children":["#","Human-Computer Interaction"]}]]}]]}]]}],["$","article","2025-10-20-OmniVinci-Enhancing-Architecture-and-Data-for-Omni-Modal-Understanding-LLM",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-OmniVinci-Enhancing-Architecture-and-Data-for-Omni-Modal-Understanding-LLM/","children":"[논문리뷰] OmniVinci: Enhancing Architecture and Data for Omni-Modal Understanding LLM"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'OmniVinci: Enhancing Architecture and Data for Omni-Modal Understanding LLM' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Omni-Modal LLM",{"className":"page__taxonomy-item","children":["#","Omni-Modal LLM"]}],["$","span","Multimodal Understanding",{"className":"page__taxonomy-item","children":["#","Multimodal Understanding"]}],["$","span","Vision-Audio Alignment",{"className":"page__taxonomy-item","children":["#","Vision-Audio Alignment"]}],["$","span","Temporal Reasoning",{"className":"page__taxonomy-item","children":["#","Temporal Reasoning"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Rotary Time Embedding",{"className":"page__taxonomy-item","children":["#","Rotary Time Embedding"]}]]}]]}]]}],["$","article","2025-10-20-NANO3D-A-Training-Free-Approach-for-Efficient-3D-Editing-Without-Masks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-NANO3D-A-Training-Free-Approach-for-Efficient-3D-Editing-Without-Masks/","children":"[논문리뷰] NANO3D: A Training-Free Approach for Efficient 3D Editing Without Masks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hongyu Yan이 [arXiv]에 게시한 'NANO3D: A Training-Free Approach for Efficient 3D Editing Without Masks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Object Editing",{"className":"page__taxonomy-item","children":["#","3D Object Editing"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}],["$","span","FlowEdit",{"className":"page__taxonomy-item","children":["#","FlowEdit"]}],["$","span","Mask-Free",{"className":"page__taxonomy-item","children":["#","Mask-Free"]}],["$","span","Deep Generative Models",{"className":"page__taxonomy-item","children":["#","Deep Generative Models"]}],["$","span","TRELLIS",{"className":"page__taxonomy-item","children":["#","TRELLIS"]}],["$","span","Data Generation",{"className":"page__taxonomy-item","children":["#","Data Generation"]}],["$","span","Geometric Consistency",{"className":"page__taxonomy-item","children":["#","Geometric Consistency"]}]]}]]}]]}],["$","article","2025-10-20-MorphoBench-A-Benchmark-with-Difficulty-Adaptive-to-Model-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-MorphoBench-A-Benchmark-with-Difficulty-Adaptive-to-Model-Reasoning/","children":"[논문리뷰] MorphoBench: A Benchmark with Difficulty Adaptive to Model Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'MorphoBench: A Benchmark with Difficulty Adaptive to Model Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Reasoning Benchmark",{"className":"page__taxonomy-item","children":["#","Reasoning Benchmark"]}],["$","span","Difficulty Adaptation",{"className":"page__taxonomy-item","children":["#","Difficulty Adaptation"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Proof Graph",{"className":"page__taxonomy-item","children":["#","Proof Graph"]}],["$","span","Agent Recognition",{"className":"page__taxonomy-item","children":["#","Agent Recognition"]}],["$","span","Automated Question Generation",{"className":"page__taxonomy-item","children":["#","Automated Question Generation"]}]]}]]}]]}],["$","article","2025-10-20-LightsOut-Diffusion-based-Outpainting-for-Enhanced-Lens-Flare-Removal",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-LightsOut-Diffusion-based-Outpainting-for-Enhanced-Lens-Flare-Removal/","children":"[논문리뷰] LightsOut: Diffusion-based Outpainting for Enhanced Lens Flare Removal"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'LightsOut: Diffusion-based Outpainting for Enhanced Lens Flare Removal' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Lens Flare Removal",{"className":"page__taxonomy-item","children":["#","Lens Flare Removal"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Image Outpainting",{"className":"page__taxonomy-item","children":["#","Image Outpainting"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}],["$","span","Image Restoration",{"className":"page__taxonomy-item","children":["#","Image Restoration"]}],["$","span","Preprocessing",{"className":"page__taxonomy-item","children":["#","Preprocessing"]}],["$","span","LoRA",{"className":"page__taxonomy-item","children":["#","LoRA"]}]]}]]}]]}],["$","article","2025-10-20-Latent-Diffusion-Model-without-Variational-Autoencoder",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-Latent-Diffusion-Model-without-Variational-Autoencoder/","children":"[논문리뷰] Latent Diffusion Model without Variational Autoencoder"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Latent Diffusion Model without Variational Autoencoder' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Latent Diffusion Model",{"className":"page__taxonomy-item","children":["#","Latent Diffusion Model"]}],["$","span","Variational Autoencoder",{"className":"page__taxonomy-item","children":["#","Variational Autoencoder"]}],["$","span","Self-supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-supervised Learning"]}],["$","span","DINO Features",{"className":"page__taxonomy-item","children":["#","DINO Features"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Training Efficiency",{"className":"page__taxonomy-item","children":["#","Training Efficiency"]}],["$","span","Unified Representation",{"className":"page__taxonomy-item","children":["#","Unified Representation"]}]]}]]}]]}],["$","article","2025-10-20-Language-Models-Model-Language",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-Language-Models-Model-Language/","children":"[논문리뷰] Language Models Model Language"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Language Models Model Language' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Linguistics",{"className":"page__taxonomy-item","children":["#","Linguistics"]}],["$","span","Witold Mańczak",{"className":"page__taxonomy-item","children":["#","Witold Mańczak"]}],["$","span","Frequency Hypothesis",{"className":"page__taxonomy-item","children":["#","Frequency Hypothesis"]}],["$","span","Empirical Validation",{"className":"page__taxonomy-item","children":["#","Empirical Validation"]}],["$","span","Usage-Based Linguistics",{"className":"page__taxonomy-item","children":["#","Usage-Based Linguistics"]}],["$","span","Semantic Embeddings",{"className":"page__taxonomy-item","children":["#","Semantic Embeddings"]}]]}]]}]]}],["$","article","2025-10-20-InfiMed-ORBIT-Aligning-LLMs-on-Open-Ended-Complex-Tasks-via-Rubric-Based-Incremental-Training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-InfiMed-ORBIT-Aligning-LLMs-on-Open-Ended-Complex-Tasks-via-Rubric-Based-Incremental-Training/","children":"[논문리뷰] InfiMed-ORBIT: Aligning LLMs on Open-Ended Complex Tasks via Rubric-Based Incremental Training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Congkai Xie이 [arXiv]에 게시한 'InfiMed-ORBIT: Aligning LLMs on Open-Ended Complex Tasks via Rubric-Based Incremental Training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Rubric-Based Training",{"className":"page__taxonomy-item","children":["#","Rubric-Based Training"]}],["$","span","Medical Dialogue",{"className":"page__taxonomy-item","children":["#","Medical Dialogue"]}],["$","span","Open-Ended Tasks",{"className":"page__taxonomy-item","children":["#","Open-Ended Tasks"]}],["$","span","HealthBench",{"className":"page__taxonomy-item","children":["#","HealthBench"]}],["$","span","RAG",{"className":"page__taxonomy-item","children":["#","RAG"]}]]}]]}]]}],["$","article","2025-10-20-Imaginarium-Vision-guided-High-Quality-3D-Scene-Layout-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-Imaginarium-Vision-guided-High-Quality-3D-Scene-Layout-Generation/","children":"[논문리뷰] Imaginarium: Vision-guided High-Quality 3D Scene Layout Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Junsheng Yu이 [arXiv]에 게시한 'Imaginarium: Vision-guided High-Quality 3D Scene Layout Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Scene Layout Generation",{"className":"page__taxonomy-item","children":["#","3D Scene Layout Generation"]}],["$","span","Vision-guided",{"className":"page__taxonomy-item","children":["#","Vision-guided"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Scene Graph",{"className":"page__taxonomy-item","children":["#","Scene Graph"]}],["$","span","Asset Retrieval",{"className":"page__taxonomy-item","children":["#","Asset Retrieval"]}],["$","span","Pose Estimation",{"className":"page__taxonomy-item","children":["#","Pose Estimation"]}],["$","span","High-Quality Assets",{"className":"page__taxonomy-item","children":["#","High-Quality Assets"]}],["$","span","AI Content Creation",{"className":"page__taxonomy-item","children":["#","AI Content Creation"]}]]}]]}]]}],["$","article","2025-10-20-Foundation-Models-for-Scientific-Discovery-From-Paradigm-Enhancement-to-Paradigm-Transition",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-Foundation-Models-for-Scientific-Discovery-From-Paradigm-Enhancement-to-Paradigm-Transition/","children":"[논문리뷰] Foundation Models for Scientific Discovery: From Paradigm Enhancement to Paradigm Transition"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Foundation Models for Scientific Discovery: From Paradigm Enhancement to Paradigm Transition' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Scientific Discovery",{"className":"page__taxonomy-item","children":["#","Scientific Discovery"]}],["$","span","Paradigm Shift",{"className":"page__taxonomy-item","children":["#","Paradigm Shift"]}],["$","span","Human-AI Collaboration",{"className":"page__taxonomy-item","children":["#","Human-AI Collaboration"]}],["$","span","Autonomous Agents",{"className":"page__taxonomy-item","children":["#","Autonomous Agents"]}],["$","span","Meta-Science",{"className":"page__taxonomy-item","children":["#","Meta-Science"]}],["$","span","Experimental Design",{"className":"page__taxonomy-item","children":["#","Experimental Design"]}],["$","span","Hypothesis Generation",{"className":"page__taxonomy-item","children":["#","Hypothesis Generation"]}]]}]]}]]}],["$","article","2025-10-20-FinTrust-A-Comprehensive-Benchmark-of-Trustworthiness-Evaluation-in-Finance-Domain",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-FinTrust-A-Comprehensive-Benchmark-of-Trustworthiness-Evaluation-in-Finance-Domain/","children":"[논문리뷰] FinTrust: A Comprehensive Benchmark of Trustworthiness Evaluation in Finance Domain"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Arman Cohan이 [arXiv]에 게시한 'FinTrust: A Comprehensive Benchmark of Trustworthiness Evaluation in Finance Domain' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Trustworthiness",{"className":"page__taxonomy-item","children":["#","LLM Trustworthiness"]}],["$","span","Finance Domain",{"className":"page__taxonomy-item","children":["#","Finance Domain"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Alignment Evaluation",{"className":"page__taxonomy-item","children":["#","Alignment Evaluation"]}],["$","span","Financial AI",{"className":"page__taxonomy-item","children":["#","Financial AI"]}],["$","span","Hallucination",{"className":"page__taxonomy-item","children":["#","Hallucination"]}],["$","span","Privacy",{"className":"page__taxonomy-item","children":["#","Privacy"]}],["$","span","Fairness",{"className":"page__taxonomy-item","children":["#","Fairness"]}]]}]]}]]}],["$","article","2025-10-20-Explore-to-Evolve-Scaling-Evolved-Aggregation-Logic-via-Proactive-Online-Exploration-for-Deep-Research-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-Explore-to-Evolve-Scaling-Evolved-Aggregation-Logic-via-Proactive-Online-Exploration-for-Deep-Research-Agents/","children":"[논문리뷰] Explore to Evolve: Scaling Evolved Aggregation Logic via Proactive Online Exploration for Deep Research Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jianshu Zhang이 [arXiv]에 게시한 'Explore to Evolve: Scaling Evolved Aggregation Logic via Proactive Online Exploration for Deep Research Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Web Agents",{"className":"page__taxonomy-item","children":["#","Web Agents"]}],["$","span","Information Aggregation",{"className":"page__taxonomy-item","children":["#","Information Aggregation"]}],["$","span","Data Synthesis",{"className":"page__taxonomy-item","children":["#","Data Synthesis"]}],["$","span","Online Exploration",{"className":"page__taxonomy-item","children":["#","Online Exploration"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Multi-hop QA",{"className":"page__taxonomy-item","children":["#","Multi-hop QA"]}],["$","span","Deep Research",{"className":"page__taxonomy-item","children":["#","Deep Research"]}]]}]]}]]}],["$","article","2025-10-20-Emergent-Misalignment-via-In-Context-Learning-Narrow-in-context-examples-can-produce-broadly-misaligned-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-Emergent-Misalignment-via-In-Context-Learning-Narrow-in-context-examples-can-produce-broadly-misaligned-LLMs/","children":"[논문리뷰] Emergent Misalignment via In-Context Learning: Narrow in-context examples can produce broadly misaligned LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kevin Zhu이 [arXiv]에 게시한 'Emergent Misalignment via In-Context Learning: Narrow in-context examples can produce broadly misaligned LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Emergent Misalignment",{"className":"page__taxonomy-item","children":["#","Emergent Misalignment"]}],["$","span","In-Context Learning",{"className":"page__taxonomy-item","children":["#","In-Context Learning"]}],["$","span","LLM Safety",{"className":"page__taxonomy-item","children":["#","LLM Safety"]}],["$","span","Persona Rationalization",{"className":"page__taxonomy-item","children":["#","Persona Rationalization"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","Model Alignment",{"className":"page__taxonomy-item","children":["#","Model Alignment"]}]]}]]}]]}],["$","article","2025-10-20-ERGO-Entropy-guided-Resetting-for-Generation-Optimization-in-Multi-turn-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-ERGO-Entropy-guided-Resetting-for-Generation-Optimization-in-Multi-turn-Language-Models/","children":"[논문리뷰] ERGO: Entropy-guided Resetting for Generation Optimization in Multi-turn Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Sean O'Brien이 [arXiv]에 게시한 'ERGO: Entropy-guided Resetting for Generation Optimization in Multi-turn Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-turn Conversation",{"className":"page__taxonomy-item","children":["#","Multi-turn Conversation"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Context Management",{"className":"page__taxonomy-item","children":["#","Context Management"]}],["$","span","Entropy-guided Resetting",{"className":"page__taxonomy-item","children":["#","Entropy-guided Resetting"]}],["$","span","Uncertainty Quantification",{"className":"page__taxonomy-item","children":["#","Uncertainty Quantification"]}],["$","span","Performance Degradation",{"className":"page__taxonomy-item","children":["#","Performance Degradation"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","Conversational AI",{"className":"page__taxonomy-item","children":["#","Conversational AI"]}]]}]]}]]}],["$","article","2025-10-20-DriveGen3D-Boosting-Feed-Forward-Driving-Scene-Generation-with-Efficient-Video-Diffusion",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-DriveGen3D-Boosting-Feed-Forward-Driving-Scene-Generation-with-Efficient-Video-Diffusion/","children":"[논문리뷰] DriveGen3D: Boosting Feed-Forward Driving Scene Generation with Efficient Video Diffusion"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DriveGen3D: Boosting Feed-Forward Driving Scene Generation with Efficient Video Diffusion' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Driving Scene Generation",{"className":"page__taxonomy-item","children":["#","Driving Scene Generation"]}],["$","span","Video Diffusion",{"className":"page__taxonomy-item","children":["#","Video Diffusion"]}],["$","span","3D Reconstruction",{"className":"page__taxonomy-item","children":["#","3D Reconstruction"]}],["$","span","Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","Gaussian Splatting"]}],["$","span","Feed-Forward Models",{"className":"page__taxonomy-item","children":["#","Feed-Forward Models"]}],["$","span","Temporal Coherence",{"className":"page__taxonomy-item","children":["#","Temporal Coherence"]}],["$","span","Multimodal Control",{"className":"page__taxonomy-item","children":["#","Multimodal Control"]}]]}]]}]]}],["$","article","2025-10-20-DLER-Doing-Length-pEnalty-Right-Incentivizing-More-Intelligence-per-Token-via-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-DLER-Doing-Length-pEnalty-Right-Incentivizing-More-Intelligence-per-Token-via-Reinforcement-Learning/","children":"[논문리뷰] DLER: Doing Length pEnalty Right - Incentivizing More Intelligence per Token via Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DLER: Doing Length pEnalty Right - Incentivizing More Intelligence per Token via Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Length Penalty",{"className":"page__taxonomy-item","children":["#","Length Penalty"]}],["$","span","Reasoning Efficiency",{"className":"page__taxonomy-item","children":["#","Reasoning Efficiency"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","RL Optimization",{"className":"page__taxonomy-item","children":["#","RL Optimization"]}],["$","span","Accuracy-Efficiency Trade-off",{"className":"page__taxonomy-item","children":["#","Accuracy-Efficiency Trade-off"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}]]}]]}]]}],["$","article","2025-10-20-Build-Your-Personalized-Research-Group-A-Multiagent-Framework-for-Continual-and-Interactive-Science-Automation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-Build-Your-Personalized-Research-Group-A-Multiagent-Framework-for-Continual-and-Interactive-Science-Automation/","children":"[논문리뷰] Build Your Personalized Research Group: A Multiagent Framework for Continual and Interactive Science Automation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Cat Yan이 [arXiv]에 게시한 'Build Your Personalized Research Group: A Multiagent Framework for Continual and Interactive Science Automation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multiagent Systems",{"className":"page__taxonomy-item","children":["#","Multiagent Systems"]}],["$","span","Science Automation",{"className":"page__taxonomy-item","children":["#","Science Automation"]}],["$","span","Dynamic Workflows",{"className":"page__taxonomy-item","children":["#","Dynamic Workflows"]}],["$","span","Workspace-based Communication",{"className":"page__taxonomy-item","children":["#","Workspace-based Communication"]}],["$","span","Context Compaction",{"className":"page__taxonomy-item","children":["#","Context Compaction"]}],["$","span","Human-in-the-loop AI",{"className":"page__taxonomy-item","children":["#","Human-in-the-loop AI"]}],["$","span","Open-source Framework",{"className":"page__taxonomy-item","children":["#","Open-source Framework"]}]]}]]}]]}],["$","article","2025-10-20-BLIP3o-NEXT-Next-Frontier-of-Native-Image-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-BLIP3o-NEXT-Next-Frontier-of-Native-Image-Generation/","children":"[논문리뷰] BLIP3o-NEXT: Next Frontier of Native Image Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'BLIP3o-NEXT: Next Frontier of Native Image Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Autoregressive Model",{"className":"page__taxonomy-item","children":["#","Autoregressive Model"]}],["$","span","Diffusion Model",{"className":"page__taxonomy-item","children":["#","Diffusion Model"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Foundation Model",{"className":"page__taxonomy-item","children":["#","Foundation Model"]}],["$","span","Open-source",{"className":"page__taxonomy-item","children":["#","Open-source"]}]]}]]}]]}],["$","article","2025-10-20-A2FM-An-Adaptive-Agent-Foundation-Model-for-Tool-Aware-Hybrid-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-A2FM-An-Adaptive-Agent-Foundation-Model-for-Tool-Aware-Hybrid-Reasoning/","children":"[논문리뷰] A^2FM: An Adaptive Agent Foundation Model for Tool-Aware Hybrid Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'A^2FM: An Adaptive Agent Foundation Model for Tool-Aware Hybrid Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Adaptive Agent",{"className":"page__taxonomy-item","children":["#","Adaptive Agent"]}],["$","span","Foundation Model",{"className":"page__taxonomy-item","children":["#","Foundation Model"]}],["$","span","Hybrid Reasoning",{"className":"page__taxonomy-item","children":["#","Hybrid Reasoning"]}],["$","span","Tool-Aware LLM",{"className":"page__taxonomy-item","children":["#","Tool-Aware LLM"]}],["$","span","Mode Selection",{"className":"page__taxonomy-item","children":["#","Mode Selection"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Cost Efficiency",{"className":"page__taxonomy-item","children":["#","Cost Efficiency"]}],["$","span","LLM Agent",{"className":"page__taxonomy-item","children":["#","LLM Agent"]}]]}]]}]]}],["$","article","2025-10-17-pi-Flow-Policy-Based-Few-Step-Generation-via-Imitation-Distillation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-pi-Flow-Policy-Based-Few-Step-Generation-via-Imitation-Distillation/","children":"[논문리뷰] pi-Flow: Policy-Based Few-Step Generation via Imitation Distillation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'pi-Flow: Policy-Based Few-Step Generation via Imitation Distillation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Model Distillation",{"className":"page__taxonomy-item","children":["#","Model Distillation"]}],["$","span","Imitation Learning",{"className":"page__taxonomy-item","children":["#","Imitation Learning"]}],["$","span","Few-Step Generation",{"className":"page__taxonomy-item","children":["#","Few-Step Generation"]}],["$","span","Policy-Based AI",{"className":"page__taxonomy-item","children":["#","Policy-Based AI"]}],["$","span","Text-to-Image",{"className":"page__taxonomy-item","children":["#","Text-to-Image"]}]]}]]}]]}],["$","article","2025-10-17-WithAnyone-Towards-Controllable-and-ID-Consistent-Image-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-WithAnyone-Towards-Controllable-and-ID-Consistent-Image-Generation/","children":"[논문리뷰] WithAnyone: Towards Controllable and ID Consistent Image Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'WithAnyone: Towards Controllable and ID Consistent Image Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Identity-Consistent Generation",{"className":"page__taxonomy-item","children":["#","Identity-Consistent Generation"]}],["$","span","Text-to-Image Diffusion",{"className":"page__taxonomy-item","children":["#","Text-to-Image Diffusion"]}],["$","span","Copy-Paste Artifacts",{"className":"page__taxonomy-item","children":["#","Copy-Paste Artifacts"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Multi-Identity Dataset",{"className":"page__taxonomy-item","children":["#","Multi-Identity Dataset"]}],["$","span","Controllable Generation",{"className":"page__taxonomy-item","children":["#","Controllable Generation"]}],["$","span","ID-Preservation",{"className":"page__taxonomy-item","children":["#","ID-Preservation"]}]]}]]}]]}],["$","article","2025-10-17-When-Models-Lie-We-Learn-Multilingual-Span-Level-Hallucination-Detection-with-PsiloQA",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-When-Models-Lie-We-Learn-Multilingual-Span-Level-Hallucination-Detection-with-PsiloQA/","children":"[논문리뷰] When Models Lie, We Learn: Multilingual Span-Level Hallucination Detection with PsiloQA"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Artem Vazhentsev이 [arXiv]에 게시한 'When Models Lie, We Learn: Multilingual Span-Level Hallucination Detection with PsiloQA' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Hallucination Detection",{"className":"page__taxonomy-item","children":["#","Hallucination Detection"]}],["$","span","Multilingual LLMs",{"className":"page__taxonomy-item","children":["#","Multilingual LLMs"]}],["$","span","Span-Level Annotation",{"className":"page__taxonomy-item","children":["#","Span-Level Annotation"]}],["$","span","Synthetic Data Generation",{"className":"page__taxonomy-item","children":["#","Synthetic Data Generation"]}],["$","span","Question Answering (QA)",{"className":"page__taxonomy-item","children":["#","Question Answering (QA)"]}],["$","span","Encoder Models",{"className":"page__taxonomy-item","children":["#","Encoder Models"]}],["$","span","Uncertainty Quantification",{"className":"page__taxonomy-item","children":["#","Uncertainty Quantification"]}],["$","span","GPT-4o",{"className":"page__taxonomy-item","children":["#","GPT-4o"]}]]}]]}]]}],["$","article","2025-10-17-VR-Thinker-Boosting-Video-Reward-Models-through-Thinking-with-Image-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-VR-Thinker-Boosting-Video-Reward-Models-through-Thinking-with-Image-Reasoning/","children":"[논문리뷰] VR-Thinker: Boosting Video Reward Models through Thinking-with-Image Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'VR-Thinker: Boosting Video Reward Models through Thinking-with-Image Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Reward Models",{"className":"page__taxonomy-item","children":["#","Video Reward Models"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","span","Thinking-with-Image",{"className":"page__taxonomy-item","children":["#","Thinking-with-Image"]}],["$","span","Visual Reasoning",{"className":"page__taxonomy-item","children":["#","Visual Reasoning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Context Management",{"className":"page__taxonomy-item","children":["#","Context Management"]}]]}]]}]]}],["$","article","2025-10-17-VLA2-Empowering-Vision-Language-Action-Models-with-an-Agentic-Framework-for-Unseen-Concept-Manipulation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-VLA2-Empowering-Vision-Language-Action-Models-with-an-Agentic-Framework-for-Unseen-Concept-Manipulation/","children":"[논문리뷰] VLA^2: Empowering Vision-Language-Action Models with an Agentic Framework for Unseen Concept Manipulation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'VLA^2: Empowering Vision-Language-Action Models with an Agentic Framework for Unseen Concept Manipulation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action Models"]}],["$","span","Agentic Framework",{"className":"page__taxonomy-item","children":["#","Agentic Framework"]}],["$","span","Unseen Concept Manipulation",{"className":"page__taxonomy-item","children":["#","Unseen Concept Manipulation"]}],["$","span","Out-of-Distribution Generalization",{"className":"page__taxonomy-item","children":["#","Out-of-Distribution Generalization"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Web Retrieval",{"className":"page__taxonomy-item","children":["#","Web Retrieval"]}],["$","span","Object Detection",{"className":"page__taxonomy-item","children":["#","Object Detection"]}],["$","span","LIBERO Simulation",{"className":"page__taxonomy-item","children":["#","LIBERO Simulation"]}]]}]]}]]}],["$","article","2025-10-17-VLA-0-Building-State-of-the-Art-VLAs-with-Zero-Modification",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-VLA-0-Building-State-of-the-Art-VLAs-with-Zero-Modification/","children":"[논문리뷰] VLA-0: Building State-of-the-Art VLAs with Zero Modification"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'VLA-0: Building State-of-the-Art VLAs with Zero Modification' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action Models"]}],["$","span","VLA-0",{"className":"page__taxonomy-item","children":["#","VLA-0"]}],["$","span","Zero Modification",{"className":"page__taxonomy-item","children":["#","Zero Modification"]}],["$","span","Text-based Action Prediction",{"className":"page__taxonomy-item","children":["#","Text-based Action Prediction"]}],["$","span","Robot Manipulation",{"className":"page__taxonomy-item","children":["#","Robot Manipulation"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","State-of-the-Art",{"className":"page__taxonomy-item","children":["#","State-of-the-Art"]}]]}]]}]]}],["$","article","2025-10-17-VIST3A-Text-to-3D-by-Stitching-a-Multi-view-Reconstruction-Network-to-a-Video-Generator",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-VIST3A-Text-to-3D-by-Stitching-a-Multi-view-Reconstruction-Network-to-a-Video-Generator/","children":"[논문리뷰] VIST3A: Text-to-3D by Stitching a Multi-view Reconstruction Network to a Video Generator"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Federico Tombari이 [arXiv]에 게시한 'VIST3A: Text-to-3D by Stitching a Multi-view Reconstruction Network to a Video Generator' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-3D",{"className":"page__taxonomy-item","children":["#","Text-to-3D"]}],["$","span","Model Stitching",{"className":"page__taxonomy-item","children":["#","Model Stitching"]}],["$","span","Multi-view Reconstruction",{"className":"page__taxonomy-item","children":["#","Multi-view Reconstruction"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Latent Diffusion Models",{"className":"page__taxonomy-item","children":["#","Latent Diffusion Models"]}],["$","span","Gaussian Splats",{"className":"page__taxonomy-item","children":["#","Gaussian Splats"]}],["$","span","Pointmaps",{"className":"page__taxonomy-item","children":["#","Pointmaps"]}],["$","span","Reward Finetuning",{"className":"page__taxonomy-item","children":["#","Reward Finetuning"]}]]}]]}]]}],["$","article","2025-10-17-TokDrift-When-LLM-Speaks-in-Subwords-but-Code-Speaks-in-Grammar",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-TokDrift-When-LLM-Speaks-in-Subwords-but-Code-Speaks-in-Grammar/","children":"[논문리뷰] TokDrift: When LLM Speaks in Subwords but Code Speaks in Grammar"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'TokDrift: When LLM Speaks in Subwords but Code Speaks in Grammar' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Code LLMs",{"className":"page__taxonomy-item","children":["#","Code LLMs"]}],["$","span","Subword Tokenization",{"className":"page__taxonomy-item","children":["#","Subword Tokenization"]}],["$","span","Grammar-aware Tokenization",{"className":"page__taxonomy-item","children":["#","Grammar-aware Tokenization"]}],["$","span","Semantic Preservation",{"className":"page__taxonomy-item","children":["#","Semantic Preservation"]}],["$","span","Rewrite Rules",{"className":"page__taxonomy-item","children":["#","Rewrite Rules"]}],["$","span","Model Robustness",{"className":"page__taxonomy-item","children":["#","Model Robustness"]}],["$","span","Tokenization Misalignment",{"className":"page__taxonomy-item","children":["#","Tokenization Misalignment"]}]]}]]}]]}],["$","article","2025-10-17-The-German-Commons-154-Billion-Tokens-of-Openly-Licensed-Text-for-German-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-The-German-Commons-154-Billion-Tokens-of-Openly-Licensed-Text-for-German-Language-Models/","children":"[논문리뷰] The German Commons - 154 Billion Tokens of Openly Licensed Text for German Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'The German Commons - 154 Billion Tokens of Openly Licensed Text for German Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","German Commons",{"className":"page__taxonomy-item","children":["#","German Commons"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Training Data",{"className":"page__taxonomy-item","children":["#","Training Data"]}],["$","span","Openly Licensed Text",{"className":"page__taxonomy-item","children":["#","Openly Licensed Text"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","German NLP",{"className":"page__taxonomy-item","children":["#","German NLP"]}],["$","span","Corpus Construction",{"className":"page__taxonomy-item","children":["#","Corpus Construction"]}],["$","span","Quality Filtering",{"className":"page__taxonomy-item","children":["#","Quality Filtering"]}]]}]]}]]}],["$","article","2025-10-17-SCas4D-Structural-Cascaded-Optimization-for-Boosting-Persistent-4D-Novel-View-Synthesis",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-SCas4D-Structural-Cascaded-Optimization-for-Boosting-Persistent-4D-Novel-View-Synthesis/","children":"[논문리뷰] SCas4D: Structural Cascaded Optimization for Boosting Persistent 4D Novel View Synthesis"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'SCas4D: Structural Cascaded Optimization for Boosting Persistent 4D Novel View Synthesis' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","4D Novel View Synthesis",{"className":"page__taxonomy-item","children":["#","4D Novel View Synthesis"]}],["$","span","Dynamic Scenes",{"className":"page__taxonomy-item","children":["#","Dynamic Scenes"]}],["$","span","3D Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","3D Gaussian Splatting"]}],["$","span","Cascaded Optimization",{"className":"page__taxonomy-item","children":["#","Cascaded Optimization"]}],["$","span","Deformation Modeling",{"className":"page__taxonomy-item","children":["#","Deformation Modeling"]}],["$","span","Point Tracking",{"className":"page__taxonomy-item","children":["#","Point Tracking"]}],["$","span","Object Segmentation",{"className":"page__taxonomy-item","children":["#","Object Segmentation"]}]]}]]}]]}],["$","article","2025-10-17-RefusalBench-Generative-Evaluation-of-Selective-Refusal-in-Grounded-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-RefusalBench-Generative-Evaluation-of-Selective-Refusal-in-Grounded-Language-Models/","children":"[논문리뷰] RefusalBench: Generative Evaluation of Selective Refusal in Grounded Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'RefusalBench: Generative Evaluation of Selective Refusal in Grounded Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","RAG Systems",{"className":"page__taxonomy-item","children":["#","RAG Systems"]}],["$","span","Selective Refusal",{"className":"page__taxonomy-item","children":["#","Selective Refusal"]}],["$","span","Generative Evaluation",{"className":"page__taxonomy-item","children":["#","Generative Evaluation"]}],["$","span","Linguistic Perturbations",{"className":"page__taxonomy-item","children":["#","Linguistic Perturbations"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Informational Uncertainty",{"className":"page__taxonomy-item","children":["#","Informational Uncertainty"]}],["$","span","Model Calibration",{"className":"page__taxonomy-item","children":["#","Model Calibration"]}],["$","span","AI Safety",{"className":"page__taxonomy-item","children":["#","AI Safety"]}]]}]]}]]}],["$","article","2025-10-17-RealDPO-Real-or-Not-Real-that-is-the-Preference",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-RealDPO-Real-or-Not-Real-that-is-the-Preference/","children":"[논문리뷰] RealDPO: Real or Not Real, that is the Preference"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chenyang Si이 [arXiv]에 게시한 'RealDPO: Real or Not Real, that is the Preference' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Direct Preference Optimization",{"className":"page__taxonomy-item","children":["#","Direct Preference Optimization"]}],["$","span","Preference Learning",{"className":"page__taxonomy-item","children":["#","Preference Learning"]}],["$","span","Real Data",{"className":"page__taxonomy-item","children":["#","Real Data"]}],["$","span","Human Motion Synthesis",{"className":"page__taxonomy-item","children":["#","Human Motion Synthesis"]}],["$","span","RealDPO",{"className":"page__taxonomy-item","children":["#","RealDPO"]}],["$","span","RealAction-5K",{"className":"page__taxonomy-item","children":["#","RealAction-5K"]}]]}]]}]]}],["$","article","2025-10-17-RAGCap-Bench-Benchmarking-Capabilities-of-LLMs-in-Agentic-Retrieval-Augmented-Generation-Systems",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-RAGCap-Bench-Benchmarking-Capabilities-of-LLMs-in-Agentic-Retrieval-Augmented-Generation-Systems/","children":"[논문리뷰] RAGCap-Bench: Benchmarking Capabilities of LLMs in Agentic Retrieval Augmented Generation Systems"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'RAGCap-Bench: Benchmarking Capabilities of LLMs in Agentic Retrieval Augmented Generation Systems' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Retrieval Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval Augmented Generation"]}],["$","span","Agentic Systems",{"className":"page__taxonomy-item","children":["#","Agentic Systems"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Intermediate Tasks",{"className":"page__taxonomy-item","children":["#","Intermediate Tasks"]}],["$","span","Error Analysis",{"className":"page__taxonomy-item","children":["#","Error Analysis"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}]]}]]}]]}],["$","article","2025-10-17-Qwen3Guard-Technical-Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-Qwen3Guard-Technical-Report/","children":"[논문리뷰] Qwen3Guard Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Qwen3Guard Technical Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Safety",{"className":"page__taxonomy-item","children":["#","LLM Safety"]}],["$","span","Guardrail Models",{"className":"page__taxonomy-item","children":["#","Guardrail Models"]}],["$","span","Multilingual AI",{"className":"page__taxonomy-item","children":["#","Multilingual AI"]}],["$","span","Real-time Moderation",{"className":"page__taxonomy-item","children":["#","Real-time Moderation"]}],["$","span","Tri-class Classification",{"className":"page__taxonomy-item","children":["#","Tri-class Classification"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}],["$","span","Streaming Inference",{"className":"page__taxonomy-item","children":["#","Streaming Inference"]}]]}]]}]]}],["$","article","2025-10-17-Ponimator-Unfolding-Interactive-Pose-for-Versatile-Human-human-Interaction-Animation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-Ponimator-Unfolding-Interactive-Pose-for-Versatile-Human-human-Interaction-Animation/","children":"[논문리뷰] Ponimator: Unfolding Interactive Pose for Versatile Human-human Interaction Animation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Ponimator: Unfolding Interactive Pose for Versatile Human-human Interaction Animation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Human-human Interaction",{"className":"page__taxonomy-item","children":["#","Human-human Interaction"]}],["$","span","Pose Animation",{"className":"page__taxonomy-item","children":["#","Pose Animation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Motion Synthesis",{"className":"page__taxonomy-item","children":["#","Motion Synthesis"]}],["$","span","Interactive Poses",{"className":"page__taxonomy-item","children":["#","Interactive Poses"]}],["$","span","Temporal Priors",{"className":"page__taxonomy-item","children":["#","Temporal Priors"]}],["$","span","Spatial Priors",{"className":"page__taxonomy-item","children":["#","Spatial Priors"]}]]}]]}]]}],["$","article","2025-10-17-PaddleOCR-VL-Boosting-Multilingual-Document-Parsing-via-a-0-9B-Ultra-Compact-Vision-Language-Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-PaddleOCR-VL-Boosting-Multilingual-Document-Parsing-via-a-0-9B-Ultra-Compact-Vision-Language-Model/","children":"[논문리뷰] PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Document Parsing",{"className":"page__taxonomy-item","children":["#","Document Parsing"]}],["$","span","Vision-Language Model",{"className":"page__taxonomy-item","children":["#","Vision-Language Model"]}],["$","span","Multilingual OCR",{"className":"page__taxonomy-item","children":["#","Multilingual OCR"]}],["$","span","Layout Analysis",{"className":"page__taxonomy-item","children":["#","Layout Analysis"]}],["$","span","Resource-Efficient AI",{"className":"page__taxonomy-item","children":["#","Resource-Efficient AI"]}],["$","span","Table Recognition",{"className":"page__taxonomy-item","children":["#","Table Recognition"]}],["$","span","Formula Recognition",{"className":"page__taxonomy-item","children":["#","Formula Recognition"]}],["$","span","Chart Recognition",{"className":"page__taxonomy-item","children":["#","Chart Recognition"]}]]}]]}]]}],["$","article","2025-10-17-On-Pretraining-for-Project-Level-Code-Completion",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-On-Pretraining-for-Project-Level-Code-Completion/","children":"[논문리뷰] On Pretraining for Project-Level Code Completion"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'On Pretraining for Project-Level Code Completion' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Code LLMs",{"className":"page__taxonomy-item","children":["#","Code LLMs"]}],["$","span","Project-level Context",{"className":"page__taxonomy-item","children":["#","Project-level Context"]}],["$","span","Code Completion",{"className":"page__taxonomy-item","children":["#","Code Completion"]}],["$","span","Context Window Extension",{"className":"page__taxonomy-item","children":["#","Context Window Extension"]}],["$","span","RoPE Scaling",{"className":"page__taxonomy-item","children":["#","RoPE Scaling"]}],["$","span","Repository Pretraining",{"className":"page__taxonomy-item","children":["#","Repository Pretraining"]}],["$","span","Long Code Arena",{"className":"page__taxonomy-item","children":["#","Long Code Arena"]}]]}]]}]]}],["$","article","2025-10-17-MoM-Mixtures-of-Scenario-Aware-Document-Memories-for-Retrieval-Augmented-Generation-Systems",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-MoM-Mixtures-of-Scenario-Aware-Document-Memories-for-Retrieval-Augmented-Generation-Systems/","children":"[논문리뷰] MoM: Mixtures of Scenario-Aware Document Memories for Retrieval-Augmented Generation Systems"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Feiyu Xiong이 [arXiv]에 게시한 'MoM: Mixtures of Scenario-Aware Document Memories for Retrieval-Augmented Generation Systems' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Retrieval-Augmented Generation (RAG)",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation (RAG)"]}],["$","span","Document Memory",{"className":"page__taxonomy-item","children":["#","Document Memory"]}],["$","span","Text Chunking",{"className":"page__taxonomy-item","children":["#","Text Chunking"]}],["$","span","Small Language Models (SLMs)",{"className":"page__taxonomy-item","children":["#","Small Language Models (SLMs)"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Scenario-Aware Processing",{"className":"page__taxonomy-item","children":["#","Scenario-Aware Processing"]}],["$","span","Multi-Layer Retrieval",{"className":"page__taxonomy-item","children":["#","Multi-Layer Retrieval"]}],["$","span","Cognitive Simulation",{"className":"page__taxonomy-item","children":["#","Cognitive Simulation"]}]]}]]}]]}],["$","article","2025-10-17-MathCanvas-Intrinsic-Visual-Chain-of-Thought-for-Multimodal-Mathematical-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-MathCanvas-Intrinsic-Visual-Chain-of-Thought-for-Multimodal-Mathematical-Reasoning/","children":"[논문리뷰] MathCanvas: Intrinsic Visual Chain-of-Thought for Multimodal Mathematical Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ke Wang이 [arXiv]에 게시한 'MathCanvas: Intrinsic Visual Chain-of-Thought for Multimodal Mathematical Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","span","Visual Chain-of-Thought (VCoT)",{"className":"page__taxonomy-item","children":["#","Visual Chain-of-Thought (VCoT)"]}],["$","span","Large Multimodal Models (LMMs)",{"className":"page__taxonomy-item","children":["#","Large Multimodal Models (LMMs)"]}],["$","span","Geometric Reasoning",{"className":"page__taxonomy-item","children":["#","Geometric Reasoning"]}],["$","span","Diagram Generation",{"className":"page__taxonomy-item","children":["#","Diagram Generation"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}]]}]]}]]}],["$","article","2025-10-17-LiteStage-Latency-aware-Layer-Skipping-for-Multi-stage-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-LiteStage-Latency-aware-Layer-Skipping-for-Multi-stage-Reasoning/","children":"[논문리뷰] LiteStage: Latency-aware Layer Skipping for Multi-stage Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'LiteStage: Latency-aware Layer Skipping for Multi-stage Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Layer Skipping",{"className":"page__taxonomy-item","children":["#","Layer Skipping"]}],["$","span","Multi-stage Reasoning",{"className":"page__taxonomy-item","children":["#","Multi-stage Reasoning"]}],["$","span","Latency Optimization",{"className":"page__taxonomy-item","children":["#","Latency Optimization"]}],["$","span","Early Exit",{"className":"page__taxonomy-item","children":["#","Early Exit"]}],["$","span","Small Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Small Language Models (LLMs)"]}],["$","span","Adaptive Computation",{"className":"page__taxonomy-item","children":["#","Adaptive Computation"]}],["$","span","Confidence-based Decoding",{"className":"page__taxonomy-item","children":["#","Confidence-based Decoding"]}]]}]]}]]}],["$","article","2025-10-17-Learning-an-Image-Editing-Model-without-Image-Editing-Pairs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-Learning-an-Image-Editing-Model-without-Image-Editing-Pairs/","children":"[논문리뷰] Learning an Image Editing Model without Image Editing Pairs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Learning an Image Editing Model without Image Editing Pairs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Vision-Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision-Language Models (VLMs)"]}],["$","span","No-Pair Training",{"className":"page__taxonomy-item","children":["#","No-Pair Training"]}],["$","span","Few-step Generation",{"className":"page__taxonomy-item","children":["#","Few-step Generation"]}],["$","span","Distribution Matching",{"className":"page__taxonomy-item","children":["#","Distribution Matching"]}],["$","span","Gradient-based Optimization",{"className":"page__taxonomy-item","children":["#","Gradient-based Optimization"]}]]}]]}]]}],["$","article","2025-10-17-Large-Language-Models-Do-NOT-Really-Know-What-They-Dont-Know",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-Large-Language-Models-Do-NOT-Really-Know-What-They-Dont-Know/","children":"[논문리뷰] Large Language Models Do NOT Really Know What They Don't Know"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Large Language Models Do NOT Really Know What They Don't Know' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Hallucination Detection",{"className":"page__taxonomy-item","children":["#","Hallucination Detection"]}],["$","span","Mechanistic Interpretability",{"className":"page__taxonomy-item","children":["#","Mechanistic Interpretability"]}],["$","span","Internal States",{"className":"page__taxonomy-item","children":["#","Internal States"]}],["$","span","Knowledge Recall",{"className":"page__taxonomy-item","children":["#","Knowledge Recall"]}],["$","span","Refusal Tuning",{"className":"page__taxonomy-item","children":["#","Refusal Tuning"]}],["$","span","Factual Associations",{"className":"page__taxonomy-item","children":["#","Factual Associations"]}],["$","span","Associated Hallucinations",{"className":"page__taxonomy-item","children":["#","Associated Hallucinations"]}]]}]]}]]}],["$","article","2025-10-17-LaSeR-Reinforcement-Learning-with-Last-Token-Self-Rewarding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-LaSeR-Reinforcement-Learning-with-Last-Token-Self-Rewarding/","children":"[논문리뷰] LaSeR: Reinforcement Learning with Last-Token Self-Rewarding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'LaSeR: Reinforcement Learning with Last-Token Self-Rewarding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Self-Verification",{"className":"page__taxonomy-item","children":["#","Self-Verification"]}],["$","span","Last-Token",{"className":"page__taxonomy-item","children":["#","Last-Token"]}],["$","span","Reward Modeling",{"className":"page__taxonomy-item","children":["#","Reward Modeling"]}],["$","span","Efficiency",{"className":"page__taxonomy-item","children":["#","Efficiency"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","RLVR",{"className":"page__taxonomy-item","children":["#","RLVR"]}]]}]]}]]}],["$","article","2025-10-17-LLMs-as-Scalable-General-Purpose-Simulators-For-Evolving-Digital-Agent-Training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-LLMs-as-Scalable-General-Purpose-Simulators-For-Evolving-Digital-Agent-Training/","children":"[논문리뷰] LLMs as Scalable, General-Purpose Simulators For Evolving Digital Agent Training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'LLMs as Scalable, General-Purpose Simulators For Evolving Digital Agent Training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Digital Agents",{"className":"page__taxonomy-item","children":["#","Digital Agents"]}],["$","span","UI Simulation",{"className":"page__taxonomy-item","children":["#","UI Simulation"]}],["$","span","Synthetic Data Generation",{"className":"page__taxonomy-item","children":["#","Synthetic Data Generation"]}],["$","span","Targeted Data Synthesis",{"className":"page__taxonomy-item","children":["#","Targeted Data Synthesis"]}],["$","span","World Models",{"className":"page__taxonomy-item","children":["#","World Models"]}]]}]]}]]}],["$","article","2025-10-17-LLM-guided-Hierarchical-Retrieval",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-LLM-guided-Hierarchical-Retrieval/","children":"[논문리뷰] LLM-guided Hierarchical Retrieval"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'LLM-guided Hierarchical Retrieval' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Information Retrieval",{"className":"page__taxonomy-item","children":["#","Information Retrieval"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Hierarchical Retrieval",{"className":"page__taxonomy-item","children":["#","Hierarchical Retrieval"]}],["$","span","Semantic Tree",{"className":"page__taxonomy-item","children":["#","Semantic Tree"]}],["$","span","Tree Traversal",{"className":"page__taxonomy-item","children":["#","Tree Traversal"]}],["$","span","Zero-shot Performance",{"className":"page__taxonomy-item","children":["#","Zero-shot Performance"]}],["$","span","Reasoning-based Retrieval",{"className":"page__taxonomy-item","children":["#","Reasoning-based Retrieval"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}]]}]]}]]}],["$","article","2025-10-17-Information-Gain-based-Policy-Optimization-A-Simple-and-Effective-Approach-for-Multi-Turn-LLM-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-Information-Gain-based-Policy-Optimization-A-Simple-and-Effective-Approach-for-Multi-Turn-LLM-Agents/","children":"[논문리뷰] Information Gain-based Policy Optimization: A Simple and Effective Approach for Multi-Turn LLM Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Information Gain-based Policy Optimization: A Simple and Effective Approach for Multi-Turn LLM Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Multi-Turn Interactions",{"className":"page__taxonomy-item","children":["#","Multi-Turn Interactions"]}],["$","span","Reward Sparsity",{"className":"page__taxonomy-item","children":["#","Reward Sparsity"]}],["$","span","Information Gain",{"className":"page__taxonomy-item","children":["#","Information Gain"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Ground-Truth Awareness",{"className":"page__taxonomy-item","children":["#","Ground-Truth Awareness"]}],["$","span","Sample Efficiency",{"className":"page__taxonomy-item","children":["#","Sample Efficiency"]}]]}]]}]]}],["$","article","2025-10-17-ImagerySearch-Adaptive-Test-Time-Search-for-Video-Generation-Beyond-Semantic-Dependency-Constraints",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-ImagerySearch-Adaptive-Test-Time-Search-for-Video-Generation-Beyond-Semantic-Dependency-Constraints/","children":"[논문리뷰] ImagerySearch: Adaptive Test-Time Search for Video Generation Beyond Semantic Dependency Constraints"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'ImagerySearch: Adaptive Test-Time Search for Video Generation Beyond Semantic Dependency Constraints' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Test-Time Search",{"className":"page__taxonomy-item","children":["#","Test-Time Search"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Semantic Dependency",{"className":"page__taxonomy-item","children":["#","Semantic Dependency"]}],["$","span","Adaptive Reward",{"className":"page__taxonomy-item","children":["#","Adaptive Reward"]}],["$","span","Evaluation Benchmark",{"className":"page__taxonomy-item","children":["#","Evaluation Benchmark"]}],["$","span","Prompt-Guided",{"className":"page__taxonomy-item","children":["#","Prompt-Guided"]}]]}]]}]]}],["$","article","2025-10-17-From-Pixels-to-Words-Towards-Native-Vision-Language-Primitives-at-Scale",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-From-Pixels-to-Words-Towards-Native-Vision-Language-Primitives-at-Scale/","children":"[논문리뷰] From Pixels to Words -- Towards Native Vision-Language Primitives at Scale"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'From Pixels to Words -- Towards Native Vision-Language Primitives at Scale' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Native VLMs",{"className":"page__taxonomy-item","children":["#","Native VLMs"]}],["$","span","Early Fusion",{"className":"page__taxonomy-item","children":["#","Early Fusion"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Rotary Position Embeddings",{"className":"page__taxonomy-item","children":["#","Rotary Position Embeddings"]}],["$","span","Pixel-Word Alignment",{"className":"page__taxonomy-item","children":["#","Pixel-Word Alignment"]}],["$","span","End-to-End Training",{"className":"page__taxonomy-item","children":["#","End-to-End Training"]}]]}]]}]]}],["$","article","2025-10-17-Fantastic-small-Retrievers-and-How-to-Train-Them-mxbai-edge-colbert-v0-Tech-Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-Fantastic-small-Retrievers-and-How-to-Train-Them-mxbai-edge-colbert-v0-Tech-Report/","children":"[논문리뷰] Fantastic (small) Retrievers and How to Train Them: mxbai-edge-colbert-v0 Tech Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Fantastic (small) Retrievers and How to Train Them: mxbai-edge-colbert-v0 Tech Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","ColBERT",{"className":"page__taxonomy-item","children":["#","ColBERT"]}],["$","span","Retrieval Models",{"className":"page__taxonomy-item","children":["#","Retrieval Models"]}],["$","span","Small Models",{"className":"page__taxonomy-item","children":["#","Small Models"]}],["$","span","Distillation",{"className":"page__taxonomy-item","children":["#","Distillation"]}],["$","span","Long Context",{"className":"page__taxonomy-item","children":["#","Long Context"]}],["$","span","Edge AI",{"className":"page__taxonomy-item","children":["#","Edge AI"]}],["$","span","Information Retrieval",{"className":"page__taxonomy-item","children":["#","Information Retrieval"]}],["$","span","RAG",{"className":"page__taxonomy-item","children":["#","RAG"]}]]}]]}]]}],["$","article","2025-10-17-Expertise-need-not-monopolize-Action-Specialized-Mixture-of-Experts-for-Vision-Language-Action-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-Expertise-need-not-monopolize-Action-Specialized-Mixture-of-Experts-for-Vision-Language-Action-Learning/","children":"[논문리뷰] Expertise need not monopolize: Action-Specialized Mixture of Experts for Vision-Language-Action Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Sijia Gu이 [arXiv]에 게시한 'Expertise need not monopolize: Action-Specialized Mixture of Experts for Vision-Language-Action Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action (VLA)",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action (VLA)"]}],["$","span","Mixture of Experts (MoE)",{"className":"page__taxonomy-item","children":["#","Mixture of Experts (MoE)"]}],["$","span","Robotic Manipulation",{"className":"page__taxonomy-item","children":["#","Robotic Manipulation"]}],["$","span","Expert Specialization",{"className":"page__taxonomy-item","children":["#","Expert Specialization"]}],["$","span","Decoupled Routing",{"className":"page__taxonomy-item","children":["#","Decoupled Routing"]}],["$","span","Load Balancing",{"className":"page__taxonomy-item","children":["#","Load Balancing"]}],["$","span","Transfer Learning",{"className":"page__taxonomy-item","children":["#","Transfer Learning"]}]]}]]}]]}],["$","article","2025-10-17-Efficient-Parallel-Samplers-for-Recurrent-Depth-Models-and-Their-Connection-to-Diffusion-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-Efficient-Parallel-Samplers-for-Recurrent-Depth-Models-and-Their-Connection-to-Diffusion-Language-Models/","children":"[논문리뷰] Efficient Parallel Samplers for Recurrent-Depth Models and Their Connection to Diffusion Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Efficient Parallel Samplers for Recurrent-Depth Models and Their Connection to Diffusion Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Recurrent-Depth Models",{"className":"page__taxonomy-item","children":["#","Recurrent-Depth Models"]}],["$","span","Diffusion Forcing",{"className":"page__taxonomy-item","children":["#","Diffusion Forcing"]}],["$","span","Parallel Sampling",{"className":"page__taxonomy-item","children":["#","Parallel Sampling"]}],["$","span","LLM Inference Acceleration",{"className":"page__taxonomy-item","children":["#","LLM Inference Acceleration"]}],["$","span","Transformer Architectures",{"className":"page__taxonomy-item","children":["#","Transformer Architectures"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Latent Space Diffusion",{"className":"page__taxonomy-item","children":["#","Latent Space Diffusion"]}]]}]]}]]}],["$","article","2025-10-17-DialectGen-Benchmarking-and-Improving-Dialect-Robustness-in-Multimodal-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-DialectGen-Benchmarking-and-Improving-Dialect-Robustness-in-Multimodal-Generation/","children":"[논문리뷰] DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Generation",{"className":"page__taxonomy-item","children":["#","Multimodal Generation"]}],["$","span","Dialect Robustness",{"className":"page__taxonomy-item","children":["#","Dialect Robustness"]}],["$","span","Text-to-Image",{"className":"page__taxonomy-item","children":["#","Text-to-Image"]}],["$","span","Text-to-Video",{"className":"page__taxonomy-item","children":["#","Text-to-Video"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Text Encoder Tuning",{"className":"page__taxonomy-item","children":["#","Text Encoder Tuning"]}],["$","span","Low-Resource Dialects",{"className":"page__taxonomy-item","children":["#","Low-Resource Dialects"]}]]}]]}]]}],["$","article","2025-10-17-COIG-Writer-A-High-Quality-Dataset-for-Chinese-Creative-Writing-with-Thought-Processes",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-COIG-Writer-A-High-Quality-Dataset-for-Chinese-Creative-Writing-with-Thought-Processes/","children":"[논문리뷰] COIG-Writer: A High-Quality Dataset for Chinese Creative Writing with Thought Processes"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'COIG-Writer: A High-Quality Dataset for Chinese Creative Writing with Thought Processes' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Chinese Creative Writing",{"className":"page__taxonomy-item","children":["#","Chinese Creative Writing"]}],["$","span","Process Supervision",{"className":"page__taxonomy-item","children":["#","Process Supervision"]}],["$","span","LLM Training",{"className":"page__taxonomy-item","children":["#","LLM Training"]}],["$","span","Dataset Creation",{"className":"page__taxonomy-item","children":["#","Dataset Creation"]}],["$","span","Cross-Lingual Transfer",{"className":"page__taxonomy-item","children":["#","Cross-Lingual Transfer"]}],["$","span","Narrative Logic",{"className":"page__taxonomy-item","children":["#","Narrative Logic"]}],["$","span","Linguistic Expression",{"className":"page__taxonomy-item","children":["#","Linguistic Expression"]}],["$","span","Type-Token Ratio",{"className":"page__taxonomy-item","children":["#","Type-Token Ratio"]}]]}]]}]]}],["$","article","2025-10-17-BitNet-Distillation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-BitNet-Distillation/","children":"[논문리뷰] BitNet Distillation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'BitNet Distillation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Low-bit Quantization",{"className":"page__taxonomy-item","children":["#","Low-bit Quantization"]}],["$","span","LLM Compression",{"className":"page__taxonomy-item","children":["#","LLM Compression"]}],["$","span","Knowledge Distillation",{"className":"page__taxonomy-item","children":["#","Knowledge Distillation"]}],["$","span","Ternary Weights",{"className":"page__taxonomy-item","children":["#","Ternary Weights"]}],["$","span","Inference Optimization",{"className":"page__taxonomy-item","children":["#","Inference Optimization"]}],["$","span","Memory Efficiency",{"className":"page__taxonomy-item","children":["#","Memory Efficiency"]}],["$","span","SubLN",{"className":"page__taxonomy-item","children":["#","SubLN"]}],["$","span","Continual Pre-training",{"className":"page__taxonomy-item","children":["#","Continual Pre-training"]}]]}]]}]]}],["$","article","2025-10-17-Beyond-One-World-Benchmarking-Super-Heros-in-Role-Playing-Across-Multiversal-Contexts",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-Beyond-One-World-Benchmarking-Super-Heros-in-Role-Playing-Across-Multiversal-Contexts/","children":"[논문리뷰] Beyond One World: Benchmarking Super Heros in Role-Playing Across Multiversal Contexts"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Beyond One World: Benchmarking Super Heros in Role-Playing Across Multiversal Contexts' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Role-playing LLMs",{"className":"page__taxonomy-item","children":["#","Role-playing LLMs"]}],["$","span","Multiversal Consistency",{"className":"page__taxonomy-item","children":["#","Multiversal Consistency"]}],["$","span","Character Benchmarking",{"className":"page__taxonomy-item","children":["#","Character Benchmarking"]}],["$","span","Moral Dilemmas",{"className":"page__taxonomy-item","children":["#","Moral Dilemmas"]}],["$","span","Canon Events",{"className":"page__taxonomy-item","children":["#","Canon Events"]}],["$","span","Reasoning-Acting Alignment",{"className":"page__taxonomy-item","children":["#","Reasoning-Acting Alignment"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Superheroes",{"className":"page__taxonomy-item","children":["#","Superheroes"]}]]}]]}]]}],["$","article","2025-10-17-Beyond-Correctness-Evaluating-Subjective-Writing-Preferences-Across-Cultures",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-Beyond-Correctness-Evaluating-Subjective-Writing-Preferences-Across-Cultures/","children":"[논문리뷰] Beyond Correctness: Evaluating Subjective Writing Preferences Across Cultures"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Beyond Correctness: Evaluating Subjective Writing Preferences Across Cultures' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Subjective Preference Learning",{"className":"page__taxonomy-item","children":["#","Subjective Preference Learning"]}],["$","span","Writing Evaluation",{"className":"page__taxonomy-item","children":["#","Writing Evaluation"]}],["$","span","Reward Models",{"className":"page__taxonomy-item","children":["#","Reward Models"]}],["$","span","RLHF",{"className":"page__taxonomy-item","children":["#","RLHF"]}],["$","span","Cross-Cultural AI",{"className":"page__taxonomy-item","children":["#","Cross-Cultural AI"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Language Model Judges",{"className":"page__taxonomy-item","children":["#","Language Model Judges"]}],["$","span","Genre Instability",{"className":"page__taxonomy-item","children":["#","Genre Instability"]}]]}]]}]]}],["$","article","2025-10-17-Attention-Is-All-You-Need-for-KV-Cache-in-Diffusion-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-Attention-Is-All-You-Need-for-KV-Cache-in-Diffusion-LLMs/","children":"[논문리뷰] Attention Is All You Need for KV Cache in Diffusion LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Attention Is All You Need for KV Cache in Diffusion LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion LLMs",{"className":"page__taxonomy-item","children":["#","Diffusion LLMs"]}],["$","span","KV Cache",{"className":"page__taxonomy-item","children":["#","KV Cache"]}],["$","span","Adaptive Caching",{"className":"page__taxonomy-item","children":["#","Adaptive Caching"]}],["$","span","Inference Optimization",{"className":"page__taxonomy-item","children":["#","Inference Optimization"]}],["$","span","Attention Mechanism",{"className":"page__taxonomy-item","children":["#","Attention Mechanism"]}],["$","span","Latency Reduction",{"className":"page__taxonomy-item","children":["#","Latency Reduction"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}]]}]]}]]}],["$","article","2025-10-17-Agentic-Entropy-Balanced-Policy-Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-Agentic-Entropy-Balanced-Policy-Optimization/","children":"[논문리뷰] Agentic Entropy-Balanced Policy Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Agentic Entropy-Balanced Policy Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Agentic Reinforcement Learning"]}],["$","span","Web Agents",{"className":"page__taxonomy-item","children":["#","Web Agents"]}],["$","span","Tool Learning",{"className":"page__taxonomy-item","children":["#","Tool Learning"]}],["$","span","Entropy Balancing",{"className":"page__taxonomy-item","children":["#","Entropy Balancing"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Rollout Strategy",{"className":"page__taxonomy-item","children":["#","Rollout Strategy"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}]]}]]}]]}],["$","article","2025-10-17-AI-for-Service-Proactive-Assistance-with-AI-Glasses",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-AI-for-Service-Proactive-Assistance-with-AI-Glasses/","children":"[논문리뷰] AI for Service: Proactive Assistance with AI Glasses"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'AI for Service: Proactive Assistance with AI Glasses' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI for Service",{"className":"page__taxonomy-item","children":["#","AI for Service"]}],["$","span","Proactive AI",{"className":"page__taxonomy-item","children":["#","Proactive AI"]}],["$","span","AI Glasses",{"className":"page__taxonomy-item","children":["#","AI Glasses"]}],["$","span","Multi-agent System",{"className":"page__taxonomy-item","children":["#","Multi-agent System"]}],["$","span","Human-AI Interaction",{"className":"page__taxonomy-item","children":["#","Human-AI Interaction"]}],["$","span","Context-aware AI",{"className":"page__taxonomy-item","children":["#","Context-aware AI"]}],["$","span","Wearable AI",{"className":"page__taxonomy-item","children":["#","Wearable AI"]}]]}]]}]]}],["$","article","2025-10-16-X-VLA-Soft-Prompted-Transformer-as-Scalable-Cross-Embodiment-Vision-Language-Action-Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-X-VLA-Soft-Prompted-Transformer-as-Scalable-Cross-Embodiment-Vision-Language-Action-Model/","children":"[논문리뷰] X-VLA: Soft-Prompted Transformer as Scalable Cross-Embodiment Vision-Language-Action Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xirui Kang이 [arXiv]에 게시한 'X-VLA: Soft-Prompted Transformer as Scalable Cross-Embodiment Vision-Language-Action Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action (VLA) Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action (VLA) Models"]}],["$","span","Soft Prompts",{"className":"page__taxonomy-item","children":["#","Soft Prompts"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Cross-Embodiment",{"className":"page__taxonomy-item","children":["#","Cross-Embodiment"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Pretraining",{"className":"page__taxonomy-item","children":["#","Pretraining"]}],["$","span","Domain Adaptation",{"className":"page__taxonomy-item","children":["#","Domain Adaptation"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}]]}]]}]]}],["$","article","2025-10-16-Universal-Image-Restoration-Pre-training-via-Masked-Degradation-Classification",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-Universal-Image-Restoration-Pre-training-via-Masked-Degradation-Classification/","children":"[논문리뷰] Universal Image Restoration Pre-training via Masked Degradation Classification"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Universal Image Restoration Pre-training via Masked Degradation Classification' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Universal Image Restoration",{"className":"page__taxonomy-item","children":["#","Universal Image Restoration"]}],["$","span","Pre-training",{"className":"page__taxonomy-item","children":["#","Pre-training"]}],["$","span","Masked Image Modeling",{"className":"page__taxonomy-item","children":["#","Masked Image Modeling"]}],["$","span","Degradation Classification",{"className":"page__taxonomy-item","children":["#","Degradation Classification"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}],["$","span","Computer Vision",{"className":"page__taxonomy-item","children":["#","Computer Vision"]}],["$","span","Self-supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-supervised Learning"]}],["$","span","Low-level Vision",{"className":"page__taxonomy-item","children":["#","Low-level Vision"]}]]}]]}]]}],["$","article","2025-10-16-UniMoE-Audio-Unified-Speech-and-Music-Generation-with-Dynamic-Capacity-MoE",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-UniMoE-Audio-Unified-Speech-and-Music-Generation-with-Dynamic-Capacity-MoE/","children":"[논문리뷰] UniMoE-Audio: Unified Speech and Music Generation with Dynamic-Capacity MoE"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'UniMoE-Audio: Unified Speech and Music Generation with Dynamic-Capacity MoE' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Mixture of Experts",{"className":"page__taxonomy-item","children":["#","Mixture of Experts"]}],["$","span","Speech Generation",{"className":"page__taxonomy-item","children":["#","Speech Generation"]}],["$","span","Music Generation",{"className":"page__taxonomy-item","children":["#","Music Generation"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Dynamic Routing",{"className":"page__taxonomy-item","children":["#","Dynamic Routing"]}],["$","span","Training Curriculum",{"className":"page__taxonomy-item","children":["#","Training Curriculum"]}],["$","span","Data Imbalance",{"className":"page__taxonomy-item","children":["#","Data Imbalance"]}],["$","span","Audio Synthesis",{"className":"page__taxonomy-item","children":["#","Audio Synthesis"]}]]}]]}]]}],["$","article","2025-10-16-UniME-V2-MLLM-as-a-Judge-for-Universal-Multimodal-Embedding-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-UniME-V2-MLLM-as-a-Judge-for-Universal-Multimodal-Embedding-Learning/","children":"[논문리뷰] UniME-V2: MLLM-as-a-Judge for Universal Multimodal Embedding Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ziyong Feng이 [arXiv]에 게시한 'UniME-V2: MLLM-as-a-Judge for Universal Multimodal Embedding Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Embeddings",{"className":"page__taxonomy-item","children":["#","Multimodal Embeddings"]}],["$","span","MLLM-as-a-Judge",{"className":"page__taxonomy-item","children":["#","MLLM-as-a-Judge"]}],["$","span","Hard Negative Mining",{"className":"page__taxonomy-item","children":["#","Hard Negative Mining"]}],["$","span","Semantic Alignment",{"className":"page__taxonomy-item","children":["#","Semantic Alignment"]}],["$","span","Representation Learning",{"className":"page__taxonomy-item","children":["#","Representation Learning"]}],["$","span","Reranking",{"className":"page__taxonomy-item","children":["#","Reranking"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}]]}]]}]]}],["$","article","2025-10-16-Uni-MMMU-A-Massive-Multi-discipline-Multimodal-Unified-Benchmark",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-Uni-MMMU-A-Massive-Multi-discipline-Multimodal-Unified-Benchmark/","children":"[논문리뷰] Uni-MMMU: A Massive Multi-discipline Multimodal Unified Benchmark"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Uni-MMMU: A Massive Multi-discipline Multimodal Unified Benchmark' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Unified Models",{"className":"page__taxonomy-item","children":["#","Unified Models"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Generation",{"className":"page__taxonomy-item","children":["#","Generation"]}],["$","span","Understanding",{"className":"page__taxonomy-item","children":["#","Understanding"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Evaluation",{"className":"page__taxonomy-item","children":["#","Evaluation"]}],["$","span","Cross-modal Synergy",{"className":"page__taxonomy-item","children":["#","Cross-modal Synergy"]}]]}]]}]]}],["$","article","2025-10-16-Trace-Anything-Representing-Any-Video-in-4D-via-Trajectory-Fields",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-Trace-Anything-Representing-Any-Video-in-4D-via-Trajectory-Fields/","children":"[논문리뷰] Trace Anything: Representing Any Video in 4D via Trajectory Fields"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Trace Anything: Representing Any Video in 4D via Trajectory Fields' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","4D Video Representation",{"className":"page__taxonomy-item","children":["#","4D Video Representation"]}],["$","span","Trajectory Fields",{"className":"page__taxonomy-item","children":["#","Trajectory Fields"]}],["$","span","Neural Networks",{"className":"page__taxonomy-item","children":["#","Neural Networks"]}],["$","span","Spatio-temporal Modeling",{"className":"page__taxonomy-item","children":["#","Spatio-temporal Modeling"]}],["$","span","3D Point Tracking",{"className":"page__taxonomy-item","children":["#","3D Point Tracking"]}],["$","span","Motion Forecasting",{"className":"page__taxonomy-item","children":["#","Motion Forecasting"]}],["$","span","Computer Vision",{"className":"page__taxonomy-item","children":["#","Computer Vision"]}],["$","span","B-splines",{"className":"page__taxonomy-item","children":["#","B-splines"]}]]}]]}]]}],["$","article","2025-10-16-The-Role-of-Computing-Resources-in-Publishing-Foundation-Model-Research",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-The-Role-of-Computing-Resources-in-Publishing-Foundation-Model-Research/","children":"[논문리뷰] The Role of Computing Resources in Publishing Foundation Model Research"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhenwen Liang이 [arXiv]에 게시한 'The Role of Computing Resources in Publishing Foundation Model Research' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Computing Resources",{"className":"page__taxonomy-item","children":["#","Computing Resources"]}],["$","span","GPU Disparity",{"className":"page__taxonomy-item","children":["#","GPU Disparity"]}],["$","span","AI Research",{"className":"page__taxonomy-item","children":["#","AI Research"]}],["$","span","Publication Bias",{"className":"page__taxonomy-item","children":["#","Publication Bias"]}],["$","span","Resource Allocation",{"className":"page__taxonomy-item","children":["#","Resource Allocation"]}],["$","span","Research Transparency",{"className":"page__taxonomy-item","children":["#","Research Transparency"]}]]}]]}]]}],["$","article","2025-10-16-The-Art-of-Scaling-Reinforcement-Learning-Compute-for-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-The-Art-of-Scaling-Reinforcement-Learning-Compute-for-LLMs/","children":"[논문리뷰] The Art of Scaling Reinforcement Learning Compute for LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'The Art of Scaling Reinforcement Learning Compute for LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Scaling Laws",{"className":"page__taxonomy-item","children":["#","Scaling Laws"]}],["$","span","Compute Efficiency",{"className":"page__taxonomy-item","children":["#","Compute Efficiency"]}],["$","span","Predictability",{"className":"page__taxonomy-item","children":["#","Predictability"]}],["$","span","Sigmoidal Curves",{"className":"page__taxonomy-item","children":["#","Sigmoidal Curves"]}],["$","span","ScaleRL",{"className":"page__taxonomy-item","children":["#","ScaleRL"]}],["$","span","Off-Policy RL",{"className":"page__taxonomy-item","children":["#","Off-Policy RL"]}]]}]]}]]}],["$","article","2025-10-16-Stronger-Together-On-Policy-Reinforcement-Learning-for-Collaborative-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-Stronger-Together-On-Policy-Reinforcement-Learning-for-Collaborative-LLMs/","children":"[논문리뷰] Stronger Together: On-Policy Reinforcement Learning for Collaborative LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hao Zhang이 [arXiv]에 게시한 'Stronger Together: On-Policy Reinforcement Learning for Collaborative LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Multi-Agent Systems (MAS)",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems (MAS)"]}],["$","span","On-Policy RL",{"className":"page__taxonomy-item","children":["#","On-Policy RL"]}],["$","span","Collaborative AI",{"className":"page__taxonomy-item","children":["#","Collaborative AI"]}],["$","span","Agentic LLMs",{"className":"page__taxonomy-item","children":["#","Agentic LLMs"]}],["$","span","Group-based Optimization",{"className":"page__taxonomy-item","children":["#","Group-based Optimization"]}]]}]]}]]}],["$","article","2025-10-16-Revisiting-Model-Interpolation-for-Efficient-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-Revisiting-Model-Interpolation-for-Efficient-Reasoning/","children":"[논문리뷰] Revisiting Model Interpolation for Efficient Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Revisiting Model Interpolation for Efficient Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Model Interpolation",{"className":"page__taxonomy-item","children":["#","Model Interpolation"]}],["$","span","Efficient Reasoning",{"className":"page__taxonomy-item","children":["#","Efficient Reasoning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Model Merging",{"className":"page__taxonomy-item","children":["#","Model Merging"]}],["$","span","Performance Dynamics",{"className":"page__taxonomy-item","children":["#","Performance Dynamics"]}],["$","span","Ablation Study",{"className":"page__taxonomy-item","children":["#","Ablation Study"]}]]}]]}]]}],["$","article","2025-10-16-Reasoning-in-Space-via-Grounding-in-the-World",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-Reasoning-in-Space-via-Grounding-in-the-World/","children":"[논문리뷰] Reasoning in Space via Grounding in the World"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Li Zhang이 [arXiv]에 게시한 'Reasoning in Space via Grounding in the World' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Visual Grounding",{"className":"page__taxonomy-item","children":["#","3D Visual Grounding"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Chain-of-Thought (CoT)",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought (CoT)"]}],["$","span","Hybrid Representation",{"className":"page__taxonomy-item","children":["#","Hybrid Representation"]}],["$","span","Multi-modal LLMs",{"className":"page__taxonomy-item","children":["#","Multi-modal LLMs"]}],["$","span","Point Clouds",{"className":"page__taxonomy-item","children":["#","Point Clouds"]}]]}]]}]]}],["$","article","2025-10-16-Point-Prompting-Counterfactual-Tracking-with-Video-Diffusion-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-Point-Prompting-Counterfactual-Tracking-with-Video-Diffusion-Models/","children":"[논문리뷰] Point Prompting: Counterfactual Tracking with Video Diffusion Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Andrew Owens이 [arXiv]에 게시한 'Point Prompting: Counterfactual Tracking with Video Diffusion Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Diffusion Models",{"className":"page__taxonomy-item","children":["#","Video Diffusion Models"]}],["$","span","Point Tracking",{"className":"page__taxonomy-item","children":["#","Point Tracking"]}],["$","span","Zero-Shot Learning",{"className":"page__taxonomy-item","children":["#","Zero-Shot Learning"]}],["$","span","Counterfactual Modeling",{"className":"page__taxonomy-item","children":["#","Counterfactual Modeling"]}],["$","span","Visual Prompting",{"className":"page__taxonomy-item","children":["#","Visual Prompting"]}],["$","span","SDEdit",{"className":"page__taxonomy-item","children":["#","SDEdit"]}],["$","span","Negative Prompting",{"className":"page__taxonomy-item","children":["#","Negative Prompting"]}],["$","span","Object Permanence",{"className":"page__taxonomy-item","children":["#","Object Permanence"]}]]}]]}]]}],["$","article","2025-10-16-PhysMaster-Mastering-Physical-Representation-for-Video-Generation-via-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-PhysMaster-Mastering-Physical-Representation-for-Video-Generation-via-Reinforcement-Learning/","children":"[논문리뷰] PhysMaster: Mastering Physical Representation for Video Generation via Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hengshuang Zhao이 [arXiv]에 게시한 'PhysMaster: Mastering Physical Representation for Video Generation via Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Physical Plausibility",{"className":"page__taxonomy-item","children":["#","Physical Plausibility"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Direct Preference Optimization",{"className":"page__taxonomy-item","children":["#","Direct Preference Optimization"]}],["$","span","Physical Representation",{"className":"page__taxonomy-item","children":["#","Physical Representation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","World Models",{"className":"page__taxonomy-item","children":["#","World Models"]}],["$","span","Image-to-Video",{"className":"page__taxonomy-item","children":["#","Image-to-Video"]}]]}]]}]]}],["$","article","2025-10-16-ParallelBench-Understanding-the-Trade-offs-of-Parallel-Decoding-in-Diffusion-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-ParallelBench-Understanding-the-Trade-offs-of-Parallel-Decoding-in-Diffusion-LLMs/","children":"[논문리뷰] ParallelBench: Understanding the Trade-offs of Parallel Decoding in Diffusion LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'ParallelBench: Understanding the Trade-offs of Parallel Decoding in Diffusion LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion LLMs",{"className":"page__taxonomy-item","children":["#","Diffusion LLMs"]}],["$","span","Parallel Decoding",{"className":"page__taxonomy-item","children":["#","Parallel Decoding"]}],["$","span","Speed-Quality Trade-off",{"className":"page__taxonomy-item","children":["#","Speed-Quality Trade-off"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Token Dependencies",{"className":"page__taxonomy-item","children":["#","Token Dependencies"]}],["$","span","Unmasking Strategies",{"className":"page__taxonomy-item","children":["#","Unmasking Strategies"]}],["$","span","Information Theory",{"className":"page__taxonomy-item","children":["#","Information Theory"]}]]}]]}]]}],["$","article","2025-10-16-NOSA-Native-and-Offloadable-Sparse-Attention",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-NOSA-Native-and-Offloadable-Sparse-Attention/","children":"[논문리뷰] NOSA: Native and Offloadable Sparse Attention"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhiyuan Liu이 [arXiv]에 게시한 'NOSA: Native and Offloadable Sparse Attention' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Sparse Attention",{"className":"page__taxonomy-item","children":["#","Sparse Attention"]}],["$","span","KV Cache Offloading",{"className":"page__taxonomy-item","children":["#","KV Cache Offloading"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Decoding Throughput",{"className":"page__taxonomy-item","children":["#","Decoding Throughput"]}],["$","span","Locality Constraint",{"className":"page__taxonomy-item","children":["#","Locality Constraint"]}],["$","span","Memory Optimization",{"className":"page__taxonomy-item","children":["#","Memory Optimization"]}],["$","span","Trainable Sparse Attention",{"className":"page__taxonomy-item","children":["#","Trainable Sparse Attention"]}]]}]]}]]}],["$","article","2025-10-16-MTSQL-R1-Towards-Long-Horizon-Multi-Turn-Text-to-SQL-via-Agentic-Training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-MTSQL-R1-Towards-Long-Horizon-Multi-Turn-Text-to-SQL-via-Agentic-Training/","children":"[논문리뷰] MTSQL-R1: Towards Long-Horizon Multi-Turn Text-to-SQL via Agentic Training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'MTSQL-R1: Towards Long-Horizon Multi-Turn Text-to-SQL via Agentic Training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-turn Text-to-SQL",{"className":"page__taxonomy-item","children":["#","Multi-turn Text-to-SQL"]}],["$","span","Agentic Training",{"className":"page__taxonomy-item","children":["#","Agentic Training"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Dialogue Systems",{"className":"page__taxonomy-item","children":["#","Dialogue Systems"]}],["$","span","Semantic Parsing",{"className":"page__taxonomy-item","children":["#","Semantic Parsing"]}],["$","span","Database Interaction",{"className":"page__taxonomy-item","children":["#","Database Interaction"]}],["$","span","Self-correction",{"className":"page__taxonomy-item","children":["#","Self-correction"]}]]}]]}]]}],["$","article","2025-10-16-MATH-Beyond-A-Benchmark-for-RL-to-Expand-Beyond-the-Base-Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-MATH-Beyond-A-Benchmark-for-RL-to-Expand-Beyond-the-Base-Model/","children":"[논문리뷰] MATH-Beyond: A Benchmark for RL to Expand Beyond the Base Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wieland Brendel이 [arXiv]에 게시한 'MATH-Beyond: A Benchmark for RL to Expand Beyond the Base Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Exploration",{"className":"page__taxonomy-item","children":["#","Exploration"]}],["$","span","Boundary Expansion",{"className":"page__taxonomy-item","children":["#","Boundary Expansion"]}],["$","span","MATH-Beyond",{"className":"page__taxonomy-item","children":["#","MATH-Beyond"]}]]}]]}]]}],["$","article","2025-10-16-LIBERO-Plus-In-depth-Robustness-Analysis-of-Vision-Language-Action-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-LIBERO-Plus-In-depth-Robustness-Analysis-of-Vision-Language-Action-Models/","children":"[논문리뷰] LIBERO-Plus: In-depth Robustness Analysis of Vision-Language-Action Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'LIBERO-Plus: In-depth Robustness Analysis of Vision-Language-Action Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action Models"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Robustness Analysis",{"className":"page__taxonomy-item","children":["#","Robustness Analysis"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Perturbations",{"className":"page__taxonomy-item","children":["#","Perturbations"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","LIBERO-Plus",{"className":"page__taxonomy-item","children":["#","LIBERO-Plus"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}]]}]]}]]}],["$","article","2025-10-16-InternVLA-M1-A-Spatially-Guided-Vision-Language-Action-Framework-for-Generalist-Robot-Policy",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-InternVLA-M1-A-Spatially-Guided-Vision-Language-Action-Framework-for-Generalist-Robot-Policy/","children":"[논문리뷰] InternVLA-M1: A Spatially Guided Vision-Language-Action Framework for Generalist Robot Policy"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yilun Chen이 [arXiv]에 게시한 'InternVLA-M1: A Spatially Guided Vision-Language-Action Framework for Generalist Robot Policy' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Vision-Language-Action (VLA)",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action (VLA)"]}],["$","span","Spatial Grounding",{"className":"page__taxonomy-item","children":["#","Spatial Grounding"]}],["$","span","Generalist Policy",{"className":"page__taxonomy-item","children":["#","Generalist Policy"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}],["$","span","Simulation-to-Real",{"className":"page__taxonomy-item","children":["#","Simulation-to-Real"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}]]}]]}]]}],["$","article","2025-10-16-InteractiveOmni-A-Unified-Omni-modal-Model-for-Audio-Visual-Multi-turn-Dialogue",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-InteractiveOmni-A-Unified-Omni-modal-Model-for-Audio-Visual-Multi-turn-Dialogue/","children":"[논문리뷰] InteractiveOmni: A Unified Omni-modal Model for Audio-Visual Multi-turn Dialogue"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Dongchuan Ran이 [arXiv]에 게시한 'InteractiveOmni: A Unified Omni-modal Model for Audio-Visual Multi-turn Dialogue' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Omni-modal LLM",{"className":"page__taxonomy-item","children":["#","Omni-modal LLM"]}],["$","span","Audio-Visual Dialogue",{"className":"page__taxonomy-item","children":["#","Audio-Visual Dialogue"]}],["$","span","Multi-turn Interaction",{"className":"page__taxonomy-item","children":["#","Multi-turn Interaction"]}],["$","span","Speech Generation",{"className":"page__taxonomy-item","children":["#","Speech Generation"]}],["$","span","Long-term Memory",{"className":"page__taxonomy-item","children":["#","Long-term Memory"]}],["$","span","Multimodal Understanding",{"className":"page__taxonomy-item","children":["#","Multimodal Understanding"]}],["$","span","End-to-end Training",{"className":"page__taxonomy-item","children":["#","End-to-end Training"]}]]}]]}]]}],["$","article","2025-10-16-HyperAgent-Leveraging-Hypergraphs-for-Topology-Optimization-in-Multi-Agent-Communication",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-HyperAgent-Leveraging-Hypergraphs-for-Topology-Optimization-in-Multi-Agent-Communication/","children":"[논문리뷰] HyperAgent: Leveraging Hypergraphs for Topology Optimization in Multi-Agent Communication"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Haochen You이 [arXiv]에 게시한 'HyperAgent: Leveraging Hypergraphs for Topology Optimization in Multi-Agent Communication' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Model",{"className":"page__taxonomy-item","children":["#","Large Language Model"]}],["$","span","Multi-agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-agent Systems"]}],["$","span","Multi-agent Communication",{"className":"page__taxonomy-item","children":["#","Multi-agent Communication"]}],["$","span","Graph Neural Networks",{"className":"page__taxonomy-item","children":["#","Graph Neural Networks"]}],["$","span","Hypergraph",{"className":"page__taxonomy-item","children":["#","Hypergraph"]}],["$","span","Topology Optimization",{"className":"page__taxonomy-item","children":["#","Topology Optimization"]}],["$","span","Variational Autoencoder",{"className":"page__taxonomy-item","children":["#","Variational Autoencoder"]}],["$","span","Sparsity Regularization",{"className":"page__taxonomy-item","children":["#","Sparsity Regularization"]}]]}]]}]]}],["$","article","2025-10-16-Hierarchical-Frequency-Tagging-Probe-HFTP-A-Unified-Approach-to-Investigate-Syntactic-Structure-Representations-in-Large-Language-Models-and-the-Human-Brain",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-Hierarchical-Frequency-Tagging-Probe-HFTP-A-Unified-Approach-to-Investigate-Syntactic-Structure-Representations-in-Large-Language-Models-and-the-Human-Brain/","children":"[논문리뷰] Hierarchical Frequency Tagging Probe (HFTP): A Unified Approach to Investigate Syntactic Structure Representations in Large Language Models and the Human Brain"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Lingxi Lu이 [arXiv]에 게시한 'Hierarchical Frequency Tagging Probe (HFTP): A Unified Approach to Investigate Syntactic Structure Representations in Large Language Models and the Human Brain' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Syntactic Structure",{"className":"page__taxonomy-item","children":["#","Syntactic Structure"]}],["$","span","Human Brain",{"className":"page__taxonomy-item","children":["#","Human Brain"]}],["$","span","Frequency Tagging",{"className":"page__taxonomy-item","children":["#","Frequency Tagging"]}],["$","span","Neuroscience",{"className":"page__taxonomy-item","children":["#","Neuroscience"]}],["$","span","Model Interpretability",{"className":"page__taxonomy-item","children":["#","Model Interpretability"]}],["$","span","Representational Similarity Analysis",{"className":"page__taxonomy-item","children":["#","Representational Similarity Analysis"]}],["$","span","Intracranial EEG",{"className":"page__taxonomy-item","children":["#","Intracranial EEG"]}]]}]]}]]}],["$","article","2025-10-16-Hard2Verify-A-Step-Level-Verification-Benchmark-for-Open-Ended-Frontier-Math",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-Hard2Verify-A-Step-Level-Verification-Benchmark-for-Open-Ended-Frontier-Math/","children":"[논문리뷰] Hard2Verify: A Step-Level Verification Benchmark for Open-Ended Frontier Math"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Hard2Verify: A Step-Level Verification Benchmark for Open-Ended Frontier Math' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Verification",{"className":"page__taxonomy-item","children":["#","LLM Verification"]}],["$","span","Math Reasoning",{"className":"page__taxonomy-item","children":["#","Math Reasoning"]}],["$","span","Step-Level Verification",{"className":"page__taxonomy-item","children":["#","Step-Level Verification"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Open-Ended Problems",{"className":"page__taxonomy-item","children":["#","Open-Ended Problems"]}],["$","span","Process Reward Models",{"className":"page__taxonomy-item","children":["#","Process Reward Models"]}],["$","span","Generative Critics",{"className":"page__taxonomy-item","children":["#","Generative Critics"]}]]}]]}]]}],["$","article","2025-10-16-GraphTracer-Graph-Guided-Failure-Tracing-in-LLM-Agents-for-Robust-Multi-Turn-Deep-Search",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-GraphTracer-Graph-Guided-Failure-Tracing-in-LLM-Agents-for-Robust-Multi-Turn-Deep-Search/","children":"[논문리뷰] GraphTracer: Graph-Guided Failure Tracing in LLM Agents for Robust Multi-Turn Deep Search"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zijian Zhang이 [arXiv]에 게시한 'GraphTracer: Graph-Guided Failure Tracing in LLM Agents for Robust Multi-Turn Deep Search' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Failure Tracing",{"className":"page__taxonomy-item","children":["#","Failure Tracing"]}],["$","span","Root Cause Analysis",{"className":"page__taxonomy-item","children":["#","Root Cause Analysis"]}],["$","span","Information Dependency Graph",{"className":"page__taxonomy-item","children":["#","Information Dependency Graph"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Deep Search",{"className":"page__taxonomy-item","children":["#","Deep Search"]}]]}]]}]]}],["$","article","2025-10-16-Generative-Universal-Verifier-as-Multimodal-Meta-Reasoner",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-Generative-Universal-Verifier-as-Multimodal-Meta-Reasoner/","children":"[논문리뷰] Generative Universal Verifier as Multimodal Meta-Reasoner"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Generative Universal Verifier as Multimodal Meta-Reasoner' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Visual Verification",{"className":"page__taxonomy-item","children":["#","Visual Verification"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Self-Refinement",{"className":"page__taxonomy-item","children":["#","Self-Refinement"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Test-Time Scaling",{"className":"page__taxonomy-item","children":["#","Test-Time Scaling"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}]]}]]}]]}],["$","article","2025-10-16-FlashWorld-High-quality-3D-Scene-Generation-within-Seconds",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-FlashWorld-High-quality-3D-Scene-Generation-within-Seconds/","children":"[논문리뷰] FlashWorld: High-quality 3D Scene Generation within Seconds"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chunchao Guo이 [arXiv]에 게시한 'FlashWorld: High-quality 3D Scene Generation within Seconds' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Scene Generation",{"className":"page__taxonomy-item","children":["#","3D Scene Generation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Multi-View Synthesis",{"className":"page__taxonomy-item","children":["#","Multi-View Synthesis"]}],["$","span","3D Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","3D Gaussian Splatting"]}],["$","span","Knowledge Distillation",{"className":"page__taxonomy-item","children":["#","Knowledge Distillation"]}],["$","span","Real-time Generation",{"className":"page__taxonomy-item","children":["#","Real-time Generation"]}],["$","span","High-Quality Rendering",{"className":"page__taxonomy-item","children":["#","High-Quality Rendering"]}],["$","span","Cross-modal Training",{"className":"page__taxonomy-item","children":["#","Cross-modal Training"]}]]}]]}]]}],["$","article","2025-10-16-FG-CLIP-2-A-Bilingual-Fine-grained-Vision-Language-Alignment-Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-FG-CLIP-2-A-Bilingual-Fine-grained-Vision-Language-Alignment-Model/","children":"[논문리뷰] FG-CLIP 2: A Bilingual Fine-grained Vision-Language Alignment Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Dawei Liang이 [arXiv]에 게시한 'FG-CLIP 2: A Bilingual Fine-grained Vision-Language Alignment Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Alignment",{"className":"page__taxonomy-item","children":["#","Vision-Language Alignment"]}],["$","span","Fine-grained Understanding",{"className":"page__taxonomy-item","children":["#","Fine-grained Understanding"]}],["$","span","Bilingual Model",{"className":"page__taxonomy-item","children":["#","Bilingual Model"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Multimodal Retrieval",{"className":"page__taxonomy-item","children":["#","Multimodal Retrieval"]}],["$","span","Open-Vocabulary Detection",{"className":"page__taxonomy-item","children":["#","Open-Vocabulary Detection"]}],["$","span","Region-Text Matching",{"className":"page__taxonomy-item","children":["#","Region-Text Matching"]}]]}]]}]]}],["$","article","2025-10-16-EAGER-Entropy-Aware-GEneRation-for-Adaptive-Inference-Time-Scaling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-EAGER-Entropy-Aware-GEneRation-for-Adaptive-Inference-Time-Scaling/","children":"[논문리뷰] EAGER: Entropy-Aware GEneRation for Adaptive Inference-Time Scaling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ahmet Üstün이 [arXiv]에 게시한 'EAGER: Entropy-Aware GEneRation for Adaptive Inference-Time Scaling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Inference-Time Scaling",{"className":"page__taxonomy-item","children":["#","Inference-Time Scaling"]}],["$","span","Entropy-Aware Generation",{"className":"page__taxonomy-item","children":["#","Entropy-Aware Generation"]}],["$","span","Adaptive Budget Allocation",{"className":"page__taxonomy-item","children":["#","Adaptive Budget Allocation"]}],["$","span","Reasoning Benchmarks",{"className":"page__taxonomy-item","children":["#","Reasoning Benchmarks"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}]]}]]}]]}],["$","article","2025-10-16-Direct-Multi-Token-Decoding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-Direct-Multi-Token-Decoding/","children":"[논문리뷰] Direct Multi-Token Decoding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xifeng Yan이 [arXiv]에 게시한 'Direct Multi-Token Decoding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Inference",{"className":"page__taxonomy-item","children":["#","LLM Inference"]}],["$","span","Multi-token Decoding",{"className":"page__taxonomy-item","children":["#","Multi-token Decoding"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Layer Specialization",{"className":"page__taxonomy-item","children":["#","Layer Specialization"]}],["$","span","Cyclical Refilling",{"className":"page__taxonomy-item","children":["#","Cyclical Refilling"]}],["$","span","Inference Speedup",{"className":"page__taxonomy-item","children":["#","Inference Speedup"]}],["$","span","Model Scaling",{"className":"page__taxonomy-item","children":["#","Model Scaling"]}]]}]]}]]}],["$","article","2025-10-16-Deflanderization-for-Game-Dialogue-Balancing-Character-Authenticity-with-Task-Execution-in-LLM-based-NPCs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-Deflanderization-for-Game-Dialogue-Balancing-Character-Authenticity-with-Task-Execution-in-LLM-based-NPCs/","children":"[논문리뷰] Deflanderization for Game Dialogue: Balancing Character Authenticity with Task Execution in LLM-based NPCs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Deflanderization for Game Dialogue: Balancing Character Authenticity with Task Execution in LLM-based NPCs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","NPC",{"className":"page__taxonomy-item","children":["#","NPC"]}],["$","span","Game Dialogue",{"className":"page__taxonomy-item","children":["#","Game Dialogue"]}],["$","span","Persona-Grounded Dialogue",{"className":"page__taxonomy-item","children":["#","Persona-Grounded Dialogue"]}],["$","span","Task Execution",{"className":"page__taxonomy-item","children":["#","Task Execution"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Deflanderization",{"className":"page__taxonomy-item","children":["#","Deflanderization"]}]]}]]}]]}],["$","article","2025-10-16-CoIRL-AD-Collaborative-Competitive-Imitation-Reinforcement-Learning-in-Latent-World-Models-for-Autonomous-Driving",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-CoIRL-AD-Collaborative-Competitive-Imitation-Reinforcement-Learning-in-Latent-World-Models-for-Autonomous-Driving/","children":"[논문리뷰] CoIRL-AD: Collaborative-Competitive Imitation-Reinforcement Learning in Latent World Models for Autonomous Driving"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'CoIRL-AD: Collaborative-Competitive Imitation-Reinforcement Learning in Latent World Models for Autonomous Driving' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Autonomous Driving",{"className":"page__taxonomy-item","children":["#","Autonomous Driving"]}],["$","span","Imitation Learning",{"className":"page__taxonomy-item","children":["#","Imitation Learning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","World Models",{"className":"page__taxonomy-item","children":["#","World Models"]}],["$","span","Latent Space",{"className":"page__taxonomy-item","children":["#","Latent Space"]}],["$","span","Dual-Policy",{"className":"page__taxonomy-item","children":["#","Dual-Policy"]}],["$","span","Competitive Learning",{"className":"page__taxonomy-item","children":["#","Competitive Learning"]}]]}]]}]]}],["$","article","2025-10-16-CVD-STORM-Cross-View-Video-Diffusion-with-Spatial-Temporal-Reconstruction-Model-for-Autonomous-Driving",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-CVD-STORM-Cross-View-Video-Diffusion-with-Spatial-Temporal-Reconstruction-Model-for-Autonomous-Driving/","children":"[논문리뷰] CVD-STORM: Cross-View Video Diffusion with Spatial-Temporal Reconstruction Model for Autonomous Driving"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jingcheng Ni이 [arXiv]에 게시한 'CVD-STORM: Cross-View Video Diffusion with Spatial-Temporal Reconstruction Model for Autonomous Driving' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Autonomous Driving",{"className":"page__taxonomy-item","children":["#","Autonomous Driving"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Spatial-Temporal Reconstruction",{"className":"page__taxonomy-item","children":["#","Spatial-Temporal Reconstruction"]}],["$","span","3D Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","3D Gaussian Splatting"]}],["$","span","Variational Autoencoder",{"className":"page__taxonomy-item","children":["#","Variational Autoencoder"]}],["$","span","World Modeling",{"className":"page__taxonomy-item","children":["#","World Modeling"]}],["$","span","Multi-View Video",{"className":"page__taxonomy-item","children":["#","Multi-View Video"]}]]}]]}]]}],["$","article","2025-10-16-Bee-A-High-Quality-Corpus-and-Full-Stack-Suite-to-Unlock-Advanced-Fully-Open-MLLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-Bee-A-High-Quality-Corpus-and-Full-Stack-Suite-to-Unlock-Advanced-Fully-Open-MLLMs/","children":"[논문리뷰] Bee: A High-Quality Corpus and Full-Stack Suite to Unlock Advanced Fully Open MLLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Bee: A High-Quality Corpus and Full-Stack Suite to Unlock Advanced Fully Open MLLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Open-source AI",{"className":"page__taxonomy-item","children":["#","Open-source AI"]}],["$","span","Data Quality",{"className":"page__taxonomy-item","children":["#","Data Quality"]}],["$","span","MLLM Training",{"className":"page__taxonomy-item","children":["#","MLLM Training"]}]]}]]}]]}],["$","article","2025-10-16-Attention-Illuminates-LLM-Reasoning-The-Preplan-and-Anchor-Rhythm-Enables-Fine-Grained-Policy-Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-Attention-Illuminates-LLM-Reasoning-The-Preplan-and-Anchor-Rhythm-Enables-Fine-Grained-Policy-Optimization/","children":"[논문리뷰] Attention Illuminates LLM Reasoning: The Preplan-and-Anchor Rhythm Enables Fine-Grained Policy Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Attention Illuminates LLM Reasoning: The Preplan-and-Anchor Rhythm Enables Fine-Grained Policy Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Reasoning",{"className":"page__taxonomy-item","children":["#","LLM Reasoning"]}],["$","span","Attention Mechanisms",{"className":"page__taxonomy-item","children":["#","Attention Mechanisms"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Credit Assignment",{"className":"page__taxonomy-item","children":["#","Credit Assignment"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Interpretability",{"className":"page__taxonomy-item","children":["#","Interpretability"]}],["$","span","Preplan-and-Anchor Rhythm",{"className":"page__taxonomy-item","children":["#","Preplan-and-Anchor Rhythm"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}]]}]]}]]}],["$","article","2025-10-15-What-If-Understanding-Motion-Through-Sparse-Interactions",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-What-If-Understanding-Motion-Through-Sparse-Interactions/","children":"[논문리뷰] What If : Understanding Motion Through Sparse Interactions"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'What If : Understanding Motion Through Sparse Interactions' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Motion Understanding",{"className":"page__taxonomy-item","children":["#","Motion Understanding"]}],["$","span","Sparse Interactions",{"className":"page__taxonomy-item","children":["#","Sparse Interactions"]}],["$","span","Multimodal Prediction",{"className":"page__taxonomy-item","children":["#","Multimodal Prediction"]}],["$","span","Flow Poke Transformer",{"className":"page__taxonomy-item","children":["#","Flow Poke Transformer"]}],["$","span","Physical Scene Dynamics",{"className":"page__taxonomy-item","children":["#","Physical Scene Dynamics"]}],["$","span","Uncertainty Quantification",{"className":"page__taxonomy-item","children":["#","Uncertainty Quantification"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Computer Vision",{"className":"page__taxonomy-item","children":["#","Computer Vision"]}]]}]]}]]}],["$","article","2025-10-15-ViCO-A-Training-Strategy-towards-Semantic-Aware-Dynamic-High-Resolution",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-ViCO-A-Training-Strategy-towards-Semantic-Aware-Dynamic-High-Resolution/","children":"[논문리뷰] ViCO: A Training Strategy towards Semantic Aware Dynamic High-Resolution"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'ViCO: A Training Strategy towards Semantic Aware Dynamic High-Resolution' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models (MLLMs)"]}],["$","span","Dynamic Resolution",{"className":"page__taxonomy-item","children":["#","Dynamic Resolution"]}],["$","span","Token Compression",{"className":"page__taxonomy-item","children":["#","Token Compression"]}],["$","span","Semantic Awareness",{"className":"page__taxonomy-item","children":["#","Semantic Awareness"]}],["$","span","Visual Consistency Learning (ViCO)",{"className":"page__taxonomy-item","children":["#","Visual Consistency Learning (ViCO)"]}],["$","span","Visual Resolution Router (ViR)",{"className":"page__taxonomy-item","children":["#","Visual Resolution Router (ViR)"]}],["$","span","Inference Optimization",{"className":"page__taxonomy-item","children":["#","Inference Optimization"]}]]}]]}]]}],["$","article","2025-10-15-UniFusion-Vision-Language-Model-as-Unified-Encoder-in-Image-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-UniFusion-Vision-Language-Model-as-Unified-Encoder-in-Image-Generation/","children":"[논문리뷰] UniFusion: Vision-Language Model as Unified Encoder in Image Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'UniFusion: Vision-Language Model as Unified Encoder in Image Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Model",{"className":"page__taxonomy-item","children":["#","Vision-Language Model"]}],["$","span","Unified Encoder",{"className":"page__taxonomy-item","children":["#","Unified Encoder"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Text-to-Image",{"className":"page__taxonomy-item","children":["#","Text-to-Image"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Zero-shot Learning",{"className":"page__taxonomy-item","children":["#","Zero-shot Learning"]}]]}]]}]]}],["$","article","2025-10-15-Tensor-Logic-The-Language-of-AI",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-Tensor-Logic-The-Language-of-AI/","children":"[논문리뷰] Tensor Logic: The Language of AI"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Pedro Domingos이 [arXiv]에 게시한 'Tensor Logic: The Language of AI' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Tensor Logic",{"className":"page__taxonomy-item","children":["#","Tensor Logic"]}],["$","span","Neurosymbolic AI",{"className":"page__taxonomy-item","children":["#","Neurosymbolic AI"]}],["$","span","Logic Programming",{"className":"page__taxonomy-item","children":["#","Logic Programming"]}],["$","span","Tensor Algebra",{"className":"page__taxonomy-item","children":["#","Tensor Algebra"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}],["$","span","Automated Reasoning",{"className":"page__taxonomy-item","children":["#","Automated Reasoning"]}],["$","span","Embedding Space",{"className":"page__taxonomy-item","children":["#","Embedding Space"]}]]}]]}]]}],["$","article","2025-10-15-Temporal-Alignment-Guidance-On-Manifold-Sampling-in-Diffusion-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-Temporal-Alignment-Guidance-On-Manifold-Sampling-in-Diffusion-Models/","children":"[논문리뷰] Temporal Alignment Guidance: On-Manifold Sampling in Diffusion Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Temporal Alignment Guidance: On-Manifold Sampling in Diffusion Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Guidance",{"className":"page__taxonomy-item","children":["#","Guidance"]}],["$","span","On-Manifold Sampling",{"className":"page__taxonomy-item","children":["#","On-Manifold Sampling"]}],["$","span","Temporal Alignment",{"className":"page__taxonomy-item","children":["#","Temporal Alignment"]}],["$","span","Score Approximation Error",{"className":"page__taxonomy-item","children":["#","Score Approximation Error"]}],["$","span","Training-Free Guidance",{"className":"page__taxonomy-item","children":["#","Training-Free Guidance"]}]]}]]}]]}],["$","article","2025-10-15-SynthID-Image-Image-watermarking-at-internet-scale",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-SynthID-Image-Image-watermarking-at-internet-scale/","children":"[논문리뷰] SynthID-Image: Image watermarking at internet scale"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'SynthID-Image: Image watermarking at internet scale' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Watermarking",{"className":"page__taxonomy-item","children":["#","Image Watermarking"]}],["$","span","AI-Generated Content",{"className":"page__taxonomy-item","children":["#","AI-Generated Content"]}],["$","span","Provenance",{"className":"page__taxonomy-item","children":["#","Provenance"]}],["$","span","Robustness",{"className":"page__taxonomy-item","children":["#","Robustness"]}],["$","span","Security",{"className":"page__taxonomy-item","children":["#","Security"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}],["$","span","Internet Scale",{"className":"page__taxonomy-item","children":["#","Internet Scale"]}],["$","span","Post-hoc",{"className":"page__taxonomy-item","children":["#","Post-hoc"]}]]}]]}]]}],["$","article","2025-10-15-Spatial-Forcing-Implicit-Spatial-Representation-Alignment-for-Vision-language-action-Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-Spatial-Forcing-Implicit-Spatial-Representation-Alignment-for-Vision-language-action-Model/","children":"[논문리뷰] Spatial Forcing: Implicit Spatial Representation Alignment for Vision-language-action Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Spatial Forcing: Implicit Spatial Representation Alignment for Vision-language-action Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action Models"]}],["$","span","Spatial Perception",{"className":"page__taxonomy-item","children":["#","Spatial Perception"]}],["$","span","Implicit Representation Alignment",{"className":"page__taxonomy-item","children":["#","Implicit Representation Alignment"]}],["$","span","3D Foundation Models",{"className":"page__taxonomy-item","children":["#","3D Foundation Models"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Data Efficiency",{"className":"page__taxonomy-item","children":["#","Data Efficiency"]}],["$","span","Representation Learning",{"className":"page__taxonomy-item","children":["#","Representation Learning"]}]]}]]}]]}],["$","article","2025-10-15-Scaling-Language-Centric-Omnimodal-Representation-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-Scaling-Language-Centric-Omnimodal-Representation-Learning/","children":"[논문리뷰] Scaling Language-Centric Omnimodal Representation Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Scaling Language-Centric Omnimodal Representation Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Embeddings",{"className":"page__taxonomy-item","children":["#","Multimodal Embeddings"]}],["$","span","MLLMs",{"className":"page__taxonomy-item","children":["#","MLLMs"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Cross-modal Alignment",{"className":"page__taxonomy-item","children":["#","Cross-modal Alignment"]}],["$","span","Generative Pretraining",{"className":"page__taxonomy-item","children":["#","Generative Pretraining"]}],["$","span","Representation Learning",{"className":"page__taxonomy-item","children":["#","Representation Learning"]}],["$","span","Scaling Laws",{"className":"page__taxonomy-item","children":["#","Scaling Laws"]}]]}]]}]]}],["$","article","2025-10-15-SRUM-Fine-Grained-Self-Rewarding-for-Unified-Multimodal-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-SRUM-Fine-Grained-Self-Rewarding-for-Unified-Multimodal-Models/","children":"[논문리뷰] SRUM: Fine-Grained Self-Rewarding for Unified Multimodal Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'SRUM: Fine-Grained Self-Rewarding for Unified Multimodal Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Unified Multimodal Models",{"className":"page__taxonomy-item","children":["#","Unified Multimodal Models"]}],["$","span","Self-Rewarding",{"className":"page__taxonomy-item","children":["#","Self-Rewarding"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Image Understanding",{"className":"page__taxonomy-item","children":["#","Image Understanding"]}],["$","span","Post-Training",{"className":"page__taxonomy-item","children":["#","Post-Training"]}],["$","span","Global-Local Reward",{"className":"page__taxonomy-item","children":["#","Global-Local Reward"]}],["$","span","Compositional Reasoning",{"className":"page__taxonomy-item","children":["#","Compositional Reasoning"]}]]}]]}]]}],["$","article","2025-10-15-SAIL-Embedding-Technical-Report-Omni-modal-Embedding-Foundation-Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-SAIL-Embedding-Technical-Report-Omni-modal-Embedding-Foundation-Model/","children":"[논문리뷰] SAIL-Embedding Technical Report: Omni-modal Embedding Foundation Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'SAIL-Embedding Technical Report: Omni-modal Embedding Foundation Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Omni-modal Embedding",{"className":"page__taxonomy-item","children":["#","Omni-modal Embedding"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Recommendation Systems",{"className":"page__taxonomy-item","children":["#","Recommendation Systems"]}],["$","span","Hard Negative Mining",{"className":"page__taxonomy-item","children":["#","Hard Negative Mining"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Data Balancing",{"className":"page__taxonomy-item","children":["#","Data Balancing"]}],["$","span","Multitask Learning",{"className":"page__taxonomy-item","children":["#","Multitask Learning"]}]]}]]}]]}],["$","article","2025-10-15-Robot-Learning-A-Tutorial",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-Robot-Learning-A-Tutorial/","children":"[논문리뷰] Robot Learning: A Tutorial"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Robot Learning: A Tutorial' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Robot Learning",{"className":"page__taxonomy-item","children":["#","Robot Learning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Imitation Learning",{"className":"page__taxonomy-item","children":["#","Imitation Learning"]}],["$","span","Behavioral Cloning",{"className":"page__taxonomy-item","children":["#","Behavioral Cloning"]}],["$","span","Vision-Language-Action Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action Models"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Transformers",{"className":"page__taxonomy-item","children":["#","Transformers"]}],["$","span","LeRobot",{"className":"page__taxonomy-item","children":["#","LeRobot"]}]]}]]}]]}],["$","article","2025-10-15-ReFIne-A-Framework-for-Trustworthy-Large-Reasoning-Models-with-Reliability-Faithfulness-and-Interpretability",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-ReFIne-A-Framework-for-Trustworthy-Large-Reasoning-Models-with-Reliability-Faithfulness-and-Interpretability/","children":"[논문리뷰] ReFIne: A Framework for Trustworthy Large Reasoning Models with Reliability, Faithfulness, and Interpretability"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Tsui-Wei Weng이 [arXiv]에 게시한 'ReFIne: A Framework for Trustworthy Large Reasoning Models with Reliability, Faithfulness, and Interpretability' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Trustworthy AI",{"className":"page__taxonomy-item","children":["#","Trustworthy AI"]}],["$","span","Large Reasoning Models (LRMs)",{"className":"page__taxonomy-item","children":["#","Large Reasoning Models (LRMs)"]}],["$","span","Interpretability",{"className":"page__taxonomy-item","children":["#","Interpretability"]}],["$","span","Faithfulness",{"className":"page__taxonomy-item","children":["#","Faithfulness"]}],["$","span","Reliability",{"className":"page__taxonomy-item","children":["#","Reliability"]}],["$","span","Chain-of-Thought (CoT)",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought (CoT)"]}],["$","span","Supervised Fine-tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning (SFT)"]}],["$","span","GRPO",{"className":"page__taxonomy-item","children":["#","GRPO"]}]]}]]}]]}],["$","article","2025-10-15-One-Life-to-Learn-Inferring-Symbolic-World-Models-for-Stochastic-Environments-from-Unguided-Exploration",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-One-Life-to-Learn-Inferring-Symbolic-World-Models-for-Stochastic-Environments-from-Unguided-Exploration/","children":"[논문리뷰] One Life to Learn: Inferring Symbolic World Models for Stochastic Environments from Unguided Exploration"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Mohit Bansal이 [arXiv]에 게시한 'One Life to Learn: Inferring Symbolic World Models for Stochastic Environments from Unguided Exploration' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Symbolic World Models",{"className":"page__taxonomy-item","children":["#","Symbolic World Models"]}],["$","span","Stochastic Environments",{"className":"page__taxonomy-item","children":["#","Stochastic Environments"]}],["$","span","Unguided Exploration",{"className":"page__taxonomy-item","children":["#","Unguided Exploration"]}],["$","span","Probabilistic Programming",{"className":"page__taxonomy-item","children":["#","Probabilistic Programming"]}],["$","span","Law Synthesis",{"className":"page__taxonomy-item","children":["#","Law Synthesis"]}],["$","span","Crafter-OO",{"className":"page__taxonomy-item","children":["#","Crafter-OO"]}],["$","span","Program Synthesis",{"className":"page__taxonomy-item","children":["#","Program Synthesis"]}]]}]]}]]}],["$","article","2025-10-15-Memory-as-Action-Autonomous-Context-Curation-for-Long-Horizon-Agentic-Tasks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-Memory-as-Action-Autonomous-Context-Curation-for-Long-Horizon-Agentic-Tasks/","children":"[논문리뷰] Memory as Action: Autonomous Context Curation for Long-Horizon Agentic Tasks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xueyuan Lin이 [arXiv]에 게시한 'Memory as Action: Autonomous Context Curation for Long-Horizon Agentic Tasks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Long-Horizon Tasks",{"className":"page__taxonomy-item","children":["#","Long-Horizon Tasks"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Context Curation",{"className":"page__taxonomy-item","children":["#","Context Curation"]}],["$","span","Working Memory",{"className":"page__taxonomy-item","children":["#","Working Memory"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Memory-as-Action",{"className":"page__taxonomy-item","children":["#","Memory-as-Action"]}]]}]]}]]}],["$","article","2025-10-15-MLLM-as-a-UI-Judge-Benchmarking-Multimodal-LLMs-for-Predicting-Human-Perception-of-User-Interfaces",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-MLLM-as-a-UI-Judge-Benchmarking-Multimodal-LLMs-for-Predicting-Human-Perception-of-User-Interfaces/","children":"[논문리뷰] MLLM as a UI Judge: Benchmarking Multimodal LLMs for Predicting Human Perception of User Interfaces"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Sungchul Kim이 [arXiv]에 게시한 'MLLM as a UI Judge: Benchmarking Multimodal LLMs for Predicting Human Perception of User Interfaces' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","UI Evaluation",{"className":"page__taxonomy-item","children":["#","UI Evaluation"]}],["$","span","Human Perception",{"className":"page__taxonomy-item","children":["#","Human Perception"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","UX Research",{"className":"page__taxonomy-item","children":["#","UX Research"]}],["$","span","MLLM-as-a-Judge",{"className":"page__taxonomy-item","children":["#","MLLM-as-a-Judge"]}],["$","span","Cognitive Factors",{"className":"page__taxonomy-item","children":["#","Cognitive Factors"]}],["$","span","Pairwise Comparison",{"className":"page__taxonomy-item","children":["#","Pairwise Comparison"]}]]}]]}]]}],["$","article","2025-10-15-LLM-Reasoning-for-Machine-Translation-Synthetic-Data-Generation-over-Thinking-Tokens",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-LLM-Reasoning-for-Machine-Translation-Synthetic-Data-Generation-over-Thinking-Tokens/","children":"[논문리뷰] LLM Reasoning for Machine Translation: Synthetic Data Generation over Thinking Tokens"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'LLM Reasoning for Machine Translation: Synthetic Data Generation over Thinking Tokens' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Machine Translation (MT)",{"className":"page__taxonomy-item","children":["#","Machine Translation (MT)"]}],["$","span","Chain-of-Thought (CoT)",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought (CoT)"]}],["$","span","Knowledge Distillation",{"className":"page__taxonomy-item","children":["#","Knowledge Distillation"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","Synthetic Data",{"className":"page__taxonomy-item","children":["#","Synthetic Data"]}]]}]]}]]}],["$","article","2025-10-15-Information-Preserving-Reformulation-of-Reasoning-Traces-for-Antidistillation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-Information-Preserving-Reformulation-of-Reasoning-Traces-for-Antidistillation/","children":"[논문리뷰] Information-Preserving Reformulation of Reasoning Traces for Antidistillation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Information-Preserving Reformulation of Reasoning Traces for Antidistillation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Antidistillation",{"className":"page__taxonomy-item","children":["#","Antidistillation"]}],["$","span","Reasoning Traces",{"className":"page__taxonomy-item","children":["#","Reasoning Traces"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Knowledge Distillation",{"className":"page__taxonomy-item","children":["#","Knowledge Distillation"]}],["$","span","Information Preservation",{"className":"page__taxonomy-item","children":["#","Information Preservation"]}],["$","span","Trace Reformulation",{"className":"page__taxonomy-item","children":["#","Trace Reformulation"]}],["$","span","Supervised Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning"]}]]}]]}]]}],["$","article","2025-10-15-HoneyBee-Data-Recipes-for-Vision-Language-Reasoners",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-HoneyBee-Data-Recipes-for-Vision-Language-Reasoners/","children":"[논문리뷰] HoneyBee: Data Recipes for Vision-Language Reasoners"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'HoneyBee: Data Recipes for Vision-Language Reasoners' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","VL Reasoning",{"className":"page__taxonomy-item","children":["#","VL Reasoning"]}],["$","span","Dataset Scaling",{"className":"page__taxonomy-item","children":["#","Dataset Scaling"]}],["$","span","Supervised Finetuning",{"className":"page__taxonomy-item","children":["#","Supervised Finetuning"]}],["$","span","HONEYBEE",{"className":"page__taxonomy-item","children":["#","HONEYBEE"]}],["$","span","Test-Time Scaling",{"className":"page__taxonomy-item","children":["#","Test-Time Scaling"]}]]}]]}]]}],["$","article","2025-10-15-FlashVSR-Towards-Real-Time-Diffusion-Based-Streaming-Video-Super-Resolution",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-FlashVSR-Towards-Real-Time-Diffusion-Based-Streaming-Video-Super-Resolution/","children":"[논문리뷰] FlashVSR: Towards Real-Time Diffusion-Based Streaming Video Super-Resolution"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yihao Liu이 [arXiv]에 게시한 'FlashVSR: Towards Real-Time Diffusion-Based Streaming Video Super-Resolution' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Super-Resolution (VSR)",{"className":"page__taxonomy-item","children":["#","Video Super-Resolution (VSR)"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Real-time VSR",{"className":"page__taxonomy-item","children":["#","Real-time VSR"]}],["$","span","Streaming VSR",{"className":"page__taxonomy-item","children":["#","Streaming VSR"]}],["$","span","Sparse Attention",{"className":"page__taxonomy-item","children":["#","Sparse Attention"]}],["$","span","Distillation",{"className":"page__taxonomy-item","children":["#","Distillation"]}],["$","span","Conditional Decoder",{"className":"page__taxonomy-item","children":["#","Conditional Decoder"]}],["$","span","High-resolution",{"className":"page__taxonomy-item","children":["#","High-resolution"]}]]}]]}]]}],["$","article","2025-10-15-ExpVid-A-Benchmark-for-Experiment-Video-Understanding-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-ExpVid-A-Benchmark-for-Experiment-Video-Understanding-Reasoning/","children":"[논문리뷰] ExpVid: A Benchmark for Experiment Video Understanding & Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'ExpVid: A Benchmark for Experiment Video Understanding & Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Experiment Video Understanding",{"className":"page__taxonomy-item","children":["#","Experiment Video Understanding"]}],["$","span","Multimodal Large Language Models (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models (MLLMs)"]}],["$","span","Scientific Reasoning",{"className":"page__taxonomy-item","children":["#","Scientific Reasoning"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Wet-Lab Experiments",{"className":"page__taxonomy-item","children":["#","Wet-Lab Experiments"]}],["$","span","Procedural Understanding",{"className":"page__taxonomy-item","children":["#","Procedural Understanding"]}],["$","span","Fine-grained Perception",{"className":"page__taxonomy-item","children":["#","Fine-grained Perception"]}],["$","span","Video QA",{"className":"page__taxonomy-item","children":["#","Video QA"]}]]}]]}]]}],["$","article","2025-10-15-ERA-Transforming-VLMs-into-Embodied-Agents-via-Embodied-Prior-Learning-and-Online-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-ERA-Transforming-VLMs-into-Embodied-Agents-via-Embodied-Prior-Learning-and-Online-Reinforcement-Learning/","children":"[논문리뷰] ERA: Transforming VLMs into Embodied Agents via Embodied Prior Learning and Online Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'ERA: Transforming VLMs into Embodied Agents via Embodied Prior Learning and Online Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Vision Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision Language Models (VLMs)"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Prior Learning",{"className":"page__taxonomy-item","children":["#","Prior Learning"]}],["$","span","Supervised Fine-tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning (SFT)"]}],["$","span","Embodied Agents",{"className":"page__taxonomy-item","children":["#","Embodied Agents"]}]]}]]}]]}],["$","article","2025-10-15-Dr-LLM-Dynamic-Layer-Routing-in-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-Dr-LLM-Dynamic-Layer-Routing-in-LLMs/","children":"[논문리뷰] Dr.LLM: Dynamic Layer Routing in LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Dr.LLM: Dynamic Layer Routing in LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Dynamic Routing",{"className":"page__taxonomy-item","children":["#","Dynamic Routing"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Adaptive Depth",{"className":"page__taxonomy-item","children":["#","Adaptive Depth"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}],["$","span","Monte Carlo Tree Search (MCTS)",{"className":"page__taxonomy-item","children":["#","Monte Carlo Tree Search (MCTS)"]}],["$","span","Retrofittable Framework",{"className":"page__taxonomy-item","children":["#","Retrofittable Framework"]}],["$","span","Supervised Learning",{"className":"page__taxonomy-item","children":["#","Supervised Learning"]}],["$","span","Accuracy Improvement",{"className":"page__taxonomy-item","children":["#","Accuracy Improvement"]}]]}]]}]]}],["$","article","2025-10-15-Detect-Anything-via-Next-Point-Prediction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-Detect-Anything-via-Next-Point-Prediction/","children":"[논문리뷰] Detect Anything via Next Point Prediction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Detect Anything via Next Point Prediction' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models"]}],["$","span","Object Detection",{"className":"page__taxonomy-item","children":["#","Object Detection"]}],["$","span","Coordinate Prediction",{"className":"page__taxonomy-item","children":["#","Coordinate Prediction"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Visual Perception",{"className":"page__taxonomy-item","children":["#","Visual Perception"]}],["$","span","Zero-shot Learning",{"className":"page__taxonomy-item","children":["#","Zero-shot Learning"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}]]}]]}]]}],["$","article","2025-10-15-DeepMMSearch-R1-Empowering-Multimodal-LLMs-in-Multimodal-Web-Search",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-DeepMMSearch-R1-Empowering-Multimodal-LLMs-in-Multimodal-Web-Search/","children":"[논문리뷰] DeepMMSearch-R1: Empowering Multimodal LLMs in Multimodal Web Search"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DeepMMSearch-R1: Empowering Multimodal LLMs in Multimodal Web Search' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLM",{"className":"page__taxonomy-item","children":["#","Multimodal LLM"]}],["$","span","Web Search",{"className":"page__taxonomy-item","children":["#","Web Search"]}],["$","span","Visual Question Answering",{"className":"page__taxonomy-item","children":["#","Visual Question Answering"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Image Cropping",{"className":"page__taxonomy-item","children":["#","Image Cropping"]}],["$","span","Self-Correction",{"className":"page__taxonomy-item","children":["#","Self-Correction"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}]]}]]}]]}],["$","article","2025-10-15-DITING-A-Multi-Agent-Evaluation-Framework-for-Benchmarking-Web-Novel-Translation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-DITING-A-Multi-Agent-Evaluation-Framework-for-Benchmarking-Web-Novel-Translation/","children":"[논문리뷰] DITING: A Multi-Agent Evaluation Framework for Benchmarking Web Novel Translation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DITING: A Multi-Agent Evaluation Framework for Benchmarking Web Novel Translation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Machine Translation Evaluation",{"className":"page__taxonomy-item","children":["#","Machine Translation Evaluation"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Web Novel Translation",{"className":"page__taxonomy-item","children":["#","Web Novel Translation"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Cultural Nuance",{"className":"page__taxonomy-item","children":["#","Cultural Nuance"]}],["$","span","Benchmark Dataset",{"className":"page__taxonomy-item","children":["#","Benchmark Dataset"]}],["$","span","Natural Language Generation",{"className":"page__taxonomy-item","children":["#","Natural Language Generation"]}]]}]]}]]}],["$","article","2025-10-15-Boundary-Guided-Policy-Optimization-for-Memory-efficient-RL-of-Diffusion-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-Boundary-Guided-Policy-Optimization-for-Memory-efficient-RL-of-Diffusion-Large-Language-Models/","children":"[논문리뷰] Boundary-Guided Policy Optimization for Memory-efficient RL of Diffusion Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Boundary-Guided Policy Optimization for Memory-efficient RL of Diffusion Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Large Language Models",{"className":"page__taxonomy-item","children":["#","Diffusion Large Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Memory Efficiency",{"className":"page__taxonomy-item","children":["#","Memory Efficiency"]}],["$","span","Monte Carlo Sampling",{"className":"page__taxonomy-item","children":["#","Monte Carlo Sampling"]}],["$","span","Log-Likelihood Approximation",{"className":"page__taxonomy-item","children":["#","Log-Likelihood Approximation"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","ELBO",{"className":"page__taxonomy-item","children":["#","ELBO"]}]]}]]}]]}],["$","article","2025-10-15-Advancing-End-to-End-Pixel-Space-Generative-Modeling-via-Self-supervised-Pre-training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-Advancing-End-to-End-Pixel-Space-Generative-Modeling-via-Self-supervised-Pre-training/","children":"[논문리뷰] Advancing End-to-End Pixel Space Generative Modeling via Self-supervised Pre-training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Advancing End-to-End Pixel Space Generative Modeling via Self-supervised Pre-training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Pixel-space Generative Models",{"className":"page__taxonomy-item","children":["#","Pixel-space Generative Models"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Consistency Models",{"className":"page__taxonomy-item","children":["#","Consistency Models"]}],["$","span","Self-supervised Pre-training",{"className":"page__taxonomy-item","children":["#","Self-supervised Pre-training"]}],["$","span","End-to-end Training",{"className":"page__taxonomy-item","children":["#","End-to-end Training"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","FID",{"className":"page__taxonomy-item","children":["#","FID"]}],["$","span","Representation Learning",{"className":"page__taxonomy-item","children":["#","Representation Learning"]}]]}]]}]]}],["$","article","2025-10-15-A-Survey-of-Vibe-Coding-with-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-A-Survey-of-Vibe-Coding-with-Large-Language-Models/","children":"[논문리뷰] A Survey of Vibe Coding with Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'A Survey of Vibe Coding with Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vibe Coding",{"className":"page__taxonomy-item","children":["#","Vibe Coding"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Coding Agents",{"className":"page__taxonomy-item","children":["#","Coding Agents"]}],["$","span","Human-AI Collaboration",{"className":"page__taxonomy-item","children":["#","Human-AI Collaboration"]}],["$","span","Software Engineering",{"className":"page__taxonomy-item","children":["#","Software Engineering"]}],["$","span","Development Models",{"className":"page__taxonomy-item","children":["#","Development Models"]}],["$","span","Context Engineering",{"className":"page__taxonomy-item","children":["#","Context Engineering"]}]]}]]}]]}],["$","article","2025-10-13-Which-Heads-Matter-for-Reasoning-RL-Guided-KV-Cache-Compression",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Which-Heads-Matter-for-Reasoning-RL-Guided-KV-Cache-Compression/","children":"[논문리뷰] Which Heads Matter for Reasoning? RL-Guided KV Cache Compression"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Huan Wang이 [arXiv]에 게시한 'Which Heads Matter for Reasoning? RL-Guided KV Cache Compression' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","KV Cache Compression",{"className":"page__taxonomy-item","children":["#","KV Cache Compression"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Reasoning Models",{"className":"page__taxonomy-item","children":["#","Reasoning Models"]}],["$","span","Attention Heads",{"className":"page__taxonomy-item","children":["#","Attention Heads"]}],["$","span","Chain-of-Thought (CoT)",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought (CoT)"]}],["$","span","Memory Efficiency",{"className":"page__taxonomy-item","children":["#","Memory Efficiency"]}]]}]]}]]}],["$","article","2025-10-13-Webscale-RL-Automated-Data-Pipeline-for-Scaling-RL-Data-to-Pretraining-Levels",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Webscale-RL-Automated-Data-Pipeline-for-Scaling-RL-Data-to-Pretraining-Levels/","children":"[논문리뷰] Webscale-RL: Automated Data Pipeline for Scaling RL Data to Pretraining Levels"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Webscale-RL: Automated Data Pipeline for Scaling RL Data to Pretraining Levels' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Data Pipeline",{"className":"page__taxonomy-item","children":["#","Data Pipeline"]}],["$","span","Web-scale Data",{"className":"page__taxonomy-item","children":["#","Web-scale Data"]}],["$","span","Question-Answering (QA)",{"className":"page__taxonomy-item","children":["#","Question-Answering (QA)"]}],["$","span","Data Generation",{"className":"page__taxonomy-item","children":["#","Data Generation"]}],["$","span","Data Diversity",{"className":"page__taxonomy-item","children":["#","Data Diversity"]}],["$","span","Data Efficiency",{"className":"page__taxonomy-item","children":["#","Data Efficiency"]}]]}]]}]]}],["$","article","2025-10-13-Understanding-DeepResearch-via-Reports",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Understanding-DeepResearch-via-Reports/","children":"[논문리뷰] Understanding DeepResearch via Reports"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chengen Huang이 [arXiv]에 게시한 'Understanding DeepResearch via Reports' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","DeepResearch Agents",{"className":"page__taxonomy-item","children":["#","DeepResearch Agents"]}],["$","span","LLM-as-a-Judge",{"className":"page__taxonomy-item","children":["#","LLM-as-a-Judge"]}],["$","span","Report Evaluation",{"className":"page__taxonomy-item","children":["#","Report Evaluation"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Factuality",{"className":"page__taxonomy-item","children":["#","Factuality"]}],["$","span","Redundancy",{"className":"page__taxonomy-item","children":["#","Redundancy"]}],["$","span","Research Automation",{"className":"page__taxonomy-item","children":["#","Research Automation"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}]]}]]}]]}],["$","article","2025-10-13-Thinking-with-Camera-A-Unified-Multimodal-Model-for-Camera-Centric-Understanding-and-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Thinking-with-Camera-A-Unified-Multimodal-Model-for-Camera-Centric-Understanding-and-Generation/","children":"[논문리뷰] Thinking with Camera: A Unified Multimodal Model for Camera-Centric Understanding and Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Linyi Jin이 [arXiv]에 게시한 'Thinking with Camera: A Unified Multimodal Model for Camera-Centric Understanding and Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Unified Multimodal Model",{"className":"page__taxonomy-item","children":["#","Unified Multimodal Model"]}],["$","span","Camera-Centric",{"className":"page__taxonomy-item","children":["#","Camera-Centric"]}],["$","span","Image Understanding",{"className":"page__taxonomy-item","children":["#","Image Understanding"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}],["$","span","Camera Parameters",{"className":"page__taxonomy-item","children":["#","Camera Parameters"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}],["$","span","Multimodal Spatial Intelligence",{"className":"page__taxonomy-item","children":["#","Multimodal Spatial Intelligence"]}]]}]]}]]}],["$","article","2025-10-13-Temporal-Prompting-Matters-Rethinking-Referring-Video-Object-Segmentation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Temporal-Prompting-Matters-Rethinking-Referring-Video-Object-Segmentation/","children":"[논문리뷰] Temporal Prompting Matters: Rethinking Referring Video Object Segmentation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Sifei Liu이 [arXiv]에 게시한 'Temporal Prompting Matters: Rethinking Referring Video Object Segmentation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Referring Video Object Segmentation",{"className":"page__taxonomy-item","children":["#","Referring Video Object Segmentation"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","Object Tracking",{"className":"page__taxonomy-item","children":["#","Object Tracking"]}],["$","span","SAM",{"className":"page__taxonomy-item","children":["#","SAM"]}],["$","span","Video Analysis",{"className":"page__taxonomy-item","children":["#","Video Analysis"]}],["$","span","Prompt Preference Learning",{"className":"page__taxonomy-item","children":["#","Prompt Preference Learning"]}]]}]]}]]}],["$","article","2025-10-13-TC-LoRA-Temporally-Modulated-Conditional-LoRA-for-Adaptive-Diffusion-Control",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-TC-LoRA-Temporally-Modulated-Conditional-LoRA-for-Adaptive-Diffusion-Control/","children":"[논문리뷰] TC-LoRA: Temporally Modulated Conditional LoRA for Adaptive Diffusion Control"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Adityan Jothi이 [arXiv]에 게시한 'TC-LoRA: Temporally Modulated Conditional LoRA for Adaptive Diffusion Control' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Conditional Generation",{"className":"page__taxonomy-item","children":["#","Conditional Generation"]}],["$","span","LoRA",{"className":"page__taxonomy-item","children":["#","LoRA"]}],["$","span","Hypernetwork",{"className":"page__taxonomy-item","children":["#","Hypernetwork"]}],["$","span","Dynamic Weight Adaptation",{"className":"page__taxonomy-item","children":["#","Dynamic Weight Adaptation"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Controllable Generation",{"className":"page__taxonomy-item","children":["#","Controllable Generation"]}]]}]]}]]}],["$","article","2025-10-13-StreamingVLM-Real-Time-Understanding-for-Infinite-Video-Streams",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-StreamingVLM-Real-Time-Understanding-for-Infinite-Video-Streams/","children":"[논문리뷰] StreamingVLM: Real-Time Understanding for Infinite Video Streams"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kelly Peng이 [arXiv]에 게시한 'StreamingVLM: Real-Time Understanding for Infinite Video Streams' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Stream Understanding",{"className":"page__taxonomy-item","children":["#","Video Stream Understanding"]}],["$","span","Real-Time VLM",{"className":"page__taxonomy-item","children":["#","Real-Time VLM"]}],["$","span","Attention Sink",{"className":"page__taxonomy-item","children":["#","Attention Sink"]}],["$","span","KV Cache Management",{"className":"page__taxonomy-item","children":["#","KV Cache Management"]}],["$","span","Contiguous RoPE",{"className":"page__taxonomy-item","children":["#","Contiguous RoPE"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Long-Context Video",{"className":"page__taxonomy-item","children":["#","Long-Context Video"]}]]}]]}]]}],["$","article","2025-10-13-StatEval-A-Comprehensive-Benchmark-for-Large-Language-Models-in-Statistics",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-StatEval-A-Comprehensive-Benchmark-for-Large-Language-Models-in-Statistics/","children":"[논문리뷰] StatEval: A Comprehensive Benchmark for Large Language Models in Statistics"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'StatEval: A Comprehensive Benchmark for Large Language Models in Statistics' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Statistical Reasoning",{"className":"page__taxonomy-item","children":["#","Statistical Reasoning"]}],["$","span","LLM Benchmark",{"className":"page__taxonomy-item","children":["#","LLM Benchmark"]}],["$","span","Statistics Education",{"className":"page__taxonomy-item","children":["#","Statistics Education"]}],["$","span","Proof Verification",{"className":"page__taxonomy-item","children":["#","Proof Verification"]}],["$","span","Multi-agent Pipeline",{"className":"page__taxonomy-item","children":["#","Multi-agent Pipeline"]}],["$","span","Automated Extraction",{"className":"page__taxonomy-item","children":["#","Automated Extraction"]}],["$","span","Evaluation Framework",{"className":"page__taxonomy-item","children":["#","Evaluation Framework"]}]]}]]}]]}],["$","article","2025-10-13-Speculative-Jacobi-Denoising-Decoding-for-Accelerating-Autoregressive-Text-to-image-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Speculative-Jacobi-Denoising-Decoding-for-Accelerating-Autoregressive-Text-to-image-Generation/","children":"[논문리뷰] Speculative Jacobi-Denoising Decoding for Accelerating Autoregressive Text-to-image Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Han Shi이 [arXiv]에 게시한 'Speculative Jacobi-Denoising Decoding for Accelerating Autoregressive Text-to-image Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Autoregressive Models",{"className":"page__taxonomy-item","children":["#","Autoregressive Models"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Inference Acceleration",{"className":"page__taxonomy-item","children":["#","Inference Acceleration"]}],["$","span","Jacobi Decoding",{"className":"page__taxonomy-item","children":["#","Jacobi Decoding"]}],["$","span","Denoising Diffusion Models",{"className":"page__taxonomy-item","children":["#","Denoising Diffusion Models"]}],["$","span","Speculative Decoding",{"className":"page__taxonomy-item","children":["#","Speculative Decoding"]}],["$","span","Multi-token Prediction",{"className":"page__taxonomy-item","children":["#","Multi-token Prediction"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}]]}]]}]]}],["$","article","2025-10-13-SpaceVista-All-Scale-Visual-Spatial-Reasoning-from-mm-to-km",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-SpaceVista-All-Scale-Visual-Spatial-Reasoning-from-mm-to-km/","children":"[논문리뷰] SpaceVista: All-Scale Visual Spatial Reasoning from mm to km"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kaituo Feng이 [arXiv]에 게시한 'SpaceVista: All-Scale Visual Spatial Reasoning from mm to km' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}],["$","span","Multi-Scale Vision",{"className":"page__taxonomy-item","children":["#","Multi-Scale Vision"]}],["$","span","MLLM",{"className":"page__taxonomy-item","children":["#","MLLM"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}],["$","span","Scale Experts",{"className":"page__taxonomy-item","children":["#","Scale Experts"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Computer Vision",{"className":"page__taxonomy-item","children":["#","Computer Vision"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}]]}]]}]]}],["$","article","2025-10-13-ReviewerToo-Should-AI-Join-The-Program-Committee-A-Look-At-The-Future-of-Peer-Review",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-ReviewerToo-Should-AI-Join-The-Program-Committee-A-Look-At-The-Future-of-Peer-Review/","children":"[논문리뷰] ReviewerToo: Should AI Join The Program Committee? A Look At The Future of Peer Review"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Christopher Pal이 [arXiv]에 게시한 'ReviewerToo: Should AI Join The Program Committee? A Look At The Future of Peer Review' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Peer Review",{"className":"page__taxonomy-item","children":["#","Peer Review"]}],["$","span","AI-Assisted Review",{"className":"page__taxonomy-item","children":["#","AI-Assisted Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Meta-Review",{"className":"page__taxonomy-item","children":["#","Meta-Review"]}],["$","span","Conference Submissions",{"className":"page__taxonomy-item","children":["#","Conference Submissions"]}],["$","span","Reviewer Personas",{"className":"page__taxonomy-item","children":["#","Reviewer Personas"]}],["$","span","Evaluation Metrics",{"className":"page__taxonomy-item","children":["#","Evaluation Metrics"]}]]}]]}]]}],["$","article","2025-10-13-R-Horizon-How-Far-Can-Your-Large-Reasoning-Model-Really-Go-in-Breadth-and-Depth",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-R-Horizon-How-Far-Can-Your-Large-Reasoning-Model-Really-Go-in-Breadth-and-Depth/","children":"[논문리뷰] R-Horizon: How Far Can Your Large Reasoning Model Really Go in Breadth and Depth?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'R-Horizon: How Far Can Your Large Reasoning Model Really Go in Breadth and Depth?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Long-Horizon Reasoning",{"className":"page__taxonomy-item","children":["#","Long-Horizon Reasoning"]}],["$","span","Query Composition",{"className":"page__taxonomy-item","children":["#","Query Composition"]}],["$","span","Large Reasoning Models",{"className":"page__taxonomy-item","children":["#","Large Reasoning Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Benchmark Evaluation",{"className":"page__taxonomy-item","children":["#","Benchmark Evaluation"]}],["$","span","Thinking Budget",{"className":"page__taxonomy-item","children":["#","Thinking Budget"]}],["$","span","Performance Degradation",{"className":"page__taxonomy-item","children":["#","Performance Degradation"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}]]}]]}]]}],["$","article","2025-10-13-Pseudo2Real-Task-Arithmetic-for-Pseudo-Label-Correction-in-Automatic-Speech-Recognition",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Pseudo2Real-Task-Arithmetic-for-Pseudo-Label-Correction-in-Automatic-Speech-Recognition/","children":"[논문리뷰] Pseudo2Real: Task Arithmetic for Pseudo-Label Correction in Automatic Speech Recognition"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shang-Tse Chen이 [arXiv]에 게시한 'Pseudo2Real: Task Arithmetic for Pseudo-Label Correction in Automatic Speech Recognition' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","ASR",{"className":"page__taxonomy-item","children":["#","ASR"]}],["$","span","Pseudo-labeling",{"className":"page__taxonomy-item","children":["#","Pseudo-labeling"]}],["$","span","Domain Adaptation",{"className":"page__taxonomy-item","children":["#","Domain Adaptation"]}],["$","span","Task Arithmetic",{"className":"page__taxonomy-item","children":["#","Task Arithmetic"]}],["$","span","Correction Vector",{"className":"page__taxonomy-item","children":["#","Correction Vector"]}],["$","span","Accent Adaptation",{"className":"page__taxonomy-item","children":["#","Accent Adaptation"]}],["$","span","Speaker Clustering",{"className":"page__taxonomy-item","children":["#","Speaker Clustering"]}],["$","span","Model Editing",{"className":"page__taxonomy-item","children":["#","Model Editing"]}]]}]]}]]}],["$","article","2025-10-13-Progressive-Gaussian-Transformer-with-Anisotropy-aware-Sampling-for-Open-Vocabulary-Occupancy-Prediction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Progressive-Gaussian-Transformer-with-Anisotropy-aware-Sampling-for-Open-Vocabulary-Occupancy-Prediction/","children":"[논문리뷰] Progressive Gaussian Transformer with Anisotropy-aware Sampling for Open Vocabulary Occupancy Prediction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"danxuhk이 [arXiv]에 게시한 'Progressive Gaussian Transformer with Anisotropy-aware Sampling for Open Vocabulary Occupancy Prediction' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Occupancy Prediction",{"className":"page__taxonomy-item","children":["#","3D Occupancy Prediction"]}],["$","span","Open Vocabulary",{"className":"page__taxonomy-item","children":["#","Open Vocabulary"]}],["$","span","Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","Gaussian Splatting"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Progressive Densification",{"className":"page__taxonomy-item","children":["#","Progressive Densification"]}],["$","span","Anisotropy-aware Sampling",{"className":"page__taxonomy-item","children":["#","Anisotropy-aware Sampling"]}],["$","span","Autonomous Driving",{"className":"page__taxonomy-item","children":["#","Autonomous Driving"]}]]}]]}]]}],["$","article","2025-10-13-PhysToolBench-Benchmarking-Physical-Tool-Understanding-for-MLLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-PhysToolBench-Benchmarking-Physical-Tool-Understanding-for-MLLMs/","children":"[논문리뷰] PhysToolBench: Benchmarking Physical Tool Understanding for MLLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xu Zheng이 [arXiv]에 게시한 'PhysToolBench: Benchmarking Physical Tool Understanding for MLLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models (MLLMs)"]}],["$","span","Physical Tool Understanding",{"className":"page__taxonomy-item","children":["#","Physical Tool Understanding"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Visual Question Answering (VQA)",{"className":"page__taxonomy-item","children":["#","Visual Question Answering (VQA)"]}],["$","span","Tool Affordances",{"className":"page__taxonomy-item","children":["#","Tool Affordances"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}]]}]]}]]}],["$","article","2025-10-13-Parallel-Test-Time-Scaling-for-Latent-Reasoning-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Parallel-Test-Time-Scaling-for-Latent-Reasoning-Models/","children":"[논문리뷰] Parallel Test-Time Scaling for Latent Reasoning Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Parallel Test-Time Scaling for Latent Reasoning Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Latent Reasoning",{"className":"page__taxonomy-item","children":["#","Latent Reasoning"]}],["$","span","Test-Time Scaling",{"className":"page__taxonomy-item","children":["#","Test-Time Scaling"]}],["$","span","Parallel Inference",{"className":"page__taxonomy-item","children":["#","Parallel Inference"]}],["$","span","Stochastic Sampling",{"className":"page__taxonomy-item","children":["#","Stochastic Sampling"]}],["$","span","Monte Carlo Dropout",{"className":"page__taxonomy-item","children":["#","Monte Carlo Dropout"]}],["$","span","Additive Gaussian Noise",{"className":"page__taxonomy-item","children":["#","Additive Gaussian Noise"]}],["$","span","Latent Reward Model",{"className":"page__taxonomy-item","children":["#","Latent Reward Model"]}],["$","span","Trajectory Aggregation",{"className":"page__taxonomy-item","children":["#","Trajectory Aggregation"]}]]}]]}]]}],["$","article","2025-10-13-One-Patch-to-Caption-Them-All-A-Unified-Zero-Shot-Captioning-Framework",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-One-Patch-to-Caption-Them-All-A-Unified-Zero-Shot-Captioning-Framework/","children":"[논문리뷰] One Patch to Caption Them All: A Unified Zero-Shot Captioning Framework"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Giuseppe Amato이 [arXiv]에 게시한 'One Patch to Caption Them All: A Unified Zero-Shot Captioning Framework' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Zero-Shot Captioning",{"className":"page__taxonomy-item","children":["#","Zero-Shot Captioning"]}],["$","span","Region-Level Captioning",{"className":"page__taxonomy-item","children":["#","Region-Level Captioning"]}],["$","span","Vision Transformers",{"className":"page__taxonomy-item","children":["#","Vision Transformers"]}],["$","span","DINOv2",{"className":"page__taxonomy-item","children":["#","DINOv2"]}],["$","span","Patch-Centric",{"className":"page__taxonomy-item","children":["#","Patch-Centric"]}],["$","span","Modality Gap Mitigation",{"className":"page__taxonomy-item","children":["#","Modality Gap Mitigation"]}],["$","span","Visual-Language Models",{"className":"page__taxonomy-item","children":["#","Visual-Language Models"]}]]}]]}]]}],["$","article","2025-10-13-Multimodal-Prompt-Optimization-Why-Not-Leverage-Multiple-Modalities-for-MLLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Multimodal-Prompt-Optimization-Why-Not-Leverage-Multiple-Modalities-for-MLLMs/","children":"[논문리뷰] Multimodal Prompt Optimization: Why Not Leverage Multiple Modalities for MLLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Multimodal Prompt Optimization: Why Not Leverage Multiple Modalities for MLLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Prompt Optimization",{"className":"page__taxonomy-item","children":["#","Prompt Optimization"]}],["$","span","MLLMs",{"className":"page__taxonomy-item","children":["#","MLLMs"]}],["$","span","Bayesian Optimization",{"className":"page__taxonomy-item","children":["#","Bayesian Optimization"]}],["$","span","Cross-modal Alignment",{"className":"page__taxonomy-item","children":["#","Cross-modal Alignment"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Exploration-Exploitation",{"className":"page__taxonomy-item","children":["#","Exploration-Exploitation"]}]]}]]}]]}],["$","article","2025-10-13-Mitigating-Overthinking-through-Reasoning-Shaping",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Mitigating-Overthinking-through-Reasoning-Shaping/","children":"[논문리뷰] Mitigating Overthinking through Reasoning Shaping"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wen Luo이 [arXiv]에 게시한 'Mitigating Overthinking through Reasoning Shaping' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Reasoning Models (LRMs)",{"className":"page__taxonomy-item","children":["#","Large Reasoning Models (LRMs)"]}],["$","span","RLVR",{"className":"page__taxonomy-item","children":["#","RLVR"]}],["$","span","Overthinking Mitigation",{"className":"page__taxonomy-item","children":["#","Overthinking Mitigation"]}],["$","span","Reasoning Shaping",{"className":"page__taxonomy-item","children":["#","Reasoning Shaping"]}],["$","span","Segment-level Penalization",{"className":"page__taxonomy-item","children":["#","Segment-level Penalization"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}],["$","span","Training Stability",{"className":"page__taxonomy-item","children":["#","Training Stability"]}],["$","span","Length-aware Weighting",{"className":"page__taxonomy-item","children":["#","Length-aware Weighting"]}]]}]]}]]}],["$","article","2025-10-13-MRMR-A-Realistic-and-Expert-Level-Multidisciplinary-Benchmark-for-Reasoning-Intensive-Multimodal-Retrieval",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-MRMR-A-Realistic-and-Expert-Level-Multidisciplinary-Benchmark-for-Reasoning-Intensive-Multimodal-Retrieval/","children":"[논문리뷰] MRMR: A Realistic and Expert-Level Multidisciplinary Benchmark for Reasoning-Intensive Multimodal Retrieval"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Tingyu Song이 [arXiv]에 게시한 'MRMR: A Realistic and Expert-Level Multidisciplinary Benchmark for Reasoning-Intensive Multimodal Retrieval' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Retrieval",{"className":"page__taxonomy-item","children":["#","Multimodal Retrieval"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Multidisciplinary",{"className":"page__taxonomy-item","children":["#","Multidisciplinary"]}],["$","span","Expert-Level",{"className":"page__taxonomy-item","children":["#","Expert-Level"]}],["$","span","Image-Text Interleaving",{"className":"page__taxonomy-item","children":["#","Image-Text Interleaving"]}],["$","span","Contradiction Retrieval",{"className":"page__taxonomy-item","children":["#","Contradiction Retrieval"]}]]}]]}]]}],["$","article","2025-10-13-KORMo-Korean-Open-Reasoning-Model-for-Everyone",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-KORMo-Korean-Open-Reasoning-Model-for-Everyone/","children":"[논문리뷰] KORMo: Korean Open Reasoning Model for Everyone"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'KORMo: Korean Open Reasoning Model for Everyone' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Model",{"className":"page__taxonomy-item","children":["#","Large Language Model"]}],["$","span","Korean",{"className":"page__taxonomy-item","children":["#","Korean"]}],["$","span","Bilingual",{"className":"page__taxonomy-item","children":["#","Bilingual"]}],["$","span","Synthetic Data",{"className":"page__taxonomy-item","children":["#","Synthetic Data"]}],["$","span","Fully Open Model",{"className":"page__taxonomy-item","children":["#","Fully Open Model"]}],["$","span","Tokenizer",{"className":"page__taxonomy-item","children":["#","Tokenizer"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Pretraining",{"className":"page__taxonomy-item","children":["#","Pretraining"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}]]}]]}]]}],["$","article","2025-10-13-Instant4D-4D-Gaussian-Splatting-in-Minutes",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Instant4D-4D-Gaussian-Splatting-in-Minutes/","children":"[논문리뷰] Instant4D: 4D Gaussian Splatting in Minutes"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Li Lu이 [arXiv]에 게시한 'Instant4D: 4D Gaussian Splatting in Minutes' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","4D Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","4D Gaussian Splatting"]}],["$","span","Dynamic View Synthesis",{"className":"page__taxonomy-item","children":["#","Dynamic View Synthesis"]}],["$","span","Monocular Reconstruction",{"className":"page__taxonomy-item","children":["#","Monocular Reconstruction"]}],["$","span","Visual SLAM",{"className":"page__taxonomy-item","children":["#","Visual SLAM"]}],["$","span","Grid Pruning",{"className":"page__taxonomy-item","children":["#","Grid Pruning"]}],["$","span","Real-time Rendering",{"className":"page__taxonomy-item","children":["#","Real-time Rendering"]}],["$","span","GPU Memory Optimization",{"className":"page__taxonomy-item","children":["#","GPU Memory Optimization"]}]]}]]}]]}],["$","article","2025-10-13-Hybrid-grained-Feature-Aggregation-with-Coarse-to-fine-Language-Guidance-for-Self-supervised-Monocular-Depth-Estimation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Hybrid-grained-Feature-Aggregation-with-Coarse-to-fine-Language-Guidance-for-Self-supervised-Monocular-Depth-Estimation/","children":"[논문리뷰] Hybrid-grained Feature Aggregation with Coarse-to-fine Language Guidance for Self-supervised Monocular Depth Estimation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zekun Qi이 [arXiv]에 게시한 'Hybrid-grained Feature Aggregation with Coarse-to-fine Language Guidance for Self-supervised Monocular Depth Estimation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Self-supervised Monocular Depth Estimation",{"className":"page__taxonomy-item","children":["#","Self-supervised Monocular Depth Estimation"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","CLIP",{"className":"page__taxonomy-item","children":["#","CLIP"]}],["$","span","DINO",{"className":"page__taxonomy-item","children":["#","DINO"]}],["$","span","Language Guidance",{"className":"page__taxonomy-item","children":["#","Language Guidance"]}],["$","span","Coarse-to-fine Learning",{"className":"page__taxonomy-item","children":["#","Coarse-to-fine Learning"]}],["$","span","Feature Aggregation",{"className":"page__taxonomy-item","children":["#","Feature Aggregation"]}],["$","span","3D Perception",{"className":"page__taxonomy-item","children":["#","3D Perception"]}]]}]]}]]}],["$","article","2025-10-13-GTAlign-Game-Theoretic-Alignment-of-LLM-Assistants-for-Mutual-Welfare",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-GTAlign-Game-Theoretic-Alignment-of-LLM-Assistants-for-Mutual-Welfare/","children":"[논문리뷰] GTAlign: Game-Theoretic Alignment of LLM Assistants for Mutual Welfare"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'GTAlign: Game-Theoretic Alignment of LLM Assistants for Mutual Welfare' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","LLM Alignment",{"className":"page__taxonomy-item","children":["#","LLM Alignment"]}],["$","span","Game Theory",{"className":"page__taxonomy-item","children":["#","Game Theory"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Mutual Welfare",{"className":"page__taxonomy-item","children":["#","Mutual Welfare"]}],["$","span","Payoff Matrix",{"className":"page__taxonomy-item","children":["#","Payoff Matrix"]}],["$","span","Strategic Decision Making",{"className":"page__taxonomy-item","children":["#","Strategic Decision Making"]}],["$","span","Human-AI Interaction",{"className":"page__taxonomy-item","children":["#","Human-AI Interaction"]}]]}]]}]]}],["$","article","2025-10-13-Dyna-Mind-Learning-to-Simulate-from-Experience-for-Better-AI-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Dyna-Mind-Learning-to-Simulate-from-Experience-for-Better-AI-Agents/","children":"[논문리뷰] Dyna-Mind: Learning to Simulate from Experience for Better AI Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Qianhui Wu이 [arXiv]에 게시한 'Dyna-Mind: Learning to Simulate from Experience for Better AI Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Agents",{"className":"page__taxonomy-item","children":["#","AI Agents"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","World Models",{"className":"page__taxonomy-item","children":["#","World Models"]}],["$","span","Simulation",{"className":"page__taxonomy-item","children":["#","Simulation"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Language Models",{"className":"page__taxonomy-item","children":["#","Language Models"]}],["$","span","Planning",{"className":"page__taxonomy-item","children":["#","Planning"]}],["$","span","Interactive AI",{"className":"page__taxonomy-item","children":["#","Interactive AI"]}]]}]]}]]}],["$","article","2025-10-13-Dont-Waste-Mistakes-Leveraging-Negative-RL-Groups-via-Confidence-Reweighting",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Dont-Waste-Mistakes-Leveraging-Negative-RL-Groups-via-Confidence-Reweighting/","children":"[논문리뷰] Don't Waste Mistakes: Leveraging Negative RL-Groups via Confidence Reweighting"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Julia Kempe이 [arXiv]에 게시한 'Don't Waste Mistakes: Leveraging Negative RL-Groups via Confidence Reweighting' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reasoning Tasks",{"className":"page__taxonomy-item","children":["#","Reasoning Tasks"]}],["$","span","GRPO",{"className":"page__taxonomy-item","children":["#","GRPO"]}],["$","span","Negative Samples",{"className":"page__taxonomy-item","children":["#","Negative Samples"]}],["$","span","Reward Modeling",{"className":"page__taxonomy-item","children":["#","Reward Modeling"]}],["$","span","Confidence Reweighting",{"className":"page__taxonomy-item","children":["#","Confidence Reweighting"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}]]}]]}]]}],["$","article","2025-10-13-DISCO-Diversifying-Sample-Condensation-for-Efficient-Model-Evaluation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-DISCO-Diversifying-Sample-Condensation-for-Efficient-Model-Evaluation/","children":"[논문리뷰] DISCO: Diversifying Sample Condensation for Efficient Model Evaluation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DISCO: Diversifying Sample Condensation for Efficient Model Evaluation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Efficient Evaluation",{"className":"page__taxonomy-item","children":["#","Efficient Evaluation"]}],["$","span","Sample Condensation",{"className":"page__taxonomy-item","children":["#","Sample Condensation"]}],["$","span","Model Disagreement",{"className":"page__taxonomy-item","children":["#","Model Disagreement"]}],["$","span","Predictive Diversity",{"className":"page__taxonomy-item","children":["#","Predictive Diversity"]}],["$","span","Performance Prediction",{"className":"page__taxonomy-item","children":["#","Performance Prediction"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Model Signatures",{"className":"page__taxonomy-item","children":["#","Model Signatures"]}],["$","span","Meta-modeling",{"className":"page__taxonomy-item","children":["#","Meta-modeling"]}]]}]]}]]}],["$","article","2025-10-13-D2E-Scaling-Vision-Action-Pretraining-on-Desktop-Data-for-Transfer-to-Embodied-AI",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-D2E-Scaling-Vision-Action-Pretraining-on-Desktop-Data-for-Transfer-to-Embodied-AI/","children":"[논문리뷰] D2E: Scaling Vision-Action Pretraining on Desktop Data for Transfer to Embodied AI"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Haebin Seong이 [arXiv]에 게시한 'D2E: Scaling Vision-Action Pretraining on Desktop Data for Transfer to Embodied AI' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Vision-Action Pretraining",{"className":"page__taxonomy-item","children":["#","Vision-Action Pretraining"]}],["$","span","Desktop Data",{"className":"page__taxonomy-item","children":["#","Desktop Data"]}],["$","span","Inverse Dynamics Model (IDM)",{"className":"page__taxonomy-item","children":["#","Inverse Dynamics Model (IDM)"]}],["$","span","Pseudo-labeling",{"className":"page__taxonomy-item","children":["#","Pseudo-labeling"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Data Compression",{"className":"page__taxonomy-item","children":["#","Data Compression"]}]]}]]}]]}],["$","article","2025-10-13-Bridging-Reasoning-to-Learning-Unmasking-Illusions-using-Complexity-Out-of-Distribution-Generalization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Bridging-Reasoning-to-Learning-Unmasking-Illusions-using-Complexity-Out-of-Distribution-Generalization/","children":"[논문리뷰] Bridging Reasoning to Learning: Unmasking Illusions using Complexity Out of Distribution Generalization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Mahdi Ghaznavai이 [arXiv]에 게시한 'Bridging Reasoning to Learning: Unmasking Illusions using Complexity Out of Distribution Generalization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Complexity OoD Generalization",{"className":"page__taxonomy-item","children":["#","Complexity OoD Generalization"]}],["$","span","System-1 Thinking",{"className":"page__taxonomy-item","children":["#","System-1 Thinking"]}],["$","span","System-2 Reasoning",{"className":"page__taxonomy-item","children":["#","System-2 Reasoning"]}],["$","span","Kolmogorov Complexity",{"className":"page__taxonomy-item","children":["#","Kolmogorov Complexity"]}],["$","span","Inductive Biases",{"className":"page__taxonomy-item","children":["#","Inductive Biases"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Reasoning Evaluation",{"className":"page__taxonomy-item","children":["#","Reasoning Evaluation"]}]]}]]}]]}],["$","article","2025-10-13-BigCodeArena-Unveiling-More-Reliable-Human-Preferences-in-Code-Generation-via-Execution",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-BigCodeArena-Unveiling-More-Reliable-Human-Preferences-in-Code-Generation-via-Execution/","children":"[논문리뷰] BigCodeArena: Unveiling More Reliable Human Preferences in Code Generation via Execution"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hange Liu이 [arXiv]에 게시한 'BigCodeArena: Unveiling More Reliable Human Preferences in Code Generation via Execution' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","Human Preference",{"className":"page__taxonomy-item","children":["#","Human Preference"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Execution Feedback",{"className":"page__taxonomy-item","children":["#","Execution Feedback"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Crowdsourcing",{"className":"page__taxonomy-item","children":["#","Crowdsourcing"]}],["$","span","Software Engineering",{"className":"page__taxonomy-item","children":["#","Software Engineering"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}]]}]]}]]}],["$","article","2025-10-13-Better-Together-Leveraging-Unpaired-Multimodal-Data-for-Stronger-Unimodal-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Better-Together-Leveraging-Unpaired-Multimodal-Data-for-Stronger-Unimodal-Models/","children":"[논문리뷰] Better Together: Leveraging Unpaired Multimodal Data for Stronger Unimodal Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Better Together: Leveraging Unpaired Multimodal Data for Stronger Unimodal Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Unpaired Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Unpaired Multimodal Learning"]}],["$","span","Unimodal Representation",{"className":"page__taxonomy-item","children":["#","Unimodal Representation"]}],["$","span","Weight Sharing",{"className":"page__taxonomy-item","children":["#","Weight Sharing"]}],["$","span","Cross-modal Transfer",{"className":"page__taxonomy-item","children":["#","Cross-modal Transfer"]}],["$","span","Fisher Information",{"className":"page__taxonomy-item","children":["#","Fisher Information"]}],["$","span","Self-supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-supervised Learning"]}],["$","span","Multimodal Neurons",{"className":"page__taxonomy-item","children":["#","Multimodal Neurons"]}],["$","span","Data Efficiency",{"className":"page__taxonomy-item","children":["#","Data Efficiency"]}]]}]]}]]}],["$","article","2025-10-13-AutoPR-Lets-Automate-Your-Academic-Promotion",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-AutoPR-Lets-Automate-Your-Academic-Promotion/","children":"[논문리뷰] AutoPR: Let's Automate Your Academic Promotion!"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yixin Yuan이 [arXiv]에 게시한 'AutoPR: Let's Automate Your Academic Promotion!' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Academic Promotion",{"className":"page__taxonomy-item","children":["#","Academic Promotion"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Scholarly Communication",{"className":"page__taxonomy-item","children":["#","Scholarly Communication"]}],["$","span","Multimodal Processing",{"className":"page__taxonomy-item","children":["#","Multimodal Processing"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Content Generation",{"className":"page__taxonomy-item","children":["#","Content Generation"]}],["$","span","Social Media Marketing",{"className":"page__taxonomy-item","children":["#","Social Media Marketing"]}]]}]]}]]}],["$","article","2025-10-13-Adaptive-Attacks-on-Trusted-Monitors-Subvert-AI-Control-Protocols",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Adaptive-Attacks-on-Trusted-Monitors-Subvert-AI-Control-Protocols/","children":"[논문리뷰] Adaptive Attacks on Trusted Monitors Subvert AI Control Protocols"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Maksym Andriushchenko이 [arXiv]에 게시한 'Adaptive Attacks on Trusted Monitors Subvert AI Control Protocols' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Control Protocols",{"className":"page__taxonomy-item","children":["#","AI Control Protocols"]}],["$","span","LLM Monitors",{"className":"page__taxonomy-item","children":["#","LLM Monitors"]}],["$","span","Adaptive Attacks",{"className":"page__taxonomy-item","children":["#","Adaptive Attacks"]}],["$","span","Prompt Injection",{"className":"page__taxonomy-item","children":["#","Prompt Injection"]}],["$","span","Jailbreaking",{"className":"page__taxonomy-item","children":["#","Jailbreaking"]}],["$","span","Red Teaming",{"className":"page__taxonomy-item","children":["#","Red Teaming"]}],["$","span","Scalable Oversight",{"className":"page__taxonomy-item","children":["#","Scalable Oversight"]}]]}]]}]]}],["$","article","2025-10-13-ARES-Multimodal-Adaptive-Reasoning-via-Difficulty-Aware-Token-Level-Entropy-Shaping",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-ARES-Multimodal-Adaptive-Reasoning-via-Difficulty-Aware-Token-Level-Entropy-Shaping/","children":"[논문리뷰] ARES: Multimodal Adaptive Reasoning via Difficulty-Aware Token-Level Entropy Shaping"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wenbo Hu이 [arXiv]에 게시한 'ARES: Multimodal Adaptive Reasoning via Difficulty-Aware Token-Level Entropy Shaping' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","span","Adaptive Learning",{"className":"page__taxonomy-item","children":["#","Adaptive Learning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Entropy Shaping",{"className":"page__taxonomy-item","children":["#","Entropy Shaping"]}],["$","span","Difficulty-Aware",{"className":"page__taxonomy-item","children":["#","Difficulty-Aware"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Token-Level Analysis",{"className":"page__taxonomy-item","children":["#","Token-Level Analysis"]}]]}]]}]]}],["$","article","2025-10-13-ACE-Attribution-Controlled-Knowledge-Editing-for-Multi-hop-Factual-Recall",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-ACE-Attribution-Controlled-Knowledge-Editing-for-Multi-hop-Factual-Recall/","children":"[논문리뷰] ACE: Attribution-Controlled Knowledge Editing for Multi-hop Factual Recall"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiaqi Tang이 [arXiv]에 게시한 'ACE: Attribution-Controlled Knowledge Editing for Multi-hop Factual Recall' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Knowledge Editing",{"className":"page__taxonomy-item","children":["#","Knowledge Editing"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Multi-hop Reasoning",{"className":"page__taxonomy-item","children":["#","Multi-hop Reasoning"]}],["$","span","Mechanistic Interpretability",{"className":"page__taxonomy-item","children":["#","Mechanistic Interpretability"]}],["$","span","Neuron-level Attribution",{"className":"page__taxonomy-item","children":["#","Neuron-level Attribution"]}],["$","span","Factual Recall",{"className":"page__taxonomy-item","children":["#","Factual Recall"]}],["$","span","Transformer Networks",{"className":"page__taxonomy-item","children":["#","Transformer Networks"]}]]}]]}]]}],["$","article","2025-10-13-A-Goal-Without-a-Plan-Is-Just-a-Wish-Efficient-and-Effective-Global-Planner-Training-for-Long-Horizon-Agent-Tasks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-A-Goal-Without-a-Plan-Is-Just-a-Wish-Efficient-and-Effective-Global-Planner-Training-for-Long-Horizon-Agent-Tasks/","children":"[논문리뷰] A Goal Without a Plan Is Just a Wish: Efficient and Effective Global Planner Training for Long-Horizon Agent Tasks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Fanchao Qi이 [arXiv]에 게시한 'A Goal Without a Plan Is Just a Wish: Efficient and Effective Global Planner Training for Long-Horizon Agent Tasks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Long-Horizon Tasks",{"className":"page__taxonomy-item","children":["#","Long-Horizon Tasks"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Global Planning",{"className":"page__taxonomy-item","children":["#","Global Planning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Homologous Consensus Filtering",{"className":"page__taxonomy-item","children":["#","Homologous Consensus Filtering"]}],["$","span","Executor Capability Gain Reward",{"className":"page__taxonomy-item","children":["#","Executor Capability Gain Reward"]}],["$","span","Plan-and-Execute",{"className":"page__taxonomy-item","children":["#","Plan-and-Execute"]}]]}]]}]]}],["$","article","2025-10-10-When-Thoughts-Meet-Facts-Reusable-Reasoning-for-Long-Context-LMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-When-Thoughts-Meet-Facts-Reusable-Reasoning-for-Long-Context-LMs/","children":"[논문리뷰] When Thoughts Meet Facts: Reusable Reasoning for Long-Context LMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'When Thoughts Meet Facts: Reusable Reasoning for Long-Context LMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Long-Context LMs",{"className":"page__taxonomy-item","children":["#","Long-Context LMs"]}],["$","span","Multi-hop Reasoning",{"className":"page__taxonomy-item","children":["#","Multi-hop Reasoning"]}],["$","span","Thought Templates",{"className":"page__taxonomy-item","children":["#","Thought Templates"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","Natural Language Feedback",{"className":"page__taxonomy-item","children":["#","Natural Language Feedback"]}],["$","span","Knowledge-intensive QA",{"className":"page__taxonomy-item","children":["#","Knowledge-intensive QA"]}],["$","span","Reasoning Reuse",{"className":"page__taxonomy-item","children":["#","Reasoning Reuse"]}]]}]]}]]}],["$","article","2025-10-10-VideoCanvas-Unified-Video-Completion-from-Arbitrary-Spatiotemporal-Patches-via-In-Context-Conditioning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-VideoCanvas-Unified-Video-Completion-from-Arbitrary-Spatiotemporal-Patches-via-In-Context-Conditioning/","children":"[논문리뷰] VideoCanvas: Unified Video Completion from Arbitrary Spatiotemporal Patches via In-Context Conditioning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Quande Liu이 [arXiv]에 게시한 'VideoCanvas: Unified Video Completion from Arbitrary Spatiotemporal Patches via In-Context Conditioning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Completion",{"className":"page__taxonomy-item","children":["#","Video Completion"]}],["$","span","Spatio-Temporal Control",{"className":"page__taxonomy-item","children":["#","Spatio-Temporal Control"]}],["$","span","In-Context Conditioning",{"className":"page__taxonomy-item","children":["#","In-Context Conditioning"]}],["$","span","Video Diffusion Models",{"className":"page__taxonomy-item","children":["#","Video Diffusion Models"]}],["$","span","RoPE Interpolation",{"className":"page__taxonomy-item","children":["#","RoPE Interpolation"]}],["$","span","VAE",{"className":"page__taxonomy-item","children":["#","VAE"]}],["$","span","Unified Framework",{"className":"page__taxonomy-item","children":["#","Unified Framework"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}]]}]]}]]}],["$","article","2025-10-10-UniVideo-Unified-Understanding-Generation-and-Editing-for-Videos",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-UniVideo-Unified-Understanding-Generation-and-Editing-for-Videos/","children":"[논문리뷰] UniVideo: Unified Understanding, Generation, and Editing for Videos"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xintao Wang이 [arXiv]에 게시한 'UniVideo: Unified Understanding, Generation, and Editing for Videos' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Unified Multimodal Model",{"className":"page__taxonomy-item","children":["#","Unified Multimodal Model"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Video Editing",{"className":"page__taxonomy-item","children":["#","Video Editing"]}],["$","span","MLLM",{"className":"page__taxonomy-item","children":["#","MLLM"]}],["$","span","Diffusion Transformer",{"className":"page__taxonomy-item","children":["#","Diffusion Transformer"]}],["$","span","In-Context Learning",{"className":"page__taxonomy-item","children":["#","In-Context Learning"]}],["$","span","Zero-shot Generalization",{"className":"page__taxonomy-item","children":["#","Zero-shot Generalization"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}]]}]]}]]}],["$","article","2025-10-10-UniMMVSR-A-Unified-Multi-Modal-Framework-for-Cascaded-Video-Super-Resolution",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-UniMMVSR-A-Unified-Multi-Modal-Framework-for-Cascaded-Video-Super-Resolution/","children":"[논문리뷰] UniMMVSR: A Unified Multi-Modal Framework for Cascaded Video Super-Resolution"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'UniMMVSR: A Unified Multi-Modal Framework for Cascaded Video Super-Resolution' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Super-Resolution",{"className":"page__taxonomy-item","children":["#","Video Super-Resolution"]}],["$","span","Multi-Modal Generation",{"className":"page__taxonomy-item","children":["#","Multi-Modal Generation"]}],["$","span","Latent Diffusion Models",{"className":"page__taxonomy-item","children":["#","Latent Diffusion Models"]}],["$","span","Cascaded Framework",{"className":"page__taxonomy-item","children":["#","Cascaded Framework"]}],["$","span","Condition Injection",{"className":"page__taxonomy-item","children":["#","Condition Injection"]}],["$","span","Text-to-Video",{"className":"page__taxonomy-item","children":["#","Text-to-Video"]}],["$","span","Video Editing",{"className":"page__taxonomy-item","children":["#","Video Editing"]}],["$","span","4K Video",{"className":"page__taxonomy-item","children":["#","4K Video"]}]]}]]}]]}],["$","article","2025-10-10-UP2You-Fast-Reconstruction-of-Yourself-from-Unconstrained-Photo-Collections",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-UP2You-Fast-Reconstruction-of-Yourself-from-Unconstrained-Photo-Collections/","children":"[논문리뷰] UP2You: Fast Reconstruction of Yourself from Unconstrained Photo Collections"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Boqian Li이 [arXiv]에 게시한 'UP2You: Fast Reconstruction of Yourself from Unconstrained Photo Collections' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Human Reconstruction",{"className":"page__taxonomy-item","children":["#","3D Human Reconstruction"]}],["$","span","Unconstrained Photos",{"className":"page__taxonomy-item","children":["#","Unconstrained Photos"]}],["$","span","Data Rectifier",{"className":"page__taxonomy-item","children":["#","Data Rectifier"]}],["$","span","Multi-View Generation",{"className":"page__taxonomy-item","children":["#","Multi-View Generation"]}],["$","span","Pose-Correlated Feature Aggregation",{"className":"page__taxonomy-item","children":["#","Pose-Correlated Feature Aggregation"]}],["$","span","SMPL-X",{"className":"page__taxonomy-item","children":["#","SMPL-X"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Virtual Try-On",{"className":"page__taxonomy-item","children":["#","Virtual Try-On"]}]]}]]}]]}],["$","article","2025-10-10-UNIDOC-BENCH-A-Unified-Benchmark-for-Document-Centric-Multimodal-RAG",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-UNIDOC-BENCH-A-Unified-Benchmark-for-Document-Centric-Multimodal-RAG/","children":"[논문리뷰] UNIDOC-BENCH: A Unified Benchmark for Document-Centric Multimodal RAG"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'UNIDOC-BENCH: A Unified Benchmark for Document-Centric Multimodal RAG' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal RAG",{"className":"page__taxonomy-item","children":["#","Multimodal RAG"]}],["$","span","Document AI",{"className":"page__taxonomy-item","children":["#","Document AI"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Information Retrieval",{"className":"page__taxonomy-item","children":["#","Information Retrieval"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Multimodal Embeddings",{"className":"page__taxonomy-item","children":["#","Multimodal Embeddings"]}],["$","span","PDF Processing",{"className":"page__taxonomy-item","children":["#","PDF Processing"]}],["$","span","Question Answering",{"className":"page__taxonomy-item","children":["#","Question Answering"]}]]}]]}]]}],["$","article","2025-10-10-Training-Free-Group-Relative-Policy-Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Training-Free-Group-Relative-Policy-Optimization/","children":"[논문리뷰] Training-Free Group Relative Policy Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Training-Free Group Relative Policy Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Parameter-Free Optimization",{"className":"page__taxonomy-item","children":["#","Parameter-Free Optimization"]}],["$","span","Experiential Knowledge",{"className":"page__taxonomy-item","children":["#","Experiential Knowledge"]}],["$","span","Token Prior",{"className":"page__taxonomy-item","children":["#","Token Prior"]}],["$","span","Group Relative Policy Optimization",{"className":"page__taxonomy-item","children":["#","Group Relative Policy Optimization"]}],["$","span","In-Context Learning",{"className":"page__taxonomy-item","children":["#","In-Context Learning"]}],["$","span","Cost-Effective AI",{"className":"page__taxonomy-item","children":["#","Cost-Effective AI"]}]]}]]}]]}],["$","article","2025-10-10-Towards-Scalable-and-Consistent-3D-Editing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Towards-Scalable-and-Consistent-3D-Editing/","children":"[논문리뷰] Towards Scalable and Consistent 3D Editing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Pan Zhou이 [arXiv]에 게시한 'Towards Scalable and Consistent 3D Editing' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Editing",{"className":"page__taxonomy-item","children":["#","3D Editing"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Dataset Generation",{"className":"page__taxonomy-item","children":["#","Dataset Generation"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Conditional Generation",{"className":"page__taxonomy-item","children":["#","Conditional Generation"]}],["$","span","Image-to-3D",{"className":"page__taxonomy-item","children":["#","Image-to-3D"]}]]}]]}]]}],["$","article","2025-10-10-The-Alignment-Waltz-Jointly-Training-Agents-to-Collaborate-for-Safety",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-The-Alignment-Waltz-Jointly-Training-Agents-to-Collaborate-for-Safety/","children":"[논문리뷰] The Alignment Waltz: Jointly Training Agents to Collaborate for Safety"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'The Alignment Waltz: Jointly Training Agents to Collaborate for Safety' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Safety",{"className":"page__taxonomy-item","children":["#","LLM Safety"]}],["$","span","Multi-agent Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Multi-agent Reinforcement Learning"]}],["$","span","Safety Alignment",{"className":"page__taxonomy-item","children":["#","Safety Alignment"]}],["$","span","Overrefusal",{"className":"page__taxonomy-item","children":["#","Overrefusal"]}],["$","span","Adversarial Attacks",{"className":"page__taxonomy-item","children":["#","Adversarial Attacks"]}],["$","span","Feedback Agent",{"className":"page__taxonomy-item","children":["#","Feedback Agent"]}],["$","span","Conversation Agent",{"className":"page__taxonomy-item","children":["#","Conversation Agent"]}],["$","span","Dynamic Improvement Reward",{"className":"page__taxonomy-item","children":["#","Dynamic Improvement Reward"]}]]}]]}]]}],["$","article","2025-10-10-Taming-Text-to-Sounding-Video-Generation-via-Advanced-Modality-Condition-and-Interaction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Taming-Text-to-Sounding-Video-Generation-via-Advanced-Modality-Condition-and-Interaction/","children":"[논문리뷰] Taming Text-to-Sounding Video Generation via Advanced Modality Condition and Interaction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Taming Text-to-Sounding Video Generation via Advanced Modality Condition and Interaction' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Sounding Video Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Sounding Video Generation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Dual-tower Architecture",{"className":"page__taxonomy-item","children":["#","Dual-tower Architecture"]}],["$","span","Cross-modal Fusion",{"className":"page__taxonomy-item","children":["#","Cross-modal Fusion"]}],["$","span","Visual Grounding",{"className":"page__taxonomy-item","children":["#","Visual Grounding"]}],["$","span","Hierarchical Captioning",{"className":"page__taxonomy-item","children":["#","Hierarchical Captioning"]}],["$","span","Cross-Attention",{"className":"page__taxonomy-item","children":["#","Cross-Attention"]}]]}]]}]]}],["$","article","2025-10-10-Search-R3-Unifying-Reasoning-and-Embedding-Generation-in-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Search-R3-Unifying-Reasoning-and-Embedding-Generation-in-Large-Language-Models/","children":"[논문리뷰] Search-R3: Unifying Reasoning and Embedding Generation in Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"James Cheng이 [arXiv]에 게시한 'Search-R3: Unifying Reasoning and Embedding Generation in Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Sentence Embedding",{"className":"page__taxonomy-item","children":["#","Sentence Embedding"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Information Retrieval",{"className":"page__taxonomy-item","children":["#","Information Retrieval"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}]]}]]}]]}],["$","article","2025-10-10-SciVideoBench-Benchmarking-Scientific-Video-Reasoning-in-Large-Multimodal-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-SciVideoBench-Benchmarking-Scientific-Video-Reasoning-in-Large-Multimodal-Models/","children":"[논문리뷰] SciVideoBench: Benchmarking Scientific Video Reasoning in Large Multimodal Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Mohit Bansal이 [arXiv]에 게시한 'SciVideoBench: Benchmarking Scientific Video Reasoning in Large Multimodal Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Reasoning",{"className":"page__taxonomy-item","children":["#","Video Reasoning"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Scientific Research",{"className":"page__taxonomy-item","children":["#","Scientific Research"]}],["$","span","Large Multimodal Models",{"className":"page__taxonomy-item","children":["#","Large Multimodal Models"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Quantitative Reasoning",{"className":"page__taxonomy-item","children":["#","Quantitative Reasoning"]}],["$","span","Domain Knowledge",{"className":"page__taxonomy-item","children":["#","Domain Knowledge"]}],["$","span","Visual Grounding",{"className":"page__taxonomy-item","children":["#","Visual Grounding"]}]]}]]}]]}],["$","article","2025-10-10-SViM3D-Stable-Video-Material-Diffusion-for-Single-Image-3D-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-SViM3D-Stable-Video-Material-Diffusion-for-Single-Image-3D-Generation/","children":"[논문리뷰] SViM3D: Stable Video Material Diffusion for Single Image 3D Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'SViM3D: Stable Video Material Diffusion for Single Image 3D Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Single Image 3D Reconstruction",{"className":"page__taxonomy-item","children":["#","Single Image 3D Reconstruction"]}],["$","span","Material Prediction",{"className":"page__taxonomy-item","children":["#","Material Prediction"]}],["$","span","Video Diffusion Models",{"className":"page__taxonomy-item","children":["#","Video Diffusion Models"]}],["$","span","Physically Based Rendering (PBR)",{"className":"page__taxonomy-item","children":["#","Physically Based Rendering (PBR)"]}],["$","span","Inverse Rendering",{"className":"page__taxonomy-item","children":["#","Inverse Rendering"]}],["$","span","Novel View Synthesis",{"className":"page__taxonomy-item","children":["#","Novel View Synthesis"]}],["$","span","Camera Control",{"className":"page__taxonomy-item","children":["#","Camera Control"]}],["$","span","Latent Diffusion",{"className":"page__taxonomy-item","children":["#","Latent Diffusion"]}]]}]]}]]}],["$","article","2025-10-10-Reinforcing-Diffusion-Models-by-Direct-Group-Preference-Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Reinforcing-Diffusion-Models-by-Direct-Group-Preference-Optimization/","children":"[논문리뷰] Reinforcing Diffusion Models by Direct Group Preference Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jing Tang이 [arXiv]에 게시한 'Reinforcing Diffusion Models by Direct Group Preference Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Preference Optimization",{"className":"page__taxonomy-item","children":["#","Preference Optimization"]}],["$","span","Group Preference",{"className":"page__taxonomy-item","children":["#","Group Preference"]}],["$","span","Direct Preference Optimization",{"className":"page__taxonomy-item","children":["#","Direct Preference Optimization"]}],["$","span","ODE Samplers",{"className":"page__taxonomy-item","children":["#","ODE Samplers"]}],["$","span","Efficient Training",{"className":"page__taxonomy-item","children":["#","Efficient Training"]}]]}]]}]]}],["$","article","2025-10-10-Recycling-Pretrained-Checkpoints-Orthogonal-Growth-of-Mixture-of-Experts-for-Efficient-Large-Language-Model-Pre-Training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Recycling-Pretrained-Checkpoints-Orthogonal-Growth-of-Mixture-of-Experts-for-Efficient-Large-Language-Model-Pre-Training/","children":"[논문리뷰] Recycling Pretrained Checkpoints: Orthogonal Growth of Mixture-of-Experts for Efficient Large Language Model Pre-Training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Peng Cheng이 [arXiv]에 게시한 'Recycling Pretrained Checkpoints: Orthogonal Growth of Mixture-of-Experts for Efficient Large Language Model Pre-Training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Mixture-of-Experts",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Checkpoint Recycling",{"className":"page__taxonomy-item","children":["#","Checkpoint Recycling"]}],["$","span","Model Growth",{"className":"page__taxonomy-item","children":["#","Model Growth"]}],["$","span","Efficient Pretraining",{"className":"page__taxonomy-item","children":["#","Efficient Pretraining"]}],["$","span","Depth Growth",{"className":"page__taxonomy-item","children":["#","Depth Growth"]}],["$","span","Width Growth",{"className":"page__taxonomy-item","children":["#","Width Growth"]}],["$","span","Sunk Cost",{"className":"page__taxonomy-item","children":["#","Sunk Cost"]}]]}]]}]]}],["$","article","2025-10-10-R2RGEN-Real-to-Real-3D-Data-Generation-for-Spatially-Generalized-Manipulation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-R2RGEN-Real-to-Real-3D-Data-Generation-for-Spatially-Generalized-Manipulation/","children":"[논문리뷰] R2RGEN: Real-to-Real 3D Data Generation for Spatially Generalized Manipulation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zheng Zhu이 [arXiv]에 게시한 'R2RGEN: Real-to-Real 3D Data Generation for Spatially Generalized Manipulation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Robotic Manipulation",{"className":"page__taxonomy-item","children":["#","Robotic Manipulation"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}],["$","span","Spatial Generalization",{"className":"page__taxonomy-item","children":["#","Spatial Generalization"]}],["$","span","3D Data Generation",{"className":"page__taxonomy-item","children":["#","3D Data Generation"]}],["$","span","Imitation Learning",{"className":"page__taxonomy-item","children":["#","Imitation Learning"]}],["$","span","Point Cloud",{"className":"page__taxonomy-item","children":["#","Point Cloud"]}],["$","span","Real-to-Real",{"className":"page__taxonomy-item","children":["#","Real-to-Real"]}],["$","span","Mobile Manipulation",{"className":"page__taxonomy-item","children":["#","Mobile Manipulation"]}]]}]]}]]}],["$","article","2025-10-10-NewtonBench-Benchmarking-Generalizable-Scientific-Law-Discovery-in-LLM-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-NewtonBench-Benchmarking-Generalizable-Scientific-Law-Discovery-in-LLM-Agents/","children":"[논문리뷰] NewtonBench: Benchmarking Generalizable Scientific Law Discovery in LLM Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Baixuan Xu이 [arXiv]에 게시한 'NewtonBench: Benchmarking Generalizable Scientific Law Discovery in LLM Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Scientific Law Discovery",{"className":"page__taxonomy-item","children":["#","Scientific Law Discovery"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Metaphysical Shifts",{"className":"page__taxonomy-item","children":["#","Metaphysical Shifts"]}],["$","span","Interactive Environments",{"className":"page__taxonomy-item","children":["#","Interactive Environments"]}],["$","span","Exploration-Exploitation",{"className":"page__taxonomy-item","children":["#","Exploration-Exploitation"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}]]}]]}]]}],["$","article","2025-10-10-NaViL-Rethinking-Scaling-Properties-of-Native-Multimodal-Large-Language-Models-under-Data-Constraints",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-NaViL-Rethinking-Scaling-Properties-of-Native-Multimodal-Large-Language-Models-under-Data-Constraints/","children":"[논문리뷰] NaViL: Rethinking Scaling Properties of Native Multimodal Large Language Models under Data Constraints"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'NaViL: Rethinking Scaling Properties of Native Multimodal Large Language Models under Data Constraints' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models"]}],["$","span","Native MLLMs",{"className":"page__taxonomy-item","children":["#","Native MLLMs"]}],["$","span","Scaling Laws",{"className":"page__taxonomy-item","children":["#","Scaling Laws"]}],["$","span","Data Constraints",{"className":"page__taxonomy-item","children":["#","Data Constraints"]}],["$","span","Visual Encoder",{"className":"page__taxonomy-item","children":["#","Visual Encoder"]}],["$","span","LLM Initialization",{"className":"page__taxonomy-item","children":["#","LLM Initialization"]}],["$","span","Mixture-of-Experts",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts"]}],["$","span","End-to-end Training",{"className":"page__taxonomy-item","children":["#","End-to-end Training"]}]]}]]}]]}],["$","article","2025-10-10-Meta-Awareness-Enhances-Reasoning-Models-Self-Alignment-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Meta-Awareness-Enhances-Reasoning-Models-Self-Alignment-Reinforcement-Learning/","children":"[논문리뷰] Meta-Awareness Enhances Reasoning Models: Self-Alignment Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Meta-Awareness Enhances Reasoning Models: Self-Alignment Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Meta-Awareness",{"className":"page__taxonomy-item","children":["#","Meta-Awareness"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Self-Alignment",{"className":"page__taxonomy-item","children":["#","Self-Alignment"]}],["$","span","LLM Reasoning",{"className":"page__taxonomy-item","children":["#","LLM Reasoning"]}],["$","span","Training Efficiency",{"className":"page__taxonomy-item","children":["#","Training Efficiency"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Predictive Gating",{"className":"page__taxonomy-item","children":["#","Predictive Gating"]}]]}]]}]]}],["$","article","2025-10-10-Memory-Retrieval-and-Consolidation-in-Large-Language-Models-through-Function-Tokens",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Memory-Retrieval-and-Consolidation-in-Large-Language-Models-through-Function-Tokens/","children":"[논문리뷰] Memory Retrieval and Consolidation in Large Language Models through Function Tokens"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Memory Retrieval and Consolidation in Large Language Models through Function Tokens' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","LLM Interpretability",{"className":"page__taxonomy-item","children":["#","LLM Interpretability"]}],["$","span","Function Tokens",{"className":"page__taxonomy-item","children":["#","Function Tokens"]}],["$","span","Memory Retrieval",{"className":"page__taxonomy-item","children":["#","Memory Retrieval"]}],["$","span","Memory Consolidation",{"className":"page__taxonomy-item","children":["#","Memory Consolidation"]}],["$","span","Sparse Autoencoders",{"className":"page__taxonomy-item","children":["#","Sparse Autoencoders"]}],["$","span","Pre-training",{"className":"page__taxonomy-item","children":["#","Pre-training"]}]]}]]}]]}],["$","article","2025-10-10-MemMamba-Rethinking-Memory-Patterns-in-State-Space-Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-MemMamba-Rethinking-Memory-Patterns-in-State-Space-Model/","children":"[논문리뷰] MemMamba: Rethinking Memory Patterns in State Space Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiao Sun이 [arXiv]에 게시한 'MemMamba: Rethinking Memory Patterns in State Space Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","State Space Models",{"className":"page__taxonomy-item","children":["#","State Space Models"]}],["$","span","Mamba",{"className":"page__taxonomy-item","children":["#","Mamba"]}],["$","span","Long-sequence modeling",{"className":"page__taxonomy-item","children":["#","Long-sequence modeling"]}],["$","span","Memory decay",{"className":"page__taxonomy-item","children":["#","Memory decay"]}],["$","span","State summarization",{"className":"page__taxonomy-item","children":["#","State summarization"]}],["$","span","Cross-layer attention",{"className":"page__taxonomy-item","children":["#","Cross-layer attention"]}],["$","span","Perplexity",{"className":"page__taxonomy-item","children":["#","Perplexity"]}],["$","span","Linear complexity",{"className":"page__taxonomy-item","children":["#","Linear complexity"]}]]}]]}]]}],["$","article","2025-10-10-MM-HELIX-Boosting-Multimodal-Long-Chain-Reflective-Reasoning-with-Holistic-Platform-and-Adaptive-Hybrid-Policy-Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-MM-HELIX-Boosting-Multimodal-Long-Chain-Reflective-Reasoning-with-Holistic-Platform-and-Adaptive-Hybrid-Policy-Optimization/","children":"[논문리뷰] MM-HELIX: Boosting Multimodal Long-Chain Reflective Reasoning with Holistic Platform and Adaptive Hybrid Policy Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"vanilla1116이 [arXiv]에 게시한 'MM-HELIX: Boosting Multimodal Long-Chain Reflective Reasoning with Holistic Platform and Adaptive Hybrid Policy Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Reflective Reasoning",{"className":"page__taxonomy-item","children":["#","Reflective Reasoning"]}],["$","span","Long-Chain Reasoning",{"className":"page__taxonomy-item","children":["#","Long-Chain Reasoning"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Data Generation",{"className":"page__taxonomy-item","children":["#","Data Generation"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Backtracking",{"className":"page__taxonomy-item","children":["#","Backtracking"]}]]}]]}]]}],["$","article","2025-10-10-Low-probability-Tokens-Sustain-Exploration-in-Reinforcement-Learning-with-Verifiable-Reward",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Low-probability-Tokens-Sustain-Exploration-in-Reinforcement-Learning-with-Verifiable-Reward/","children":"[논문리뷰] Low-probability Tokens Sustain Exploration in Reinforcement Learning with Verifiable Reward"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Low-probability Tokens Sustain Exploration in Reinforcement Learning with Verifiable Reward' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","LLM Exploration",{"className":"page__taxonomy-item","children":["#","LLM Exploration"]}],["$","span","Verifiable Reward",{"className":"page__taxonomy-item","children":["#","Verifiable Reward"]}],["$","span","Low-Probability Regularization",{"className":"page__taxonomy-item","children":["#","Low-Probability Regularization"]}],["$","span","Reasoning Sparks",{"className":"page__taxonomy-item","children":["#","Reasoning Sparks"]}],["$","span","Policy Entropy",{"className":"page__taxonomy-item","children":["#","Policy Entropy"]}],["$","span","KL Divergence",{"className":"page__taxonomy-item","children":["#","KL Divergence"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}]]}]]}]]}],["$","article","2025-10-10-LongRM-Revealing-and-Unlocking-the-Context-Boundary-of-Reward-Modeling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-LongRM-Revealing-and-Unlocking-the-Context-Boundary-of-Reward-Modeling/","children":"[논문리뷰] LongRM: Revealing and Unlocking the Context Boundary of Reward Modeling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'LongRM: Revealing and Unlocking the Context Boundary of Reward Modeling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reward Model",{"className":"page__taxonomy-item","children":["#","Reward Model"]}],["$","span","Long Context",{"className":"page__taxonomy-item","children":["#","Long Context"]}],["$","span","LLM Alignment",{"className":"page__taxonomy-item","children":["#","LLM Alignment"]}],["$","span","Multi-stage Training",{"className":"page__taxonomy-item","children":["#","Multi-stage Training"]}],["$","span","Context Window Scaling",{"className":"page__taxonomy-item","children":["#","Context Window Scaling"]}],["$","span","Preference Learning",{"className":"page__taxonomy-item","children":["#","Preference Learning"]}],["$","span","Long-RewardBench",{"className":"page__taxonomy-item","children":["#","Long-RewardBench"]}]]}]]}]]}],["$","article","2025-10-10-Learning-to-Route-LLMs-from-Bandit-Feedback-One-Policy-Many-Trade-offs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Learning-to-Route-LLMs-from-Bandit-Feedback-One-Policy-Many-Trade-offs/","children":"[논문리뷰] Learning to Route LLMs from Bandit Feedback: One Policy, Many Trade-offs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Franck Dernoncourt이 [arXiv]에 게시한 'Learning to Route LLMs from Bandit Feedback: One Policy, Many Trade-offs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Routing",{"className":"page__taxonomy-item","children":["#","LLM Routing"]}],["$","span","Contextual Bandits",{"className":"page__taxonomy-item","children":["#","Contextual Bandits"]}],["$","span","Bandit Feedback",{"className":"page__taxonomy-item","children":["#","Bandit Feedback"]}],["$","span","Multi-objective Optimization",{"className":"page__taxonomy-item","children":["#","Multi-objective Optimization"]}],["$","span","Preference-tuning",{"className":"page__taxonomy-item","children":["#","Preference-tuning"]}],["$","span","Policy Gradient",{"className":"page__taxonomy-item","children":["#","Policy Gradient"]}],["$","span","Cost-efficiency",{"className":"page__taxonomy-item","children":["#","Cost-efficiency"]}]]}]]}]]}],["$","article","2025-10-10-Learning-on-the-Job-An-Experience-Driven-Self-Evolving-Agent-for-Long-Horizon-Tasks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Learning-on-the-Job-An-Experience-Driven-Self-Evolving-Agent-for-Long-Horizon-Tasks/","children":"[논문리뷰] Learning on the Job: An Experience-Driven Self-Evolving Agent for Long-Horizon Tasks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Learning on the Job: An Experience-Driven Self-Evolving Agent for Long-Horizon Tasks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Continuous Learning",{"className":"page__taxonomy-item","children":["#","Continuous Learning"]}],["$","span","Self-Evolving",{"className":"page__taxonomy-item","children":["#","Self-Evolving"]}],["$","span","Memory Module",{"className":"page__taxonomy-item","children":["#","Memory Module"]}],["$","span","Long-Horizon Planning",{"className":"page__taxonomy-item","children":["#","Long-Horizon Planning"]}],["$","span","Productivity Tasks",{"className":"page__taxonomy-item","children":["#","Productivity Tasks"]}],["$","span","Test-Time Learning",{"className":"page__taxonomy-item","children":["#","Test-Time Learning"]}],["$","span","Experience Replay",{"className":"page__taxonomy-item","children":["#","Experience Replay"]}]]}]]}]]}],["$","article","2025-10-10-Large-Scale-Diffusion-Distillation-via-Score-Regularized-Continuous-Time-Consistency",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Large-Scale-Diffusion-Distillation-via-Score-Regularized-Continuous-Time-Consistency/","children":"[논문리뷰] Large Scale Diffusion Distillation via Score-Regularized Continuous-Time Consistency"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jintao Zhang이 [arXiv]에 게시한 'Large Scale Diffusion Distillation via Score-Regularized Continuous-Time Consistency' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Distillation",{"className":"page__taxonomy-item","children":["#","Diffusion Distillation"]}],["$","span","Consistency Models",{"className":"page__taxonomy-item","children":["#","Consistency Models"]}],["$","span","Score Regularization",{"className":"page__taxonomy-item","children":["#","Score Regularization"]}],["$","span","Large-Scale Generative Models",{"className":"page__taxonomy-item","children":["#","Large-Scale Generative Models"]}],["$","span","Text-to-Image",{"className":"page__taxonomy-item","children":["#","Text-to-Image"]}],["$","span","Text-to-Video",{"className":"page__taxonomy-item","children":["#","Text-to-Video"]}],["$","span","Model Acceleration",{"className":"page__taxonomy-item","children":["#","Model Acceleration"]}],["$","span","JVP",{"className":"page__taxonomy-item","children":["#","JVP"]}]]}]]}]]}],["$","article","2025-10-10-LLMs-Learn-to-Deceive-Unintentionally-Emergent-Misalignment-in-Dishonesty-from-Misaligned-Samples-to-Biased-Human-AI-Interactions",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-LLMs-Learn-to-Deceive-Unintentionally-Emergent-Misalignment-in-Dishonesty-from-Misaligned-Samples-to-Biased-Human-AI-Interactions/","children":"[논문리뷰] LLMs Learn to Deceive Unintentionally: Emergent Misalignment in Dishonesty from Misaligned Samples to Biased Human-AI Interactions"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'LLMs Learn to Deceive Unintentionally: Emergent Misalignment in Dishonesty from Misaligned Samples to Biased Human-AI Interactions' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Misalignment",{"className":"page__taxonomy-item","children":["#","LLM Misalignment"]}],["$","span","Dishonesty",{"className":"page__taxonomy-item","children":["#","Dishonesty"]}],["$","span","Deception",{"className":"page__taxonomy-item","children":["#","Deception"]}],["$","span","Finetuning",{"className":"page__taxonomy-item","children":["#","Finetuning"]}],["$","span","Human-AI Interaction",{"className":"page__taxonomy-item","children":["#","Human-AI Interaction"]}],["$","span","Biased Feedback",{"className":"page__taxonomy-item","children":["#","Biased Feedback"]}],["$","span","Emergent Behavior",{"className":"page__taxonomy-item","children":["#","Emergent Behavior"]}]]}]]}]]}],["$","article","2025-10-10-InstructX-Towards-Unified-Visual-Editing-with-MLLM-Guidance",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-InstructX-Towards-Unified-Visual-Editing-with-MLLM-Guidance/","children":"[논문리뷰] InstructX: Towards Unified Visual Editing with MLLM Guidance"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xinghui Li이 [arXiv]에 게시한 'InstructX: Towards Unified Visual Editing with MLLM Guidance' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Visual Editing",{"className":"page__taxonomy-item","children":["#","Visual Editing"]}],["$","span","MLLM Guidance",{"className":"page__taxonomy-item","children":["#","MLLM Guidance"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Video Editing",{"className":"page__taxonomy-item","children":["#","Video Editing"]}],["$","span","Unified Framework",{"className":"page__taxonomy-item","children":["#","Unified Framework"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Instruction-based Editing",{"className":"page__taxonomy-item","children":["#","Instruction-based Editing"]}]]}]]}]]}],["$","article","2025-10-10-Hybrid-Reinforcement-When-Reward-Is-Sparse-Its-Better-to-Be-Dense",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Hybrid-Reinforcement-When-Reward-Is-Sparse-Its-Better-to-Be-Dense/","children":"[논문리뷰] Hybrid Reinforcement: When Reward Is Sparse, It's Better to Be Dense"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Hybrid Reinforcement: When Reward Is Sparse, It's Better to Be Dense' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Reward Modeling",{"className":"page__taxonomy-item","children":["#","Reward Modeling"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Sparse Rewards",{"className":"page__taxonomy-item","children":["#","Sparse Rewards"]}],["$","span","Dense Rewards",{"className":"page__taxonomy-item","children":["#","Dense Rewards"]}],["$","span","Hybrid Reinforcement",{"className":"page__taxonomy-item","children":["#","Hybrid Reinforcement"]}],["$","span","Verifier-based Rewards",{"className":"page__taxonomy-item","children":["#","Verifier-based Rewards"]}]]}]]}]]}],["$","article","2025-10-10-GCPO-When-Contrast-Fails-Go-Gold",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-GCPO-When-Contrast-Fails-Go-Gold/","children":"[논문리뷰] GCPO: When Contrast Fails, Go Gold"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'GCPO: When Contrast Fails, Go Gold' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","LLMs Reasoning",{"className":"page__taxonomy-item","children":["#","LLMs Reasoning"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Chain of Thought",{"className":"page__taxonomy-item","children":["#","Chain of Thought"]}],["$","span","Reference Answers",{"className":"page__taxonomy-item","children":["#","Reference Answers"]}],["$","span","Math Reasoning",{"className":"page__taxonomy-item","children":["#","Math Reasoning"]}],["$","span","Gold-Standard Answer",{"className":"page__taxonomy-item","children":["#","Gold-Standard Answer"]}]]}]]}]]}],["$","article","2025-10-10-From-What-to-Why-A-Multi-Agent-System-for-Evidence-based-Chemical-Reaction-Condition-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-From-What-to-Why-A-Multi-Agent-System-for-Evidence-based-Chemical-Reaction-Condition-Reasoning/","children":"[논문리뷰] From What to Why: A Multi-Agent System for Evidence-based Chemical Reaction Condition Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Feiwei Qin이 [arXiv]에 게시한 'From What to Why: A Multi-Agent System for Evidence-based Chemical Reaction Condition Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-Agent System",{"className":"page__taxonomy-item","children":["#","Multi-Agent System"]}],["$","span","Chemical Reaction Prediction",{"className":"page__taxonomy-item","children":["#","Chemical Reaction Prediction"]}],["$","span","Explainable AI",{"className":"page__taxonomy-item","children":["#","Explainable AI"]}],["$","span","Evidence-Based Reasoning",{"className":"page__taxonomy-item","children":["#","Evidence-Based Reasoning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Tool-Augmented LLMs",{"className":"page__taxonomy-item","children":["#","Tool-Augmented LLMs"]}],["$","span","Scientific Discovery",{"className":"page__taxonomy-item","children":["#","Scientific Discovery"]}]]}]]}]]}],["$","article","2025-10-10-First-Try-Matters-Revisiting-the-Role-of-Reflection-in-Reasoning-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-First-Try-Matters-Revisiting-the-Role-of-Reflection-in-Reasoning-Models/","children":"[논문리뷰] First Try Matters: Revisiting the Role of Reflection in Reasoning Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wee Sun Lee이 [arXiv]에 게시한 'First Try Matters: Revisiting the Role of Reflection in Reasoning Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Chain-of-Thought (CoT)",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought (CoT)"]}],["$","span","Reflection",{"className":"page__taxonomy-item","children":["#","Reflection"]}],["$","span","Early Stopping",{"className":"page__taxonomy-item","children":["#","Early Stopping"]}],["$","span","Supervised Fine-tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning (SFT)"]}],["$","span","Token Efficiency",{"className":"page__taxonomy-item","children":["#","Token Efficiency"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}]]}]]}]]}],["$","article","2025-10-10-Fidelity-Aware-Data-Composition-for-Robust-Robot-Generalization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Fidelity-Aware-Data-Composition-for-Robust-Robot-Generalization/","children":"[논문리뷰] Fidelity-Aware Data Composition for Robust Robot Generalization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Liliang Chen이 [arXiv]에 게시한 'Fidelity-Aware Data Composition for Robust Robot Generalization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Robot Generalization",{"className":"page__taxonomy-item","children":["#","Robot Generalization"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}],["$","span","Out-of-Distribution (OOD)",{"className":"page__taxonomy-item","children":["#","Out-of-Distribution (OOD)"]}],["$","span","Shortcut Learning",{"className":"page__taxonomy-item","children":["#","Shortcut Learning"]}],["$","span","Information Fidelity",{"className":"page__taxonomy-item","children":["#","Information Fidelity"]}],["$","span","Data Composition",{"className":"page__taxonomy-item","children":["#","Data Composition"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Multi-View Video Synthesis",{"className":"page__taxonomy-item","children":["#","Multi-View Video Synthesis"]}]]}]]}]]}],["$","article","2025-10-10-Entropy-Regularizing-Activation-Boosting-Continuous-Control-Large-Language-Models-and-Image-Classification-with-Activation-as-Entropy-Constraints",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Entropy-Regularizing-Activation-Boosting-Continuous-Control-Large-Language-Models-and-Image-Classification-with-Activation-as-Entropy-Constraints/","children":"[논문리뷰] Entropy Regularizing Activation: Boosting Continuous Control, Large Language Models, and Image Classification with Activation as Entropy Constraints"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Huazhe Xu이 [arXiv]에 게시한 'Entropy Regularizing Activation: Boosting Continuous Control, Large Language Models, and Image Classification with Activation as Entropy Constraints' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Entropy Regularization",{"className":"page__taxonomy-item","children":["#","Entropy Regularization"]}],["$","span","Activation Functions",{"className":"page__taxonomy-item","children":["#","Activation Functions"]}],["$","span","Continuous Control",{"className":"page__taxonomy-item","children":["#","Continuous Control"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Image Classification",{"className":"page__taxonomy-item","children":["#","Image Classification"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Policy Stochasticity",{"className":"page__taxonomy-item","children":["#","Policy Stochasticity"]}],["$","span","Entropy Constraints",{"className":"page__taxonomy-item","children":["#","Entropy Constraints"]}]]}]]}]]}],["$","article","2025-10-10-DexNDM-Closing-the-Reality-Gap-for-Dexterous-In-Hand-Rotation-via-Joint-Wise-Neural-Dynamics-Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-DexNDM-Closing-the-Reality-Gap-for-Dexterous-In-Hand-Rotation-via-Joint-Wise-Neural-Dynamics-Model/","children":"[논문리뷰] DexNDM: Closing the Reality Gap for Dexterous In-Hand Rotation via Joint-Wise Neural Dynamics Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Li Yi이 [arXiv]에 게시한 'DexNDM: Closing the Reality Gap for Dexterous In-Hand Rotation via Joint-Wise Neural Dynamics Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Dexterous Manipulation",{"className":"page__taxonomy-item","children":["#","Dexterous Manipulation"]}],["$","span","In-Hand Rotation",{"className":"page__taxonomy-item","children":["#","In-Hand Rotation"]}],["$","span","Sim-to-Real Transfer",{"className":"page__taxonomy-item","children":["#","Sim-to-Real Transfer"]}],["$","span","Neural Dynamics Model",{"className":"page__taxonomy-item","children":["#","Neural Dynamics Model"]}],["$","span","Joint-Wise Learning",{"className":"page__taxonomy-item","children":["#","Joint-Wise Learning"]}],["$","span","Autonomous Data Collection",{"className":"page__taxonomy-item","children":["#","Autonomous Data Collection"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}]]}]]}]]}],["$","article","2025-10-10-DeepPrune-Parallel-Scaling-without-Inter-trace-Redundancy",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-DeepPrune-Parallel-Scaling-without-Inter-trace-Redundancy/","children":"[논문리뷰] DeepPrune: Parallel Scaling without Inter-trace Redundancy"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DeepPrune: Parallel Scaling without Inter-trace Redundancy' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Parallel Scaling",{"className":"page__taxonomy-item","children":["#","Parallel Scaling"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","LLM Reasoning",{"className":"page__taxonomy-item","children":["#","LLM Reasoning"]}],["$","span","Dynamic Pruning",{"className":"page__taxonomy-item","children":["#","Dynamic Pruning"]}],["$","span","Inter-trace Redundancy",{"className":"page__taxonomy-item","children":["#","Inter-trace Redundancy"]}],["$","span","Judge Model",{"className":"page__taxonomy-item","children":["#","Judge Model"]}],["$","span","Resource Efficiency",{"className":"page__taxonomy-item","children":["#","Resource Efficiency"]}],["$","span","Answer Diversity",{"className":"page__taxonomy-item","children":["#","Answer Diversity"]}]]}]]}]]}],["$","article","2025-10-10-CoMAS-Co-Evolving-Multi-Agent-Systems-via-Interaction-Rewards",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-CoMAS-Co-Evolving-Multi-Agent-Systems-via-Interaction-Rewards/","children":"[논문리뷰] CoMAS: Co-Evolving Multi-Agent Systems via Interaction Rewards"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yijiang Li이 [arXiv]에 게시한 'CoMAS: Co-Evolving Multi-Agent Systems via Interaction Rewards' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Self-Evolution",{"className":"page__taxonomy-item","children":["#","Self-Evolution"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Interaction Rewards",{"className":"page__taxonomy-item","children":["#","Interaction Rewards"]}],["$","span","LLM-as-a-Judge",{"className":"page__taxonomy-item","children":["#","LLM-as-a-Judge"]}],["$","span","Decentralized Learning",{"className":"page__taxonomy-item","children":["#","Decentralized Learning"]}]]}]]}]]}],["$","article","2025-10-10-Beyond-Turn-Limits-Training-Deep-Search-Agents-with-Dynamic-Context-Window",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Beyond-Turn-Limits-Training-Deep-Search-Agents-with-Dynamic-Context-Window/","children":"[논문리뷰] Beyond Turn Limits: Training Deep Search Agents with Dynamic Context Window"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yaojie Lu이 [arXiv]에 게시한 'Beyond Turn Limits: Training Deep Search Agents with Dynamic Context Window' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Deep Search Agents",{"className":"page__taxonomy-item","children":["#","Deep Search Agents"]}],["$","span","Dynamic Context Window",{"className":"page__taxonomy-item","children":["#","Dynamic Context Window"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Long-horizon Interaction",{"className":"page__taxonomy-item","children":["#","Long-horizon Interaction"]}],["$","span","Context Management",{"className":"page__taxonomy-item","children":["#","Context Management"]}],["$","span","High-difficulty Tasks",{"className":"page__taxonomy-item","children":["#","High-difficulty Tasks"]}],["$","span","Multi-turn Reasoning",{"className":"page__taxonomy-item","children":["#","Multi-turn Reasoning"]}],["$","span","Web Agents",{"className":"page__taxonomy-item","children":["#","Web Agents"]}]]}]]}]]}],["$","article","2025-10-10-Beyond-Outliers-A-Study-of-Optimizers-Under-Quantization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Beyond-Outliers-A-Study-of-Optimizers-Under-Quantization/","children":"[논문리뷰] Beyond Outliers: A Study of Optimizers Under Quantization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Beyond Outliers: A Study of Optimizers Under Quantization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Quantization",{"className":"page__taxonomy-item","children":["#","Quantization"]}],["$","span","Optimizers",{"className":"page__taxonomy-item","children":["#","Optimizers"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Post-Training Quantization (PTQ)",{"className":"page__taxonomy-item","children":["#","Post-Training Quantization (PTQ)"]}],["$","span","Quantization-Aware Training (QAT)",{"className":"page__taxonomy-item","children":["#","Quantization-Aware Training (QAT)"]}],["$","span","Error Propagation",{"className":"page__taxonomy-item","children":["#","Error Propagation"]}],["$","span","Scaling Laws",{"className":"page__taxonomy-item","children":["#","Scaling Laws"]}],["$","span","Shampoo",{"className":"page__taxonomy-item","children":["#","Shampoo"]}]]}]]}]]}],["$","article","2025-10-10-Agent-Learning-via-Early-Experience",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Agent-Learning-via-Early-Experience/","children":"[논문리뷰] Agent Learning via Early Experience"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Agent Learning via Early Experience' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Language Agents",{"className":"page__taxonomy-item","children":["#","Language Agents"]}],["$","span","Early Experience",{"className":"page__taxonomy-item","children":["#","Early Experience"]}],["$","span","Reward-Free Learning",{"className":"page__taxonomy-item","children":["#","Reward-Free Learning"]}],["$","span","World Modeling",{"className":"page__taxonomy-item","children":["#","World Modeling"]}],["$","span","Self-Reflection",{"className":"page__taxonomy-item","children":["#","Self-Reflection"]}],["$","span","Imitation Learning",{"className":"page__taxonomy-item","children":["#","Imitation Learning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Out-of-Domain Generalization",{"className":"page__taxonomy-item","children":["#","Out-of-Domain Generalization"]}]]}]]}]]}],["$","article","2025-10-10-ARTDECO-Towards-Efficient-and-High-Fidelity-On-the-Fly-3D-Reconstruction-with-Structured-Scene-Representation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-ARTDECO-Towards-Efficient-and-High-Fidelity-On-the-Fly-3D-Reconstruction-with-Structured-Scene-Representation/","children":"[논문리뷰] ARTDECO: Towards Efficient and High-Fidelity On-the-Fly 3D Reconstruction with Structured Scene Representation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'ARTDECO: Towards Efficient and High-Fidelity On-the-Fly 3D Reconstruction with Structured Scene Representation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Reconstruction",{"className":"page__taxonomy-item","children":["#","3D Reconstruction"]}],["$","span","Monocular SLAM",{"className":"page__taxonomy-item","children":["#","Monocular SLAM"]}],["$","span","Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","Gaussian Splatting"]}],["$","span","Level of Detail (LoD)",{"className":"page__taxonomy-item","children":["#","Level of Detail (LoD)"]}],["$","span","Feed-Forward Models",{"className":"page__taxonomy-item","children":["#","Feed-Forward Models"]}],["$","span","Structured Scene Representation",{"className":"page__taxonomy-item","children":["#","Structured Scene Representation"]}],["$","span","Real-time",{"className":"page__taxonomy-item","children":["#","Real-time"]}],["$","span","High-Fidelity",{"className":"page__taxonomy-item","children":["#","High-Fidelity"]}]]}]]}]]}],["$","article","2025-10-10-A2Search-Ambiguity-Aware-Question-Answering-with-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-A2Search-Ambiguity-Aware-Question-Answering-with-Reinforcement-Learning/","children":"[논문리뷰] A^2Search: Ambiguity-Aware Question Answering with Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'A^2Search: Ambiguity-Aware Question Answering with Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Question Answering",{"className":"page__taxonomy-item","children":["#","Question Answering"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Ambiguity Resolution",{"className":"page__taxonomy-item","children":["#","Ambiguity Resolution"]}],["$","span","Multi-hop QA",{"className":"page__taxonomy-item","children":["#","Multi-hop QA"]}],["$","span","Automated Data Generation",{"className":"page__taxonomy-item","children":["#","Automated Data Generation"]}],["$","span","Tool-Augmented LLMs",{"className":"page__taxonomy-item","children":["#","Tool-Augmented LLMs"]}],["$","span","AnsF1 Reward",{"className":"page__taxonomy-item","children":["#","AnsF1 Reward"]}]]}]]}]]}],["$","article","2025-10-9-WristWorld-Generating-Wrist-Views-via-4D-World-Models-for-Robotic-Manipulation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-WristWorld-Generating-Wrist-Views-via-4D-World-Models-for-Robotic-Manipulation/","children":"[논문리뷰] WristWorld: Generating Wrist-Views via 4D World Models for Robotic Manipulation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'WristWorld: Generating Wrist-Views via 4D World Models for Robotic Manipulation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","4D World Models",{"className":"page__taxonomy-item","children":["#","4D World Models"]}],["$","span","Robotic Manipulation",{"className":"page__taxonomy-item","children":["#","Robotic Manipulation"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Multi-view Synthesis",{"className":"page__taxonomy-item","children":["#","Multi-view Synthesis"]}],["$","span","Visual-Language-Action (VLA)",{"className":"page__taxonomy-item","children":["#","Visual-Language-Action (VLA)"]}],["$","span","Geometric Consistency",{"className":"page__taxonomy-item","children":["#","Geometric Consistency"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Wrist-View",{"className":"page__taxonomy-item","children":["#","Wrist-View"]}]]}]]}]]}],["$","article","2025-10-9-Why-Low-Precision-Transformer-Training-Fails-An-Analysis-on-Flash-Attention",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Why-Low-Precision-Transformer-Training-Fails-An-Analysis-on-Flash-Attention/","children":"[논문리뷰] Why Low-Precision Transformer Training Fails: An Analysis on Flash Attention"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Why Low-Precision Transformer Training Fails: An Analysis on Flash Attention' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Low-Precision Training",{"className":"page__taxonomy-item","children":["#","Low-Precision Training"]}],["$","span","Flash Attention",{"className":"page__taxonomy-item","children":["#","Flash Attention"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Numerical Stability",{"className":"page__taxonomy-item","children":["#","Numerical Stability"]}],["$","span","BF16",{"className":"page__taxonomy-item","children":["#","BF16"]}],["$","span","Rounding Error",{"className":"page__taxonomy-item","children":["#","Rounding Error"]}],["$","span","Gradient Bias",{"className":"page__taxonomy-item","children":["#","Gradient Bias"]}],["$","span","Deep Learning Optimization",{"className":"page__taxonomy-item","children":["#","Deep Learning Optimization"]}]]}]]}]]}],["$","article","2025-10-9-When-Benchmarks-Age-Temporal-Misalignment-through-Large-Language-Model-Factuality-Evaluation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-When-Benchmarks-Age-Temporal-Misalignment-through-Large-Language-Model-Factuality-Evaluation/","children":"[논문리뷰] When Benchmarks Age: Temporal Misalignment through Large Language Model Factuality Evaluation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'When Benchmarks Age: Temporal Misalignment through Large Language Model Factuality Evaluation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Factuality Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Factuality Evaluation"]}],["$","span","Benchmark Aging",{"className":"page__taxonomy-item","children":["#","Benchmark Aging"]}],["$","span","Temporal Misalignment",{"className":"page__taxonomy-item","children":["#","Temporal Misalignment"]}],["$","span","Information Retrieval",{"className":"page__taxonomy-item","children":["#","Information Retrieval"]}],["$","span","Question Answering",{"className":"page__taxonomy-item","children":["#","Question Answering"]}],["$","span","Evaluation Metrics",{"className":"page__taxonomy-item","children":["#","Evaluation Metrics"]}],["$","span","GPT-4o-mini",{"className":"page__taxonomy-item","children":["#","GPT-4o-mini"]}],["$","span","Qwen2.5",{"className":"page__taxonomy-item","children":["#","Qwen2.5"]}]]}]]}]]}],["$","article","2025-10-9-Vibe-Checker-Aligning-Code-Evaluation-with-Human-Preference",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Vibe-Checker-Aligning-Code-Evaluation-with-Human-Preference/","children":"[논문리뷰] Vibe Checker: Aligning Code Evaluation with Human Preference"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Vibe Checker: Aligning Code Evaluation with Human Preference' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Code Evaluation",{"className":"page__taxonomy-item","children":["#","Code Evaluation"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}],["$","span","Human Preference",{"className":"page__taxonomy-item","children":["#","Human Preference"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Vibe Check",{"className":"page__taxonomy-item","children":["#","Vibe Check"]}],["$","span","Non-functional Requirements",{"className":"page__taxonomy-item","children":["#","Non-functional Requirements"]}],["$","span","VeriCode",{"className":"page__taxonomy-item","children":["#","VeriCode"]}]]}]]}]]}],["$","article","2025-10-9-U-Bench-A-Comprehensive-Understanding-of-U-Net-through-100-Variant-Benchmarking",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-U-Bench-A-Comprehensive-Understanding-of-U-Net-through-100-Variant-Benchmarking/","children":"[논문리뷰] U-Bench: A Comprehensive Understanding of U-Net through 100-Variant Benchmarking"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Heqin Zhu이 [arXiv]에 게시한 'U-Bench: A Comprehensive Understanding of U-Net through 100-Variant Benchmarking' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","U-Net",{"className":"page__taxonomy-item","children":["#","U-Net"]}],["$","span","Medical Image Segmentation",{"className":"page__taxonomy-item","children":["#","Medical Image Segmentation"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Performance Evaluation",{"className":"page__taxonomy-item","children":["#","Performance Evaluation"]}],["$","span","Efficiency Metrics",{"className":"page__taxonomy-item","children":["#","Efficiency Metrics"]}],["$","span","Zero-shot Generalization",{"className":"page__taxonomy-item","children":["#","Zero-shot Generalization"]}],["$","span","U-Score",{"className":"page__taxonomy-item","children":["#","U-Score"]}]]}]]}]]}],["$","article","2025-10-9-The-Markovian-Thinker",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-The-Markovian-Thinker/","children":"[논문리뷰] The Markovian Thinker"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'The Markovian Thinker' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Markovian Thinking",{"className":"page__taxonomy-item","children":["#","Markovian Thinking"]}],["$","span","Context Management",{"className":"page__taxonomy-item","children":["#","Context Management"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}],["$","span","Long-Context LLMs",{"className":"page__taxonomy-item","children":["#","Long-Context LLMs"]}],["$","span","Transformer Optimization",{"className":"page__taxonomy-item","children":["#","Transformer Optimization"]}]]}]]}]]}],["$","article","2025-10-9-The-African-Languages-Lab-A-Collaborative-Approach-to-Advancing-Low-Resource-African-NLP",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-The-African-Languages-Lab-A-Collaborative-Approach-to-Advancing-Low-Resource-African-NLP/","children":"[논문리뷰] The African Languages Lab: A Collaborative Approach to Advancing Low-Resource African NLP"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'The African Languages Lab: A Collaborative Approach to Advancing Low-Resource African NLP' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Low-Resource NLP",{"className":"page__taxonomy-item","children":["#","Low-Resource NLP"]}],["$","span","African Languages",{"className":"page__taxonomy-item","children":["#","African Languages"]}],["$","span","Data Collection",{"className":"page__taxonomy-item","children":["#","Data Collection"]}],["$","span","Multilingual Models",{"className":"page__taxonomy-item","children":["#","Multilingual Models"]}],["$","span","Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Fine-Tuning"]}],["$","span","Speech Data",{"className":"page__taxonomy-item","children":["#","Speech Data"]}],["$","span","Text Data",{"className":"page__taxonomy-item","children":["#","Text Data"]}],["$","span","Capacity Building",{"className":"page__taxonomy-item","children":["#","Capacity Building"]}]]}]]}]]}],["$","article","2025-10-9-TTRV-Test-Time-Reinforcement-Learning-for-Vision-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-TTRV-Test-Time-Reinforcement-Learning-for-Vision-Language-Models/","children":"[논문리뷰] TTRV: Test-Time Reinforcement Learning for Vision Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Serena Yeung-Levy이 [arXiv]에 게시한 'TTRV: Test-Time Reinforcement Learning for Vision Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision-Language Models (VLMs)"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Test-Time Adaptation",{"className":"page__taxonomy-item","children":["#","Test-Time Adaptation"]}],["$","span","Unsupervised Learning",{"className":"page__taxonomy-item","children":["#","Unsupervised Learning"]}],["$","span","Image Recognition",{"className":"page__taxonomy-item","children":["#","Image Recognition"]}],["$","span","Visual Question Answering (VQA)",{"className":"page__taxonomy-item","children":["#","Visual Question Answering (VQA)"]}],["$","span","Group Relative Policy Optimization (GRPO)",{"className":"page__taxonomy-item","children":["#","Group Relative Policy Optimization (GRPO)"]}],["$","span","Entropy Regularization",{"className":"page__taxonomy-item","children":["#","Entropy Regularization"]}]]}]]}]]}],["$","article","2025-10-9-StaMo-Unsupervised-Learning-of-Generalizable-Robot-Motion-from-Compact-State-Representation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-StaMo-Unsupervised-Learning-of-Generalizable-Robot-Motion-from-Compact-State-Representation/","children":"[논문리뷰] StaMo: Unsupervised Learning of Generalizable Robot Motion from Compact State Representation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'StaMo: Unsupervised Learning of Generalizable Robot Motion from Compact State Representation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Robot Learning",{"className":"page__taxonomy-item","children":["#","Robot Learning"]}],["$","span","State Representation",{"className":"page__taxonomy-item","children":["#","State Representation"]}],["$","span","Motion Representation",{"className":"page__taxonomy-item","children":["#","Motion Representation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Unsupervised Learning",{"className":"page__taxonomy-item","children":["#","Unsupervised Learning"]}],["$","span","World Modeling",{"className":"page__taxonomy-item","children":["#","World Modeling"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Latent Action",{"className":"page__taxonomy-item","children":["#","Latent Action"]}]]}]]}]]}],["$","article","2025-10-9-SHANKS-Simultaneous-Hearing-and-Thinking-for-Spoken-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-SHANKS-Simultaneous-Hearing-and-Thinking-for-Spoken-Language-Models/","children":"[논문리뷰] SHANKS: Simultaneous Hearing and Thinking for Spoken Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kevin Lin이 [arXiv]에 게시한 'SHANKS: Simultaneous Hearing and Thinking for Spoken Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Spoken Language Models",{"className":"page__taxonomy-item","children":["#","Spoken Language Models"]}],["$","span","Real-time Interaction",{"className":"page__taxonomy-item","children":["#","Real-time Interaction"]}],["$","span","Thinking While Listening",{"className":"page__taxonomy-item","children":["#","Thinking While Listening"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Interruption",{"className":"page__taxonomy-item","children":["#","Interruption"]}],["$","span","Tool Calling",{"className":"page__taxonomy-item","children":["#","Tool Calling"]}],["$","span","Streaming ASR",{"className":"page__taxonomy-item","children":["#","Streaming ASR"]}]]}]]}]]}],["$","article","2025-10-9-Revisiting-the-Uniform-Information-Density-Hypothesis-in-LLM-Reasoning-Traces",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Revisiting-the-Uniform-Information-Density-Hypothesis-in-LLM-Reasoning-Traces/","children":"[논문리뷰] Revisiting the Uniform Information Density Hypothesis in LLM Reasoning Traces"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Revisiting the Uniform Information Density Hypothesis in LLM Reasoning Traces' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Reasoning",{"className":"page__taxonomy-item","children":["#","LLM Reasoning"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Uniform Information Density",{"className":"page__taxonomy-item","children":["#","Uniform Information Density"]}],["$","span","Information Theory",{"className":"page__taxonomy-item","children":["#","Information Theory"]}],["$","span","Reasoning Trace Analysis",{"className":"page__taxonomy-item","children":["#","Reasoning Trace Analysis"]}],["$","span","Entropy",{"className":"page__taxonomy-item","children":["#","Entropy"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Model Evaluation",{"className":"page__taxonomy-item","children":["#","Model Evaluation"]}]]}]]}]]}],["$","article","2025-10-9-Revisiting-Long-context-Modeling-from-Context-Denoising-Perspective",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Revisiting-Long-context-Modeling-from-Context-Denoising-Perspective/","children":"[논문리뷰] Revisiting Long-context Modeling from Context Denoising Perspective"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Revisiting Long-context Modeling from Context Denoising Perspective' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Long-context Models",{"className":"page__taxonomy-item","children":["#","Long-context Models"]}],["$","span","Context Denoising",{"className":"page__taxonomy-item","children":["#","Context Denoising"]}],["$","span","Integrated Gradient",{"className":"page__taxonomy-item","children":["#","Integrated Gradient"]}],["$","span","LLM Training",{"className":"page__taxonomy-item","children":["#","LLM Training"]}],["$","span","Context Window Scaling",{"className":"page__taxonomy-item","children":["#","Context Window Scaling"]}],["$","span","Information Flow",{"className":"page__taxonomy-item","children":["#","Information Flow"]}],["$","span","Attention Mechanism",{"className":"page__taxonomy-item","children":["#","Attention Mechanism"]}]]}]]}]]}],["$","article","2025-10-9-RLinf-VLA-A-Unified-and-Efficient-Framework-for-VLARL-Training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-RLinf-VLA-A-Unified-and-Efficient-Framework-for-VLARL-Training/","children":"[논문리뷰] RLinf-VLA: A Unified and Efficient Framework for VLA+RL Training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'RLinf-VLA: A Unified and Efficient Framework for VLA+RL Training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","VLA Models",{"className":"page__taxonomy-item","children":["#","VLA Models"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","GPU Management",{"className":"page__taxonomy-item","children":["#","GPU Management"]}],["$","span","PPO",{"className":"page__taxonomy-item","children":["#","PPO"]}],["$","span","GRPO",{"className":"page__taxonomy-item","children":["#","GRPO"]}],["$","span","Sim-to-Real",{"className":"page__taxonomy-item","children":["#","Sim-to-Real"]}]]}]]}]]}],["$","article","2025-10-9-Pushing-on-Multilingual-Reasoning-Models-with-Language-Mixed-Chain-of-Thought",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Pushing-on-Multilingual-Reasoning-Models-with-Language-Mixed-Chain-of-Thought/","children":"[논문리뷰] Pushing on Multilingual Reasoning Models with Language-Mixed Chain-of-Thought"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Pushing on Multilingual Reasoning Models with Language-Mixed Chain-of-Thought' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multilingual Reasoning",{"className":"page__taxonomy-item","children":["#","Multilingual Reasoning"]}],["$","span","Chain-of-Thought (CoT)",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought (CoT)"]}],["$","span","Language-Mixed CoT",{"className":"page__taxonomy-item","children":["#","Language-Mixed CoT"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}],["$","span","Korean LLMs",{"className":"page__taxonomy-item","children":["#","Korean LLMs"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Supervised Fine-tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning (SFT)"]}]]}]]}]]}],["$","article","2025-10-9-Patch-as-Decodable-Token-Towards-Unified-Multi-Modal-Vision-Tasks-in-MLLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Patch-as-Decodable-Token-Towards-Unified-Multi-Modal-Vision-Tasks-in-MLLMs/","children":"[논문리뷰] Patch-as-Decodable-Token: Towards Unified Multi-Modal Vision Tasks in MLLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jingyi Liao이 [arXiv]에 게시한 'Patch-as-Decodable-Token: Towards Unified Multi-Modal Vision Tasks in MLLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models (MLLMs)"]}],["$","span","Visual Reference Tokens (VRTs)",{"className":"page__taxonomy-item","children":["#","Visual Reference Tokens (VRTs)"]}],["$","span","Dense Prediction",{"className":"page__taxonomy-item","children":["#","Dense Prediction"]}],["$","span","Referring Expression Comprehension (REC)",{"className":"page__taxonomy-item","children":["#","Referring Expression Comprehension (REC)"]}],["$","span","Open-Vocabulary Detection (OVD)",{"className":"page__taxonomy-item","children":["#","Open-Vocabulary Detection (OVD)"]}],["$","span","Image Captioning",{"className":"page__taxonomy-item","children":["#","Image Captioning"]}],["$","span","Unified Architecture",{"className":"page__taxonomy-item","children":["#","Unified Architecture"]}],["$","span","Autoregressive Generation",{"className":"page__taxonomy-item","children":["#","Autoregressive Generation"]}]]}]]}]]}],["$","article","2025-10-9-Online-Generic-Event-Boundary-Detection",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Online-Generic-Event-Boundary-Detection/","children":"[논문리뷰] Online Generic Event Boundary Detection"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jonghyun Choi이 [arXiv]에 게시한 'Online Generic Event Boundary Detection' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Online Video Analysis",{"className":"page__taxonomy-item","children":["#","Online Video Analysis"]}],["$","span","Event Boundary Detection",{"className":"page__taxonomy-item","children":["#","Event Boundary Detection"]}],["$","span","Event Segmentation Theory",{"className":"page__taxonomy-item","children":["#","Event Segmentation Theory"]}],["$","span","Real-time AI",{"className":"page__taxonomy-item","children":["#","Real-time AI"]}],["$","span","Anomaly Detection",{"className":"page__taxonomy-item","children":["#","Anomaly Detection"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}]]}]]}]]}],["$","article","2025-10-9-OBS-Diff-Accurate-Pruning-For-Diffusion-Models-in-One-Shot",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-OBS-Diff-Accurate-Pruning-For-Diffusion-Models-in-One-Shot/","children":"[논문리뷰] OBS-Diff: Accurate Pruning For Diffusion Models in One-Shot"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'OBS-Diff: Accurate Pruning For Diffusion Models in One-Shot' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Network Pruning",{"className":"page__taxonomy-item","children":["#","Network Pruning"]}],["$","span","One-Shot Pruning",{"className":"page__taxonomy-item","children":["#","One-Shot Pruning"]}],["$","span","Optimal Brain Surgeon (OBS)",{"className":"page__taxonomy-item","children":["#","Optimal Brain Surgeon (OBS)"]}],["$","span","Model Compression",{"className":"page__taxonomy-item","children":["#","Model Compression"]}],["$","span","Timestep-Aware Hessian",{"className":"page__taxonomy-item","children":["#","Timestep-Aware Hessian"]}],["$","span","Structured Pruning",{"className":"page__taxonomy-item","children":["#","Structured Pruning"]}]]}]]}]]}],["$","article","2025-10-9-NorMuon-Making-Muon-more-efficient-and-scalable",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-NorMuon-Making-Muon-more-efficient-and-scalable/","children":"[논문리뷰] NorMuon: Making Muon more efficient and scalable"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Tuo Zhao이 [arXiv]에 게시한 'NorMuon: Making Muon more efficient and scalable' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Training",{"className":"page__taxonomy-item","children":["#","LLM Training"]}],["$","span","Optimizer",{"className":"page__taxonomy-item","children":["#","Optimizer"]}],["$","span","Muon",{"className":"page__taxonomy-item","children":["#","Muon"]}],["$","span","Orthogonalization",{"className":"page__taxonomy-item","children":["#","Orthogonalization"]}],["$","span","Adaptive Learning Rates",{"className":"page__taxonomy-item","children":["#","Adaptive Learning Rates"]}],["$","span","Distributed Training",{"className":"page__taxonomy-item","children":["#","Distributed Training"]}],["$","span","FSDP2",{"className":"page__taxonomy-item","children":["#","FSDP2"]}],["$","span","NorMuon",{"className":"page__taxonomy-item","children":["#","NorMuon"]}]]}]]}]]}],["$","article","2025-10-9-Native-Hybrid-Attention-for-Efficient-Sequence-Modeling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Native-Hybrid-Attention-for-Efficient-Sequence-Modeling/","children":"[논문리뷰] Native Hybrid Attention for Efficient Sequence Modeling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yu Cheng이 [arXiv]에 게시한 'Native Hybrid Attention for Efficient Sequence Modeling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Sequence Modeling",{"className":"page__taxonomy-item","children":["#","Sequence Modeling"]}],["$","span","Hybrid Attention",{"className":"page__taxonomy-item","children":["#","Hybrid Attention"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Linear Attention",{"className":"page__taxonomy-item","children":["#","Linear Attention"]}],["$","span","Sliding Window Attention",{"className":"page__taxonomy-item","children":["#","Sliding Window Attention"]}],["$","span","Long Context",{"className":"page__taxonomy-item","children":["#","Long Context"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Efficiency",{"className":"page__taxonomy-item","children":["#","Efficiency"]}]]}]]}]]}],["$","article","2025-10-9-Multi-Agent-Tool-Integrated-Policy-Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Multi-Agent-Tool-Integrated-Policy-Optimization/","children":"[논문리뷰] Multi-Agent Tool-Integrated Policy Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Lidong Bing이 [arXiv]에 게시한 'Multi-Agent Tool-Integrated Policy Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-Agent RL",{"className":"page__taxonomy-item","children":["#","Multi-Agent RL"]}],["$","span","Tool-Integrated Planning",{"className":"page__taxonomy-item","children":["#","Tool-Integrated Planning"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Credit Assignment",{"className":"page__taxonomy-item","children":["#","Credit Assignment"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","MATPO",{"className":"page__taxonomy-item","children":["#","MATPO"]}]]}]]}]]}],["$","article","2025-10-9-Ming-UniVision-Joint-Image-Understanding-and-Generation-with-a-Unified-Continuous-Tokenizer",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Ming-UniVision-Joint-Image-Understanding-and-Generation-with-a-Unified-Continuous-Tokenizer/","children":"[논문리뷰] Ming-UniVision: Joint Image Understanding and Generation with a Unified Continuous Tokenizer"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Ming-UniVision: Joint Image Understanding and Generation with a Unified Continuous Tokenizer' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Unified Vision-Language Model",{"className":"page__taxonomy-item","children":["#","Unified Vision-Language Model"]}],["$","span","Continuous Tokenizer",{"className":"page__taxonomy-item","children":["#","Continuous Tokenizer"]}],["$","span","Autoregressive Generation",{"className":"page__taxonomy-item","children":["#","Autoregressive Generation"]}],["$","span","Image Understanding",{"className":"page__taxonomy-item","children":["#","Image Understanding"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","In-context Editing",{"className":"page__taxonomy-item","children":["#","In-context Editing"]}]]}]]}]]}],["$","article","2025-10-9-MLE-Smith-Scaling-MLE-Tasks-with-Automated-Multi-Agent-Pipeline",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-MLE-Smith-Scaling-MLE-Tasks-with-Automated-Multi-Agent-Pipeline/","children":"[논문리뷰] MLE-Smith: Scaling MLE Tasks with Automated Multi-Agent Pipeline"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'MLE-Smith: Scaling MLE Tasks with Automated Multi-Agent Pipeline' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","MLE (Machine Learning Engineering)",{"className":"page__taxonomy-item","children":["#","MLE (Machine Learning Engineering)"]}],["$","span","Automated Task Generation",{"className":"page__taxonomy-item","children":["#","Automated Task Generation"]}],["$","span","Multi-Agent System",{"className":"page__taxonomy-item","children":["#","Multi-Agent System"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Hybrid Verification",{"className":"page__taxonomy-item","children":["#","Hybrid Verification"]}],["$","span","Kaggle",{"className":"page__taxonomy-item","children":["#","Kaggle"]}]]}]]}]]}],["$","article","2025-10-9-MATRIX-Mask-Track-Alignment-for-Interaction-aware-Video-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-MATRIX-Mask-Track-Alignment-for-Interaction-aware-Video-Generation/","children":"[논문리뷰] MATRIX: Mask Track Alignment for Interaction-aware Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hyunwook Choi이 [arXiv]에 게시한 'MATRIX: Mask Track Alignment for Interaction-aware Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Diffusion Transformers",{"className":"page__taxonomy-item","children":["#","Diffusion Transformers"]}],["$","span","Human-Object Interaction",{"className":"page__taxonomy-item","children":["#","Human-Object Interaction"]}],["$","span","Attention Alignment",{"className":"page__taxonomy-item","children":["#","Attention Alignment"]}],["$","span","Mask Tracking",{"className":"page__taxonomy-item","children":["#","Mask Tracking"]}],["$","span","Semantic Grounding",{"className":"page__taxonomy-item","children":["#","Semantic Grounding"]}],["$","span","Semantic Propagation",{"className":"page__taxonomy-item","children":["#","Semantic Propagation"]}],["$","span","Text-to-Video",{"className":"page__taxonomy-item","children":["#","Text-to-Video"]}]]}]]}]]}],["$","article","2025-10-9-Lumina-DiMOO-An-Omni-Diffusion-Large-Language-Model-for-Multi-Modal-Generation-and-Understanding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Lumina-DiMOO-An-Omni-Diffusion-Large-Language-Model-for-Multi-Modal-Generation-and-Understanding/","children":"[논문리뷰] Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-modal LLM",{"className":"page__taxonomy-item","children":["#","Multi-modal LLM"]}],["$","span","Discrete Diffusion",{"className":"page__taxonomy-item","children":["#","Discrete Diffusion"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Image Understanding",{"className":"page__taxonomy-item","children":["#","Image Understanding"]}],["$","span","Omni-modal",{"className":"page__taxonomy-item","children":["#","Omni-modal"]}],["$","span","Interactive Retouching",{"className":"page__taxonomy-item","children":["#","Interactive Retouching"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}]]}]]}]]}],["$","article","2025-10-9-Heptapod-Language-Modeling-on-Visual-Signals",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Heptapod-Language-Modeling-on-Visual-Signals/","children":"[논문리뷰] Heptapod: Language Modeling on Visual Signals"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Heptapod: Language Modeling on Visual Signals' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Autoregressive Models",{"className":"page__taxonomy-item","children":["#","Autoregressive Models"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Language Modeling",{"className":"page__taxonomy-item","children":["#","Language Modeling"]}],["$","span","Causal Transformer",{"className":"page__taxonomy-item","children":["#","Causal Transformer"]}],["$","span","2D Distribution Prediction",{"className":"page__taxonomy-item","children":["#","2D Distribution Prediction"]}],["$","span","Visual Tokenization",{"className":"page__taxonomy-item","children":["#","Visual Tokenization"]}],["$","span","Self-Supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-Supervised Learning"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}]]}]]}]]}],["$","article","2025-10-9-G2RPO-Granular-GRPO-for-Precise-Reward-in-Flow-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-G2RPO-Granular-GRPO-for-Precise-Reward-in-Flow-Models/","children":"[논문리뷰] G^2RPO: Granular GRPO for Precise Reward in Flow Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'G^2RPO: Granular GRPO for Precise Reward in Flow Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Flow Models",{"className":"page__taxonomy-item","children":["#","Flow Models"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Human Preference Alignment",{"className":"page__taxonomy-item","children":["#","Human Preference Alignment"]}],["$","span","Stochastic Differential Equations (SDE)",{"className":"page__taxonomy-item","children":["#","Stochastic Differential Equations (SDE)"]}],["$","span","Reward Signal",{"className":"page__taxonomy-item","children":["#","Reward Signal"]}],["$","span","Multi-Granularity",{"className":"page__taxonomy-item","children":["#","Multi-Granularity"]}]]}]]}]]}],["$","article","2025-10-9-DeepTravel-An-End-to-End-Agentic-Reinforcement-Learning-Framework-for-Autonomous-Travel-Planning-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-DeepTravel-An-End-to-End-Agentic-Reinforcement-Learning-Framework-for-Autonomous-Travel-Planning-Agents/","children":"[논문리뷰] DeepTravel: An End-to-End Agentic Reinforcement Learning Framework for Autonomous Travel Planning Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DeepTravel: An End-to-End Agentic Reinforcement Learning Framework for Autonomous Travel Planning Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Agentic Reinforcement Learning"]}],["$","span","Travel Planning",{"className":"page__taxonomy-item","children":["#","Travel Planning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Sandbox Environment",{"className":"page__taxonomy-item","children":["#","Sandbox Environment"]}],["$","span","Hierarchical Reward Modeling",{"className":"page__taxonomy-item","children":["#","Hierarchical Reward Modeling"]}],["$","span","Experience Replay",{"className":"page__taxonomy-item","children":["#","Experience Replay"]}],["$","span","Autonomous Agents",{"className":"page__taxonomy-item","children":["#","Autonomous Agents"]}]]}]]}]]}],["$","article","2025-10-9-D3QE-Learning-Discrete-Distribution-Discrepancy-aware-Quantization-Error-for-Autoregressive-Generated-Image-Detection",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-D3QE-Learning-Discrete-Distribution-Discrepancy-aware-Quantization-Error-for-Autoregressive-Generated-Image-Detection/","children":"[논문리뷰] D^3QE: Learning Discrete Distribution Discrepancy-aware Quantization Error for Autoregressive-Generated Image Detection"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yueqi Duan이 [arXiv]에 게시한 'D^3QE: Learning Discrete Distribution Discrepancy-aware Quantization Error for Autoregressive-Generated Image Detection' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Autoregressive Models",{"className":"page__taxonomy-item","children":["#","Autoregressive Models"]}],["$","span","Image Detection",{"className":"page__taxonomy-item","children":["#","Image Detection"]}],["$","span","Discrete Distribution Discrepancy",{"className":"page__taxonomy-item","children":["#","Discrete Distribution Discrepancy"]}],["$","span","Quantization Error",{"className":"page__taxonomy-item","children":["#","Quantization Error"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Deepfake Detection",{"className":"page__taxonomy-item","children":["#","Deepfake Detection"]}]]}]]}]]}],["$","article","2025-10-9-Cache-to-Cache-Direct-Semantic-Communication-Between-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Cache-to-Cache-Direct-Semantic-Communication-Between-Large-Language-Models/","children":"[논문리뷰] Cache-to-Cache: Direct Semantic Communication Between Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Cache-to-Cache: Direct Semantic Communication Between Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Inter-model Communication",{"className":"page__taxonomy-item","children":["#","Inter-model Communication"]}],["$","span","KV-Cache",{"className":"page__taxonomy-item","children":["#","KV-Cache"]}],["$","span","Semantic Transfer",{"className":"page__taxonomy-item","children":["#","Semantic Transfer"]}],["$","span","Multi-LLM Systems",{"className":"page__taxonomy-item","children":["#","Multi-LLM Systems"]}],["$","span","Cache Fusion",{"className":"page__taxonomy-item","children":["#","Cache Fusion"]}],["$","span","Latency Reduction",{"className":"page__taxonomy-item","children":["#","Latency Reduction"]}],["$","span","Knowledge Sharing",{"className":"page__taxonomy-item","children":["#","Knowledge Sharing"]}]]}]]}]]}],["$","article","2025-10-9-CALM-Before-the-STORM-Unlocking-Native-Reasoning-for-Optimization-Modeling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-CALM-Before-the-STORM-Unlocking-Native-Reasoning-for-Optimization-Modeling/","children":"[논문리뷰] CALM Before the STORM: Unlocking Native Reasoning for Optimization Modeling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chengpeng Li이 [arXiv]에 게시한 'CALM Before the STORM: Unlocking Native Reasoning for Optimization Modeling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Reasoning Models",{"className":"page__taxonomy-item","children":["#","Large Reasoning Models"]}],["$","span","Optimization Modeling",{"className":"page__taxonomy-item","children":["#","Optimization Modeling"]}],["$","span","Reflective Generation",{"className":"page__taxonomy-item","children":["#","Reflective Generation"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Human-in-the-Loop",{"className":"page__taxonomy-item","children":["#","Human-in-the-Loop"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","Domain Adaptation",{"className":"page__taxonomy-item","children":["#","Domain Adaptation"]}]]}]]}]]}],["$","article","2025-10-9-Bridging-Text-and-Video-Generation-A-Survey",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Bridging-Text-and-Video-Generation-A-Survey/","children":"[논문리뷰] Bridging Text and Video Generation: A Survey"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"G. Maragatham이 [arXiv]에 게시한 'Bridging Text and Video Generation: A Survey' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Video Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Video Generation"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","GANs",{"className":"page__taxonomy-item","children":["#","GANs"]}],["$","span","VAEs",{"className":"page__taxonomy-item","children":["#","VAEs"]}],["$","span","Video Synthesis",{"className":"page__taxonomy-item","children":["#","Video Synthesis"]}],["$","span","Survey",{"className":"page__taxonomy-item","children":["#","Survey"]}],["$","span","Evaluation Metrics",{"className":"page__taxonomy-item","children":["#","Evaluation Metrics"]}]]}]]}]]}],["$","article","2025-10-9-Beyond-Monolingual-Assumptions-A-Survey-of-Code-Switched-NLP-in-the-Era-of-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Beyond-Monolingual-Assumptions-A-Survey-of-Code-Switched-NLP-in-the-Era-of-Large-Language-Models/","children":"[논문리뷰] Beyond Monolingual Assumptions: A Survey of Code-Switched NLP in the Era of Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Beyond Monolingual Assumptions: A Survey of Code-Switched NLP in the Era of Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Code-switching",{"className":"page__taxonomy-item","children":["#","Code-switching"]}],["$","span","Multilingual NLP",{"className":"page__taxonomy-item","children":["#","Multilingual NLP"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","NLP Survey",{"className":"page__taxonomy-item","children":["#","NLP Survey"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}],["$","span","Evaluation Metrics",{"className":"page__taxonomy-item","children":["#","Evaluation Metrics"]}],["$","span","Low-Resource Languages",{"className":"page__taxonomy-item","children":["#","Low-Resource Languages"]}]]}]]}]]}],["$","article","2025-10-9-Artificial-Hippocampus-Networks-for-Efficient-Long-Context-Modeling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Artificial-Hippocampus-Networks-for-Efficient-Long-Context-Modeling/","children":"[논문리뷰] Artificial Hippocampus Networks for Efficient Long-Context Modeling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Artificial Hippocampus Networks for Efficient Long-Context Modeling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Long-Context Modeling",{"className":"page__taxonomy-item","children":["#","Long-Context Modeling"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","RNN",{"className":"page__taxonomy-item","children":["#","RNN"]}],["$","span","Memory Management",{"className":"page__taxonomy-item","children":["#","Memory Management"]}],["$","span","Self-Distillation",{"className":"page__taxonomy-item","children":["#","Self-Distillation"]}],["$","span","Attention Mechanism",{"className":"page__taxonomy-item","children":["#","Attention Mechanism"]}],["$","span","Artificial Hippocampus Networks",{"className":"page__taxonomy-item","children":["#","Artificial Hippocampus Networks"]}],["$","span","Cognitive Science",{"className":"page__taxonomy-item","children":["#","Cognitive Science"]}]]}]]}]]}],["$","article","2025-10-9-Are-We-Using-the-Right-Benchmark-An-Evaluation-Framework-for-Visual-Token-Compression-Methods",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Are-We-Using-the-Right-Benchmark-An-Evaluation-Framework-for-Visual-Token-Compression-Methods/","children":"[논문리뷰] Are We Using the Right Benchmark: An Evaluation Framework for Visual Token Compression Methods"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yiyu Wang이 [arXiv]에 게시한 'Are We Using the Right Benchmark: An Evaluation Framework for Visual Token Compression Methods' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Visual Token Compression",{"className":"page__taxonomy-item","children":["#","Visual Token Compression"]}],["$","span","MLLMs",{"className":"page__taxonomy-item","children":["#","MLLMs"]}],["$","span","Evaluation Framework",{"className":"page__taxonomy-item","children":["#","Evaluation Framework"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Downsampling",{"className":"page__taxonomy-item","children":["#","Downsampling"]}],["$","span","Data Filtering",{"className":"page__taxonomy-item","children":["#","Data Filtering"]}],["$","span","Model Efficiency",{"className":"page__taxonomy-item","children":["#","Model Efficiency"]}]]}]]}]]}],["$","article","2025-10-9-AlphaApollo-Orchestrating-Foundation-Models-and-Professional-Tools-into-a-Self-Evolving-System-for-Deep-Agentic-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-AlphaApollo-Orchestrating-Foundation-Models-and-Professional-Tools-into-a-Self-Evolving-System-for-Deep-Agentic-Reasoning/","children":"[논문리뷰] AlphaApollo: Orchestrating Foundation Models and Professional Tools into a Self-Evolving System for Deep Agentic Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zongze Li이 [arXiv]에 게시한 'AlphaApollo: Orchestrating Foundation Models and Professional Tools into a Self-Evolving System for Deep Agentic Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Agentic Reasoning",{"className":"page__taxonomy-item","children":["#","Agentic Reasoning"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Self-Evolving System",{"className":"page__taxonomy-item","children":["#","Self-Evolving System"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","Computational Tools",{"className":"page__taxonomy-item","children":["#","Computational Tools"]}],["$","span","Error Correction",{"className":"page__taxonomy-item","children":["#","Error Correction"]}]]}]]}]]}],["$","article","2025-10-8-VeriGuard-Enhancing-LLM-Agent-Safety-via-Verified-Code-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-VeriGuard-Enhancing-LLM-Agent-Safety-via-Verified-Code-Generation/","children":"[논문리뷰] VeriGuard: Enhancing LLM Agent Safety via Verified Code Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'VeriGuard: Enhancing LLM Agent Safety via Verified Code Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Safety",{"className":"page__taxonomy-item","children":["#","Safety"]}],["$","span","Formal Verification",{"className":"page__taxonomy-item","children":["#","Formal Verification"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","Runtime Monitoring",{"className":"page__taxonomy-item","children":["#","Runtime Monitoring"]}],["$","span","Security",{"className":"page__taxonomy-item","children":["#","Security"]}],["$","span","Guardrails",{"className":"page__taxonomy-item","children":["#","Guardrails"]}],["$","span","Policy Enforcement",{"className":"page__taxonomy-item","children":["#","Policy Enforcement"]}]]}]]}]]}],["$","article","2025-10-8-Training-Dynamics-Impact-Post-Training-Quantization-Robustness",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Training-Dynamics-Impact-Post-Training-Quantization-Robustness/","children":"[논문리뷰] Training Dynamics Impact Post-Training Quantization Robustness"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jonas Geiping이 [arXiv]에 게시한 'Training Dynamics Impact Post-Training Quantization Robustness' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Post-Training Quantization",{"className":"page__taxonomy-item","children":["#","Post-Training Quantization"]}],["$","span","Quantization Robustness",{"className":"page__taxonomy-item","children":["#","Quantization Robustness"]}],["$","span","Training Dynamics",{"className":"page__taxonomy-item","children":["#","Training Dynamics"]}],["$","span","Learning Rate Schedules",{"className":"page__taxonomy-item","children":["#","Learning Rate Schedules"]}],["$","span","Weight Averaging",{"className":"page__taxonomy-item","children":["#","Weight Averaging"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Hyperparameter Tuning",{"className":"page__taxonomy-item","children":["#","Hyperparameter Tuning"]}]]}]]}]]}],["$","article","2025-10-8-TensorBLEU-Vectorized-GPU-based-BLEU-Score-Implementation-for-Per-Sentence-In-Training-Evaluation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-TensorBLEU-Vectorized-GPU-based-BLEU-Score-Implementation-for-Per-Sentence-In-Training-Evaluation/","children":"[논문리뷰] TensorBLEU: Vectorized GPU-based BLEU Score Implementation for Per-Sentence In-Training Evaluation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'TensorBLEU: Vectorized GPU-based BLEU Score Implementation for Per-Sentence In-Training Evaluation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","BLEU Score",{"className":"page__taxonomy-item","children":["#","BLEU Score"]}],["$","span","GPU Acceleration",{"className":"page__taxonomy-item","children":["#","GPU Acceleration"]}],["$","span","PyTorch",{"className":"page__taxonomy-item","children":["#","PyTorch"]}],["$","span","Natural Language Processing",{"className":"page__taxonomy-item","children":["#","Natural Language Processing"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Vectorization",{"className":"page__taxonomy-item","children":["#","Vectorization"]}],["$","span","In-Training Evaluation",{"className":"page__taxonomy-item","children":["#","In-Training Evaluation"]}],["$","span","N-gram Counting",{"className":"page__taxonomy-item","children":["#","N-gram Counting"]}]]}]]}]]}],["$","article","2025-10-8-TaTToo-Tool-Grounded-Thinking-PRM-for-Test-Time-Scaling-in-Tabular-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-TaTToo-Tool-Grounded-Thinking-PRM-for-Test-Time-Scaling-in-Tabular-Reasoning/","children":"[논문리뷰] TaTToo: Tool-Grounded Thinking PRM for Test-Time Scaling in Tabular Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'TaTToo: Tool-Grounded Thinking PRM for Test-Time Scaling in Tabular Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Process Reward Models",{"className":"page__taxonomy-item","children":["#","Process Reward Models"]}],["$","span","Tabular Reasoning",{"className":"page__taxonomy-item","children":["#","Tabular Reasoning"]}],["$","span","Test-Time Scaling",{"className":"page__taxonomy-item","children":["#","Test-Time Scaling"]}],["$","span","Tool Integration",{"className":"page__taxonomy-item","children":["#","Tool Integration"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}]]}]]}]]}],["$","article","2025-10-8-ShapeGen4D-Towards-High-Quality-4D-Shape-Generation-from-Videos",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-ShapeGen4D-Towards-High-Quality-4D-Shape-Generation-from-Videos/","children":"[논문리뷰] ShapeGen4D: Towards High Quality 4D Shape Generation from Videos"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Sergey Tulyakov이 [arXiv]에 게시한 'ShapeGen4D: Towards High Quality 4D Shape Generation from Videos' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","4D Shape Generation",{"className":"page__taxonomy-item","children":["#","4D Shape Generation"]}],["$","span","Video-conditioned",{"className":"page__taxonomy-item","children":["#","Video-conditioned"]}],["$","span","Dynamic 3D Meshes",{"className":"page__taxonomy-item","children":["#","Dynamic 3D Meshes"]}],["$","span","Latent Diffusion Model",{"className":"page__taxonomy-item","children":["#","Latent Diffusion Model"]}],["$","span","Spatiotemporal Attention",{"className":"page__taxonomy-item","children":["#","Spatiotemporal Attention"]}],["$","span","Temporal Consistency",{"className":"page__taxonomy-item","children":["#","Temporal Consistency"]}],["$","span","Pre-trained 3D Models",{"className":"page__taxonomy-item","children":["#","Pre-trained 3D Models"]}],["$","span","VAE",{"className":"page__taxonomy-item","children":["#","VAE"]}]]}]]}]]}],["$","article","2025-10-8-Scaling-Code-Assisted-Chain-of-Thoughts-and-Instructions-for-Model-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Scaling-Code-Assisted-Chain-of-Thoughts-and-Instructions-for-Model-Reasoning/","children":"[논문리뷰] Scaling Code-Assisted Chain-of-Thoughts and Instructions for Model Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhuoshi Pan이 [arXiv]에 게시한 'Scaling Code-Assisted Chain-of-Thoughts and Instructions for Model Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Code-Assisted Reasoning",{"className":"page__taxonomy-item","children":["#","Code-Assisted Reasoning"]}],["$","span","Chain-of-Thought (CoT)",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought (CoT)"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Self-Verification",{"className":"page__taxonomy-item","children":["#","Self-Verification"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}]]}]]}]]}],["$","article","2025-10-8-Revisiting-Modeling-and-Evaluation-Approaches-in-Speech-Emotion-Recognition-Considering-Subjectivity-of-Annotators-and-Ambiguity-of-Emotions",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Revisiting-Modeling-and-Evaluation-Approaches-in-Speech-Emotion-Recognition-Considering-Subjectivity-of-Annotators-and-Ambiguity-of-Emotions/","children":"[논문리뷰] Revisiting Modeling and Evaluation Approaches in Speech Emotion Recognition: Considering Subjectivity of Annotators and Ambiguity of Emotions"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Revisiting Modeling and Evaluation Approaches in Speech Emotion Recognition: Considering Subjectivity of Annotators and Ambiguity of Emotions' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Speech Emotion Recognition",{"className":"page__taxonomy-item","children":["#","Speech Emotion Recognition"]}],["$","span","Annotator Subjectivity",{"className":"page__taxonomy-item","children":["#","Annotator Subjectivity"]}],["$","span","Emotion Ambiguity",{"className":"page__taxonomy-item","children":["#","Emotion Ambiguity"]}],["$","span","Soft Labels",{"className":"page__taxonomy-item","children":["#","Soft Labels"]}],["$","span","Multi-label Classification",{"className":"page__taxonomy-item","children":["#","Multi-label Classification"]}],["$","span","Evaluation Metrics",{"className":"page__taxonomy-item","children":["#","Evaluation Metrics"]}],["$","span","Loss Functions",{"className":"page__taxonomy-item","children":["#","Loss Functions"]}]]}]]}]]}],["$","article","2025-10-8-Refusal-Falls-off-a-Cliff-How-Safety-Alignment-Fails-in-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Refusal-Falls-off-a-Cliff-How-Safety-Alignment-Fails-in-Reasoning/","children":"[논문리뷰] Refusal Falls off a Cliff: How Safety Alignment Fails in Reasoning?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Refusal Falls off a Cliff: How Safety Alignment Fails in Reasoning?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Safety Alignment",{"className":"page__taxonomy-item","children":["#","Safety Alignment"]}],["$","span","Large Reasoning Models",{"className":"page__taxonomy-item","children":["#","Large Reasoning Models"]}],["$","span","Mechanistic Interpretability",{"className":"page__taxonomy-item","children":["#","Mechanistic Interpretability"]}],["$","span","Refusal Cliff",{"className":"page__taxonomy-item","children":["#","Refusal Cliff"]}],["$","span","Attention Heads",{"className":"page__taxonomy-item","children":["#","Attention Heads"]}],["$","span","Data Selection",{"className":"page__taxonomy-item","children":["#","Data Selection"]}],["$","span","Linear Probing",{"className":"page__taxonomy-item","children":["#","Linear Probing"]}]]}]]}]]}],["$","article","2025-10-8-Presenting-a-Paper-is-an-Art-Self-Improvement-Aesthetic-Agents-for-Academic-Presentations",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Presenting-a-Paper-is-an-Art-Self-Improvement-Aesthetic-Agents-for-Academic-Presentations/","children":"[논문리뷰] Presenting a Paper is an Art: Self-Improvement Aesthetic Agents for Academic Presentations"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Presenting a Paper is an Art: Self-Improvement Aesthetic Agents for Academic Presentations' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Self-Improvement Agent",{"className":"page__taxonomy-item","children":["#","Self-Improvement Agent"]}],["$","span","Academic Presentation",{"className":"page__taxonomy-item","children":["#","Academic Presentation"]}],["$","span","Aesthetic Evaluation",{"className":"page__taxonomy-item","children":["#","Aesthetic Evaluation"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Multi-task Learning",{"className":"page__taxonomy-item","children":["#","Multi-task Learning"]}],["$","span","Presentation Generation",{"className":"page__taxonomy-item","children":["#","Presentation Generation"]}],["$","span","LLM-based Agents",{"className":"page__taxonomy-item","children":["#","LLM-based Agents"]}],["$","span","Human Feedback",{"className":"page__taxonomy-item","children":["#","Human Feedback"]}]]}]]}]]}],["$","article","2025-10-8-OneFlow-Concurrent-Mixed-Modal-and-Interleaved-Generation-with-Edit-Flows",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-OneFlow-Concurrent-Mixed-Modal-and-Interleaved-Generation-with-Edit-Flows/","children":"[논문리뷰] OneFlow: Concurrent Mixed-Modal and Interleaved Generation with Edit Flows"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'OneFlow: Concurrent Mixed-Modal and Interleaved Generation with Edit Flows' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Non-Autoregressive",{"className":"page__taxonomy-item","children":["#","Non-Autoregressive"]}],["$","span","Multimodal Generation",{"className":"page__taxonomy-item","children":["#","Multimodal Generation"]}],["$","span","Edit Flows",{"className":"page__taxonomy-item","children":["#","Edit Flows"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Interleaved Generation",{"className":"page__taxonomy-item","children":["#","Interleaved Generation"]}],["$","span","Text-to-Image Synthesis",{"className":"page__taxonomy-item","children":["#","Text-to-Image Synthesis"]}],["$","span","Unified Models",{"className":"page__taxonomy-item","children":["#","Unified Models"]}]]}]]}]]}],["$","article","2025-10-8-No-Tokens-Wasted-Leveraging-Long-Context-in-Biomedical-Vision-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-No-Tokens-Wasted-Leveraging-Long-Context-in-Biomedical-Vision-Language-Models/","children":"[논문리뷰] No Tokens Wasted: Leveraging Long Context in Biomedical Vision-Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiao Xiao Sun이 [arXiv]에 게시한 'No Tokens Wasted: Leveraging Long Context in Biomedical Vision-Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Biomedical Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Biomedical Vision-Language Models"]}],["$","span","Long-context Modeling",{"className":"page__taxonomy-item","children":["#","Long-context Modeling"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Token Efficiency",{"className":"page__taxonomy-item","children":["#","Token Efficiency"]}],["$","span","Zero-shot Classification",{"className":"page__taxonomy-item","children":["#","Zero-shot Classification"]}],["$","span","Medical Image Retrieval",{"className":"page__taxonomy-item","children":["#","Medical Image Retrieval"]}]]}]]}]]}],["$","article","2025-10-8-Mixing-Mechanisms-How-Language-Models-Retrieve-Bound-Entities-In-Context",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Mixing-Mechanisms-How-Language-Models-Retrieve-Bound-Entities-In-Context/","children":"[논문리뷰] Mixing Mechanisms: How Language Models Retrieve Bound Entities In-Context"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Mixing Mechanisms: How Language Models Retrieve Bound Entities In-Context' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Language Models",{"className":"page__taxonomy-item","children":["#","Language Models"]}],["$","span","In-Context Learning",{"className":"page__taxonomy-item","children":["#","In-Context Learning"]}],["$","span","Entity Binding",{"className":"page__taxonomy-item","children":["#","Entity Binding"]}],["$","span","Mechanistic Interpretability",{"className":"page__taxonomy-item","children":["#","Mechanistic Interpretability"]}],["$","span","Causal Abstraction",{"className":"page__taxonomy-item","children":["#","Causal Abstraction"]}],["$","span","Long-Context Reasoning",{"className":"page__taxonomy-item","children":["#","Long-Context Reasoning"]}],["$","span","Positional Encoding",{"className":"page__taxonomy-item","children":["#","Positional Encoding"]}],["$","span","Information Retrieval",{"className":"page__taxonomy-item","children":["#","Information Retrieval"]}]]}]]}]]}],["$","article","2025-10-8-MixReasoning-Switching-Modes-to-Think",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-MixReasoning-Switching-Modes-to-Think/","children":"[논문리뷰] MixReasoning: Switching Modes to Think"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'MixReasoning: Switching Modes to Think' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Reasoning",{"className":"page__taxonomy-item","children":["#","LLM Reasoning"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Efficiency",{"className":"page__taxonomy-item","children":["#","Efficiency"]}],["$","span","LoRA",{"className":"page__taxonomy-item","children":["#","LoRA"]}],["$","span","Adaptive Reasoning",{"className":"page__taxonomy-item","children":["#","Adaptive Reasoning"]}],["$","span","Token Uncertainty",{"className":"page__taxonomy-item","children":["#","Token Uncertainty"]}],["$","span","Dynamic Switching",{"className":"page__taxonomy-item","children":["#","Dynamic Switching"]}],["$","span","Reasoning Compression",{"className":"page__taxonomy-item","children":["#","Reasoning Compression"]}]]}]]}]]}],["$","article","2025-10-8-Margin-Adaptive-DPO-Leveraging-Reward-Model-for-Granular-Control-in-Preference-Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Margin-Adaptive-DPO-Leveraging-Reward-Model-for-Granular-Control-in-Preference-Optimization/","children":"[논문리뷰] Margin Adaptive DPO: Leveraging Reward Model for Granular Control in Preference Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"sirano1004이 [arXiv]에 게시한 'Margin Adaptive DPO: Leveraging Reward Model for Granular Control in Preference Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Direct Preference Optimization",{"className":"page__taxonomy-item","children":["#","Direct Preference Optimization"]}],["$","span","Preference Alignment",{"className":"page__taxonomy-item","children":["#","Preference Alignment"]}],["$","span","Adaptive Regularization",{"className":"page__taxonomy-item","children":["#","Adaptive Regularization"]}],["$","span","Reward Model",{"className":"page__taxonomy-item","children":["#","Reward Model"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Sentiment Generation",{"className":"page__taxonomy-item","children":["#","Sentiment Generation"]}]]}]]}]]}],["$","article","2025-10-8-LightCache-Memory-Efficient-Training-Free-Acceleration-for-Video-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-LightCache-Memory-Efficient-Training-Free-Acceleration-for-Video-Generation/","children":"[논문리뷰] LightCache: Memory-Efficient, Training-Free Acceleration for Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zheng Zhan이 [arXiv]에 게시한 'LightCache: Memory-Efficient, Training-Free Acceleration for Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Memory Efficiency",{"className":"page__taxonomy-item","children":["#","Memory Efficiency"]}],["$","span","Inference Acceleration",{"className":"page__taxonomy-item","children":["#","Inference Acceleration"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}],["$","span","Cache Mechanism",{"className":"page__taxonomy-item","children":["#","Cache Mechanism"]}],["$","span","GPU Optimization",{"className":"page__taxonomy-item","children":["#","GPU Optimization"]}]]}]]}]]}],["$","article","2025-10-8-Less-is-More-Recursive-Reasoning-with-Tiny-Networks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Less-is-More-Recursive-Reasoning-with-Tiny-Networks/","children":"[논문리뷰] Less is More: Recursive Reasoning with Tiny Networks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Less is More: Recursive Reasoning with Tiny Networks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Recursive Reasoning",{"className":"page__taxonomy-item","children":["#","Recursive Reasoning"]}],["$","span","Tiny Networks",{"className":"page__taxonomy-item","children":["#","Tiny Networks"]}],["$","span","Deep Supervision",{"className":"page__taxonomy-item","children":["#","Deep Supervision"]}],["$","span","Hierarchical Reasoning Model (HRM)",{"className":"page__taxonomy-item","children":["#","Hierarchical Reasoning Model (HRM)"]}],["$","span","Sudoku-Extreme",{"className":"page__taxonomy-item","children":["#","Sudoku-Extreme"]}],["$","span","ARC-AGI",{"className":"page__taxonomy-item","children":["#","ARC-AGI"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Parameter Efficiency",{"className":"page__taxonomy-item","children":["#","Parameter Efficiency"]}]]}]]}]]}],["$","article","2025-10-8-In-the-Flow-Agentic-System-Optimization-for-Effective-Planning-and-Tool-Use",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-In-the-Flow-Agentic-System-Optimization-for-Effective-Planning-and-Tool-Use/","children":"[논문리뷰] In-the-Flow Agentic System Optimization for Effective Planning and Tool Use"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'In-the-Flow Agentic System Optimization for Effective Planning and Tool Use' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic Systems",{"className":"page__taxonomy-item","children":["#","Agentic Systems"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","On-policy Optimization",{"className":"page__taxonomy-item","children":["#","On-policy Optimization"]}],["$","span","Flow-based Group Refined Policy Optimization (Flow-GRPO)",{"className":"page__taxonomy-item","children":["#","Flow-based Group Refined Policy Optimization (Flow-GRPO)"]}],["$","span","Multi-turn Reasoning",{"className":"page__taxonomy-item","children":["#","Multi-turn Reasoning"]}]]}]]}]]}],["$","article","2025-10-8-Human3R-Everyone-Everywhere-All-at-Once",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Human3R-Everyone-Everywhere-All-at-Once/","children":"[논문리뷰] Human3R: Everyone Everywhere All at Once"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuliang Xiu이 [arXiv]에 게시한 'Human3R: Everyone Everywhere All at Once' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","4D Human-Scene Reconstruction",{"className":"page__taxonomy-item","children":["#","4D Human-Scene Reconstruction"]}],["$","span","Online Reconstruction",{"className":"page__taxonomy-item","children":["#","Online Reconstruction"]}],["$","span","Multi-person",{"className":"page__taxonomy-item","children":["#","Multi-person"]}],["$","span","SMPL-X",{"className":"page__taxonomy-item","children":["#","SMPL-X"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Visual Prompt Tuning",{"className":"page__taxonomy-item","children":["#","Visual Prompt Tuning"]}],["$","span","Real-time",{"className":"page__taxonomy-item","children":["#","Real-time"]}],["$","span","Foundation Model",{"className":"page__taxonomy-item","children":["#","Foundation Model"]}]]}]]}]]}],["$","article","2025-10-8-HoloScene-Simulation-Ready-Interactive-3D-Worlds-from-a-Single-Video",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-HoloScene-Simulation-Ready-Interactive-3D-Worlds-from-a-Single-Video/","children":"[논문리뷰] HoloScene: Simulation-Ready Interactive 3D Worlds from a Single Video"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Katelyn Gao이 [arXiv]에 게시한 'HoloScene: Simulation-Ready Interactive 3D Worlds from a Single Video' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Reconstruction",{"className":"page__taxonomy-item","children":["#","3D Reconstruction"]}],["$","span","Digital Twin",{"className":"page__taxonomy-item","children":["#","Digital Twin"]}],["$","span","Scene Graph",{"className":"page__taxonomy-item","children":["#","Scene Graph"]}],["$","span","Physical Simulation",{"className":"page__taxonomy-item","children":["#","Physical Simulation"]}],["$","span","Interactive Environments",{"className":"page__taxonomy-item","children":["#","Interactive Environments"]}],["$","span","Single Video Reconstruction",{"className":"page__taxonomy-item","children":["#","Single Video Reconstruction"]}],["$","span","Neural Rendering",{"className":"page__taxonomy-item","children":["#","Neural Rendering"]}]]}]]}]]}],["$","article","2025-10-8-HalluGuard-Evidence-Grounded-Small-Reasoning-Models-to-Mitigate-Hallucinations-in-Retrieval-Augmented-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-HalluGuard-Evidence-Grounded-Small-Reasoning-Models-to-Mitigate-Hallucinations-in-Retrieval-Augmented-Generation/","children":"[논문리뷰] HalluGuard: Evidence-Grounded Small Reasoning Models to Mitigate Hallucinations in Retrieval-Augmented Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Radu State이 [arXiv]에 게시한 'HalluGuard: Evidence-Grounded Small Reasoning Models to Mitigate Hallucinations in Retrieval-Augmented Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Hallucination Detection",{"className":"page__taxonomy-item","children":["#","Hallucination Detection"]}],["$","span","Retrieval-Augmented Generation (RAG)",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation (RAG)"]}],["$","span","Small Reasoning Model (SRM)",{"className":"page__taxonomy-item","children":["#","Small Reasoning Model (SRM)"]}],["$","span","Preference Fine-tuning",{"className":"page__taxonomy-item","children":["#","Preference Fine-tuning"]}],["$","span","ORPO",{"className":"page__taxonomy-item","children":["#","ORPO"]}],["$","span","Evidence Grounding",{"className":"page__taxonomy-item","children":["#","Evidence Grounding"]}],["$","span","Fact-checking",{"className":"page__taxonomy-item","children":["#","Fact-checking"]}]]}]]}]]}],["$","article","2025-10-8-Fathom-DeepResearch-Unlocking-Long-Horizon-Information-Retrieval-and-Synthesis-for-SLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Fathom-DeepResearch-Unlocking-Long-Horizon-Information-Retrieval-and-Synthesis-for-SLMs/","children":"[논문리뷰] Fathom-DeepResearch: Unlocking Long Horizon Information Retrieval and Synthesis for SLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Fathom-DeepResearch: Unlocking Long Horizon Information Retrieval and Synthesis for SLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","DeepResearch Agents",{"className":"page__taxonomy-item","children":["#","DeepResearch Agents"]}],["$","span","Tool-integrated Reasoning",{"className":"page__taxonomy-item","children":["#","Tool-integrated Reasoning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Information Retrieval",{"className":"page__taxonomy-item","children":["#","Information Retrieval"]}],["$","span","Information Synthesis",{"className":"page__taxonomy-item","children":["#","Information Synthesis"]}],["$","span","Multi-agent Self-play",{"className":"page__taxonomy-item","children":["#","Multi-agent Self-play"]}],["$","span","Reward Shaping",{"className":"page__taxonomy-item","children":["#","Reward Shaping"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}]]}]]}]]}],["$","article","2025-10-8-Fast-dLLM-v2-Efficient-Block-Diffusion-LLM",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Fast-dLLM-v2-Efficient-Block-Diffusion-LLM/","children":"[논문리뷰] Fast-dLLM v2: Efficient Block-Diffusion LLM"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Fast-dLLM v2: Efficient Block-Diffusion LLM' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion LLMs",{"className":"page__taxonomy-item","children":["#","Diffusion LLMs"]}],["$","span","Inference Acceleration",{"className":"page__taxonomy-item","children":["#","Inference Acceleration"]}],["$","span","Parallel Decoding",{"className":"page__taxonomy-item","children":["#","Parallel Decoding"]}],["$","span","Autoregressive Models",{"className":"page__taxonomy-item","children":["#","Autoregressive Models"]}],["$","span","Caching",{"className":"page__taxonomy-item","children":["#","Caching"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Block-wise Attention",{"className":"page__taxonomy-item","children":["#","Block-wise Attention"]}]]}]]}]]}],["$","article","2025-10-8-Equilibrium-Matching-Generative-Modeling-with-Implicit-Energy-Based-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Equilibrium-Matching-Generative-Modeling-with-Implicit-Energy-Based-Models/","children":"[논문리뷰] Equilibrium Matching: Generative Modeling with Implicit Energy-Based Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Equilibrium Matching: Generative Modeling with Implicit Energy-Based Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Equilibrium Dynamics",{"className":"page__taxonomy-item","children":["#","Equilibrium Dynamics"]}],["$","span","Energy-Based Models (EBMs)",{"className":"page__taxonomy-item","children":["#","Energy-Based Models (EBMs)"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Optimization-Based Sampling",{"className":"page__taxonomy-item","children":["#","Optimization-Based Sampling"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}]]}]]}]]}],["$","article","2025-10-8-EgoNight-Towards-Egocentric-Vision-Understanding-at-Night-with-a-Challenging-Benchmark",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-EgoNight-Towards-Egocentric-Vision-Understanding-at-Night-with-a-Challenging-Benchmark/","children":"[논문리뷰] EgoNight: Towards Egocentric Vision Understanding at Night with a Challenging Benchmark"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Tianwen Qian이 [arXiv]에 게시한 'EgoNight: Towards Egocentric Vision Understanding at Night with a Challenging Benchmark' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Egocentric Vision",{"className":"page__taxonomy-item","children":["#","Egocentric Vision"]}],["$","span","Nighttime Conditions",{"className":"page__taxonomy-item","children":["#","Nighttime Conditions"]}],["$","span","Visual Question Answering (VQA)",{"className":"page__taxonomy-item","children":["#","Visual Question Answering (VQA)"]}],["$","span","Day-Night Alignment",{"className":"page__taxonomy-item","children":["#","Day-Night Alignment"]}],["$","span","Multimodal Large Language Models (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models (MLLMs)"]}],["$","span","Depth Estimation",{"className":"page__taxonomy-item","children":["#","Depth Estimation"]}],["$","span","Correspondence Retrieval",{"className":"page__taxonomy-item","children":["#","Correspondence Retrieval"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}]]}]]}]]}],["$","article","2025-10-8-Drax-Speech-Recognition-with-Discrete-Flow-Matching",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Drax-Speech-Recognition-with-Discrete-Flow-Matching/","children":"[논문리뷰] Drax: Speech Recognition with Discrete Flow Matching"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Drax: Speech Recognition with Discrete Flow Matching' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Automatic Speech Recognition (ASR)",{"className":"page__taxonomy-item","children":["#","Automatic Speech Recognition (ASR)"]}],["$","span","Discrete Flow Matching (DFM)",{"className":"page__taxonomy-item","children":["#","Discrete Flow Matching (DFM)"]}],["$","span","Non-Autoregressive (NAR)",{"className":"page__taxonomy-item","children":["#","Non-Autoregressive (NAR)"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Tri-mixture Probability Path",{"className":"page__taxonomy-item","children":["#","Tri-mixture Probability Path"]}],["$","span","Parallel Decoding",{"className":"page__taxonomy-item","children":["#","Parallel Decoding"]}],["$","span","Accuracy-Efficiency Trade-off",{"className":"page__taxonomy-item","children":["#","Accuracy-Efficiency Trade-off"]}],["$","span","Speech Synthesis",{"className":"page__taxonomy-item","children":["#","Speech Synthesis"]}]]}]]}]]}],["$","article","2025-10-8-Distributional-Semantics-Tracing-A-Framework-for-Explaining-Hallucinations-in-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Distributional-Semantics-Tracing-A-Framework-for-Explaining-Hallucinations-in-Large-Language-Models/","children":"[논문리뷰] Distributional Semantics Tracing: A Framework for Explaining Hallucinations in Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jacobo Azcona이 [arXiv]에 게시한 'Distributional Semantics Tracing: A Framework for Explaining Hallucinations in Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Hallucinations",{"className":"page__taxonomy-item","children":["#","LLM Hallucinations"]}],["$","span","Mechanistic Interpretability",{"className":"page__taxonomy-item","children":["#","Mechanistic Interpretability"]}],["$","span","Distributional Semantics Tracing (DST)",{"className":"page__taxonomy-item","children":["#","Distributional Semantics Tracing (DST)"]}],["$","span","Dual-Process Theory",{"className":"page__taxonomy-item","children":["#","Dual-Process Theory"]}],["$","span","Semantic Drift",{"className":"page__taxonomy-item","children":["#","Semantic Drift"]}],["$","span","Commitment Layer",{"className":"page__taxonomy-item","children":["#","Commitment Layer"]}],["$","span","Faithfulness Score",{"className":"page__taxonomy-item","children":["#","Faithfulness Score"]}]]}]]}]]}],["$","article","2025-10-8-Discrete-Diffusion-Models-with-MLLMs-for-Unified-Medical-Multimodal-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Discrete-Diffusion-Models-with-MLLMs-for-Unified-Medical-Multimodal-Generation/","children":"[논문리뷰] Discrete Diffusion Models with MLLMs for Unified Medical Multimodal Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Discrete Diffusion Models with MLLMs for Unified Medical Multimodal Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Discrete Diffusion Models",{"className":"page__taxonomy-item","children":["#","Discrete Diffusion Models"]}],["$","span","Multimodal Large Language Models (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models (MLLMs)"]}],["$","span","Medical Image Generation",{"className":"page__taxonomy-item","children":["#","Medical Image Generation"]}],["$","span","Medical Report Generation",{"className":"page__taxonomy-item","children":["#","Medical Report Generation"]}],["$","span","Multimodal Generation",{"className":"page__taxonomy-item","children":["#","Multimodal Generation"]}],["$","span","Medical AI",{"className":"page__taxonomy-item","children":["#","Medical AI"]}],["$","span","Cross-modal Alignment",{"className":"page__taxonomy-item","children":["#","Cross-modal Alignment"]}]]}]]}]]}],["$","article","2025-10-8-Demystifying-deep-search-a-holistic-evaluation-with-hint-free-multi-hop-questions-and-factorised-metrics",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Demystifying-deep-search-a-holistic-evaluation-with-hint-free-multi-hop-questions-and-factorised-metrics/","children":"[논문리뷰] Demystifying deep search: a holistic evaluation with hint-free multi-hop questions and factorised metrics"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Demystifying deep search: a holistic evaluation with hint-free multi-hop questions and factorised metrics' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Deep Search",{"className":"page__taxonomy-item","children":["#","Deep Search"]}],["$","span","Multi-hop Reasoning",{"className":"page__taxonomy-item","children":["#","Multi-hop Reasoning"]}],["$","span","Evaluation Benchmark",{"className":"page__taxonomy-item","children":["#","Evaluation Benchmark"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","Web Agents",{"className":"page__taxonomy-item","children":["#","Web Agents"]}],["$","span","Diagnostic Metrics",{"className":"page__taxonomy-item","children":["#","Diagnostic Metrics"]}],["$","span","Knowledge Utilization",{"className":"page__taxonomy-item","children":["#","Knowledge Utilization"]}],["$","span","Hint-Free Questions",{"className":"page__taxonomy-item","children":["#","Hint-Free Questions"]}]]}]]}]]}],["$","article","2025-10-8-Deforming-Videos-to-Masks-Flow-Matching-for-Referring-Video-Segmentation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Deforming-Videos-to-Masks-Flow-Matching-for-Referring-Video-Segmentation/","children":"[논문리뷰] Deforming Videos to Masks: Flow Matching for Referring Video Segmentation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chengzu Li이 [arXiv]에 게시한 'Deforming Videos to Masks: Flow Matching for Referring Video Segmentation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Referring Video Object Segmentation",{"className":"page__taxonomy-item","children":["#","Referring Video Object Segmentation"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Video Segmentation",{"className":"page__taxonomy-item","children":["#","Video Segmentation"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Text-to-Video",{"className":"page__taxonomy-item","children":["#","Text-to-Video"]}],["$","span","Continuous Flow",{"className":"page__taxonomy-item","children":["#","Continuous Flow"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}]]}]]}]]}],["$","article","2025-10-8-DRIFT-Learning-from-Abundant-User-Dissatisfaction-in-Real-World-Preference-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-DRIFT-Learning-from-Abundant-User-Dissatisfaction-in-Real-World-Preference-Learning/","children":"[논문리뷰] DRIFT: Learning from Abundant User Dissatisfaction in Real-World Preference Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zheli Liu이 [arXiv]에 게시한 'DRIFT: Learning from Abundant User Dissatisfaction in Real-World Preference Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Preference Learning",{"className":"page__taxonomy-item","children":["#","Preference Learning"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","User Feedback",{"className":"page__taxonomy-item","children":["#","User Feedback"]}],["$","span","Dissatisfaction Signals",{"className":"page__taxonomy-item","children":["#","Dissatisfaction Signals"]}],["$","span","DPO",{"className":"page__taxonomy-item","children":["#","DPO"]}],["$","span","Iterative Training",{"className":"page__taxonomy-item","children":["#","Iterative Training"]}],["$","span","RLHF",{"className":"page__taxonomy-item","children":["#","RLHF"]}],["$","span","Exploration",{"className":"page__taxonomy-item","children":["#","Exploration"]}]]}]]}]]}],["$","article","2025-10-8-CoDA-Coding-LM-via-Diffusion-Adaptation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-CoDA-Coding-LM-via-Diffusion-Adaptation/","children":"[논문리뷰] CoDA: Coding LM via Diffusion Adaptation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'CoDA: Coding LM via Diffusion Adaptation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Language Models",{"className":"page__taxonomy-item","children":["#","Diffusion Language Models"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","Bidirectional Decoding",{"className":"page__taxonomy-item","children":["#","Bidirectional Decoding"]}],["$","span","Text Infilling",{"className":"page__taxonomy-item","children":["#","Text Infilling"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}],["$","span","Lightweight Models",{"className":"page__taxonomy-item","children":["#","Lightweight Models"]}],["$","span","TPU Training",{"className":"page__taxonomy-item","children":["#","TPU Training"]}]]}]]}]]}],["$","article","2025-10-8-CCD-Mitigating-Hallucinations-in-Radiology-MLLMs-via-Clinical-Contrastive-Decoding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-CCD-Mitigating-Hallucinations-in-Radiology-MLLMs-via-Clinical-Contrastive-Decoding/","children":"[논문리뷰] CCD: Mitigating Hallucinations in Radiology MLLMs via Clinical Contrastive Decoding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'CCD: Mitigating Hallucinations in Radiology MLLMs via Clinical Contrastive Decoding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models (MLLMs)"]}],["$","span","Radiology Report Generation (RRG)",{"className":"page__taxonomy-item","children":["#","Radiology Report Generation (RRG)"]}],["$","span","Medical Hallucinations",{"className":"page__taxonomy-item","children":["#","Medical Hallucinations"]}],["$","span","Contrastive Decoding",{"className":"page__taxonomy-item","children":["#","Contrastive Decoding"]}],["$","span","Training-free Inference",{"className":"page__taxonomy-item","children":["#","Training-free Inference"]}],["$","span","Clinical AI",{"className":"page__taxonomy-item","children":["#","Clinical AI"]}],["$","span","Visual Question Answering (VQA)",{"className":"page__taxonomy-item","children":["#","Visual Question Answering (VQA)"]}]]}]]}]]}],["$","article","2025-10-8-CARE-Cognitive-reasoning-Augmented-Reinforcement-for-Emotional-Support-Conversation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-CARE-Cognitive-reasoning-Augmented-Reinforcement-for-Emotional-Support-Conversation/","children":"[논문리뷰] CARE: Cognitive-reasoning Augmented Reinforcement for Emotional Support Conversation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'CARE: Cognitive-reasoning Augmented Reinforcement for Emotional Support Conversation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Emotional Support Conversation",{"className":"page__taxonomy-item","children":["#","Emotional Support Conversation"]}],["$","span","Cognitive Reasoning",{"className":"page__taxonomy-item","children":["#","Cognitive Reasoning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Dialogue Generation",{"className":"page__taxonomy-item","children":["#","Dialogue Generation"]}],["$","span","Natural Language Processing",{"className":"page__taxonomy-item","children":["#","Natural Language Processing"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Psychological Support",{"className":"page__taxonomy-item","children":["#","Psychological Support"]}]]}]]}]]}],["$","article","2025-10-8-Benchmark-It-Yourself-BIY-Preparing-a-Dataset-and-Benchmarking-AI-Models-for-Scatterplot-Related-Tasks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Benchmark-It-Yourself-BIY-Preparing-a-Dataset-and-Benchmarking-AI-Models-for-Scatterplot-Related-Tasks/","children":"[논문리뷰] Benchmark It Yourself (BIY): Preparing a Dataset and Benchmarking AI Models for Scatterplot-Related Tasks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Pedro Bizarro이 [arXiv]에 게시한 'Benchmark It Yourself (BIY): Preparing a Dataset and Benchmarking AI Models for Scatterplot-Related Tasks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Scatterplot Analysis",{"className":"page__taxonomy-item","children":["#","Scatterplot Analysis"]}],["$","span","AI Benchmarking",{"className":"page__taxonomy-item","children":["#","AI Benchmarking"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Synthetic Data Generation",{"className":"page__taxonomy-item","children":["#","Synthetic Data Generation"]}],["$","span","Cluster Detection",{"className":"page__taxonomy-item","children":["#","Cluster Detection"]}],["$","span","Outlier Detection",{"className":"page__taxonomy-item","children":["#","Outlier Detection"]}],["$","span","Data Visualization",{"className":"page__taxonomy-item","children":["#","Data Visualization"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}]]}]]}]]}],["$","article","2025-10-8-BIRD-INTERACT-Re-imagining-Text-to-SQL-Evaluation-for-Large-Language-Models-via-Lens-of-Dynamic-Interactions",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-BIRD-INTERACT-Re-imagining-Text-to-SQL-Evaluation-for-Large-Language-Models-via-Lens-of-Dynamic-Interactions/","children":"[논문리뷰] BIRD-INTERACT: Re-imagining Text-to-SQL Evaluation for Large Language Models via Lens of Dynamic Interactions"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shipei Lin이 [arXiv]에 게시한 'BIRD-INTERACT: Re-imagining Text-to-SQL Evaluation for Large Language Models via Lens of Dynamic Interactions' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-SQL",{"className":"page__taxonomy-item","children":["#","Text-to-SQL"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Multi-turn Interaction",{"className":"page__taxonomy-item","children":["#","Multi-turn Interaction"]}],["$","span","Dynamic Environment",{"className":"page__taxonomy-item","children":["#","Dynamic Environment"]}],["$","span","User Simulator",{"className":"page__taxonomy-item","children":["#","User Simulator"]}],["$","span","Ambiguity Resolution",{"className":"page__taxonomy-item","children":["#","Ambiguity Resolution"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}]]}]]}]]}],["$","article","2025-10-8-ASPO-Asymmetric-Importance-Sampling-Policy-Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-ASPO-Asymmetric-Importance-Sampling-Policy-Optimization/","children":"[논문리뷰] ASPO: Asymmetric Importance Sampling Policy Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiu Li이 [arXiv]에 게시한 'ASPO: Asymmetric Importance Sampling Policy Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Importance Sampling",{"className":"page__taxonomy-item","children":["#","Importance Sampling"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","PPO-Clip",{"className":"page__taxonomy-item","children":["#","PPO-Clip"]}],["$","span","Outcome-Supervised RL",{"className":"page__taxonomy-item","children":["#","Outcome-Supervised RL"]}],["$","span","Token Weighting",{"className":"page__taxonomy-item","children":["#","Token Weighting"]}],["$","span","GRPO",{"className":"page__taxonomy-item","children":["#","GRPO"]}]]}]]}]]}],["$","article","2025-10-8-AInstein-Assessing-the-Feasibility-of-AI-Generated-Approaches-to-Research-Problems",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-AInstein-Assessing-the-Feasibility-of-AI-Generated-Approaches-to-Research-Problems/","children":"[논문리뷰] AInstein: Assessing the Feasibility of AI-Generated Approaches to Research Problems"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jose Dolz이 [arXiv]에 게시한 'AInstein: Assessing the Feasibility of AI-Generated Approaches to Research Problems' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Scientific Problem Solving",{"className":"page__taxonomy-item","children":["#","Scientific Problem Solving"]}],["$","span","AI Research",{"className":"page__taxonomy-item","children":["#","AI Research"]}],["$","span","Iterative Refinement",{"className":"page__taxonomy-item","children":["#","Iterative Refinement"]}],["$","span","Autonomous Agents",{"className":"page__taxonomy-item","children":["#","Autonomous Agents"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Evaluation Framework",{"className":"page__taxonomy-item","children":["#","Evaluation Framework"]}],["$","span","Problem Extraction",{"className":"page__taxonomy-item","children":["#","Problem Extraction"]}]]}]]}]]}],["$","article","2025-10-8-A-Contextual-Quality-Reward-Model-for-Reliable-and-Efficient-Best-of-N-Sampling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-A-Contextual-Quality-Reward-Model-for-Reliable-and-Efficient-Best-of-N-Sampling/","children":"[논문리뷰] A Contextual Quality Reward Model for Reliable and Efficient Best-of-N Sampling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"sirano1004이 [arXiv]에 게시한 'A Contextual Quality Reward Model for Reliable and Efficient Best-of-N Sampling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reward Model",{"className":"page__taxonomy-item","children":["#","Reward Model"]}],["$","span","Best-of-N Sampling",{"className":"page__taxonomy-item","children":["#","Best-of-N Sampling"]}],["$","span","Preference Alignment",{"className":"page__taxonomy-item","children":["#","Preference Alignment"]}],["$","span","Contextual Acceptability",{"className":"page__taxonomy-item","children":["#","Contextual Acceptability"]}],["$","span","Discrete Choice Model",{"className":"page__taxonomy-item","children":["#","Discrete Choice Model"]}],["$","span","Alignment Guardrail",{"className":"page__taxonomy-item","children":["#","Alignment Guardrail"]}],["$","span","Inference Accelerator",{"className":"page__taxonomy-item","children":["#","Inference Accelerator"]}]]}]]}]]}],["$","article","2025-10-7-Watch-and-Learn-Learning-to-Use-Computers-from-Online-Videos",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Watch-and-Learn-Learning-to-Use-Computers-from-Online-Videos/","children":"[논문리뷰] Watch and Learn: Learning to Use Computers from Online Videos"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Oriana Riva이 [arXiv]에 게시한 'Watch and Learn: Learning to Use Computers from Online Videos' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Computer Use Agents",{"className":"page__taxonomy-item","children":["#","Computer Use Agents"]}],["$","span","Inverse Dynamics Model",{"className":"page__taxonomy-item","children":["#","Inverse Dynamics Model"]}],["$","span","UI Trajectories",{"className":"page__taxonomy-item","children":["#","UI Trajectories"]}],["$","span","Web Videos",{"className":"page__taxonomy-item","children":["#","Web Videos"]}],["$","span","In-Context Learning",{"className":"page__taxonomy-item","children":["#","In-Context Learning"]}],["$","span","Supervised Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","OSWorld Benchmark",{"className":"page__taxonomy-item","children":["#","OSWorld Benchmark"]}]]}]]}]]}],["$","article","2025-10-7-Video-LMM-Post-Training-A-Deep-Dive-into-Video-Reasoning-with-Large-Multimodal-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Video-LMM-Post-Training-A-Deep-Dive-into-Video-Reasoning-with-Large-Multimodal-Models/","children":"[논문리뷰] Video-LMM Post-Training: A Deep Dive into Video Reasoning with Large Multimodal Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"zeliang0426이 [arXiv]에 게시한 'Video-LMM Post-Training: A Deep Dive into Video Reasoning with Large Multimodal Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Reasoning",{"className":"page__taxonomy-item","children":["#","Video Reasoning"]}],["$","span","Large Multimodal Models (LMMs)",{"className":"page__taxonomy-item","children":["#","Large Multimodal Models (LMMs)"]}],["$","span","Post-training",{"className":"page__taxonomy-item","children":["#","Post-training"]}],["$","span","Supervised Fine-tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning (SFT)"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Test-Time Scaling (TTS)",{"className":"page__taxonomy-item","children":["#","Test-Time Scaling (TTS)"]}],["$","span","Chain-of-Thought (CoT)",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought (CoT)"]}]]}]]}]]}],["$","article","2025-10-7-VChain-Chain-of-Visual-Thought-for-Reasoning-in-Video-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-VChain-Chain-of-Visual-Thought-for-Reasoning-in-Video-Generation/","children":"[논문리뷰] VChain: Chain-of-Visual-Thought for Reasoning in Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Paul Debevec이 [arXiv]에 게시한 'VChain: Chain-of-Visual-Thought for Reasoning in Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Multimodal Models",{"className":"page__taxonomy-item","children":["#","Multimodal Models"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Inference-Time Tuning",{"className":"page__taxonomy-item","children":["#","Inference-Time Tuning"]}],["$","span","Sparse Supervision",{"className":"page__taxonomy-item","children":["#","Sparse Supervision"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Keyframe Generation",{"className":"page__taxonomy-item","children":["#","Keyframe Generation"]}]]}]]}]]}],["$","article","2025-10-7-Utility-Learning-Tension-in-Self-Modifying-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Utility-Learning-Tension-in-Self-Modifying-Agents/","children":"[논문리뷰] Utility-Learning Tension in Self-Modifying Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Peter Jin이 [arXiv]에 게시한 'Utility-Learning Tension in Self-Modifying Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Self-Modifying Agents",{"className":"page__taxonomy-item","children":["#","Self-Modifying Agents"]}],["$","span","PAC Learnability",{"className":"page__taxonomy-item","children":["#","PAC Learnability"]}],["$","span","VC Dimension",{"className":"page__taxonomy-item","children":["#","VC Dimension"]}],["$","span","Capacity Bounds",{"className":"page__taxonomy-item","children":["#","Capacity Bounds"]}],["$","span","Metacognition",{"className":"page__taxonomy-item","children":["#","Metacognition"]}],["$","span","Architectural Search",{"className":"page__taxonomy-item","children":["#","Architectural Search"]}],["$","span","Algorithmic Stability",{"className":"page__taxonomy-item","children":["#","Algorithmic Stability"]}],["$","span","Generalization Theory",{"className":"page__taxonomy-item","children":["#","Generalization Theory"]}]]}]]}]]}],["$","article","2025-10-7-Thai-Semantic-End-of-Turn-Detection-for-Real-Time-Voice-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Thai-Semantic-End-of-Turn-Detection-for-Real-Time-Voice-Agents/","children":"[논문리뷰] Thai Semantic End-of-Turn Detection for Real-Time Voice Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Monthol Charattrakool이 [arXiv]에 게시한 'Thai Semantic End-of-Turn Detection for Real-Time Voice Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","End-of-Turn Detection",{"className":"page__taxonomy-item","children":["#","End-of-Turn Detection"]}],["$","span","Thai NLP",{"className":"page__taxonomy-item","children":["#","Thai NLP"]}],["$","span","Voice Agents",{"className":"page__taxonomy-item","children":["#","Voice Agents"]}],["$","span","Real-time Inference",{"className":"page__taxonomy-item","children":["#","Real-time Inference"]}],["$","span","Transformer Models",{"className":"page__taxonomy-item","children":["#","Transformer Models"]}],["$","span","Few-shot Learning",{"className":"page__taxonomy-item","children":["#","Few-shot Learning"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Latency Optimization",{"className":"page__taxonomy-item","children":["#","Latency Optimization"]}]]}]]}]]}],["$","article","2025-10-7-SwiReasoning-Switch-Thinking-in-Latent-and-Explicit-for-Pareto-Superior-Reasoning-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-SwiReasoning-Switch-Thinking-in-Latent-and-Explicit-for-Pareto-Superior-Reasoning-LLMs/","children":"[논문리뷰] SwiReasoning: Switch-Thinking in Latent and Explicit for Pareto-Superior Reasoning LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'SwiReasoning: Switch-Thinking in Latent and Explicit for Pareto-Superior Reasoning LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Reasoning",{"className":"page__taxonomy-item","children":["#","LLM Reasoning"]}],["$","span","Latent Thinking",{"className":"page__taxonomy-item","children":["#","Latent Thinking"]}],["$","span","Explicit Thinking",{"className":"page__taxonomy-item","children":["#","Explicit Thinking"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}],["$","span","Token Efficiency",{"className":"page__taxonomy-item","children":["#","Token Efficiency"]}],["$","span","Accuracy Improvement",{"className":"page__taxonomy-item","children":["#","Accuracy Improvement"]}],["$","span","Dynamic Switching",{"className":"page__taxonomy-item","children":["#","Dynamic Switching"]}],["$","span","Entropy-based Control",{"className":"page__taxonomy-item","children":["#","Entropy-based Control"]}]]}]]}]]}],["$","article","2025-10-7-Self-Reflective-Generation-at-Test-Time",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Self-Reflective-Generation-at-Test-Time/","children":"[논문리뷰] Self-Reflective Generation at Test Time"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shuang Qiu이 [arXiv]에 게시한 'Self-Reflective Generation at Test Time' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Self-Reflection",{"className":"page__taxonomy-item","children":["#","Self-Reflection"]}],["$","span","Test-Time Optimization",{"className":"page__taxonomy-item","children":["#","Test-Time Optimization"]}],["$","span","Uncertainty Monitoring",{"className":"page__taxonomy-item","children":["#","Uncertainty Monitoring"]}],["$","span","Proactive Error Prevention",{"className":"page__taxonomy-item","children":["#","Proactive Error Prevention"]}],["$","span","Reasoning Tasks",{"className":"page__taxonomy-item","children":["#","Reasoning Tasks"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}]]}]]}]]}],["$","article","2025-10-7-SAEdit-Token-level-control-for-continuous-image-editing-via-Sparse-AutoEncoder",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-SAEdit-Token-level-control-for-continuous-image-editing-via-Sparse-AutoEncoder/","children":"[논문리뷰] SAEdit: Token-level control for continuous image editing via Sparse AutoEncoder"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Or Patashnik이 [arXiv]에 게시한 'SAEdit: Token-level control for continuous image editing via Sparse AutoEncoder' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Sparse Autoencoder (SAE)",{"className":"page__taxonomy-item","children":["#","Sparse Autoencoder (SAE)"]}],["$","span","Text-to-Image",{"className":"page__taxonomy-item","children":["#","Text-to-Image"]}],["$","span","Disentangled Control",{"className":"page__taxonomy-item","children":["#","Disentangled Control"]}],["$","span","Continuous Control",{"className":"page__taxonomy-item","children":["#","Continuous Control"]}],["$","span","Token-level Manipulation",{"className":"page__taxonomy-item","children":["#","Token-level Manipulation"]}],["$","span","Text Embeddings",{"className":"page__taxonomy-item","children":["#","Text Embeddings"]}]]}]]}]]}],["$","article","2025-10-7-Reinforce-Ada-An-Adaptive-Sampling-Framework-for-Reinforce-Style-LLM-Training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Reinforce-Ada-An-Adaptive-Sampling-Framework-for-Reinforce-Style-LLM-Training/","children":"[논문리뷰] Reinforce-Ada: An Adaptive Sampling Framework for Reinforce-Style LLM Training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Reinforce-Ada: An Adaptive Sampling Framework for Reinforce-Style LLM Training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Adaptive Sampling",{"className":"page__taxonomy-item","children":["#","Adaptive Sampling"]}],["$","span","Policy Gradient",{"className":"page__taxonomy-item","children":["#","Policy Gradient"]}],["$","span","Reward Optimization",{"className":"page__taxonomy-item","children":["#","Reward Optimization"]}],["$","span","Signal Collapse",{"className":"page__taxonomy-item","children":["#","Signal Collapse"]}],["$","span","Variance Reduction",{"className":"page__taxonomy-item","children":["#","Variance Reduction"]}]]}]]}]]}],["$","article","2025-10-7-Reactive-Transformer-RxT-Stateful-Real-Time-Processing-for-Event-Driven-Reactive-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Reactive-Transformer-RxT-Stateful-Real-Time-Processing-for-Event-Driven-Reactive-Language-Models/","children":"[논문리뷰] Reactive Transformer (RxT) -- Stateful Real-Time Processing for Event-Driven Reactive Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Reactive Transformer (RxT) -- Stateful Real-Time Processing for Event-Driven Reactive Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reactive Transformer",{"className":"page__taxonomy-item","children":["#","Reactive Transformer"]}],["$","span","Stateful LLM",{"className":"page__taxonomy-item","children":["#","Stateful LLM"]}],["$","span","Event-Driven AI",{"className":"page__taxonomy-item","children":["#","Event-Driven AI"]}],["$","span","Asynchronous Memory",{"className":"page__taxonomy-item","children":["#","Asynchronous Memory"]}],["$","span","Conversational AI",{"className":"page__taxonomy-item","children":["#","Conversational AI"]}],["$","span","Linear Scaling",{"className":"page__taxonomy-item","children":["#","Linear Scaling"]}],["$","span","Short-Term Memory (STM)",{"className":"page__taxonomy-item","children":["#","Short-Term Memory (STM)"]}],["$","span","Memory Attention",{"className":"page__taxonomy-item","children":["#","Memory Attention"]}]]}]]}]]}],["$","article","2025-10-7-Optimal-Scaling-Needs-Optimal-Norm",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Optimal-Scaling-Needs-Optimal-Norm/","children":"[논문리뷰] Optimal Scaling Needs Optimal Norm"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Stefan Kesselheim이 [arXiv]에 게시한 'Optimal Scaling Needs Optimal Norm' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Optimal Scaling",{"className":"page__taxonomy-item","children":["#","Optimal Scaling"]}],["$","span","Norm-Based Optimizers",{"className":"page__taxonomy-item","children":["#","Norm-Based Optimizers"]}],["$","span","Hyperparameter Transfer",{"className":"page__taxonomy-item","children":["#","Hyperparameter Transfer"]}],["$","span","Learning Rate Scaling",{"className":"page__taxonomy-item","children":["#","Learning Rate Scaling"]}],["$","span","Batch Size Scaling",{"className":"page__taxonomy-item","children":["#","Batch Size Scaling"]}],["$","span","Transformer Models",{"className":"page__taxonomy-item","children":["#","Transformer Models"]}],["$","span","Scion Optimizer",{"className":"page__taxonomy-item","children":["#","Scion Optimizer"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}]]}]]}]]}],["$","article","2025-10-7-MoME-Mixture-of-Matryoshka-Experts-for-Audio-Visual-Speech-Recognition",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-MoME-Mixture-of-Matryoshka-Experts-for-Audio-Visual-Speech-Recognition/","children":"[논문리뷰] MoME: Mixture of Matryoshka Experts for Audio-Visual Speech Recognition"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'MoME: Mixture of Matryoshka Experts for Audio-Visual Speech Recognition' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Audio-Visual Speech Recognition",{"className":"page__taxonomy-item","children":["#","Audio-Visual Speech Recognition"]}],["$","span","Mixture of Experts",{"className":"page__taxonomy-item","children":["#","Mixture of Experts"]}],["$","span","Matryoshka Representation Learning",{"className":"page__taxonomy-item","children":["#","Matryoshka Representation Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Elastic Inference",{"className":"page__taxonomy-item","children":["#","Elastic Inference"]}],["$","span","Token Compression",{"className":"page__taxonomy-item","children":["#","Token Compression"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}]]}]]}]]}],["$","article","2025-10-7-MITS-Enhanced-Tree-Search-Reasoning-for-LLMs-via-Pointwise-Mutual-Information",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-MITS-Enhanced-Tree-Search-Reasoning-for-LLMs-via-Pointwise-Mutual-Information/","children":"[논문리뷰] MITS: Enhanced Tree Search Reasoning for LLMs via Pointwise Mutual Information"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'MITS: Enhanced Tree Search Reasoning for LLMs via Pointwise Mutual Information' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Reasoning",{"className":"page__taxonomy-item","children":["#","LLM Reasoning"]}],["$","span","Tree Search",{"className":"page__taxonomy-item","children":["#","Tree Search"]}],["$","span","Pointwise Mutual Information (PMI)",{"className":"page__taxonomy-item","children":["#","Pointwise Mutual Information (PMI)"]}],["$","span","Dynamic Sampling",{"className":"page__taxonomy-item","children":["#","Dynamic Sampling"]}],["$","span","Beam Search",{"className":"page__taxonomy-item","children":["#","Beam Search"]}],["$","span","Weighted Voting",{"className":"page__taxonomy-item","children":["#","Weighted Voting"]}],["$","span","Information Theory",{"className":"page__taxonomy-item","children":["#","Information Theory"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}]]}]]}]]}],["$","article","2025-10-7-Learning-on-the-Job-Test-Time-Curricula-for-Targeted-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Learning-on-the-Job-Test-Time-Curricula-for-Targeted-Reinforcement-Learning/","children":"[논문리뷰] Learning on the Job: Test-Time Curricula for Targeted Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Learning on the Job: Test-Time Curricula for Targeted Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Test-Time Curriculum",{"className":"page__taxonomy-item","children":["#","Test-Time Curriculum"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Self-Curated Learning",{"className":"page__taxonomy-item","children":["#","Self-Curated Learning"]}],["$","span","Continual Learning",{"className":"page__taxonomy-item","children":["#","Continual Learning"]}],["$","span","Reasoning Benchmarks",{"className":"page__taxonomy-item","children":["#","Reasoning Benchmarks"]}],["$","span","Adaptive Training",{"className":"page__taxonomy-item","children":["#","Adaptive Training"]}]]}]]}]]}],["$","article","2025-10-7-LLMSQL-Upgrading-WikiSQL-for-the-LLM-Era-of-Text-to-SQL",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-LLMSQL-Upgrading-WikiSQL-for-the-LLM-Era-of-Text-to-SQL/","children":"[논문리뷰] LLMSQL: Upgrading WikiSQL for the LLM Era of Text-to-SQL"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'LLMSQL: Upgrading WikiSQL for the LLM Era of Text-to-SQL' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-SQL",{"className":"page__taxonomy-item","children":["#","Text-to-SQL"]}],["$","span","WikiSQL",{"className":"page__taxonomy-item","children":["#","WikiSQL"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Dataset Curation",{"className":"page__taxonomy-item","children":["#","Dataset Curation"]}],["$","span","Natural Language Processing",{"className":"page__taxonomy-item","children":["#","Natural Language Processing"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","SQL Generation",{"className":"page__taxonomy-item","children":["#","SQL Generation"]}],["$","span","Data Cleaning",{"className":"page__taxonomy-item","children":["#","Data Cleaning"]}]]}]]}]]}],["$","article","2025-10-7-Judging-with-Confidence-Calibrating-Autoraters-to-Preference-Distributions",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Judging-with-Confidence-Calibrating-Autoraters-to-Preference-Distributions/","children":"[논문리뷰] Judging with Confidence: Calibrating Autoraters to Preference Distributions"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Judging with Confidence: Calibrating Autoraters to Preference Distributions' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Autoraters",{"className":"page__taxonomy-item","children":["#","Autoraters"]}],["$","span","Calibration",{"className":"page__taxonomy-item","children":["#","Calibration"]}],["$","span","Preference Distributions",{"className":"page__taxonomy-item","children":["#","Preference Distributions"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Positional Bias",{"className":"page__taxonomy-item","children":["#","Positional Bias"]}]]}]]}]]}],["$","article","2025-10-7-Imperceptible-Jailbreaking-against-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Imperceptible-Jailbreaking-against-Large-Language-Models/","children":"[논문리뷰] Imperceptible Jailbreaking against Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Imperceptible Jailbreaking against Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Jailbreaking",{"className":"page__taxonomy-item","children":["#","Jailbreaking"]}],["$","span","Imperceptible Attacks",{"className":"page__taxonomy-item","children":["#","Imperceptible Attacks"]}],["$","span","Unicode Variation Selectors",{"className":"page__taxonomy-item","children":["#","Unicode Variation Selectors"]}],["$","span","Adversarial Suffixes",{"className":"page__taxonomy-item","children":["#","Adversarial Suffixes"]}],["$","span","Safety Alignment",{"className":"page__taxonomy-item","children":["#","Safety Alignment"]}],["$","span","Prompt Injection",{"className":"page__taxonomy-item","children":["#","Prompt Injection"]}]]}]]}]]}],["$","article","2025-10-7-Hybrid-Architectures-for-Language-Models-Systematic-Analysis-and-Design-Insights",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Hybrid-Architectures-for-Language-Models-Systematic-Analysis-and-Design-Insights/","children":"[논문리뷰] Hybrid Architectures for Language Models: Systematic Analysis and Design Insights"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Hybrid Architectures for Language Models: Systematic Analysis and Design Insights' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Hybrid LLM",{"className":"page__taxonomy-item","children":["#","Hybrid LLM"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Mamba",{"className":"page__taxonomy-item","children":["#","Mamba"]}],["$","span","State Space Models (SSM)",{"className":"page__taxonomy-item","children":["#","State Space Models (SSM)"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}],["$","span","Long-Context",{"className":"page__taxonomy-item","children":["#","Long-Context"]}],["$","span","Language Model Architectures",{"className":"page__taxonomy-item","children":["#","Language Model Architectures"]}],["$","span","Scaling Laws",{"className":"page__taxonomy-item","children":["#","Scaling Laws"]}]]}]]}]]}],["$","article","2025-10-7-HiKE-Hierarchical-Evaluation-Framework-for-Korean-English-Code-Switching-Speech-Recognition",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-HiKE-Hierarchical-Evaluation-Framework-for-Korean-English-Code-Switching-Speech-Recognition/","children":"[논문리뷰] HiKE: Hierarchical Evaluation Framework for Korean-English Code-Switching Speech Recognition"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'HiKE: Hierarchical Evaluation Framework for Korean-English Code-Switching Speech Recognition' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Code-Switching",{"className":"page__taxonomy-item","children":["#","Code-Switching"]}],["$","span","Speech Recognition",{"className":"page__taxonomy-item","children":["#","Speech Recognition"]}],["$","span","Korean-English ASR",{"className":"page__taxonomy-item","children":["#","Korean-English ASR"]}],["$","span","Evaluation Framework",{"className":"page__taxonomy-item","children":["#","Evaluation Framework"]}],["$","span","Multilingual ASR",{"className":"page__taxonomy-item","children":["#","Multilingual ASR"]}],["$","span","Loanword Processing",{"className":"page__taxonomy-item","children":["#","Loanword Processing"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Hierarchical Labeling",{"className":"page__taxonomy-item","children":["#","Hierarchical Labeling"]}]]}]]}]]}],["$","article","2025-10-7-Graph2Eval-Automatic-Multimodal-Task-Generation-for-Agents-via-Knowledge-Graphs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Graph2Eval-Automatic-Multimodal-Task-Generation-for-Agents-via-Knowledge-Graphs/","children":"[논문리뷰] Graph2Eval: Automatic Multimodal Task Generation for Agents via Knowledge Graphs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zeyi Liao이 [arXiv]에 게시한 'Graph2Eval: Automatic Multimodal Task Generation for Agents via Knowledge Graphs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agent Evaluation",{"className":"page__taxonomy-item","children":["#","Agent Evaluation"]}],["$","span","Task Generation",{"className":"page__taxonomy-item","children":["#","Task Generation"]}],["$","span","Knowledge Graphs",{"className":"page__taxonomy-item","children":["#","Knowledge Graphs"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Web Interaction",{"className":"page__taxonomy-item","children":["#","Web Interaction"]}],["$","span","Document Comprehension",{"className":"page__taxonomy-item","children":["#","Document Comprehension"]}],["$","span","LLM-driven Agents",{"className":"page__taxonomy-item","children":["#","LLM-driven Agents"]}]]}]]}]]}],["$","article","2025-10-7-Good-Intentions-Beyond-ACL-Who-Does-NLP-for-Social-Good-and-Where",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Good-Intentions-Beyond-ACL-Who-Does-NLP-for-Social-Good-and-Where/","children":"[논문리뷰] Good Intentions Beyond ACL: Who Does NLP for Social Good, and Where?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Denis Peskoff이 [arXiv]에 게시한 'Good Intentions Beyond ACL: Who Does NLP for Social Good, and Where?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","NLP for Social Good",{"className":"page__taxonomy-item","children":["#","NLP for Social Good"]}],["$","span","ACL Community",{"className":"page__taxonomy-item","children":["#","ACL Community"]}],["$","span","Scientometrics",{"className":"page__taxonomy-item","children":["#","Scientometrics"]}],["$","span","Venue Analysis",{"className":"page__taxonomy-item","children":["#","Venue Analysis"]}],["$","span","Author Classification",{"className":"page__taxonomy-item","children":["#","Author Classification"]}],["$","span","Sustainable Development Goals",{"className":"page__taxonomy-item","children":["#","Sustainable Development Goals"]}],["$","span","Neural Methods",{"className":"page__taxonomy-item","children":["#","Neural Methods"]}],["$","span","Research Landscape",{"className":"page__taxonomy-item","children":["#","Research Landscape"]}]]}]]}]]}],["$","article","2025-10-7-Front-Loading-Reasoning-The-Synergy-between-Pretraining-and-Post-Training-Data",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Front-Loading-Reasoning-The-Synergy-between-Pretraining-and-Post-Training-Data/","children":"[논문리뷰] Front-Loading Reasoning: The Synergy between Pretraining and Post-Training Data"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Front-Loading Reasoning: The Synergy between Pretraining and Post-Training Data' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Pretraining",{"className":"page__taxonomy-item","children":["#","Pretraining"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Reasoning Data",{"className":"page__taxonomy-item","children":["#","Reasoning Data"]}],["$","span","Data Allocation",{"className":"page__taxonomy-item","children":["#","Data Allocation"]}],["$","span","Diversity",{"className":"page__taxonomy-item","children":["#","Diversity"]}],["$","span","Quality",{"className":"page__taxonomy-item","children":["#","Quality"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}]]}]]}]]}],["$","article","2025-10-7-Factuality-Matters-When-Image-Generation-and-Editing-Meet-Structured-Visuals",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Factuality-Matters-When-Image-Generation-and-Editing-Meet-Structured-Visuals/","children":"[논문리뷰] Factuality Matters: When Image Generation and Editing Meet Structured Visuals"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Boxiang Qiu이 [arXiv]에 게시한 'Factuality Matters: When Image Generation and Editing Meet Structured Visuals' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Structured Visuals",{"className":"page__taxonomy-item","children":["#","Structured Visuals"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","span","Factual Fidelity",{"className":"page__taxonomy-item","children":["#","Factual Fidelity"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Evaluation Benchmark",{"className":"page__taxonomy-item","children":["#","Evaluation Benchmark"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}]]}]]}]]}],["$","article","2025-10-7-EvolProver-Advancing-Automated-Theorem-Proving-by-Evolving-Formalized-Problems-via-Symmetry-and-Difficulty",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-EvolProver-Advancing-Automated-Theorem-Proving-by-Evolving-Formalized-Problems-via-Symmetry-and-Difficulty/","children":"[논문리뷰] EvolProver: Advancing Automated Theorem Proving by Evolving Formalized Problems via Symmetry and Difficulty"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xuanwu Wang이 [arXiv]에 게시한 'EvolProver: Advancing Automated Theorem Proving by Evolving Formalized Problems via Symmetry and Difficulty' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Automated Theorem Proving",{"className":"page__taxonomy-item","children":["#","Automated Theorem Proving"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Formal Mathematics",{"className":"page__taxonomy-item","children":["#","Formal Mathematics"]}],["$","span","Symmetry",{"className":"page__taxonomy-item","children":["#","Symmetry"]}],["$","span","Difficulty Evolution",{"className":"page__taxonomy-item","children":["#","Difficulty Evolution"]}],["$","span","Abstract Syntax Tree",{"className":"page__taxonomy-item","children":["#","Abstract Syntax Tree"]}],["$","span","Generalizability",{"className":"page__taxonomy-item","children":["#","Generalizability"]}]]}]]}]]}],["$","article","2025-10-7-Epistemic-Diversity-and-Knowledge-Collapse-in-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Epistemic-Diversity-and-Knowledge-Collapse-in-Large-Language-Models/","children":"[논문리뷰] Epistemic Diversity and Knowledge Collapse in Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Epistemic Diversity and Knowledge Collapse in Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Epistemic Diversity",{"className":"page__taxonomy-item","children":["#","Epistemic Diversity"]}],["$","span","Knowledge Collapse",{"className":"page__taxonomy-item","children":["#","Knowledge Collapse"]}],["$","span","Homogenization",{"className":"page__taxonomy-item","children":["#","Homogenization"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Information Diversity",{"className":"page__taxonomy-item","children":["#","Information Diversity"]}],["$","span","Cultural Bias",{"className":"page__taxonomy-item","children":["#","Cultural Bias"]}]]}]]}]]}],["$","article","2025-10-7-Code4MeV2-a-Research-oriented-Code-completion-Platform",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Code4MeV2-a-Research-oriented-Code-completion-Platform/","children":"[논문리뷰] Code4MeV2: a Research-oriented Code-completion Platform"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Code4MeV2: a Research-oriented Code-completion Platform' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Code Completion",{"className":"page__taxonomy-item","children":["#","Code Completion"]}],["$","span","Research Platform",{"className":"page__taxonomy-item","children":["#","Research Platform"]}],["$","span","Human-AI Interaction",{"className":"page__taxonomy-item","children":["#","Human-AI Interaction"]}],["$","span","Software Engineering",{"className":"page__taxonomy-item","children":["#","Software Engineering"]}],["$","span","Open Science",{"className":"page__taxonomy-item","children":["#","Open Science"]}],["$","span","JetBrains IDE Plugin",{"className":"page__taxonomy-item","children":["#","JetBrains IDE Plugin"]}],["$","span","Telemetry",{"className":"page__taxonomy-item","children":["#","Telemetry"]}],["$","span","AI4SE",{"className":"page__taxonomy-item","children":["#","AI4SE"]}]]}]]}]]}],["$","article","2025-10-7-ChronoEdit-Towards-Temporal-Reasoning-for-Image-Editing-and-World-Simulation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-ChronoEdit-Towards-Temporal-Reasoning-for-Image-Editing-and-World-Simulation/","children":"[논문리뷰] ChronoEdit: Towards Temporal Reasoning for Image Editing and World Simulation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'ChronoEdit: Towards Temporal Reasoning for Image Editing and World Simulation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Temporal Reasoning",{"className":"page__taxonomy-item","children":["#","Temporal Reasoning"]}],["$","span","World Simulation",{"className":"page__taxonomy-item","children":["#","World Simulation"]}],["$","span","Physical Consistency",{"className":"page__taxonomy-item","children":["#","Physical Consistency"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}]]}]]}]]}],["$","article","2025-10-7-Character-Mixing-for-Video-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Character-Mixing-for-Video-Generation/","children":"[논문리뷰] Character Mixing for Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Character Mixing for Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Character Mixing",{"className":"page__taxonomy-item","children":["#","Character Mixing"]}],["$","span","Style Preservation",{"className":"page__taxonomy-item","children":["#","Style Preservation"]}],["$","span","Multi-character Interaction",{"className":"page__taxonomy-item","children":["#","Multi-character Interaction"]}],["$","span","Text-to-Video",{"className":"page__taxonomy-item","children":["#","Text-to-Video"]}],["$","span","Cross-Domain Synthesis",{"className":"page__taxonomy-item","children":["#","Cross-Domain Synthesis"]}],["$","span","Identity Preservation",{"className":"page__taxonomy-item","children":["#","Identity Preservation"]}]]}]]}]]}],["$","article","2025-10-7-Alignment-Tipping-Process-How-Self-Evolution-Pushes-LLM-Agents-Off-the-Rails",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Alignment-Tipping-Process-How-Self-Evolution-Pushes-LLM-Agents-Off-the-Rails/","children":"[논문리뷰] Alignment Tipping Process: How Self-Evolution Pushes LLM Agents Off the Rails"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xinyuan Liu이 [arXiv]에 게시한 'Alignment Tipping Process: How Self-Evolution Pushes LLM Agents Off the Rails' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Alignment",{"className":"page__taxonomy-item","children":["#","Alignment"]}],["$","span","Self-Evolution",{"className":"page__taxonomy-item","children":["#","Self-Evolution"]}],["$","span","Behavioral Drift",{"className":"page__taxonomy-item","children":["#","Behavioral Drift"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Alignment Tipping Process",{"className":"page__taxonomy-item","children":["#","Alignment Tipping Process"]}]]}]]}]]}],["$","article","2025-10-7-Agentic-Context-Engineering-Evolving-Contexts-for-Self-Improving-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Agentic-Context-Engineering-Evolving-Contexts-for-Self-Improving-Language-Models/","children":"[논문리뷰] Agentic Context Engineering: Evolving Contexts for Self-Improving Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Fenglu Hong이 [arXiv]에 게시한 'Agentic Context Engineering: Evolving Contexts for Self-Improving Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Context Adaptation",{"className":"page__taxonomy-item","children":["#","LLM Context Adaptation"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Self-Improving Systems",{"className":"page__taxonomy-item","children":["#","Self-Improving Systems"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","Context Management",{"className":"page__taxonomy-item","children":["#","Context Management"]}],["$","span","Dynamic Playbooks",{"className":"page__taxonomy-item","children":["#","Dynamic Playbooks"]}],["$","span","Incremental Learning",{"className":"page__taxonomy-item","children":["#","Incremental Learning"]}]]}]]}]]}],["$","article","2025-10-7-AdvEvo-MARL-Shaping-Internalized-Safety-through-Adversarial-Co-Evolution-in-Multi-Agent-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-AdvEvo-MARL-Shaping-Internalized-Safety-through-Adversarial-Co-Evolution-in-Multi-Agent-Reinforcement-Learning/","children":"[논문리뷰] AdvEvo-MARL: Shaping Internalized Safety through Adversarial Co-Evolution in Multi-Agent Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zeliang Zhang이 [arXiv]에 게시한 'AdvEvo-MARL: Shaping Internalized Safety through Adversarial Co-Evolution in Multi-Agent Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-Agent Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Multi-Agent Reinforcement Learning"]}],["$","span","Adversarial Co-evolution",{"className":"page__taxonomy-item","children":["#","Adversarial Co-evolution"]}],["$","span","LLM Safety",{"className":"page__taxonomy-item","children":["#","LLM Safety"]}],["$","span","Jailbreak Attacks",{"className":"page__taxonomy-item","children":["#","Jailbreak Attacks"]}],["$","span","Internalized Safety",{"className":"page__taxonomy-item","children":["#","Internalized Safety"]}],["$","span","Public Baseline",{"className":"page__taxonomy-item","children":["#","Public Baseline"]}],["$","span","System Robustness",{"className":"page__taxonomy-item","children":["#","System Robustness"]}]]}]]}]]}],["$","article","2025-10-6-Your-Agent-May-Misevolve-Emergent-Risks-in-Self-evolving-LLM-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-Your-Agent-May-Misevolve-Emergent-Risks-in-Self-evolving-LLM-Agents/","children":"[논문리뷰] Your Agent May Misevolve: Emergent Risks in Self-evolving LLM Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Boyi Wei이 [arXiv]에 게시한 'Your Agent May Misevolve: Emergent Risks in Self-evolving LLM Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Self-evolving Agents",{"className":"page__taxonomy-item","children":["#","Self-evolving Agents"]}],["$","span","LLM Safety",{"className":"page__taxonomy-item","children":["#","LLM Safety"]}],["$","span","Misevolution",{"className":"page__taxonomy-item","children":["#","Misevolution"]}],["$","span","Emergent Risks",{"className":"page__taxonomy-item","children":["#","Emergent Risks"]}],["$","span","Model Evolution",{"className":"page__taxonomy-item","children":["#","Model Evolution"]}],["$","span","Memory Evolution",{"className":"page__taxonomy-item","children":["#","Memory Evolution"]}],["$","span","Tool Evolution",{"className":"page__taxonomy-item","children":["#","Tool Evolution"]}],["$","span","Workflow Evolution",{"className":"page__taxonomy-item","children":["#","Workflow Evolution"]}]]}]]}]]}],["$","article","2025-10-6-WAInjectBench-Benchmarking-Prompt-Injection-Detections-for-Web-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-WAInjectBench-Benchmarking-Prompt-Injection-Detections-for-Web-Agents/","children":"[논문리뷰] WAInjectBench: Benchmarking Prompt Injection Detections for Web Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Neil Zhenqiang Gong이 [arXiv]에 게시한 'WAInjectBench: Benchmarking Prompt Injection Detections for Web Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Prompt Injection",{"className":"page__taxonomy-item","children":["#","Prompt Injection"]}],["$","span","Web Agents",{"className":"page__taxonomy-item","children":["#","Web Agents"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Adversarial Attacks",{"className":"page__taxonomy-item","children":["#","Adversarial Attacks"]}],["$","span","Detection Benchmarking",{"className":"page__taxonomy-item","children":["#","Detection Benchmarking"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Image-based Detection",{"className":"page__taxonomy-item","children":["#","Image-based Detection"]}],["$","span","Text-based Detection",{"className":"page__taxonomy-item","children":["#","Text-based Detection"]}]]}]]}]]}],["$","article","2025-10-6-Triangle-Splatting-Differentiable-Rendering-with-Opaque-Triangles",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-Triangle-Splatting-Differentiable-Rendering-with-Opaque-Triangles/","children":"[논문리뷰] Triangle Splatting+: Differentiable Rendering with Opaque Triangles"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Matheus Gadelha이 [arXiv]에 게시한 'Triangle Splatting+: Differentiable Rendering with Opaque Triangles' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Differentiable Rendering",{"className":"page__taxonomy-item","children":["#","Differentiable Rendering"]}],["$","span","3D Reconstruction",{"className":"page__taxonomy-item","children":["#","3D Reconstruction"]}],["$","span","Novel View Synthesis",{"className":"page__taxonomy-item","children":["#","Novel View Synthesis"]}],["$","span","Triangles",{"className":"page__taxonomy-item","children":["#","Triangles"]}],["$","span","Opaque Primitives",{"className":"page__taxonomy-item","children":["#","Opaque Primitives"]}],["$","span","Game Engines",{"className":"page__taxonomy-item","children":["#","Game Engines"]}],["$","span","Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","Gaussian Splatting"]}],["$","span","Mesh-based Rendering",{"className":"page__taxonomy-item","children":["#","Mesh-based Rendering"]}]]}]]}]]}],["$","article","2025-10-6-TalkPlay-Tools-Conversational-Music-Recommendation-with-LLM-Tool-Calling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-TalkPlay-Tools-Conversational-Music-Recommendation-with-LLM-Tool-Calling/","children":"[논문리뷰] TalkPlay-Tools: Conversational Music Recommendation with LLM Tool Calling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Juhan Nam이 [arXiv]에 게시한 'TalkPlay-Tools: Conversational Music Recommendation with LLM Tool Calling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Conversational Recommendation",{"className":"page__taxonomy-item","children":["#","Conversational Recommendation"]}],["$","span","LLM Tool Calling",{"className":"page__taxonomy-item","children":["#","LLM Tool Calling"]}],["$","span","Music Recommendation",{"className":"page__taxonomy-item","children":["#","Music Recommendation"]}],["$","span","Multimodal Retrieval",{"className":"page__taxonomy-item","children":["#","Multimodal Retrieval"]}],["$","span","Information Retrieval",{"className":"page__taxonomy-item","children":["#","Information Retrieval"]}],["$","span","Retrieval-Reranking",{"className":"page__taxonomy-item","children":["#","Retrieval-Reranking"]}],["$","span","Semantic IDs",{"className":"page__taxonomy-item","children":["#","Semantic IDs"]}]]}]]}]]}],["$","article","2025-10-6-SurveyBench-How-Well-Can-LLM-Agents-Write-Academic-Surveys",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-SurveyBench-How-Well-Can-LLM-Agents-Write-Academic-Surveys/","children":"[논문리뷰] SurveyBench: How Well Can LLM(-Agents) Write Academic Surveys?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shuo Wang이 [arXiv]에 게시한 'SurveyBench: How Well Can LLM(-Agents) Write Academic Surveys?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Academic Survey Generation",{"className":"page__taxonomy-item","children":["#","Academic Survey Generation"]}],["$","span","Evaluation Framework",{"className":"page__taxonomy-item","children":["#","Evaluation Framework"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Quiz-driven Evaluation",{"className":"page__taxonomy-item","children":["#","Quiz-driven Evaluation"]}],["$","span","Content Quality Metrics",{"className":"page__taxonomy-item","children":["#","Content Quality Metrics"]}]]}]]}]]}],["$","article","2025-10-6-SpineBench-A-Clinically-Salient-Level-Aware-Benchmark-Powered-by-the-SpineMed-450k-Corpus",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-SpineBench-A-Clinically-Salient-Level-Aware-Benchmark-Powered-by-the-SpineMed-450k-Corpus/","children":"[논문리뷰] SpineBench: A Clinically Salient, Level-Aware Benchmark Powered by the SpineMed-450k Corpus"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhonghao Zhang이 [arXiv]에 게시한 'SpineBench: A Clinically Salient, Level-Aware Benchmark Powered by the SpineMed-450k Corpus' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Medical AI",{"className":"page__taxonomy-item","children":["#","Medical AI"]}],["$","span","Spine Diagnosis",{"className":"page__taxonomy-item","children":["#","Spine Diagnosis"]}],["$","span","Multimodal LLM",{"className":"page__taxonomy-item","children":["#","Multimodal LLM"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}],["$","span","Clinical Reasoning",{"className":"page__taxonomy-item","children":["#","Clinical Reasoning"]}],["$","span","Spine Surgery",{"className":"page__taxonomy-item","children":["#","Spine Surgery"]}],["$","span","Vision-Language Model",{"className":"page__taxonomy-item","children":["#","Vision-Language Model"]}]]}]]}]]}],["$","article","2025-10-6-Self-Improvement-in-Multimodal-Large-Language-Models-A-Survey",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-Self-Improvement-in-Multimodal-Large-Language-Models-A-Survey/","children":"[논문리뷰] Self-Improvement in Multimodal Large Language Models: A Survey"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yapeng Tian이 [arXiv]에 게시한 'Self-Improvement in Multimodal Large Language Models: A Survey' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models (MLLMs)"]}],["$","span","Self-Improvement",{"className":"page__taxonomy-item","children":["#","Self-Improvement"]}],["$","span","Data Collection",{"className":"page__taxonomy-item","children":["#","Data Collection"]}],["$","span","Data Organization",{"className":"page__taxonomy-item","children":["#","Data Organization"]}],["$","span","Model Optimization",{"className":"page__taxonomy-item","children":["#","Model Optimization"]}],["$","span","Survey",{"className":"page__taxonomy-item","children":["#","Survey"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Direct Preference Optimization",{"className":"page__taxonomy-item","children":["#","Direct Preference Optimization"]}]]}]]}]]}],["$","article","2025-10-6-Scaling-Policy-Compliance-Assessment-in-Language-Models-with-Policy-Reasoning-Traces",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-Scaling-Policy-Compliance-Assessment-in-Language-Models-with-Policy-Reasoning-Traces/","children":"[논문리뷰] Scaling Policy Compliance Assessment in Language Models with Policy Reasoning Traces"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Scaling Policy Compliance Assessment in Language Models with Policy Reasoning Traces' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Policy Compliance",{"className":"page__taxonomy-item","children":["#","Policy Compliance"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Reasoning Traces",{"className":"page__taxonomy-item","children":["#","Reasoning Traces"]}],["$","span","In-Context Learning (ICL)",{"className":"page__taxonomy-item","children":["#","In-Context Learning (ICL)"]}],["$","span","Supervised Finetuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Finetuning (SFT)"]}],["$","span","HIPAA",{"className":"page__taxonomy-item","children":["#","HIPAA"]}],["$","span","GDPR",{"className":"page__taxonomy-item","children":["#","GDPR"]}],["$","span","ModelSpec",{"className":"page__taxonomy-item","children":["#","ModelSpec"]}]]}]]}]]}],["$","article","2025-10-6-REPAIR-Robust-Editing-via-Progressive-Adaptive-Intervention-and-Reintegration",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-REPAIR-Robust-Editing-via-Progressive-Adaptive-Intervention-and-Reintegration/","children":"[논문리뷰] REPAIR: Robust Editing via Progressive Adaptive Intervention and Reintegration"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'REPAIR: Robust Editing via Progressive Adaptive Intervention and Reintegration' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Model Editing",{"className":"page__taxonomy-item","children":["#","Model Editing"]}],["$","span","Lifelong Learning",{"className":"page__taxonomy-item","children":["#","Lifelong Learning"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Continual Learning",{"className":"page__taxonomy-item","children":["#","Continual Learning"]}],["$","span","Knowledge Distillation",{"className":"page__taxonomy-item","children":["#","Knowledge Distillation"]}],["$","span","Error Feedback",{"className":"page__taxonomy-item","children":["#","Error Feedback"]}],["$","span","Memory Management",{"className":"page__taxonomy-item","children":["#","Memory Management"]}],["$","span","Parameter Merging",{"className":"page__taxonomy-item","children":["#","Parameter Merging"]}]]}]]}]]}],["$","article","2025-10-6-OrtSAE-Orthogonal-Sparse-Autoencoders-Uncover-Atomic-Features",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-OrtSAE-Orthogonal-Sparse-Autoencoders-Uncover-Atomic-Features/","children":"[논문리뷰] OrtSAE: Orthogonal Sparse Autoencoders Uncover Atomic Features"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Elena Tutubalina이 [arXiv]에 게시한 'OrtSAE: Orthogonal Sparse Autoencoders Uncover Atomic Features' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Sparse Autoencoders",{"className":"page__taxonomy-item","children":["#","Sparse Autoencoders"]}],["$","span","Mechanistic Interpretability",{"className":"page__taxonomy-item","children":["#","Mechanistic Interpretability"]}],["$","span","Feature Disentanglement",{"className":"page__taxonomy-item","children":["#","Feature Disentanglement"]}],["$","span","Orthogonality",{"className":"page__taxonomy-item","children":["#","Orthogonality"]}],["$","span","LLM Features",{"className":"page__taxonomy-item","children":["#","LLM Features"]}],["$","span","Feature Absorption",{"className":"page__taxonomy-item","children":["#","Feature Absorption"]}],["$","span","Feature Composition",{"className":"page__taxonomy-item","children":["#","Feature Composition"]}]]}]]}]]}],["$","article","2025-10-6-NuRisk-A-Visual-Question-Answering-Dataset-for-Agent-Level-Risk-Assessment-in-Autonomous-Driving",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-NuRisk-A-Visual-Question-Answering-Dataset-for-Agent-Level-Risk-Assessment-in-Autonomous-Driving/","children":"[논문리뷰] NuRisk: A Visual Question Answering Dataset for Agent-Level Risk Assessment in Autonomous Driving"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'NuRisk: A Visual Question Answering Dataset for Agent-Level Risk Assessment in Autonomous Driving' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Visual Question Answering (VQA)",{"className":"page__taxonomy-item","children":["#","Visual Question Answering (VQA)"]}],["$","span","Autonomous Driving",{"className":"page__taxonomy-item","children":["#","Autonomous Driving"]}],["$","span","Risk Assessment",{"className":"page__taxonomy-item","children":["#","Risk Assessment"]}],["$","span","Spatio-Temporal Reasoning",{"className":"page__taxonomy-item","children":["#","Spatio-Temporal Reasoning"]}],["$","span","Large Vision Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Large Vision Models (VLMs)"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}],["$","span","Bird-Eye-View (BEV)",{"className":"page__taxonomy-item","children":["#","Bird-Eye-View (BEV)"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}]]}]]}]]}],["$","article","2025-10-6-LSPO-Length-aware-Dynamic-Sampling-for-Policy-Optimization-in-LLM-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-LSPO-Length-aware-Dynamic-Sampling-for-Policy-Optimization-in-LLM-Reasoning/","children":"[논문리뷰] LSPO: Length-aware Dynamic Sampling for Policy Optimization in LLM Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'LSPO: Length-aware Dynamic Sampling for Policy Optimization in LLM Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Reasoning",{"className":"page__taxonomy-item","children":["#","LLM Reasoning"]}],["$","span","RLVR",{"className":"page__taxonomy-item","children":["#","RLVR"]}],["$","span","Dynamic Sampling",{"className":"page__taxonomy-item","children":["#","Dynamic Sampling"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Response Length",{"className":"page__taxonomy-item","children":["#","Response Length"]}],["$","span","Meta-RL",{"className":"page__taxonomy-item","children":["#","Meta-RL"]}],["$","span","Overthinking",{"className":"page__taxonomy-item","children":["#","Overthinking"]}]]}]]}]]}],["$","article","2025-10-6-LEAML-Label-Efficient-Adaptation-to-Out-of-Distribution-Visual-Tasks-for-Multimodal-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-LEAML-Label-Efficient-Adaptation-to-Out-of-Distribution-Visual-Tasks-for-Multimodal-Large-Language-Models/","children":"[논문리뷰] LEAML: Label-Efficient Adaptation to Out-of-Distribution Visual Tasks for Multimodal Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yu-Chiang Frank Wang이 [arXiv]에 게시한 'LEAML: Label-Efficient Adaptation to Out-of-Distribution Visual Tasks for Multimodal Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLM",{"className":"page__taxonomy-item","children":["#","Multimodal LLM"]}],["$","span","OOD Adaptation",{"className":"page__taxonomy-item","children":["#","OOD Adaptation"]}],["$","span","Label Efficiency",{"className":"page__taxonomy-item","children":["#","Label Efficiency"]}],["$","span","VQA",{"className":"page__taxonomy-item","children":["#","VQA"]}],["$","span","Semi-Supervised Learning",{"className":"page__taxonomy-item","children":["#","Semi-Supervised Learning"]}],["$","span","Neuron Distillation",{"className":"page__taxonomy-item","children":["#","Neuron Distillation"]}],["$","span","Pseudo Labeling",{"className":"page__taxonomy-item","children":["#","Pseudo Labeling"]}],["$","span","Medical Imaging",{"className":"page__taxonomy-item","children":["#","Medical Imaging"]}]]}]]}]]}],["$","article","2025-10-6-Improving-GUI-Grounding-with-Explicit-Position-to-Coordinate-Mapping",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-Improving-GUI-Grounding-with-Explicit-Position-to-Coordinate-Mapping/","children":"[논문리뷰] Improving GUI Grounding with Explicit Position-to-Coordinate Mapping"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Spandana Gella이 [arXiv]에 게시한 'Improving GUI Grounding with Explicit Position-to-Coordinate Mapping' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","GUI Grounding",{"className":"page__taxonomy-item","children":["#","GUI Grounding"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Positional Embedding",{"className":"page__taxonomy-item","children":["#","Positional Embedding"]}],["$","span","UI Automation",{"className":"page__taxonomy-item","children":["#","UI Automation"]}],["$","span","Coordinate Prediction",{"className":"page__taxonomy-item","children":["#","Coordinate Prediction"]}],["$","span","Resolution Generalization",{"className":"page__taxonomy-item","children":["#","Resolution Generalization"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}]]}]]}]]}],["$","article","2025-10-6-How-Confident-are-Video-Models-Empowering-Video-Models-to-Express-their-Uncertainty",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-How-Confident-are-Video-Models-Empowering-Video-Models-to-Express-their-Uncertainty/","children":"[논문리뷰] How Confident are Video Models? Empowering Video Models to Express their Uncertainty"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Anirudha Majumdar이 [arXiv]에 게시한 'How Confident are Video Models? Empowering Video Models to Express their Uncertainty' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Uncertainty Quantification",{"className":"page__taxonomy-item","children":["#","Uncertainty Quantification"]}],["$","span","Aleatoric Uncertainty",{"className":"page__taxonomy-item","children":["#","Aleatoric Uncertainty"]}],["$","span","Epistemic Uncertainty",{"className":"page__taxonomy-item","children":["#","Epistemic Uncertainty"]}],["$","span","Model Calibration",{"className":"page__taxonomy-item","children":["#","Model Calibration"]}],["$","span","Text-to-Video",{"className":"page__taxonomy-item","children":["#","Text-to-Video"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","VMF Distribution",{"className":"page__taxonomy-item","children":["#","VMF Distribution"]}]]}]]}]]}],["$","article","2025-10-6-Free-Lunch-Alignment-of-Text-to-Image-Diffusion-Models-without-Preference-Image-Pairs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-Free-Lunch-Alignment-of-Text-to-Image-Diffusion-Models-without-Preference-Image-Pairs/","children":"[논문리뷰] Free Lunch Alignment of Text-to-Image Diffusion Models without Preference Image Pairs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Free Lunch Alignment of Text-to-Image Diffusion Models without Preference Image Pairs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Image Models",{"className":"page__taxonomy-item","children":["#","Text-to-Image Models"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Preference Optimization",{"className":"page__taxonomy-item","children":["#","Preference Optimization"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","RLHF",{"className":"page__taxonomy-item","children":["#","RLHF"]}],["$","span","Prompt Editing",{"className":"page__taxonomy-item","children":["#","Prompt Editing"]}],["$","span","Free Lunch Alignment",{"className":"page__taxonomy-item","children":["#","Free Lunch Alignment"]}],["$","span","TDPO",{"className":"page__taxonomy-item","children":["#","TDPO"]}],["$","span","TKTO",{"className":"page__taxonomy-item","children":["#","TKTO"]}]]}]]}]]}],["$","article","2025-10-6-FocusAgent-Simple-Yet-Effective-Ways-of-Trimming-the-Large-Context-of-Web-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-FocusAgent-Simple-Yet-Effective-Ways-of-Trimming-the-Large-Context-of-Web-Agents/","children":"[논문리뷰] FocusAgent: Simple Yet Effective Ways of Trimming the Large Context of Web Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Léo Boisvert이 [arXiv]에 게시한 'FocusAgent: Simple Yet Effective Ways of Trimming the Large Context of Web Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Web Agents",{"className":"page__taxonomy-item","children":["#","Web Agents"]}],["$","span","LLM Context Pruning",{"className":"page__taxonomy-item","children":["#","LLM Context Pruning"]}],["$","span","Accessibility Tree",{"className":"page__taxonomy-item","children":["#","Accessibility Tree"]}],["$","span","Prompt Injection",{"className":"page__taxonomy-item","children":["#","Prompt Injection"]}],["$","span","Retrieval Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval Augmented Generation"]}],["$","span","Web Navigation",{"className":"page__taxonomy-item","children":["#","Web Navigation"]}],["$","span","Agent Security",{"className":"page__taxonomy-item","children":["#","Agent Security"]}],["$","span","Efficient LLM",{"className":"page__taxonomy-item","children":["#","Efficient LLM"]}]]}]]}]]}],["$","article","2025-10-6-Efficient-Multi-modal-Large-Language-Models-via-Progressive-Consistency-Distillation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-Efficient-Multi-modal-Large-Language-Models-via-Progressive-Consistency-Distillation/","children":"[논문리뷰] Efficient Multi-modal Large Language Models via Progressive Consistency Distillation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Efficient Multi-modal Large Language Models via Progressive Consistency Distillation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-modal LLMs",{"className":"page__taxonomy-item","children":["#","Multi-modal LLMs"]}],["$","span","Token Compression",{"className":"page__taxonomy-item","children":["#","Token Compression"]}],["$","span","Efficiency",{"className":"page__taxonomy-item","children":["#","Efficiency"]}],["$","span","Knowledge Distillation",{"className":"page__taxonomy-item","children":["#","Knowledge Distillation"]}],["$","span","Progressive Learning",{"className":"page__taxonomy-item","children":["#","Progressive Learning"]}],["$","span","Consistency Distillation",{"className":"page__taxonomy-item","children":["#","Consistency Distillation"]}],["$","span","MLLM Training",{"className":"page__taxonomy-item","children":["#","MLLM Training"]}]]}]]}]]}],["$","article","2025-10-6-DiffTester-Accelerating-Unit-Test-Generation-for-Diffusion-LLMs-via-Repetitive-Pattern",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-DiffTester-Accelerating-Unit-Test-Generation-for-Diffusion-LLMs-via-Repetitive-Pattern/","children":"[논문리뷰] DiffTester: Accelerating Unit Test Generation for Diffusion LLMs via Repetitive Pattern"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jia Li이 [arXiv]에 게시한 'DiffTester: Accelerating Unit Test Generation for Diffusion LLMs via Repetitive Pattern' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion LLMs",{"className":"page__taxonomy-item","children":["#","Diffusion LLMs"]}],["$","span","Unit Test Generation",{"className":"page__taxonomy-item","children":["#","Unit Test Generation"]}],["$","span","Acceleration",{"className":"page__taxonomy-item","children":["#","Acceleration"]}],["$","span","Repetitive Patterns",{"className":"page__taxonomy-item","children":["#","Repetitive Patterns"]}],["$","span","Abstract Syntax Tree",{"className":"page__taxonomy-item","children":["#","Abstract Syntax Tree"]}],["$","span","Software Testing",{"className":"page__taxonomy-item","children":["#","Software Testing"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}]]}]]}]]}],["$","article","2025-10-6-Compose-Your-Policies-Improving-Diffusion-based-or-Flow-based-Robot-Policies-via-Test-time-Distribution-level-Composition",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-Compose-Your-Policies-Improving-Diffusion-based-or-Flow-based-Robot-Policies-via-Test-time-Distribution-level-Composition/","children":"[논문리뷰] Compose Your Policies! Improving Diffusion-based or Flow-based Robot Policies via Test-time Distribution-level Composition"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Compose Your Policies! Improving Diffusion-based or Flow-based Robot Policies via Test-time Distribution-level Composition' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Flow-based Models",{"className":"page__taxonomy-item","children":["#","Flow-based Models"]}],["$","span","Robotics Control",{"className":"page__taxonomy-item","children":["#","Robotics Control"]}],["$","span","Policy Composition",{"className":"page__taxonomy-item","children":["#","Policy Composition"]}],["$","span","Test-time Optimization",{"className":"page__taxonomy-item","children":["#","Test-time Optimization"]}],["$","span","Score-based Models",{"className":"page__taxonomy-item","children":["#","Score-based Models"]}],["$","span","Training-free",{"className":"page__taxonomy-item","children":["#","Training-free"]}]]}]]}]]}],["$","article","2025-10-6-CoDA-Agentic-Systems-for-Collaborative-Data-Visualization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-CoDA-Agentic-Systems-for-Collaborative-Data-Visualization/","children":"[논문리뷰] CoDA: Agentic Systems for Collaborative Data Visualization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'CoDA: Agentic Systems for Collaborative Data Visualization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-agent Systems"]}],["$","span","Data Visualization",{"className":"page__taxonomy-item","children":["#","Data Visualization"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Automation",{"className":"page__taxonomy-item","children":["#","Automation"]}],["$","span","Self-reflection",{"className":"page__taxonomy-item","children":["#","Self-reflection"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","Natural Language to Visualization",{"className":"page__taxonomy-item","children":["#","Natural Language to Visualization"]}]]}]]}]]}],["$","article","2025-10-6-Apriel-1-5-15b-Thinker",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-Apriel-1-5-15b-Thinker/","children":"[논문리뷰] Apriel-1.5-15b-Thinker"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Apriel-1.5-15b-Thinker' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Reasoning Model",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning Model"]}],["$","span","Open-Weights Model",{"className":"page__taxonomy-item","children":["#","Open-Weights Model"]}],["$","span","Continual Pretraining (CPT)",{"className":"page__taxonomy-item","children":["#","Continual Pretraining (CPT)"]}],["$","span","Supervised Fine-Tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning (SFT)"]}],["$","span","Training Design",{"className":"page__taxonomy-item","children":["#","Training Design"]}],["$","span","Efficiency",{"className":"page__taxonomy-item","children":["#","Efficiency"]}],["$","span","Frontier Performance",{"className":"page__taxonomy-item","children":["#","Frontier Performance"]}]]}]]}]]}],["$","article","2025-10-6-Align-Your-Tangent-Training-Better-Consistency-Models-via-Manifold-Aligned-Tangents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-Align-Your-Tangent-Training-Better-Consistency-Models-via-Manifold-Aligned-Tangents/","children":"[논문리뷰] Align Your Tangent: Training Better Consistency Models via Manifold-Aligned Tangents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jong Chul Ye이 [arXiv]에 게시한 'Align Your Tangent: Training Better Consistency Models via Manifold-Aligned Tangents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Consistency Models",{"className":"page__taxonomy-item","children":["#","Consistency Models"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Manifold Learning",{"className":"page__taxonomy-item","children":["#","Manifold Learning"]}],["$","span","Tangent Alignment",{"className":"page__taxonomy-item","children":["#","Tangent Alignment"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Training Dynamics",{"className":"page__taxonomy-item","children":["#","Training Dynamics"]}],["$","span","Manifold Feature Distance",{"className":"page__taxonomy-item","children":["#","Manifold Feature Distance"]}]]}]]}]]}],["$","article","2025-10-6-A-Practitioners-Guide-to-Multi-turn-Agentic-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-A-Practitioners-Guide-to-Multi-turn-Agentic-Reinforcement-Learning/","children":"[논문리뷰] A Practitioner's Guide to Multi-turn Agentic Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'A Practitioner's Guide to Multi-turn Agentic Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-turn Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Multi-turn Reinforcement Learning"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Text-based Environments",{"className":"page__taxonomy-item","children":["#","Text-based Environments"]}],["$","span","Reward Shaping",{"className":"page__taxonomy-item","children":["#","Reward Shaping"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Supervised Fine-tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning (SFT)"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Environment Complexity",{"className":"page__taxonomy-item","children":["#","Environment Complexity"]}]]}]]}]]}],["$","article","2025-10-2-Why-Cant-Transformers-Learn-Multiplication-Reverse-Engineering-Reveals-Long-Range-Dependency-Pitfalls",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-Why-Cant-Transformers-Learn-Multiplication-Reverse-Engineering-Reveals-Long-Range-Dependency-Pitfalls/","children":"[논문리뷰] Why Can't Transformers Learn Multiplication? Reverse-Engineering Reveals Long-Range Dependency Pitfalls"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Stuart Shieber이 [arXiv]에 게시한 'Why Can't Transformers Learn Multiplication? Reverse-Engineering Reveals Long-Range Dependency Pitfalls' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Transformers",{"className":"page__taxonomy-item","children":["#","Transformers"]}],["$","span","Multiplication",{"className":"page__taxonomy-item","children":["#","Multiplication"]}],["$","span","Long-Range Dependencies",{"className":"page__taxonomy-item","children":["#","Long-Range Dependencies"]}],["$","span","Implicit Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Implicit Chain-of-Thought"]}],["$","span","Attention Mechanisms",{"className":"page__taxonomy-item","children":["#","Attention Mechanisms"]}],["$","span","Inductive Bias",{"className":"page__taxonomy-item","children":["#","Inductive Bias"]}],["$","span","Reverse Engineering",{"className":"page__taxonomy-item","children":["#","Reverse Engineering"]}]]}]]}]]}],["$","article","2025-10-2-VLM-FO1-Bridging-the-Gap-Between-High-Level-Reasoning-and-Fine-Grained-Perception-in-VLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-VLM-FO1-Bridging-the-Gap-Between-High-Level-Reasoning-and-Fine-Grained-Perception-in-VLMs/","children":"[논문리뷰] VLM-FO1: Bridging the Gap Between High-Level Reasoning and Fine-Grained Perception in VLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'VLM-FO1: Bridging the Gap Between High-Level Reasoning and Fine-Grained Perception in VLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Object Grounding",{"className":"page__taxonomy-item","children":["#","Object Grounding"]}],["$","span","Fine-grained Perception",{"className":"page__taxonomy-item","children":["#","Fine-grained Perception"]}],["$","span","Hybrid Region Encoder",{"className":"page__taxonomy-item","children":["#","Hybrid Region Encoder"]}],["$","span","Plug-and-play",{"className":"page__taxonomy-item","children":["#","Plug-and-play"]}],["$","span","Two-stage Training",{"className":"page__taxonomy-item","children":["#","Two-stage Training"]}],["$","span","Visual Reasoning",{"className":"page__taxonomy-item","children":["#","Visual Reasoning"]}]]}]]}]]}],["$","article","2025-10-2-VLA-RFT-Vision-Language-Action-Reinforcement-Fine-tuning-with-Verified-Rewards-in-World-Simulators",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-VLA-RFT-Vision-Language-Action-Reinforcement-Fine-tuning-with-Verified-Rewards-in-World-Simulators/","children":"[논문리뷰] VLA-RFT: Vision-Language-Action Reinforcement Fine-tuning with Verified Rewards in World Simulators"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zirui Ge이 [arXiv]에 게시한 'VLA-RFT: Vision-Language-Action Reinforcement Fine-tuning with Verified Rewards in World Simulators' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","World Models",{"className":"page__taxonomy-item","children":["#","World Models"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Reward Design",{"className":"page__taxonomy-item","children":["#","Reward Design"]}],["$","span","Distribution Shift",{"className":"page__taxonomy-item","children":["#","Distribution Shift"]}]]}]]}]]}],["$","article","2025-10-2-Training-Vision-Language-Process-Reward-Models-for-Test-Time-Scaling-in-Multimodal-Reasoning-Key-Insights-and-Lessons-Learned",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-Training-Vision-Language-Process-Reward-Models-for-Test-Time-Scaling-in-Multimodal-Reasoning-Key-Insights-and-Lessons-Learned/","children":"[논문리뷰] Training Vision-Language Process Reward Models for Test-Time Scaling in Multimodal Reasoning: Key Insights and Lessons Learned"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Training Vision-Language Process Reward Models for Test-Time Scaling in Multimodal Reasoning: Key Insights and Lessons Learned' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision-Language Models (VLMs)"]}],["$","span","Process Reward Models (PRMs)",{"className":"page__taxonomy-item","children":["#","Process Reward Models (PRMs)"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","span","Test-Time Scaling (TTS)",{"className":"page__taxonomy-item","children":["#","Test-Time Scaling (TTS)"]}],["$","span","Process Supervision",{"className":"page__taxonomy-item","children":["#","Process Supervision"]}],["$","span","Dataset Construction",{"className":"page__taxonomy-item","children":["#","Dataset Construction"]}],["$","span","Perception Errors",{"className":"page__taxonomy-item","children":["#","Perception Errors"]}],["$","span","MCTS",{"className":"page__taxonomy-item","children":["#","MCTS"]}]]}]]}]]}],["$","article","2025-10-2-ReSWD-ReSTIRd-not-shaken-Combining-Reservoir-Sampling-and-Sliced-Wasserstein-Distance-for-Variance-Reduction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-ReSWD-ReSTIRd-not-shaken-Combining-Reservoir-Sampling-and-Sliced-Wasserstein-Distance-for-Variance-Reduction/","children":"[논문리뷰] ReSWD: ReSTIR'd, not shaken. Combining Reservoir Sampling and Sliced Wasserstein Distance for Variance Reduction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'ReSWD: ReSTIR'd, not shaken. Combining Reservoir Sampling and Sliced Wasserstein Distance for Variance Reduction' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Sliced Wasserstein Distance",{"className":"page__taxonomy-item","children":["#","Sliced Wasserstein Distance"]}],["$","span","Reservoir Sampling",{"className":"page__taxonomy-item","children":["#","Reservoir Sampling"]}],["$","span","Variance Reduction",{"className":"page__taxonomy-item","children":["#","Variance Reduction"]}],["$","span","Distribution Matching",{"className":"page__taxonomy-item","children":["#","Distribution Matching"]}],["$","span","Diffusion Guidance",{"className":"page__taxonomy-item","children":["#","Diffusion Guidance"]}],["$","span","Color Correction",{"className":"page__taxonomy-item","children":["#","Color Correction"]}],["$","span","Monte Carlo Estimation",{"className":"page__taxonomy-item","children":["#","Monte Carlo Estimation"]}]]}]]}]]}],["$","article","2025-10-2-PIPer-On-Device-Environment-Setup-via-Online-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-PIPer-On-Device-Environment-Setup-via-Online-Reinforcement-Learning/","children":"[논문리뷰] PIPer: On-Device Environment Setup via Online Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'PIPer: On-Device Environment Setup via Online Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Environment Setup",{"className":"page__taxonomy-item","children":["#","Environment Setup"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","On-device AI",{"className":"page__taxonomy-item","children":["#","On-device AI"]}],["$","span","Software Engineering",{"className":"page__taxonomy-item","children":["#","Software Engineering"]}],["$","span","Verifiable Rewards",{"className":"page__taxonomy-item","children":["#","Verifiable Rewards"]}]]}]]}]]}],["$","article","2025-10-2-On-Predictability-of-Reinforcement-Learning-Dynamics-for-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-On-Predictability-of-Reinforcement-Learning-Dynamics-for-Large-Language-Models/","children":"[논문리뷰] On Predictability of Reinforcement Learning Dynamics for Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuqing Huang이 [arXiv]에 게시한 'On Predictability of Reinforcement Learning Dynamics for Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Parameter Dynamics",{"className":"page__taxonomy-item","children":["#","Parameter Dynamics"]}],["$","span","Rank-1 Dominance",{"className":"page__taxonomy-item","children":["#","Rank-1 Dominance"]}],["$","span","Linear Dynamics",{"className":"page__taxonomy-item","children":["#","Linear Dynamics"]}],["$","span","SVD",{"className":"page__taxonomy-item","children":["#","SVD"]}],["$","span","Model Acceleration",{"className":"page__taxonomy-item","children":["#","Model Acceleration"]}],["$","span","Predictability",{"className":"page__taxonomy-item","children":["#","Predictability"]}]]}]]}]]}],["$","article","2025-10-2-Making-not-Taking-the-Best-of-N",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-Making-not-Taking-the-Best-of-N/","children":"[논문리뷰] Making, not Taking, the Best of N"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Making, not Taking, the Best of N' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Aggregation",{"className":"page__taxonomy-item","children":["#","LLM Aggregation"]}],["$","span","Generative Fusion",{"className":"page__taxonomy-item","children":["#","Generative Fusion"]}],["$","span","Best-of-N",{"className":"page__taxonomy-item","children":["#","Best-of-N"]}],["$","span","Synthetic Data Generation",{"className":"page__taxonomy-item","children":["#","Synthetic Data Generation"]}],["$","span","Test-Time Scaling",{"className":"page__taxonomy-item","children":["#","Test-Time Scaling"]}],["$","span","Multilingual Models",{"className":"page__taxonomy-item","children":["#","Multilingual Models"]}],["$","span","Ensemble Learning",{"className":"page__taxonomy-item","children":["#","Ensemble Learning"]}]]}]]}]]}],["$","article","2025-10-2-Knapsack-RL-Unlocking-Exploration-of-LLMs-via-Optimizing-Budget-Allocation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-Knapsack-RL-Unlocking-Exploration-of-LLMs-via-Optimizing-Budget-Allocation/","children":"[논문리뷰] Knapsack RL: Unlocking Exploration of LLMs via Optimizing Budget Allocation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Knapsack RL: Unlocking Exploration of LLMs via Optimizing Budget Allocation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Exploration Budget Allocation",{"className":"page__taxonomy-item","children":["#","Exploration Budget Allocation"]}],["$","span","Knapsack Problem",{"className":"page__taxonomy-item","children":["#","Knapsack Problem"]}],["$","span","Group Relative Policy Optimization (GRPO)",{"className":"page__taxonomy-item","children":["#","Group Relative Policy Optimization (GRPO)"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Resource Optimization",{"className":"page__taxonomy-item","children":["#","Resource Optimization"]}]]}]]}]]}],["$","article","2025-10-2-JoyAgent-JDGenie-Technical-Report-on-the-GAIA",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-JoyAgent-JDGenie-Technical-Report-on-the-GAIA/","children":"[논문리뷰] JoyAgent-JDGenie: Technical Report on the GAIA"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'JoyAgent-JDGenie: Technical Report on the GAIA' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Generalist Agent",{"className":"page__taxonomy-item","children":["#","Generalist Agent"]}],["$","span","Multi-Agent System",{"className":"page__taxonomy-item","children":["#","Multi-Agent System"]}],["$","span","Plan-Execute",{"className":"page__taxonomy-item","children":["#","Plan-Execute"]}],["$","span","ReAct",{"className":"page__taxonomy-item","children":["#","ReAct"]}],["$","span","Hierarchical Memory",{"className":"page__taxonomy-item","children":["#","Hierarchical Memory"]}],["$","span","Tool Integration",{"className":"page__taxonomy-item","children":["#","Tool Integration"]}],["$","span","GAIA Benchmark",{"className":"page__taxonomy-item","children":["#","GAIA Benchmark"]}],["$","span","LLM Agent",{"className":"page__taxonomy-item","children":["#","LLM Agent"]}]]}]]}]]}],["$","article","2025-10-2-Infusing-Theory-of-Mind-into-Socially-Intelligent-LLM-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-Infusing-Theory-of-Mind-into-Socially-Intelligent-LLM-Agents/","children":"[논문리뷰] Infusing Theory of Mind into Socially Intelligent LLM Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Infusing Theory of Mind into Socially Intelligent LLM Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Theory of Mind",{"className":"page__taxonomy-item","children":["#","Theory of Mind"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Social Agents",{"className":"page__taxonomy-item","children":["#","Social Agents"]}],["$","span","Dialogue Systems",{"className":"page__taxonomy-item","children":["#","Dialogue Systems"]}],["$","span","Mental State Modeling",{"className":"page__taxonomy-item","children":["#","Mental State Modeling"]}],["$","span","Look-ahead Planning",{"className":"page__taxonomy-item","children":["#","Look-ahead Planning"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Sotopia Benchmark",{"className":"page__taxonomy-item","children":["#","Sotopia Benchmark"]}]]}]]}]]}],["$","article","2025-10-2-In-Place-Feedback-A-New-Paradigm-for-Guiding-LLMs-in-Multi-Turn-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-In-Place-Feedback-A-New-Paradigm-for-Guiding-LLMs-in-Multi-Turn-Reasoning/","children":"[논문리뷰] In-Place Feedback: A New Paradigm for Guiding LLMs in Multi-Turn Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chaehyeon Chung이 [arXiv]에 게시한 'In-Place Feedback: A New Paradigm for Guiding LLMs in Multi-Turn Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Feedback",{"className":"page__taxonomy-item","children":["#","LLM Feedback"]}],["$","span","Multi-turn Reasoning",{"className":"page__taxonomy-item","children":["#","Multi-turn Reasoning"]}],["$","span","In-place Editing",{"className":"page__taxonomy-item","children":["#","In-place Editing"]}],["$","span","Token Efficiency",{"className":"page__taxonomy-item","children":["#","Token Efficiency"]}],["$","span","Error Correction",{"className":"page__taxonomy-item","children":["#","Error Correction"]}],["$","span","Human-AI Interaction",{"className":"page__taxonomy-item","children":["#","Human-AI Interaction"]}],["$","span","Reasoning Tasks",{"className":"page__taxonomy-item","children":["#","Reasoning Tasks"]}]]}]]}]]}],["$","article","2025-10-2-Hyperdimensional-Probe-Decoding-LLM-Representations-via-Vector-Symbolic-Architectures",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-Hyperdimensional-Probe-Decoding-LLM-Representations-via-Vector-Symbolic-Architectures/","children":"[논문리뷰] Hyperdimensional Probe: Decoding LLM Representations via Vector Symbolic Architectures"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Andrea Passerini이 [arXiv]에 게시한 'Hyperdimensional Probe: Decoding LLM Representations via Vector Symbolic Architectures' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Interpretability",{"className":"page__taxonomy-item","children":["#","LLM Interpretability"]}],["$","span","Vector Symbolic Architectures",{"className":"page__taxonomy-item","children":["#","Vector Symbolic Architectures"]}],["$","span","Neural Probing",{"className":"page__taxonomy-item","children":["#","Neural Probing"]}],["$","span","Information Decoding",{"className":"page__taxonomy-item","children":["#","Information Decoding"]}],["$","span","Hyperdimensional Computing",{"className":"page__taxonomy-item","children":["#","Hyperdimensional Computing"]}],["$","span","Latent Representations",{"className":"page__taxonomy-item","children":["#","Latent Representations"]}]]}]]}]]}],["$","article","2025-10-2-GUI-KV-Efficient-GUI-Agents-via-KV-Cache-with-Spatio-Temporal-Awareness",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-GUI-KV-Efficient-GUI-Agents-via-KV-Cache-with-Spatio-Temporal-Awareness/","children":"[논문리뷰] GUI-KV: Efficient GUI Agents via KV Cache with Spatio-Temporal Awareness"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chien-Sheng Wu이 [arXiv]에 게시한 'GUI-KV: Efficient GUI Agents via KV Cache with Spatio-Temporal Awareness' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","GUI Agents",{"className":"page__taxonomy-item","children":["#","GUI Agents"]}],["$","span","KV Cache Compression",{"className":"page__taxonomy-item","children":["#","KV Cache Compression"]}],["$","span","Spatio-Temporal Awareness",{"className":"page__taxonomy-item","children":["#","Spatio-Temporal Awareness"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Efficiency",{"className":"page__taxonomy-item","children":["#","Efficiency"]}],["$","span","Attention Sparsity",{"className":"page__taxonomy-item","children":["#","Attention Sparsity"]}],["$","span","QR Decomposition",{"className":"page__taxonomy-item","children":["#","QR Decomposition"]}]]}]]}]]}],["$","article","2025-10-2-GEM-A-Gym-for-Agentic-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-GEM-A-Gym-for-Agentic-LLMs/","children":"[논문리뷰] GEM: A Gym for Agentic LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'GEM: A Gym for Agentic LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic LLMs",{"className":"page__taxonomy-item","children":["#","Agentic LLMs"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Environment Simulator",{"className":"page__taxonomy-item","children":["#","Environment Simulator"]}],["$","span","Multi-turn Interactions",{"className":"page__taxonomy-item","children":["#","Multi-turn Interactions"]}],["$","span","Return Batch Normalization",{"className":"page__taxonomy-item","children":["#","Return Batch Normalization"]}],["$","span","Tool Integration",{"className":"page__taxonomy-item","children":["#","Tool Integration"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}]]}]]}]]}],["$","article","2025-10-2-Flash-Searcher-Fast-and-Effective-Web-Agents-via-DAG-Based-Parallel-Execution",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-Flash-Searcher-Fast-and-Effective-Web-Agents-via-DAG-Based-Parallel-Execution/","children":"[논문리뷰] Flash-Searcher: Fast and Effective Web Agents via DAG-Based Parallel Execution"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Flash-Searcher: Fast and Effective Web Agents via DAG-Based Parallel Execution' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Parallel Execution",{"className":"page__taxonomy-item","children":["#","Parallel Execution"]}],["$","span","DAG-based Planning",{"className":"page__taxonomy-item","children":["#","DAG-based Planning"]}],["$","span","Tool Orchestration",{"className":"page__taxonomy-item","children":["#","Tool Orchestration"]}],["$","span","Web Agents",{"className":"page__taxonomy-item","children":["#","Web Agents"]}],["$","span","Reasoning Framework",{"className":"page__taxonomy-item","children":["#","Reasoning Framework"]}],["$","span","Efficiency",{"className":"page__taxonomy-item","children":["#","Efficiency"]}]]}]]}]]}],["$","article","2025-10-2-Eliciting-Secret-Knowledge-from-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-Eliciting-Secret-Knowledge-from-Language-Models/","children":"[논문리뷰] Eliciting Secret Knowledge from Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Neel Nanda이 [arXiv]에 게시한 'Eliciting Secret Knowledge from Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Language Models",{"className":"page__taxonomy-item","children":["#","Language Models"]}],["$","span","Secret Elicitation",{"className":"page__taxonomy-item","children":["#","Secret Elicitation"]}],["$","span","Mechanistic Interpretability",{"className":"page__taxonomy-item","children":["#","Mechanistic Interpretability"]}],["$","span","Black-box Methods",{"className":"page__taxonomy-item","children":["#","Black-box Methods"]}],["$","span","White-box Methods",{"className":"page__taxonomy-item","children":["#","White-box Methods"]}],["$","span","AI Auditing",{"className":"page__taxonomy-item","children":["#","AI Auditing"]}],["$","span","Model Organisms",{"className":"page__taxonomy-item","children":["#","Model Organisms"]}],["$","span","Prefill Attacks",{"className":"page__taxonomy-item","children":["#","Prefill Attacks"]}]]}]]}]]}],["$","article","2025-10-2-DeepSearch-Overcome-the-Bottleneck-of-Reinforcement-Learning-with-Verifiable-Rewards-via-Monte-Carlo-Tree-Search",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-DeepSearch-Overcome-the-Bottleneck-of-Reinforcement-Learning-with-Verifiable-Rewards-via-Monte-Carlo-Tree-Search/","children":"[논문리뷰] DeepSearch: Overcome the Bottleneck of Reinforcement Learning with Verifiable Rewards via Monte Carlo Tree Search"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DeepSearch: Overcome the Bottleneck of Reinforcement Learning with Verifiable Rewards via Monte Carlo Tree Search' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning with Verifiable Rewards (RLVR)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning with Verifiable Rewards (RLVR)"]}],["$","span","Monte Carlo Tree Search (MCTS)",{"className":"page__taxonomy-item","children":["#","Monte Carlo Tree Search (MCTS)"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Systematic Exploration",{"className":"page__taxonomy-item","children":["#","Systematic Exploration"]}],["$","span","Adaptive Training",{"className":"page__taxonomy-item","children":["#","Adaptive Training"]}],["$","span","Tree-GRPO",{"className":"page__taxonomy-item","children":["#","Tree-GRPO"]}]]}]]}]]}],["$","article","2025-10-2-CurES-From-Gradient-Analysis-to-Efficient-Curriculum-Learning-for-Reasoning-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-CurES-From-Gradient-Analysis-to-Efficient-Curriculum-Learning-for-Reasoning-LLMs/","children":"[논문리뷰] CurES: From Gradient Analysis to Efficient Curriculum Learning for Reasoning LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hengyi Cai이 [arXiv]에 게시한 'CurES: From Gradient Analysis to Efficient Curriculum Learning for Reasoning LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Gradient Optimization",{"className":"page__taxonomy-item","children":["#","Gradient Optimization"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Bayesian Inference",{"className":"page__taxonomy-item","children":["#","Bayesian Inference"]}],["$","span","Sample Efficiency",{"className":"page__taxonomy-item","children":["#","Sample Efficiency"]}]]}]]}]]}],["$","article","2025-10-2-Code2Video-A-Code-centric-Paradigm-for-Educational-Video-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-Code2Video-A-Code-centric-Paradigm-for-Educational-Video-Generation/","children":"[논문리뷰] Code2Video: A Code-centric Paradigm for Educational Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Code2Video: A Code-centric Paradigm for Educational Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Educational Video Generation",{"className":"page__taxonomy-item","children":["#","Educational Video Generation"]}],["$","span","Code-centric AI",{"className":"page__taxonomy-item","children":["#","Code-centric AI"]}],["$","span","Multi-agent Framework",{"className":"page__taxonomy-item","children":["#","Multi-agent Framework"]}],["$","span","Manim",{"className":"page__taxonomy-item","children":["#","Manim"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Knowledge Transfer",{"className":"page__taxonomy-item","children":["#","Knowledge Transfer"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","MMMC Benchmark",{"className":"page__taxonomy-item","children":["#","MMMC Benchmark"]}]]}]]}]]}],["$","article","2025-10-2-BroRL-Scaling-Reinforcement-Learning-via-Broadened-Exploration",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-BroRL-Scaling-Reinforcement-Learning-via-Broadened-Exploration/","children":"[논문리뷰] BroRL: Scaling Reinforcement Learning via Broadened Exploration"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'BroRL: Scaling Reinforcement Learning via Broadened Exploration' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Scaling Laws",{"className":"page__taxonomy-item","children":["#","Scaling Laws"]}],["$","span","Exploration",{"className":"page__taxonomy-item","children":["#","Exploration"]}],["$","span","Rollout Size",{"className":"page__taxonomy-item","children":["#","Rollout Size"]}],["$","span","Verifiable Rewards",{"className":"page__taxonomy-item","children":["#","Verifiable Rewards"]}],["$","span","PPO",{"className":"page__taxonomy-item","children":["#","PPO"]}],["$","span","Mass Balance Equation",{"className":"page__taxonomy-item","children":["#","Mass Balance Equation"]}]]}]]}]]}],["$","article","2025-10-2-Boolean-Satisfiability-via-Imitation-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-Boolean-Satisfiability-via-Imitation-Learning/","children":"[논문리뷰] Boolean Satisfiability via Imitation Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiangyu Xu이 [arXiv]에 게시한 'Boolean Satisfiability via Imitation Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Boolean Satisfiability",{"className":"page__taxonomy-item","children":["#","Boolean Satisfiability"]}],["$","span","Imitation Learning",{"className":"page__taxonomy-item","children":["#","Imitation Learning"]}],["$","span","CDCL Solvers",{"className":"page__taxonomy-item","children":["#","CDCL Solvers"]}],["$","span","Branching Policy",{"className":"page__taxonomy-item","children":["#","Branching Policy"]}],["$","span","KeyTrace",{"className":"page__taxonomy-item","children":["#","KeyTrace"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Perceiver AR",{"className":"page__taxonomy-item","children":["#","Perceiver AR"]}]]}]]}]]}],["$","article","2025-10-2-BindWeave-Subject-Consistent-Video-Generation-via-Cross-Modal-Integration",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-BindWeave-Subject-Consistent-Video-Generation-via-Cross-Modal-Integration/","children":"[논문리뷰] BindWeave: Subject-Consistent Video Generation via Cross-Modal Integration"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiangyang Xia이 [arXiv]에 게시한 'BindWeave: Subject-Consistent Video Generation via Cross-Modal Integration' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Subject Consistency",{"className":"page__taxonomy-item","children":["#","Subject Consistency"]}],["$","span","Cross-Modal Integration",{"className":"page__taxonomy-item","children":["#","Cross-Modal Integration"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Multimodal LLM",{"className":"page__taxonomy-item","children":["#","Multimodal LLM"]}],["$","span","Diffusion Transformer",{"className":"page__taxonomy-item","children":["#","Diffusion Transformer"]}],["$","span","Text-to-Video",{"className":"page__taxonomy-item","children":["#","Text-to-Video"]}]]}]]}]]}],["$","article","2025-10-2-BiasFreeBench-a-Benchmark-for-Mitigating-Bias-in-Large-Language-Model-Responses",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-BiasFreeBench-a-Benchmark-for-Mitigating-Bias-in-Large-Language-Model-Responses/","children":"[논문리뷰] BiasFreeBench: a Benchmark for Mitigating Bias in Large Language Model Responses"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Julian McAuley이 [arXiv]에 게시한 'BiasFreeBench: a Benchmark for Mitigating Bias in Large Language Model Responses' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Bias Mitigation",{"className":"page__taxonomy-item","children":["#","LLM Bias Mitigation"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Evaluation Metrics",{"className":"page__taxonomy-item","children":["#","Evaluation Metrics"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Bias-Free Score",{"className":"page__taxonomy-item","children":["#","Bias-Free Score"]}],["$","span","Fairness",{"className":"page__taxonomy-item","children":["#","Fairness"]}]]}]]}]]}],["$","article","2025-10-2-Beyond-Log-Likelihood-Probability-Based-Objectives-for-Supervised-Fine-Tuning-across-the-Model-Capability-Continuum",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-Beyond-Log-Likelihood-Probability-Based-Objectives-for-Supervised-Fine-Tuning-across-the-Model-Capability-Continuum/","children":"[논문리뷰] Beyond Log Likelihood: Probability-Based Objectives for Supervised Fine-Tuning across the Model Capability Continuum"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hanghang Tong이 [arXiv]에 게시한 'Beyond Log Likelihood: Probability-Based Objectives for Supervised Fine-Tuning across the Model Capability Continuum' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Supervised Fine-tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning (SFT)"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Training Objectives",{"className":"page__taxonomy-item","children":["#","Training Objectives"]}],["$","span","Negative Log Likelihood (NLL)",{"className":"page__taxonomy-item","children":["#","Negative Log Likelihood (NLL)"]}],["$","span","Model Capability Continuum",{"className":"page__taxonomy-item","children":["#","Model Capability Continuum"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Probability-based Loss Functions",{"className":"page__taxonomy-item","children":["#","Probability-based Loss Functions"]}]]}]]}]]}],["$","article","2025-10-2-An-Empirical-Study-of-Testing-Practices-in-Open-Source-AI-Agent-Frameworks-and-Agentic-Applications",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-An-Empirical-Study-of-Testing-Practices-in-Open-Source-AI-Agent-Frameworks-and-Agentic-Applications/","children":"[논문리뷰] An Empirical Study of Testing Practices in Open Source AI Agent Frameworks and Agentic Applications"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Bram Adams이 [arXiv]에 게시한 'An Empirical Study of Testing Practices in Open Source AI Agent Frameworks and Agentic Applications' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Agent",{"className":"page__taxonomy-item","children":["#","AI Agent"]}],["$","span","LLM Agent",{"className":"page__taxonomy-item","children":["#","LLM Agent"]}],["$","span","Testing",{"className":"page__taxonomy-item","children":["#","Testing"]}],["$","span","Empirical Study",{"className":"page__taxonomy-item","children":["#","Empirical Study"]}],["$","span","Software Quality",{"className":"page__taxonomy-item","children":["#","Software Quality"]}],["$","span","Agent Frameworks",{"className":"page__taxonomy-item","children":["#","Agent Frameworks"]}],["$","span","Agentic Applications",{"className":"page__taxonomy-item","children":["#","Agentic Applications"]}],["$","span","Non-Determinism",{"className":"page__taxonomy-item","children":["#","Non-Determinism"]}]]}]]}]]}],["$","article","2025-10-2-ACON-Optimizing-Context-Compression-for-Long-horizon-LLM-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-ACON-Optimizing-Context-Compression-for-Long-horizon-LLM-Agents/","children":"[논문리뷰] ACON: Optimizing Context Compression for Long-horizon LLM Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'ACON: Optimizing Context Compression for Long-horizon LLM Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Context Compression",{"className":"page__taxonomy-item","children":["#","Context Compression"]}],["$","span","Long-horizon Tasks",{"className":"page__taxonomy-item","children":["#","Long-horizon Tasks"]}],["$","span","Prompt Optimization",{"className":"page__taxonomy-item","children":["#","Prompt Optimization"]}],["$","span","Knowledge Distillation",{"className":"page__taxonomy-item","children":["#","Knowledge Distillation"]}],["$","span","Memory Efficiency",{"className":"page__taxonomy-item","children":["#","Memory Efficiency"]}],["$","span","Task Performance",{"className":"page__taxonomy-item","children":["#","Task Performance"]}],["$","span","Failure Analysis",{"className":"page__taxonomy-item","children":["#","Failure Analysis"]}]]}]]}]]}],["$","article","2025-10-1-jina-reranker-v3-Last-but-Not-Late-Interaction-for-Document-Reranking",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-jina-reranker-v3-Last-but-Not-Late-Interaction-for-Document-Reranking/","children":"[논문리뷰] jina-reranker-v3: Last but Not Late Interaction for Document Reranking"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'jina-reranker-v3: Last but Not Late Interaction for Document Reranking' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Document Reranking",{"className":"page__taxonomy-item","children":["#","Document Reranking"]}],["$","span","Last but Not Late Interaction",{"className":"page__taxonomy-item","children":["#","Last but Not Late Interaction"]}],["$","span","Multilingual",{"className":"page__taxonomy-item","children":["#","Multilingual"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Cross-Encoder",{"className":"page__taxonomy-item","children":["#","Cross-Encoder"]}],["$","span","InfoNCE Loss",{"className":"page__taxonomy-item","children":["#","InfoNCE Loss"]}],["$","span","Contextual Embedding",{"className":"page__taxonomy-item","children":["#","Contextual Embedding"]}],["$","span","Qwen3",{"className":"page__taxonomy-item","children":["#","Qwen3"]}]]}]]}]]}],["$","article","2025-10-1-dParallel-Learnable-Parallel-Decoding-for-dLLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-dParallel-Learnable-Parallel-Decoding-for-dLLMs/","children":"[논문리뷰] dParallel: Learnable Parallel Decoding for dLLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'dParallel: Learnable Parallel Decoding for dLLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Language Models",{"className":"page__taxonomy-item","children":["#","Diffusion Language Models"]}],["$","span","Parallel Decoding",{"className":"page__taxonomy-item","children":["#","Parallel Decoding"]}],["$","span","Inference Acceleration",{"className":"page__taxonomy-item","children":["#","Inference Acceleration"]}],["$","span","Certainty Distillation",{"className":"page__taxonomy-item","children":["#","Certainty Distillation"]}],["$","span","Self-Distillation",{"className":"page__taxonomy-item","children":["#","Self-Distillation"]}],["$","span","Masked Language Models",{"className":"page__taxonomy-item","children":["#","Masked Language Models"]}],["$","span","LLaDA",{"className":"page__taxonomy-item","children":["#","LLaDA"]}]]}]]}]]}],["$","article","2025-10-1-d2Cache-Accelerating-Diffusion-Based-LLMs-via-Dual-Adaptive-Caching",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-d2Cache-Accelerating-Diffusion-Based-LLMs-via-Dual-Adaptive-Caching/","children":"[논문리뷰] d^2Cache: Accelerating Diffusion-Based LLMs via Dual Adaptive Caching"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiarui Wang이 [arXiv]에 게시한 'd^2Cache: Accelerating Diffusion-Based LLMs via Dual Adaptive Caching' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Inference Acceleration",{"className":"page__taxonomy-item","children":["#","Inference Acceleration"]}],["$","span","KV Cache",{"className":"page__taxonomy-item","children":["#","KV Cache"]}],["$","span","Bidirectional Attention",{"className":"page__taxonomy-item","children":["#","Bidirectional Attention"]}],["$","span","Adaptive Caching",{"className":"page__taxonomy-item","children":["#","Adaptive Caching"]}],["$","span","Token Selection",{"className":"page__taxonomy-item","children":["#","Token Selection"]}]]}]]}]]}],["$","article","2025-10-1-Winning-the-Pruning-Gamble-A-Unified-Approach-to-Joint-Sample-and-Token-Pruning-for-Efficient-Supervised-Fine-Tuning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Winning-the-Pruning-Gamble-A-Unified-Approach-to-Joint-Sample-and-Token-Pruning-for-Efficient-Supervised-Fine-Tuning/","children":"[논문리뷰] Winning the Pruning Gamble: A Unified Approach to Joint Sample and Token Pruning for Efficient Supervised Fine-Tuning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yue Min이 [arXiv]에 게시한 'Winning the Pruning Gamble: A Unified Approach to Joint Sample and Token Pruning for Efficient Supervised Fine-Tuning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM SFT",{"className":"page__taxonomy-item","children":["#","LLM SFT"]}],["$","span","Data Pruning",{"className":"page__taxonomy-item","children":["#","Data Pruning"]}],["$","span","Sample Pruning",{"className":"page__taxonomy-item","children":["#","Sample Pruning"]}],["$","span","Token Pruning",{"className":"page__taxonomy-item","children":["#","Token Pruning"]}],["$","span","Error-Uncertainty Plane",{"className":"page__taxonomy-item","children":["#","Error-Uncertainty Plane"]}],["$","span","Q-Tuning",{"className":"page__taxonomy-item","children":["#","Q-Tuning"]}],["$","span","Data Efficiency",{"className":"page__taxonomy-item","children":["#","Data Efficiency"]}],["$","span","Dynamic Pruning",{"className":"page__taxonomy-item","children":["#","Dynamic Pruning"]}]]}]]}]]}],["$","article","2025-10-1-Whos-Your-Judge-On-the-Detectability-of-LLM-Generated-Judgments",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Whos-Your-Judge-On-the-Detectability-of-LLM-Generated-Judgments/","children":"[논문리뷰] Who's Your Judge? On the Detectability of LLM-Generated Judgments"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Who's Your Judge? On the Detectability of LLM-Generated Judgments' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM-as-a-judge",{"className":"page__taxonomy-item","children":["#","LLM-as-a-judge"]}],["$","span","Judgment Detection",{"className":"page__taxonomy-item","children":["#","Judgment Detection"]}],["$","span","Bias Quantification",{"className":"page__taxonomy-item","children":["#","Bias Quantification"]}],["$","span","Feature Engineering",{"className":"page__taxonomy-item","children":["#","Feature Engineering"]}],["$","span","Interpretability",{"className":"page__taxonomy-item","children":["#","Interpretability"]}],["$","span","Peer Review",{"className":"page__taxonomy-item","children":["#","Peer Review"]}],["$","span","AI Ethics",{"className":"page__taxonomy-item","children":["#","AI Ethics"]}],["$","span","Evaluation",{"className":"page__taxonomy-item","children":["#","Evaluation"]}]]}]]}]]}],["$","article","2025-10-1-Who-invented-deep-residual-learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Who-invented-deep-residual-learning/","children":"[논문리뷰] Who invented deep residual learning?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Juergen Schmidhuber이 [arXiv]에 게시한 'Who invented deep residual learning?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Deep Learning History",{"className":"page__taxonomy-item","children":["#","Deep Learning History"]}],["$","span","Residual Connections",{"className":"page__taxonomy-item","children":["#","Residual Connections"]}],["$","span","Recurrent Neural Networks (RNN)",{"className":"page__taxonomy-item","children":["#","Recurrent Neural Networks (RNN)"]}],["$","span","Long Short-Term Memory (LSTM)",{"className":"page__taxonomy-item","children":["#","Long Short-Term Memory (LSTM)"]}],["$","span","Feedforward Neural Networks (FNN)",{"className":"page__taxonomy-item","children":["#","Feedforward Neural Networks (FNN)"]}],["$","span","Highway Networks",{"className":"page__taxonomy-item","children":["#","Highway Networks"]}],["$","span","ResNet",{"className":"page__taxonomy-item","children":["#","ResNet"]}],["$","span","Vanishing Gradient",{"className":"page__taxonomy-item","children":["#","Vanishing Gradient"]}]]}]]}]]}],["$","article","2025-10-1-Voice-Evaluation-of-Reasoning-Ability-Diagnosing-the-Modality-Induced-Performance-Gap",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Voice-Evaluation-of-Reasoning-Ability-Diagnosing-the-Modality-Induced-Performance-Gap/","children":"[논문리뷰] Voice Evaluation of Reasoning Ability: Diagnosing the Modality-Induced Performance Gap"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hengfan Zhang이 [arXiv]에 게시한 'Voice Evaluation of Reasoning Ability: Diagnosing the Modality-Induced Performance Gap' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Voice AI",{"className":"page__taxonomy-item","children":["#","Voice AI"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Modality Gap",{"className":"page__taxonomy-item","children":["#","Modality Gap"]}],["$","span","Latency",{"className":"page__taxonomy-item","children":["#","Latency"]}],["$","span","Speech Recognition",{"className":"page__taxonomy-item","children":["#","Speech Recognition"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Real-time Systems",{"className":"page__taxonomy-item","children":["#","Real-time Systems"]}],["$","span","Conversational AI",{"className":"page__taxonomy-item","children":["#","Conversational AI"]}]]}]]}]]}],["$","article","2025-10-1-VitaBench-Benchmarking-LLM-Agents-with-Versatile-Interactive-Tasks-in-Real-world-Applications",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-VitaBench-Benchmarking-LLM-Agents-with-Versatile-Interactive-Tasks-in-Real-world-Applications/","children":"[논문리뷰] VitaBench: Benchmarking LLM Agents with Versatile Interactive Tasks in Real-world Applications"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'VitaBench: Benchmarking LLM Agents with Versatile Interactive Tasks in Real-world Applications' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Interactive Tasks",{"className":"page__taxonomy-item","children":["#","Interactive Tasks"]}],["$","span","Real-world Applications",{"className":"page__taxonomy-item","children":["#","Real-world Applications"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Multi-turn Conversation",{"className":"page__taxonomy-item","children":["#","Multi-turn Conversation"]}],["$","span","Task Complexity",{"className":"page__taxonomy-item","children":["#","Task Complexity"]}]]}]]}]]}],["$","article","2025-10-1-VisualOverload-Probing-Visual-Understanding-of-VLMs-in-Really-Dense-Scenes",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-VisualOverload-Probing-Visual-Understanding-of-VLMs-in-Really-Dense-Scenes/","children":"[논문리뷰] VisualOverload: Probing Visual Understanding of VLMs in Really Dense Scenes"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Muhammad Huzaifa이 [arXiv]에 게시한 'VisualOverload: Probing Visual Understanding of VLMs in Really Dense Scenes' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Visual Question Answering",{"className":"page__taxonomy-item","children":["#","Visual Question Answering"]}],["$","span","Multimodal Models",{"className":"page__taxonomy-item","children":["#","Multimodal Models"]}],["$","span","Dense Scenes",{"className":"page__taxonomy-item","children":["#","Dense Scenes"]}],["$","span","Fine-Grained Perception",{"className":"page__taxonomy-item","children":["#","Fine-Grained Perception"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Error Analysis",{"className":"page__taxonomy-item","children":["#","Error Analysis"]}],["$","span","Counting",{"className":"page__taxonomy-item","children":["#","Counting"]}],["$","span","OCR",{"className":"page__taxonomy-item","children":["#","OCR"]}]]}]]}]]}],["$","article","2025-10-1-Vision-Zero-Scalable-VLM-Self-Improvement-via-Strategic-Gamified-Self-Play",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Vision-Zero-Scalable-VLM-Self-Improvement-via-Strategic-Gamified-Self-Play/","children":"[논문리뷰] Vision-Zero: Scalable VLM Self-Improvement via Strategic Gamified Self-Play"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jing Shi이 [arXiv]에 게시한 'Vision-Zero: Scalable VLM Self-Improvement via Strategic Gamified Self-Play' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision-Language Models (VLMs)"]}],["$","span","Self-Play",{"className":"page__taxonomy-item","children":["#","Self-Play"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Gamification",{"className":"page__taxonomy-item","children":["#","Gamification"]}],["$","span","Data Efficiency",{"className":"page__taxonomy-item","children":["#","Data Efficiency"]}],["$","span","Strategic Reasoning",{"className":"page__taxonomy-item","children":["#","Strategic Reasoning"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Self-Improvement",{"className":"page__taxonomy-item","children":["#","Self-Improvement"]}]]}]]}]]}],["$","article","2025-10-1-TruthRL-Incentivizing-Truthful-LLMs-via-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-TruthRL-Incentivizing-Truthful-LLMs-via-Reinforcement-Learning/","children":"[논문리뷰] TruthRL: Incentivizing Truthful LLMs via Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'TruthRL: Incentivizing Truthful LLMs via Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Hallucination",{"className":"page__taxonomy-item","children":["#","LLM Hallucination"]}],["$","span","Truthfulness",{"className":"page__taxonomy-item","children":["#","Truthfulness"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Ternary Reward",{"className":"page__taxonomy-item","children":["#","Ternary Reward"]}],["$","span","Abstention",{"className":"page__taxonomy-item","children":["#","Abstention"]}],["$","span","Knowledge Boundary",{"className":"page__taxonomy-item","children":["#","Knowledge Boundary"]}],["$","span","GRPO",{"className":"page__taxonomy-item","children":["#","GRPO"]}],["$","span","RLHF",{"className":"page__taxonomy-item","children":["#","RLHF"]}]]}]]}]]}],["$","article","2025-10-1-Thinking-Sparks-Emergent-Attention-Heads-in-Reasoning-Models-During-Post-Training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Thinking-Sparks-Emergent-Attention-Heads-in-Reasoning-Models-During-Post-Training/","children":"[논문리뷰] Thinking Sparks!: Emergent Attention Heads in Reasoning Models During Post Training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Thinking Sparks!: Emergent Attention Heads in Reasoning Models During Post Training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Mechanistic Interpretability",{"className":"page__taxonomy-item","children":["#","Mechanistic Interpretability"]}],["$","span","Attention Heads",{"className":"page__taxonomy-item","children":["#","Attention Heads"]}],["$","span","Post-Training",{"className":"page__taxonomy-item","children":["#","Post-Training"]}],["$","span","Supervised Fine-Tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning (SFT)"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Circuit Analysis",{"className":"page__taxonomy-item","children":["#","Circuit Analysis"]}],["$","span","Reasoning Models",{"className":"page__taxonomy-item","children":["#","Reasoning Models"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}]]}]]}]]}],["$","article","2025-10-1-The-Dragon-Hatchling-The-Missing-Link-between-the-Transformer-and-Models-of-the-Brain",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-The-Dragon-Hatchling-The-Missing-Link-between-the-Transformer-and-Models-of-the-Brain/","children":"[논문리뷰] The Dragon Hatchling: The Missing Link between the Transformer and Models of the Brain"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'The Dragon Hatchling: The Missing Link between the Transformer and Models of the Brain' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Brain-Inspired AI",{"className":"page__taxonomy-item","children":["#","Brain-Inspired AI"]}],["$","span","Graph Neural Networks",{"className":"page__taxonomy-item","children":["#","Graph Neural Networks"]}],["$","span","Hebbian Learning",{"className":"page__taxonomy-item","children":["#","Hebbian Learning"]}],["$","span","Scale-Free Networks",{"className":"page__taxonomy-item","children":["#","Scale-Free Networks"]}],["$","span","Model Interpretability",{"className":"page__taxonomy-item","children":["#","Model Interpretability"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}]]}]]}]]}],["$","article","2025-10-1-Test-Time-Policy-Adaptation-for-Enhanced-Multi-Turn-Interactions-with-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Test-Time-Policy-Adaptation-for-Enhanced-Multi-Turn-Interactions-with-LLMs/","children":"[논문리뷰] Test-Time Policy Adaptation for Enhanced Multi-Turn Interactions with LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yao Shu이 [arXiv]에 게시한 'Test-Time Policy Adaptation for Enhanced Multi-Turn Interactions with LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Multi-turn Interaction",{"className":"page__taxonomy-item","children":["#","Multi-turn Interaction"]}],["$","span","Test-Time Adaptation",{"className":"page__taxonomy-item","children":["#","Test-Time Adaptation"]}],["$","span","Reinforcement Learning from Human Feedback",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning from Human Feedback"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Online Learning",{"className":"page__taxonomy-item","children":["#","Online Learning"]}],["$","span","Self-Correction",{"className":"page__taxonomy-item","children":["#","Self-Correction"]}]]}]]}]]}],["$","article","2025-10-1-TTT3R-3D-Reconstruction-as-Test-Time-Training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-TTT3R-3D-Reconstruction-as-Test-Time-Training/","children":"[논문리뷰] TTT3R: 3D Reconstruction as Test-Time Training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Anpei Chen이 [arXiv]에 게시한 'TTT3R: 3D Reconstruction as Test-Time Training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Reconstruction",{"className":"page__taxonomy-item","children":["#","3D Reconstruction"]}],["$","span","Test-Time Training (TTT)",{"className":"page__taxonomy-item","children":["#","Test-Time Training (TTT)"]}],["$","span","Recurrent Neural Networks (RNN)",{"className":"page__taxonomy-item","children":["#","Recurrent Neural Networks (RNN)"]}],["$","span","Online Learning",{"className":"page__taxonomy-item","children":["#","Online Learning"]}],["$","span","Length Generalization",{"className":"page__taxonomy-item","children":["#","Length Generalization"]}],["$","span","Associative Memory",{"className":"page__taxonomy-item","children":["#","Associative Memory"]}],["$","span","State Update Rule",{"className":"page__taxonomy-item","children":["#","State Update Rule"]}]]}]]}]]}],["$","article","2025-10-1-TAU-A-Benchmark-for-Cultural-Sound-Understanding-Beyond-Semantics",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-TAU-A-Benchmark-for-Cultural-Sound-Understanding-Beyond-Semantics/","children":"[논문리뷰] TAU: A Benchmark for Cultural Sound Understanding Beyond Semantics"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Szu-Chi Chen이 [arXiv]에 게시한 'TAU: A Benchmark for Cultural Sound Understanding Beyond Semantics' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Audio Language Models",{"className":"page__taxonomy-item","children":["#","Audio Language Models"]}],["$","span","Cultural Sound Understanding",{"className":"page__taxonomy-item","children":["#","Cultural Sound Understanding"]}],["$","span","Localized Benchmark",{"className":"page__taxonomy-item","children":["#","Localized Benchmark"]}],["$","span","Non-semantic Audio",{"className":"page__taxonomy-item","children":["#","Non-semantic Audio"]}],["$","span","Human-in-the-loop",{"className":"page__taxonomy-item","children":["#","Human-in-the-loop"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Taipei Soundscape",{"className":"page__taxonomy-item","children":["#","Taipei Soundscape"]}]]}]]}]]}],["$","article","2025-10-1-Stable-Cinemetrics-Structured-Taxonomy-and-Evaluation-for-Professional-Video-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Stable-Cinemetrics-Structured-Taxonomy-and-Evaluation-for-Professional-Video-Generation/","children":"[논문리뷰] Stable Cinemetrics : Structured Taxonomy and Evaluation for Professional Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Stable Cinemetrics : Structured Taxonomy and Evaluation for Professional Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Evaluation Framework",{"className":"page__taxonomy-item","children":["#","Evaluation Framework"]}],["$","span","Cinematic Control",{"className":"page__taxonomy-item","children":["#","Cinematic Control"]}],["$","span","Taxonomy",{"className":"page__taxonomy-item","children":["#","Taxonomy"]}],["$","span","Human Annotation",{"className":"page__taxonomy-item","children":["#","Human Annotation"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Text-to-Video",{"className":"page__taxonomy-item","children":["#","Text-to-Video"]}]]}]]}]]}],["$","article","2025-10-1-Specialization-after-Generalization-Towards-Understanding-Test-Time-Training-in-Foundation-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Specialization-after-Generalization-Towards-Understanding-Test-Time-Training-in-Foundation-Models/","children":"[논문리뷰] Specialization after Generalization: Towards Understanding Test-Time Training in Foundation Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Specialization after Generalization: Towards Understanding Test-Time Training in Foundation Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Test-Time Training (TTT)",{"className":"page__taxonomy-item","children":["#","Test-Time Training (TTT)"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Underparameterization",{"className":"page__taxonomy-item","children":["#","Underparameterization"]}],["$","span","Sparse Autoencoders (SAE)",{"className":"page__taxonomy-item","children":["#","Sparse Autoencoders (SAE)"]}],["$","span","Linear Representation Hypothesis (LRH)",{"className":"page__taxonomy-item","children":["#","Linear Representation Hypothesis (LRH)"]}],["$","span","Specialization",{"className":"page__taxonomy-item","children":["#","Specialization"]}],["$","span","Scaling Laws",{"className":"page__taxonomy-item","children":["#","Scaling Laws"]}],["$","span","In-Distribution Data",{"className":"page__taxonomy-item","children":["#","In-Distribution Data"]}]]}]]}]]}],["$","article","2025-10-1-Regression-Language-Models-for-Code",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Regression-Language-Models-for-Code/","children":"[논문리뷰] Regression Language Models for Code"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Regression Language Models for Code' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Regression Language Model",{"className":"page__taxonomy-item","children":["#","Regression Language Model"]}],["$","span","Code Performance Prediction",{"className":"page__taxonomy-item","children":["#","Code Performance Prediction"]}],["$","span","Static Analysis",{"className":"page__taxonomy-item","children":["#","Static Analysis"]}],["$","span","Neural Architecture Search",{"className":"page__taxonomy-item","children":["#","Neural Architecture Search"]}],["$","span","Text-to-Text Regression",{"className":"page__taxonomy-item","children":["#","Text-to-Text Regression"]}],["$","span","Multi-task Learning",{"className":"page__taxonomy-item","children":["#","Multi-task Learning"]}],["$","span","T5Gemma",{"className":"page__taxonomy-item","children":["#","T5Gemma"]}],["$","span","ONNX",{"className":"page__taxonomy-item","children":["#","ONNX"]}]]}]]}]]}],["$","article","2025-10-1-ProfVLM-A-Lightweight-Video-Language-Model-for-Multi-View-Proficiency-Estimation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-ProfVLM-A-Lightweight-Video-Language-Model-for-Multi-View-Proficiency-Estimation/","children":"[논문리뷰] ProfVLM: A Lightweight Video-Language Model for Multi-View Proficiency Estimation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Antonio Liotta이 [arXiv]에 게시한 'ProfVLM: A Lightweight Video-Language Model for Multi-View Proficiency Estimation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video-Language Model",{"className":"page__taxonomy-item","children":["#","Video-Language Model"]}],["$","span","Proficiency Estimation",{"className":"page__taxonomy-item","children":["#","Proficiency Estimation"]}],["$","span","Multi-View Video",{"className":"page__taxonomy-item","children":["#","Multi-View Video"]}],["$","span","Action Quality Assessment",{"className":"page__taxonomy-item","children":["#","Action Quality Assessment"]}],["$","span","Lightweight Model",{"className":"page__taxonomy-item","children":["#","Lightweight Model"]}],["$","span","Generative Feedback",{"className":"page__taxonomy-item","children":["#","Generative Feedback"]}]]}]]}]]}],["$","article","2025-10-1-Probing-the-Critical-Point-CritPt-of-AI-Reasoning-a-Frontier-Physics-Research-Benchmark",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Probing-the-Critical-Point-CritPt-of-AI-Reasoning-a-Frontier-Physics-Research-Benchmark/","children":"[논문리뷰] Probing the Critical Point (CritPt) of AI Reasoning: a Frontier Physics Research Benchmark"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Penghao Zhu이 [arXiv]에 게시한 'Probing the Critical Point (CritPt) of AI Reasoning: a Frontier Physics Research Benchmark' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Reasoning",{"className":"page__taxonomy-item","children":["#","AI Reasoning"]}],["$","span","Physics Research",{"className":"page__taxonomy-item","children":["#","Physics Research"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Scientific Benchmark",{"className":"page__taxonomy-item","children":["#","Scientific Benchmark"]}],["$","span","Frontier Physics",{"className":"page__taxonomy-item","children":["#","Frontier Physics"]}],["$","span","Problem Solving",{"className":"page__taxonomy-item","children":["#","Problem Solving"]}],["$","span","Model Reliability",{"className":"page__taxonomy-item","children":["#","Model Reliability"]}],["$","span","Auto-grading",{"className":"page__taxonomy-item","children":["#","Auto-grading"]}]]}]]}]]}],["$","article","2025-10-1-OffTopicEval-When-Large-Language-Models-Enter-the-Wrong-Chat-Almost-Always",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-OffTopicEval-When-Large-Language-Models-Enter-the-Wrong-Chat-Almost-Always/","children":"[논문리뷰] OffTopicEval: When Large Language Models Enter the Wrong Chat, Almost Always!"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'OffTopicEval: When Large Language Models Enter the Wrong Chat, Almost Always!' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Operational Safety",{"className":"page__taxonomy-item","children":["#","Operational Safety"]}],["$","span","Out-of-Domain (OOD)",{"className":"page__taxonomy-item","children":["#","Out-of-Domain (OOD)"]}],["$","span","Prompt Steering",{"className":"page__taxonomy-item","children":["#","Prompt Steering"]}],["$","span","Jailbreak Attacks",{"className":"page__taxonomy-item","children":["#","Jailbreak Attacks"]}],["$","span","Evaluation Benchmark",{"className":"page__taxonomy-item","children":["#","Evaluation Benchmark"]}],["$","span","Refusal Rate",{"className":"page__taxonomy-item","children":["#","Refusal Rate"]}]]}]]}]]}],["$","article","2025-10-1-OceanGym-A-Benchmark-Environment-for-Underwater-Embodied-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-OceanGym-A-Benchmark-Environment-for-Underwater-Embodied-Agents/","children":"[논문리뷰] OceanGym: A Benchmark Environment for Underwater Embodied Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'OceanGym: A Benchmark Environment for Underwater Embodied Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Underwater Robotics",{"className":"page__taxonomy-item","children":["#","Underwater Robotics"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Benchmark Environment",{"className":"page__taxonomy-item","children":["#","Benchmark Environment"]}],["$","span","Multi-modal Large Language Models",{"className":"page__taxonomy-item","children":["#","Multi-modal Large Language Models"]}],["$","span","Autonomous Underwater Vehicles",{"className":"page__taxonomy-item","children":["#","Autonomous Underwater Vehicles"]}],["$","span","Perception",{"className":"page__taxonomy-item","children":["#","Perception"]}],["$","span","Decision-Making",{"className":"page__taxonomy-item","children":["#","Decision-Making"]}],["$","span","Simulation",{"className":"page__taxonomy-item","children":["#","Simulation"]}]]}]]}]]}],["$","article","2025-10-1-MotionRAG-Motion-Retrieval-Augmented-Image-to-Video-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-MotionRAG-Motion-Retrieval-Augmented-Image-to-Video-Generation/","children":"[논문리뷰] MotionRAG: Motion Retrieval-Augmented Image-to-Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Limin Wang이 [arXiv]에 게시한 'MotionRAG: Motion Retrieval-Augmented Image-to-Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image-to-Video Generation",{"className":"page__taxonomy-item","children":["#","Image-to-Video Generation"]}],["$","span","Motion Transfer",{"className":"page__taxonomy-item","children":["#","Motion Transfer"]}],["$","span","Retrieval-Augmented Generation (RAG)",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation (RAG)"]}],["$","span","In-Context Learning",{"className":"page__taxonomy-item","children":["#","In-Context Learning"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Video Diffusion",{"className":"page__taxonomy-item","children":["#","Video Diffusion"]}],["$","span","Motion Realism",{"className":"page__taxonomy-item","children":["#","Motion Realism"]}]]}]]}]]}],["$","article","2025-10-1-More-Thought-Less-Accuracy-On-the-Dual-Nature-of-Reasoning-in-Vision-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-More-Thought-Less-Accuracy-On-the-Dual-Nature-of-Reasoning-in-Vision-Language-Models/","children":"[논문리뷰] More Thought, Less Accuracy? On the Dual Nature of Reasoning in Vision-Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Fabian Waschkowski이 [arXiv]에 게시한 'More Thought, Less Accuracy? On the Dual Nature of Reasoning in Vision-Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Visual Forgetting",{"className":"page__taxonomy-item","children":["#","Visual Forgetting"]}],["$","span","Perceptual Grounding",{"className":"page__taxonomy-item","children":["#","Perceptual Grounding"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Visual Anchors",{"className":"page__taxonomy-item","children":["#","Visual Anchors"]}]]}]]}]]}],["$","article","2025-10-1-Mem-a-Learning-Memory-Construction-via-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Mem-a-Learning-Memory-Construction-via-Reinforcement-Learning/","children":"[논문리뷰] Mem-α: Learning Memory Construction via Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuzhen Mao이 [arXiv]에 게시한 'Mem-α: Learning Memory Construction via Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","External Memory",{"className":"page__taxonomy-item","children":["#","External Memory"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Memory Management",{"className":"page__taxonomy-item","children":["#","Memory Management"]}],["$","span","Long-Context Understanding",{"className":"page__taxonomy-item","children":["#","Long-Context Understanding"]}],["$","span","Tool Learning",{"className":"page__taxonomy-item","children":["#","Tool Learning"]}],["$","span","RAG",{"className":"page__taxonomy-item","children":["#","RAG"]}],["$","span","Memory Architecture",{"className":"page__taxonomy-item","children":["#","Memory Architecture"]}]]}]]}]]}],["$","article","2025-10-1-MCPMark-A-Benchmark-for-Stress-Testing-Realistic-and-Comprehensive-MCP-Use",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-MCPMark-A-Benchmark-for-Stress-Testing-Realistic-and-Comprehensive-MCP-Use/","children":"[논문리뷰] MCPMark: A Benchmark for Stress-Testing Realistic and Comprehensive MCP Use"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'MCPMark: A Benchmark for Stress-Testing Realistic and Comprehensive MCP Use' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Model Context Protocol",{"className":"page__taxonomy-item","children":["#","Model Context Protocol"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","CRUD Operations",{"className":"page__taxonomy-item","children":["#","CRUD Operations"]}],["$","span","Workflow Automation",{"className":"page__taxonomy-item","children":["#","Workflow Automation"]}],["$","span","Stress Testing",{"className":"page__taxonomy-item","children":["#","Stress Testing"]}],["$","span","Evaluation",{"className":"page__taxonomy-item","children":["#","Evaluation"]}]]}]]}]]}],["$","article","2025-10-1-MANI-Pure-Magnitude-Adaptive-Noise-Injection-for-Adversarial-Purification",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-MANI-Pure-Magnitude-Adaptive-Noise-Injection-for-Adversarial-Purification/","children":"[논문리뷰] MANI-Pure: Magnitude-Adaptive Noise Injection for Adversarial Purification"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhiming Luo이 [arXiv]에 게시한 'MANI-Pure: Magnitude-Adaptive Noise Injection for Adversarial Purification' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Adversarial Purification",{"className":"page__taxonomy-item","children":["#","Adversarial Purification"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Frequency Domain",{"className":"page__taxonomy-item","children":["#","Frequency Domain"]}],["$","span","Adaptive Noise Injection",{"className":"page__taxonomy-item","children":["#","Adaptive Noise Injection"]}],["$","span","Robustness",{"className":"page__taxonomy-item","children":["#","Robustness"]}],["$","span","Image Security",{"className":"page__taxonomy-item","children":["#","Image Security"]}],["$","span","Magnitude Spectrum",{"className":"page__taxonomy-item","children":["#","Magnitude Spectrum"]}]]}]]}]]}],["$","article","2025-10-1-Learning-to-See-Before-Seeing-Demystifying-LLM-Visual-Priors-from-Language-Pre-training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Learning-to-See-Before-Seeing-Demystifying-LLM-Visual-Priors-from-Language-Pre-training/","children":"[논문리뷰] Learning to See Before Seeing: Demystifying LLM Visual Priors from Language Pre-training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Koustuv Sinha이 [arXiv]에 게시한 'Learning to See Before Seeing: Demystifying LLM Visual Priors from Language Pre-training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Visual Priors",{"className":"page__taxonomy-item","children":["#","LLM Visual Priors"]}],["$","span","Language Pre-training",{"className":"page__taxonomy-item","children":["#","Language Pre-training"]}],["$","span","Multimodal LLM",{"className":"page__taxonomy-item","children":["#","Multimodal LLM"]}],["$","span","Data Mixture Optimization",{"className":"page__taxonomy-item","children":["#","Data Mixture Optimization"]}],["$","span","Reasoning Prior",{"className":"page__taxonomy-item","children":["#","Reasoning Prior"]}],["$","span","Perception Prior",{"className":"page__taxonomy-item","children":["#","Perception Prior"]}],["$","span","VQA",{"className":"page__taxonomy-item","children":["#","VQA"]}],["$","span","MLE-Bench",{"className":"page__taxonomy-item","children":["#","MLE-Bench"]}]]}]]}]]}],["$","article","2025-10-1-Learning-Human-Perceived-Fakeness-in-AI-Generated-Videos-via-Multimodal-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Learning-Human-Perceived-Fakeness-in-AI-Generated-Videos-via-Multimodal-LLMs/","children":"[논문리뷰] Learning Human-Perceived Fakeness in AI-Generated Videos via Multimodal LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Learning Human-Perceived Fakeness in AI-Generated Videos via Multimodal LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI-Generated Videos",{"className":"page__taxonomy-item","children":["#","AI-Generated Videos"]}],["$","span","Deepfake Detection",{"className":"page__taxonomy-item","children":["#","Deepfake Detection"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Human Perception",{"className":"page__taxonomy-item","children":["#","Human Perception"]}],["$","span","Video Generation Evaluation",{"className":"page__taxonomy-item","children":["#","Video Generation Evaluation"]}],["$","span","Spatiotemporal Annotation",{"className":"page__taxonomy-item","children":["#","Spatiotemporal Annotation"]}],["$","span","Reward Modeling",{"className":"page__taxonomy-item","children":["#","Reward Modeling"]}]]}]]}]]}],["$","article","2025-10-1-LayerD-Decomposing-Raster-Graphic-Designs-into-Layers",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-LayerD-Decomposing-Raster-Graphic-Designs-into-Layers/","children":"[논문리뷰] LayerD: Decomposing Raster Graphic Designs into Layers"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kota Yamaguchi이 [arXiv]에 게시한 'LayerD: Decomposing Raster Graphic Designs into Layers' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Graphic Design",{"className":"page__taxonomy-item","children":["#","Graphic Design"]}],["$","span","Image Decomposition",{"className":"page__taxonomy-item","children":["#","Image Decomposition"]}],["$","span","Layer Extraction",{"className":"page__taxonomy-item","children":["#","Layer Extraction"]}],["$","span","Image Matting",{"className":"page__taxonomy-item","children":["#","Image Matting"]}],["$","span","Background Completion",{"className":"page__taxonomy-item","children":["#","Background Completion"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}],["$","span","Creative AI",{"className":"page__taxonomy-item","children":["#","Creative AI"]}],["$","span","Dynamic Time Warping",{"className":"page__taxonomy-item","children":["#","Dynamic Time Warping"]}]]}]]}]]}],["$","article","2025-10-1-Knowledge-Homophily-in-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Knowledge-Homophily-in-Large-Language-Models/","children":"[논문리뷰] Knowledge Homophily in Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Nedim Lipka이 [arXiv]에 게시한 'Knowledge Homophily in Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Knowledge Homophily",{"className":"page__taxonomy-item","children":["#","Knowledge Homophily"]}],["$","span","Graph Neural Networks",{"className":"page__taxonomy-item","children":["#","Graph Neural Networks"]}],["$","span","Knowledge Graph",{"className":"page__taxonomy-item","children":["#","Knowledge Graph"]}],["$","span","Knowledge Injection",{"className":"page__taxonomy-item","children":["#","Knowledge Injection"]}],["$","span","Question Answering",{"className":"page__taxonomy-item","children":["#","Question Answering"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Knowledge Retrieval",{"className":"page__taxonomy-item","children":["#","Knowledge Retrieval"]}]]}]]}]]}],["$","article","2025-10-1-InfoAgent-Advancing-Autonomous-Information-Seeking-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-InfoAgent-Advancing-Autonomous-Information-Seeking-Agents/","children":"[논문리뷰] InfoAgent: Advancing Autonomous Information-Seeking Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'InfoAgent: Advancing Autonomous Information-Seeking Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Information Seeking",{"className":"page__taxonomy-item","children":["#","Information Seeking"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Data Synthesis",{"className":"page__taxonomy-item","children":["#","Data Synthesis"]}],["$","span","Web Search Tools",{"className":"page__taxonomy-item","children":["#","Web Search Tools"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Deep Research Agents",{"className":"page__taxonomy-item","children":["#","Deep Research Agents"]}]]}]]}]]}],["$","article","2025-10-1-IMG-Calibrating-Diffusion-Models-via-Implicit-Multimodal-Guidance",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-IMG-Calibrating-Diffusion-Models-via-Implicit-Multimodal-Guidance/","children":"[논문리뷰] IMG: Calibrating Diffusion Models via Implicit Multimodal Guidance"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'IMG: Calibrating Diffusion Models via Implicit Multimodal Guidance' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Multimodal Alignment",{"className":"page__taxonomy-item","children":["#","Multimodal Alignment"]}],["$","span","MLLM",{"className":"page__taxonomy-item","children":["#","MLLM"]}],["$","span","Image Re-generation",{"className":"page__taxonomy-item","children":["#","Image Re-generation"]}],["$","span","Preference Learning",{"className":"page__taxonomy-item","children":["#","Preference Learning"]}],["$","span","Implicit Guidance",{"className":"page__taxonomy-item","children":["#","Implicit Guidance"]}],["$","span","Text-to-Image",{"className":"page__taxonomy-item","children":["#","Text-to-Image"]}]]}]]}]]}],["$","article","2025-10-1-Humanline-Online-Alignment-as-Perceptual-Loss",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Humanline-Online-Alignment-as-Perceptual-Loss/","children":"[논문리뷰] Humanline: Online Alignment as Perceptual Loss"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Humanline: Online Alignment as Perceptual Loss' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Alignment",{"className":"page__taxonomy-item","children":["#","LLM Alignment"]}],["$","span","Online RLHF",{"className":"page__taxonomy-item","children":["#","Online RLHF"]}],["$","span","Offline RLHF",{"className":"page__taxonomy-item","children":["#","Offline RLHF"]}],["$","span","Prospect Theory",{"className":"page__taxonomy-item","children":["#","Prospect Theory"]}],["$","span","Perceptual Loss",{"className":"page__taxonomy-item","children":["#","Perceptual Loss"]}],["$","span","Human-Centric AI",{"className":"page__taxonomy-item","children":["#","Human-Centric AI"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}]]}]]}]]}],["$","article","2025-10-1-Ferret-UI-Lite-Lessons-from-Building-Small-On-Device-GUI-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Ferret-UI-Lite-Lessons-from-Building-Small-On-Device-GUI-Agents/","children":"[논문리뷰] Ferret-UI Lite: Lessons from Building Small On-Device GUI Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Ferret-UI Lite: Lessons from Building Small On-Device GUI Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","GUI Agents",{"className":"page__taxonomy-item","children":["#","GUI Agents"]}],["$","span","On-Device AI",{"className":"page__taxonomy-item","children":["#","On-Device AI"]}],["$","span","Multimodal LLM",{"className":"page__taxonomy-item","children":["#","Multimodal LLM"]}],["$","span","GUI Grounding",{"className":"page__taxonomy-item","children":["#","GUI Grounding"]}],["$","span","GUI Navigation",{"className":"page__taxonomy-item","children":["#","GUI Navigation"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Synthetic Data",{"className":"page__taxonomy-item","children":["#","Synthetic Data"]}]]}]]}]]}],["$","article","2025-10-1-Estimating-Time-Series-Foundation-Model-Transferability-via-In-Context-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Estimating-Time-Series-Foundation-Model-Transferability-via-In-Context-Learning/","children":"[논문리뷰] Estimating Time Series Foundation Model Transferability via In-Context Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jun Qi이 [arXiv]에 게시한 'Estimating Time Series Foundation Model Transferability via In-Context Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Time Series Foundation Models",{"className":"page__taxonomy-item","children":["#","Time Series Foundation Models"]}],["$","span","Transferability Estimation",{"className":"page__taxonomy-item","children":["#","Transferability Estimation"]}],["$","span","In-Context Learning",{"className":"page__taxonomy-item","children":["#","In-Context Learning"]}],["$","span","Tabular Foundation Models",{"className":"page__taxonomy-item","children":["#","Tabular Foundation Models"]}],["$","span","Model Selection",{"className":"page__taxonomy-item","children":["#","Model Selection"]}],["$","span","Entropy Profile",{"className":"page__taxonomy-item","children":["#","Entropy Profile"]}],["$","span","Meta-learning",{"className":"page__taxonomy-item","children":["#","Meta-learning"]}],["$","span","Forecasting",{"className":"page__taxonomy-item","children":["#","Forecasting"]}]]}]]}]]}],["$","article","2025-10-1-EntroPE-Entropy-Guided-Dynamic-Patch-Encoder-for-Time-Series-Forecasting",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-EntroPE-Entropy-Guided-Dynamic-Patch-Encoder-for-Time-Series-Forecasting/","children":"[논문리뷰] EntroPE: Entropy-Guided Dynamic Patch Encoder for Time Series Forecasting"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'EntroPE: Entropy-Guided Dynamic Patch Encoder for Time Series Forecasting' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Time Series Forecasting",{"className":"page__taxonomy-item","children":["#","Time Series Forecasting"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Dynamic Patching",{"className":"page__taxonomy-item","children":["#","Dynamic Patching"]}],["$","span","Entropy",{"className":"page__taxonomy-item","children":["#","Entropy"]}],["$","span","Predictive Uncertainty",{"className":"page__taxonomy-item","children":["#","Predictive Uncertainty"]}],["$","span","Adaptive Encoding",{"className":"page__taxonomy-item","children":["#","Adaptive Encoding"]}],["$","span","Attention Mechanisms",{"className":"page__taxonomy-item","children":["#","Attention Mechanisms"]}],["$","span","Causal Transformer",{"className":"page__taxonomy-item","children":["#","Causal Transformer"]}]]}]]}]]}],["$","article","2025-10-1-Efficient-Audio-Visual-Speech-Separation-with-Discrete-Lip-Semantics-and-Multi-Scale-Global-Local-Attention",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Efficient-Audio-Visual-Speech-Separation-with-Discrete-Lip-Semantics-and-Multi-Scale-Global-Local-Attention/","children":"[논문리뷰] Efficient Audio-Visual Speech Separation with Discrete Lip Semantics and Multi-Scale Global-Local Attention"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Efficient Audio-Visual Speech Separation with Discrete Lip Semantics and Multi-Scale Global-Local Attention' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Audio-Visual Speech Separation",{"className":"page__taxonomy-item","children":["#","Audio-Visual Speech Separation"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}],["$","span","Efficiency",{"className":"page__taxonomy-item","children":["#","Efficiency"]}],["$","span","Discrete Lip Semantics",{"className":"page__taxonomy-item","children":["#","Discrete Lip Semantics"]}],["$","span","Global-Local Attention",{"className":"page__taxonomy-item","children":["#","Global-Local Attention"]}],["$","span","Lightweight Models",{"className":"page__taxonomy-item","children":["#","Lightweight Models"]}],["$","span","VQ-VAE",{"className":"page__taxonomy-item","children":["#","VQ-VAE"]}]]}]]}]]}],["$","article","2025-10-1-DeepScientist-Advancing-Frontier-Pushing-Scientific-Findings-Progressively",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-DeepScientist-Advancing-Frontier-Pushing-Scientific-Findings-Progressively/","children":"[논문리뷰] DeepScientist: Advancing Frontier-Pushing Scientific Findings Progressively"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DeepScientist: Advancing Frontier-Pushing Scientific Findings Progressively' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Scientist",{"className":"page__taxonomy-item","children":["#","AI Scientist"]}],["$","span","Autonomous Scientific Discovery",{"className":"page__taxonomy-item","children":["#","Autonomous Scientific Discovery"]}],["$","span","Bayesian Optimization",{"className":"page__taxonomy-item","children":["#","Bayesian Optimization"]}],["$","span","LLM-based Agents",{"className":"page__taxonomy-item","children":["#","LLM-based Agents"]}],["$","span","SOTA-Surpassing",{"className":"page__taxonomy-item","children":["#","SOTA-Surpassing"]}],["$","span","Findings Memory",{"className":"page__taxonomy-item","children":["#","Findings Memory"]}],["$","span","Exploration-Exploitation",{"className":"page__taxonomy-item","children":["#","Exploration-Exploitation"]}]]}]]}]]}],["$","article","2025-10-1-DC-VideoGen-Efficient-Video-Generation-with-Deep-Compression-Video-Autoencoder",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-DC-VideoGen-Efficient-Video-Generation-with-Deep-Compression-Video-Autoencoder/","children":"[논문리뷰] DC-VideoGen: Efficient Video Generation with Deep Compression Video Autoencoder"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DC-VideoGen: Efficient Video Generation with Deep Compression Video Autoencoder' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Video Autoencoder",{"className":"page__taxonomy-item","children":["#","Video Autoencoder"]}],["$","span","Deep Compression",{"className":"page__taxonomy-item","children":["#","Deep Compression"]}],["$","span","Model Acceleration",{"className":"page__taxonomy-item","children":["#","Model Acceleration"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Latent Space",{"className":"page__taxonomy-item","children":["#","Latent Space"]}],["$","span","Temporal Modeling",{"className":"page__taxonomy-item","children":["#","Temporal Modeling"]}]]}]]}]]}],["$","article","2025-10-1-DA2-Depth-Anything-in-Any-Direction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-DA2-Depth-Anything-in-Any-Direction/","children":"[논문리뷰] DA^2: Depth Anything in Any Direction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DA^2: Depth Anything in Any Direction' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Panoramic Depth Estimation",{"className":"page__taxonomy-item","children":["#","Panoramic Depth Estimation"]}],["$","span","Zero-shot Generalization",{"className":"page__taxonomy-item","children":["#","Zero-shot Generalization"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","SphereViT",{"className":"page__taxonomy-item","children":["#","SphereViT"]}],["$","span","Spherical Geometry",{"className":"page__taxonomy-item","children":["#","Spherical Geometry"]}],["$","span","360-degree Imaging",{"className":"page__taxonomy-item","children":["#","360-degree Imaging"]}],["$","span","Vision Transformer",{"className":"page__taxonomy-item","children":["#","Vision Transformer"]}]]}]]}]]}],["$","article","2025-10-1-Context-Is-What-You-Need-The-Maximum-Effective-Context-Window-for-Real-World-Limits-of-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Context-Is-What-You-Need-The-Maximum-Effective-Context-Window-for-Real-World-Limits-of-LLMs/","children":"[논문리뷰] Context Is What You Need: The Maximum Effective Context Window for Real World Limits of LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"normanpaulsen이 [arXiv]에 게시한 'Context Is What You Need: The Maximum Effective Context Window for Real World Limits of LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Context Window",{"className":"page__taxonomy-item","children":["#","Context Window"]}],["$","span","Effective Context Window",{"className":"page__taxonomy-item","children":["#","Effective Context Window"]}],["$","span","Model Performance",{"className":"page__taxonomy-item","children":["#","Model Performance"]}],["$","span","Hallucination Rates",{"className":"page__taxonomy-item","children":["#","Hallucination Rates"]}],["$","span","RAG Systems",{"className":"page__taxonomy-item","children":["#","RAG Systems"]}],["$","span","Token Limits",{"className":"page__taxonomy-item","children":["#","Token Limits"]}]]}]]}]]}],["$","article","2025-10-1-BuildBench-Benchmarking-LLM-Agents-on-Compiling-Real-World-Open-Source-Software",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-BuildBench-Benchmarking-LLM-Agents-on-Compiling-Real-World-Open-Source-Software/","children":"[논문리뷰] BuildBench: Benchmarking LLM Agents on Compiling Real-World Open-Source Software"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'BuildBench: Benchmarking LLM Agents on Compiling Real-World Open-Source Software' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Open-Source Software",{"className":"page__taxonomy-item","children":["#","Open-Source Software"]}],["$","span","Compilation",{"className":"page__taxonomy-item","children":["#","Compilation"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Software Engineering",{"className":"page__taxonomy-item","children":["#","Software Engineering"]}],["$","span","Error Resolution",{"className":"page__taxonomy-item","children":["#","Error Resolution"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}]]}]]}]]}],["$","article","2025-10-1-Benefits-and-Pitfalls-of-Reinforcement-Learning-for-Language-Model-Planning-A-Theoretical-Perspective",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Benefits-and-Pitfalls-of-Reinforcement-Learning-for-Language-Model-Planning-A-Theoretical-Perspective/","children":"[논문리뷰] Benefits and Pitfalls of Reinforcement Learning for Language Model Planning: A Theoretical Perspective"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Benefits and Pitfalls of Reinforcement Learning for Language Model Planning: A Theoretical Perspective' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Planning",{"className":"page__taxonomy-item","children":["#","Planning"]}],["$","span","Policy Gradient",{"className":"page__taxonomy-item","children":["#","Policy Gradient"]}],["$","span","Q-learning",{"className":"page__taxonomy-item","children":["#","Q-learning"]}],["$","span","Supervised Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning"]}],["$","span","Diversity Collapse",{"className":"page__taxonomy-item","children":["#","Diversity Collapse"]}],["$","span","Reward Hacking",{"className":"page__taxonomy-item","children":["#","Reward Hacking"]}]]}]]}]]}],["$","article","2025-10-1-Attention-as-a-Compass-Efficient-Exploration-for-Process-Supervised-RL-in-Reasoning-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Attention-as-a-Compass-Efficient-Exploration-for-Process-Supervised-RL-in-Reasoning-Models/","children":"[논문리뷰] Attention as a Compass: Efficient Exploration for Process-Supervised RL in Reasoning Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Attention as a Compass: Efficient Exploration for Process-Supervised RL in Reasoning Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Process-Supervised RL",{"className":"page__taxonomy-item","children":["#","Process-Supervised RL"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reasoning Models",{"className":"page__taxonomy-item","children":["#","Reasoning Models"]}],["$","span","Attention Mechanism",{"className":"page__taxonomy-item","children":["#","Attention Mechanism"]}],["$","span","Efficient Exploration",{"className":"page__taxonomy-item","children":["#","Efficient Exploration"]}],["$","span","Adaptive Sampling",{"className":"page__taxonomy-item","children":["#","Adaptive Sampling"]}],["$","span","Off-Policy Training",{"className":"page__taxonomy-item","children":["#","Off-Policy Training"]}]]}]]}]]}],["$","article","2025-10-1-A-Cartography-of-Open-Collaboration-in-Open-Source-AI-Mapping-Practices-Motivations-and-Governance-in-14-Open-Large-Language-Model-Projects",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-A-Cartography-of-Open-Collaboration-in-Open-Source-AI-Mapping-Practices-Motivations-and-Governance-in-14-Open-Large-Language-Model-Projects/","children":"[논문리뷰] A Cartography of Open Collaboration in Open Source AI: Mapping Practices, Motivations, and Governance in 14 Open Large Language Model Projects"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jennifer Ding이 [arXiv]에 게시한 'A Cartography of Open Collaboration in Open Source AI: Mapping Practices, Motivations, and Governance in 14 Open Large Language Model Projects' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Open Source AI",{"className":"page__taxonomy-item","children":["#","Open Source AI"]}],["$","span","LLM Development",{"className":"page__taxonomy-item","children":["#","LLM Development"]}],["$","span","Open Collaboration",{"className":"page__taxonomy-item","children":["#","Open Collaboration"]}],["$","span","Governance Models",{"className":"page__taxonomy-item","children":["#","Governance Models"]}],["$","span","Developer Motivations",{"className":"page__taxonomy-item","children":["#","Developer Motivations"]}],["$","span","Community Engagement",{"className":"page__taxonomy-item","children":["#","Community Engagement"]}],["$","span","AI Ecosystem",{"className":"page__taxonomy-item","children":["#","AI Ecosystem"]}]]}]]}]]}],["$","article","2025-9-30-Visual-Jigsaw-Post-Training-Improves-MLLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-30-Visual-Jigsaw-Post-Training-Improves-MLLMs/","children":"[논문리뷰] Visual Jigsaw Post-Training Improves MLLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Lewei Lu이 [arXiv]에 게시한 'Visual Jigsaw Post-Training Improves MLLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-30 13:52:24+0900","children":"2025년 9월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","MLLMs",{"className":"page__taxonomy-item","children":["#","MLLMs"]}],["$","span","Post-training",{"className":"page__taxonomy-item","children":["#","Post-training"]}],["$","span","Self-supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-supervised Learning"]}],["$","span","Visual Understanding",{"className":"page__taxonomy-item","children":["#","Visual Understanding"]}],["$","span","Jigsaw Puzzles",{"className":"page__taxonomy-item","children":["#","Jigsaw Puzzles"]}],["$","span","RLVR",{"className":"page__taxonomy-item","children":["#","RLVR"]}],["$","span","Multimodal Perception",{"className":"page__taxonomy-item","children":["#","Multimodal Perception"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}]]}]]}]]}],["$","article","2025-9-30-StableToken-A-Noise-Robust-Semantic-Speech-Tokenizer-for-Resilient-SpeechLLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-30-StableToken-A-Noise-Robust-Semantic-Speech-Tokenizer-for-Resilient-SpeechLLMs/","children":"[논문리뷰] StableToken: A Noise-Robust Semantic Speech Tokenizer for Resilient SpeechLLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wei Jia이 [arXiv]에 게시한 'StableToken: A Noise-Robust Semantic Speech Tokenizer for Resilient SpeechLLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-30 13:52:24+0900","children":"2025년 9월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Speech Tokenizer",{"className":"page__taxonomy-item","children":["#","Speech Tokenizer"]}],["$","span","Noise Robustness",{"className":"page__taxonomy-item","children":["#","Noise Robustness"]}],["$","span","Semantic Tokens",{"className":"page__taxonomy-item","children":["#","Semantic Tokens"]}],["$","span","SpeechLLMs",{"className":"page__taxonomy-item","children":["#","SpeechLLMs"]}],["$","span","Voting-LFQ",{"className":"page__taxonomy-item","children":["#","Voting-LFQ"]}],["$","span","Consensus Training",{"className":"page__taxonomy-item","children":["#","Consensus Training"]}],["$","span","Automatic Speech Recognition",{"className":"page__taxonomy-item","children":["#","Automatic Speech Recognition"]}],["$","span","Speech Synthesis",{"className":"page__taxonomy-item","children":["#","Speech Synthesis"]}]]}]]}]]}],["$","article","2025-9-30-SLA-Beyond-Sparsity-in-Diffusion-Transformers-via-Fine-Tunable-Sparse-Linear-Attention",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-30-SLA-Beyond-Sparsity-in-Diffusion-Transformers-via-Fine-Tunable-Sparse-Linear-Attention/","children":"[논문리뷰] SLA: Beyond Sparsity in Diffusion Transformers via Fine-Tunable Sparse-Linear Attention"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'SLA: Beyond Sparsity in Diffusion Transformers via Fine-Tunable Sparse-Linear Attention' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-30 13:52:24+0900","children":"2025년 9월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Transformers",{"className":"page__taxonomy-item","children":["#","Diffusion Transformers"]}],["$","span","Sparse Attention",{"className":"page__taxonomy-item","children":["#","Sparse Attention"]}],["$","span","Linear Attention",{"className":"page__taxonomy-item","children":["#","Linear Attention"]}],["$","span","Model Acceleration",{"className":"page__taxonomy-item","children":["#","Model Acceleration"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Attention Mechanisms",{"className":"page__taxonomy-item","children":["#","Attention Mechanisms"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}]]}]]}]]}],["$","article","2025-9-30-SANA-Video-Efficient-Video-Generation-with-Block-Linear-Diffusion-Transformer",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-30-SANA-Video-Efficient-Video-Generation-with-Block-Linear-Diffusion-Transformer/","children":"[논문리뷰] SANA-Video: Efficient Video Generation with Block Linear Diffusion Transformer"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'SANA-Video: Efficient Video Generation with Block Linear Diffusion Transformer' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-30 13:52:24+0900","children":"2025년 9월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Diffusion Model",{"className":"page__taxonomy-item","children":["#","Diffusion Model"]}],["$","span","Linear Attention",{"className":"page__taxonomy-item","children":["#","Linear Attention"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Long Video",{"className":"page__taxonomy-item","children":["#","Long Video"]}],["$","span","Efficient Inference",{"className":"page__taxonomy-item","children":["#","Efficient Inference"]}],["$","span","Constant Memory",{"className":"page__taxonomy-item","children":["#","Constant Memory"]}],["$","span","Low-Cost Training",{"className":"page__taxonomy-item","children":["#","Low-Cost Training"]}],["$","span","RTX Deployment",{"className":"page__taxonomy-item","children":["#","RTX Deployment"]}]]}]]}]]}],["$","article","2025-9-30-RealUnify-Do-Unified-Models-Truly-Benefit-from-Unification-A-Comprehensive-Benchmark",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-30-RealUnify-Do-Unified-Models-Truly-Benefit-from-Unification-A-Comprehensive-Benchmark/","children":"[논문리뷰] RealUnify: Do Unified Models Truly Benefit from Unification? A Comprehensive Benchmark"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuran Wang이 [arXiv]에 게시한 'RealUnify: Do Unified Models Truly Benefit from Unification? A Comprehensive Benchmark' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-30 13:52:24+0900","children":"2025년 9월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Unified Models",{"className":"page__taxonomy-item","children":["#","Unified Models"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Capability Synergy",{"className":"page__taxonomy-item","children":["#","Capability Synergy"]}],["$","span","Visual Understanding",{"className":"page__taxonomy-item","children":["#","Visual Understanding"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Dual-Evaluation Protocol",{"className":"page__taxonomy-item","children":["#","Dual-Evaluation Protocol"]}]]}]]}]]}],["$","article","2025-9-30-Random-Policy-Valuation-is-Enough-for-LLM-Reasoning-with-Verifiable-Rewards",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-30-Random-Policy-Valuation-is-Enough-for-LLM-Reasoning-with-Verifiable-Rewards/","children":"[논문리뷰] Random Policy Valuation is Enough for LLM Reasoning with Verifiable Rewards"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Binxing Jiao이 [arXiv]에 게시한 'Random Policy Valuation is Enough for LLM Reasoning with Verifiable Rewards' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-30 13:52:24+0900","children":"2025년 9월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","LLM Reasoning",{"className":"page__taxonomy-item","children":["#","LLM Reasoning"]}],["$","span","Policy Valuation",{"className":"page__taxonomy-item","children":["#","Policy Valuation"]}],["$","span","Markov Decision Process",{"className":"page__taxonomy-item","children":["#","Markov Decision Process"]}],["$","span","Diversity",{"className":"page__taxonomy-item","children":["#","Diversity"]}],["$","span","Math Reasoning",{"className":"page__taxonomy-item","children":["#","Math Reasoning"]}],["$","span","Verifiable Rewards",{"className":"page__taxonomy-item","children":["#","Verifiable Rewards"]}]]}]]}]]}],["$","article","2025-9-30-OpenGPT-4o-Image-A-Comprehensive-Dataset-for-Advanced-Image-Generation-and-Editing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-30-OpenGPT-4o-Image-A-Comprehensive-Dataset-for-Advanced-Image-Generation-and-Editing/","children":"[논문리뷰] OpenGPT-4o-Image: A Comprehensive Dataset for Advanced Image Generation and Editing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Huanyu Zhang이 [arXiv]에 게시한 'OpenGPT-4o-Image: A Comprehensive Dataset for Advanced Image Generation and Editing' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-30 13:52:24+0900","children":"2025년 9월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}],["$","span","Taxonomy",{"className":"page__taxonomy-item","children":["#","Taxonomy"]}],["$","span","GPT-40",{"className":"page__taxonomy-item","children":["#","GPT-40"]}]]}]]}]]}],["$","article","2025-9-30-Multiplayer-Nash-Preference-Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-30-Multiplayer-Nash-Preference-Optimization/","children":"[논문리뷰] Multiplayer Nash Preference Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Multiplayer Nash Preference Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-30 13:52:24+0900","children":"2025년 9월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","RLHF",{"className":"page__taxonomy-item","children":["#","RLHF"]}],["$","span","LLM Alignment",{"className":"page__taxonomy-item","children":["#","LLM Alignment"]}],["$","span","Nash Equilibrium",{"className":"page__taxonomy-item","children":["#","Nash Equilibrium"]}],["$","span","Multiplayer Games",{"className":"page__taxonomy-item","children":["#","Multiplayer Games"]}],["$","span","Preference Optimization",{"className":"page__taxonomy-item","children":["#","Preference Optimization"]}],["$","span","Non-transitive Preferences",{"className":"page__taxonomy-item","children":["#","Non-transitive Preferences"]}],["$","span","Game Theory",{"className":"page__taxonomy-item","children":["#","Game Theory"]}]]}]]}]]}],["$","article","2025-9-30-EditScore-Unlocking-Online-RL-for-Image-Editing-via-High-Fidelity-Reward-Modeling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-30-EditScore-Unlocking-Online-RL-for-Image-Editing-via-High-Fidelity-Reward-Modeling/","children":"[논문리뷰] EditScore: Unlocking Online RL for Image Editing via High-Fidelity Reward Modeling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'EditScore: Unlocking Online RL for Image Editing via High-Fidelity Reward Modeling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-30 13:52:24+0900","children":"2025년 9월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Reward Modeling",{"className":"page__taxonomy-item","children":["#","Reward Modeling"]}],["$","span","Instruction-Guided Editing",{"className":"page__taxonomy-item","children":["#","Instruction-Guided Editing"]}],["$","span","Online RL",{"className":"page__taxonomy-item","children":["#","Online RL"]}],["$","span","Visual Language Models",{"className":"page__taxonomy-item","children":["#","Visual Language Models"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Self-Ensembling",{"className":"page__taxonomy-item","children":["#","Self-Ensembling"]}]]}]]}]]}],["$","article","2025-9-30-EasySteer-A-Unified-Framework-for-High-Performance-and-Extensible-LLM-Steering",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-30-EasySteer-A-Unified-Framework-for-High-Performance-and-Extensible-LLM-Steering/","children":"[논문리뷰] EasySteer: A Unified Framework for High-Performance and Extensible LLM Steering"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'EasySteer: A Unified Framework for High-Performance and Extensible LLM Steering' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-30 13:52:24+0900","children":"2025년 9월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Steering Framework",{"className":"page__taxonomy-item","children":["#","LLM Steering Framework"]}],["$","span","vLLM Integration",{"className":"page__taxonomy-item","children":["#","vLLM Integration"]}],["$","span","Hidden State Manipulation",{"className":"page__taxonomy-item","children":["#","Hidden State Manipulation"]}],["$","span","Inference Optimization",{"className":"page__taxonomy-item","children":["#","Inference Optimization"]}],["$","span","Extensibility",{"className":"page__taxonomy-item","children":["#","Extensibility"]}],["$","span","Modular Architecture",{"className":"page__taxonomy-item","children":["#","Modular Architecture"]}],["$","span","Reasoning Mitigation",{"className":"page__taxonomy-item","children":["#","Reasoning Mitigation"]}],["$","span","Hallucination Reduction",{"className":"page__taxonomy-item","children":["#","Hallucination Reduction"]}]]}]]}]]}],["$","article","2025-9-29-X-Streamer-Unified-Human-World-Modeling-with-Audiovisual-Interaction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-X-Streamer-Unified-Human-World-Modeling-with-Audiovisual-Interaction/","children":"[논문리뷰] X-Streamer: Unified Human World Modeling with Audiovisual Interaction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Guoxian Song이 [arXiv]에 게시한 'X-Streamer: Unified Human World Modeling with Audiovisual Interaction' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Digital Human",{"className":"page__taxonomy-item","children":["#","Digital Human"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Real-time Streaming",{"className":"page__taxonomy-item","children":["#","Real-time Streaming"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Audiovisual Synchronization",{"className":"page__taxonomy-item","children":["#","Audiovisual Synchronization"]}],["$","span","World Modeling",{"className":"page__taxonomy-item","children":["#","World Modeling"]}]]}]]}]]}],["$","article","2025-9-29-X-CoT-Explainable-Text-to-Video-Retrieval-via-LLM-based-Chain-of-Thought-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-X-CoT-Explainable-Text-to-Video-Retrieval-via-LLM-based-Chain-of-Thought-Reasoning/","children":"[논문리뷰] X-CoT: Explainable Text-to-Video Retrieval via LLM-based Chain-of-Thought Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Raghuveer Rao이 [arXiv]에 게시한 'X-CoT: Explainable Text-to-Video Retrieval via LLM-based Chain-of-Thought Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Video Retrieval",{"className":"page__taxonomy-item","children":["#","Text-to-Video Retrieval"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Explainable AI",{"className":"page__taxonomy-item","children":["#","Explainable AI"]}],["$","span","Multimodal Retrieval",{"className":"page__taxonomy-item","children":["#","Multimodal Retrieval"]}],["$","span","Bradley-Terry Model",{"className":"page__taxonomy-item","children":["#","Bradley-Terry Model"]}],["$","span","Video Annotation",{"className":"page__taxonomy-item","children":["#","Video Annotation"]}]]}]]}]]}],["$","article","2025-9-29-WoW-Towards-a-World-omniscient-World-model-Through-Embodied-Interaction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-WoW-Towards-a-World-omniscient-World-model-Through-Embodied-Interaction/","children":"[논문리뷰] WoW: Towards a World omniscient World model Through Embodied Interaction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Weishi Mi이 [arXiv]에 게시한 'WoW: Towards a World omniscient World model Through Embodied Interaction' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","World Model",{"className":"page__taxonomy-item","children":["#","World Model"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Physical Reasoning",{"className":"page__taxonomy-item","children":["#","Physical Reasoning"]}],["$","span","Vision Language Models",{"className":"page__taxonomy-item","children":["#","Vision Language Models"]}],["$","span","Interaction Data",{"className":"page__taxonomy-item","children":["#","Interaction Data"]}],["$","span","Self-Optimization",{"className":"page__taxonomy-item","children":["#","Self-Optimization"]}]]}]]}]]}],["$","article","2025-9-29-Where-MLLMs-Attend-and-What-They-Rely-On-Explaining-Autoregressive-Token-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-Where-MLLMs-Attend-and-What-They-Rely-On-Explaining-Autoregressive-Token-Generation/","children":"[논문리뷰] Where MLLMs Attend and What They Rely On: Explaining Autoregressive Token Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shiming Liu이 [arXiv]에 게시한 'Where MLLMs Attend and What They Rely On: Explaining Autoregressive Token Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","MLLM",{"className":"page__taxonomy-item","children":["#","MLLM"]}],["$","span","Interpretability",{"className":"page__taxonomy-item","children":["#","Interpretability"]}],["$","span","Attribution",{"className":"page__taxonomy-item","children":["#","Attribution"]}],["$","span","Token Generation",{"className":"page__taxonomy-item","children":["#","Token Generation"]}],["$","span","Black-box Explanation",{"className":"page__taxonomy-item","children":["#","Black-box Explanation"]}],["$","span","Hallucination Diagnosis",{"className":"page__taxonomy-item","children":["#","Hallucination Diagnosis"]}],["$","span","Multimodality",{"className":"page__taxonomy-item","children":["#","Multimodality"]}],["$","span","VQA",{"className":"page__taxonomy-item","children":["#","VQA"]}]]}]]}]]}],["$","article","2025-9-29-WebGen-Agent-Enhancing-Interactive-Website-Generation-with-Multi-Level-Feedback-and-Step-Level-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-WebGen-Agent-Enhancing-Interactive-Website-Generation-with-Multi-Level-Feedback-and-Step-Level-Reinforcement-Learning/","children":"[논문리뷰] WebGen-Agent: Enhancing Interactive Website Generation with Multi-Level Feedback and Step-Level Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhuofan Zong이 [arXiv]에 게시한 'WebGen-Agent: Enhancing Interactive Website Generation with Multi-Level Feedback and Step-Level Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Website Generation",{"className":"page__taxonomy-item","children":["#","Website Generation"]}],["$","span","Code Agent",{"className":"page__taxonomy-item","children":["#","Code Agent"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","VLM",{"className":"page__taxonomy-item","children":["#","VLM"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Multi-Level Feedback",{"className":"page__taxonomy-item","children":["#","Multi-Level Feedback"]}],["$","span","GUI Agent",{"className":"page__taxonomy-item","children":["#","GUI Agent"]}],["$","span","Step-GRPO",{"className":"page__taxonomy-item","children":["#","Step-GRPO"]}]]}]]}]]}],["$","article","2025-9-29-VoiceAssistant-Eval-Benchmarking-AI-Assistants-across-Listening-Speaking-and-Viewing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-VoiceAssistant-Eval-Benchmarking-AI-Assistants-across-Listening-Speaking-and-Viewing/","children":"[논문리뷰] VoiceAssistant-Eval: Benchmarking AI Assistants across Listening, Speaking, and Viewing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'VoiceAssistant-Eval: Benchmarking AI Assistants across Listening, Speaking, and Viewing' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Assistants",{"className":"page__taxonomy-item","children":["#","AI Assistants"]}],["$","span","Multimodal Benchmarking",{"className":"page__taxonomy-item","children":["#","Multimodal Benchmarking"]}],["$","span","Audio Understanding",{"className":"page__taxonomy-item","children":["#","Audio Understanding"]}],["$","span","Speech Synthesis",{"className":"page__taxonomy-item","children":["#","Speech Synthesis"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Role-play",{"className":"page__taxonomy-item","children":["#","Role-play"]}],["$","span","Safety",{"className":"page__taxonomy-item","children":["#","Safety"]}],["$","span","Robustness",{"className":"page__taxonomy-item","children":["#","Robustness"]}]]}]]}]]}],["$","article","2025-9-29-Variational-Reasoning-for-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-Variational-Reasoning-for-Language-Models/","children":"[논문리뷰] Variational Reasoning for Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Variational Reasoning for Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Variational Inference",{"className":"page__taxonomy-item","children":["#","Variational Inference"]}],["$","span","Language Models",{"className":"page__taxonomy-item","children":["#","Language Models"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","ELBO",{"className":"page__taxonomy-item","children":["#","ELBO"]}],["$","span","IWAE",{"className":"page__taxonomy-item","children":["#","IWAE"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Latent Variables",{"className":"page__taxonomy-item","children":["#","Latent Variables"]}],["$","span","Forward-KL",{"className":"page__taxonomy-item","children":["#","Forward-KL"]}]]}]]}]]}],["$","article","2025-9-29-UniVid-Unifying-Vision-Tasks-with-Pre-trained-Video-Generation-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-UniVid-Unifying-Vision-Tasks-with-Pre-trained-Video-Generation-Models/","children":"[논문리뷰] UniVid: Unifying Vision Tasks with Pre-trained Video Generation Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuchao Gu이 [arXiv]에 게시한 'UniVid: Unifying Vision Tasks with Pre-trained Video Generation Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Unified Vision Modeling",{"className":"page__taxonomy-item","children":["#","Unified Vision Modeling"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Diffusion Transformer",{"className":"page__taxonomy-item","children":["#","Diffusion Transformer"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Cross-modal",{"className":"page__taxonomy-item","children":["#","Cross-modal"]}],["$","span","Cross-source Tasks",{"className":"page__taxonomy-item","children":["#","Cross-source Tasks"]}],["$","span","Visual Sentences",{"className":"page__taxonomy-item","children":["#","Visual Sentences"]}],["$","span","LoRA",{"className":"page__taxonomy-item","children":["#","LoRA"]}]]}]]}]]}],["$","article","2025-9-29-UltraHorizon-Benchmarking-Agent-Capabilities-in-Ultra-Long-Horizon-Scenarios",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-UltraHorizon-Benchmarking-Agent-Capabilities-in-Ultra-Long-Horizon-Scenarios/","children":"[논문리뷰] UltraHorizon: Benchmarking Agent Capabilities in Ultra Long-Horizon Scenarios"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zeyu Qin이 [arXiv]에 게시한 'UltraHorizon: Benchmarking Agent Capabilities in Ultra Long-Horizon Scenarios' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Long-Horizon Reasoning",{"className":"page__taxonomy-item","children":["#","Long-Horizon Reasoning"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Partially Observable",{"className":"page__taxonomy-item","children":["#","Partially Observable"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Memory Management",{"className":"page__taxonomy-item","children":["#","Memory Management"]}],["$","span","Exploration",{"className":"page__taxonomy-item","children":["#","Exploration"]}]]}]]}]]}],["$","article","2025-9-29-Think-on-Graph-3-0-Efficient-and-Adaptive-LLM-Reasoning-on-Heterogeneous-Graphs-via-Multi-Agent-Dual-Evolving-Context-Retrieval",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-Think-on-Graph-3-0-Efficient-and-Adaptive-LLM-Reasoning-on-Heterogeneous-Graphs-via-Multi-Agent-Dual-Evolving-Context-Retrieval/","children":"[논문리뷰] Think-on-Graph 3.0: Efficient and Adaptive LLM Reasoning on Heterogeneous Graphs via Multi-Agent Dual-Evolving Context Retrieval"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Think-on-Graph 3.0: Efficient and Adaptive LLM Reasoning on Heterogeneous Graphs via Multi-Agent Dual-Evolving Context Retrieval' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","RAG",{"className":"page__taxonomy-item","children":["#","RAG"]}],["$","span","LLM Reasoning",{"className":"page__taxonomy-item","children":["#","LLM Reasoning"]}],["$","span","Knowledge Graphs",{"className":"page__taxonomy-item","children":["#","Knowledge Graphs"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Context Retrieval",{"className":"page__taxonomy-item","children":["#","Context Retrieval"]}],["$","span","Heterogeneous Graphs",{"className":"page__taxonomy-item","children":["#","Heterogeneous Graphs"]}],["$","span","Adaptive Learning",{"className":"page__taxonomy-item","children":["#","Adaptive Learning"]}],["$","span","Dual-Evolution",{"className":"page__taxonomy-item","children":["#","Dual-Evolution"]}]]}]]}]]}],["$","article","2025-9-29-TUN3D-Towards-Real-World-Scene-Understanding-from-Unposed-Images",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-TUN3D-Towards-Real-World-Scene-Understanding-from-Unposed-Images/","children":"[논문리뷰] TUN3D: Towards Real-World Scene Understanding from Unposed Images"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Anna Vorontsova이 [arXiv]에 게시한 'TUN3D: Towards Real-World Scene Understanding from Unposed Images' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Scene Understanding",{"className":"page__taxonomy-item","children":["#","3D Scene Understanding"]}],["$","span","Layout Estimation",{"className":"page__taxonomy-item","children":["#","Layout Estimation"]}],["$","span","3D Object Detection",{"className":"page__taxonomy-item","children":["#","3D Object Detection"]}],["$","span","Unposed Images",{"className":"page__taxonomy-item","children":["#","Unposed Images"]}],["$","span","Sparse Convolutional Networks",{"className":"page__taxonomy-item","children":["#","Sparse Convolutional Networks"]}],["$","span","Multi-view Stereo",{"className":"page__taxonomy-item","children":["#","Multi-view Stereo"]}],["$","span","Real-time AI",{"className":"page__taxonomy-item","children":["#","Real-time AI"]}]]}]]}]]}],["$","article","2025-9-29-StateX-Enhancing-RNN-Recall-via-Post-training-State-Expansion",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-StateX-Enhancing-RNN-Recall-via-Post-training-State-Expansion/","children":"[논문리뷰] StateX: Enhancing RNN Recall via Post-training State Expansion"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhiyuan Liu이 [arXiv]에 게시한 'StateX: Enhancing RNN Recall via Post-training State Expansion' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","RNN",{"className":"page__taxonomy-item","children":["#","RNN"]}],["$","span","State Expansion",{"className":"page__taxonomy-item","children":["#","State Expansion"]}],["$","span","Post-training",{"className":"page__taxonomy-item","children":["#","Post-training"]}],["$","span","Long-context Recall",{"className":"page__taxonomy-item","children":["#","Long-context Recall"]}],["$","span","Linear Attention",{"className":"page__taxonomy-item","children":["#","Linear Attention"]}],["$","span","State Space Models",{"className":"page__taxonomy-item","children":["#","State Space Models"]}],["$","span","GLA",{"className":"page__taxonomy-item","children":["#","GLA"]}],["$","span","Mamba2",{"className":"page__taxonomy-item","children":["#","Mamba2"]}]]}]]}]]}],["$","article","2025-9-29-See-Point-Fly-A-Learning-Free-VLM-Framework-for-Universal-Unmanned-Aerial-Navigation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-See-Point-Fly-A-Learning-Free-VLM-Framework-for-Universal-Unmanned-Aerial-Navigation/","children":"[논문리뷰] See, Point, Fly: A Learning-Free VLM Framework for Universal Unmanned Aerial Navigation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chih-Hai Su이 [arXiv]에 게시한 'See, Point, Fly: A Learning-Free VLM Framework for Universal Unmanned Aerial Navigation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","UAV Navigation",{"className":"page__taxonomy-item","children":["#","UAV Navigation"]}],["$","span","Zero-shot",{"className":"page__taxonomy-item","children":["#","Zero-shot"]}],["$","span","Spatial Grounding",{"className":"page__taxonomy-item","children":["#","Spatial Grounding"]}],["$","span","Waypoint Prompting",{"className":"page__taxonomy-item","children":["#","Waypoint Prompting"]}],["$","span","Autonomous Navigation",{"className":"page__taxonomy-item","children":["#","Autonomous Navigation"]}],["$","span","Adaptive Control",{"className":"page__taxonomy-item","children":["#","Adaptive Control"]}]]}]]}]]}],["$","article","2025-9-29-SPARK-Synergistic-Policy-And-Reward-Co-Evolving-Framework",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-SPARK-Synergistic-Policy-And-Reward-Co-Evolving-Framework/","children":"[논문리뷰] SPARK: Synergistic Policy And Reward Co-Evolving Framework"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'SPARK: Synergistic Policy And Reward Co-Evolving Framework' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","LVLMs",{"className":"page__taxonomy-item","children":["#","LVLMs"]}],["$","span","Reward Modeling",{"className":"page__taxonomy-item","children":["#","Reward Modeling"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Self-Reflection",{"className":"page__taxonomy-item","children":["#","Self-Reflection"]}],["$","span","Verifiable Rewards",{"className":"page__taxonomy-item","children":["#","Verifiable Rewards"]}],["$","span","Co-evolution",{"className":"page__taxonomy-item","children":["#","Co-evolution"]}]]}]]}]]}],["$","article","2025-9-29-ReviewScore-Misinformed-Peer-Review-Detection-with-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-ReviewScore-Misinformed-Peer-Review-Detection-with-Large-Language-Models/","children":"[논문리뷰] ReviewScore: Misinformed Peer Review Detection with Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'ReviewScore: Misinformed Peer Review Detection with Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Peer Review",{"className":"page__taxonomy-item","children":["#","Peer Review"]}],["$","span","Review Quality",{"className":"page__taxonomy-item","children":["#","Review Quality"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Misinformed Review",{"className":"page__taxonomy-item","children":["#","Misinformed Review"]}],["$","span","Argument Reconstruction",{"className":"page__taxonomy-item","children":["#","Argument Reconstruction"]}],["$","span","Factuality Evaluation",{"className":"page__taxonomy-item","children":["#","Factuality Evaluation"]}],["$","span","Natural Language Processing",{"className":"page__taxonomy-item","children":["#","Natural Language Processing"]}],["$","span","Automated Evaluation",{"className":"page__taxonomy-item","children":["#","Automated Evaluation"]}]]}]]}]]}],["$","article","2025-9-29-RefAM-Attention-Magnets-for-Zero-Shot-Referral-Segmentation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-RefAM-Attention-Magnets-for-Zero-Shot-Referral-Segmentation/","children":"[논문리뷰] RefAM: Attention Magnets for Zero-Shot Referral Segmentation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Federico Tombari이 [arXiv]에 게시한 'RefAM: Attention Magnets for Zero-Shot Referral Segmentation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Zero-Shot Segmentation",{"className":"page__taxonomy-item","children":["#","Zero-Shot Segmentation"]}],["$","span","Referring Segmentation",{"className":"page__taxonomy-item","children":["#","Referring Segmentation"]}],["$","span","Diffusion Transformers (DiTs)",{"className":"page__taxonomy-item","children":["#","Diffusion Transformers (DiTs)"]}],["$","span","Attention Mechanisms",{"className":"page__taxonomy-item","children":["#","Attention Mechanisms"]}],["$","span","Attention Sinks",{"className":"page__taxonomy-item","children":["#","Attention Sinks"]}],["$","span","Stop Words",{"className":"page__taxonomy-item","children":["#","Stop Words"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Training-Free Methods",{"className":"page__taxonomy-item","children":["#","Training-Free Methods"]}]]}]]}]]}],["$","article","2025-9-29-Real-Time-Object-Detection-Meets-DINOv3",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-Real-Time-Object-Detection-Meets-DINOv3/","children":"[논문리뷰] Real-Time Object Detection Meets DINOv3"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xi Shen이 [arXiv]에 게시한 'Real-Time Object Detection Meets DINOv3' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Real-time Object Detection",{"className":"page__taxonomy-item","children":["#","Real-time Object Detection"]}],["$","span","DINOv3",{"className":"page__taxonomy-item","children":["#","DINOv3"]}],["$","span","DEIMv2",{"className":"page__taxonomy-item","children":["#","DEIMv2"]}],["$","span","Vision Transformer",{"className":"page__taxonomy-item","children":["#","Vision Transformer"]}],["$","span","Multi-scale Features",{"className":"page__taxonomy-item","children":["#","Multi-scale Features"]}],["$","span","Spatial Tuning Adapter",{"className":"page__taxonomy-item","children":["#","Spatial Tuning Adapter"]}],["$","span","Lightweight Models",{"className":"page__taxonomy-item","children":["#","Lightweight Models"]}],["$","span","Object Detection Framework",{"className":"page__taxonomy-item","children":["#","Object Detection Framework"]}]]}]]}]]}],["$","article","2025-9-29-Quantile-Advantage-Estimation-for-Entropy-Safe-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-Quantile-Advantage-Estimation-for-Entropy-Safe-Reasoning/","children":"[논문리뷰] Quantile Advantage Estimation for Entropy-Safe Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"An Zhang이 [arXiv]에 게시한 'Quantile Advantage Estimation for Entropy-Safe Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","LLM Reasoning",{"className":"page__taxonomy-item","children":["#","LLM Reasoning"]}],["$","span","Entropy Control",{"className":"page__taxonomy-item","children":["#","Entropy Control"]}],["$","span","Advantage Estimation",{"className":"page__taxonomy-item","children":["#","Advantage Estimation"]}],["$","span","Quantile Baseline",{"className":"page__taxonomy-item","children":["#","Quantile Baseline"]}],["$","span","Exploration-Exploitation",{"className":"page__taxonomy-item","children":["#","Exploration-Exploitation"]}],["$","span","RLVR",{"className":"page__taxonomy-item","children":["#","RLVR"]}]]}]]}]]}],["$","article","2025-9-29-PromptCoT-2-0-Scaling-Prompt-Synthesis-for-Large-Language-Model-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-PromptCoT-2-0-Scaling-Prompt-Synthesis-for-Large-Language-Model-Reasoning/","children":"[논문리뷰] PromptCoT 2.0: Scaling Prompt Synthesis for Large Language Model Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Lingpeng Kong이 [arXiv]에 게시한 'PromptCoT 2.0: Scaling Prompt Synthesis for Large Language Model Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Prompt Synthesis",{"className":"page__taxonomy-item","children":["#","Prompt Synthesis"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Expectation-Maximization",{"className":"page__taxonomy-item","children":["#","Expectation-Maximization"]}],["$","span","Self-Play",{"className":"page__taxonomy-item","children":["#","Self-Play"]}],["$","span","Supervised Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning"]}],["$","span","Task Generation",{"className":"page__taxonomy-item","children":["#","Task Generation"]}],["$","span","Rationale Generation",{"className":"page__taxonomy-item","children":["#","Rationale Generation"]}]]}]]}]]}],["$","article","2025-9-29-No-Prompt-Left-Behind-Exploiting-Zero-Variance-Prompts-in-LLM-Reinforcement-Learning-via-Entropy-Guided-Advantage-Shaping",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-No-Prompt-Left-Behind-Exploiting-Zero-Variance-Prompts-in-LLM-Reinforcement-Learning-via-Entropy-Guided-Advantage-Shaping/","children":"[논문리뷰] No Prompt Left Behind: Exploiting Zero-Variance Prompts in LLM Reinforcement Learning via Entropy-Guided Advantage Shaping"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'No Prompt Left Behind: Exploiting Zero-Variance Prompts in LLM Reinforcement Learning via Entropy-Guided Advantage Shaping' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","LLM Reinforcement Learning"]}],["$","span","Zero-Variance Prompts",{"className":"page__taxonomy-item","children":["#","Zero-Variance Prompts"]}],["$","span","Advantage Shaping",{"className":"page__taxonomy-item","children":["#","Advantage Shaping"]}],["$","span","Entropy-Guided",{"className":"page__taxonomy-item","children":["#","Entropy-Guided"]}],["$","span","Math Reasoning",{"className":"page__taxonomy-item","children":["#","Math Reasoning"]}],["$","span","RLVR",{"className":"page__taxonomy-item","children":["#","RLVR"]}],["$","span","Group Relative Policy Optimization",{"className":"page__taxonomy-item","children":["#","Group Relative Policy Optimization"]}]]}]]}]]}],["$","article","2025-9-29-MinerU2-5-A-Decoupled-Vision-Language-Model-for-Efficient-High-Resolution-Document-Parsing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-MinerU2-5-A-Decoupled-Vision-Language-Model-for-Efficient-High-Resolution-Document-Parsing/","children":"[논문리뷰] MinerU2.5: A Decoupled Vision-Language Model for Efficient High-Resolution Document Parsing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"SunYuefeng이 [arXiv]에 게시한 'MinerU2.5: A Decoupled Vision-Language Model for Efficient High-Resolution Document Parsing' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Document Parsing",{"className":"page__taxonomy-item","children":["#","Document Parsing"]}],["$","span","Vision-Language Model",{"className":"page__taxonomy-item","children":["#","Vision-Language Model"]}],["$","span","High-Resolution",{"className":"page__taxonomy-item","children":["#","High-Resolution"]}],["$","span","Two-Stage Inference",{"className":"page__taxonomy-item","children":["#","Two-Stage Inference"]}],["$","span","Layout Analysis",{"className":"page__taxonomy-item","children":["#","Layout Analysis"]}],["$","span","Content Recognition",{"className":"page__taxonomy-item","children":["#","Content Recognition"]}],["$","span","Data Engine",{"className":"page__taxonomy-item","children":["#","Data Engine"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}]]}]]}]]}],["$","article","2025-9-29-Mind-the-Glitch-Visual-Correspondence-for-Detecting-Inconsistencies-in-Subject-Driven-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-Mind-the-Glitch-Visual-Correspondence-for-Detecting-Inconsistencies-in-Subject-Driven-Generation/","children":"[논문리뷰] Mind-the-Glitch: Visual Correspondence for Detecting Inconsistencies in Subject-Driven Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Peter Wonka이 [arXiv]에 게시한 'Mind-the-Glitch: Visual Correspondence for Detecting Inconsistencies in Subject-Driven Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Subject-Driven Generation",{"className":"page__taxonomy-item","children":["#","Subject-Driven Generation"]}],["$","span","Visual Inconsistency Detection",{"className":"page__taxonomy-item","children":["#","Visual Inconsistency Detection"]}],["$","span","Feature Disentanglement",{"className":"page__taxonomy-item","children":["#","Feature Disentanglement"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Semantic Correspondence",{"className":"page__taxonomy-item","children":["#","Semantic Correspondence"]}],["$","span","Evaluation Metric",{"className":"page__taxonomy-item","children":["#","Evaluation Metric"]}],["$","span","Spatial Localization",{"className":"page__taxonomy-item","children":["#","Spatial Localization"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}]]}]]}]]}],["$","article","2025-9-29-MesaTask-Towards-Task-Driven-Tabletop-Scene-Generation-via-3D-Spatial-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-MesaTask-Towards-Task-Driven-Tabletop-Scene-Generation-via-3D-Spatial-Reasoning/","children":"[논문리뷰] MesaTask: Towards Task-Driven Tabletop Scene Generation via 3D Spatial Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Weipeng Zhong이 [arXiv]에 게시한 'MesaTask: Towards Task-Driven Tabletop Scene Generation via 3D Spatial Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Scene Generation",{"className":"page__taxonomy-item","children":["#","3D Scene Generation"]}],["$","span","Robotic Manipulation",{"className":"page__taxonomy-item","children":["#","Robotic Manipulation"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}],["$","span","Direct Preference Optimization",{"className":"page__taxonomy-item","children":["#","Direct Preference Optimization"]}],["$","span","Tabletop Scene",{"className":"page__taxonomy-item","children":["#","Tabletop Scene"]}]]}]]}]]}],["$","article","2025-9-29-LucidFlux-Caption-Free-Universal-Image-Restoration-via-a-Large-Scale-Diffusion-Transformer",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-LucidFlux-Caption-Free-Universal-Image-Restoration-via-a-Large-Scale-Diffusion-Transformer/","children":"[논문리뷰] LucidFlux: Caption-Free Universal Image Restoration via a Large-Scale Diffusion Transformer"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'LucidFlux: Caption-Free Universal Image Restoration via a Large-Scale Diffusion Transformer' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Universal Image Restoration",{"className":"page__taxonomy-item","children":["#","Universal Image Restoration"]}],["$","span","Diffusion Transformer",{"className":"page__taxonomy-item","children":["#","Diffusion Transformer"]}],["$","span","Caption-Free",{"className":"page__taxonomy-item","children":["#","Caption-Free"]}],["$","span","Semantic Alignment",{"className":"page__taxonomy-item","children":["#","Semantic Alignment"]}],["$","span","Image Quality Assessment",{"className":"page__taxonomy-item","children":["#","Image Quality Assessment"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Real-World Degradations",{"className":"page__taxonomy-item","children":["#","Real-World Degradations"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}]]}]]}]]}],["$","article","2025-9-29-LongLive-Real-time-Interactive-Long-Video-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-LongLive-Real-time-Interactive-Long-Video-Generation/","children":"[논문리뷰] LongLive: Real-time Interactive Long Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'LongLive: Real-time Interactive Long Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Long Video Generation",{"className":"page__taxonomy-item","children":["#","Long Video Generation"]}],["$","span","Real-time",{"className":"page__taxonomy-item","children":["#","Real-time"]}],["$","span","Interactive AI",{"className":"page__taxonomy-item","children":["#","Interactive AI"]}],["$","span","Autoregressive Models",{"className":"page__taxonomy-item","children":["#","Autoregressive Models"]}],["$","span","KV Cache",{"className":"page__taxonomy-item","children":["#","KV Cache"]}],["$","span","Streaming Tuning",{"className":"page__taxonomy-item","children":["#","Streaming Tuning"]}],["$","span","Attention Sink",{"className":"page__taxonomy-item","children":["#","Attention Sink"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}]]}]]}]]}],["$","article","2025-9-29-Learn-the-Ropes-Then-Trust-the-Wins-Self-imitation-with-Progressive-Exploration-for-Agentic-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-Learn-the-Ropes-Then-Trust-the-Wins-Self-imitation-with-Progressive-Exploration-for-Agentic-Reinforcement-Learning/","children":"[논문리뷰] Learn the Ropes, Then Trust the Wins: Self-imitation with Progressive Exploration for Agentic Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Gang Li이 [arXiv]에 게시한 'Learn the Ropes, Then Trust the Wins: Self-imitation with Progressive Exploration for Agentic Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Exploration-Exploitation",{"className":"page__taxonomy-item","children":["#","Exploration-Exploitation"]}],["$","span","Self-Imitation Learning",{"className":"page__taxonomy-item","children":["#","Self-Imitation Learning"]}],["$","span","Intrinsic Rewards",{"className":"page__taxonomy-item","children":["#","Intrinsic Rewards"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Policy Entropy",{"className":"page__taxonomy-item","children":["#","Policy Entropy"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}]]}]]}]]}],["$","article","2025-9-29-Language-Models-Can-Learn-from-Verbal-Feedback-Without-Scalar-Rewards",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-Language-Models-Can-Learn-from-Verbal-Feedback-Without-Scalar-Rewards/","children":"[논문리뷰] Language Models Can Learn from Verbal Feedback Without Scalar Rewards"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Language Models Can Learn from Verbal Feedback Without Scalar Rewards' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Verbal Feedback",{"className":"page__taxonomy-item","children":["#","Verbal Feedback"]}],["$","span","Conditional Generation",{"className":"page__taxonomy-item","children":["#","Conditional Generation"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Feedback-Conditional Policy",{"className":"page__taxonomy-item","children":["#","Feedback-Conditional Policy"]}],["$","span","Offline-Online Learning",{"className":"page__taxonomy-item","children":["#","Offline-Online Learning"]}],["$","span","Reward Hypothesis Bypass",{"className":"page__taxonomy-item","children":["#","Reward Hypothesis Bypass"]}]]}]]}]]}],["$","article","2025-9-29-Instruction-Following-Evaluation-in-Function-Calling-for-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-Instruction-Following-Evaluation-in-Function-Calling-for-Large-Language-Models/","children":"[논문리뷰] Instruction-Following Evaluation in Function Calling for Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"NikolaiSkripko이 [arXiv]에 게시한 'Instruction-Following Evaluation in Function Calling for Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Function Calling",{"className":"page__taxonomy-item","children":["#","Function Calling"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","JSON Schema",{"className":"page__taxonomy-item","children":["#","JSON Schema"]}],["$","span","AI Agents",{"className":"page__taxonomy-item","children":["#","AI Agents"]}],["$","span","Evaluation Metrics",{"className":"page__taxonomy-item","children":["#","Evaluation Metrics"]}]]}]]}]]}],["$","article","2025-9-29-HiGS-History-Guided-Sampling-for-Plug-and-Play-Enhancement-of-Diffusion-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-HiGS-History-Guided-Sampling-for-Plug-and-Play-Enhancement-of-Diffusion-Models/","children":"[논문리뷰] HiGS: History-Guided Sampling for Plug-and-Play Enhancement of Diffusion Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Romann M. Weber이 [arXiv]에 게시한 'HiGS: History-Guided Sampling for Plug-and-Play Enhancement of Diffusion Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Sampling",{"className":"page__taxonomy-item","children":["#","Sampling"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Plug-and-Play",{"className":"page__taxonomy-item","children":["#","Plug-and-Play"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}],["$","span","Guidance",{"className":"page__taxonomy-item","children":["#","Guidance"]}],["$","span","Momentum-Based Methods",{"className":"page__taxonomy-item","children":["#","Momentum-Based Methods"]}]]}]]}]]}],["$","article","2025-9-29-FlashEdit-Decoupling-Speed-Structure-and-Semantics-for-Precise-Image-Editing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-FlashEdit-Decoupling-Speed-Structure-and-Semantics-for-Precise-Image-Editing/","children":"[논문리뷰] FlashEdit: Decoupling Speed, Structure, and Semantics for Precise Image Editing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Linghe Kong이 [arXiv]에 게시한 'FlashEdit: Decoupling Speed, Structure, and Semantics for Precise Image Editing' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-Guided Image Editing",{"className":"page__taxonomy-item","children":["#","Text-Guided Image Editing"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Real-Time Editing",{"className":"page__taxonomy-item","children":["#","Real-Time Editing"]}],["$","span","One-Step Inversion",{"className":"page__taxonomy-item","children":["#","One-Step Inversion"]}],["$","span","Attention Control",{"className":"page__taxonomy-item","children":["#","Attention Control"]}],["$","span","Background Preservation",{"className":"page__taxonomy-item","children":["#","Background Preservation"]}],["$","span","Semantic Disentanglement",{"className":"page__taxonomy-item","children":["#","Semantic Disentanglement"]}]]}]]}]]}],["$","article","2025-9-29-Fine-tuning-Done-Right-in-Model-Editing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-Fine-tuning-Done-Right-in-Model-Editing/","children":"[논문리뷰] Fine-tuning Done Right in Model Editing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Du Su이 [arXiv]에 게시한 'Fine-tuning Done Right in Model Editing' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Model Editing",{"className":"page__taxonomy-item","children":["#","Model Editing"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Catastrophic Forgetting",{"className":"page__taxonomy-item","children":["#","Catastrophic Forgetting"]}],["$","span","Breadth-First Pipeline",{"className":"page__taxonomy-item","children":["#","Breadth-First Pipeline"]}],["$","span","Depth-First Pipeline",{"className":"page__taxonomy-item","children":["#","Depth-First Pipeline"]}],["$","span","Localized Tuning",{"className":"page__taxonomy-item","children":["#","Localized Tuning"]}],["$","span","Lifelong Learning",{"className":"page__taxonomy-item","children":["#","Lifelong Learning"]}]]}]]}]]}],["$","article","2025-9-29-Finding-3D-Positions-of-Distant-Objects-from-Noisy-Camera-Movement-and-Semantic-Segmentation-Sequences",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-Finding-3D-Positions-of-Distant-Objects-from-Noisy-Camera-Movement-and-Semantic-Segmentation-Sequences/","children":"[논문리뷰] Finding 3D Positions of Distant Objects from Noisy Camera Movement and Semantic Segmentation Sequences"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Eija Honkavaara이 [arXiv]에 게시한 'Finding 3D Positions of Distant Objects from Noisy Camera Movement and Semantic Segmentation Sequences' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Object Localization",{"className":"page__taxonomy-item","children":["#","3D Object Localization"]}],["$","span","Particle Filter",{"className":"page__taxonomy-item","children":["#","Particle Filter"]}],["$","span","Multi-target Tracking",{"className":"page__taxonomy-item","children":["#","Multi-target Tracking"]}],["$","span","Drone Surveillance",{"className":"page__taxonomy-item","children":["#","Drone Surveillance"]}],["$","span","Wildfire Monitoring",{"className":"page__taxonomy-item","children":["#","Wildfire Monitoring"]}],["$","span","Semantic Segmentation",{"className":"page__taxonomy-item","children":["#","Semantic Segmentation"]}],["$","span","Camera Pose Estimation",{"className":"page__taxonomy-item","children":["#","Camera Pose Estimation"]}]]}]]}]]}],["$","article","2025-9-29-ERGO-Efficient-High-Resolution-Visual-Understanding-for-Vision-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-ERGO-Efficient-High-Resolution-Visual-Understanding-for-Vision-Language-Models/","children":"[논문리뷰] ERGO: Efficient High-Resolution Visual Understanding for Vision-Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ki-Ung Song이 [arXiv]에 게시한 'ERGO: Efficient High-Resolution Visual Understanding for Vision-Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","High-Resolution Vision",{"className":"page__taxonomy-item","children":["#","High-Resolution Vision"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Efficient Reasoning",{"className":"page__taxonomy-item","children":["#","Efficient Reasoning"]}],["$","span","Coarse-to-Fine",{"className":"page__taxonomy-item","children":["#","Coarse-to-Fine"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Visual Understanding",{"className":"page__taxonomy-item","children":["#","Visual Understanding"]}],["$","span","Attention Mechanism",{"className":"page__taxonomy-item","children":["#","Attention Mechanism"]}]]}]]}]]}],["$","article","2025-9-29-EPO-Entropy-regularized-Policy-Optimization-for-LLM-Agents-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-EPO-Entropy-regularized-Policy-Optimization-for-LLM-Agents-Reinforcement-Learning/","children":"[논문리뷰] EPO: Entropy-regularized Policy Optimization for LLM Agents Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Li Yu-Jhe이 [arXiv]에 게시한 'EPO: Entropy-regularized Policy Optimization for LLM Agents Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Entropy Regularization",{"className":"page__taxonomy-item","children":["#","Entropy Regularization"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Sparse Rewards",{"className":"page__taxonomy-item","children":["#","Sparse Rewards"]}],["$","span","Multi-turn Environments",{"className":"page__taxonomy-item","children":["#","Multi-turn Environments"]}],["$","span","Exploration-Exploitation",{"className":"page__taxonomy-item","children":["#","Exploration-Exploitation"]}]]}]]}]]}],["$","article","2025-9-29-D-Artemis-A-Deliberative-Cognitive-Framework-for-Mobile-GUI-Multi-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-D-Artemis-A-Deliberative-Cognitive-Framework-for-Mobile-GUI-Multi-Agents/","children":"[논문리뷰] D-Artemis: A Deliberative Cognitive Framework for Mobile GUI Multi-Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jinyuan Li이 [arXiv]에 게시한 'D-Artemis: A Deliberative Cognitive Framework for Mobile GUI Multi-Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Mobile GUI Automation",{"className":"page__taxonomy-item","children":["#","Mobile GUI Automation"]}],["$","span","Multi-Agent System",{"className":"page__taxonomy-item","children":["#","Multi-Agent System"]}],["$","span","Cognitive Architecture",{"className":"page__taxonomy-item","children":["#","Cognitive Architecture"]}],["$","span","Pre-execution Alignment",{"className":"page__taxonomy-item","children":["#","Pre-execution Alignment"]}],["$","span","Post-execution Reflection",{"className":"page__taxonomy-item","children":["#","Post-execution Reflection"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","Multimodal LLM",{"className":"page__taxonomy-item","children":["#","Multimodal LLM"]}],["$","span","Deliberative AI",{"className":"page__taxonomy-item","children":["#","Deliberative AI"]}]]}]]}]]}],["$","article","2025-9-29-Chasing-the-Tail-Effective-Rubric-based-Reward-Modeling-for-Large-Language-Model-Post-Training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-Chasing-the-Tail-Effective-Rubric-based-Reward-Modeling-for-Large-Language-Model-Post-Training/","children":"[논문리뷰] Chasing the Tail: Effective Rubric-based Reward Modeling for Large Language Model Post-Training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Chasing the Tail: Effective Rubric-based Reward Modeling for Large Language Model Post-Training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Reinforcement Fine-tuning",{"className":"page__taxonomy-item","children":["#","Reinforcement Fine-tuning"]}],["$","span","Reward Modeling",{"className":"page__taxonomy-item","children":["#","Reward Modeling"]}],["$","span","Reward Over-optimization",{"className":"page__taxonomy-item","children":["#","Reward Over-optimization"]}],["$","span","Rubric-based Rewards",{"className":"page__taxonomy-item","children":["#","Rubric-based Rewards"]}],["$","span","High-reward Tail",{"className":"page__taxonomy-item","children":["#","High-reward Tail"]}],["$","span","Off-policy Data",{"className":"page__taxonomy-item","children":["#","Off-policy Data"]}],["$","span","LLM Alignment",{"className":"page__taxonomy-item","children":["#","LLM Alignment"]}]]}]]}]]}],["$","article","2025-9-29-CapRL-Stimulating-Dense-Image-Caption-Capabilities-via-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-CapRL-Stimulating-Dense-Image-Caption-Capabilities-via-Reinforcement-Learning/","children":"[논문리뷰] CapRL: Stimulating Dense Image Caption Capabilities via Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'CapRL: Stimulating Dense Image Caption Capabilities via Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Captioning",{"className":"page__taxonomy-item","children":["#","Image Captioning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Verifiable Rewards",{"className":"page__taxonomy-item","children":["#","Verifiable Rewards"]}],["$","span","LVLMs",{"className":"page__taxonomy-item","children":["#","LVLMs"]}],["$","span","VQA",{"className":"page__taxonomy-item","children":["#","VQA"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Caption Quality",{"className":"page__taxonomy-item","children":["#","Caption Quality"]}]]}]]}]]}],["$","article","2025-9-29-CHURRO-Making-History-Readable-with-an-Open-Weight-Large-Vision-Language-Model-for-High-Accuracy-Low-Cost-Historical-Text-Recognition",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-CHURRO-Making-History-Readable-with-an-Open-Weight-Large-Vision-Language-Model-for-High-Accuracy-Low-Cost-Historical-Text-Recognition/","children":"[논문리뷰] CHURRO: Making History Readable with an Open-Weight Large Vision-Language Model for High-Accuracy, Low-Cost Historical Text Recognition"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'CHURRO: Making History Readable with an Open-Weight Large Vision-Language Model for High-Accuracy, Low-Cost Historical Text Recognition' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Historical Text Recognition",{"className":"page__taxonomy-item","children":["#","Historical Text Recognition"]}],["$","span","Vision-Language Model",{"className":"page__taxonomy-item","children":["#","Vision-Language Model"]}],["$","span","Open-Weight Model",{"className":"page__taxonomy-item","children":["#","Open-Weight Model"]}],["$","span","OCR",{"className":"page__taxonomy-item","children":["#","OCR"]}],["$","span","Cultural Heritage",{"className":"page__taxonomy-item","children":["#","Cultural Heritage"]}],["$","span","Low-Cost AI",{"className":"page__taxonomy-item","children":["#","Low-Cost AI"]}],["$","span","Dataset Curation",{"className":"page__taxonomy-item","children":["#","Dataset Curation"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}]]}]]}]]}],["$","article","2025-9-26-When-Judgment-Becomes-Noise-How-Design-Failures-in-LLM-Judge-Benchmarks-Silently-Undermine-Validity",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-When-Judgment-Becomes-Noise-How-Design-Failures-in-LLM-Judge-Benchmarks-Silently-Undermine-Validity/","children":"[논문리뷰] When Judgment Becomes Noise: How Design Failures in LLM Judge Benchmarks Silently Undermine Validity"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"John P Dickerson이 [arXiv]에 게시한 'When Judgment Becomes Noise: How Design Failures in LLM Judge Benchmarks Silently Undermine Validity' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Judge",{"className":"page__taxonomy-item","children":["#","LLM Judge"]}],["$","span","Benchmark Evaluation",{"className":"page__taxonomy-item","children":["#","Benchmark Evaluation"]}],["$","span","Validity",{"className":"page__taxonomy-item","children":["#","Validity"]}],["$","span","Reliability",{"className":"page__taxonomy-item","children":["#","Reliability"]}],["$","span","Psychometrics",{"className":"page__taxonomy-item","children":["#","Psychometrics"]}],["$","span","Factor Analysis",{"className":"page__taxonomy-item","children":["#","Factor Analysis"]}],["$","span","Schema Adherence",{"className":"page__taxonomy-item","children":["#","Schema Adherence"]}],["$","span","ELO Ranking",{"className":"page__taxonomy-item","children":["#","ELO Ranking"]}]]}]]}]]}],["$","article","2025-9-26-VCRL-Variance-based-Curriculum-Reinforcement-Learning-for-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-VCRL-Variance-based-Curriculum-Reinforcement-Learning-for-Large-Language-Models/","children":"[논문리뷰] VCRL: Variance-based Curriculum Reinforcement Learning for Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuewei Zhang이 [arXiv]에 게시한 'VCRL: Variance-based Curriculum Reinforcement Learning for Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Variance-based Sampling",{"className":"page__taxonomy-item","children":["#","Variance-based Sampling"]}],["$","span","Replay Learning",{"className":"page__taxonomy-item","children":["#","Replay Learning"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}]]}]]}]]}],["$","article","2025-9-26-V-GameGym-Visual-Game-Generation-for-Code-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-V-GameGym-Visual-Game-Generation-for-Code-Large-Language-Models/","children":"[논문리뷰] V-GameGym: Visual Game Generation for Code Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shawn Guo이 [arXiv]에 게시한 'V-GameGym: Visual Game Generation for Code Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Code Large Language Models",{"className":"page__taxonomy-item","children":["#","Code Large Language Models"]}],["$","span","Visual Game Generation",{"className":"page__taxonomy-item","children":["#","Visual Game Generation"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Pygame",{"className":"page__taxonomy-item","children":["#","Pygame"]}],["$","span","Multimodal Evaluation",{"className":"page__taxonomy-item","children":["#","Multimodal Evaluation"]}],["$","span","Software Engineering",{"className":"page__taxonomy-item","children":["#","Software Engineering"]}],["$","span","AI-assisted Game Development",{"className":"page__taxonomy-item","children":["#","AI-assisted Game Development"]}]]}]]}]]}],["$","article","2025-9-26-Understanding-the-Thinking-Process-of-Reasoning-Models-A-Perspective-from-Schoenfelds-Episode-Theory",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-Understanding-the-Thinking-Process-of-Reasoning-Models-A-Perspective-from-Schoenfelds-Episode-Theory/","children":"[논문리뷰] Understanding the Thinking Process of Reasoning Models: A Perspective from Schoenfeld's Episode Theory"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yanbin Fu이 [arXiv]에 게시한 'Understanding the Thinking Process of Reasoning Models: A Perspective from Schoenfeld's Episode Theory' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Reasoning Models",{"className":"page__taxonomy-item","children":["#","Large Reasoning Models"]}],["$","span","Cognitive Science",{"className":"page__taxonomy-item","children":["#","Cognitive Science"]}],["$","span","Schoenfeld's Episode Theory",{"className":"page__taxonomy-item","children":["#","Schoenfeld's Episode Theory"]}],["$","span","Math Problem Solving",{"className":"page__taxonomy-item","children":["#","Math Problem Solving"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Behavioral Analysis",{"className":"page__taxonomy-item","children":["#","Behavioral Analysis"]}],["$","span","Dataset Annotation",{"className":"page__taxonomy-item","children":["#","Dataset Annotation"]}]]}]]}]]}],["$","article","2025-9-26-TrustJudge-Inconsistencies-of-LLM-as-a-Judge-and-How-to-Alleviate-Them",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-TrustJudge-Inconsistencies-of-LLM-as-a-Judge-and-How-to-Alleviate-Them/","children":"[논문리뷰] TrustJudge: Inconsistencies of LLM-as-a-Judge and How to Alleviate Them"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhuohao Yu이 [arXiv]에 게시한 'TrustJudge: Inconsistencies of LLM-as-a-Judge and How to Alleviate Them' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM-as-a-Judge",{"className":"page__taxonomy-item","children":["#","LLM-as-a-Judge"]}],["$","span","Evaluation Frameworks",{"className":"page__taxonomy-item","children":["#","Evaluation Frameworks"]}],["$","span","Inconsistency Reduction",{"className":"page__taxonomy-item","children":["#","Inconsistency Reduction"]}],["$","span","Probabilistic Scoring",{"className":"page__taxonomy-item","children":["#","Probabilistic Scoring"]}],["$","span","Transitivity",{"className":"page__taxonomy-item","children":["#","Transitivity"]}],["$","span","Information Loss",{"className":"page__taxonomy-item","children":["#","Information Loss"]}],["$","span","Perplexity",{"className":"page__taxonomy-item","children":["#","Perplexity"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}]]}]]}]]}],["$","article","2025-9-26-Tree-Search-for-LLM-Agent-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-Tree-Search-for-LLM-Agent-Reinforcement-Learning/","children":"[논문리뷰] Tree Search for LLM Agent Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiangxiang Chu이 [arXiv]에 게시한 'Tree Search for LLM Agent Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Tree Search",{"className":"page__taxonomy-item","children":["#","Tree Search"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Preference Learning",{"className":"page__taxonomy-item","children":["#","Preference Learning"]}],["$","span","Sparse Rewards",{"className":"page__taxonomy-item","children":["#","Sparse Rewards"]}],["$","span","Multi-turn Tasks",{"className":"page__taxonomy-item","children":["#","Multi-turn Tasks"]}]]}]]}]]}],["$","article","2025-9-26-Thinking-While-Listening-Simple-Test-Time-Scaling-For-Audio-Classification",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-Thinking-While-Listening-Simple-Test-Time-Scaling-For-Audio-Classification/","children":"[논문리뷰] Thinking While Listening: Simple Test Time Scaling For Audio Classification"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Mert Pilanci이 [arXiv]에 게시한 'Thinking While Listening: Simple Test Time Scaling For Audio Classification' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Audio Classification",{"className":"page__taxonomy-item","children":["#","Audio Classification"]}],["$","span","Test-Time Scaling",{"className":"page__taxonomy-item","children":["#","Test-Time Scaling"]}],["$","span","Reasoning Traces",{"className":"page__taxonomy-item","children":["#","Reasoning Traces"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Transformer Architectures",{"className":"page__taxonomy-item","children":["#","Transformer Architectures"]}],["$","span","Zero-shot Reasoning",{"className":"page__taxonomy-item","children":["#","Zero-shot Reasoning"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}]]}]]}]]}],["$","article","2025-9-26-Thinking-Augmented-Pre-training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-Thinking-Augmented-Pre-training/","children":"[논문리뷰] Thinking Augmented Pre-training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Furu Wei이 [arXiv]에 게시한 'Thinking Augmented Pre-training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Pre-training",{"className":"page__taxonomy-item","children":["#","Pre-training"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Data Efficiency",{"className":"page__taxonomy-item","children":["#","Data Efficiency"]}],["$","span","Thinking Trajectories",{"className":"page__taxonomy-item","children":["#","Thinking Trajectories"]}]]}]]}]]}],["$","article","2025-9-26-The-Unanticipated-Asymmetry-Between-Perceptual-Optimization-and-Assessment",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-The-Unanticipated-Asymmetry-Between-Perceptual-Optimization-and-Assessment/","children":"[논문리뷰] The Unanticipated Asymmetry Between Perceptual Optimization and Assessment"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Du Chen이 [arXiv]에 게시한 'The Unanticipated Asymmetry Between Perceptual Optimization and Assessment' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Perceptual Optimization",{"className":"page__taxonomy-item","children":["#","Perceptual Optimization"]}],["$","span","Image Quality Assessment (IQA)",{"className":"page__taxonomy-item","children":["#","Image Quality Assessment (IQA)"]}],["$","span","Adversarial Training",{"className":"page__taxonomy-item","children":["#","Adversarial Training"]}],["$","span","Discriminators",{"className":"page__taxonomy-item","children":["#","Discriminators"]}],["$","span","Super-Resolution",{"className":"page__taxonomy-item","children":["#","Super-Resolution"]}],["$","span","Fidelity Metrics",{"className":"page__taxonomy-item","children":["#","Fidelity Metrics"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}]]}]]}]]}],["$","article","2025-9-26-StyleBench-Evaluating-thinking-styles-in-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-StyleBench-Evaluating-thinking-styles-in-Large-Language-Models/","children":"[논문리뷰] StyleBench: Evaluating thinking styles in Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Javad Lavaei이 [arXiv]에 게시한 'StyleBench: Evaluating thinking styles in Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reasoning Strategies",{"className":"page__taxonomy-item","children":["#","Reasoning Strategies"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Thinking Styles",{"className":"page__taxonomy-item","children":["#","Thinking Styles"]}],["$","span","Scaling Laws",{"className":"page__taxonomy-item","children":["#","Scaling Laws"]}],["$","span","Meta-Reasoning",{"className":"page__taxonomy-item","children":["#","Meta-Reasoning"]}]]}]]}]]}],["$","article","2025-9-26-Seedream-4-0-Toward-Next-generation-Multimodal-Image-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-Seedream-4-0-Toward-Next-generation-Multimodal-Image-Generation/","children":"[논문리뷰] Seedream 4.0: Toward Next-generation Multimodal Image Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yunpeng Chen이 [arXiv]에 게시한 'Seedream 4.0: Toward Next-generation Multimodal Image Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Image Generation",{"className":"page__taxonomy-item","children":["#","Multimodal Image Generation"]}],["$","span","Diffusion Transformer",{"className":"page__taxonomy-item","children":["#","Diffusion Transformer"]}],["$","span","VAE",{"className":"page__taxonomy-item","children":["#","VAE"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Text-to-Image",{"className":"page__taxonomy-item","children":["#","Text-to-Image"]}],["$","span","Model Acceleration",{"className":"page__taxonomy-item","children":["#","Model Acceleration"]}],["$","span","Human Evaluation",{"className":"page__taxonomy-item","children":["#","Human Evaluation"]}]]}]]}]]}],["$","article","2025-9-26-SciReasoner-Laying-the-Scientific-Reasoning-Ground-Across-Disciplines",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-SciReasoner-Laying-the-Scientific-Reasoning-Ground-Across-Disciplines/","children":"[논문리뷰] SciReasoner: Laying the Scientific Reasoning Ground Across Disciplines"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiabei Xiao이 [arXiv]에 게시한 'SciReasoner: Laying the Scientific Reasoning Ground Across Disciplines' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Scientific Reasoning",{"className":"page__taxonomy-item","children":["#","Scientific Reasoning"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Multi-modal Learning",{"className":"page__taxonomy-item","children":["#","Multi-modal Learning"]}],["$","span","Cross-domain Generalization",{"className":"page__taxonomy-item","children":["#","Cross-domain Generalization"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Scientific Discovery",{"className":"page__taxonomy-item","children":["#","Scientific Discovery"]}],["$","span","Molecular Design",{"className":"page__taxonomy-item","children":["#","Molecular Design"]}]]}]]}]]}],["$","article","2025-9-26-SceneWeaver-All-in-One-3D-Scene-Synthesis-with-an-Extensible-and-Self-Reflective-Agent",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-SceneWeaver-All-in-One-3D-Scene-Synthesis-with-an-Extensible-and-Self-Reflective-Agent/","children":"[논문리뷰] SceneWeaver: All-in-One 3D Scene Synthesis with an Extensible and Self-Reflective Agent"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Siyuan Huang이 [arXiv]에 게시한 'SceneWeaver: All-in-One 3D Scene Synthesis with an Extensible and Self-Reflective Agent' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Scene Synthesis",{"className":"page__taxonomy-item","children":["#","3D Scene Synthesis"]}],["$","span","Agentic Framework",{"className":"page__taxonomy-item","children":["#","Agentic Framework"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Self-Reflection",{"className":"page__taxonomy-item","children":["#","Self-Reflection"]}],["$","span","Tool-Use",{"className":"page__taxonomy-item","children":["#","Tool-Use"]}],["$","span","Physical Plausibility",{"className":"page__taxonomy-item","children":["#","Physical Plausibility"]}],["$","span","Iterative Refinement",{"className":"page__taxonomy-item","children":["#","Iterative Refinement"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}]]}]]}]]}],["$","article","2025-9-26-ScaleDiff-Scaling-Difficult-Problems-for-Advanced-Mathematical-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-ScaleDiff-Scaling-Difficult-Problems-for-Advanced-Mathematical-Reasoning/","children":"[논문리뷰] ScaleDiff: Scaling Difficult Problems for Advanced Mathematical Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yu Li이 [arXiv]에 게시한 'ScaleDiff: Scaling Difficult Problems for Advanced Mathematical Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Large Reasoning Models (LRMs)",{"className":"page__taxonomy-item","children":["#","Large Reasoning Models (LRMs)"]}],["$","span","Difficulty Scaling",{"className":"page__taxonomy-item","children":["#","Difficulty Scaling"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}],["$","span","Supervised Fine-Tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning (SFT)"]}],["$","span","Problem Generation",{"className":"page__taxonomy-item","children":["#","Problem Generation"]}],["$","span","Solution Distillation",{"className":"page__taxonomy-item","children":["#","Solution Distillation"]}]]}]]}]]}],["$","article","2025-9-26-SD3-5-Flash-Distribution-Guided-Distillation-of-Generative-Flows",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-SD3-5-Flash-Distribution-Guided-Distillation-of-Generative-Flows/","children":"[논문리뷰] SD3.5-Flash: Distribution-Guided Distillation of Generative Flows"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yi-Zhe Song이 [arXiv]에 게시한 'SD3.5-Flash: Distribution-Guided Distillation of Generative Flows' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Rectified Flow",{"className":"page__taxonomy-item","children":["#","Rectified Flow"]}],["$","span","Model Distillation",{"className":"page__taxonomy-item","children":["#","Model Distillation"]}],["$","span","Few-Step Generation",{"className":"page__taxonomy-item","children":["#","Few-Step Generation"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}],["$","span","Prompt Alignment",{"className":"page__taxonomy-item","children":["#","Prompt Alignment"]}]]}]]}]]}],["$","article","2025-9-26-Residual-Off-Policy-RL-for-Finetuning-Behavior-Cloning-Policies",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-Residual-Off-Policy-RL-for-Finetuning-Behavior-Cloning-Policies/","children":"[논문리뷰] Residual Off-Policy RL for Finetuning Behavior Cloning Policies"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Pieter Abbeel이 [arXiv]에 게시한 'Residual Off-Policy RL for Finetuning Behavior Cloning Policies' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Behavior Cloning (BC)",{"className":"page__taxonomy-item","children":["#","Behavior Cloning (BC)"]}],["$","span","Residual Learning",{"className":"page__taxonomy-item","children":["#","Residual Learning"]}],["$","span","Off-Policy RL",{"className":"page__taxonomy-item","children":["#","Off-Policy RL"]}],["$","span","Robot Manipulation",{"className":"page__taxonomy-item","children":["#","Robot Manipulation"]}],["$","span","Real-World Robotics",{"className":"page__taxonomy-item","children":["#","Real-World Robotics"]}],["$","span","High-DoF Systems",{"className":"page__taxonomy-item","children":["#","High-DoF Systems"]}],["$","span","Sample Efficiency",{"className":"page__taxonomy-item","children":["#","Sample Efficiency"]}]]}]]}]]}],["$","article","2025-9-26-Recon-Act-A-Self-Evolving-Multi-Agent-Browser-Use-System-via-Web-Reconnaissance-Tool-Generation-and-Task-Execution",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-Recon-Act-A-Self-Evolving-Multi-Agent-Browser-Use-System-via-Web-Reconnaissance-Tool-Generation-and-Task-Execution/","children":"[논문리뷰] Recon-Act: A Self-Evolving Multi-Agent Browser-Use System via Web Reconnaissance, Tool Generation, and Task Execution"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jinjie Gu이 [arXiv]에 게시한 'Recon-Act: A Self-Evolving Multi-Agent Browser-Use System via Web Reconnaissance, Tool Generation, and Task Execution' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-Agent System",{"className":"page__taxonomy-item","children":["#","Multi-Agent System"]}],["$","span","Browser Automation",{"className":"page__taxonomy-item","children":["#","Browser Automation"]}],["$","span","Web Reconnaissance",{"className":"page__taxonomy-item","children":["#","Web Reconnaissance"]}],["$","span","Tool Generation",{"className":"page__taxonomy-item","children":["#","Tool Generation"]}],["$","span","Task Execution",{"className":"page__taxonomy-item","children":["#","Task Execution"]}],["$","span","Self-Evolving AI",{"className":"page__taxonomy-item","children":["#","Self-Evolving AI"]}],["$","span","LLM/VLM",{"className":"page__taxonomy-item","children":["#","LLM/VLM"]}],["$","span","VisualWebArena",{"className":"page__taxonomy-item","children":["#","VisualWebArena"]}]]}]]}]]}],["$","article","2025-9-26-Quantized-Visual-Geometry-Grounded-Transformer",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-Quantized-Visual-Geometry-Grounded-Transformer/","children":"[논문리뷰] Quantized Visual Geometry Grounded Transformer"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuqi Li이 [arXiv]에 게시한 'Quantized Visual Geometry Grounded Transformer' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Quantization",{"className":"page__taxonomy-item","children":["#","Quantization"]}],["$","span","Post-Training Quantization",{"className":"page__taxonomy-item","children":["#","Post-Training Quantization"]}],["$","span","3D Reconstruction",{"className":"page__taxonomy-item","children":["#","3D Reconstruction"]}],["$","span","Visual Transformer",{"className":"page__taxonomy-item","children":["#","Visual Transformer"]}],["$","span","Model Compression",{"className":"page__taxonomy-item","children":["#","Model Compression"]}],["$","span","Efficient Inference",{"className":"page__taxonomy-item","children":["#","Efficient Inference"]}],["$","span","Hadamard Rotation",{"className":"page__taxonomy-item","children":["#","Hadamard Rotation"]}],["$","span","Calibration Sampling",{"className":"page__taxonomy-item","children":["#","Calibration Sampling"]}]]}]]}]]}],["$","article","2025-9-26-MOSS-ChatV-Reinforcement-Learning-with-Process-Reasoning-Reward-for-Video-Temporal-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-MOSS-ChatV-Reinforcement-Learning-with-Process-Reasoning-Reward-for-Video-Temporal-Reasoning/","children":"[논문리뷰] MOSS-ChatV: Reinforcement Learning with Process Reasoning Reward for Video Temporal Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Junyan Zhang이 [arXiv]에 게시한 'MOSS-ChatV: Reinforcement Learning with Process Reasoning Reward for Video Temporal Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Temporal Reasoning",{"className":"page__taxonomy-item","children":["#","Video Temporal Reasoning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Process Supervision",{"className":"page__taxonomy-item","children":["#","Process Supervision"]}],["$","span","Dynamic Time Warping",{"className":"page__taxonomy-item","children":["#","Dynamic Time Warping"]}],["$","span","Multimodal Large Language Models",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models"]}],["$","span","Video State Prediction",{"className":"page__taxonomy-item","children":["#","Video State Prediction"]}],["$","span","Reward Hacking",{"className":"page__taxonomy-item","children":["#","Reward Hacking"]}]]}]]}]]}],["$","article","2025-9-26-MMR1-Enhancing-Multimodal-Reasoning-with-Variance-Aware-Sampling-and-Open-Resources",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-MMR1-Enhancing-Multimodal-Reasoning-with-Variance-Aware-Sampling-and-Open-Resources/","children":"[논문리뷰] MMR1: Enhancing Multimodal Reasoning with Variance-Aware Sampling and Open Resources"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jing Wang이 [arXiv]에 게시한 'MMR1: Enhancing Multimodal Reasoning with Variance-Aware Sampling and Open Resources' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Variance-Aware Sampling",{"className":"page__taxonomy-item","children":["#","Variance-Aware Sampling"]}],["$","span","Gradient Vanishing",{"className":"page__taxonomy-item","children":["#","Gradient Vanishing"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","GRPO",{"className":"page__taxonomy-item","children":["#","GRPO"]}]]}]]}]]}],["$","article","2025-9-26-MI-Fuse-Label-Fusion-for-Unsupervised-Domain-Adaptation-with-Closed-Source-Large-Audio-Language-Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-MI-Fuse-Label-Fusion-for-Unsupervised-Domain-Adaptation-with-Closed-Source-Large-Audio-Language-Model/","children":"[논문리뷰] MI-Fuse: Label Fusion for Unsupervised Domain Adaptation with Closed-Source Large-Audio Language Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hung-yi Lee이 [arXiv]에 게시한 'MI-Fuse: Label Fusion for Unsupervised Domain Adaptation with Closed-Source Large-Audio Language Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Speech Emotion Recognition",{"className":"page__taxonomy-item","children":["#","Speech Emotion Recognition"]}],["$","span","Source-Free Unsupervised Domain Adaptation",{"className":"page__taxonomy-item","children":["#","Source-Free Unsupervised Domain Adaptation"]}],["$","span","Large Audio-Language Models",{"className":"page__taxonomy-item","children":["#","Large Audio-Language Models"]}],["$","span","Label Fusion",{"className":"page__taxonomy-item","children":["#","Label Fusion"]}],["$","span","Mutual Information",{"className":"page__taxonomy-item","children":["#","Mutual Information"]}],["$","span","API-Only Models",{"className":"page__taxonomy-item","children":["#","API-Only Models"]}],["$","span","Domain Mismatch",{"className":"page__taxonomy-item","children":["#","Domain Mismatch"]}]]}]]}]]}],["$","article","2025-9-26-Interactive-Recommendation-Agent-with-Active-User-Commands",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-Interactive-Recommendation-Agent-with-Active-User-Commands/","children":"[논문리뷰] Interactive Recommendation Agent with Active User Commands"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xueyang Feng이 [arXiv]에 게시한 'Interactive Recommendation Agent with Active User Commands' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Interactive Recommendation",{"className":"page__taxonomy-item","children":["#","Interactive Recommendation"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Multi-Agent System",{"className":"page__taxonomy-item","children":["#","Multi-Agent System"]}],["$","span","Natural Language Processing",{"className":"page__taxonomy-item","children":["#","Natural Language Processing"]}],["$","span","Knowledge Distillation",{"className":"page__taxonomy-item","children":["#","Knowledge Distillation"]}],["$","span","User Control",{"className":"page__taxonomy-item","children":["#","User Control"]}]]}]]}]]}],["$","article","2025-9-26-Hunyuan3D-Omni-A-Unified-Framework-for-Controllable-Generation-of-3D-Assets",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-Hunyuan3D-Omni-A-Unified-Framework-for-Controllable-Generation-of-3D-Assets/","children":"[논문리뷰] Hunyuan3D-Omni: A Unified Framework for Controllable Generation of 3D Assets"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Bowen Zhang이 [arXiv]에 게시한 'Hunyuan3D-Omni: A Unified Framework for Controllable Generation of 3D Assets' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Generation",{"className":"page__taxonomy-item","children":["#","3D Generation"]}],["$","span","Controllable Generation",{"className":"page__taxonomy-item","children":["#","Controllable Generation"]}],["$","span","Multi-modal Conditioning",{"className":"page__taxonomy-item","children":["#","Multi-modal Conditioning"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Point Clouds",{"className":"page__taxonomy-item","children":["#","Point Clouds"]}],["$","span","Voxels",{"className":"page__taxonomy-item","children":["#","Voxels"]}],["$","span","Bounding Boxes",{"className":"page__taxonomy-item","children":["#","Bounding Boxes"]}],["$","span","Skeletons",{"className":"page__taxonomy-item","children":["#","Skeletons"]}],["$","span","Hunyuan3D",{"className":"page__taxonomy-item","children":["#","Hunyuan3D"]}]]}]]}]]}],["$","article","2025-9-26-Does-FLUX-Already-Know-How-to-Perform-Physically-Plausible-Image-Composition",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-Does-FLUX-Already-Know-How-to-Perform-Physically-Plausible-Image-Composition/","children":"[논문리뷰] Does FLUX Already Know How to Perform Physically Plausible Image Composition?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chen Zhao이 [arXiv]에 게시한 'Does FLUX Already Know How to Perform Physically Plausible Image Composition?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Composition",{"className":"page__taxonomy-item","children":["#","Image Composition"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}],["$","span","Physically Plausible",{"className":"page__taxonomy-item","children":["#","Physically Plausible"]}],["$","span","FLUX",{"className":"page__taxonomy-item","children":["#","FLUX"]}],["$","span","Adapter",{"className":"page__taxonomy-item","children":["#","Adapter"]}],["$","span","Guidance",{"className":"page__taxonomy-item","children":["#","Guidance"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}]]}]]}]]}],["$","article","2025-9-26-Discrete-Diffusion-for-Reflective-Vision-Language-Action-Models-in-Autonomous-Driving",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-Discrete-Diffusion-for-Reflective-Vision-Language-Action-Models-in-Autonomous-Driving/","children":"[논문리뷰] Discrete Diffusion for Reflective Vision-Language-Action Models in Autonomous Driving"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hang Zhao이 [arXiv]에 게시한 'Discrete Diffusion for Reflective Vision-Language-Action Models in Autonomous Driving' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Autonomous Driving",{"className":"page__taxonomy-item","children":["#","Autonomous Driving"]}],["$","span","Vision-Language-Action Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action Models"]}],["$","span","Discrete Diffusion",{"className":"page__taxonomy-item","children":["#","Discrete Diffusion"]}],["$","span","Reflection Mechanism",{"className":"page__taxonomy-item","children":["#","Reflection Mechanism"]}],["$","span","Trajectory Generation",{"className":"page__taxonomy-item","children":["#","Trajectory Generation"]}],["$","span","Safety Constraints",{"className":"page__taxonomy-item","children":["#","Safety Constraints"]}],["$","span","Imitation Learning",{"className":"page__taxonomy-item","children":["#","Imitation Learning"]}]]}]]}]]}],["$","article","2025-9-26-CHARM-Control-point-based-3D-Anime-Hairstyle-Auto-Regressive-Modeling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-CHARM-Control-point-based-3D-Anime-Hairstyle-Auto-Regressive-Modeling/","children":"[논문리뷰] CHARM: Control-point-based 3D Anime Hairstyle Auto-Regressive Modeling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yushi Bai이 [arXiv]에 게시한 'CHARM: Control-point-based 3D Anime Hairstyle Auto-Regressive Modeling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Anime Hairstyle",{"className":"page__taxonomy-item","children":["#","3D Anime Hairstyle"]}],["$","span","Autoregressive Modeling",{"className":"page__taxonomy-item","children":["#","Autoregressive Modeling"]}],["$","span","Control Points",{"className":"page__taxonomy-item","children":["#","Control Points"]}],["$","span","Parametric Representation",{"className":"page__taxonomy-item","children":["#","Parametric Representation"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Dataset (AnimeHair)",{"className":"page__taxonomy-item","children":["#","Dataset (AnimeHair)"]}],["$","span","Computer Graphics",{"className":"page__taxonomy-item","children":["#","Computer Graphics"]}]]}]]}]]}],["$","article","2025-9-26-CE-GPPO-Controlling-Entropy-via-Gradient-Preserving-Clipping-Policy-Optimization-in-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-CE-GPPO-Controlling-Entropy-via-Gradient-Preserving-Clipping-Policy-Optimization-in-Reinforcement-Learning/","children":"[논문리뷰] CE-GPPO: Controlling Entropy via Gradient-Preserving Clipping Policy Optimization in Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wenping Hu이 [arXiv]에 게시한 'CE-GPPO: Controlling Entropy via Gradient-Preserving Clipping Policy Optimization in Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","PPO",{"className":"page__taxonomy-item","children":["#","PPO"]}],["$","span","Entropy Control",{"className":"page__taxonomy-item","children":["#","Entropy Control"]}],["$","span","Gradient Clipping",{"className":"page__taxonomy-item","children":["#","Gradient Clipping"]}],["$","span","Exploration-Exploitation",{"className":"page__taxonomy-item","children":["#","Exploration-Exploitation"]}]]}]]}]]}],["$","article","2025-9-26-Blueprints-of-Trust-AI-System-Cards-for-End-to-End-Transparency-and-Governance",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-Blueprints-of-Trust-AI-System-Cards-for-End-to-End-Transparency-and-Governance/","children":"[논문리뷰] Blueprints of Trust: AI System Cards for End to End Transparency and Governance"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Roman Zhukov이 [arXiv]에 게시한 'Blueprints of Trust: AI System Cards for End to End Transparency and Governance' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Governance",{"className":"page__taxonomy-item","children":["#","AI Governance"]}],["$","span","Transparency",{"className":"page__taxonomy-item","children":["#","Transparency"]}],["$","span","AI System Card",{"className":"page__taxonomy-item","children":["#","AI System Card"]}],["$","span","Hazard-Aware System Card",{"className":"page__taxonomy-item","children":["#","Hazard-Aware System Card"]}],["$","span","Data Provenance",{"className":"page__taxonomy-item","children":["#","Data Provenance"]}],["$","span","AI Safety",{"className":"page__taxonomy-item","children":["#","AI Safety"]}],["$","span","AI Risk Management",{"className":"page__taxonomy-item","children":["#","AI Risk Management"]}],["$","span","ISO/IEC 42001",{"className":"page__taxonomy-item","children":["#","ISO/IEC 42001"]}]]}]]}]]}],["$","article","2025-9-26-Behind-RoPE-How-Does-Causal-Mask-Encode-Positional-Information",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-Behind-RoPE-How-Does-Causal-Mask-Encode-Positional-Information/","children":"[논문리뷰] Behind RoPE: How Does Causal Mask Encode Positional Information?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yeyun Gong이 [arXiv]에 게시한 'Behind RoPE: How Does Causal Mask Encode Positional Information?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Transformer Decoder",{"className":"page__taxonomy-item","children":["#","Transformer Decoder"]}],["$","span","Causal Mask",{"className":"page__taxonomy-item","children":["#","Causal Mask"]}],["$","span","Positional Encoding",{"className":"page__taxonomy-item","children":["#","Positional Encoding"]}],["$","span","RoPE",{"className":"page__taxonomy-item","children":["#","RoPE"]}],["$","span","Attention Mechanism",{"className":"page__taxonomy-item","children":["#","Attention Mechanism"]}],["$","span","Length Generalization",{"className":"page__taxonomy-item","children":["#","Length Generalization"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}]]}]]}]]}],["$","article","2025-9-26-BESPOKE-Benchmark-for-Search-Augmented-Large-Language-Model-Personalization-via-Diagnostic-Feedback",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-BESPOKE-Benchmark-for-Search-Augmented-Large-Language-Model-Personalization-via-Diagnostic-Feedback/","children":"[논문리뷰] BESPOKE: Benchmark for Search-Augmented Large Language Model Personalization via Diagnostic Feedback"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Dongha Lee이 [arXiv]에 게시한 'BESPOKE: Benchmark for Search-Augmented Large Language Model Personalization via Diagnostic Feedback' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Search-Augmented LLMs",{"className":"page__taxonomy-item","children":["#","Search-Augmented LLMs"]}],["$","span","Personalization",{"className":"page__taxonomy-item","children":["#","Personalization"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Diagnostic Feedback",{"className":"page__taxonomy-item","children":["#","Diagnostic Feedback"]}],["$","span","User History",{"className":"page__taxonomy-item","children":["#","User History"]}],["$","span","Evaluation Framework",{"className":"page__taxonomy-item","children":["#","Evaluation Framework"]}],["$","span","RAG",{"className":"page__taxonomy-item","children":["#","RAG"]}]]}]]}]]}],["$","article","2025-9-26-AutoIntent-AutoML-for-Text-Classification",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-AutoIntent-AutoML-for-Text-Classification/","children":"[논문리뷰] AutoIntent: AutoML for Text Classification"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Denis Kuznetsov이 [arXiv]에 게시한 'AutoIntent: AutoML for Text Classification' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AutoML",{"className":"page__taxonomy-item","children":["#","AutoML"]}],["$","span","Text Classification",{"className":"page__taxonomy-item","children":["#","Text Classification"]}],["$","span","Intent Classification",{"className":"page__taxonomy-item","children":["#","Intent Classification"]}],["$","span","Transformer Embeddings",{"className":"page__taxonomy-item","children":["#","Transformer Embeddings"]}],["$","span","Out-of-Scope Detection",{"className":"page__taxonomy-item","children":["#","Out-of-Scope Detection"]}],["$","span","Multi-label Classification",{"className":"page__taxonomy-item","children":["#","Multi-label Classification"]}],["$","span","Few-shot Learning",{"className":"page__taxonomy-item","children":["#","Few-shot Learning"]}],["$","span","Sklearn-like Interface",{"className":"page__taxonomy-item","children":["#","Sklearn-like Interface"]}]]}]]}]]}],["$","article","2025-9-25-Video-models-are-zero-shot-learners-and-reasoners",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-25-Video-models-are-zero-shot-learners-and-reasoners/","children":"[논문리뷰] Video models are zero-shot learners and reasoners"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"rgeirhos이 [arXiv]에 게시한 'Video models are zero-shot learners and reasoners' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-25 13:08:16+0900","children":"2025년 9월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Models",{"className":"page__taxonomy-item","children":["#","Video Models"]}],["$","span","Zero-shot Learning",{"className":"page__taxonomy-item","children":["#","Zero-shot Learning"]}],["$","span","Visual Reasoning",{"className":"page__taxonomy-item","children":["#","Visual Reasoning"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Perception",{"className":"page__taxonomy-item","children":["#","Perception"]}],["$","span","Manipulation",{"className":"page__taxonomy-item","children":["#","Manipulation"]}],["$","span","Modeling",{"className":"page__taxonomy-item","children":["#","Modeling"]}]]}]]}]]}],["$","article","2025-9-25-SIM-CoT-Supervised-Implicit-Chain-of-Thought",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-25-SIM-CoT-Supervised-Implicit-Chain-of-Thought/","children":"[논문리뷰] SIM-CoT: Supervised Implicit Chain-of-Thought"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuhang Cao이 [arXiv]에 게시한 'SIM-CoT: Supervised Implicit Chain-of-Thought' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-25 13:08:16+0900","children":"2025년 9월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Implicit Reasoning",{"className":"page__taxonomy-item","children":["#","Implicit Reasoning"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Latent Space",{"className":"page__taxonomy-item","children":["#","Latent Space"]}],["$","span","Supervised Learning",{"className":"page__taxonomy-item","children":["#","Supervised Learning"]}],["$","span","Model Stability",{"className":"page__taxonomy-item","children":["#","Model Stability"]}],["$","span","Interpretability",{"className":"page__taxonomy-item","children":["#","Interpretability"]}]]}]]}]]}],["$","article","2025-9-25-PhysCtrl-Generative-Physics-for-Controllable-and-Physics-Grounded-Video-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-25-PhysCtrl-Generative-Physics-for-Controllable-and-Physics-Grounded-Video-Generation/","children":"[논문리뷰] PhysCtrl: Generative Physics for Controllable and Physics-Grounded Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yiming Huang이 [arXiv]에 게시한 'PhysCtrl: Generative Physics for Controllable and Physics-Grounded Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-25 13:08:16+0900","children":"2025년 9월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Physics-Grounded",{"className":"page__taxonomy-item","children":["#","Physics-Grounded"]}],["$","span","Controllable Generation",{"className":"page__taxonomy-item","children":["#","Controllable Generation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Point Cloud Trajectories",{"className":"page__taxonomy-item","children":["#","Point Cloud Trajectories"]}],["$","span","Material Simulation",{"className":"page__taxonomy-item","children":["#","Material Simulation"]}],["$","span","Generative Physics",{"className":"page__taxonomy-item","children":["#","Generative Physics"]}]]}]]}]]}],["$","article","2025-9-25-On-the-Use-of-Agentic-Coding-An-Empirical-Study-of-Pull-Requests-on-GitHub",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-25-On-the-Use-of-Agentic-Coding-An-Empirical-Study-of-Pull-Requests-on-GitHub/","children":"[논문리뷰] On the Use of Agentic Coding: An Empirical Study of Pull Requests on GitHub"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hajimu Iida이 [arXiv]에 게시한 'On the Use of Agentic Coding: An Empirical Study of Pull Requests on GitHub' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-25 13:08:16+0900","children":"2025년 9월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic Coding",{"className":"page__taxonomy-item","children":["#","Agentic Coding"]}],["$","span","AI Agents",{"className":"page__taxonomy-item","children":["#","AI Agents"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","GitHub Pull Requests",{"className":"page__taxonomy-item","children":["#","GitHub Pull Requests"]}],["$","span","Software Engineering",{"className":"page__taxonomy-item","children":["#","Software Engineering"]}],["$","span","Empirical Study",{"className":"page__taxonomy-item","children":["#","Empirical Study"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","Software Development",{"className":"page__taxonomy-item","children":["#","Software Development"]}]]}]]}]]}],["$","article","2025-9-25-Logics-Parsing-Technical-Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-25-Logics-Parsing-Technical-Report/","children":"[논문리뷰] Logics-Parsing Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Fan Yang이 [arXiv]에 게시한 'Logics-Parsing Technical Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-25 13:08:16+0900","children":"2025년 9월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Document Parsing",{"className":"page__taxonomy-item","children":["#","Document Parsing"]}],["$","span","Large Vision-Language Models (LVLM)",{"className":"page__taxonomy-item","children":["#","Large Vision-Language Models (LVLM)"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Layout Analysis",{"className":"page__taxonomy-item","children":["#","Layout Analysis"]}],["$","span","Reading Order",{"className":"page__taxonomy-item","children":["#","Reading Order"]}],["$","span","Supervised Fine-Tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning (SFT)"]}],["$","span","HTML Annotation",{"className":"page__taxonomy-item","children":["#","HTML Annotation"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}]]}]]}]]}],["$","article","2025-9-25-Lavida-O-Elastic-Large-Masked-Diffusion-Models-for-Unified-Multimodal-Understanding-and-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-25-Lavida-O-Elastic-Large-Masked-Diffusion-Models-for-Unified-Multimodal-Understanding-and-Generation/","children":"[논문리뷰] Lavida-O: Elastic Large Masked Diffusion Models for Unified Multimodal Understanding and Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhe Lin이 [arXiv]에 게시한 'Lavida-O: Elastic Large Masked Diffusion Models for Unified Multimodal Understanding and Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-25 13:08:16+0900","children":"2025년 9월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Masked Diffusion Models",{"className":"page__taxonomy-item","children":["#","Masked Diffusion Models"]}],["$","span","Image Understanding",{"className":"page__taxonomy-item","children":["#","Image Understanding"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Object Grounding",{"className":"page__taxonomy-item","children":["#","Object Grounding"]}],["$","span","ElasticMoT",{"className":"page__taxonomy-item","children":["#","ElasticMoT"]}],["$","span","Self-reflection",{"className":"page__taxonomy-item","children":["#","Self-reflection"]}]]}]]}]]}],["$","article","2025-9-25-LLMs4All-A-Review-on-Large-Language-Models-for-Research-and-Applications-in-Academic-Disciplines",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-25-LLMs4All-A-Review-on-Large-Language-Models-for-Research-and-Applications-in-Academic-Disciplines/","children":"[논문리뷰] LLMs4All: A Review on Large Language Models for Research and Applications in Academic Disciplines"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yanfang이 [arXiv]에 게시한 'LLMs4All: A Review on Large Language Models for Research and Applications in Academic Disciplines' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-25 13:08:16+0900","children":"2025년 9월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Academic Disciplines",{"className":"page__taxonomy-item","children":["#","Academic Disciplines"]}],["$","span","LLM Applications",{"className":"page__taxonomy-item","children":["#","LLM Applications"]}],["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Cross-disciplinary Research",{"className":"page__taxonomy-item","children":["#","Cross-disciplinary Research"]}],["$","span","Benchmarks",{"className":"page__taxonomy-item","children":["#","Benchmarks"]}]]}]]}]]}],["$","article","2025-9-25-EmbeddingGemma-Powerful-and-Lightweight-Text-Representations",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-25-EmbeddingGemma-Powerful-and-Lightweight-Text-Representations/","children":"[논문리뷰] EmbeddingGemma: Powerful and Lightweight Text Representations"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Marksherwood이 [arXiv]에 게시한 'EmbeddingGemma: Powerful and Lightweight Text Representations' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-25 13:08:16+0900","children":"2025년 9월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text Embeddings",{"className":"page__taxonomy-item","children":["#","Text Embeddings"]}],["$","span","Lightweight Models",{"className":"page__taxonomy-item","children":["#","Lightweight Models"]}],["$","span","Encoder-Decoder",{"className":"page__taxonomy-item","children":["#","Encoder-Decoder"]}],["$","span","Knowledge Distillation",{"className":"page__taxonomy-item","children":["#","Knowledge Distillation"]}],["$","span","Model Souping",{"className":"page__taxonomy-item","children":["#","Model Souping"]}],["$","span","Quantization",{"className":"page__taxonomy-item","children":["#","Quantization"]}],["$","span","Multilingual",{"className":"page__taxonomy-item","children":["#","Multilingual"]}],["$","span","Gemma",{"className":"page__taxonomy-item","children":["#","Gemma"]}]]}]]}]]}],["$","article","2025-9-25-EditVerse-Unifying-Image-and-Video-Editing-and-Generation-with-In-Context-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-25-EditVerse-Unifying-Image-and-Video-Editing-and-Generation-with-In-Context-Learning/","children":"[논문리뷰] EditVerse: Unifying Image and Video Editing and Generation with In-Context Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Tianyu Wang이 [arXiv]에 게시한 'EditVerse: Unifying Image and Video Editing and Generation with In-Context Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-25 13:08:16+0900","children":"2025년 9월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Unified Multimodal Model",{"className":"page__taxonomy-item","children":["#","Unified Multimodal Model"]}],["$","span","In-Context Learning",{"className":"page__taxonomy-item","children":["#","In-Context Learning"]}],["$","span","Image and Video Editing",{"className":"page__taxonomy-item","children":["#","Image and Video Editing"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Full Self-Attention",{"className":"page__taxonomy-item","children":["#","Full Self-Attention"]}],["$","span","Rotary Positional Embedding",{"className":"page__taxonomy-item","children":["#","Rotary Positional Embedding"]}],["$","span","Cross-Modal Knowledge Transfer",{"className":"page__taxonomy-item","children":["#","Cross-Modal Knowledge Transfer"]}]]}]]}]]}],["$","article","2025-9-25-Advancing-Speech-Understanding-in-Speech-Aware-Language-Models-with-GRPO",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-25-Advancing-Speech-Understanding-in-Speech-Aware-Language-Models-with-GRPO/","children":"[논문리뷰] Advancing Speech Understanding in Speech-Aware Language Models with GRPO"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Avihu이 [arXiv]에 게시한 'Advancing Speech Understanding in Speech-Aware Language Models with GRPO' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-25 13:08:16+0900","children":"2025년 9월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Speech-Aware Language Models",{"className":"page__taxonomy-item","children":["#","Speech-Aware Language Models"]}],["$","span","SALLMs",{"className":"page__taxonomy-item","children":["#","SALLMs"]}],["$","span","GRPO",{"className":"page__taxonomy-item","children":["#","GRPO"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Speech Understanding",{"className":"page__taxonomy-item","children":["#","Speech Understanding"]}],["$","span","Spoken Question Answering",{"className":"page__taxonomy-item","children":["#","Spoken Question Answering"]}],["$","span","Automatic Speech Translation",{"className":"page__taxonomy-item","children":["#","Automatic Speech Translation"]}],["$","span","BLEU Metric",{"className":"page__taxonomy-item","children":["#","BLEU Metric"]}]]}]]}]]}],["$","article","2025-9-24-Zero-Shot-Multi-Spectral-Learning-Reimagining-a-Generalist-Multimodal-Gemini-2-5-Model-for-Remote-Sensing-Applications",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-24-Zero-Shot-Multi-Spectral-Learning-Reimagining-a-Generalist-Multimodal-Gemini-2-5-Model-for-Remote-Sensing-Applications/","children":"[논문리뷰] Zero-Shot Multi-Spectral Learning: Reimagining a Generalist Multimodal Gemini 2.5 Model for Remote Sensing Applications"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Genady Beryozkin이 [arXiv]에 게시한 'Zero-Shot Multi-Spectral Learning: Reimagining a Generalist Multimodal Gemini 2.5 Model for Remote Sensing Applications' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-24 13:14:19+0900","children":"2025년 9월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Remote Sensing",{"className":"page__taxonomy-item","children":["#","Remote Sensing"]}],["$","span","Zero-Shot Learning",{"className":"page__taxonomy-item","children":["#","Zero-Shot Learning"]}],["$","span","Multimodal Models",{"className":"page__taxonomy-item","children":["#","Multimodal Models"]}],["$","span","Multi-spectral Imagery",{"className":"page__taxonomy-item","children":["#","Multi-spectral Imagery"]}],["$","span","Gemini 2.5",{"className":"page__taxonomy-item","children":["#","Gemini 2.5"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","Land Cover Classification",{"className":"page__taxonomy-item","children":["#","Land Cover Classification"]}],["$","span","Pseudo-Image",{"className":"page__taxonomy-item","children":["#","Pseudo-Image"]}]]}]]}]]}],["$","article","2025-9-24-What-Characterizes-Effective-Reasoning-Revisiting-Length-Review-and-Structure-of-CoT",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-24-What-Characterizes-Effective-Reasoning-Revisiting-Length-Review-and-Structure-of-CoT/","children":"[논문리뷰] What Characterizes Effective Reasoning? Revisiting Length, Review, and Structure of CoT"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Anthony Hartshorn이 [arXiv]에 게시한 'What Characterizes Effective Reasoning? Revisiting Length, Review, and Structure of CoT' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-24 13:14:19+0900","children":"2025년 9월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Reasoning Effectiveness",{"className":"page__taxonomy-item","children":["#","Reasoning Effectiveness"]}],["$","span","Large Reasoning Models",{"className":"page__taxonomy-item","children":["#","Large Reasoning Models"]}],["$","span","Failed-Step Fraction",{"className":"page__taxonomy-item","children":["#","Failed-Step Fraction"]}],["$","span","Test-time Scaling",{"className":"page__taxonomy-item","children":["#","Test-time Scaling"]}],["$","span","Reasoning Graph",{"className":"page__taxonomy-item","children":["#","Reasoning Graph"]}],["$","span","Model Evaluation",{"className":"page__taxonomy-item","children":["#","Model Evaluation"]}]]}]]}]]}],["$","article","2025-9-24-VolSplat-Rethinking-Feed-Forward-3D-Gaussian-Splatting-with-Voxel-Aligned-Prediction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-24-VolSplat-Rethinking-Feed-Forward-3D-Gaussian-Splatting-with-Voxel-Aligned-Prediction/","children":"[논문리뷰] VolSplat: Rethinking Feed-Forward 3D Gaussian Splatting with Voxel-Aligned Prediction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Haoxiao Wang이 [arXiv]에 게시한 'VolSplat: Rethinking Feed-Forward 3D Gaussian Splatting with Voxel-Aligned Prediction' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-24 13:14:19+0900","children":"2025년 9월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","3D Gaussian Splatting"]}],["$","span","Novel View Synthesis",{"className":"page__taxonomy-item","children":["#","Novel View Synthesis"]}],["$","span","Voxel-Aligned Prediction",{"className":"page__taxonomy-item","children":["#","Voxel-Aligned Prediction"]}],["$","span","Feed-Forward Reconstruction",{"className":"page__taxonomy-item","children":["#","Feed-Forward Reconstruction"]}],["$","span","Multi-View Consistency",{"className":"page__taxonomy-item","children":["#","Multi-View Consistency"]}],["$","span","Scene Representation",{"className":"page__taxonomy-item","children":["#","Scene Representation"]}],["$","span","Computer Vision",{"className":"page__taxonomy-item","children":["#","Computer Vision"]}]]}]]}]]}],["$","article","2025-9-24-VIR-Bench-Evaluating-Geospatial-and-Temporal-Understanding-of-MLLMs-via-Travel-Video-Itinerary-Reconstruction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-24-VIR-Bench-Evaluating-Geospatial-and-Temporal-Understanding-of-MLLMs-via-Travel-Video-Itinerary-Reconstruction/","children":"[논문리뷰] VIR-Bench: Evaluating Geospatial and Temporal Understanding of MLLMs via Travel Video Itinerary Reconstruction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"So Fukuda이 [arXiv]에 게시한 'VIR-Bench: Evaluating Geospatial and Temporal Understanding of MLLMs via Travel Video Itinerary Reconstruction' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-24 13:14:19+0900","children":"2025년 9월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Video Understanding",{"className":"page__taxonomy-item","children":["#","Video Understanding"]}],["$","span","Geospatial Reasoning",{"className":"page__taxonomy-item","children":["#","Geospatial Reasoning"]}],["$","span","Temporal Reasoning",{"className":"page__taxonomy-item","children":["#","Temporal Reasoning"]}],["$","span","Travel Itinerary Reconstruction",{"className":"page__taxonomy-item","children":["#","Travel Itinerary Reconstruction"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Agent System",{"className":"page__taxonomy-item","children":["#","Agent System"]}],["$","span","VLOG",{"className":"page__taxonomy-item","children":["#","VLOG"]}]]}]]}]]}],["$","article","2025-9-24-Reinforcement-Learning-on-Pre-Training-Data",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-24-Reinforcement-Learning-on-Pre-Training-Data/","children":"[논문리뷰] Reinforcement Learning on Pre-Training Data"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Evander Yang이 [arXiv]에 게시한 'Reinforcement Learning on Pre-Training Data' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-24 13:14:19+0900","children":"2025년 9월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Pre-training",{"className":"page__taxonomy-item","children":["#","Pre-training"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Self-supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-supervised Learning"]}],["$","span","Scaling Laws",{"className":"page__taxonomy-item","children":["#","Scaling Laws"]}],["$","span","Next-segment Reasoning",{"className":"page__taxonomy-item","children":["#","Next-segment Reasoning"]}],["$","span","Reward Modeling",{"className":"page__taxonomy-item","children":["#","Reward Modeling"]}]]}]]}]]}],["$","article","2025-9-24-OpenGVL-Benchmarking-Visual-Temporal-Progress-for-Data-Curation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-24-OpenGVL-Benchmarking-Visual-Temporal-Progress-for-Data-Curation/","children":"[논문리뷰] OpenGVL - Benchmarking Visual Temporal Progress for Data Curation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Viktor Petrenko이 [arXiv]에 게시한 'OpenGVL - Benchmarking Visual Temporal Progress for Data Curation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-24 13:14:19+0900","children":"2025년 9월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Robotics Data Curation",{"className":"page__taxonomy-item","children":["#","Robotics Data Curation"]}],["$","span","Visual Temporal Progress",{"className":"page__taxonomy-item","children":["#","Visual Temporal Progress"]}],["$","span","Generative Value Learning (GVL)",{"className":"page__taxonomy-item","children":["#","Generative Value Learning (GVL)"]}],["$","span","Vision-Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision-Language Models (VLMs)"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Task Progress Prediction",{"className":"page__taxonomy-item","children":["#","Task Progress Prediction"]}],["$","span","Value-Order Correlation (VOC)",{"className":"page__taxonomy-item","children":["#","Value-Order Correlation (VOC)"]}]]}]]}]]}],["$","article","2025-9-24-MiniCPM-V-4-5-Cooking-Efficient-MLLMs-via-Architecture-Data-and-Training-Recipe",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-24-MiniCPM-V-4-5-Cooking-Efficient-MLLMs-via-Architecture-Data-and-Training-Recipe/","children":"[논문리뷰] MiniCPM-V 4.5: Cooking Efficient MLLMs via Architecture, Data, and Training Recipe"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wenshuo Ma이 [arXiv]에 게시한 'MiniCPM-V 4.5: Cooking Efficient MLLMs via Architecture, Data, and Training Recipe' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-24 13:14:19+0900","children":"2025년 9월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","MLLM Efficiency",{"className":"page__taxonomy-item","children":["#","MLLM Efficiency"]}],["$","span","Multimodal Transformer",{"className":"page__taxonomy-item","children":["#","Multimodal Transformer"]}],["$","span","3D-Resampler",{"className":"page__taxonomy-item","children":["#","3D-Resampler"]}],["$","span","Document AI",{"className":"page__taxonomy-item","children":["#","Document AI"]}],["$","span","Hybrid Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Hybrid Reinforcement Learning"]}],["$","span","Video Understanding",{"className":"page__taxonomy-item","children":["#","Video Understanding"]}],["$","span","Efficient Inference",{"className":"page__taxonomy-item","children":["#","Efficient Inference"]}]]}]]}]]}],["$","article","2025-9-24-MAPO-Mixed-Advantage-Policy-Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-24-MAPO-Mixed-Advantage-Policy-Optimization/","children":"[논문리뷰] MAPO: Mixed Advantage Policy Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xuankun Rong이 [arXiv]에 게시한 'MAPO: Mixed Advantage Policy Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-24 13:14:19+0900","children":"2025년 9월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Advantage Function",{"className":"page__taxonomy-item","children":["#","Advantage Function"]}],["$","span","Trajectory Certainty",{"className":"page__taxonomy-item","children":["#","Trajectory Certainty"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","span","GRPO",{"className":"page__taxonomy-item","children":["#","GRPO"]}]]}]]}]]}],["$","article","2025-9-24-Lyra-Generative-3D-Scene-Reconstruction-via-Video-Diffusion-Model-Self-Distillation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-24-Lyra-Generative-3D-Scene-Reconstruction-via-Video-Diffusion-Model-Self-Distillation/","children":"[논문리뷰] Lyra: Generative 3D Scene Reconstruction via Video Diffusion Model Self-Distillation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yifeng Jiang이 [arXiv]에 게시한 'Lyra: Generative 3D Scene Reconstruction via Video Diffusion Model Self-Distillation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-24 13:14:19+0900","children":"2025년 9월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","3D Scene Reconstruction",{"className":"page__taxonomy-item","children":["#","3D Scene Reconstruction"]}],["$","span","Video Diffusion Models",{"className":"page__taxonomy-item","children":["#","Video Diffusion Models"]}],["$","span","Self-Distillation",{"className":"page__taxonomy-item","children":["#","Self-Distillation"]}],["$","span","3D Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","3D Gaussian Splatting"]}],["$","span","Dynamic 4D Generation",{"className":"page__taxonomy-item","children":["#","Dynamic 4D Generation"]}],["$","span","Monocular Input",{"className":"page__taxonomy-item","children":["#","Monocular Input"]}]]}]]}]]}],["$","article","2025-9-24-Large-Language-Models-Discriminate-Against-Speakers-of-German-Dialects",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-24-Large-Language-Models-Discriminate-Against-Speakers-of-German-Dialects/","children":"[논문리뷰] Large Language Models Discriminate Against Speakers of German Dialects"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Katharina von der Wense이 [arXiv]에 게시한 'Large Language Models Discriminate Against Speakers of German Dialects' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-24 13:14:19+0900","children":"2025년 9월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Bias",{"className":"page__taxonomy-item","children":["#","Bias"]}],["$","span","German Dialects",{"className":"page__taxonomy-item","children":["#","German Dialects"]}],["$","span","Sociolinguistics",{"className":"page__taxonomy-item","children":["#","Sociolinguistics"]}],["$","span","Stereotypes",{"className":"page__taxonomy-item","children":["#","Stereotypes"]}],["$","span","Implicit Association Test",{"className":"page__taxonomy-item","children":["#","Implicit Association Test"]}],["$","span","Decision Making",{"className":"page__taxonomy-item","children":["#","Decision Making"]}]]}]]}]]}],["$","article","2025-9-24-Hyper-Bagel-A-Unified-Acceleration-Framework-for-Multimodal-Understanding-and-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-24-Hyper-Bagel-A-Unified-Acceleration-Framework-for-Multimodal-Understanding-and-Generation/","children":"[논문리뷰] Hyper-Bagel: A Unified Acceleration Framework for Multimodal Understanding and Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jianbin Zheng이 [arXiv]에 게시한 'Hyper-Bagel: A Unified Acceleration Framework for Multimodal Understanding and Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-24 13:14:19+0900","children":"2025년 9월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Acceleration Framework",{"className":"page__taxonomy-item","children":["#","Acceleration Framework"]}],["$","span","Speculative Decoding",{"className":"page__taxonomy-item","children":["#","Speculative Decoding"]}],["$","span","Diffusion Distillation",{"className":"page__taxonomy-item","children":["#","Diffusion Distillation"]}],["$","span","Unified Models",{"className":"page__taxonomy-item","children":["#","Unified Models"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}]]}]]}]]}],["$","article","2025-9-24-HyRF-Hybrid-Radiance-Fields-for-Memory-efficient-and-High-quality-Novel-View-Synthesis",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-24-HyRF-Hybrid-Radiance-Fields-for-Memory-efficient-and-High-quality-Novel-View-Synthesis/","children":"[논문리뷰] HyRF: Hybrid Radiance Fields for Memory-efficient and High-quality Novel View Synthesis"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Dan Xu이 [arXiv]에 게시한 'HyRF: Hybrid Radiance Fields for Memory-efficient and High-quality Novel View Synthesis' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-24 13:14:19+0900","children":"2025년 9월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Novel View Synthesis",{"className":"page__taxonomy-item","children":["#","Novel View Synthesis"]}],["$","span","3D Gaussian Splatting (3DGS)",{"className":"page__taxonomy-item","children":["#","3D Gaussian Splatting (3DGS)"]}],["$","span","Neural Radiance Fields (NeRF)",{"className":"page__taxonomy-item","children":["#","Neural Radiance Fields (NeRF)"]}],["$","span","Memory Efficiency",{"className":"page__taxonomy-item","children":["#","Memory Efficiency"]}],["$","span","High-Quality Rendering",{"className":"page__taxonomy-item","children":["#","High-Quality Rendering"]}],["$","span","Hybrid Representation",{"className":"page__taxonomy-item","children":["#","Hybrid Representation"]}],["$","span","Real-time Rendering",{"className":"page__taxonomy-item","children":["#","Real-time Rendering"]}]]}]]}]]}],["$","article","2025-9-24-GeoSVR-Taming-Sparse-Voxels-for-Geometrically-Accurate-Surface-Reconstruction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-24-GeoSVR-Taming-Sparse-Voxels-for-Geometrically-Accurate-Surface-Reconstruction/","children":"[논문리뷰] GeoSVR: Taming Sparse Voxels for Geometrically Accurate Surface Reconstruction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jin Zheng이 [arXiv]에 게시한 'GeoSVR: Taming Sparse Voxels for Geometrically Accurate Surface Reconstruction' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-24 13:14:19+0900","children":"2025년 9월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Surface Reconstruction",{"className":"page__taxonomy-item","children":["#","Surface Reconstruction"]}],["$","span","Sparse Voxels",{"className":"page__taxonomy-item","children":["#","Sparse Voxels"]}],["$","span","Geometric Accuracy",{"className":"page__taxonomy-item","children":["#","Geometric Accuracy"]}],["$","span","Neural Radiance Fields",{"className":"page__taxonomy-item","children":["#","Neural Radiance Fields"]}],["$","span","3D Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","3D Gaussian Splatting"]}],["$","span","Monocular Depth",{"className":"page__taxonomy-item","children":["#","Monocular Depth"]}],["$","span","Voxel Uncertainty",{"className":"page__taxonomy-item","children":["#","Voxel Uncertainty"]}]]}]]}]]}],["$","article","2025-9-24-Do-You-Need-Proprioceptive-States-in-Visuomotor-Policies",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-24-Do-You-Need-Proprioceptive-States-in-Visuomotor-Policies/","children":"[논문리뷰] Do You Need Proprioceptive States in Visuomotor Policies?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yushen Liang이 [arXiv]에 게시한 'Do You Need Proprioceptive States in Visuomotor Policies?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-24 13:14:19+0900","children":"2025년 9월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Visuomotor Policies",{"className":"page__taxonomy-item","children":["#","Visuomotor Policies"]}],["$","span","Spatial Generalization",{"className":"page__taxonomy-item","children":["#","Spatial Generalization"]}],["$","span","Imitation Learning",{"className":"page__taxonomy-item","children":["#","Imitation Learning"]}],["$","span","Proprioception",{"className":"page__taxonomy-item","children":["#","Proprioception"]}],["$","span","State-free Policies",{"className":"page__taxonomy-item","children":["#","State-free Policies"]}],["$","span","Robot Manipulation",{"className":"page__taxonomy-item","children":["#","Robot Manipulation"]}],["$","span","End-Effector Control",{"className":"page__taxonomy-item","children":["#","End-Effector Control"]}],["$","span","Data Efficiency",{"className":"page__taxonomy-item","children":["#","Data Efficiency"]}]]}]]}]]}],["$","article","2025-9-24-CAR-Flow-Condition-Aware-Reparameterization-Aligns-Source-and-Target-for-Better-Flow-Matching",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-24-CAR-Flow-Condition-Aware-Reparameterization-Aligns-Source-and-Target-for-Better-Flow-Matching/","children":"[논문리뷰] CAR-Flow: Condition-Aware Reparameterization Aligns Source and Target for Better Flow Matching"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Rui Qian이 [arXiv]에 게시한 'CAR-Flow: Condition-Aware Reparameterization Aligns Source and Target for Better Flow Matching' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-24 13:14:19+0900","children":"2025년 9월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Conditional Generative Models",{"className":"page__taxonomy-item","children":["#","Conditional Generative Models"]}],["$","span","Reparameterization",{"className":"page__taxonomy-item","children":["#","Reparameterization"]}],["$","span","Mode Collapse",{"className":"page__taxonomy-item","children":["#","Mode Collapse"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Latent Space Alignment",{"className":"page__taxonomy-item","children":["#","Latent Space Alignment"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}]]}]]}]]}],["$","article","2025-9-24-Baseer-A-Vision-Language-Model-for-Arabic-Document-to-Markdown-OCR",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-24-Baseer-A-Vision-Language-Model-for-Arabic-Document-to-Markdown-OCR/","children":"[논문리뷰] Baseer: A Vision-Language Model for Arabic Document-to-Markdown OCR"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zeina Aldallal이 [arXiv]에 게시한 'Baseer: A Vision-Language Model for Arabic Document-to-Markdown OCR' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-24 13:14:19+0900","children":"2025년 9월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Arabic OCR",{"className":"page__taxonomy-item","children":["#","Arabic OCR"]}],["$","span","Vision-Language Model",{"className":"page__taxonomy-item","children":["#","Vision-Language Model"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Document Understanding",{"className":"page__taxonomy-item","children":["#","Document Understanding"]}],["$","span","Markdown Conversion",{"className":"page__taxonomy-item","children":["#","Markdown Conversion"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}]]}]]}]]}],["$","article","2025-9-23-When-Big-Models-Train-Small-Ones-Label-Free-Model-Parity-Alignment-for-Efficient-Visual-Question-Answering-using-Small-VLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-When-Big-Models-Train-Small-Ones-Label-Free-Model-Parity-Alignment-for-Efficient-Visual-Question-Answering-using-Small-VLMs/","children":"[논문리뷰] When Big Models Train Small Ones: Label-Free Model Parity Alignment for Efficient Visual Question Answering using Small VLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Anand Mishra이 [arXiv]에 게시한 'When Big Models Train Small Ones: Label-Free Model Parity Alignment for Efficient Visual Question Answering using Small VLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","VQA",{"className":"page__taxonomy-item","children":["#","VQA"]}],["$","span","Small VLMs",{"className":"page__taxonomy-item","children":["#","Small VLMs"]}],["$","span","Large VLMs",{"className":"page__taxonomy-item","children":["#","Large VLMs"]}],["$","span","Knowledge Transfer",{"className":"page__taxonomy-item","children":["#","Knowledge Transfer"]}],["$","span","Pseudo-labeling",{"className":"page__taxonomy-item","children":["#","Pseudo-labeling"]}],["$","span","Label-Free Learning",{"className":"page__taxonomy-item","children":["#","Label-Free Learning"]}],["$","span","Model Parity Alignment",{"className":"page__taxonomy-item","children":["#","Model Parity Alignment"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}]]}]]}]]}],["$","article","2025-9-23-VideoFrom3D-3D-Scene-Video-Generation-via-Complementary-Image-and-Video-Diffusion-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-VideoFrom3D-3D-Scene-Video-Generation-via-Complementary-Image-and-Video-Diffusion-Models/","children":"[논문리뷰] VideoFrom3D: 3D Scene Video Generation via Complementary Image and Video Diffusion Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Sunghyun Cho이 [arXiv]에 게시한 'VideoFrom3D: 3D Scene Video Generation via Complementary Image and Video Diffusion Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Scene Generation",{"className":"page__taxonomy-item","children":["#","3D Scene Generation"]}],["$","span","Video Diffusion",{"className":"page__taxonomy-item","children":["#","Video Diffusion"]}],["$","span","Image Diffusion",{"className":"page__taxonomy-item","children":["#","Image Diffusion"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Computer Graphics",{"className":"page__taxonomy-item","children":["#","Computer Graphics"]}],["$","span","Temporal Consistency",{"className":"page__taxonomy-item","children":["#","Temporal Consistency"]}],["$","span","Sparse Anchor Views",{"className":"page__taxonomy-item","children":["#","Sparse Anchor Views"]}]]}]]}]]}],["$","article","2025-9-23-VaseVQA-Multimodal-Agent-and-Benchmark-for-Ancient-Greek-Pottery",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-VaseVQA-Multimodal-Agent-and-Benchmark-for-Ancient-Greek-Pottery/","children":"[논문리뷰] VaseVQA: Multimodal Agent and Benchmark for Ancient Greek Pottery"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shiya Huang이 [arXiv]에 게시한 'VaseVQA: Multimodal Agent and Benchmark for Ancient Greek Pottery' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models"]}],["$","span","Visual Question Answering",{"className":"page__taxonomy-item","children":["#","Visual Question Answering"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Cultural Heritage",{"className":"page__taxonomy-item","children":["#","Cultural Heritage"]}],["$","span","Ancient Greek Pottery",{"className":"page__taxonomy-item","children":["#","Ancient Greek Pottery"]}],["$","span","Supervised Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}]]}]]}]]}],["$","article","2025-9-23-Understanding-Embedding-Scaling-in-Collaborative-Filtering",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-Understanding-Embedding-Scaling-in-Collaborative-Filtering/","children":"[논문리뷰] Understanding Embedding Scaling in Collaborative Filtering"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yonghui Yang이 [arXiv]에 게시한 'Understanding Embedding Scaling in Collaborative Filtering' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Collaborative Filtering",{"className":"page__taxonomy-item","children":["#","Collaborative Filtering"]}],["$","span","Embedding Scaling",{"className":"page__taxonomy-item","children":["#","Embedding Scaling"]}],["$","span","Noise Robustness",{"className":"page__taxonomy-item","children":["#","Noise Robustness"]}],["$","span","Recommender Systems",{"className":"page__taxonomy-item","children":["#","Recommender Systems"]}],["$","span","Graph Neural Networks",{"className":"page__taxonomy-item","children":["#","Graph Neural Networks"]}],["$","span","Self-supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-supervised Learning"]}],["$","span","Performance Degradation",{"className":"page__taxonomy-item","children":["#","Performance Degradation"]}]]}]]}]]}],["$","article","2025-9-23-Turk-LettuceDetect-A-Hallucination-Detection-Models-for-Turkish-RAG-Applications",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-Turk-LettuceDetect-A-Hallucination-Detection-Models-for-Turkish-RAG-Applications/","children":"[논문리뷰] Turk-LettuceDetect: A Hallucination Detection Models for Turkish RAG Applications"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Fatma Betül Terzioğlu이 [arXiv]에 게시한 'Turk-LettuceDetect: A Hallucination Detection Models for Turkish RAG Applications' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Hallucination Detection",{"className":"page__taxonomy-item","children":["#","Hallucination Detection"]}],["$","span","Retrieval Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval Augmented Generation"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Turkish NLP",{"className":"page__taxonomy-item","children":["#","Turkish NLP"]}],["$","span","Token Classification",{"className":"page__taxonomy-item","children":["#","Token Classification"]}],["$","span","ModernBERT",{"className":"page__taxonomy-item","children":["#","ModernBERT"]}],["$","span","Low-Resource Languages",{"className":"page__taxonomy-item","children":["#","Low-Resource Languages"]}]]}]]}]]}],["$","article","2025-9-23-TempSamp-R1-Effective-Temporal-Sampling-with-Reinforcement-Fine-Tuning-for-Video-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-TempSamp-R1-Effective-Temporal-Sampling-with-Reinforcement-Fine-Tuning-for-Video-LLMs/","children":"[논문리뷰] TempSamp-R1: Effective Temporal Sampling with Reinforcement Fine-Tuning for Video LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shaohui Jiao이 [arXiv]에 게시한 'TempSamp-R1: Effective Temporal Sampling with Reinforcement Fine-Tuning for Video LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video LLMs",{"className":"page__taxonomy-item","children":["#","Video LLMs"]}],["$","span","Temporal Grounding",{"className":"page__taxonomy-item","children":["#","Temporal Grounding"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Off-policy Learning",{"className":"page__taxonomy-item","children":["#","Off-policy Learning"]}],["$","span","Reward Shaping",{"className":"page__taxonomy-item","children":["#","Reward Shaping"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}]]}]]}]]}],["$","article","2025-9-23-Synthetic-bootstrapped-pretraining",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-Synthetic-bootstrapped-pretraining/","children":"[논문리뷰] Synthetic bootstrapped pretraining"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Emmanuel Candès이 [arXiv]에 게시한 'Synthetic bootstrapped pretraining' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Language Model Pretraining",{"className":"page__taxonomy-item","children":["#","Language Model Pretraining"]}],["$","span","Synthetic Data",{"className":"page__taxonomy-item","children":["#","Synthetic Data"]}],["$","span","Inter-document Correlation",{"className":"page__taxonomy-item","children":["#","Inter-document Correlation"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Bootstrapping",{"className":"page__taxonomy-item","children":["#","Bootstrapping"]}],["$","span","Concept Learning",{"className":"page__taxonomy-item","children":["#","Concept Learning"]}]]}]]}]]}],["$","article","2025-9-23-SWE-Bench-Pro-Can-AI-Agents-Solve-Long-Horizon-Software-Engineering-Tasks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-SWE-Bench-Pro-Can-AI-Agents-Solve-Long-Horizon-Software-Engineering-Tasks/","children":"[논문리뷰] SWE-Bench Pro: Can AI Agents Solve Long-Horizon Software Engineering Tasks?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yannis Yiming He이 [arXiv]에 게시한 'SWE-Bench Pro: Can AI Agents Solve Long-Horizon Software Engineering Tasks?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Agents",{"className":"page__taxonomy-item","children":["#","AI Agents"]}],["$","span","Software Engineering",{"className":"page__taxonomy-item","children":["#","Software Engineering"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Contamination Resistance",{"className":"page__taxonomy-item","children":["#","Contamination Resistance"]}],["$","span","Long-Horizon Tasks",{"className":"page__taxonomy-item","children":["#","Long-Horizon Tasks"]}],["$","span","Enterprise Software",{"className":"page__taxonomy-item","children":["#","Enterprise Software"]}]]}]]}]]}],["$","article","2025-9-23-SCAN-Self-Denoising-Monte-Carlo-Annotation-for-Robust-Process-Reward-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-SCAN-Self-Denoising-Monte-Carlo-Annotation-for-Robust-Process-Reward-Learning/","children":"[논문리뷰] SCAN: Self-Denoising Monte Carlo Annotation for Robust Process Reward Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhaopeng Tu이 [arXiv]에 게시한 'SCAN: Self-Denoising Monte Carlo Annotation for Robust Process Reward Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Process Reward Models",{"className":"page__taxonomy-item","children":["#","Process Reward Models"]}],["$","span","Monte Carlo Annotation",{"className":"page__taxonomy-item","children":["#","Monte Carlo Annotation"]}],["$","span","Noise Denoising",{"className":"page__taxonomy-item","children":["#","Noise Denoising"]}],["$","span","Robust Learning",{"className":"page__taxonomy-item","children":["#","Robust Learning"]}],["$","span","Self-Supervision",{"className":"page__taxonomy-item","children":["#","Self-Supervision"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}]]}]]}]]}],["$","article","2025-9-23-Reasoning-Core-A-Scalable-RL-Environment-for-LLM-Symbolic-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-Reasoning-Core-A-Scalable-RL-Environment-for-LLM-Symbolic-Reasoning/","children":"[논문리뷰] Reasoning Core: A Scalable RL Environment for LLM Symbolic Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Damien Sileo이 [arXiv]에 게시한 'Reasoning Core: A Scalable RL Environment for LLM Symbolic Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Reasoning",{"className":"page__taxonomy-item","children":["#","LLM Reasoning"]}],["$","span","Symbolic AI",{"className":"page__taxonomy-item","children":["#","Symbolic AI"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Procedural Content Generation",{"className":"page__taxonomy-item","children":["#","Procedural Content Generation"]}],["$","span","Verifiable Rewards",{"className":"page__taxonomy-item","children":["#","Verifiable Rewards"]}],["$","span","Adaptive Curricula",{"className":"page__taxonomy-item","children":["#","Adaptive Curricula"]}],["$","span","First-Order Logic",{"className":"page__taxonomy-item","children":["#","First-Order Logic"]}],["$","span","PDDL Planning",{"className":"page__taxonomy-item","children":["#","PDDL Planning"]}]]}]]}]]}],["$","article","2025-9-23-Qwen3-Omni-Technical-Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-Qwen3-Omni-Technical-Report/","children":"[논문리뷰] Qwen3-Omni Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Lhma-aslp이 [arXiv]에 게시한 'Qwen3-Omni Technical Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Model",{"className":"page__taxonomy-item","children":["#","Multimodal Model"]}],["$","span","Thinker-Talker Architecture",{"className":"page__taxonomy-item","children":["#","Thinker-Talker Architecture"]}],["$","span","Mixture-of-Experts",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts"]}],["$","span","Low-latency",{"className":"page__taxonomy-item","children":["#","Low-latency"]}],["$","span","Audio Understanding",{"className":"page__taxonomy-item","children":["#","Audio Understanding"]}],["$","span","Cross-modal Reasoning",{"className":"page__taxonomy-item","children":["#","Cross-modal Reasoning"]}],["$","span","State-of-the-Art",{"className":"page__taxonomy-item","children":["#","State-of-the-Art"]}],["$","span","Real-time Interaction",{"className":"page__taxonomy-item","children":["#","Real-time Interaction"]}]]}]]}]]}],["$","article","2025-9-23-QWHA-Quantization-Aware-Walsh-Hadamard-Adaptation-for-Parameter-Efficient-Fine-Tuning-on-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-QWHA-Quantization-Aware-Walsh-Hadamard-Adaptation-for-Parameter-Efficient-Fine-Tuning-on-Large-Language-Models/","children":"[논문리뷰] QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jae-Joon Kim이 [arXiv]에 게시한 'QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Fine-tuning",{"className":"page__taxonomy-item","children":["#","LLM Fine-tuning"]}],["$","span","Quantization-Aware PEFT",{"className":"page__taxonomy-item","children":["#","Quantization-Aware PEFT"]}],["$","span","Walsh-Hadamard Transform",{"className":"page__taxonomy-item","children":["#","Walsh-Hadamard Transform"]}],["$","span","Sparse Adaptation",{"className":"page__taxonomy-item","children":["#","Sparse Adaptation"]}],["$","span","Low-bit Quantization",{"className":"page__taxonomy-item","children":["#","Low-bit Quantization"]}],["$","span","Parameter-Efficient Learning",{"className":"page__taxonomy-item","children":["#","Parameter-Efficient Learning"]}]]}]]}]]}],["$","article","2025-9-23-OmniInsert-Mask-Free-Video-Insertion-of-Any-Reference-via-Diffusion-Transformer-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-OmniInsert-Mask-Free-Video-Insertion-of-Any-Reference-via-Diffusion-Transformer-Models/","children":"[논문리뷰] OmniInsert: Mask-Free Video Insertion of Any Reference via Diffusion Transformer Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Pengze Zhang이 [arXiv]에 게시한 'OmniInsert: Mask-Free Video Insertion of Any Reference via Diffusion Transformer Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Insertion",{"className":"page__taxonomy-item","children":["#","Video Insertion"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Diffusion Transformers",{"className":"page__taxonomy-item","children":["#","Diffusion Transformers"]}],["$","span","Mask-Free",{"className":"page__taxonomy-item","children":["#","Mask-Free"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}],["$","span","Progressive Training",{"className":"page__taxonomy-item","children":["#","Progressive Training"]}],["$","span","Preference Optimization",{"className":"page__taxonomy-item","children":["#","Preference Optimization"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}]]}]]}]]}],["$","article","2025-9-23-MetaEmbed-Scaling-Multimodal-Retrieval-at-Test-Time-with-Flexible-Late-Interaction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-MetaEmbed-Scaling-Multimodal-Retrieval-at-Test-Time-with-Flexible-Late-Interaction/","children":"[논문리뷰] MetaEmbed: Scaling Multimodal Retrieval at Test-Time with Flexible Late Interaction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xintao Chen이 [arXiv]에 게시한 'MetaEmbed: Scaling Multimodal Retrieval at Test-Time with Flexible Late Interaction' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Retrieval",{"className":"page__taxonomy-item","children":["#","Multimodal Retrieval"]}],["$","span","Late Interaction",{"className":"page__taxonomy-item","children":["#","Late Interaction"]}],["$","span","Meta Tokens",{"className":"page__taxonomy-item","children":["#","Meta Tokens"]}],["$","span","Matryoshka Representation Learning",{"className":"page__taxonomy-item","children":["#","Matryoshka Representation Learning"]}],["$","span","Test-Time Scaling",{"className":"page__taxonomy-item","children":["#","Test-Time Scaling"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Dense Retrieval",{"className":"page__taxonomy-item","children":["#","Dense Retrieval"]}],["$","span","Efficiency",{"className":"page__taxonomy-item","children":["#","Efficiency"]}]]}]]}]]}],["$","article","2025-9-23-Mano-Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-Mano-Report/","children":"[논문리뷰] Mano Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Minghui Wu이 [arXiv]에 게시한 'Mano Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","GUI Agent",{"className":"page__taxonomy-item","children":["#","GUI Agent"]}],["$","span","Multi-modal Foundation Model",{"className":"page__taxonomy-item","children":["#","Multi-modal Foundation Model"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Simulated Environment",{"className":"page__taxonomy-item","children":["#","Simulated Environment"]}],["$","span","Data Generation",{"className":"page__taxonomy-item","children":["#","Data Generation"]}],["$","span","Error Recovery",{"className":"page__taxonomy-item","children":["#","Error Recovery"]}],["$","span","Web Automation",{"className":"page__taxonomy-item","children":["#","Web Automation"]}]]}]]}]]}],["$","article","2025-9-23-LIMI-Less-is-More-for-Agency",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-LIMI-Less-is-More-for-Agency/","children":"[논문리뷰] LIMI: Less is More for Agency"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"happyZYM이 [arXiv]에 게시한 'LIMI: Less is More for Agency' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Agency",{"className":"page__taxonomy-item","children":["#","AI Agency"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Less Is More",{"className":"page__taxonomy-item","children":["#","Less Is More"]}],["$","span","Agentic Intelligence",{"className":"page__taxonomy-item","children":["#","Agentic Intelligence"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Evaluation Benchmark",{"className":"page__taxonomy-item","children":["#","Evaluation Benchmark"]}],["$","span","Efficiency Principle",{"className":"page__taxonomy-item","children":["#","Efficiency Principle"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}]]}]]}]]}],["$","article","2025-9-23-GeoPQA-Bridging-the-Visual-Perception-Gap-in-MLLMs-for-Geometric-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-GeoPQA-Bridging-the-Visual-Perception-Gap-in-MLLMs-for-Geometric-Reasoning/","children":"[논문리뷰] GeoPQA: Bridging the Visual Perception Gap in MLLMs for Geometric Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hou Pong Chan이 [arXiv]에 게시한 'GeoPQA: Bridging the Visual Perception Gap in MLLMs for Geometric Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models (MLLMs)"]}],["$","span","Geometric Reasoning",{"className":"page__taxonomy-item","children":["#","Geometric Reasoning"]}],["$","span","Visual Perception",{"className":"page__taxonomy-item","children":["#","Visual Perception"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Two-stage Training",{"className":"page__taxonomy-item","children":["#","Two-stage Training"]}],["$","span","GeoPQA Benchmark",{"className":"page__taxonomy-item","children":["#","GeoPQA Benchmark"]}],["$","span","Perceptual Bottleneck",{"className":"page__taxonomy-item","children":["#","Perceptual Bottleneck"]}]]}]]}]]}],["$","article","2025-9-23-From-Uniform-to-Heterogeneous-Tailoring-Policy-Optimization-to-Every-Tokens-Nature",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-From-Uniform-to-Heterogeneous-Tailoring-Policy-Optimization-to-Every-Tokens-Nature/","children":"[논문리뷰] From Uniform to Heterogeneous: Tailoring Policy Optimization to Every Token's Nature"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Bin Cui이 [arXiv]에 게시한 'From Uniform to Heterogeneous: Tailoring Policy Optimization to Every Token's Nature' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Token Heterogeneity",{"className":"page__taxonomy-item","children":["#","Token Heterogeneity"]}],["$","span","Adaptive Sampling",{"className":"page__taxonomy-item","children":["#","Adaptive Sampling"]}],["$","span","Advantage Redistribution",{"className":"page__taxonomy-item","children":["#","Advantage Redistribution"]}],["$","span","Asymmetric Clipping",{"className":"page__taxonomy-item","children":["#","Asymmetric Clipping"]}],["$","span","Entropy-based RL",{"className":"page__taxonomy-item","children":["#","Entropy-based RL"]}]]}]]}]]}],["$","article","2025-9-23-From-Hugging-Face-to-GitHub-Tracing-License-Drift-in-the-Open-Source-AI-Ecosystem",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-From-Hugging-Face-to-GitHub-Tracing-License-Drift-in-the-Open-Source-AI-Ecosystem/","children":"[논문리뷰] From Hugging Face to GitHub: Tracing License Drift in the Open-Source AI Ecosystem"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ahmed E. Hassan이 [arXiv]에 게시한 'From Hugging Face to GitHub: Tracing License Drift in the Open-Source AI Ecosystem' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Open-Source AI",{"className":"page__taxonomy-item","children":["#","Open-Source AI"]}],["$","span","License Compliance",{"className":"page__taxonomy-item","children":["#","License Compliance"]}],["$","span","License Drift",{"className":"page__taxonomy-item","children":["#","License Drift"]}],["$","span","AI Supply Chain",{"className":"page__taxonomy-item","children":["#","AI Supply Chain"]}],["$","span","Hugging Face",{"className":"page__taxonomy-item","children":["#","Hugging Face"]}],["$","span","GitHub",{"className":"page__taxonomy-item","children":["#","GitHub"]}],["$","span","LicenseRec",{"className":"page__taxonomy-item","children":["#","LicenseRec"]}],["$","span","Legal Risk",{"className":"page__taxonomy-item","children":["#","Legal Risk"]}]]}]]}]]}],["$","article","2025-9-23-FlagEval-Findings-Report-A-Preliminary-Evaluation-of-Large-Reasoning-Models-on-Automatically-Verifiable-Textual-and-Visual-Questions",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-FlagEval-Findings-Report-A-Preliminary-Evaluation-of-Large-Reasoning-Models-on-Automatically-Verifiable-Textual-and-Visual-Questions/","children":"[논문리뷰] FlagEval Findings Report: A Preliminary Evaluation of Large Reasoning Models on Automatically Verifiable Textual and Visual Questions"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"tengdai722이 [arXiv]에 게시한 'FlagEval Findings Report: A Preliminary Evaluation of Large Reasoning Models on Automatically Verifiable Textual and Visual Questions' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Reasoning Models",{"className":"page__taxonomy-item","children":["#","Large Reasoning Models"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Reasoning Behaviors",{"className":"page__taxonomy-item","children":["#","Reasoning Behaviors"]}],["$","span","Hallucination",{"className":"page__taxonomy-item","children":["#","Hallucination"]}],["$","span","Contamination-Free",{"className":"page__taxonomy-item","children":["#","Contamination-Free"]}],["$","span","AI Safety",{"className":"page__taxonomy-item","children":["#","AI Safety"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}]]}]]}]]}],["$","article","2025-9-23-EpiCache-Episodic-KV-Cache-Management-for-Long-Conversational-Question-Answering",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-EpiCache-Episodic-KV-Cache-Management-for-Long-Conversational-Question-Answering/","children":"[논문리뷰] EpiCache: Episodic KV Cache Management for Long Conversational Question Answering"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Minsik Cho이 [arXiv]에 게시한 'EpiCache: Episodic KV Cache Management for Long Conversational Question Answering' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","KV Cache Management",{"className":"page__taxonomy-item","children":["#","KV Cache Management"]}],["$","span","Long Conversational QA",{"className":"page__taxonomy-item","children":["#","Long Conversational QA"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Memory Efficiency",{"className":"page__taxonomy-item","children":["#","Memory Efficiency"]}],["$","span","Episodic Clustering",{"className":"page__taxonomy-item","children":["#","Episodic Clustering"]}],["$","span","Block Prefill Eviction",{"className":"page__taxonomy-item","children":["#","Block Prefill Eviction"]}],["$","span","Sensitivity-aware Allocation",{"className":"page__taxonomy-item","children":["#","Sensitivity-aware Allocation"]}]]}]]}]]}],["$","article","2025-9-23-DiffusionNFT-Online-Diffusion-Reinforcement-with-Forward-Process",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-DiffusionNFT-Online-Diffusion-Reinforcement-with-Forward-Process/","children":"[논문리뷰] DiffusionNFT: Online Diffusion Reinforcement with Forward Process"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Qinsheng Zhang이 [arXiv]에 게시한 'DiffusionNFT: Online Diffusion Reinforcement with Forward Process' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Online RL",{"className":"page__taxonomy-item","children":["#","Online RL"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Forward Process",{"className":"page__taxonomy-item","children":["#","Forward Process"]}],["$","span","CFG-free",{"className":"page__taxonomy-item","children":["#","CFG-free"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Negative-Aware FineTuning",{"className":"page__taxonomy-item","children":["#","Negative-Aware FineTuning"]}]]}]]}]]}],["$","article","2025-9-23-DIWALI-Diversity-and-Inclusivity-aWare-cuLture-specific-Items-for-India-Dataset-and-Assessment-of-LLMs-for-Cultural-Text-Adaptation-in-Indian-Context",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-DIWALI-Diversity-and-Inclusivity-aWare-cuLture-specific-Items-for-India-Dataset-and-Assessment-of-LLMs-for-Cultural-Text-Adaptation-in-Indian-Context/","children":"[논문리뷰] DIWALI - Diversity and Inclusivity aWare cuLture specific Items for India: Dataset and Assessment of LLMs for Cultural Text Adaptation in Indian Context"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Maunendra Sankar Desarkar이 [arXiv]에 게시한 'DIWALI - Diversity and Inclusivity aWare cuLture specific Items for India: Dataset and Assessment of LLMs for Cultural Text Adaptation in Indian Context' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Cultural Adaptation",{"className":"page__taxonomy-item","children":["#","Cultural Adaptation"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Indian Culture",{"className":"page__taxonomy-item","children":["#","Indian Culture"]}],["$","span","Dataset Creation",{"className":"page__taxonomy-item","children":["#","Dataset Creation"]}],["$","span","CSI",{"className":"page__taxonomy-item","children":["#","CSI"]}],["$","span","Human Evaluation",{"className":"page__taxonomy-item","children":["#","Human Evaluation"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Cultural Bias",{"className":"page__taxonomy-item","children":["#","Cultural Bias"]}]]}]]}]]}],["$","article","2025-9-23-Cross-Attention-is-Half-Explanation-in-Speech-to-Text-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-Cross-Attention-is-Half-Explanation-in-Speech-to-Text-Models/","children":"[논문리뷰] Cross-Attention is Half Explanation in Speech-to-Text Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Luisa Bentivogli이 [arXiv]에 게시한 'Cross-Attention is Half Explanation in Speech-to-Text Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Cross-attention",{"className":"page__taxonomy-item","children":["#","Cross-attention"]}],["$","span","Speech-to-Text (S2T)",{"className":"page__taxonomy-item","children":["#","Speech-to-Text (S2T)"]}],["$","span","Explainable AI (XAI)",{"className":"page__taxonomy-item","children":["#","Explainable AI (XAI)"]}],["$","span","Saliency Maps",{"className":"page__taxonomy-item","children":["#","Saliency Maps"]}],["$","span","Feature Attribution",{"className":"page__taxonomy-item","children":["#","Feature Attribution"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Context Mixing",{"className":"page__taxonomy-item","children":["#","Context Mixing"]}],["$","span","Correlation",{"className":"page__taxonomy-item","children":["#","Correlation"]}]]}]]}]]}],["$","article","2025-9-23-ContextFlow-Training-Free-Video-Object-Editing-via-Adaptive-Context-Enrichment",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-ContextFlow-Training-Free-Video-Object-Editing-via-Adaptive-Context-Enrichment/","children":"[논문리뷰] ContextFlow: Training-Free Video Object Editing via Adaptive Context Enrichment"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yue Ma이 [arXiv]에 게시한 'ContextFlow: Training-Free Video Object Editing via Adaptive Context Enrichment' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Object Editing",{"className":"page__taxonomy-item","children":["#","Video Object Editing"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}],["$","span","Diffusion Transformers",{"className":"page__taxonomy-item","children":["#","Diffusion Transformers"]}],["$","span","Rectified Flow",{"className":"page__taxonomy-item","children":["#","Rectified Flow"]}],["$","span","Adaptive Context Enrichment",{"className":"page__taxonomy-item","children":["#","Adaptive Context Enrichment"]}],["$","span","Guidance Responsiveness",{"className":"page__taxonomy-item","children":["#","Guidance Responsiveness"]}],["$","span","Temporal Consistency",{"className":"page__taxonomy-item","children":["#","Temporal Consistency"]}],["$","span","Image-to-Video",{"className":"page__taxonomy-item","children":["#","Image-to-Video"]}]]}]]}]]}],["$","article","2025-9-23-CodeFuse-CR-Bench-A-Comprehensiveness-aware-Benchmark-for-End-to-End-Code-Review-Evaluation-in-Python-Projects",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-CodeFuse-CR-Bench-A-Comprehensiveness-aware-Benchmark-for-End-to-End-Code-Review-Evaluation-in-Python-Projects/","children":"[논문리뷰] CodeFuse-CR-Bench: A Comprehensiveness-aware Benchmark for End-to-End Code Review Evaluation in Python Projects"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hang Yu이 [arXiv]에 게시한 'CodeFuse-CR-Bench: A Comprehensiveness-aware Benchmark for End-to-End Code Review Evaluation in Python Projects' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Code Review",{"className":"page__taxonomy-item","children":["#","Code Review"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Python Projects",{"className":"page__taxonomy-item","children":["#","Python Projects"]}],["$","span","End-to-End Evaluation",{"className":"page__taxonomy-item","children":["#","End-to-End Evaluation"]}],["$","span","Context-Awareness",{"className":"page__taxonomy-item","children":["#","Context-Awareness"]}],["$","span","Software Engineering",{"className":"page__taxonomy-item","children":["#","Software Engineering"]}],["$","span","LLM-as-a-Judge",{"className":"page__taxonomy-item","children":["#","LLM-as-a-Judge"]}]]}]]}]]}],["$","article","2025-9-23-ByteWrist-A-Parallel-Robotic-Wrist-Enabling-Flexible-and-Anthropomorphic-Motion-for-Confined-Spaces",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-ByteWrist-A-Parallel-Robotic-Wrist-Enabling-Flexible-and-Anthropomorphic-Motion-for-Confined-Spaces/","children":"[논문리뷰] ByteWrist: A Parallel Robotic Wrist Enabling Flexible and Anthropomorphic Motion for Confined Spaces"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiafeng Xu이 [arXiv]에 게시한 'ByteWrist: A Parallel Robotic Wrist Enabling Flexible and Anthropomorphic Motion for Confined Spaces' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Parallel Manipulator",{"className":"page__taxonomy-item","children":["#","Parallel Manipulator"]}],["$","span","Robotic Wrist",{"className":"page__taxonomy-item","children":["#","Robotic Wrist"]}],["$","span","Confined Space Manipulation",{"className":"page__taxonomy-item","children":["#","Confined Space Manipulation"]}],["$","span","Kinematics",{"className":"page__taxonomy-item","children":["#","Kinematics"]}],["$","span","Anthropomorphic Robot",{"className":"page__taxonomy-item","children":["#","Anthropomorphic Robot"]}],["$","span","Robot Design",{"className":"page__taxonomy-item","children":["#","Robot Design"]}]]}]]}]]}],["$","article","2025-9-23-AuditoryBench-Can-Language-Models-Understand-Auditory-Knowledge-without-Hearing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-AuditoryBench-Can-Language-Models-Understand-Auditory-Knowledge-without-Hearing/","children":"[논문리뷰] AuditoryBench++: Can Language Models Understand Auditory Knowledge without Hearing?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jaeho Lee이 [arXiv]에 게시한 'AuditoryBench++: Can Language Models Understand Auditory Knowledge without Hearing?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Auditory Knowledge",{"className":"page__taxonomy-item","children":["#","Auditory Knowledge"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Auditory Imagination",{"className":"page__taxonomy-item","children":["#","Auditory Imagination"]}],["$","span","Text-only Reasoning",{"className":"page__taxonomy-item","children":["#","Text-only Reasoning"]}]]}]]}]]}],["$","article","2025-9-23-Analyzing-the-Effects-of-Supervised-Fine-Tuning-on-Model-Knowledge-from-Token-and-Parameter-Levels",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-Analyzing-the-Effects-of-Supervised-Fine-Tuning-on-Model-Knowledge-from-Token-and-Parameter-Levels/","children":"[논문리뷰] Analyzing the Effects of Supervised Fine-Tuning on Model Knowledge from Token and Parameter Levels"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Qi Zhang이 [arXiv]에 게시한 'Analyzing the Effects of Supervised Fine-Tuning on Model Knowledge from Token and Parameter Levels' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Supervised Fine-Tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning (SFT)"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Model Knowledge",{"className":"page__taxonomy-item","children":["#","Model Knowledge"]}],["$","span","Closed-Book Question Answering (CBQA)",{"className":"page__taxonomy-item","children":["#","Closed-Book Question Answering (CBQA)"]}],["$","span","Parameter Restoration",{"className":"page__taxonomy-item","children":["#","Parameter Restoration"]}],["$","span","Kullback-Leibler Divergence",{"className":"page__taxonomy-item","children":["#","Kullback-Leibler Divergence"]}],["$","span","Knowledge Forgetting",{"className":"page__taxonomy-item","children":["#","Knowledge Forgetting"]}]]}]]}]]}],["$","article","2025-9-23-ARE-Scaling-Up-Agent-Environments-and-Evaluations",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-ARE-Scaling-Up-Agent-Environments-and-Evaluations/","children":"[논문리뷰] ARE: Scaling Up Agent Environments and Evaluations"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Matteo Bettini이 [arXiv]에 게시한 'ARE: Scaling Up Agent Environments and Evaluations' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agent Environments",{"className":"page__taxonomy-item","children":["#","Agent Environments"]}],["$","span","Agent Evaluation",{"className":"page__taxonomy-item","children":["#","Agent Evaluation"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Asynchronous Systems",{"className":"page__taxonomy-item","children":["#","Asynchronous Systems"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Multi-agent Collaboration",{"className":"page__taxonomy-item","children":["#","Multi-agent Collaboration"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}]]}]]}]]}],["$","article","2025-9-22-WhisTLE-Deeply-Supervised-Text-Only-Domain-Adaptation-for-Pretrained-Speech-Recognition-Transformers",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-22-WhisTLE-Deeply-Supervised-Text-Only-Domain-Adaptation-for-Pretrained-Speech-Recognition-Transformers/","children":"[논문리뷰] WhisTLE: Deeply Supervised, Text-Only Domain Adaptation for Pretrained Speech Recognition Transformers"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Karun Kumar이 [arXiv]에 게시한 'WhisTLE: Deeply Supervised, Text-Only Domain Adaptation for Pretrained Speech Recognition Transformers' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-22 13:11:29+0900","children":"2025년 9월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","ASR",{"className":"page__taxonomy-item","children":["#","ASR"]}],["$","span","Domain Adaptation",{"className":"page__taxonomy-item","children":["#","Domain Adaptation"]}],["$","span","Text-Only Training",{"className":"page__taxonomy-item","children":["#","Text-Only Training"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Variational Autoencoder",{"className":"page__taxonomy-item","children":["#","Variational Autoencoder"]}],["$","span","Deep Supervision",{"className":"page__taxonomy-item","children":["#","Deep Supervision"]}],["$","span","Whisper",{"className":"page__taxonomy-item","children":["#","Whisper"]}],["$","span","Encoder-Decoder Models",{"className":"page__taxonomy-item","children":["#","Encoder-Decoder Models"]}]]}]]}]]}],["$","article","2025-9-22-Video2Roleplay-A-Multimodal-Dataset-and-Framework-for-Video-Guided-Role-playing-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-22-Video2Roleplay-A-Multimodal-Dataset-and-Framework-for-Video-Guided-Role-playing-Agents/","children":"[논문리뷰] Video2Roleplay: A Multimodal Dataset and Framework for Video-Guided Role-playing Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chao Zhang이 [arXiv]에 게시한 'Video2Roleplay: A Multimodal Dataset and Framework for Video-Guided Role-playing Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-22 13:11:29+0900","children":"2025년 9월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Role-playing Agents (RPAs)",{"className":"page__taxonomy-item","children":["#","Role-playing Agents (RPAs)"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Video Understanding",{"className":"page__taxonomy-item","children":["#","Video Understanding"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Dataset Creation",{"className":"page__taxonomy-item","children":["#","Dataset Creation"]}],["$","span","Dynamic Role Profiles",{"className":"page__taxonomy-item","children":["#","Dynamic Role Profiles"]}],["$","span","Adaptive Temporal Sampling",{"className":"page__taxonomy-item","children":["#","Adaptive Temporal Sampling"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}]]}]]}]]}],["$","article","2025-9-22-SPATIALGEN-Layout-guided-3D-Indoor-Scene-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-22-SPATIALGEN-Layout-guided-3D-Indoor-Scene-Generation/","children":"[논문리뷰] SPATIALGEN: Layout-guided 3D Indoor Scene Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yongsen Mao이 [arXiv]에 게시한 'SPATIALGEN: Layout-guided 3D Indoor Scene Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-22 13:11:29+0900","children":"2025년 9월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Scene Generation",{"className":"page__taxonomy-item","children":["#","3D Scene Generation"]}],["$","span","Layout Guidance",{"className":"page__taxonomy-item","children":["#","Layout Guidance"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Multi-view Synthesis",{"className":"page__taxonomy-item","children":["#","Multi-view Synthesis"]}],["$","span","Synthetic Dataset",{"className":"page__taxonomy-item","children":["#","Synthetic Dataset"]}],["$","span","Indoor Environments",{"className":"page__taxonomy-item","children":["#","Indoor Environments"]}],["$","span","Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","Gaussian Splatting"]}],["$","span","Semantic Consistency",{"className":"page__taxonomy-item","children":["#","Semantic Consistency"]}]]}]]}]]}],["$","article","2025-9-22-RPG-A-Repository-Planning-Graph-for-Unified-and-Scalable-Codebase-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-22-RPG-A-Repository-Planning-Graph-for-Unified-and-Scalable-Codebase-Generation/","children":"[논문리뷰] RPG: A Repository Planning Graph for Unified and Scalable Codebase Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Steven Liu이 [arXiv]에 게시한 'RPG: A Repository Planning Graph for Unified and Scalable Codebase Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-22 13:11:29+0900","children":"2025년 9월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Repository Planning",{"className":"page__taxonomy-item","children":["#","Repository Planning"]}],["$","span","Graph-based Representation",{"className":"page__taxonomy-item","children":["#","Graph-based Representation"]}],["$","span","Software Engineering",{"className":"page__taxonomy-item","children":["#","Software Engineering"]}],["$","span","Agent Frameworks",{"className":"page__taxonomy-item","children":["#","Agent Frameworks"]}],["$","span","Scalable Codebase",{"className":"page__taxonomy-item","children":["#","Scalable Codebase"]}]]}]]}]]}],["$","article","2025-9-22-RGB-Only-Supervised-Camera-Parameter-Optimization-in-Dynamic-Scenes",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-22-RGB-Only-Supervised-Camera-Parameter-Optimization-in-Dynamic-Scenes/","children":"[논문리뷰] RGB-Only Supervised Camera Parameter Optimization in Dynamic Scenes"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Narendra Ahuja이 [arXiv]에 게시한 'RGB-Only Supervised Camera Parameter Optimization in Dynamic Scenes' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-22 13:11:29+0900","children":"2025년 9월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Camera Parameter Optimization",{"className":"page__taxonomy-item","children":["#","Camera Parameter Optimization"]}],["$","span","Dynamic Scenes",{"className":"page__taxonomy-item","children":["#","Dynamic Scenes"]}],["$","span","RGB-Only Supervision",{"className":"page__taxonomy-item","children":["#","RGB-Only Supervision"]}],["$","span","Structure from Motion",{"className":"page__taxonomy-item","children":["#","Structure from Motion"]}],["$","span","Outlier Robustness",{"className":"page__taxonomy-item","children":["#","Outlier Robustness"]}],["$","span","3D Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","3D Gaussian Splatting"]}],["$","span","Two-stage Optimization",{"className":"page__taxonomy-item","children":["#","Two-stage Optimization"]}],["$","span","Point Tracking",{"className":"page__taxonomy-item","children":["#","Point Tracking"]}]]}]]}]]}],["$","article","2025-9-22-MANZANO-A-Simple-and-Scalable-Unified-Multimodal-Model-with-a-Hybrid-Vision-Tokenizer",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-22-MANZANO-A-Simple-and-Scalable-Unified-Multimodal-Model-with-a-Hybrid-Vision-Tokenizer/","children":"[논문리뷰] MANZANO: A Simple and Scalable Unified Multimodal Model with a Hybrid Vision Tokenizer"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"jialingt이 [arXiv]에 게시한 'MANZANO: A Simple and Scalable Unified Multimodal Model with a Hybrid Vision Tokenizer' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-22 13:11:29+0900","children":"2025년 9월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLM",{"className":"page__taxonomy-item","children":["#","Multimodal LLM"]}],["$","span","Hybrid Tokenizer",{"className":"page__taxonomy-item","children":["#","Hybrid Tokenizer"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Visual Question Answering",{"className":"page__taxonomy-item","children":["#","Visual Question Answering"]}],["$","span","Autoregressive Model",{"className":"page__taxonomy-item","children":["#","Autoregressive Model"]}],["$","span","Diffusion Decoder",{"className":"page__taxonomy-item","children":["#","Diffusion Decoder"]}],["$","span","Unified Architecture",{"className":"page__taxonomy-item","children":["#","Unified Architecture"]}],["$","span","Model Scaling",{"className":"page__taxonomy-item","children":["#","Model Scaling"]}]]}]]}]]}],["$","article","2025-9-22-Lynx-Towards-High-Fidelity-Personalized-Video-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-22-Lynx-Towards-High-Fidelity-Personalized-Video-Generation/","children":"[논문리뷰] Lynx: Towards High-Fidelity Personalized Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Linjie Luo이 [arXiv]에 게시한 'Lynx: Towards High-Fidelity Personalized Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-22 13:11:29+0900","children":"2025년 9월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Personalized Video Generation",{"className":"page__taxonomy-item","children":["#","Personalized Video Generation"]}],["$","span","Diffusion Transformer",{"className":"page__taxonomy-item","children":["#","Diffusion Transformer"]}],["$","span","Identity Preservation",{"className":"page__taxonomy-item","children":["#","Identity Preservation"]}],["$","span","Video Synthesis",{"className":"page__taxonomy-item","children":["#","Video Synthesis"]}],["$","span","Adapter Networks",{"className":"page__taxonomy-item","children":["#","Adapter Networks"]}],["$","span","Facial Recognition",{"className":"page__taxonomy-item","children":["#","Facial Recognition"]}],["$","span","Cross-Attention",{"className":"page__taxonomy-item","children":["#","Cross-Attention"]}]]}]]}]]}],["$","article","2025-9-22-Latent-Zoning-Network-A-Unified-Principle-for-Generative-Modeling-Representation-Learning-and-Classification",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-22-Latent-Zoning-Network-A-Unified-Principle-for-Generative-Modeling-Representation-Learning-and-Classification/","children":"[논문리뷰] Latent Zoning Network: A Unified Principle for Generative Modeling, Representation Learning, and Classification"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wenyu Wang이 [arXiv]에 게시한 'Latent Zoning Network: A Unified Principle for Generative Modeling, Representation Learning, and Classification' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-22 13:11:29+0900","children":"2025년 9월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Generative Modeling",{"className":"page__taxonomy-item","children":["#","Generative Modeling"]}],["$","span","Representation Learning",{"className":"page__taxonomy-item","children":["#","Representation Learning"]}],["$","span","Classification",{"className":"page__taxonomy-item","children":["#","Classification"]}],["$","span","Unified Framework",{"className":"page__taxonomy-item","children":["#","Unified Framework"]}],["$","span","Latent Space",{"className":"page__taxonomy-item","children":["#","Latent Space"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}]]}]]}]]}],["$","article","2025-9-22-Do-You-Hear-What-I-Mean-Quantifying-the-Instruction-Perception-Gap-in-Instruction-Guided-Expressive-Text-To-Speech-Systems",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-22-Do-You-Hear-What-I-Mean-Quantifying-the-Instruction-Perception-Gap-in-Instruction-Guided-Expressive-Text-To-Speech-Systems/","children":"[논문리뷰] Do You Hear What I Mean? Quantifying the Instruction-Perception Gap in Instruction-Guided Expressive Text-To-Speech Systems"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hung-yi Lee이 [arXiv]에 게시한 'Do You Hear What I Mean? Quantifying the Instruction-Perception Gap in Instruction-Guided Expressive Text-To-Speech Systems' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-22 13:11:29+0900","children":"2025년 9월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Instruction-Guided TTS",{"className":"page__taxonomy-item","children":["#","Instruction-Guided TTS"]}],["$","span","Expressive Speech Synthesis",{"className":"page__taxonomy-item","children":["#","Expressive Speech Synthesis"]}],["$","span","Human Perception",{"className":"page__taxonomy-item","children":["#","Human Perception"]}],["$","span","Subjective Evaluation",{"className":"page__taxonomy-item","children":["#","Subjective Evaluation"]}],["$","span","Controllability",{"className":"page__taxonomy-item","children":["#","Controllability"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}],["$","span","Evaluation Metrics",{"className":"page__taxonomy-item","children":["#","Evaluation Metrics"]}]]}]]}]]}],["$","article","2025-9-22-BaseReward-A-Strong-Baseline-for-Multimodal-Reward-Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-22-BaseReward-A-Strong-Baseline-for-Multimodal-Reward-Model/","children":"[논문리뷰] BaseReward: A Strong Baseline for Multimodal Reward Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"jianfeipan이 [arXiv]에 게시한 'BaseReward: A Strong Baseline for Multimodal Reward Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-22 13:11:29+0900","children":"2025년 9월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Reward Model",{"className":"page__taxonomy-item","children":["#","Multimodal Reward Model"]}],["$","span","MLLM Alignment",{"className":"page__taxonomy-item","children":["#","MLLM Alignment"]}],["$","span","RLHF",{"className":"page__taxonomy-item","children":["#","RLHF"]}],["$","span","Reward Head Architecture",{"className":"page__taxonomy-item","children":["#","Reward Head Architecture"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Ensemble Methods",{"className":"page__taxonomy-item","children":["#","Ensemble Methods"]}],["$","span","BaseReward",{"className":"page__taxonomy-item","children":["#","BaseReward"]}]]}]]}]]}],["$","article","2025-9-22-BTL-UI-Blink-Think-Link-Reasoning-Model-for-GUI-Agent",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-22-BTL-UI-Blink-Think-Link-Reasoning-Model-for-GUI-Agent/","children":"[논문리뷰] BTL-UI: Blink-Think-Link Reasoning Model for GUI Agent"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiahui Yang이 [arXiv]에 게시한 'BTL-UI: Blink-Think-Link Reasoning Model for GUI Agent' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-22 13:11:29+0900","children":"2025년 9월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","GUI Agent",{"className":"page__taxonomy-item","children":["#","GUI Agent"]}],["$","span","Human-GUI Interaction",{"className":"page__taxonomy-item","children":["#","Human-GUI Interaction"]}],["$","span","Cognitive Modeling",{"className":"page__taxonomy-item","children":["#","Cognitive Modeling"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Multimodal Large Language Models",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models"]}],["$","span","Attention Mechanisms",{"className":"page__taxonomy-item","children":["#","Attention Mechanisms"]}],["$","span","Action Planning",{"className":"page__taxonomy-item","children":["#","Action Planning"]}]]}]]}]]}],["$","article","2025-9-22-Ask-to-Clarify-Resolving-Instruction-Ambiguity-through-Multi-turn-Dialogue",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-22-Ask-to-Clarify-Resolving-Instruction-Ambiguity-through-Multi-turn-Dialogue/","children":"[논문리뷰] Ask-to-Clarify: Resolving Instruction Ambiguity through Multi-turn Dialogue"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hui Zhang이 [arXiv]에 게시한 'Ask-to-Clarify: Resolving Instruction Ambiguity through Multi-turn Dialogue' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-22 13:11:29+0900","children":"2025년 9월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Human-Robot Interaction",{"className":"page__taxonomy-item","children":["#","Human-Robot Interaction"]}],["$","span","Multi-turn Dialogue",{"className":"page__taxonomy-item","children":["#","Multi-turn Dialogue"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Ambiguity Resolution",{"className":"page__taxonomy-item","children":["#","Ambiguity Resolution"]}],["$","span","Low-level Actions",{"className":"page__taxonomy-item","children":["#","Low-level Actions"]}]]}]]}]]}],["$","article","2025-9-22-A-Vision-Language-Action-Critic-Model-for-Robotic-Real-World-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-22-A-Vision-Language-Action-Critic-Model-for-Robotic-Real-World-Reinforcement-Learning/","children":"[논문리뷰] A Vision-Language-Action-Critic Model for Robotic Real-World Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiangmiao이 [arXiv]에 게시한 'A Vision-Language-Action-Critic Model for Robotic Real-World Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-22 13:11:29+0900","children":"2025년 9월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Vision-Language-Action (VLA) Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action (VLA) Models"]}],["$","span","Reward Modeling",{"className":"page__taxonomy-item","children":["#","Reward Modeling"]}],["$","span","Human-in-the-Loop",{"className":"page__taxonomy-item","children":["#","Human-in-the-Loop"]}],["$","span","Dense Rewards",{"className":"page__taxonomy-item","children":["#","Dense Rewards"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Autoregressive Models",{"className":"page__taxonomy-item","children":["#","Autoregressive Models"]}]]}]]}]]}],["$","article","2025-9-19-WorldForge-Unlocking-Emergent-3D4D-Generation-in-Video-Diffusion-Model-via-Training-Free-Guidance",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-19-WorldForge-Unlocking-Emergent-3D4D-Generation-in-Video-Diffusion-Model-via-Training-Free-Guidance/","children":"[논문리뷰] WorldForge: Unlocking Emergent 3D/4D Generation in Video Diffusion Model via Training-Free Guidance"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ruibo Li이 [arXiv]에 게시한 'WorldForge: Unlocking Emergent 3D/4D Generation in Video Diffusion Model via Training-Free Guidance' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-19 13:12:21+0900","children":"2025년 9월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Diffusion Models",{"className":"page__taxonomy-item","children":["#","Video Diffusion Models"]}],["$","span","3D/4D Generation",{"className":"page__taxonomy-item","children":["#","3D/4D Generation"]}],["$","span","Training-Free Guidance",{"className":"page__taxonomy-item","children":["#","Training-Free Guidance"]}],["$","span","Camera Trajectory Control",{"className":"page__taxonomy-item","children":["#","Camera Trajectory Control"]}],["$","span","Novel View Synthesis",{"className":"page__taxonomy-item","children":["#","Novel View Synthesis"]}],["$","span","Geometric Consistency",{"className":"page__taxonomy-item","children":["#","Geometric Consistency"]}],["$","span","Inference-Time Optimization",{"className":"page__taxonomy-item","children":["#","Inference-Time Optimization"]}]]}]]}]]}],["$","article","2025-9-19-Unleashing-the-Potential-of-Multimodal-LLMs-for-Zero-Shot-Spatio-Temporal-Video-Grounding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-19-Unleashing-the-Potential-of-Multimodal-LLMs-for-Zero-Shot-Spatio-Temporal-Video-Grounding/","children":"[논문리뷰] Unleashing the Potential of Multimodal LLMs for Zero-Shot Spatio-Temporal Video Grounding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Rynson W. H. Lau이 [arXiv]에 게시한 'Unleashing the Potential of Multimodal LLMs for Zero-Shot Spatio-Temporal Video Grounding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-19 13:12:21+0900","children":"2025년 9월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Spatio-Temporal Video Grounding",{"className":"page__taxonomy-item","children":["#","Spatio-Temporal Video Grounding"]}],["$","span","Multimodal Large Language Models",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models"]}],["$","span","Zero-Shot Learning",{"className":"page__taxonomy-item","children":["#","Zero-Shot Learning"]}],["$","span","Visual Grounding",{"className":"page__taxonomy-item","children":["#","Visual Grounding"]}],["$","span","Decomposed Spatio-Temporal Highlighting",{"className":"page__taxonomy-item","children":["#","Decomposed Spatio-Temporal Highlighting"]}],["$","span","Logit-Guided Re-attention",{"className":"page__taxonomy-item","children":["#","Logit-Guided Re-attention"]}],["$","span","Temporal-Augmented Assembling",{"className":"page__taxonomy-item","children":["#","Temporal-Augmented Assembling"]}]]}]]}]]}],["$","article","2025-9-19-Understand-Before-You-Generate-Self-Guided-Training-for-Autoregressive-Image-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-19-Understand-Before-You-Generate-Self-Guided-Training-for-Autoregressive-Image-Generation/","children":"[논문리뷰] Understand Before You Generate: Self-Guided Training for Autoregressive Image Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xihui Liu이 [arXiv]에 게시한 'Understand Before You Generate: Self-Guided Training for Autoregressive Image Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-19 13:12:21+0900","children":"2025년 9월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Autoregressive Models",{"className":"page__taxonomy-item","children":["#","Autoregressive Models"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Self-Supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-Supervised Learning"]}],["$","span","Visual Understanding",{"className":"page__taxonomy-item","children":["#","Visual Understanding"]}],["$","span","Masked Image Modeling",{"className":"page__taxonomy-item","children":["#","Masked Image Modeling"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Next-Token Prediction",{"className":"page__taxonomy-item","children":["#","Next-Token Prediction"]}],["$","span","LlamaGen",{"className":"page__taxonomy-item","children":["#","LlamaGen"]}]]}]]}]]}],["$","article","2025-9-19-ScaleCUA-Scaling-Open-Source-Computer-Use-Agents-with-Cross-Platform-Data",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-19-ScaleCUA-Scaling-Open-Source-Computer-Use-Agents-with-Cross-Platform-Data/","children":"[논문리뷰] ScaleCUA: Scaling Open-Source Computer Use Agents with Cross-Platform Data"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zehao Li이 [arXiv]에 게시한 'ScaleCUA: Scaling Open-Source Computer Use Agents with Cross-Platform Data' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-19 13:12:21+0900","children":"2025년 9월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Computer Use Agents",{"className":"page__taxonomy-item","children":["#","Computer Use Agents"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Cross-Platform Data",{"className":"page__taxonomy-item","children":["#","Cross-Platform Data"]}],["$","span","GUI Automation",{"className":"page__taxonomy-item","children":["#","GUI Automation"]}],["$","span","Data Scaling",{"className":"page__taxonomy-item","children":["#","Data Scaling"]}],["$","span","Open-Source",{"className":"page__taxonomy-item","children":["#","Open-Source"]}],["$","span","Task Completion",{"className":"page__taxonomy-item","children":["#","Task Completion"]}],["$","span","GUI Grounding",{"className":"page__taxonomy-item","children":["#","GUI Grounding"]}]]}]]}]]}],["$","article","2025-9-19-RynnVLA-001-Using-Human-Demonstrations-to-Improve-Robot-Manipulation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-19-RynnVLA-001-Using-Human-Demonstrations-to-Improve-Robot-Manipulation/","children":"[논문리뷰] RynnVLA-001: Using Human Demonstrations to Improve Robot Manipulation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"SpaceProduct이 [arXiv]에 게시한 'RynnVLA-001: Using Human Demonstrations to Improve Robot Manipulation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-19 13:12:21+0900","children":"2025년 9월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action (VLA) Model",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action (VLA) Model"]}],["$","span","Robot Manipulation",{"className":"page__taxonomy-item","children":["#","Robot Manipulation"]}],["$","span","Human Demonstrations",{"className":"page__taxonomy-item","children":["#","Human Demonstrations"]}],["$","span","Video Generative Pretraining",{"className":"page__taxonomy-item","children":["#","Video Generative Pretraining"]}],["$","span","Ego-Centric Video",{"className":"page__taxonomy-item","children":["#","Ego-Centric Video"]}],["$","span","Trajectory Prediction",{"className":"page__taxonomy-item","children":["#","Trajectory Prediction"]}],["$","span","ActionVAE",{"className":"page__taxonomy-item","children":["#","ActionVAE"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}]]}]]}]]}],["$","article","2025-9-19-RecoWorld-Building-Simulated-Environments-for-Agentic-Recommender-Systems",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-19-RecoWorld-Building-Simulated-Environments-for-Agentic-Recommender-Systems/","children":"[논문리뷰] RecoWorld: Building Simulated Environments for Agentic Recommender Systems"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Mingyuan Wu이 [arXiv]에 게시한 'RecoWorld: Building Simulated Environments for Agentic Recommender Systems' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-19 13:12:21+0900","children":"2025년 9월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic Recommender Systems",{"className":"page__taxonomy-item","children":["#","Agentic Recommender Systems"]}],["$","span","Simulated Environments",{"className":"page__taxonomy-item","children":["#","Simulated Environments"]}],["$","span","LLM-driven Simulation",{"className":"page__taxonomy-item","children":["#","LLM-driven Simulation"]}],["$","span","Multi-turn Interaction",{"className":"page__taxonomy-item","children":["#","Multi-turn Interaction"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","User Retention",{"className":"page__taxonomy-item","children":["#","User Retention"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}],["$","span","Multi-agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-agent Systems"]}]]}]]}]]}],["$","article","2025-9-19-Reasoning-over-Boundaries-Enhancing-Specification-Alignment-via-Test-time-Delibration",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-19-Reasoning-over-Boundaries-Enhancing-Specification-Alignment-via-Test-time-Delibration/","children":"[논문리뷰] Reasoning over Boundaries: Enhancing Specification Alignment via Test-time Delibration"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhilin Wang이 [arXiv]에 게시한 'Reasoning over Boundaries: Enhancing Specification Alignment via Test-time Delibration' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-19 13:12:21+0900","children":"2025년 9월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Specification Alignment",{"className":"page__taxonomy-item","children":["#","Specification Alignment"]}],["$","span","Test-Time Deliberation",{"className":"page__taxonomy-item","children":["#","Test-Time Deliberation"]}],["$","span","Safety-Behavior Trade-off",{"className":"page__taxonomy-item","children":["#","Safety-Behavior Trade-off"]}],["$","span","ALIGN3",{"className":"page__taxonomy-item","children":["#","ALIGN3"]}],["$","span","SPECBENCH",{"className":"page__taxonomy-item","children":["#","SPECBENCH"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}]]}]]}]]}],["$","article","2025-9-19-MultiEdit-Advancing-Instruction-based-Image-Editing-on-Diverse-and-Challenging-Tasks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-19-MultiEdit-Advancing-Instruction-based-Image-Editing-on-Diverse-and-Challenging-Tasks/","children":"[논문리뷰] MultiEdit: Advancing Instruction-based Image Editing on Diverse and Challenging Tasks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xijun Gu이 [arXiv]에 게시한 'MultiEdit: Advancing Instruction-based Image Editing on Diverse and Challenging Tasks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-19 13:12:21+0900","children":"2025년 9월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Instruction-based Image Editing",{"className":"page__taxonomy-item","children":["#","Instruction-based Image Editing"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}],["$","span","Multi-modal LLM",{"className":"page__taxonomy-item","children":["#","Multi-modal LLM"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Style Transfer",{"className":"page__taxonomy-item","children":["#","Style Transfer"]}],["$","span","Multi-task Learning",{"className":"page__taxonomy-item","children":["#","Multi-task Learning"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}]]}]]}]]}],["$","article","2025-9-19-Mind-the-Gap-A-Closer-Look-at-Tokenization-for-Multiple-Choice-Question-Answering-with-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-19-Mind-the-Gap-A-Closer-Look-at-Tokenization-for-Multiple-Choice-Question-Answering-with-LLMs/","children":"[논문리뷰] Mind the Gap: A Closer Look at Tokenization for Multiple-Choice Question Answering with LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Katharina von der Wense이 [arXiv]에 게시한 'Mind the Gap: A Closer Look at Tokenization for Multiple-Choice Question Answering with LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-19 13:12:21+0900","children":"2025년 9월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Multiple-Choice QA",{"className":"page__taxonomy-item","children":["#","Multiple-Choice QA"]}],["$","span","Tokenization",{"className":"page__taxonomy-item","children":["#","Tokenization"]}],["$","span","Prompt Sensitivity",{"className":"page__taxonomy-item","children":["#","Prompt Sensitivity"]}],["$","span","Accuracy",{"className":"page__taxonomy-item","children":["#","Accuracy"]}],["$","span","Calibration",{"className":"page__taxonomy-item","children":["#","Calibration"]}],["$","span","Model Ranking",{"className":"page__taxonomy-item","children":["#","Model Ranking"]}]]}]]}]]}],["$","article","2025-9-19-FlowRL-Matching-Reward-Distributions-for-LLM-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-19-FlowRL-Matching-Reward-Distributions-for-LLM-Reasoning/","children":"[논문리뷰] FlowRL: Matching Reward Distributions for LLM Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hengli Li이 [arXiv]에 게시한 'FlowRL: Matching Reward Distributions for LLM Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-19 13:12:21+0900","children":"2025년 9월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reward Distribution Matching",{"className":"page__taxonomy-item","children":["#","Reward Distribution Matching"]}],["$","span","GFlowNets",{"className":"page__taxonomy-item","children":["#","GFlowNets"]}],["$","span","Mode Collapse",{"className":"page__taxonomy-item","children":["#","Mode Collapse"]}],["$","span","Diverse Reasoning",{"className":"page__taxonomy-item","children":["#","Diverse Reasoning"]}],["$","span","Flow-Balanced Optimization",{"className":"page__taxonomy-item","children":["#","Flow-Balanced Optimization"]}]]}]]}]]}],["$","article","2025-9-19-FinSearchComp-Towards-a-Realistic-Expert-Level-Evaluation-of-Financial-Search-and-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-19-FinSearchComp-Towards-a-Realistic-Expert-Level-Evaluation-of-Financial-Search-and-Reasoning/","children":"[논문리뷰] FinSearchComp: Towards a Realistic, Expert-Level Evaluation of Financial Search and Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiashuo Liu이 [arXiv]에 게시한 'FinSearchComp: Towards a Realistic, Expert-Level Evaluation of Financial Search and Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-19 13:12:21+0900","children":"2025년 9월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Financial LLMs",{"className":"page__taxonomy-item","children":["#","Financial LLMs"]}],["$","span","Agent Benchmarking",{"className":"page__taxonomy-item","children":["#","Agent Benchmarking"]}],["$","span","Open-domain Search",{"className":"page__taxonomy-item","children":["#","Open-domain Search"]}],["$","span","Financial Reasoning",{"className":"page__taxonomy-item","children":["#","Financial Reasoning"]}],["$","span","Time-Sensitive Data",{"className":"page__taxonomy-item","children":["#","Time-Sensitive Data"]}],["$","span","Multi-hop QA",{"className":"page__taxonomy-item","children":["#","Multi-hop QA"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}]]}]]}]]}],["$","article","2025-9-19-FSG-Net-Frequency-Spatial-Synergistic-Gated-Network-for-High-Resolution-Remote-Sensing-Change-Detection",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-19-FSG-Net-Frequency-Spatial-Synergistic-Gated-Network-for-High-Resolution-Remote-Sensing-Change-Detection/","children":"[논문리뷰] FSG-Net: Frequency-Spatial Synergistic Gated Network for High-Resolution Remote Sensing Change Detection"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhewei Zhang이 [arXiv]에 게시한 'FSG-Net: Frequency-Spatial Synergistic Gated Network for High-Resolution Remote Sensing Change Detection' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-19 13:12:21+0900","children":"2025년 9월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Change Detection",{"className":"page__taxonomy-item","children":["#","Change Detection"]}],["$","span","Remote Sensing",{"className":"page__taxonomy-item","children":["#","Remote Sensing"]}],["$","span","Frequency-Spatial Analysis",{"className":"page__taxonomy-item","children":["#","Frequency-Spatial Analysis"]}],["$","span","Wavelet Transform",{"className":"page__taxonomy-item","children":["#","Wavelet Transform"]}],["$","span","Attention Mechanism",{"className":"page__taxonomy-item","children":["#","Attention Mechanism"]}],["$","span","Gated Fusion",{"className":"page__taxonomy-item","children":["#","Gated Fusion"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}]]}]]}]]}],["$","article","2025-9-19-Evolving-Language-Models-without-Labels-Majority-Drives-Selection-Novelty-Promotes-Variation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-19-Evolving-Language-Models-without-Labels-Majority-Drives-Selection-Novelty-Promotes-Variation/","children":"[논문리뷰] Evolving Language Models without Labels: Majority Drives Selection, Novelty Promotes Variation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kishan Panaganti이 [arXiv]에 게시한 'Evolving Language Models without Labels: Majority Drives Selection, Novelty Promotes Variation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-19 13:12:21+0900","children":"2025년 9월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Label-free Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Label-free Reinforcement Learning"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Self-improvement",{"className":"page__taxonomy-item","children":["#","Self-improvement"]}],["$","span","Entropy Collapse",{"className":"page__taxonomy-item","children":["#","Entropy Collapse"]}],["$","span","Novelty Reward",{"className":"page__taxonomy-item","children":["#","Novelty Reward"]}],["$","span","Test-Time RL",{"className":"page__taxonomy-item","children":["#","Test-Time RL"]}],["$","span","GRPO",{"className":"page__taxonomy-item","children":["#","GRPO"]}],["$","span","Evolutionary Computing Principles",{"className":"page__taxonomy-item","children":["#","Evolutionary Computing Principles"]}]]}]]}]]}],["$","article","2025-9-19-EchoVLM-Dynamic-Mixture-of-Experts-Vision-Language-Model-for-Universal-Ultrasound-Intelligence",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-19-EchoVLM-Dynamic-Mixture-of-Experts-Vision-Language-Model-for-Universal-Ultrasound-Intelligence/","children":"[논문리뷰] EchoVLM: Dynamic Mixture-of-Experts Vision-Language Model for Universal Ultrasound Intelligence"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Qinghua Huang이 [arXiv]에 게시한 'EchoVLM: Dynamic Mixture-of-Experts Vision-Language Model for Universal Ultrasound Intelligence' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-19 13:12:21+0900","children":"2025년 9월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Ultrasound Imaging",{"className":"page__taxonomy-item","children":["#","Ultrasound Imaging"]}],["$","span","Medical Diagnosis",{"className":"page__taxonomy-item","children":["#","Medical Diagnosis"]}],["$","span","Mixture-of-Experts (MoE)",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts (MoE)"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Report Generation",{"className":"page__taxonomy-item","children":["#","Report Generation"]}],["$","span","VQA",{"className":"page__taxonomy-item","children":["#","VQA"]}]]}]]}]]}],["$","article","2025-9-19-AToken-A-Unified-Tokenizer-for-Vision",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-19-AToken-A-Unified-Tokenizer-for-Vision/","children":"[논문리뷰] AToken: A Unified Tokenizer for Vision"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Mingze Xu이 [arXiv]에 게시한 'AToken: A Unified Tokenizer for Vision' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-19 13:12:21+0900","children":"2025년 9월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Unified Visual Tokenizer",{"className":"page__taxonomy-item","children":["#","Unified Visual Tokenizer"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","4D Representation",{"className":"page__taxonomy-item","children":["#","4D Representation"]}],["$","span","Adversarial-free Training",{"className":"page__taxonomy-item","children":["#","Adversarial-free Training"]}],["$","span","Reconstruction",{"className":"page__taxonomy-item","children":["#","Reconstruction"]}],["$","span","Semantic Understanding",{"className":"page__taxonomy-item","children":["#","Semantic Understanding"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}]]}]]}]]}],["$","article","2025-9-18-Wan-Animate-Unified-Character-Animation-and-Replacement-with-Holistic-Replication",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-18-Wan-Animate-Unified-Character-Animation-and-Replacement-with-Holistic-Replication/","children":"[논문리뷰] Wan-Animate: Unified Character Animation and Replacement with Holistic Replication"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Mingyang Huang이 [arXiv]에 게시한 'Wan-Animate: Unified Character Animation and Replacement with Holistic Replication' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-18 13:07:00+0900","children":"2025년 9월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Character Animation",{"className":"page__taxonomy-item","children":["#","Character Animation"]}],["$","span","Video Replacement",{"className":"page__taxonomy-item","children":["#","Video Replacement"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","DiT",{"className":"page__taxonomy-item","children":["#","DiT"]}],["$","span","Relighting LoRA",{"className":"page__taxonomy-item","children":["#","Relighting LoRA"]}],["$","span","Holistic Replication",{"className":"page__taxonomy-item","children":["#","Holistic Replication"]}],["$","span","Open-Source",{"className":"page__taxonomy-item","children":["#","Open-Source"]}]]}]]}]]}],["$","article","2025-9-18-THOR-Tool-Integrated-Hierarchical-Optimization-via-RL-for-Mathematical-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-18-THOR-Tool-Integrated-Hierarchical-Optimization-via-RL-for-Mathematical-Reasoning/","children":"[논문리뷰] THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yicheng Pan이 [arXiv]에 게시한 'THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-18 13:07:00+0900","children":"2025년 9월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Tool-Integrated Reasoning",{"className":"page__taxonomy-item","children":["#","Tool-Integrated Reasoning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Hierarchical Optimization",{"className":"page__taxonomy-item","children":["#","Hierarchical Optimization"]}],["$","span","Self-Correction",{"className":"page__taxonomy-item","children":["#","Self-Correction"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}]]}]]}]]}],["$","article","2025-9-18-SteeringControl-Holistic-Evaluation-of-Alignment-Steering-in-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-18-SteeringControl-Holistic-Evaluation-of-Alignment-Steering-in-LLMs/","children":"[논문리뷰] SteeringControl: Holistic Evaluation of Alignment Steering in LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhun Wang이 [arXiv]에 게시한 'SteeringControl: Holistic Evaluation of Alignment Steering in LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-18 13:07:00+0900","children":"2025년 9월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Alignment",{"className":"page__taxonomy-item","children":["#","LLM Alignment"]}],["$","span","Representation Steering",{"className":"page__taxonomy-item","children":["#","Representation Steering"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Behavioral Entanglement",{"className":"page__taxonomy-item","children":["#","Behavioral Entanglement"]}],["$","span","Bias Mitigation",{"className":"page__taxonomy-item","children":["#","Bias Mitigation"]}],["$","span","Harmful Generation",{"className":"page__taxonomy-item","children":["#","Harmful Generation"]}],["$","span","Hallucination Control",{"className":"page__taxonomy-item","children":["#","Hallucination Control"]}],["$","span","Modular Framework",{"className":"page__taxonomy-item","children":["#","Modular Framework"]}]]}]]}]]}],["$","article","2025-9-18-Scrub-It-Out-Erasing-Sensitive-Memorization-in-Code-Language-Models-via-Machine-Unlearning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-18-Scrub-It-Out-Erasing-Sensitive-Memorization-in-Code-Language-Models-via-Machine-Unlearning/","children":"[논문리뷰] Scrub It Out! Erasing Sensitive Memorization in Code Language Models via Machine Unlearning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhou Yang이 [arXiv]에 게시한 'Scrub It Out! Erasing Sensitive Memorization in Code Language Models via Machine Unlearning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-18 13:07:00+0900","children":"2025년 9월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Code Language Models",{"className":"page__taxonomy-item","children":["#","Code Language Models"]}],["$","span","Machine Unlearning",{"className":"page__taxonomy-item","children":["#","Machine Unlearning"]}],["$","span","Sensitive Memorization",{"className":"page__taxonomy-item","children":["#","Sensitive Memorization"]}],["$","span","Privacy",{"className":"page__taxonomy-item","children":["#","Privacy"]}],["$","span","Gradient Ascent",{"className":"page__taxonomy-item","children":["#","Gradient Ascent"]}],["$","span","Model Utility",{"className":"page__taxonomy-item","children":["#","Model Utility"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}]]}]]}]]}],["$","article","2025-9-18-SAIL-VL2-Technical-Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-18-SAIL-VL2-Technical-Report/","children":"[논문리뷰] SAIL-VL2 Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zijian Kang이 [arXiv]에 게시한 'SAIL-VL2 Technical Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-18 13:07:00+0900","children":"2025년 9월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Model",{"className":"page__taxonomy-item","children":["#","Vision-Language Model"]}],["$","span","Multimodal Understanding",{"className":"page__taxonomy-item","children":["#","Multimodal Understanding"]}],["$","span","Mixture-of-Experts",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts"]}],["$","span","Progressive Training",{"className":"page__taxonomy-item","children":["#","Progressive Training"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","SAIL-ViT",{"className":"page__taxonomy-item","children":["#","SAIL-ViT"]}]]}]]}]]}],["$","article","2025-9-18-PANORAMA-The-Rise-of-Omnidirectional-Vision-in-the-Embodied-AI-Era",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-18-PANORAMA-The-Rise-of-Omnidirectional-Vision-in-the-Embodied-AI-Era/","children":"[논문리뷰] PANORAMA: The Rise of Omnidirectional Vision in the Embodied AI Era"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zihao Dongfang이 [arXiv]에 게시한 'PANORAMA: The Rise of Omnidirectional Vision in the Embodied AI Era' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-18 13:07:00+0900","children":"2025년 9월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Omnidirectional Vision",{"className":"page__taxonomy-item","children":["#","Omnidirectional Vision"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Panoramic Perception",{"className":"page__taxonomy-item","children":["#","Panoramic Perception"]}],["$","span","Multi-modal Learning",{"className":"page__taxonomy-item","children":["#","Multi-modal Learning"]}],["$","span","Dataset Development",{"className":"page__taxonomy-item","children":["#","Dataset Development"]}],["$","span","Robot Navigation",{"className":"page__taxonomy-item","children":["#","Robot Navigation"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}],["$","span","System Architecture",{"className":"page__taxonomy-item","children":["#","System Architecture"]}]]}]]}]]}],["$","article","2025-9-18-MARS2-2025-Challenge-on-Multimodal-Reasoning-Datasets-Methods-Results-Discussion-and-Outlook",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-18-MARS2-2025-Challenge-on-Multimodal-Reasoning-Datasets-Methods-Results-Discussion-and-Outlook/","children":"[논문리뷰] MARS2 2025 Challenge on Multimodal Reasoning: Datasets, Methods, Results, Discussion, and Outlook"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Bowen Zhou이 [arXiv]에 게시한 'MARS2 2025 Challenge on Multimodal Reasoning: Datasets, Methods, Results, Discussion, and Outlook' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-18 13:07:00+0900","children":"2025년 9월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Multimodal Large Language Models (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models (MLLMs)"]}],["$","span","Visual Grounding",{"className":"page__taxonomy-item","children":["#","Visual Grounding"]}],["$","span","Visual Question Answering",{"className":"page__taxonomy-item","children":["#","Visual Question Answering"]}],["$","span","Advertisement Video Analysis",{"className":"page__taxonomy-item","children":["#","Advertisement Video Analysis"]}],["$","span","Real-world Scenarios",{"className":"page__taxonomy-item","children":["#","Real-world Scenarios"]}],["$","span","Challenge Benchmark",{"className":"page__taxonomy-item","children":["#","Challenge Benchmark"]}]]}]]}]]}],["$","article","2025-9-18-Improving-Context-Fidelity-via-Native-Retrieval-Augmented-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-18-Improving-Context-Fidelity-via-Native-Retrieval-Augmented-Reasoning/","children":"[논문리뷰] Improving Context Fidelity via Native Retrieval-Augmented Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiangru Tang이 [arXiv]에 게시한 'Improving Context Fidelity via Native Retrieval-Augmented Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-18 13:07:00+0900","children":"2025년 9월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Context Fidelity",{"className":"page__taxonomy-item","children":["#","Context Fidelity"]}],["$","span","Retrieval-Augmented Generation (RAG)",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation (RAG)"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Supervised Fine-Tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning (SFT)"]}],["$","span","Hallucination",{"className":"page__taxonomy-item","children":["#","Hallucination"]}],["$","span","Question Answering",{"className":"page__taxonomy-item","children":["#","Question Answering"]}],["$","span","In-context Retrieval",{"className":"page__taxonomy-item","children":["#","In-context Retrieval"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}]]}]]}]]}],["$","article","2025-9-18-Hala-Technical-Report-Building-Arabic-Centric-Instruction-Translation-Models-at-Scale",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-18-Hala-Technical-Report-Building-Arabic-Centric-Instruction-Translation-Models-at-Scale/","children":"[논문리뷰] Hala Technical Report: Building Arabic-Centric Instruction & Translation Models at Scale"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Bernard Ghanem이 [arXiv]에 게시한 'Hala Technical Report: Building Arabic-Centric Instruction & Translation Models at Scale' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-18 13:07:00+0900","children":"2025년 9월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Arabic NLP",{"className":"page__taxonomy-item","children":["#","Arabic NLP"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}],["$","span","Machine Translation",{"className":"page__taxonomy-item","children":["#","Machine Translation"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","FP8 Quantization",{"className":"page__taxonomy-item","children":["#","FP8 Quantization"]}],["$","span","Data Bootstrapping",{"className":"page__taxonomy-item","children":["#","Data Bootstrapping"]}],["$","span","Model Merging",{"className":"page__taxonomy-item","children":["#","Model Merging"]}],["$","span","Language-Centric AI",{"className":"page__taxonomy-item","children":["#","Language-Centric AI"]}]]}]]}]]}],["$","article","2025-9-18-GenExam-A-Multidisciplinary-Text-to-Image-Exam",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-18-GenExam-A-Multidisciplinary-Text-to-Image-Exam/","children":"[논문리뷰] GenExam: A Multidisciplinary Text-to-Image Exam"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yu Qiao이 [arXiv]에 게시한 'GenExam: A Multidisciplinary Text-to-Image Exam' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-18 13:07:00+0900","children":"2025년 9월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Multidisciplinary",{"className":"page__taxonomy-item","children":["#","Multidisciplinary"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Evaluation",{"className":"page__taxonomy-item","children":["#","Evaluation"]}],["$","span","AGI",{"className":"page__taxonomy-item","children":["#","AGI"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Scoring System",{"className":"page__taxonomy-item","children":["#","Scoring System"]}],["$","span","Visual Question Answering",{"className":"page__taxonomy-item","children":["#","Visual Question Answering"]}]]}]]}]]}],["$","article","2025-9-17-WebWeaver-Structuring-Web-Scale-Evidence-with-Dynamic-Outlines-for-Open-Ended-Deep-Research",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-17-WebWeaver-Structuring-Web-Scale-Evidence-with-Dynamic-Outlines-for-Open-Ended-Deep-Research/","children":"[논문리뷰] WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for Open-Ended Deep Research"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Houquan Zhou이 [arXiv]에 게시한 'WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for Open-Ended Deep Research' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-17 13:16:01+0900","children":"2025년 9월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Open-Ended Deep Research",{"className":"page__taxonomy-item","children":["#","Open-Ended Deep Research"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Dynamic Outline",{"className":"page__taxonomy-item","children":["#","Dynamic Outline"]}],["$","span","Evidence Acquisition",{"className":"page__taxonomy-item","children":["#","Evidence Acquisition"]}],["$","span","Hierarchical Writing",{"className":"page__taxonomy-item","children":["#","Hierarchical Writing"]}],["$","span","Memory Bank",{"className":"page__taxonomy-item","children":["#","Memory Bank"]}],["$","span","State-of-the-Art",{"className":"page__taxonomy-item","children":["#","State-of-the-Art"]}],["$","span","Supervised Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning"]}]]}]]}]]}],["$","article","2025-9-17-WebSailor-V2-Bridging-the-Chasm-to-Proprietary-Agents-via-Synthetic-Data-and-Scalable-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-17-WebSailor-V2-Bridging-the-Chasm-to-Proprietary-Agents-via-Synthetic-Data-and-Scalable-Reinforcement-Learning/","children":"[논문리뷰] WebSailor-V2: Bridging the Chasm to Proprietary Agents via Synthetic Data and Scalable Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Huifeng Yin이 [arXiv]에 게시한 'WebSailor-V2: Bridging the Chasm to Proprietary Agents via Synthetic Data and Scalable Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-17 13:16:01+0900","children":"2025년 9월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Web Agents",{"className":"page__taxonomy-item","children":["#","Web Agents"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Synthetic Data",{"className":"page__taxonomy-item","children":["#","Synthetic Data"]}],["$","span","Knowledge Graphs",{"className":"page__taxonomy-item","children":["#","Knowledge Graphs"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Supervised Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning"]}],["$","span","Sim-to-Real Transfer",{"className":"page__taxonomy-item","children":["#","Sim-to-Real Transfer"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}]]}]]}]]}],["$","article","2025-9-17-WebResearcher-Unleashing-unbounded-reasoning-capability-in-Long-Horizon-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-17-WebResearcher-Unleashing-unbounded-reasoning-capability-in-Long-Horizon-Agents/","children":"[논문리뷰] WebResearcher: Unleashing unbounded reasoning capability in Long-Horizon Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wenbiao Yin이 [arXiv]에 게시한 'WebResearcher: Unleashing unbounded reasoning capability in Long-Horizon Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-17 13:16:01+0900","children":"2025년 9월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Deep Research",{"className":"page__taxonomy-item","children":["#","Deep Research"]}],["$","span","Iterative Reasoning",{"className":"page__taxonomy-item","children":["#","Iterative Reasoning"]}],["$","span","Long-Horizon Tasks",{"className":"page__taxonomy-item","children":["#","Long-Horizon Tasks"]}],["$","span","Context Management",{"className":"page__taxonomy-item","children":["#","Context Management"]}],["$","span","Data Synthesis",{"className":"page__taxonomy-item","children":["#","Data Synthesis"]}],["$","span","Tool-Augmented LLMs",{"className":"page__taxonomy-item","children":["#","Tool-Augmented LLMs"]}],["$","span","Markov Decision Process",{"className":"page__taxonomy-item","children":["#","Markov Decision Process"]}]]}]]}]]}],["$","article","2025-9-17-Towards-General-Agentic-Intelligence-via-Environment-Scaling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-17-Towards-General-Agentic-Intelligence-via-Environment-Scaling/","children":"[논문리뷰] Towards General Agentic Intelligence via Environment Scaling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Guangyu Li이 [arXiv]에 게시한 'Towards General Agentic Intelligence via Environment Scaling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-17 13:16:01+0900","children":"2025년 9월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Environment Scaling",{"className":"page__taxonomy-item","children":["#","Environment Scaling"]}],["$","span","Function Calling",{"className":"page__taxonomy-item","children":["#","Function Calling"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Synthetic Data Generation",{"className":"page__taxonomy-item","children":["#","Synthetic Data Generation"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}]]}]]}]]}],["$","article","2025-9-17-Single-stream-Policy-Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-17-Single-stream-Policy-Optimization/","children":"[논문리뷰] Single-stream Policy Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zihan Ding이 [arXiv]에 게시한 'Single-stream Policy Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-17 13:16:01+0900","children":"2025년 9월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","LLM Optimization",{"className":"page__taxonomy-item","children":["#","LLM Optimization"]}],["$","span","Policy Gradient",{"className":"page__taxonomy-item","children":["#","Policy Gradient"]}],["$","span","Variance Reduction",{"className":"page__taxonomy-item","children":["#","Variance Reduction"]}],["$","span","Adaptive Sampling",{"className":"page__taxonomy-item","children":["#","Adaptive Sampling"]}],["$","span","Scalability",{"className":"page__taxonomy-item","children":["#","Scalability"]}],["$","span","Agentic Systems",{"className":"page__taxonomy-item","children":["#","Agentic Systems"]}],["$","span","RLVR",{"className":"page__taxonomy-item","children":["#","RLVR"]}]]}]]}]]}],["$","article","2025-9-17-Scaling-Agents-via-Continual-Pre-training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-17-Scaling-Agents-via-Continual-Pre-training/","children":"[논문리뷰] Scaling Agents via Continual Pre-training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Guangyu Li이 [arXiv]에 게시한 'Scaling Agents via Continual Pre-training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-17 13:16:01+0900","children":"2025년 9월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic LLMs",{"className":"page__taxonomy-item","children":["#","Agentic LLMs"]}],["$","span","Continual Pre-training",{"className":"page__taxonomy-item","children":["#","Continual Pre-training"]}],["$","span","Deep Research Agents",{"className":"page__taxonomy-item","children":["#","Deep Research Agents"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Multi-step Reasoning",{"className":"page__taxonomy-item","children":["#","Multi-step Reasoning"]}],["$","span","Data Synthesis",{"className":"page__taxonomy-item","children":["#","Data Synthesis"]}],["$","span","Scaling Laws",{"className":"page__taxonomy-item","children":["#","Scaling Laws"]}]]}]]}]]}],["$","article","2025-9-17-ReSum-Unlocking-Long-Horizon-Search-Intelligence-via-Context-Summarization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-17-ReSum-Unlocking-Long-Horizon-Search-Intelligence-via-Context-Summarization/","children":"[논문리뷰] ReSum: Unlocking Long-Horizon Search Intelligence via Context Summarization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Litu Ou이 [arXiv]에 게시한 'ReSum: Unlocking Long-Horizon Search Intelligence via Context Summarization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-17 13:16:01+0900","children":"2025년 9월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Context Management",{"className":"page__taxonomy-item","children":["#","Context Management"]}],["$","span","Summarization",{"className":"page__taxonomy-item","children":["#","Summarization"]}],["$","span","ReAct",{"className":"page__taxonomy-item","children":["#","ReAct"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Web Search",{"className":"page__taxonomy-item","children":["#","Web Search"]}],["$","span","Long-Horizon Reasoning",{"className":"page__taxonomy-item","children":["#","Long-Horizon Reasoning"]}]]}]]}]]}],["$","article","2025-9-17-Optimal-Brain-Restoration-for-Joint-Quantization-and-Sparsification-of-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-17-Optimal-Brain-Restoration-for-Joint-Quantization-and-Sparsification-of-LLMs/","children":"[논문리뷰] Optimal Brain Restoration for Joint Quantization and Sparsification of LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Luca Benini이 [arXiv]에 게시한 'Optimal Brain Restoration for Joint Quantization and Sparsification of LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-17 13:16:01+0900","children":"2025년 9월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Compression",{"className":"page__taxonomy-item","children":["#","LLM Compression"]}],["$","span","Quantization",{"className":"page__taxonomy-item","children":["#","Quantization"]}],["$","span","Sparsification",{"className":"page__taxonomy-item","children":["#","Sparsification"]}],["$","span","Post-training Quantization",{"className":"page__taxonomy-item","children":["#","Post-training Quantization"]}],["$","span","Hessian-based Optimization",{"className":"page__taxonomy-item","children":["#","Hessian-based Optimization"]}],["$","span","Error Compensation",{"className":"page__taxonomy-item","children":["#","Error Compensation"]}],["$","span","Low-bit LLMs",{"className":"page__taxonomy-item","children":["#","Low-bit LLMs"]}]]}]]}]]}],["$","article","2025-9-17-Multiple-Instance-Learning-Framework-with-Masked-Hard-Instance-Mining-for-Gigapixel-Histopathology-Image-Analysis",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-17-Multiple-Instance-Learning-Framework-with-Masked-Hard-Instance-Mining-for-Gigapixel-Histopathology-Image-Analysis/","children":"[논문리뷰] Multiple Instance Learning Framework with Masked Hard Instance Mining for Gigapixel Histopathology Image Analysis"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Bo Liu이 [arXiv]에 게시한 'Multiple Instance Learning Framework with Masked Hard Instance Mining for Gigapixel Histopathology Image Analysis' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-17 13:16:01+0900","children":"2025년 9월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multiple Instance Learning",{"className":"page__taxonomy-item","children":["#","Multiple Instance Learning"]}],["$","span","Hard Instance Mining",{"className":"page__taxonomy-item","children":["#","Hard Instance Mining"]}],["$","span","Computational Pathology",{"className":"page__taxonomy-item","children":["#","Computational Pathology"]}],["$","span","Whole Slide Images",{"className":"page__taxonomy-item","children":["#","Whole Slide Images"]}],["$","span","Masked Learning",{"className":"page__taxonomy-item","children":["#","Masked Learning"]}],["$","span","Siamese Network",{"className":"page__taxonomy-item","children":["#","Siamese Network"]}],["$","span","Medical Image Analysis",{"className":"page__taxonomy-item","children":["#","Medical Image Analysis"]}]]}]]}]]}],["$","article","2025-9-17-Multimodal-Reasoning-for-Science-Technical-Report-and-1st-Place-Solution-to-the-ICML-2025-SeePhys-Challenge",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-17-Multimodal-Reasoning-for-Science-Technical-Report-and-1st-Place-Solution-to-the-ICML-2025-SeePhys-Challenge/","children":"[논문리뷰] Multimodal Reasoning for Science: Technical Report and 1st Place Solution to the ICML 2025 SeePhys Challenge"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wentao Zhang이 [arXiv]에 게시한 'Multimodal Reasoning for Science: Technical Report and 1st Place Solution to the ICML 2025 SeePhys Challenge' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-17 13:16:01+0900","children":"2025년 9월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","span","Science AI",{"className":"page__taxonomy-item","children":["#","Science AI"]}],["$","span","Caption-assisted Reasoning",{"className":"page__taxonomy-item","children":["#","Caption-assisted Reasoning"]}],["$","span","SeePhys Challenge",{"className":"page__taxonomy-item","children":["#","SeePhys Challenge"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Visual Question Answering",{"className":"page__taxonomy-item","children":["#","Visual Question Answering"]}],["$","span","Physics Problems",{"className":"page__taxonomy-item","children":["#","Physics Problems"]}],["$","span","Cross-modal Alignment",{"className":"page__taxonomy-item","children":["#","Cross-modal Alignment"]}]]}]]}]]}],["$","article","2025-9-17-Hunyuan3D-Studio-End-to-End-AI-Pipeline-for-Game-Ready-3D-Asset-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-17-Hunyuan3D-Studio-End-to-End-AI-Pipeline-for-Game-Ready-3D-Asset-Generation/","children":"[논문리뷰] Hunyuan3D Studio: End-to-End AI Pipeline for Game-Ready 3D Asset Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Lixin Xu이 [arXiv]에 게시한 'Hunyuan3D Studio: End-to-End AI Pipeline for Game-Ready 3D Asset Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-17 13:16:01+0900","children":"2025년 9월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Asset Generation",{"className":"page__taxonomy-item","children":["#","3D Asset Generation"]}],["$","span","AI Pipeline",{"className":"page__taxonomy-item","children":["#","AI Pipeline"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Game Development",{"className":"page__taxonomy-item","children":["#","Game Development"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Neural Modules",{"className":"page__taxonomy-item","children":["#","Neural Modules"]}],["$","span","Retopology",{"className":"page__taxonomy-item","children":["#","Retopology"]}],["$","span","UV Unwrapping",{"className":"page__taxonomy-item","children":["#","UV Unwrapping"]}]]}]]}]]}],["$","article","2025-9-17-Exact-Coset-Sampling-for-Quantum-Lattice-Algorithms",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-17-Exact-Coset-Sampling-for-Quantum-Lattice-Algorithms/","children":"[논문리뷰] Exact Coset Sampling for Quantum Lattice Algorithms"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yifan Zhang이 [arXiv]에 게시한 'Exact Coset Sampling for Quantum Lattice Algorithms' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-17 13:16:01+0900","children":"2025년 9월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Quantum Algorithms",{"className":"page__taxonomy-item","children":["#","Quantum Algorithms"]}],["$","span","Lattice Problems",{"className":"page__taxonomy-item","children":["#","Lattice Problems"]}],["$","span","Coset Sampling",{"className":"page__taxonomy-item","children":["#","Coset Sampling"]}],["$","span","Quantum Fourier Transform (QFT)",{"className":"page__taxonomy-item","children":["#","Quantum Fourier Transform (QFT)"]}],["$","span","Modular Arithmetic",{"className":"page__taxonomy-item","children":["#","Modular Arithmetic"]}],["$","span","Quantum Cryptography",{"className":"page__taxonomy-item","children":["#","Quantum Cryptography"]}],["$","span","Exact Sampling",{"className":"page__taxonomy-item","children":["#","Exact Sampling"]}]]}]]}]]}],["$","article","2025-9-17-EconProver-Towards-More-Economical-Test-Time-Scaling-for-Automated-Theorem-Proving",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-17-EconProver-Towards-More-Economical-Test-Time-Scaling-for-Automated-Theorem-Proving/","children":"[논문리뷰] EconProver: Towards More Economical Test-Time Scaling for Automated Theorem Proving"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shansan Gong이 [arXiv]에 게시한 'EconProver: Towards More Economical Test-Time Scaling for Automated Theorem Proving' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-17 13:16:01+0900","children":"2025년 9월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Automated Theorem Proving",{"className":"page__taxonomy-item","children":["#","Automated Theorem Proving"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Test-Time Scaling",{"className":"page__taxonomy-item","children":["#","Test-Time Scaling"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Efficiency Optimization",{"className":"page__taxonomy-item","children":["#","Efficiency Optimization"]}],["$","span","Token Cost",{"className":"page__taxonomy-item","children":["#","Token Cost"]}],["$","span","Sampling Cost",{"className":"page__taxonomy-item","children":["#","Sampling Cost"]}],["$","span","Dynamic CoT Switching",{"className":"page__taxonomy-item","children":["#","Dynamic CoT Switching"]}]]}]]}]]}],["$","article","2025-9-17-3D-Aware-Region-Prompted-Vision-Language-Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-17-3D-Aware-Region-Prompted-Vision-Language-Model/","children":"[논문리뷰] 3D Aware Region Prompted Vision Language Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiaolong Li이 [arXiv]에 게시한 '3D Aware Region Prompted Vision Language Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-17 13:16:01+0900","children":"2025년 9월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Vision",{"className":"page__taxonomy-item","children":["#","3D Vision"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}],["$","span","Region Prompting",{"className":"page__taxonomy-item","children":["#","Region Prompting"]}],["$","span","Multi-view Learning",{"className":"page__taxonomy-item","children":["#","Multi-view Learning"]}],["$","span","Depth Estimation",{"className":"page__taxonomy-item","children":["#","Depth Estimation"]}],["$","span","Unified Representation",{"className":"page__taxonomy-item","children":["#","Unified Representation"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}]]}]]}]]}],["$","article","2025-9-16-UI-S1-Advancing-GUI-Automation-via-Semi-online-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-16-UI-S1-Advancing-GUI-Automation-via-Semi-online-Reinforcement-Learning/","children":"[논문리뷰] UI-S1: Advancing GUI Automation via Semi-online Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yongliang Shen이 [arXiv]에 게시한 'UI-S1: Advancing GUI Automation via Semi-online Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-16 13:16:41+0900","children":"2025년 9월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","GUI Automation",{"className":"page__taxonomy-item","children":["#","GUI Automation"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Semi-online RL",{"className":"page__taxonomy-item","children":["#","Semi-online RL"]}],["$","span","Offline RL",{"className":"page__taxonomy-item","children":["#","Offline RL"]}],["$","span","Online RL",{"className":"page__taxonomy-item","children":["#","Online RL"]}],["$","span","Patch Module",{"className":"page__taxonomy-item","children":["#","Patch Module"]}],["$","span","Multi-turn Interaction",{"className":"page__taxonomy-item","children":["#","Multi-turn Interaction"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}]]}]]}]]}],["$","article","2025-9-16-SearchInstruct-Enhancing-Domain-Adaptation-via-Retrieval-Based-Instruction-Dataset-Creation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-16-SearchInstruct-Enhancing-Domain-Adaptation-via-Retrieval-Based-Instruction-Dataset-Creation/","children":"[논문리뷰] SearchInstruct: Enhancing Domain Adaptation via Retrieval-Based Instruction Dataset Creation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Heshaam Faili이 [arXiv]에 게시한 'SearchInstruct: Enhancing Domain Adaptation via Retrieval-Based Instruction Dataset Creation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-16 13:16:41+0900","children":"2025년 9월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}],["$","span","Domain Adaptation",{"className":"page__taxonomy-item","children":["#","Domain Adaptation"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","Dataset Creation",{"className":"page__taxonomy-item","children":["#","Dataset Creation"]}],["$","span","Model Editing",{"className":"page__taxonomy-item","children":["#","Model Editing"]}],["$","span","Supervised Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning"]}]]}]]}]]}],["$","article","2025-9-16-PersonaX-Multimodal-Datasets-with-LLM-Inferred-Behavior-Traits",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-16-PersonaX-Multimodal-Datasets-with-LLM-Inferred-Behavior-Traits/","children":"[논문리뷰] PersonaX: Multimodal Datasets with LLM-Inferred Behavior Traits"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhenhao Chen이 [arXiv]에 게시한 'PersonaX: Multimodal Datasets with LLM-Inferred Behavior Traits' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-16 13:16:41+0900","children":"2025년 9월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Dataset",{"className":"page__taxonomy-item","children":["#","Multimodal Dataset"]}],["$","span","LLM Inference",{"className":"page__taxonomy-item","children":["#","LLM Inference"]}],["$","span","Behavioral Traits",{"className":"page__taxonomy-item","children":["#","Behavioral Traits"]}],["$","span","Causal Representation Learning",{"className":"page__taxonomy-item","children":["#","Causal Representation Learning"]}],["$","span","Big Five",{"className":"page__taxonomy-item","children":["#","Big Five"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Causal Discovery",{"className":"page__taxonomy-item","children":["#","Causal Discovery"]}],["$","span","Human-Computer Interaction",{"className":"page__taxonomy-item","children":["#","Human-Computer Interaction"]}]]}]]}]]}],["$","article","2025-9-16-OmniWorld-A-Multi-Domain-and-Multi-Modal-Dataset-for-4D-World-Modeling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-16-OmniWorld-A-Multi-Domain-and-Multi-Modal-Dataset-for-4D-World-Modeling/","children":"[논문리뷰] OmniWorld: A Multi-Domain and Multi-Modal Dataset for 4D World Modeling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yang Zhou이 [arXiv]에 게시한 'OmniWorld: A Multi-Domain and Multi-Modal Dataset for 4D World Modeling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-16 13:16:41+0900","children":"2025년 9월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","4D World Modeling",{"className":"page__taxonomy-item","children":["#","4D World Modeling"]}],["$","span","Multi-Modal Dataset",{"className":"page__taxonomy-item","children":["#","Multi-Modal Dataset"]}],["$","span","Multi-Domain Data",{"className":"page__taxonomy-item","children":["#","Multi-Domain Data"]}],["$","span","Geometric Foundation Models",{"className":"page__taxonomy-item","children":["#","Geometric Foundation Models"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Spatio-Temporal Data",{"className":"page__taxonomy-item","children":["#","Spatio-Temporal Data"]}],["$","span","Dataset Benchmark",{"className":"page__taxonomy-item","children":["#","Dataset Benchmark"]}]]}]]}]]}],["$","article","2025-9-16-Measuring-Epistemic-Humility-in-Multimodal-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-16-Measuring-Epistemic-Humility-in-Multimodal-Large-Language-Models/","children":"[논문리뷰] Measuring Epistemic Humility in Multimodal Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kaiyang Zhou이 [arXiv]에 게시한 'Measuring Epistemic Humility in Multimodal Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-16 13:16:41+0900","children":"2025년 9월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models"]}],["$","span","Hallucination",{"className":"page__taxonomy-item","children":["#","Hallucination"]}],["$","span","Epistemic Humility",{"className":"page__taxonomy-item","children":["#","Epistemic Humility"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","False-Option Rejection",{"className":"page__taxonomy-item","children":["#","False-Option Rejection"]}],["$","span","Visual Question Answering",{"className":"page__taxonomy-item","children":["#","Visual Question Answering"]}],["$","span","Scene Graph",{"className":"page__taxonomy-item","children":["#","Scene Graph"]}]]}]]}]]}],["$","article","2025-9-16-Lost-in-Embeddings-Information-Loss-in-Vision-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-16-Lost-in-Embeddings-Information-Loss-in-Vision-Language-Models/","children":"[논문리뷰] Lost in Embeddings: Information Loss in Vision-Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ivan Vulić이 [arXiv]에 게시한 'Lost in Embeddings: Information Loss in Vision-Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-16 13:16:41+0900","children":"2025년 9월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Information Loss",{"className":"page__taxonomy-item","children":["#","Information Loss"]}],["$","span","Embeddings",{"className":"page__taxonomy-item","children":["#","Embeddings"]}],["$","span","Connectors",{"className":"page__taxonomy-item","children":["#","Connectors"]}],["$","span","k-NN Overlap Ratio",{"className":"page__taxonomy-item","children":["#","k-NN Overlap Ratio"]}],["$","span","Embedding Reconstruction",{"className":"page__taxonomy-item","children":["#","Embedding Reconstruction"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}]]}]]}]]}],["$","article","2025-9-16-Look-Again-Think-Slowly-Enhancing-Visual-Reflection-in-Vision-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-16-Look-Again-Think-Slowly-Enhancing-Visual-Reflection-in-Vision-Language-Models/","children":"[논문리뷰] Look Again, Think Slowly: Enhancing Visual Reflection in Vision-Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shuo Ren이 [arXiv]에 게시한 'Look Again, Think Slowly: Enhancing Visual Reflection in Vision-Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-16 13:16:41+0900","children":"2025년 9월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Visual Reasoning",{"className":"page__taxonomy-item","children":["#","Visual Reasoning"]}],["$","span","Reflection",{"className":"page__taxonomy-item","children":["#","Reflection"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Visual Attention",{"className":"page__taxonomy-item","children":["#","Visual Attention"]}],["$","span","Slow Thinking",{"className":"page__taxonomy-item","children":["#","Slow Thinking"]}],["$","span","Multimodal Agents",{"className":"page__taxonomy-item","children":["#","Multimodal Agents"]}]]}]]}]]}],["$","article","2025-9-16-Locality-in-Image-Diffusion-Models-Emerges-from-Data-Statistics",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-16-Locality-in-Image-Diffusion-Models-Emerges-from-Data-Statistics/","children":"[논문리뷰] Locality in Image Diffusion Models Emerges from Data Statistics"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Vincent Sitzmann이 [arXiv]에 게시한 'Locality in Image Diffusion Models Emerges from Data Statistics' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-16 13:16:41+0900","children":"2025년 9월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Locality",{"className":"page__taxonomy-item","children":["#","Locality"]}],["$","span","Data Statistics",{"className":"page__taxonomy-item","children":["#","Data Statistics"]}],["$","span","Optimal Denoiser",{"className":"page__taxonomy-item","children":["#","Optimal Denoiser"]}],["$","span","Wiener Filter",{"className":"page__taxonomy-item","children":["#","Wiener Filter"]}],["$","span","Sensitivity Fields",{"className":"page__taxonomy-item","children":["#","Sensitivity Fields"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Inductive Bias",{"className":"page__taxonomy-item","children":["#","Inductive Bias"]}]]}]]}]]}],["$","article","2025-9-16-Learning-to-Optimize-Multi-Objective-Alignment-Through-Dynamic-Reward-Weighting",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-16-Learning-to-Optimize-Multi-Objective-Alignment-Through-Dynamic-Reward-Weighting/","children":"[논문리뷰] Learning to Optimize Multi-Objective Alignment Through Dynamic Reward Weighting"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Changlong Yu이 [arXiv]에 게시한 'Learning to Optimize Multi-Objective Alignment Through Dynamic Reward Weighting' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-16 13:16:41+0900","children":"2025년 9월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-objective Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Multi-objective Reinforcement Learning"]}],["$","span","LLM Alignment",{"className":"page__taxonomy-item","children":["#","LLM Alignment"]}],["$","span","Dynamic Reward Weighting",{"className":"page__taxonomy-item","children":["#","Dynamic Reward Weighting"]}],["$","span","Pareto Front Optimization",{"className":"page__taxonomy-item","children":["#","Pareto Front Optimization"]}],["$","span","Hypervolume Indicator",{"className":"page__taxonomy-item","children":["#","Hypervolume Indicator"]}],["$","span","Gradient-based Optimization",{"className":"page__taxonomy-item","children":["#","Gradient-based Optimization"]}],["$","span","Online RL",{"className":"page__taxonomy-item","children":["#","Online RL"]}]]}]]}]]}],["$","article","2025-9-16-LazyDrag-Enabling-Stable-Drag-Based-Editing-on-Multi-Modal-Diffusion-Transformers-via-Explicit-Correspondence",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-16-LazyDrag-Enabling-Stable-Drag-Based-Editing-on-Multi-Modal-Diffusion-Transformers-via-Explicit-Correspondence/","children":"[논문리뷰] LazyDrag: Enabling Stable Drag-Based Editing on Multi-Modal Diffusion Transformers via Explicit Correspondence"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Lionel M. Ni이 [arXiv]에 게시한 'LazyDrag: Enabling Stable Drag-Based Editing on Multi-Modal Diffusion Transformers via Explicit Correspondence' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-16 13:16:41+0900","children":"2025년 9월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Multi-Modal Transformers",{"className":"page__taxonomy-item","children":["#","Multi-Modal Transformers"]}],["$","span","Drag-based Editing",{"className":"page__taxonomy-item","children":["#","Drag-based Editing"]}],["$","span","Explicit Correspondence",{"className":"page__taxonomy-item","children":["#","Explicit Correspondence"]}],["$","span","Attention Control",{"className":"page__taxonomy-item","children":["#","Attention Control"]}],["$","span","Identity Preservation",{"className":"page__taxonomy-item","children":["#","Identity Preservation"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}]]}]]}]]}],["$","article","2025-9-16-InternScenes-A-Large-scale-Simulatable-Indoor-Scene-Dataset-with-Realistic-Layouts",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-16-InternScenes-A-Large-scale-Simulatable-Indoor-Scene-Dataset-with-Realistic-Layouts/","children":"[논문리뷰] InternScenes: A Large-scale Simulatable Indoor Scene Dataset with Realistic Layouts"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wenzhe Cai이 [arXiv]에 게시한 'InternScenes: A Large-scale Simulatable Indoor Scene Dataset with Realistic Layouts' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-16 13:16:41+0900","children":"2025년 9월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","3D Scene Dataset",{"className":"page__taxonomy-item","children":["#","3D Scene Dataset"]}],["$","span","Simulation Environment",{"className":"page__taxonomy-item","children":["#","Simulation Environment"]}],["$","span","Scene Generation",{"className":"page__taxonomy-item","children":["#","Scene Generation"]}],["$","span","Point-Goal Navigation",{"className":"page__taxonomy-item","children":["#","Point-Goal Navigation"]}],["$","span","Realistic Layouts",{"className":"page__taxonomy-item","children":["#","Realistic Layouts"]}],["$","span","Object Interaction",{"className":"page__taxonomy-item","children":["#","Object Interaction"]}],["$","span","Real-to-Sim",{"className":"page__taxonomy-item","children":["#","Real-to-Sim"]}]]}]]}]]}],["$","article","2025-9-16-GAPrune-Gradient-Alignment-Pruning-for-Domain-Aware-Embeddings",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-16-GAPrune-Gradient-Alignment-Pruning-for-Domain-Aware-Embeddings/","children":"[논문리뷰] GAPrune: Gradient-Alignment Pruning for Domain-Aware Embeddings"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yixuan Tang이 [arXiv]에 게시한 'GAPrune: Gradient-Alignment Pruning for Domain-Aware Embeddings' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-16 13:16:41+0900","children":"2025년 9월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Model Pruning",{"className":"page__taxonomy-item","children":["#","Model Pruning"]}],["$","span","Domain Adaptation",{"className":"page__taxonomy-item","children":["#","Domain Adaptation"]}],["$","span","Embedding Models",{"className":"page__taxonomy-item","children":["#","Embedding Models"]}],["$","span","Gradient Alignment",{"className":"page__taxonomy-item","children":["#","Gradient Alignment"]}],["$","span","Fisher Information",{"className":"page__taxonomy-item","children":["#","Fisher Information"]}],["$","span","Model Compression",{"className":"page__taxonomy-item","children":["#","Model Compression"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}]]}]]}]]}],["$","article","2025-9-16-EthicsMH-A-Pilot-Benchmark-for-Ethical-Reasoning-in-Mental-Health-AI",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-16-EthicsMH-A-Pilot-Benchmark-for-Ethical-Reasoning-in-Mental-Health-AI/","children":"[논문리뷰] EthicsMH: A Pilot Benchmark for Ethical Reasoning in Mental Health AI"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"UVSKKR이 [arXiv]에 게시한 'EthicsMH: A Pilot Benchmark for Ethical Reasoning in Mental Health AI' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-16 13:16:41+0900","children":"2025년 9월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Ethical Reasoning",{"className":"page__taxonomy-item","children":["#","Ethical Reasoning"]}],["$","span","Mental Health AI",{"className":"page__taxonomy-item","children":["#","Mental Health AI"]}],["$","span","Benchmark Dataset",{"className":"page__taxonomy-item","children":["#","Benchmark Dataset"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","AI Ethics",{"className":"page__taxonomy-item","children":["#","AI Ethics"]}],["$","span","Clinical Decision Support",{"className":"page__taxonomy-item","children":["#","Clinical Decision Support"]}],["$","span","Human-in-the-loop",{"className":"page__taxonomy-item","children":["#","Human-in-the-loop"]}]]}]]}]]}],["$","article","2025-9-16-Dr-V-A-Hierarchical-Perception-Temporal-Cognition-Framework-to-Diagnose-Video-Hallucination-by-Fine-grained-Spatial-Temporal-Grounding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-16-Dr-V-A-Hierarchical-Perception-Temporal-Cognition-Framework-to-Diagnose-Video-Hallucination-by-Fine-grained-Spatial-Temporal-Grounding/","children":"[논문리뷰] Dr.V: A Hierarchical Perception-Temporal-Cognition Framework to Diagnose Video Hallucination by Fine-grained Spatial-Temporal Grounding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Li Zheng이 [arXiv]에 게시한 'Dr.V: A Hierarchical Perception-Temporal-Cognition Framework to Diagnose Video Hallucination by Fine-grained Spatial-Temporal Grounding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-16 13:16:41+0900","children":"2025년 9월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Hallucination",{"className":"page__taxonomy-item","children":["#","Video Hallucination"]}],["$","span","Large Video Models (LVMs)",{"className":"page__taxonomy-item","children":["#","Large Video Models (LVMs)"]}],["$","span","Hierarchical Reasoning",{"className":"page__taxonomy-item","children":["#","Hierarchical Reasoning"]}],["$","span","Spatial-Temporal Grounding",{"className":"page__taxonomy-item","children":["#","Spatial-Temporal Grounding"]}],["$","span","Diagnostic Framework",{"className":"page__taxonomy-item","children":["#","Diagnostic Framework"]}],["$","span","Benchmark Dataset",{"className":"page__taxonomy-item","children":["#","Benchmark Dataset"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}]]}]]}]]}],["$","article","2025-9-16-CognitiveSky-Scalable-Sentiment-and-Narrative-Analysis-for-Decentralized-Social-Media",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-16-CognitiveSky-Scalable-Sentiment-and-Narrative-Analysis-for-Decentralized-Social-Media/","children":"[논문리뷰] CognitiveSky: Scalable Sentiment and Narrative Analysis for Decentralized Social Media"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Subasish Das이 [arXiv]에 게시한 'CognitiveSky: Scalable Sentiment and Narrative Analysis for Decentralized Social Media' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-16 13:16:41+0900","children":"2025년 9월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Sentiment Analysis",{"className":"page__taxonomy-item","children":["#","Sentiment Analysis"]}],["$","span","Narrative Analysis",{"className":"page__taxonomy-item","children":["#","Narrative Analysis"]}],["$","span","Decentralized Social Media",{"className":"page__taxonomy-item","children":["#","Decentralized Social Media"]}],["$","span","Bluesky",{"className":"page__taxonomy-item","children":["#","Bluesky"]}],["$","span","Transformer Models",{"className":"page__taxonomy-item","children":["#","Transformer Models"]}],["$","span","Topic Modeling",{"className":"page__taxonomy-item","children":["#","Topic Modeling"]}],["$","span","Real-time Processing",{"className":"page__taxonomy-item","children":["#","Real-time Processing"]}],["$","span","Data Visualization",{"className":"page__taxonomy-item","children":["#","Data Visualization"]}]]}]]}]]}],["$","article","2025-9-15-X-Part-high-fidelity-and-structure-coherent-shape-decomposition",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-15-X-Part-high-fidelity-and-structure-coherent-shape-decomposition/","children":"[논문리뷰] X-Part: high fidelity and structure coherent shape decomposition"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yunhan Yang이 [arXiv]에 게시한 'X-Part: high fidelity and structure coherent shape decomposition' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-15 13:12:08+0900","children":"2025년 9월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Shape Decomposition",{"className":"page__taxonomy-item","children":["#","3D Shape Decomposition"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Part-level Generation",{"className":"page__taxonomy-item","children":["#","Part-level Generation"]}],["$","span","Controllable Generation",{"className":"page__taxonomy-item","children":["#","Controllable Generation"]}],["$","span","Bounding Box Prompts",{"className":"page__taxonomy-item","children":["#","Bounding Box Prompts"]}],["$","span","Semantic Features",{"className":"page__taxonomy-item","children":["#","Semantic Features"]}],["$","span","Interactive Editing",{"className":"page__taxonomy-item","children":["#","Interactive Editing"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}]]}]]}]]}],["$","article","2025-9-15-Virtual-Agent-Economies",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-15-Virtual-Agent-Economies/","children":"[논문리뷰] Virtual Agent Economies"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"William A. Cunningham이 [arXiv]에 게시한 'Virtual Agent Economies' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-15 13:12:08+0900","children":"2025년 9월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Agents",{"className":"page__taxonomy-item","children":["#","AI Agents"]}],["$","span","Virtual Economy",{"className":"page__taxonomy-item","children":["#","Virtual Economy"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Economic Mechanisms",{"className":"page__taxonomy-item","children":["#","Economic Mechanisms"]}],["$","span","Governance",{"className":"page__taxonomy-item","children":["#","Governance"]}],["$","span","Blockchain",{"className":"page__taxonomy-item","children":["#","Blockchain"]}],["$","span","Resource Allocation",{"className":"page__taxonomy-item","children":["#","Resource Allocation"]}],["$","span","Agent Alignment",{"className":"page__taxonomy-item","children":["#","Agent Alignment"]}]]}]]}]]}],["$","article","2025-9-15-VStyle-A-Benchmark-for-Voice-Style-Adaptation-with-Spoken-Instructions",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-15-VStyle-A-Benchmark-for-Voice-Style-Adaptation-with-Spoken-Instructions/","children":"[논문리뷰] VStyle: A Benchmark for Voice Style Adaptation with Spoken Instructions"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Dong Zhang이 [arXiv]에 게시한 'VStyle: A Benchmark for Voice Style Adaptation with Spoken Instructions' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-15 13:12:08+0900","children":"2025년 9월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Voice Style Adaptation",{"className":"page__taxonomy-item","children":["#","Voice Style Adaptation"]}],["$","span","Spoken Language Models",{"className":"page__taxonomy-item","children":["#","Spoken Language Models"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","LALM-as-a-Judge",{"className":"page__taxonomy-item","children":["#","LALM-as-a-Judge"]}],["$","span","Speech Generation",{"className":"page__taxonomy-item","children":["#","Speech Generation"]}],["$","span","Multilingual",{"className":"page__taxonomy-item","children":["#","Multilingual"]}],["$","span","Evaluation Framework",{"className":"page__taxonomy-item","children":["#","Evaluation Framework"]}]]}]]}]]}],["$","article","2025-9-15-The-Illusion-of-Diminishing-Returns-Measuring-Long-Horizon-Execution-in-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-15-The-Illusion-of-Diminishing-Returns-Measuring-Long-Horizon-Execution-in-LLMs/","children":"[논문리뷰] The Illusion of Diminishing Returns: Measuring Long Horizon Execution in LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jonas Geiping이 [arXiv]에 게시한 'The Illusion of Diminishing Returns: Measuring Long Horizon Execution in LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-15 13:12:08+0900","children":"2025년 9월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Long-Horizon Tasks",{"className":"page__taxonomy-item","children":["#","Long-Horizon Tasks"]}],["$","span","Execution Capability",{"className":"page__taxonomy-item","children":["#","Execution Capability"]}],["$","span","Scaling Laws",{"className":"page__taxonomy-item","children":["#","Scaling Laws"]}],["$","span","Self-Conditioning",{"className":"page__taxonomy-item","children":["#","Self-Conditioning"]}],["$","span","Thinking Models",{"className":"page__taxonomy-item","children":["#","Thinking Models"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}]]}]]}]]}],["$","article","2025-9-15-QuantAgent-Price-Driven-Multi-Agent-LLMs-for-High-Frequency-Trading",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-15-QuantAgent-Price-Driven-Multi-Agent-LLMs-for-High-Frequency-Trading/","children":"[논문리뷰] QuantAgent: Price-Driven Multi-Agent LLMs for High-Frequency Trading"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chenyu You이 [arXiv]에 게시한 'QuantAgent: Price-Driven Multi-Agent LLMs for High-Frequency Trading' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-15 13:12:08+0900","children":"2025년 9월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","High-Frequency Trading",{"className":"page__taxonomy-item","children":["#","High-Frequency Trading"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Technical Analysis",{"className":"page__taxonomy-item","children":["#","Technical Analysis"]}],["$","span","Algorithmic Trading",{"className":"page__taxonomy-item","children":["#","Algorithmic Trading"]}],["$","span","Financial Reasoning",{"className":"page__taxonomy-item","children":["#","Financial Reasoning"]}],["$","span","Price-Driven Signals",{"className":"page__taxonomy-item","children":["#","Price-Driven Signals"]}]]}]]}]]}],["$","article","2025-9-15-MCP-AgentBench-Evaluating-Real-World-Language-Agent-Performance-with-MCP-Mediated-Tools",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-15-MCP-AgentBench-Evaluating-Real-World-Language-Agent-Performance-with-MCP-Mediated-Tools/","children":"[논문리뷰] MCP-AgentBench: Evaluating Real-World Language Agent Performance with MCP-Mediated Tools"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiaorui Wang이 [arXiv]에 게시한 'MCP-AgentBench: Evaluating Real-World Language Agent Performance with MCP-Mediated Tools' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-15 13:12:08+0900","children":"2025년 9월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Language Agents",{"className":"page__taxonomy-item","children":["#","Language Agents"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Benchmarks",{"className":"page__taxonomy-item","children":["#","Benchmarks"]}],["$","span","Model Context Protocol (MCP)",{"className":"page__taxonomy-item","children":["#","Model Context Protocol (MCP)"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Real-World Performance",{"className":"page__taxonomy-item","children":["#","Real-World Performance"]}]]}]]}]]}],["$","article","2025-9-15-LoFT-Parameter-Efficient-Fine-Tuning-for-Long-tailed-Semi-Supervised-Learning-in-Open-World-Scenarios",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-15-LoFT-Parameter-Efficient-Fine-Tuning-for-Long-tailed-Semi-Supervised-Learning-in-Open-World-Scenarios/","children":"[논문리뷰] LoFT: Parameter-Efficient Fine-Tuning for Long-tailed Semi-Supervised Learning in Open-World Scenarios"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Bing Su이 [arXiv]에 게시한 'LoFT: Parameter-Efficient Fine-Tuning for Long-tailed Semi-Supervised Learning in Open-World Scenarios' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-15 13:12:08+0900","children":"2025년 9월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Long-tailed Learning",{"className":"page__taxonomy-item","children":["#","Long-tailed Learning"]}],["$","span","Semi-Supervised Learning",{"className":"page__taxonomy-item","children":["#","Semi-Supervised Learning"]}],["$","span","Parameter-Efficient Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Parameter-Efficient Fine-Tuning"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Open-World Scenarios",{"className":"page__taxonomy-item","children":["#","Open-World Scenarios"]}],["$","span","OOD Detection",{"className":"page__taxonomy-item","children":["#","OOD Detection"]}],["$","span","Confidence Calibration",{"className":"page__taxonomy-item","children":["#","Confidence Calibration"]}]]}]]}]]}],["$","article","2025-9-15-IntrEx-A-Dataset-for-Modeling-Engagement-in-Educational-Conversations",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-15-IntrEx-A-Dataset-for-Modeling-Engagement-in-Educational-Conversations/","children":"[논문리뷰] IntrEx: A Dataset for Modeling Engagement in Educational Conversations"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Gabriele Pergola이 [arXiv]에 게시한 'IntrEx: A Dataset for Modeling Engagement in Educational Conversations' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-15 13:12:08+0900","children":"2025년 9월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Educational Dialogue",{"className":"page__taxonomy-item","children":["#","Educational Dialogue"]}],["$","span","Engagement Modeling",{"className":"page__taxonomy-item","children":["#","Engagement Modeling"]}],["$","span","Dataset Annotation",{"className":"page__taxonomy-item","children":["#","Dataset Annotation"]}],["$","span","Second Language Learning",{"className":"page__taxonomy-item","children":["#","Second Language Learning"]}],["$","span","Human Feedback",{"className":"page__taxonomy-item","children":["#","Human Feedback"]}],["$","span","LLM Alignment",{"className":"page__taxonomy-item","children":["#","LLM Alignment"]}],["$","span","Readability Metrics",{"className":"page__taxonomy-item","children":["#","Readability Metrics"]}]]}]]}]]}],["$","article","2025-9-15-Inpainting-Guided-Policy-Optimization-for-Diffusion-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-15-Inpainting-Guided-Policy-Optimization-for-Diffusion-Large-Language-Models/","children":"[논문리뷰] Inpainting-Guided Policy Optimization for Diffusion Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chenyu Wang이 [arXiv]에 게시한 'Inpainting-Guided Policy Optimization for Diffusion Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-15 13:12:08+0900","children":"2025년 9월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion LLMs",{"className":"page__taxonomy-item","children":["#","Diffusion LLMs"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Inpainting",{"className":"page__taxonomy-item","children":["#","Inpainting"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Exploration",{"className":"page__taxonomy-item","children":["#","Exploration"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","GRPO",{"className":"page__taxonomy-item","children":["#","GRPO"]}]]}]]}]]}],["$","article","2025-9-15-InfGen-A-Resolution-Agnostic-Paradigm-for-Scalable-Image-Synthesis",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-15-InfGen-A-Resolution-Agnostic-Paradigm-for-Scalable-Image-Synthesis/","children":"[논문리뷰] InfGen: A Resolution-Agnostic Paradigm for Scalable Image Synthesis"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Song Guo이 [arXiv]에 게시한 'InfGen: A Resolution-Agnostic Paradigm for Scalable Image Synthesis' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-15 13:12:08+0900","children":"2025년 9월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Synthesis",{"className":"page__taxonomy-item","children":["#","Image Synthesis"]}],["$","span","Resolution-Agnostic",{"className":"page__taxonomy-item","children":["#","Resolution-Agnostic"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Latent Space",{"className":"page__taxonomy-item","children":["#","Latent Space"]}],["$","span","VAE Decoder",{"className":"page__taxonomy-item","children":["#","VAE Decoder"]}],["$","span","High-Resolution Image Generation",{"className":"page__taxonomy-item","children":["#","High-Resolution Image Generation"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}]]}]]}]]}],["$","article","2025-9-15-HANRAG-Heuristic-Accurate-Noise-resistant-Retrieval-Augmented-Generation-for-Multi-hop-Question-Answering",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-15-HANRAG-Heuristic-Accurate-Noise-resistant-Retrieval-Augmented-Generation-for-Multi-hop-Question-Answering/","children":"[논문리뷰] HANRAG: Heuristic Accurate Noise-resistant Retrieval-Augmented Generation for Multi-hop Question Answering"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhehao Tan이 [arXiv]에 게시한 'HANRAG: Heuristic Accurate Noise-resistant Retrieval-Augmented Generation for Multi-hop Question Answering' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-15 13:12:08+0900","children":"2025년 9월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","Multi-hop QA",{"className":"page__taxonomy-item","children":["#","Multi-hop QA"]}],["$","span","Noise Resistance",{"className":"page__taxonomy-item","children":["#","Noise Resistance"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Query Decomposition",{"className":"page__taxonomy-item","children":["#","Query Decomposition"]}],["$","span","Adaptive Retrieval",{"className":"page__taxonomy-item","children":["#","Adaptive Retrieval"]}],["$","span","Heuristic Framework",{"className":"page__taxonomy-item","children":["#","Heuristic Framework"]}],["$","span","Revelator",{"className":"page__taxonomy-item","children":["#","Revelator"]}]]}]]}]]}],["$","article","2025-9-15-FLOWER-Democratizing-Generalist-Robot-Policies-with-Efficient-Vision-Language-Action-Flow-Policies",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-15-FLOWER-Democratizing-Generalist-Robot-Policies-with-Efficient-Vision-Language-Action-Flow-Policies/","children":"[논문리뷰] FLOWER: Democratizing Generalist Robot Policies with Efficient Vision-Language-Action Flow Policies"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Fabian Otto이 [arXiv]에 게시한 'FLOWER: Democratizing Generalist Robot Policies with Efficient Vision-Language-Action Flow Policies' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-15 13:12:08+0900","children":"2025년 9월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Generalist Robot Policies",{"className":"page__taxonomy-item","children":["#","Generalist Robot Policies"]}],["$","span","Vision-Language-Action Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action Models"]}],["$","span","Efficient AI",{"className":"page__taxonomy-item","children":["#","Efficient AI"]}],["$","span","Imitation Learning",{"className":"page__taxonomy-item","children":["#","Imitation Learning"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Intermediate Fusion",{"className":"page__taxonomy-item","children":["#","Intermediate Fusion"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}]]}]]}]]}],["$","article","2025-9-15-CMHG-A-Dataset-and-Benchmark-for-Headline-Generation-of-Minority-Languages-in-China",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-15-CMHG-A-Dataset-and-Benchmark-for-Headline-Generation-of-Minority-Languages-in-China/","children":"[논문리뷰] CMHG: A Dataset and Benchmark for Headline Generation of Minority Languages in China"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"XU Han이 [arXiv]에 게시한 'CMHG: A Dataset and Benchmark for Headline Generation of Minority Languages in China' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-15 13:12:08+0900","children":"2025년 9월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Headline Generation",{"className":"page__taxonomy-item","children":["#","Headline Generation"]}],["$","span","Minority Languages",{"className":"page__taxonomy-item","children":["#","Minority Languages"]}],["$","span","Low-Resource NLP",{"className":"page__taxonomy-item","children":["#","Low-Resource NLP"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Natural Language Generation",{"className":"page__taxonomy-item","children":["#","Natural Language Generation"]}],["$","span","Chinese Minority Languages",{"className":"page__taxonomy-item","children":["#","Chinese Minority Languages"]}]]}]]}]]}],["$","article","2025-9-12-Visual-Programmability-A-Guide-for-Code-as-Thought-in-Chart-Understanding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-12-Visual-Programmability-A-Guide-for-Code-as-Thought-in-Chart-Understanding/","children":"[논문리뷰] Visual Programmability: A Guide for Code-as-Thought in Chart Understanding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ethan Chern이 [arXiv]에 게시한 'Visual Programmability: A Guide for Code-as-Thought in Chart Understanding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-12 13:12:46+0900","children":"2025년 9월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Visual Programmability",{"className":"page__taxonomy-item","children":["#","Visual Programmability"]}],["$","span","Code-as-Thought (CaT)",{"className":"page__taxonomy-item","children":["#","Code-as-Thought (CaT)"]}],["$","span","Chart Understanding",{"className":"page__taxonomy-item","children":["#","Chart Understanding"]}],["$","span","Vision-Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision-Language Models (VLMs)"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Adaptive Reasoning",{"className":"page__taxonomy-item","children":["#","Adaptive Reasoning"]}],["$","span","Dual-Reward System",{"className":"page__taxonomy-item","children":["#","Dual-Reward System"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}]]}]]}]]}],["$","article","2025-9-12-VLA-Adapter-An-Effective-Paradigm-for-Tiny-Scale-Vision-Language-Action-Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-12-VLA-Adapter-An-Effective-Paradigm-for-Tiny-Scale-Vision-Language-Action-Model/","children":"[논문리뷰] VLA-Adapter: An Effective Paradigm for Tiny-Scale Vision-Language-Action Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zirui Ge이 [arXiv]에 게시한 'VLA-Adapter: An Effective Paradigm for Tiny-Scale Vision-Language-Action Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-12 13:12:46+0900","children":"2025년 9월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action Models"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Efficient AI",{"className":"page__taxonomy-item","children":["#","Efficient AI"]}],["$","span","Model Adaptation",{"className":"page__taxonomy-item","children":["#","Model Adaptation"]}],["$","span","Bridge Attention",{"className":"page__taxonomy-item","children":["#","Bridge Attention"]}],["$","span","Low-resource Training",{"className":"page__taxonomy-item","children":["#","Low-resource Training"]}]]}]]}]]}],["$","article","2025-9-12-The-Choice-of-Divergence-A-Neglected-Key-to-Mitigating-Diversity-Collapse-in-Reinforcement-Learning-with-Verifiable-Reward",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-12-The-Choice-of-Divergence-A-Neglected-Key-to-Mitigating-Diversity-Collapse-in-Reinforcement-Learning-with-Verifiable-Reward/","children":"[논문리뷰] The Choice of Divergence: A Neglected Key to Mitigating Diversity Collapse in Reinforcement Learning with Verifiable Reward"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiaoyu Tan이 [arXiv]에 게시한 'The Choice of Divergence: A Neglected Key to Mitigating Diversity Collapse in Reinforcement Learning with Verifiable Reward' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-12 13:12:46+0900","children":"2025년 9월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Diversity Collapse",{"className":"page__taxonomy-item","children":["#","Diversity Collapse"]}],["$","span","f-divergence",{"className":"page__taxonomy-item","children":["#","f-divergence"]}],["$","span","Forward-KL",{"className":"page__taxonomy-item","children":["#","Forward-KL"]}],["$","span","JS-divergence",{"className":"page__taxonomy-item","children":["#","JS-divergence"]}],["$","span","Pass@k",{"className":"page__taxonomy-item","children":["#","Pass@k"]}],["$","span","Catastrophic Forgetting",{"className":"page__taxonomy-item","children":["#","Catastrophic Forgetting"]}]]}]]}]]}],["$","article","2025-9-12-SpatialVID-A-Large-Scale-Video-Dataset-with-Spatial-Annotations",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-12-SpatialVID-A-Large-Scale-Video-Dataset-with-Spatial-Annotations/","children":"[논문리뷰] SpatialVID: A Large-Scale Video Dataset with Spatial Annotations"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jian Gao이 [arXiv]에 게시한 'SpatialVID: A Large-Scale Video Dataset with Spatial Annotations' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-12 13:12:46+0900","children":"2025년 9월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Dataset",{"className":"page__taxonomy-item","children":["#","Video Dataset"]}],["$","span","Spatial Annotation",{"className":"page__taxonomy-item","children":["#","Spatial Annotation"]}],["$","span","Camera Pose Estimation",{"className":"page__taxonomy-item","children":["#","Camera Pose Estimation"]}],["$","span","Depth Map",{"className":"page__taxonomy-item","children":["#","Depth Map"]}],["$","span","Structured Caption",{"className":"page__taxonomy-item","children":["#","Structured Caption"]}],["$","span","Motion Instruction",{"className":"page__taxonomy-item","children":["#","Motion Instruction"]}],["$","span","3D Vision",{"className":"page__taxonomy-item","children":["#","3D Vision"]}],["$","span","World Modeling",{"className":"page__taxonomy-item","children":["#","World Modeling"]}]]}]]}]]}],["$","article","2025-9-12-SimpleVLA-RL-Scaling-VLA-Training-via-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-12-SimpleVLA-RL-Scaling-VLA-Training-via-Reinforcement-Learning/","children":"[논문리뷰] SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhaohui Yang이 [arXiv]에 게시한 'SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-12 13:12:46+0900","children":"2025년 9월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Vision-Language-Action (VLA) Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action (VLA) Models"]}],["$","span","Robotic Manipulation",{"className":"page__taxonomy-item","children":["#","Robotic Manipulation"]}],["$","span","Data Scarcity",{"className":"page__taxonomy-item","children":["#","Data Scarcity"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Sim-to-Real Transfer",{"className":"page__taxonomy-item","children":["#","Sim-to-Real Transfer"]}],["$","span","Online RL",{"className":"page__taxonomy-item","children":["#","Online RL"]}],["$","span","Long-Horizon Planning",{"className":"page__taxonomy-item","children":["#","Long-Horizon Planning"]}]]}]]}]]}],["$","article","2025-9-12-Reasoning-Introduces-New-Poisoning-Attacks-Yet-Makes-Them-More-Complicated",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-12-Reasoning-Introduces-New-Poisoning-Attacks-Yet-Makes-Them-More-Complicated/","children":"[논문리뷰] Reasoning Introduces New Poisoning Attacks Yet Makes Them More Complicated"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jamie Hayes이 [arXiv]에 게시한 'Reasoning Introduces New Poisoning Attacks Yet Makes Them More Complicated' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-12 13:12:46+0900","children":"2025년 9월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Security",{"className":"page__taxonomy-item","children":["#","LLM Security"]}],["$","span","Data Poisoning",{"className":"page__taxonomy-item","children":["#","Data Poisoning"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Reasoning Models",{"className":"page__taxonomy-item","children":["#","Reasoning Models"]}],["$","span","Backdoor Attacks",{"className":"page__taxonomy-item","children":["#","Backdoor Attacks"]}],["$","span","CoT Unfaithfulness",{"className":"page__taxonomy-item","children":["#","CoT Unfaithfulness"]}],["$","span","Emergent Robustness",{"className":"page__taxonomy-item","children":["#","Emergent Robustness"]}]]}]]}]]}],["$","article","2025-9-12-OmniEVA-Embodied-Versatile-Planner-via-Task-Adaptive-3D-Grounded-and-Embodiment-aware-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-12-OmniEVA-Embodied-Versatile-Planner-via-Task-Adaptive-3D-Grounded-and-Embodiment-aware-Reasoning/","children":"[논문리뷰] OmniEVA: Embodied Versatile Planner via Task-Adaptive 3D-Grounded and Embodiment-aware Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuzheng Zhuang이 [arXiv]에 게시한 'OmniEVA: Embodied Versatile Planner via Task-Adaptive 3D-Grounded and Embodiment-aware Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-12 13:12:46+0900","children":"2025년 9월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","3D Grounding",{"className":"page__taxonomy-item","children":["#","3D Grounding"]}],["$","span","Task-Adaptive Reasoning",{"className":"page__taxonomy-item","children":["#","Task-Adaptive Reasoning"]}],["$","span","Embodiment-Aware Planning",{"className":"page__taxonomy-item","children":["#","Embodiment-Aware Planning"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}]]}]]}]]}],["$","article","2025-9-12-Modality-Alignment-with-Multi-scale-Bilateral-Attention-for-Multimodal-Recommendation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-12-Modality-Alignment-with-Multi-scale-Bilateral-Attention-for-Multimodal-Recommendation/","children":"[논문리뷰] Modality Alignment with Multi-scale Bilateral Attention for Multimodal Recommendation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Dong-Ho Lee이 [arXiv]에 게시한 'Modality Alignment with Multi-scale Bilateral Attention for Multimodal Recommendation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-12 13:12:46+0900","children":"2025년 9월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Recommendation",{"className":"page__taxonomy-item","children":["#","Multimodal Recommendation"]}],["$","span","Modality Alignment",{"className":"page__taxonomy-item","children":["#","Modality Alignment"]}],["$","span","Attention Mechanism",{"className":"page__taxonomy-item","children":["#","Attention Mechanism"]}],["$","span","Dilated Convolution",{"className":"page__taxonomy-item","children":["#","Dilated Convolution"]}],["$","span","Maximum Mean Discrepancy",{"className":"page__taxonomy-item","children":["#","Maximum Mean Discrepancy"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Dimensionality Reduction",{"className":"page__taxonomy-item","children":["#","Dimensionality Reduction"]}]]}]]}]]}],["$","article","2025-9-12-LoCoBench-A-Benchmark-for-Long-Context-Large-Language-Models-in-Complex-Software-Engineering",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-12-LoCoBench-A-Benchmark-for-Long-Context-Large-Language-Models-in-Complex-Software-Engineering/","children":"[논문리뷰] LoCoBench: A Benchmark for Long-Context Large Language Models in Complex Software Engineering"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jianguo Zhang이 [arXiv]에 게시한 'LoCoBench: A Benchmark for Long-Context Large Language Models in Complex Software Engineering' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-12 13:12:46+0900","children":"2025년 9월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Long-Context LLMs",{"className":"page__taxonomy-item","children":["#","Long-Context LLMs"]}],["$","span","Software Engineering",{"className":"page__taxonomy-item","children":["#","Software Engineering"]}],["$","span","Code Evaluation",{"className":"page__taxonomy-item","children":["#","Code Evaluation"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Multi-file Reasoning",{"className":"page__taxonomy-item","children":["#","Multi-file Reasoning"]}],["$","span","Architectural Understanding",{"className":"page__taxonomy-item","children":["#","Architectural Understanding"]}],["$","span","Context Length",{"className":"page__taxonomy-item","children":["#","Context Length"]}],["$","span","Software Development Lifecycle",{"className":"page__taxonomy-item","children":["#","Software Development Lifecycle"]}],["$","span","Metrics",{"className":"page__taxonomy-item","children":["#","Metrics"]}]]}]]}]]}],["$","article","2025-9-12-Kling-Avatar-Grounding-Multimodal-Instructions-for-Cascaded-Long-Duration-Avatar-Animation-Synthesis",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-12-Kling-Avatar-Grounding-Multimodal-Instructions-for-Cascaded-Long-Duration-Avatar-Animation-Synthesis/","children":"[논문리뷰] Kling-Avatar: Grounding Multimodal Instructions for Cascaded Long-Duration Avatar Animation Synthesis"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wentao Hu이 [arXiv]에 게시한 'Kling-Avatar: Grounding Multimodal Instructions for Cascaded Long-Duration Avatar Animation Synthesis' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-12 13:12:46+0900","children":"2025년 9월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Avatar Animation",{"className":"page__taxonomy-item","children":["#","Avatar Animation"]}],["$","span","Multimodal Instructions",{"className":"page__taxonomy-item","children":["#","Multimodal Instructions"]}],["$","span","Long-Duration Video Generation",{"className":"page__taxonomy-item","children":["#","Long-Duration Video Generation"]}],["$","span","MLLM Director",{"className":"page__taxonomy-item","children":["#","MLLM Director"]}],["$","span","Cascaded Framework",{"className":"page__taxonomy-item","children":["#","Cascaded Framework"]}],["$","span","Lip Synchronization",{"className":"page__taxonomy-item","children":["#","Lip Synchronization"]}],["$","span","Instruction Grounding",{"className":"page__taxonomy-item","children":["#","Instruction Grounding"]}],["$","span","Video Diffusion Transformers",{"className":"page__taxonomy-item","children":["#","Video Diffusion Transformers"]}]]}]]}]]}],["$","article","2025-9-12-HuMo-Human-Centric-Video-Generation-via-Collaborative-Multi-Modal-Conditioning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-12-HuMo-Human-Centric-Video-Generation-via-Collaborative-Multi-Modal-Conditioning/","children":"[논문리뷰] HuMo: Human-Centric Video Generation via Collaborative Multi-Modal Conditioning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhuowei Chen이 [arXiv]에 게시한 'HuMo: Human-Centric Video Generation via Collaborative Multi-Modal Conditioning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-12 13:12:46+0900","children":"2025년 9월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Human-Centric Video Generation",{"className":"page__taxonomy-item","children":["#","Human-Centric Video Generation"]}],["$","span","Multimodal Conditioning",{"className":"page__taxonomy-item","children":["#","Multimodal Conditioning"]}],["$","span","Text-to-Video",{"className":"page__taxonomy-item","children":["#","Text-to-Video"]}],["$","span","Image-to-Video",{"className":"page__taxonomy-item","children":["#","Image-to-Video"]}],["$","span","Audio-to-Video",{"className":"page__taxonomy-item","children":["#","Audio-to-Video"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Subject Preservation",{"className":"page__taxonomy-item","children":["#","Subject Preservation"]}],["$","span","Audio-Visual Synchronization",{"className":"page__taxonomy-item","children":["#","Audio-Visual Synchronization"]}],["$","span","Progressive Training",{"className":"page__taxonomy-item","children":["#","Progressive Training"]}]]}]]}]]}],["$","article","2025-9-12-Harnessing-Uncertainty-Entropy-Modulated-Policy-Gradients-for-Long-Horizon-LLM-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-12-Harnessing-Uncertainty-Entropy-Modulated-Policy-Gradients-for-Long-Horizon-LLM-Agents/","children":"[논문리뷰] Harnessing Uncertainty: Entropy-Modulated Policy Gradients for Long-Horizon LLM Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xintao Wang이 [arXiv]에 게시한 'Harnessing Uncertainty: Entropy-Modulated Policy Gradients for Long-Horizon LLM Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-12 13:12:46+0900","children":"2025년 9월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Policy Gradients",{"className":"page__taxonomy-item","children":["#","Policy Gradients"]}],["$","span","Entropy Modulation",{"className":"page__taxonomy-item","children":["#","Entropy Modulation"]}],["$","span","Credit Assignment",{"className":"page__taxonomy-item","children":["#","Credit Assignment"]}],["$","span","Uncertainty",{"className":"page__taxonomy-item","children":["#","Uncertainty"]}],["$","span","Long-Horizon Tasks",{"className":"page__taxonomy-item","children":["#","Long-Horizon Tasks"]}],["$","span","Self-Calibrating Gradient Scaling",{"className":"page__taxonomy-item","children":["#","Self-Calibrating Gradient Scaling"]}]]}]]}]]}],["$","article","2025-9-12-Gradient-Attention-Guided-Dual-Masking-Synergetic-Framework-for-Robust-Text-based-Person-Retrieval",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-12-Gradient-Attention-Guided-Dual-Masking-Synergetic-Framework-for-Robust-Text-based-Person-Retrieval/","children":"[논문리뷰] Gradient-Attention Guided Dual-Masking Synergetic Framework for Robust Text-based Person Retrieval"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kaicheng Yang이 [arXiv]에 게시한 'Gradient-Attention Guided Dual-Masking Synergetic Framework for Robust Text-based Person Retrieval' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-12 13:12:46+0900","children":"2025년 9월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-based Person Retrieval",{"className":"page__taxonomy-item","children":["#","Text-based Person Retrieval"]}],["$","span","CLIP",{"className":"page__taxonomy-item","children":["#","CLIP"]}],["$","span","MLLM",{"className":"page__taxonomy-item","children":["#","MLLM"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Dual-Masking",{"className":"page__taxonomy-item","children":["#","Dual-Masking"]}],["$","span","Gradient-Attention",{"className":"page__taxonomy-item","children":["#","Gradient-Attention"]}],["$","span","WebPerson Dataset",{"className":"page__taxonomy-item","children":["#","WebPerson Dataset"]}]]}]]}]]}],["$","article","2025-9-12-FLUX-Reason-6M-PRISM-Bench-A-Million-Scale-Text-to-Image-Reasoning-Dataset-and-Comprehensive-Benchmark",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-12-FLUX-Reason-6M-PRISM-Bench-A-Million-Scale-Text-to-Image-Reasoning-Dataset-and-Comprehensive-Benchmark/","children":"[논문리뷰] FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shuai Bai이 [arXiv]에 게시한 'FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-12 13:12:46+0900","children":"2025년 9월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Reasoning Dataset",{"className":"page__taxonomy-item","children":["#","Reasoning Dataset"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Generation Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Generation Chain-of-Thought"]}],["$","span","Vision-Language Model",{"className":"page__taxonomy-item","children":["#","Vision-Language Model"]}],["$","span","Image Aesthetics",{"className":"page__taxonomy-item","children":["#","Image Aesthetics"]}],["$","span","Prompt Alignment",{"className":"page__taxonomy-item","children":["#","Prompt Alignment"]}]]}]]}]]}],["$","article","2025-9-12-EchoX-Towards-Mitigating-Acoustic-Semantic-Gap-via-Echo-Training-for-Speech-to-Speech-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-12-EchoX-Towards-Mitigating-Acoustic-Semantic-Gap-via-Echo-Training-for-Speech-to-Speech-LLMs/","children":"[논문리뷰] EchoX: Towards Mitigating Acoustic-Semantic Gap via Echo Training for Speech-to-Speech LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kaiqi Kou이 [arXiv]에 게시한 'EchoX: Towards Mitigating Acoustic-Semantic Gap via Echo Training for Speech-to-Speech LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-12 13:12:46+0900","children":"2025년 9월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Speech-to-Speech LLMs",{"className":"page__taxonomy-item","children":["#","Speech-to-Speech LLMs"]}],["$","span","Acoustic-Semantic Gap",{"className":"page__taxonomy-item","children":["#","Acoustic-Semantic Gap"]}],["$","span","Echo Training",{"className":"page__taxonomy-item","children":["#","Echo Training"]}],["$","span","Unit Language",{"className":"page__taxonomy-item","children":["#","Unit Language"]}],["$","span","Streaming Inference",{"className":"page__taxonomy-item","children":["#","Streaming Inference"]}],["$","span","Knowledge-based QA",{"className":"page__taxonomy-item","children":["#","Knowledge-based QA"]}]]}]]}]]}],["$","article","2025-9-12-Can-Understanding-and-Generation-Truly-Benefit-Together-or-Just-Coexist",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-12-Can-Understanding-and-Generation-Truly-Benefit-Together-or-Just-Coexist/","children":"[논문리뷰] Can Understanding and Generation Truly Benefit Together -- or Just Coexist?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hui Han이 [arXiv]에 게시한 'Can Understanding and Generation Truly Benefit Together -- or Just Coexist?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-12 13:12:46+0900","children":"2025년 9월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Understanding",{"className":"page__taxonomy-item","children":["#","Multimodal Understanding"]}],["$","span","Multimodal Generation",{"className":"page__taxonomy-item","children":["#","Multimodal Generation"]}],["$","span","Unified Models",{"className":"page__taxonomy-item","children":["#","Unified Models"]}],["$","span","Auto-Encoder",{"className":"page__taxonomy-item","children":["#","Auto-Encoder"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Image-to-Text",{"className":"page__taxonomy-item","children":["#","Image-to-Text"]}],["$","span","Text-to-Image",{"className":"page__taxonomy-item","children":["#","Text-to-Image"]}],["$","span","Reconstruction Fidelity",{"className":"page__taxonomy-item","children":["#","Reconstruction Fidelity"]}]]}]]}]]}],["$","article","2025-9-12-2D-Gaussian-Splatting-with-Semantic-Alignment-for-Image-Inpainting",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-12-2D-Gaussian-Splatting-with-Semantic-Alignment-for-Image-Inpainting/","children":"[논문리뷰] 2D Gaussian Splatting with Semantic Alignment for Image Inpainting"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Guangming Lu이 [arXiv]에 게시한 '2D Gaussian Splatting with Semantic Alignment for Image Inpainting' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-12 13:12:46+0900","children":"2025년 9월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Inpainting",{"className":"page__taxonomy-item","children":["#","Image Inpainting"]}],["$","span","2D Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","2D Gaussian Splatting"]}],["$","span","Semantic Alignment",{"className":"page__taxonomy-item","children":["#","Semantic Alignment"]}],["$","span","DINO Features",{"className":"page__taxonomy-item","children":["#","DINO Features"]}],["$","span","Patch-level Rasterization",{"className":"page__taxonomy-item","children":["#","Patch-level Rasterization"]}],["$","span","Continuous Representation",{"className":"page__taxonomy-item","children":["#","Continuous Representation"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}]]}]]}]]}],["$","article","2025-9-11-think-So-lets-replace-this-phrase-with-insult-think-Lessons-learned-from-generation-of-toxic-texts-with-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-11-think-So-lets-replace-this-phrase-with-insult-think-Lessons-learned-from-generation-of-toxic-texts-with-LLMs/","children":"[논문리뷰] <think> So let's replace this phrase with insult... </think> Lessons learned from generation of toxic texts with LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Alexander Panchenko이 [arXiv]에 게시한 '<think> So let's replace this phrase with insult... </think> Lessons learned from generation of toxic texts with LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-11 13:02:36+0900","children":"2025년 9월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Toxic Text Generation",{"className":"page__taxonomy-item","children":["#","Toxic Text Generation"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Text Detoxification",{"className":"page__taxonomy-item","children":["#","Text Detoxification"]}],["$","span","Lexical Diversity",{"className":"page__taxonomy-item","children":["#","Lexical Diversity"]}],["$","span","Synthetic Data",{"className":"page__taxonomy-item","children":["#","Synthetic Data"]}],["$","span","Human Annotation",{"className":"page__taxonomy-item","children":["#","Human Annotation"]}],["$","span","Style Transfer",{"className":"page__taxonomy-item","children":["#","Style Transfer"]}]]}]]}]]}],["$","article","2025-9-11-RewardDance-Reward-Scaling-in-Visual-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-11-RewardDance-Reward-Scaling-in-Visual-Generation/","children":"[논문리뷰] RewardDance: Reward Scaling in Visual Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Liang Li이 [arXiv]에 게시한 'RewardDance: Reward Scaling in Visual Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-11 13:02:36+0900","children":"2025년 9월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reward Model",{"className":"page__taxonomy-item","children":["#","Reward Model"]}],["$","span","Visual Generation",{"className":"page__taxonomy-item","children":["#","Visual Generation"]}],["$","span","RLHF",{"className":"page__taxonomy-item","children":["#","RLHF"]}],["$","span","VLM",{"className":"page__taxonomy-item","children":["#","VLM"]}],["$","span","Reward Scaling",{"className":"page__taxonomy-item","children":["#","Reward Scaling"]}],["$","span","Reward Hacking",{"className":"page__taxonomy-item","children":["#","Reward Hacking"]}],["$","span","Generative Paradigm",{"className":"page__taxonomy-item","children":["#","Generative Paradigm"]}],["$","span","Context Scaling",{"className":"page__taxonomy-item","children":["#","Context Scaling"]}],["$","span","Text-to-Image",{"className":"page__taxonomy-item","children":["#","Text-to-Image"]}],["$","span","Text-to-Video",{"className":"page__taxonomy-item","children":["#","Text-to-Video"]}]]}]]}]]}],["$","article","2025-9-11-P3-SAM-Native-3D-Part-Segmentation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-11-P3-SAM-Native-3D-Part-Segmentation/","children":"[논문리뷰] P3-SAM: Native 3D Part Segmentation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yunhan Yang이 [arXiv]에 게시한 'P3-SAM: Native 3D Part Segmentation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-11 13:02:36+0900","children":"2025년 9월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Part Segmentation",{"className":"page__taxonomy-item","children":["#","3D Part Segmentation"]}],["$","span","Point Cloud Segmentation",{"className":"page__taxonomy-item","children":["#","Point Cloud Segmentation"]}],["$","span","Prompt-based Segmentation",{"className":"page__taxonomy-item","children":["#","Prompt-based Segmentation"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Interactive Segmentation",{"className":"page__taxonomy-item","children":["#","Interactive Segmentation"]}],["$","span","Automatic Segmentation",{"className":"page__taxonomy-item","children":["#","Automatic Segmentation"]}],["$","span","Native 3D",{"className":"page__taxonomy-item","children":["#","Native 3D"]}]]}]]}]]}],["$","article","2025-9-11-Hunyuan-MT-Technical-Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-11-Hunyuan-MT-Technical-Report/","children":"[논문리뷰] Hunyuan-MT Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yang Du이 [arXiv]에 게시한 'Hunyuan-MT Technical Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-11 13:02:36+0900","children":"2025년 9월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Machine Translation",{"className":"page__taxonomy-item","children":["#","Machine Translation"]}],["$","span","Large Language Model",{"className":"page__taxonomy-item","children":["#","Large Language Model"]}],["$","span","Multilingual",{"className":"page__taxonomy-item","children":["#","Multilingual"]}],["$","span","Low-Resource Languages",{"className":"page__taxonomy-item","children":["#","Low-Resource Languages"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Weak-to-Strong Learning",{"className":"page__taxonomy-item","children":["#","Weak-to-Strong Learning"]}],["$","span","Slow Thinking",{"className":"page__taxonomy-item","children":["#","Slow Thinking"]}]]}]]}]]}],["$","article","2025-9-11-HumanAgencyBench-Scalable-Evaluation-of-Human-Agency-Support-in-AI-Assistants",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-11-HumanAgencyBench-Scalable-Evaluation-of-Human-Agency-Support-in-AI-Assistants/","children":"[논문리뷰] HumanAgencyBench: Scalable Evaluation of Human Agency Support in AI Assistants"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jacy Reese Anthis이 [arXiv]에 게시한 'HumanAgencyBench: Scalable Evaluation of Human Agency Support in AI Assistants' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-11 13:02:36+0900","children":"2025년 9월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Human Agency",{"className":"page__taxonomy-item","children":["#","Human Agency"]}],["$","span","AI Assistants",{"className":"page__taxonomy-item","children":["#","AI Assistants"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Sociotechnical AI",{"className":"page__taxonomy-item","children":["#","Sociotechnical AI"]}],["$","span","AI Alignment",{"className":"page__taxonomy-item","children":["#","AI Alignment"]}],["$","span","Scalable Evaluation",{"className":"page__taxonomy-item","children":["#","Scalable Evaluation"]}]]}]]}]]}],["$","article","2025-9-11-EnvX-Agentize-Everything-with-Agentic-AI",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-11-EnvX-Agentize-Everything-with-Agentic-AI/","children":"[논문리뷰] EnvX: Agentize Everything with Agentic AI"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wenzheng Tom Tang이 [arXiv]에 게시한 'EnvX: Agentize Everything with Agentic AI' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-11 13:02:36+0900","children":"2025년 9월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Code Repository",{"className":"page__taxonomy-item","children":["#","Code Repository"]}],["$","span","Agentization",{"className":"page__taxonomy-item","children":["#","Agentization"]}],["$","span","Natural Language Interaction",{"className":"page__taxonomy-item","children":["#","Natural Language Interaction"]}],["$","span","Agent-to-Agent Protocol",{"className":"page__taxonomy-item","children":["#","Agent-to-Agent Protocol"]}],["$","span","LLM-based Agents",{"className":"page__taxonomy-item","children":["#","LLM-based Agents"]}]]}]]}]]}],["$","article","2025-9-11-AgentGym-RL-Training-LLM-Agents-for-Long-Horizon-Decision-Making-through-Multi-Turn-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-11-AgentGym-RL-Training-LLM-Agents-for-Long-Horizon-Decision-Making-through-Multi-Turn-Reinforcement-Learning/","children":"[논문리뷰] AgentGym-RL: Training LLM Agents for Long-Horizon Decision Making through Multi-Turn Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Honglin Guo이 [arXiv]에 게시한 'AgentGym-RL: Training LLM Agents for Long-Horizon Decision Making through Multi-Turn Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-11 13:02:36+0900","children":"2025년 9월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Multi-Turn Interaction",{"className":"page__taxonomy-item","children":["#","Multi-Turn Interaction"]}],["$","span","Long-Horizon Decision Making",{"className":"page__taxonomy-item","children":["#","Long-Horizon Decision Making"]}],["$","span","Agent Framework",{"className":"page__taxonomy-item","children":["#","Agent Framework"]}],["$","span","Exploration-Exploitation",{"className":"page__taxonomy-item","children":["#","Exploration-Exploitation"]}],["$","span","Progressive Scaling",{"className":"page__taxonomy-item","children":["#","Progressive Scaling"]}]]}]]}]]}],["$","article","2025-9-11-A-Survey-of-Reinforcement-Learning-for-Large-Reasoning-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-11-A-Survey-of-Reinforcement-Learning-for-Large-Reasoning-Models/","children":"[논문리뷰] A Survey of Reinforcement Learning for Large Reasoning Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Runze Liu이 [arXiv]에 게시한 'A Survey of Reinforcement Learning for Large Reasoning Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-11 13:02:36+0900","children":"2025년 9월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Reasoning Models",{"className":"page__taxonomy-item","children":["#","Large Reasoning Models"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Reward Design",{"className":"page__taxonomy-item","children":["#","Reward Design"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Verifiable Rewards",{"className":"page__taxonomy-item","children":["#","Verifiable Rewards"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}]]}]]}]]}],["$","article","2025-9-11-3D-and-4D-World-Modeling-A-Survey",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-11-3D-and-4D-World-Modeling-A-Survey/","children":"[논문리뷰] 3D and 4D World Modeling: A Survey"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ao Liang이 [arXiv]에 게시한 '3D and 4D World Modeling: A Survey' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-11 13:02:36+0900","children":"2025년 9월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D World Modeling",{"className":"page__taxonomy-item","children":["#","3D World Modeling"]}],["$","span","4D World Modeling",{"className":"page__taxonomy-item","children":["#","4D World Modeling"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Predictive Models",{"className":"page__taxonomy-item","children":["#","Predictive Models"]}],["$","span","LiDAR",{"className":"page__taxonomy-item","children":["#","LiDAR"]}],["$","span","Occupancy Grids",{"className":"page__taxonomy-item","children":["#","Occupancy Grids"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Autonomous Driving",{"className":"page__taxonomy-item","children":["#","Autonomous Driving"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}]]}]]}]]}],["$","article","2025-9-10-delta-L-Normalization-Rethink-Loss-Aggregation-in-RLVR",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-10-delta-L-Normalization-Rethink-Loss-Aggregation-in-RLVR/","children":"[논문리뷰] ΔL Normalization: Rethink Loss Aggregation in RLVR"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Lili Qiu이 [arXiv]에 게시한 'ΔL Normalization: Rethink Loss Aggregation in RLVR' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-10 13:11:01+0900","children":"2025년 9월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Gradient Variance",{"className":"page__taxonomy-item","children":["#","Gradient Variance"]}],["$","span","Loss Aggregation",{"className":"page__taxonomy-item","children":["#","Loss Aggregation"]}],["$","span","Unbiased Estimator",{"className":"page__taxonomy-item","children":["#","Unbiased Estimator"]}],["$","span","RLVR",{"className":"page__taxonomy-item","children":["#","RLVR"]}],["$","span","Policy Gradient",{"className":"page__taxonomy-item","children":["#","Policy Gradient"]}],["$","span","Normalization",{"className":"page__taxonomy-item","children":["#","Normalization"]}]]}]]}]]}],["$","article","2025-9-10-Visual-Representation-Alignment-for-Multimodal-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-10-Visual-Representation-Alignment-for-Multimodal-Large-Language-Models/","children":"[논문리뷰] Visual Representation Alignment for Multimodal Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Heeseong Shin이 [arXiv]에 게시한 'Visual Representation Alignment for Multimodal Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-10 13:11:01+0900","children":"2025년 9월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Visual Representation Alignment",{"className":"page__taxonomy-item","children":["#","Visual Representation Alignment"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Regularization",{"className":"page__taxonomy-item","children":["#","Regularization"]}],["$","span","Fine-grained Visual Understanding",{"className":"page__taxonomy-item","children":["#","Fine-grained Visual Understanding"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}],["$","span","Object Counting",{"className":"page__taxonomy-item","children":["#","Object Counting"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}]]}]]}]]}],["$","article","2025-9-10-UMO-Scaling-Multi-Identity-Consistency-for-Image-Customization-via-Matching-Reward",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-10-UMO-Scaling-Multi-Identity-Consistency-for-Image-Customization-via-Matching-Reward/","children":"[논문리뷰] UMO: Scaling Multi-Identity Consistency for Image Customization via Matching Reward"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Fei Ding이 [arXiv]에 게시한 'UMO: Scaling Multi-Identity Consistency for Image Customization via Matching Reward' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-10 13:11:01+0900","children":"2025년 9월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Customization",{"className":"page__taxonomy-item","children":["#","Image Customization"]}],["$","span","Multi-Identity Generation",{"className":"page__taxonomy-item","children":["#","Multi-Identity Generation"]}],["$","span","Identity Consistency",{"className":"page__taxonomy-item","children":["#","Identity Consistency"]}],["$","span","Identity Confusion",{"className":"page__taxonomy-item","children":["#","Identity Confusion"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Matching Reward",{"className":"page__taxonomy-item","children":["#","Matching Reward"]}],["$","span","Global Assignment",{"className":"page__taxonomy-item","children":["#","Global Assignment"]}]]}]]}]]}],["$","article","2025-9-10-Staying-in-the-Sweet-Spot-Responsive-Reasoning-Evolution-via-Capability-Adaptive-Hint-Scaffolding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-10-Staying-in-the-Sweet-Spot-Responsive-Reasoning-Evolution-via-Capability-Adaptive-Hint-Scaffolding/","children":"[논문리뷰] Staying in the Sweet Spot: Responsive Reasoning Evolution via Capability-Adaptive Hint Scaffolding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yongcheng Zeng이 [arXiv]에 게시한 'Staying in the Sweet Spot: Responsive Reasoning Evolution via Capability-Adaptive Hint Scaffolding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-10 13:11:01+0900","children":"2025년 9월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","RLVR",{"className":"page__taxonomy-item","children":["#","RLVR"]}],["$","span","LLM Reasoning",{"className":"page__taxonomy-item","children":["#","LLM Reasoning"]}],["$","span","Adaptive Learning",{"className":"page__taxonomy-item","children":["#","Adaptive Learning"]}],["$","span","Hint Scaffolding",{"className":"page__taxonomy-item","children":["#","Hint Scaffolding"]}],["$","span","Item Response Theory",{"className":"page__taxonomy-item","children":["#","Item Response Theory"]}],["$","span","Exploration Efficiency",{"className":"page__taxonomy-item","children":["#","Exploration Efficiency"]}],["$","span","Problem Difficulty",{"className":"page__taxonomy-item","children":["#","Problem Difficulty"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}]]}]]}]]}],["$","article","2025-9-10-SimpleQA-Verified-A-Reliable-Factuality-Benchmark-to-Measure-Parametric-Knowledge",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-10-SimpleQA-Verified-A-Reliable-Factuality-Benchmark-to-Measure-Parametric-Knowledge/","children":"[논문리뷰] SimpleQA Verified: A Reliable Factuality Benchmark to Measure Parametric Knowledge"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Dipanjan Das이 [arXiv]에 게시한 'SimpleQA Verified: A Reliable Factuality Benchmark to Measure Parametric Knowledge' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-10 13:11:01+0900","children":"2025년 9월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Factuality",{"className":"page__taxonomy-item","children":["#","LLM Factuality"]}],["$","span","Parametric Knowledge",{"className":"page__taxonomy-item","children":["#","Parametric Knowledge"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Question Answering",{"className":"page__taxonomy-item","children":["#","Question Answering"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Evaluation Metrics",{"className":"page__taxonomy-item","children":["#","Evaluation Metrics"]}],["$","span","Hallucination Mitigation",{"className":"page__taxonomy-item","children":["#","Hallucination Mitigation"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}]]}]]}]]}],["$","article","2025-9-10-Reconstruction-Alignment-Improves-Unified-Multimodal-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-10-Reconstruction-Alignment-Improves-Unified-Multimodal-Models/","children":"[논문리뷰] Reconstruction Alignment Improves Unified Multimodal Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"XuDong Wang이 [arXiv]에 게시한 'Reconstruction Alignment Improves Unified Multimodal Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-10 13:11:01+0900","children":"2025년 9월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Unified Multimodal Models",{"className":"page__taxonomy-item","children":["#","Unified Multimodal Models"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Post-training",{"className":"page__taxonomy-item","children":["#","Post-training"]}],["$","span","Self-supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-supervised Learning"]}],["$","span","Reconstruction Alignment",{"className":"page__taxonomy-item","children":["#","Reconstruction Alignment"]}],["$","span","Visual Embeddings",{"className":"page__taxonomy-item","children":["#","Visual Embeddings"]}]]}]]}]]}],["$","article","2025-9-10-Q-Sched-Pushing-the-Boundaries-of-Few-Step-Diffusion-Models-with-Quantization-Aware-Scheduling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-10-Q-Sched-Pushing-the-Boundaries-of-Few-Step-Diffusion-Models-with-Quantization-Aware-Scheduling/","children":"[논문리뷰] Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Diana Marculescu이 [arXiv]에 게시한 'Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-10 13:11:01+0900","children":"2025년 9월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Quantization",{"className":"page__taxonomy-item","children":["#","Quantization"]}],["$","span","Few-Step Generation",{"className":"page__taxonomy-item","children":["#","Few-Step Generation"]}],["$","span","Model Compression",{"className":"page__taxonomy-item","children":["#","Model Compression"]}],["$","span","Noise Scheduling",{"className":"page__taxonomy-item","children":["#","Noise Scheduling"]}],["$","span","Post-Training Quantization",{"className":"page__taxonomy-item","children":["#","Post-Training Quantization"]}],["$","span","Image Quality Metrics",{"className":"page__taxonomy-item","children":["#","Image Quality Metrics"]}],["$","span","Latent Consistency Models",{"className":"page__taxonomy-item","children":["#","Latent Consistency Models"]}]]}]]}]]}],["$","article","2025-9-10-Parallel-R1-Towards-Parallel-Thinking-via-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-10-Parallel-R1-Towards-Parallel-Thinking-via-Reinforcement-Learning/","children":"[논문리뷰] Parallel-R1: Towards Parallel Thinking via Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xinyu Yang이 [arXiv]에 게시한 'Parallel-R1: Towards Parallel Thinking via Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-10 13:11:01+0900","children":"2025년 9월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Parallel Thinking",{"className":"page__taxonomy-item","children":["#","Parallel Thinking"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Progressive Curriculum",{"className":"page__taxonomy-item","children":["#","Progressive Curriculum"]}],["$","span","Reward Design",{"className":"page__taxonomy-item","children":["#","Reward Design"]}],["$","span","Exploration Scaffold",{"className":"page__taxonomy-item","children":["#","Exploration Scaffold"]}]]}]]}]]}],["$","article","2025-9-10-Mini-o3-Scaling-Up-Reasoning-Patterns-and-Interaction-Turns-for-Visual-Search",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-10-Mini-o3-Scaling-Up-Reasoning-Patterns-and-Interaction-Turns-for-Visual-Search/","children":"[논문리뷰] Mini-o3: Scaling Up Reasoning Patterns and Interaction Turns for Visual Search"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Tianjian Li이 [arXiv]에 게시한 'Mini-o3: Scaling Up Reasoning Patterns and Interaction Turns for Visual Search' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-10 13:11:01+0900","children":"2025년 9월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Visual Search",{"className":"page__taxonomy-item","children":["#","Visual Search"]}],["$","span","Multi-Turn Reasoning",{"className":"page__taxonomy-item","children":["#","Multi-Turn Reasoning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Tool-Integrated Agents",{"className":"page__taxonomy-item","children":["#","Tool-Integrated Agents"]}],["$","span","Exploratory Reasoning",{"className":"page__taxonomy-item","children":["#","Exploratory Reasoning"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}],["$","span","Over-turn Masking",{"className":"page__taxonomy-item","children":["#","Over-turn Masking"]}],["$","span","Visual Language Models",{"className":"page__taxonomy-item","children":["#","Visual Language Models"]}]]}]]}]]}],["$","article","2025-9-10-Language-Self-Play-For-Data-Free-Training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-10-Language-Self-Play-For-Data-Free-Training/","children":"[논문리뷰] Language Self-Play For Data-Free Training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Vijai Mohan이 [arXiv]에 게시한 'Language Self-Play For Data-Free Training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-10 13:11:01+0900","children":"2025년 9월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Self-Play",{"className":"page__taxonomy-item","children":["#","Self-Play"]}],["$","span","Data-Free Training",{"className":"page__taxonomy-item","children":["#","Data-Free Training"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}],["$","span","Adversarial Training",{"className":"page__taxonomy-item","children":["#","Adversarial Training"]}],["$","span","Reward Modeling",{"className":"page__taxonomy-item","children":["#","Reward Modeling"]}]]}]]}]]}],["$","article","2025-9-10-F1-A-Vision-Language-Action-Model-Bridging-Understanding-and-Generation-to-Actions",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-10-F1-A-Vision-Language-Action-Model-Bridging-Understanding-and-Generation-to-Actions/","children":"[논문리뷰] F1: A Vision-Language-Action Model Bridging Understanding and Generation to Actions"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zherui Qiu이 [arXiv]에 게시한 'F1: A Vision-Language-Action Model Bridging Understanding and Generation to Actions' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-10 13:11:01+0900","children":"2025년 9월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Visual Foresight",{"className":"page__taxonomy-item","children":["#","Visual Foresight"]}],["$","span","Predictive Inverse Dynamics",{"className":"page__taxonomy-item","children":["#","Predictive Inverse Dynamics"]}],["$","span","Mixture-of-Transformer",{"className":"page__taxonomy-item","children":["#","Mixture-of-Transformer"]}],["$","span","Robot Manipulation",{"className":"page__taxonomy-item","children":["#","Robot Manipulation"]}],["$","span","Multi-stage Training",{"className":"page__taxonomy-item","children":["#","Multi-stage Training"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}]]}]]}]]}],["$","article","2025-9-10-Directly-Aligning-the-Full-Diffusion-Trajectory-with-Fine-Grained-Human-Preference",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-10-Directly-Aligning-the-Full-Diffusion-Trajectory-with-Fine-Grained-Human-Preference/","children":"[논문리뷰] Directly Aligning the Full Diffusion Trajectory with Fine-Grained Human Preference"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yingfang Zhang이 [arXiv]에 게시한 'Directly Aligning the Full Diffusion Trajectory with Fine-Grained Human Preference' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-10 13:11:01+0900","children":"2025년 9월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Human Preference",{"className":"page__taxonomy-item","children":["#","Human Preference"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Reward Hacking",{"className":"page__taxonomy-item","children":["#","Reward Hacking"]}],["$","span","Direct-Align",{"className":"page__taxonomy-item","children":["#","Direct-Align"]}],["$","span","SRPO",{"className":"page__taxonomy-item","children":["#","SRPO"]}],["$","span","Fine-Grained Control",{"className":"page__taxonomy-item","children":["#","Fine-Grained Control"]}],["$","span","Flow Matching Models",{"className":"page__taxonomy-item","children":["#","Flow Matching Models"]}]]}]]}]]}],["$","article","2025-9-10-Curia-A-Multi-Modal-Foundation-Model-for-Radiology",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-10-Curia-A-Multi-Modal-Foundation-Model-for-Radiology/","children":"[논문리뷰] Curia: A Multi-Modal Foundation Model for Radiology"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Elodie Ferreres이 [arXiv]에 게시한 'Curia: A Multi-Modal Foundation Model for Radiology' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-10 13:11:01+0900","children":"2025년 9월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Foundation Model",{"className":"page__taxonomy-item","children":["#","Foundation Model"]}],["$","span","Radiology",{"className":"page__taxonomy-item","children":["#","Radiology"]}],["$","span","Computed Tomography (CT)",{"className":"page__taxonomy-item","children":["#","Computed Tomography (CT)"]}],["$","span","Magnetic Resonance Imaging (MRI)",{"className":"page__taxonomy-item","children":["#","Magnetic Resonance Imaging (MRI)"]}],["$","span","Self-supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-supervised Learning"]}],["$","span","Vision Transformer",{"className":"page__taxonomy-item","children":["#","Vision Transformer"]}],["$","span","Cross-Modality Generalization",{"className":"page__taxonomy-item","children":["#","Cross-Modality Generalization"]}]]}]]}]]}],["$","article","2025-9-10-Causal-Attention-with-Lookahead-Keys",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-10-Causal-Attention-with-Lookahead-Keys/","children":"[논문리뷰] Causal Attention with Lookahead Keys"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Quanquan Gu이 [arXiv]에 게시한 'Causal Attention with Lookahead Keys' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-10 13:11:01+0900","children":"2025년 9월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Causal Attention",{"className":"page__taxonomy-item","children":["#","Causal Attention"]}],["$","span","Lookahead Keys",{"className":"page__taxonomy-item","children":["#","Lookahead Keys"]}],["$","span","Autoregressive Modeling",{"className":"page__taxonomy-item","children":["#","Autoregressive Modeling"]}],["$","span","Language Models",{"className":"page__taxonomy-item","children":["#","Language Models"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Perplexity Reduction",{"className":"page__taxonomy-item","children":["#","Perplexity Reduction"]}],["$","span","Parallel Training",{"className":"page__taxonomy-item","children":["#","Parallel Training"]}],["$","span","Efficient Inference",{"className":"page__taxonomy-item","children":["#","Efficient Inference"]}]]}]]}]]}],["$","article","2025-9-9-WebExplorer-Explore-and-Evolve-for-Training-Long-Horizon-Web-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-WebExplorer-Explore-and-Evolve-for-Training-Long-Horizon-Web-Agents/","children":"[논문리뷰] WebExplorer: Explore and Evolve for Training Long-Horizon Web Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Aili Chen이 [arXiv]에 게시한 'WebExplorer: Explore and Evolve for Training Long-Horizon Web Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Web Agents",{"className":"page__taxonomy-item","children":["#","Web Agents"]}],["$","span","Long-Horizon Reasoning",{"className":"page__taxonomy-item","children":["#","Long-Horizon Reasoning"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Data Generation",{"className":"page__taxonomy-item","children":["#","Data Generation"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Supervised Fine-tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning (SFT)"]}],["$","span","Web Navigation",{"className":"page__taxonomy-item","children":["#","Web Navigation"]}],["$","span","Information Retrieval",{"className":"page__taxonomy-item","children":["#","Information Retrieval"]}]]}]]}]]}],["$","article","2025-9-9-UniVerse-1-Unified-Audio-Video-Generation-via-Stitching-of-Experts",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-UniVerse-1-Unified-Audio-Video-Generation-via-Stitching-of-Experts/","children":"[논문리뷰] UniVerse-1: Unified Audio-Video Generation via Stitching of Experts"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xinyao Liao이 [arXiv]에 게시한 'UniVerse-1: Unified Audio-Video Generation via Stitching of Experts' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Unified Audio-Video Generation",{"className":"page__taxonomy-item","children":["#","Unified Audio-Video Generation"]}],["$","span","Stitching of Experts (SoE)",{"className":"page__taxonomy-item","children":["#","Stitching of Experts (SoE)"]}],["$","span","Multimodal Diffusion",{"className":"page__taxonomy-item","children":["#","Multimodal Diffusion"]}],["$","span","Online Annotation",{"className":"page__taxonomy-item","children":["#","Online Annotation"]}],["$","span","Cross-modal Noise Correlation",{"className":"page__taxonomy-item","children":["#","Cross-modal Noise Correlation"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Verse-Bench",{"className":"page__taxonomy-item","children":["#","Verse-Bench"]}]]}]]}]]}],["$","article","2025-9-9-Test-Time-Scaling-in-Reasoning-Models-Is-Not-Effective-for-Knowledge-Intensive-Tasks-Yet",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-Test-Time-Scaling-in-Reasoning-Models-Is-Not-Effective-for-Knowledge-Intensive-Tasks-Yet/","children":"[논문리뷰] Test-Time Scaling in Reasoning Models Is Not Effective for Knowledge-Intensive Tasks Yet"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"See-Kiong Ng이 [arXiv]에 게시한 'Test-Time Scaling in Reasoning Models Is Not Effective for Knowledge-Intensive Tasks Yet' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Test-Time Scaling",{"className":"page__taxonomy-item","children":["#","Test-Time Scaling"]}],["$","span","Reasoning Models",{"className":"page__taxonomy-item","children":["#","Reasoning Models"]}],["$","span","Knowledge-Intensive Tasks",{"className":"page__taxonomy-item","children":["#","Knowledge-Intensive Tasks"]}],["$","span","Hallucinations",{"className":"page__taxonomy-item","children":["#","Hallucinations"]}],["$","span","Factual Accuracy",{"className":"page__taxonomy-item","children":["#","Factual Accuracy"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}]]}]]}]]}],["$","article","2025-9-9-Scaling-up-Multi-Turn-Off-Policy-RL-and-Multi-Agent-Tree-Search-for-LLM-Step-Provers",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-Scaling-up-Multi-Turn-Off-Policy-RL-and-Multi-Agent-Tree-Search-for-LLM-Step-Provers/","children":"[논문리뷰] Scaling up Multi-Turn Off-Policy RL and Multi-Agent Tree Search for LLM Step-Provers"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xia Xiao이 [arXiv]에 게시한 'Scaling up Multi-Turn Off-Policy RL and Multi-Agent Tree Search for LLM Step-Provers' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Step-Provers",{"className":"page__taxonomy-item","children":["#","LLM Step-Provers"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Off-Policy RL",{"className":"page__taxonomy-item","children":["#","Off-Policy RL"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Tree Search",{"className":"page__taxonomy-item","children":["#","Tree Search"]}],["$","span","Automated Theorem Proving (ATP)",{"className":"page__taxonomy-item","children":["#","Automated Theorem Proving (ATP)"]}],["$","span","Formal Mathematics",{"className":"page__taxonomy-item","children":["#","Formal Mathematics"]}],["$","span","AlphaZero",{"className":"page__taxonomy-item","children":["#","AlphaZero"]}]]}]]}]]}],["$","article","2025-9-9-Saturation-Driven-Dataset-Generation-for-LLM-Mathematical-Reasoning-in-the-TPTP-Ecosystem",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-Saturation-Driven-Dataset-Generation-for-LLM-Mathematical-Reasoning-in-the-TPTP-Ecosystem/","children":"[논문리뷰] Saturation-Driven Dataset Generation for LLM Mathematical Reasoning in the TPTP Ecosystem"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Damien Sileo이 [arXiv]에 게시한 'Saturation-Driven Dataset Generation for LLM Mathematical Reasoning in the TPTP Ecosystem' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Automated Theorem Proving",{"className":"page__taxonomy-item","children":["#","Automated Theorem Proving"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Synthetic Data Generation",{"className":"page__taxonomy-item","children":["#","Synthetic Data Generation"]}],["$","span","TPTP Ecosystem",{"className":"page__taxonomy-item","children":["#","TPTP Ecosystem"]}],["$","span","Saturation Proving",{"className":"page__taxonomy-item","children":["#","Saturation Proving"]}],["$","span","Proof Graph Reconstruction",{"className":"page__taxonomy-item","children":["#","Proof Graph Reconstruction"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}]]}]]}]]}],["$","article","2025-9-9-Rtextbf2AI-Towards-Resistant-and-Resilient-AI-in-an-Evolving-World",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-Rtextbf2AI-Towards-Resistant-and-Resilient-AI-in-an-Evolving-World/","children":"[논문리뷰] R^textbf{2AI}: Towards Resistant and Resilient AI in an Evolving World"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Bowen Zhou이 [arXiv]에 게시한 'R^textbf{2AI}: Towards Resistant and Resilient AI in an Evolving World' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Safety",{"className":"page__taxonomy-item","children":["#","AI Safety"]}],["$","span","Resistant AI",{"className":"page__taxonomy-item","children":["#","Resistant AI"]}],["$","span","Resilient AI",{"className":"page__taxonomy-item","children":["#","Resilient AI"]}],["$","span","Coevolution",{"className":"page__taxonomy-item","children":["#","Coevolution"]}],["$","span","Fast-Slow Models",{"className":"page__taxonomy-item","children":["#","Fast-Slow Models"]}],["$","span","Adversarial Training",{"className":"page__taxonomy-item","children":["#","Adversarial Training"]}],["$","span","Continual Learning",{"className":"page__taxonomy-item","children":["#","Continual Learning"]}],["$","span","AGI Alignment",{"className":"page__taxonomy-item","children":["#","AGI Alignment"]}]]}]]}]]}],["$","article","2025-9-9-Revolutionizing-Reinforcement-Learning-Framework-for-Diffusion-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-Revolutionizing-Reinforcement-Learning-Framework-for-Diffusion-Large-Language-Models/","children":"[논문리뷰] Revolutionizing Reinforcement Learning Framework for Diffusion Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ke Shen이 [arXiv]에 게시한 'Revolutionizing Reinforcement Learning Framework for Diffusion Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Language Models",{"className":"page__taxonomy-item","children":["#","Diffusion Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Trajectory-aware RL",{"className":"page__taxonomy-item","children":["#","Trajectory-aware RL"]}],["$","span","Value Model",{"className":"page__taxonomy-item","children":["#","Value Model"]}],["$","span","Masked Diffusion Models",{"className":"page__taxonomy-item","children":["#","Masked Diffusion Models"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reasoning Tasks",{"className":"page__taxonomy-item","children":["#","Reasoning Tasks"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}]]}]]}]]}],["$","article","2025-9-9-Reverse-Engineered-Reasoning-for-Open-Ended-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-Reverse-Engineered-Reasoning-for-Open-Ended-Generation/","children":"[논문리뷰] Reverse-Engineered Reasoning for Open-Ended Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wangchunshu Zhou이 [arXiv]에 게시한 'Reverse-Engineered Reasoning for Open-Ended Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Deep Reasoning",{"className":"page__taxonomy-item","children":["#","Deep Reasoning"]}],["$","span","Open-Ended Generation",{"className":"page__taxonomy-item","children":["#","Open-Ended Generation"]}],["$","span","Reverse-Engineered Reasoning (REER)",{"className":"page__taxonomy-item","children":["#","Reverse-Engineered Reasoning (REER)"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Synthetic Data",{"className":"page__taxonomy-item","children":["#","Synthetic Data"]}],["$","span","Iterative Refinement",{"className":"page__taxonomy-item","children":["#","Iterative Refinement"]}],["$","span","Perplexity Minimization",{"className":"page__taxonomy-item","children":["#","Perplexity Minimization"]}],["$","span","DeepWriting-20K",{"className":"page__taxonomy-item","children":["#","DeepWriting-20K"]}]]}]]}]]}],["$","article","2025-9-9-Reinforcement-Learning-Foundations-for-Deep-Research-Systems-A-Survey",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-Reinforcement-Learning-Foundations-for-Deep-Research-Systems-A-Survey/","children":"[논문리뷰] Reinforcement Learning Foundations for Deep Research Systems: A Survey"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wei Han이 [arXiv]에 게시한 'Reinforcement Learning Foundations for Deep Research Systems: A Survey' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Deep Research Systems",{"className":"page__taxonomy-item","children":["#","Deep Research Systems"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Hierarchical Agents",{"className":"page__taxonomy-item","children":["#","Hierarchical Agents"]}],["$","span","Reward Design",{"className":"page__taxonomy-item","children":["#","Reward Design"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","RL Frameworks",{"className":"page__taxonomy-item","children":["#","RL Frameworks"]}]]}]]}]]}],["$","article","2025-9-9-Reinforced-Visual-Perception-with-Tools",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-Reinforced-Visual-Perception-with-Tools/","children":"[논문리뷰] Reinforced Visual Perception with Tools"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Mingyang Fu이 [arXiv]에 게시한 'Reinforced Visual Perception with Tools' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Visual Reasoning",{"className":"page__taxonomy-item","children":["#","Visual Reasoning"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Tool Usage",{"className":"page__taxonomy-item","children":["#","Tool Usage"]}],["$","span","Perception-heavy Benchmarks",{"className":"page__taxonomy-item","children":["#","Perception-heavy Benchmarks"]}],["$","span","GRPO",{"className":"page__taxonomy-item","children":["#","GRPO"]}],["$","span","Vision Tools",{"className":"page__taxonomy-item","children":["#","Vision Tools"]}]]}]]}]]}],["$","article","2025-9-9-Paper2Agent-Reimagining-Research-Papers-As-Interactive-and-Reliable-AI-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-Paper2Agent-Reimagining-Research-Papers-As-Interactive-and-Reliable-AI-Agents/","children":"[논문리뷰] Paper2Agent: Reimagining Research Papers As Interactive and Reliable AI Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"James Zou이 [arXiv]에 게시한 'Paper2Agent: Reimagining Research Papers As Interactive and Reliable AI Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Agents",{"className":"page__taxonomy-item","children":["#","AI Agents"]}],["$","span","Research Reproducibility",{"className":"page__taxonomy-item","children":["#","Research Reproducibility"]}],["$","span","Scientific Communication",{"className":"page__taxonomy-item","children":["#","Scientific Communication"]}],["$","span","Model Context Protocol (MCP)",{"className":"page__taxonomy-item","children":["#","Model Context Protocol (MCP)"]}],["$","span","Natural Language Interaction",{"className":"page__taxonomy-item","children":["#","Natural Language Interaction"]}],["$","span","Genomics",{"className":"page__taxonomy-item","children":["#","Genomics"]}],["$","span","Single-Cell Analysis",{"className":"page__taxonomy-item","children":["#","Single-Cell Analysis"]}],["$","span","Spatial Transcriptomics",{"className":"page__taxonomy-item","children":["#","Spatial Transcriptomics"]}]]}]]}]]}],["$","article","2025-9-9-MAS-Bench-A-Unified-Benchmark-for-Shortcut-Augmented-Hybrid-Mobile-GUI-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-MAS-Bench-A-Unified-Benchmark-for-Shortcut-Augmented-Hybrid-Mobile-GUI-Agents/","children":"[논문리뷰] MAS-Bench: A Unified Benchmark for Shortcut-Augmented Hybrid Mobile GUI Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhengxi Lu이 [arXiv]에 게시한 'MAS-Bench: A Unified Benchmark for Shortcut-Augmented Hybrid Mobile GUI Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Mobile GUI Agents",{"className":"page__taxonomy-item","children":["#","Mobile GUI Agents"]}],["$","span","Hybrid Automation",{"className":"page__taxonomy-item","children":["#","Hybrid Automation"]}],["$","span","Shortcut Generation",{"className":"page__taxonomy-item","children":["#","Shortcut Generation"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Task Efficiency",{"className":"page__taxonomy-item","children":["#","Task Efficiency"]}],["$","span","LLM-based Agents",{"className":"page__taxonomy-item","children":["#","LLM-based Agents"]}],["$","span","Mobile Robotics",{"className":"page__taxonomy-item","children":["#","Mobile Robotics"]}]]}]]}]]}],["$","article","2025-9-9-Llama-GENBA-10B-A-Trilingual-Large-Language-Model-for-German-English-and-Bavarian",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-Llama-GENBA-10B-A-Trilingual-Large-Language-Model-for-German-English-and-Bavarian/","children":"[논문리뷰] Llama-GENBA-10B: A Trilingual Large Language Model for German, English and Bavarian"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hoi-Fong Mak이 [arXiv]에 게시한 'Llama-GENBA-10B: A Trilingual Large Language Model for German, English and Bavarian' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multilingual LLM",{"className":"page__taxonomy-item","children":["#","Multilingual LLM"]}],["$","span","Low-Resource Language",{"className":"page__taxonomy-item","children":["#","Low-Resource Language"]}],["$","span","German",{"className":"page__taxonomy-item","children":["#","German"]}],["$","span","Bavarian Dialect",{"className":"page__taxonomy-item","children":["#","Bavarian Dialect"]}],["$","span","Cross-Lingual Transfer",{"className":"page__taxonomy-item","children":["#","Cross-Lingual Transfer"]}],["$","span","Continuous Pretraining",{"className":"page__taxonomy-item","children":["#","Continuous Pretraining"]}],["$","span","Llama-3.1",{"className":"page__taxonomy-item","children":["#","Llama-3.1"]}],["$","span","Model Expansion",{"className":"page__taxonomy-item","children":["#","Model Expansion"]}]]}]]}]]}],["$","article","2025-9-9-Interleaving-Reasoning-for-Better-Text-to-Image-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-Interleaving-Reasoning-for-Better-Text-to-Image-Generation/","children":"[논문리뷰] Interleaving Reasoning for Better Text-to-Image Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shixiang Tang이 [arXiv]에 게시한 'Interleaving Reasoning for Better Text-to-Image Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Interleaving Reasoning",{"className":"page__taxonomy-item","children":["#","Interleaving Reasoning"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Visual Quality",{"className":"page__taxonomy-item","children":["#","Visual Quality"]}],["$","span","Fine-grained Detail",{"className":"page__taxonomy-item","children":["#","Fine-grained Detail"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Self-Correction",{"className":"page__taxonomy-item","children":["#","Self-Correction"]}]]}]]}]]}],["$","article","2025-9-9-Focusing-by-Contrastive-Attention-Enhancing-VLMs-Visual-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-Focusing-by-Contrastive-Attention-Enhancing-VLMs-Visual-Reasoning/","children":"[논문리뷰] Focusing by Contrastive Attention: Enhancing VLMs' Visual Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Baolong Bi이 [arXiv]에 게시한 'Focusing by Contrastive Attention: Enhancing VLMs' Visual Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision-Language Models (VLMs)"]}],["$","span","Visual Reasoning",{"className":"page__taxonomy-item","children":["#","Visual Reasoning"]}],["$","span","Attention Mechanisms",{"className":"page__taxonomy-item","children":["#","Attention Mechanisms"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Noise Suppression",{"className":"page__taxonomy-item","children":["#","Noise Suppression"]}],["$","span","Visual Complexity",{"className":"page__taxonomy-item","children":["#","Visual Complexity"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}]]}]]}]]}],["$","article","2025-9-9-Easier-Painting-Than-Thinking-Can-Text-to-Image-Models-Set-the-Stage-but-Not-Direct-the-Play",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-Easier-Painting-Than-Thinking-Can-Text-to-Image-Models-Set-the-Stage-but-Not-Direct-the-Play/","children":"[논문리뷰] Easier Painting Than Thinking: Can Text-to-Image Models Set the Stage, but Not Direct the Play?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Rui Chen이 [arXiv]에 게시한 'Easier Painting Than Thinking: Can Text-to-Image Models Set the Stage, but Not Direct the Play?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","T2I Benchmarking",{"className":"page__taxonomy-item","children":["#","T2I Benchmarking"]}],["$","span","Compositional Reasoning",{"className":"page__taxonomy-item","children":["#","Compositional Reasoning"]}],["$","span","Deductive Inference",{"className":"page__taxonomy-item","children":["#","Deductive Inference"]}],["$","span","Inductive Inference",{"className":"page__taxonomy-item","children":["#","Inductive Inference"]}],["$","span","Abductive Inference",{"className":"page__taxonomy-item","children":["#","Abductive Inference"]}],["$","span","MLLM Evaluation",{"className":"page__taxonomy-item","children":["#","MLLM Evaluation"]}]]}]]}]]}],["$","article","2025-9-9-Does-DINOv3-Set-a-New-Medical-Vision-Standard",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-Does-DINOv3-Set-a-New-Medical-Vision-Standard/","children":"[논문리뷰] Does DINOv3 Set a New Medical Vision Standard?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Bailiang Jian이 [arXiv]에 게시한 'Does DINOv3 Set a New Medical Vision Standard?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Medical Imaging",{"className":"page__taxonomy-item","children":["#","Medical Imaging"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","DINOv3",{"className":"page__taxonomy-item","children":["#","DINOv3"]}],["$","span","Self-Supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-Supervised Learning"]}],["$","span","Vision Transformer",{"className":"page__taxonomy-item","children":["#","Vision Transformer"]}],["$","span","2D/3D Classification",{"className":"page__taxonomy-item","children":["#","2D/3D Classification"]}],["$","span","Segmentation",{"className":"page__taxonomy-item","children":["#","Segmentation"]}],["$","span","Domain Adaptation",{"className":"page__taxonomy-item","children":["#","Domain Adaptation"]}],["$","span","Scaling Laws",{"className":"page__taxonomy-item","children":["#","Scaling Laws"]}]]}]]}]]}],["$","article","2025-9-9-D-HUMOR-Dark-Humor-Understanding-via-Multimodal-Open-ended-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-D-HUMOR-Dark-Humor-Understanding-via-Multimodal-Open-ended-Reasoning/","children":"[논문리뷰] D-HUMOR: Dark Humor Understanding via Multimodal Open-ended Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Dhanvin Sanjay Namboodiri이 [arXiv]에 게시한 'D-HUMOR: Dark Humor Understanding via Multimodal Open-ended Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Dark Humor Detection",{"className":"page__taxonomy-item","children":["#","Dark Humor Detection"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","span","Vision-Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision-Language Models (VLMs)"]}],["$","span","Iterative Reasoning Refinement",{"className":"page__taxonomy-item","children":["#","Iterative Reasoning Refinement"]}],["$","span","Meme Analysis",{"className":"page__taxonomy-item","children":["#","Meme Analysis"]}],["$","span","Content Moderation",{"className":"page__taxonomy-item","children":["#","Content Moderation"]}],["$","span","Cross-Modal Attention",{"className":"page__taxonomy-item","children":["#","Cross-Modal Attention"]}],["$","span","Dataset Annotation",{"className":"page__taxonomy-item","children":["#","Dataset Annotation"]}]]}]]}]]}],["$","article","2025-9-8-WinT3R-Window-Based-Streaming-Reconstruction-with-Camera-Token-Pool",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-8-WinT3R-Window-Based-Streaming-Reconstruction-with-Camera-Token-Pool/","children":"[논문리뷰] WinT3R: Window-Based Streaming Reconstruction with Camera Token Pool"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wenzheng Chang이 [arXiv]에 게시한 'WinT3R: Window-Based Streaming Reconstruction with Camera Token Pool' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-08 13:10:18+0900","children":"2025년 9월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Online 3D Reconstruction",{"className":"page__taxonomy-item","children":["#","Online 3D Reconstruction"]}],["$","span","Camera Pose Estimation",{"className":"page__taxonomy-item","children":["#","Camera Pose Estimation"]}],["$","span","Streaming Reconstruction",{"className":"page__taxonomy-item","children":["#","Streaming Reconstruction"]}],["$","span","Sliding Window",{"className":"page__taxonomy-item","children":["#","Sliding Window"]}],["$","span","Camera Token Pool",{"className":"page__taxonomy-item","children":["#","Camera Token Pool"]}],["$","span","Real-time Performance",{"className":"page__taxonomy-item","children":["#","Real-time Performance"]}],["$","span","Computer Vision",{"className":"page__taxonomy-item","children":["#","Computer Vision"]}]]}]]}]]}],["$","article","2025-9-8-WildScore-Benchmarking-MLLMs-in-the-Wild-Symbolic-Music-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-8-WildScore-Benchmarking-MLLMs-in-the-Wild-Symbolic-Music-Reasoning/","children":"[논문리뷰] WildScore: Benchmarking MLLMs in-the-Wild Symbolic Music Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Amit Namburi이 [arXiv]에 게시한 'WildScore: Benchmarking MLLMs in-the-Wild Symbolic Music Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-08 13:10:18+0900","children":"2025년 9월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models"]}],["$","span","Symbolic Music Reasoning",{"className":"page__taxonomy-item","children":["#","Symbolic Music Reasoning"]}],["$","span","Music Score Analysis",{"className":"page__taxonomy-item","children":["#","Music Score Analysis"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Visual Question Answering",{"className":"page__taxonomy-item","children":["#","Visual Question Answering"]}],["$","span","In-the-Wild Data",{"className":"page__taxonomy-item","children":["#","In-the-Wild Data"]}],["$","span","Music Theory",{"className":"page__taxonomy-item","children":["#","Music Theory"]}]]}]]}]]}],["$","article","2025-9-8-Why-Language-Models-Hallucinate",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-8-Why-Language-Models-Hallucinate/","children":"[논문리뷰] Why Language Models Hallucinate"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Edwin Zhang이 [arXiv]에 게시한 'Why Language Models Hallucinate' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-08 13:10:18+0900","children":"2025년 9월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Language Models",{"className":"page__taxonomy-item","children":["#","Language Models"]}],["$","span","Hallucination",{"className":"page__taxonomy-item","children":["#","Hallucination"]}],["$","span","Pretraining",{"className":"page__taxonomy-item","children":["#","Pretraining"]}],["$","span","Post-training",{"className":"page__taxonomy-item","children":["#","Post-training"]}],["$","span","Evaluation Metrics",{"className":"page__taxonomy-item","children":["#","Evaluation Metrics"]}],["$","span","Binary Classification",{"className":"page__taxonomy-item","children":["#","Binary Classification"]}],["$","span","Uncertainty Quantification",{"className":"page__taxonomy-item","children":["#","Uncertainty Quantification"]}],["$","span","Calibration",{"className":"page__taxonomy-item","children":["#","Calibration"]}]]}]]}]]}],["$","article","2025-9-8-U-ARM-Ultra-low-cost-general-teleoperation-interface-for-robot-manipulation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-8-U-ARM-Ultra-low-cost-general-teleoperation-interface-for-robot-manipulation/","children":"[논문리뷰] U-ARM : Ultra low-cost general teleoperation interface for robot manipulation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Junda Huang이 [arXiv]에 게시한 'U-ARM : Ultra low-cost general teleoperation interface for robot manipulation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-08 13:10:18+0900","children":"2025년 9월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Teleoperation",{"className":"page__taxonomy-item","children":["#","Teleoperation"]}],["$","span","Robot Manipulation",{"className":"page__taxonomy-item","children":["#","Robot Manipulation"]}],["$","span","Low-Cost Hardware",{"className":"page__taxonomy-item","children":["#","Low-Cost Hardware"]}],["$","span","3D Printing",{"className":"page__taxonomy-item","children":["#","3D Printing"]}],["$","span","Leader-Follower System",{"className":"page__taxonomy-item","children":["#","Leader-Follower System"]}],["$","span","Data Collection",{"className":"page__taxonomy-item","children":["#","Data Collection"]}],["$","span","Robotics Interface",{"className":"page__taxonomy-item","children":["#","Robotics Interface"]}],["$","span","Open Source",{"className":"page__taxonomy-item","children":["#","Open Source"]}]]}]]}]]}],["$","article","2025-9-8-Symbolic-Graphics-Programming-with-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-8-Symbolic-Graphics-Programming-with-Large-Language-Models/","children":"[논문리뷰] Symbolic Graphics Programming with Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kaipeng Zhang이 [arXiv]에 게시한 'Symbolic Graphics Programming with Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-08 13:10:18+0900","children":"2025년 9월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Symbolic Graphics Programming",{"className":"page__taxonomy-item","children":["#","Symbolic Graphics Programming"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","SVG Generation",{"className":"page__taxonomy-item","children":["#","SVG Generation"]}],["$","span","Text-to-Image Synthesis",{"className":"page__taxonomy-item","children":["#","Text-to-Image Synthesis"]}],["$","span","Cross-Modal Alignment",{"className":"page__taxonomy-item","children":["#","Cross-Modal Alignment"]}],["$","span","Program Synthesis",{"className":"page__taxonomy-item","children":["#","Program Synthesis"]}]]}]]}]]}],["$","article","2025-9-8-Set-Block-Decoding-is-a-Language-Model-Inference-Accelerator",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-8-Set-Block-Decoding-is-a-Language-Model-Inference-Accelerator/","children":"[논문리뷰] Set Block Decoding is a Language Model Inference Accelerator"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jeremy Reizenstein이 [arXiv]에 게시한 'Set Block Decoding is a Language Model Inference Accelerator' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-08 13:10:18+0900","children":"2025년 9월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Language Model Inference",{"className":"page__taxonomy-item","children":["#","Language Model Inference"]}],["$","span","Acceleration",{"className":"page__taxonomy-item","children":["#","Acceleration"]}],["$","span","Set Block Decoding",{"className":"page__taxonomy-item","children":["#","Set Block Decoding"]}],["$","span","Next Token Prediction",{"className":"page__taxonomy-item","children":["#","Next Token Prediction"]}],["$","span","Masked Token Prediction",{"className":"page__taxonomy-item","children":["#","Masked Token Prediction"]}],["$","span","Parallel Decoding",{"className":"page__taxonomy-item","children":["#","Parallel Decoding"]}],["$","span","KV-caching",{"className":"page__taxonomy-item","children":["#","KV-caching"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}]]}]]}]]}],["$","article","2025-9-8-On-Robustness-and-Reliability-of-Benchmark-Based-Evaluation-of-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-8-On-Robustness-and-Reliability-of-Benchmark-Based-Evaluation-of-LLMs/","children":"[논문리뷰] On Robustness and Reliability of Benchmark-Based Evaluation of LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kevin Roitero이 [arXiv]에 게시한 'On Robustness and Reliability of Benchmark-Based Evaluation of LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-08 13:10:18+0900","children":"2025년 9월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Model Robustness",{"className":"page__taxonomy-item","children":["#","Model Robustness"]}],["$","span","Benchmark Reliability",{"className":"page__taxonomy-item","children":["#","Benchmark Reliability"]}],["$","span","Paraphrasing",{"className":"page__taxonomy-item","children":["#","Paraphrasing"]}],["$","span","Linguistic Variability",{"className":"page__taxonomy-item","children":["#","Linguistic Variability"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Question Answering",{"className":"page__taxonomy-item","children":["#","Question Answering"]}]]}]]}]]}],["$","article","2025-9-8-MedVista3D-Vision-Language-Modeling-for-Reducing-Diagnostic-Errors-in-3D-CT-Disease-Detection-Understanding-and-Reporting",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-8-MedVista3D-Vision-Language-Modeling-for-Reducing-Diagnostic-Errors-in-3D-CT-Disease-Detection-Understanding-and-Reporting/","children":"[논문리뷰] MedVista3D: Vision-Language Modeling for Reducing Diagnostic Errors in 3D CT Disease Detection, Understanding and Reporting"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Vanessa Wildman이 [arXiv]에 게시한 'MedVista3D: Vision-Language Modeling for Reducing Diagnostic Errors in 3D CT Disease Detection, Understanding and Reporting' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-08 13:10:18+0900","children":"2025년 9월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D CT",{"className":"page__taxonomy-item","children":["#","3D CT"]}],["$","span","Vision-Language Model",{"className":"page__taxonomy-item","children":["#","Vision-Language Model"]}],["$","span","Medical Imaging",{"className":"page__taxonomy-item","children":["#","Medical Imaging"]}],["$","span","Diagnostic Error Reduction",{"className":"page__taxonomy-item","children":["#","Diagnostic Error Reduction"]}],["$","span","Multi-scale Alignment",{"className":"page__taxonomy-item","children":["#","Multi-scale Alignment"]}],["$","span","Semantic Enrichment",{"className":"page__taxonomy-item","children":["#","Semantic Enrichment"]}],["$","span","Radiology Reporting",{"className":"page__taxonomy-item","children":["#","Radiology Reporting"]}],["$","span","Zero-shot Learning",{"className":"page__taxonomy-item","children":["#","Zero-shot Learning"]}]]}]]}]]}],["$","article","2025-9-8-LuxDiT-Lighting-Estimation-with-Video-Diffusion-Transformer",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-8-LuxDiT-Lighting-Estimation-with-Video-Diffusion-Transformer/","children":"[논문리뷰] LuxDiT: Lighting Estimation with Video Diffusion Transformer"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Sanja Fidler이 [arXiv]에 게시한 'LuxDiT: Lighting Estimation with Video Diffusion Transformer' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-08 13:10:18+0900","children":"2025년 9월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Lighting Estimation",{"className":"page__taxonomy-item","children":["#","Lighting Estimation"]}],["$","span","HDR Environment Map",{"className":"page__taxonomy-item","children":["#","HDR Environment Map"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Video Transformer",{"className":"page__taxonomy-item","children":["#","Video Transformer"]}],["$","span","Low-Rank Adaptation",{"className":"page__taxonomy-item","children":["#","Low-Rank Adaptation"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Synthetic Data",{"className":"page__taxonomy-item","children":["#","Synthetic Data"]}]]}]]}]]}],["$","article","2025-9-8-LatticeWorld-A-Multimodal-Large-Language-Model-Empowered-Framework-for-Interactive-Complex-World-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-8-LatticeWorld-A-Multimodal-Large-Language-Model-Empowered-Framework-for-Interactive-Complex-World-Generation/","children":"[논문리뷰] LatticeWorld: A Multimodal Large Language Model-Empowered Framework for Interactive Complex World Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhan Zhao이 [arXiv]에 게시한 'LatticeWorld: A Multimodal Large Language Model-Empowered Framework for Interactive Complex World Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-08 13:10:18+0900","children":"2025년 9월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLM",{"className":"page__taxonomy-item","children":["#","Multimodal LLM"]}],["$","span","3D World Generation",{"className":"page__taxonomy-item","children":["#","3D World Generation"]}],["$","span","Unreal Engine 5",{"className":"page__taxonomy-item","children":["#","Unreal Engine 5"]}],["$","span","Procedural Content Generation",{"className":"page__taxonomy-item","children":["#","Procedural Content Generation"]}],["$","span","Interactive Environments",{"className":"page__taxonomy-item","children":["#","Interactive Environments"]}],["$","span","Sim-to-Real",{"className":"page__taxonomy-item","children":["#","Sim-to-Real"]}],["$","span","Spatial Understanding",{"className":"page__taxonomy-item","children":["#","Spatial Understanding"]}],["$","span","Multimodal Input",{"className":"page__taxonomy-item","children":["#","Multimodal Input"]}]]}]]}]]}],["$","article","2025-9-8-Bootstrapping-Task-Spaces-for-Self-Improvement",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-8-Bootstrapping-Task-Spaces-for-Self-Improvement/","children":"[논문리뷰] Bootstrapping Task Spaces for Self-Improvement"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yoram Bachrach이 [arXiv]에 게시한 'Bootstrapping Task Spaces for Self-Improvement' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-08 13:10:18+0900","children":"2025년 9월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Self-Improvement",{"className":"page__taxonomy-item","children":["#","Self-Improvement"]}],["$","span","Autocurriculum",{"className":"page__taxonomy-item","children":["#","Autocurriculum"]}],["$","span","Task-Space Exploration",{"className":"page__taxonomy-item","children":["#","Task-Space Exploration"]}],["$","span","Inference-Time Iteration",{"className":"page__taxonomy-item","children":["#","Inference-Time Iteration"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}]]}]]}]]}],["$","article","2025-9-8-Behavioral-Fingerprinting-of-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-8-Behavioral-Fingerprinting-of-Large-Language-Models/","children":"[논문리뷰] Behavioral Fingerprinting of Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xing Li이 [arXiv]에 게시한 'Behavioral Fingerprinting of Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-08 13:10:18+0900","children":"2025년 9월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Behavioral Evaluation",{"className":"page__taxonomy-item","children":["#","Behavioral Evaluation"]}],["$","span","Model Alignment",{"className":"page__taxonomy-item","children":["#","Model Alignment"]}],["$","span","Sycophancy",{"className":"page__taxonomy-item","children":["#","Sycophancy"]}],["$","span","World Model Brittleness",{"className":"page__taxonomy-item","children":["#","World Model Brittleness"]}],["$","span","Metacognition",{"className":"page__taxonomy-item","children":["#","Metacognition"]}],["$","span","Personality Profiling",{"className":"page__taxonomy-item","children":["#","Personality Profiling"]}]]}]]}]]}],["$","article","2025-9-5-Video-MTR-Reinforced-Multi-Turn-Reasoning-for-Long-Video-Understanding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-5-Video-MTR-Reinforced-Multi-Turn-Reasoning-for-Long-Video-Understanding/","children":"[논문리뷰] Video-MTR: Reinforced Multi-Turn Reasoning for Long Video Understanding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Lionel Ni이 [arXiv]에 게시한 'Video-MTR: Reinforced Multi-Turn Reasoning for Long Video Understanding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-05 13:07:20+0900","children":"2025년 9월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Long Video Understanding",{"className":"page__taxonomy-item","children":["#","Long Video Understanding"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Multi-Turn Reasoning",{"className":"page__taxonomy-item","children":["#","Multi-Turn Reasoning"]}],["$","span","MLLMs",{"className":"page__taxonomy-item","children":["#","MLLMs"]}],["$","span","Video Segment Selection",{"className":"page__taxonomy-item","children":["#","Video Segment Selection"]}],["$","span","Bi-level Reward",{"className":"page__taxonomy-item","children":["#","Bi-level Reward"]}],["$","span","Question Answering",{"className":"page__taxonomy-item","children":["#","Question Answering"]}]]}]]}]]}],["$","article","2025-9-5-Transition-Models-Rethinking-the-Generative-Learning-Objective",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-5-Transition-Models-Rethinking-the-Generative-Learning-Objective/","children":"[논문리뷰] Transition Models: Rethinking the Generative Learning Objective"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yangguang Li이 [arXiv]에 게시한 'Transition Models: Rethinking the Generative Learning Objective' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-05 13:07:20+0900","children":"2025년 9월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Training Objective",{"className":"page__taxonomy-item","children":["#","Training Objective"]}],["$","span","Continuous-Time Dynamics",{"className":"page__taxonomy-item","children":["#","Continuous-Time Dynamics"]}],["$","span","State Transition",{"className":"page__taxonomy-item","children":["#","State Transition"]}],["$","span","Few-Step Generation",{"className":"page__taxonomy-item","children":["#","Few-Step Generation"]}],["$","span","Scalable Training",{"className":"page__taxonomy-item","children":["#","Scalable Training"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}]]}]]}]]}],["$","article","2025-9-5-Towards-a-Unified-View-of-Large-Language-Model-Post-Training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-5-Towards-a-Unified-View-of-Large-Language-Model-Post-Training/","children":"[논문리뷰] Towards a Unified View of Large Language Model Post-Training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hongyi Liu이 [arXiv]에 게시한 'Towards a Unified View of Large Language Model Post-Training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-05 13:07:20+0900","children":"2025년 9월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Post-Training",{"className":"page__taxonomy-item","children":["#","Post-Training"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Supervised Fine-Tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning (SFT)"]}],["$","span","Policy Gradient",{"className":"page__taxonomy-item","children":["#","Policy Gradient"]}],["$","span","Unified Framework",{"className":"page__taxonomy-item","children":["#","Unified Framework"]}],["$","span","Hybrid Algorithms",{"className":"page__taxonomy-item","children":["#","Hybrid Algorithms"]}],["$","span","Bias-Variance Tradeoff",{"className":"page__taxonomy-item","children":["#","Bias-Variance Tradeoff"]}]]}]]}]]}],["$","article","2025-9-5-NER-Retriever-Zero-Shot-Named-Entity-Retrieval-with-Type-Aware-Embeddings",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-5-NER-Retriever-Zero-Shot-Named-Entity-Retrieval-with-Type-Aware-Embeddings/","children":"[논문리뷰] NER Retriever: Zero-Shot Named Entity Retrieval with Type-Aware Embeddings"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Oren Glickman이 [arXiv]에 게시한 'NER Retriever: Zero-Shot Named Entity Retrieval with Type-Aware Embeddings' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-05 13:07:20+0900","children":"2025년 9월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Named Entity Retrieval",{"className":"page__taxonomy-item","children":["#","Named Entity Retrieval"]}],["$","span","Zero-Shot Learning",{"className":"page__taxonomy-item","children":["#","Zero-Shot Learning"]}],["$","span","Type-Aware Embeddings",{"className":"page__taxonomy-item","children":["#","Type-Aware Embeddings"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Internal Representations",{"className":"page__taxonomy-item","children":["#","Internal Representations"]}],["$","span","Information Retrieval",{"className":"page__taxonomy-item","children":["#","Information Retrieval"]}]]}]]}]]}],["$","article","2025-9-5-Inverse-IFEval-Can-LLMs-Unlearn-Stubborn-Training-Conventions-to-Follow-Real-Instructions",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-5-Inverse-IFEval-Can-LLMs-Unlearn-Stubborn-Training-Conventions-to-Follow-Real-Instructions/","children":"[논문리뷰] Inverse IFEval: Can LLMs Unlearn Stubborn Training Conventions to Follow Real Instructions?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yu Fu이 [arXiv]에 게시한 'Inverse IFEval: Can LLMs Unlearn Stubborn Training Conventions to Follow Real Instructions?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-05 13:07:20+0900","children":"2025년 9월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Cognitive Inertia",{"className":"page__taxonomy-item","children":["#","Cognitive Inertia"]}],["$","span","Out-of-Distribution",{"className":"page__taxonomy-item","children":["#","Out-of-Distribution"]}],["$","span","Supervised Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning"]}],["$","span","Evaluation",{"className":"page__taxonomy-item","children":["#","Evaluation"]}],["$","span","Robustness",{"className":"page__taxonomy-item","children":["#","Robustness"]}]]}]]}]]}],["$","article","2025-9-5-From-Editor-to-Dense-Geometry-Estimator",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-5-From-Editor-to-Dense-Geometry-Estimator/","children":"[논문리뷰] From Editor to Dense Geometry Estimator"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Lang Nie이 [arXiv]에 게시한 'From Editor to Dense Geometry Estimator' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-05 13:07:20+0900","children":"2025년 9월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Dense Geometry Estimation",{"className":"page__taxonomy-item","children":["#","Dense Geometry Estimation"]}],["$","span","Diffusion Transformer",{"className":"page__taxonomy-item","children":["#","Diffusion Transformer"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Zero-shot Learning",{"className":"page__taxonomy-item","children":["#","Zero-shot Learning"]}],["$","span","Depth Estimation",{"className":"page__taxonomy-item","children":["#","Depth Estimation"]}],["$","span","Normal Estimation",{"className":"page__taxonomy-item","children":["#","Normal Estimation"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Logarithmic Quantization",{"className":"page__taxonomy-item","children":["#","Logarithmic Quantization"]}]]}]]}]]}],["$","article","2025-9-5-Few-step-Flow-for-3D-Generation-via-Marginal-Data-Transport-Distillation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-5-Few-step-Flow-for-3D-Generation-via-Marginal-Data-Transport-Distillation/","children":"[논문리뷰] Few-step Flow for 3D Generation via Marginal-Data Transport Distillation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Lingxi Xie이 [arXiv]에 게시한 'Few-step Flow for 3D Generation via Marginal-Data Transport Distillation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-05 13:07:20+0900","children":"2025년 9월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Generation",{"className":"page__taxonomy-item","children":["#","3D Generation"]}],["$","span","Flow-based Models",{"className":"page__taxonomy-item","children":["#","Flow-based Models"]}],["$","span","Model Distillation",{"className":"page__taxonomy-item","children":["#","Model Distillation"]}],["$","span","Few-step Sampling",{"className":"page__taxonomy-item","children":["#","Few-step Sampling"]}],["$","span","Marginal-Data Transport",{"className":"page__taxonomy-item","children":["#","Marginal-Data Transport"]}],["$","span","Velocity Matching",{"className":"page__taxonomy-item","children":["#","Velocity Matching"]}],["$","span","Velocity Distillation",{"className":"page__taxonomy-item","children":["#","Velocity Distillation"]}]]}]]}]]}],["$","article","2025-9-5-False-Sense-of-Security-Why-Probing-based-Malicious-Input-Detection-Fails-to-Generalize",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-5-False-Sense-of-Security-Why-Probing-based-Malicious-Input-Detection-Fails-to-Generalize/","children":"[논문리뷰] False Sense of Security: Why Probing-based Malicious Input Detection Fails to Generalize"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Muhao Chen이 [arXiv]에 게시한 'False Sense of Security: Why Probing-based Malicious Input Detection Fails to Generalize' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-05 13:07:20+0900","children":"2025년 9월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Safety",{"className":"page__taxonomy-item","children":["#","LLM Safety"]}],["$","span","Malicious Input Detection",{"className":"page__taxonomy-item","children":["#","Malicious Input Detection"]}],["$","span","Probing Classifiers",{"className":"page__taxonomy-item","children":["#","Probing Classifiers"]}],["$","span","Out-of-Distribution Generalization",{"className":"page__taxonomy-item","children":["#","Out-of-Distribution Generalization"]}],["$","span","Superficial Patterns",{"className":"page__taxonomy-item","children":["#","Superficial Patterns"]}],["$","span","Instructional Patterns",{"className":"page__taxonomy-item","children":["#","Instructional Patterns"]}],["$","span","Trigger Words",{"className":"page__taxonomy-item","children":["#","Trigger Words"]}],["$","span","AI Safety",{"className":"page__taxonomy-item","children":["#","AI Safety"]}]]}]]}]]}],["$","article","2025-9-5-Durian-Dual-Reference-guided-Portrait-Animation-with-Attribute-Transfer",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-5-Durian-Dual-Reference-guided-Portrait-Animation-with-Attribute-Transfer/","children":"[논문리뷰] Durian: Dual Reference-guided Portrait Animation with Attribute Transfer"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hanbyul Joo이 [arXiv]에 게시한 'Durian: Dual Reference-guided Portrait Animation with Attribute Transfer' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-05 13:07:20+0900","children":"2025년 9월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Portrait Animation",{"className":"page__taxonomy-item","children":["#","Portrait Animation"]}],["$","span","Attribute Transfer",{"className":"page__taxonomy-item","children":["#","Attribute Transfer"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Dual Reference Networks",{"className":"page__taxonomy-item","children":["#","Dual Reference Networks"]}],["$","span","Zero-shot Learning",{"className":"page__taxonomy-item","children":["#","Zero-shot Learning"]}],["$","span","Self-Reconstruction",{"className":"page__taxonomy-item","children":["#","Self-Reconstruction"]}],["$","span","Facial Editing",{"className":"page__taxonomy-item","children":["#","Facial Editing"]}]]}]]}]]}],["$","article","2025-9-5-Drivel-ology-Challenging-LLMs-with-Interpreting-Nonsense-with-Depth",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-5-Drivel-ology-Challenging-LLMs-with-Interpreting-Nonsense-with-Depth/","children":"[논문리뷰] Drivel-ology: Challenging LLMs with Interpreting Nonsense with Depth"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chi-Li Chen이 [arXiv]에 게시한 'Drivel-ology: Challenging LLMs with Interpreting Nonsense with Depth' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-05 13:07:20+0900","children":"2025년 9월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Pragmatic Understanding",{"className":"page__taxonomy-item","children":["#","Pragmatic Understanding"]}],["$","span","Drivelology",{"className":"page__taxonomy-item","children":["#","Drivelology"]}],["$","span","Benchmark Dataset",{"className":"page__taxonomy-item","children":["#","Benchmark Dataset"]}],["$","span","Multilingual NLP",{"className":"page__taxonomy-item","children":["#","Multilingual NLP"]}],["$","span","Semantic Reasoning",{"className":"page__taxonomy-item","children":["#","Semantic Reasoning"]}],["$","span","Contextual Inference",{"className":"page__taxonomy-item","children":["#","Contextual Inference"]}]]}]]}]]}],["$","article","2025-9-5-Drawing2CAD-Sequence-to-Sequence-Learning-for-CAD-Generation-from-Vector-Drawings",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-5-Drawing2CAD-Sequence-to-Sequence-Learning-for-CAD-Generation-from-Vector-Drawings/","children":"[논문리뷰] Drawing2CAD: Sequence-to-Sequence Learning for CAD Generation from Vector Drawings"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Meie Fang이 [arXiv]에 게시한 'Drawing2CAD: Sequence-to-Sequence Learning for CAD Generation from Vector Drawings' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-05 13:07:20+0900","children":"2025년 9월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","CAD Generation",{"className":"page__taxonomy-item","children":["#","CAD Generation"]}],["$","span","Vector Graphics",{"className":"page__taxonomy-item","children":["#","Vector Graphics"]}],["$","span","Sequence-to-Sequence Learning",{"className":"page__taxonomy-item","children":["#","Sequence-to-Sequence Learning"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Engineering Drawings",{"className":"page__taxonomy-item","children":["#","Engineering Drawings"]}],["$","span","Multi-modal Learning",{"className":"page__taxonomy-item","children":["#","Multi-modal Learning"]}],["$","span","Soft Target Loss",{"className":"page__taxonomy-item","children":["#","Soft Target Loss"]}],["$","span","Dual Decoder",{"className":"page__taxonomy-item","children":["#","Dual Decoder"]}]]}]]}]]}],["$","article","2025-9-5-Delta-Activations-A-Representation-for-Finetuned-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-5-Delta-Activations-A-Representation-for-Finetuned-Large-Language-Models/","children":"[논문리뷰] Delta Activations: A Representation for Finetuned Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ser-Nam Lim이 [arXiv]에 게시한 'Delta Activations: A Representation for Finetuned Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-05 13:07:20+0900","children":"2025년 9월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Embedding",{"className":"page__taxonomy-item","children":["#","LLM Embedding"]}],["$","span","Delta Activations",{"className":"page__taxonomy-item","children":["#","Delta Activations"]}],["$","span","Finetuned Models",{"className":"page__taxonomy-item","children":["#","Finetuned Models"]}],["$","span","Model Representation",{"className":"page__taxonomy-item","children":["#","Model Representation"]}],["$","span","Model Clustering",{"className":"page__taxonomy-item","children":["#","Model Clustering"]}],["$","span","Additive Property",{"className":"page__taxonomy-item","children":["#","Additive Property"]}],["$","span","Task Embedding",{"className":"page__taxonomy-item","children":["#","Task Embedding"]}],["$","span","Model Merging",{"className":"page__taxonomy-item","children":["#","Model Merging"]}]]}]]}]]}],["$","article","2025-9-5-DeepResearch-Arena-The-First-Exam-of-LLMs-Research-Abilities-via-Seminar-Grounded-Tasks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-5-DeepResearch-Arena-The-First-Exam-of-LLMs-Research-Abilities-via-Seminar-Grounded-Tasks/","children":"[논문리뷰] DeepResearch Arena: The First Exam of LLMs' Research Abilities via Seminar-Grounded Tasks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiaxuan Lu이 [arXiv]에 게시한 'DeepResearch Arena: The First Exam of LLMs' Research Abilities via Seminar-Grounded Tasks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-05 13:07:20+0900","children":"2025년 9월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Research Agents",{"className":"page__taxonomy-item","children":["#","Research Agents"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Multi-Agent System",{"className":"page__taxonomy-item","children":["#","Multi-Agent System"]}],["$","span","Seminar-Grounded Tasks",{"className":"page__taxonomy-item","children":["#","Seminar-Grounded Tasks"]}],["$","span","Data Leakage Prevention",{"className":"page__taxonomy-item","children":["#","Data Leakage Prevention"]}],["$","span","Ill-Structured Problems",{"className":"page__taxonomy-item","children":["#","Ill-Structured Problems"]}]]}]]}]]}],["$","article","2025-9-4-Robix-A-Unified-Model-for-Robot-Interaction-Reasoning-and-Planning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-4-Robix-A-Unified-Model-for-Robot-Interaction-Reasoning-and-Planning/","children":"[논문리뷰] Robix: A Unified Model for Robot Interaction, Reasoning and Planning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zixuan Wang이 [arXiv]에 게시한 'Robix: A Unified Model for Robot Interaction, Reasoning and Planning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-04 12:56:15+0900","children":"2025년 9월 4일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Robot Learning",{"className":"page__taxonomy-item","children":["#","Robot Learning"]}],["$","span","Vision-Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision-Language Models (VLMs)"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Human-Robot Interaction (HRI)",{"className":"page__taxonomy-item","children":["#","Human-Robot Interaction (HRI)"]}],["$","span","Task Planning",{"className":"page__taxonomy-item","children":["#","Task Planning"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Chain-of-Thought (CoT) Reasoning",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought (CoT) Reasoning"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}]]}]]}]]}],["$","article","2025-9-4-Open-Data-Synthesis-For-Deep-Research",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-4-Open-Data-Synthesis-For-Deep-Research/","children":"[논문리뷰] Open Data Synthesis For Deep Research"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zheng Liu이 [arXiv]에 게시한 'Open Data Synthesis For Deep Research' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-04 12:56:15+0900","children":"2025년 9월 4일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Data Synthesis",{"className":"page__taxonomy-item","children":["#","Data Synthesis"]}],["$","span","Deep Research",{"className":"page__taxonomy-item","children":["#","Deep Research"]}],["$","span","Hierarchical Constraint Satisfaction Problems",{"className":"page__taxonomy-item","children":["#","Hierarchical Constraint Satisfaction Problems"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Question Answering",{"className":"page__taxonomy-item","children":["#","Question Answering"]}]]}]]}]]}],["$","article","2025-9-4-Mixture-of-Global-and-Local-Experts-with-Diffusion-Transformer-for-Controllable-Face-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-4-Mixture-of-Global-and-Local-Experts-with-Diffusion-Transformer-for-Controllable-Face-Generation/","children":"[논문리뷰] Mixture of Global and Local Experts with Diffusion Transformer for Controllable Face Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kai Li이 [arXiv]에 게시한 'Mixture of Global and Local Experts with Diffusion Transformer for Controllable Face Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-04 12:56:15+0900","children":"2025년 9월 4일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Transformer",{"className":"page__taxonomy-item","children":["#","Diffusion Transformer"]}],["$","span","Mixture of Experts",{"className":"page__taxonomy-item","children":["#","Mixture of Experts"]}],["$","span","Controllable Generation",{"className":"page__taxonomy-item","children":["#","Controllable Generation"]}],["$","span","Face Generation",{"className":"page__taxonomy-item","children":["#","Face Generation"]}],["$","span","Multimodal Synthesis",{"className":"page__taxonomy-item","children":["#","Multimodal Synthesis"]}],["$","span","Semantic Control",{"className":"page__taxonomy-item","children":["#","Semantic Control"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}]]}]]}]]}],["$","article","2025-9-4-MOSAIC-Multi-Subject-Personalized-Generation-via-Correspondence-Aware-Alignment-and-Disentanglement",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-4-MOSAIC-Multi-Subject-Personalized-Generation-via-Correspondence-Aware-Alignment-and-Disentanglement/","children":"[논문리뷰] MOSAIC: Multi-Subject Personalized Generation via Correspondence-Aware Alignment and Disentanglement"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hualiang Wang이 [arXiv]에 게시한 'MOSAIC: Multi-Subject Personalized Generation via Correspondence-Aware Alignment and Disentanglement' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-04 12:56:15+0900","children":"2025년 9월 4일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-Subject Generation",{"className":"page__taxonomy-item","children":["#","Multi-Subject Generation"]}],["$","span","Personalized Image Synthesis",{"className":"page__taxonomy-item","children":["#","Personalized Image Synthesis"]}],["$","span","Semantic Correspondence",{"className":"page__taxonomy-item","children":["#","Semantic Correspondence"]}],["$","span","Attention Disentanglement",{"className":"page__taxonomy-item","children":["#","Attention Disentanglement"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Identity Preservation",{"className":"page__taxonomy-item","children":["#","Identity Preservation"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}]]}]]}]]}],["$","article","2025-9-4-LMEnt-A-Suite-for-Analyzing-Knowledge-in-Language-Models-from-Pretraining-Data-to-Representations",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-4-LMEnt-A-Suite-for-Analyzing-Knowledge-in-Language-Models-from-Pretraining-Data-to-Representations/","children":"[논문리뷰] LMEnt: A Suite for Analyzing Knowledge in Language Models from Pretraining Data to Representations"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yoav Gur-Arieh이 [arXiv]에 게시한 'LMEnt: A Suite for Analyzing Knowledge in Language Models from Pretraining Data to Representations' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-04 12:56:15+0900","children":"2025년 9월 4일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Language Models",{"className":"page__taxonomy-item","children":["#","Language Models"]}],["$","span","Knowledge Acquisition",{"className":"page__taxonomy-item","children":["#","Knowledge Acquisition"]}],["$","span","Pretraining Data",{"className":"page__taxonomy-item","children":["#","Pretraining Data"]}],["$","span","Entity Linking",{"className":"page__taxonomy-item","children":["#","Entity Linking"]}],["$","span","Coreference Resolution",{"className":"page__taxonomy-item","children":["#","Coreference Resolution"]}],["$","span","Information Retrieval",{"className":"page__taxonomy-item","children":["#","Information Retrieval"]}],["$","span","Model Analysis",{"className":"page__taxonomy-item","children":["#","Model Analysis"]}],["$","span","Checkpoints",{"className":"page__taxonomy-item","children":["#","Checkpoints"]}]]}]]}]]}],["$","article","2025-9-3-ViSTA-SLAM-Visual-SLAM-with-Symmetric-Two-view-Association",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-ViSTA-SLAM-Visual-SLAM-with-Symmetric-Two-view-Association/","children":"[논문리뷰] ViSTA-SLAM: Visual SLAM with Symmetric Two-view Association"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Daniel Cremers이 [arXiv]에 게시한 'ViSTA-SLAM: Visual SLAM with Symmetric Two-view Association' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Monocular SLAM",{"className":"page__taxonomy-item","children":["#","Monocular SLAM"]}],["$","span","Dense Reconstruction",{"className":"page__taxonomy-item","children":["#","Dense Reconstruction"]}],["$","span","Neural Networks",{"className":"page__taxonomy-item","children":["#","Neural Networks"]}],["$","span","Pose Graph Optimization",{"className":"page__taxonomy-item","children":["#","Pose Graph Optimization"]}],["$","span","Intrinsics-free",{"className":"page__taxonomy-item","children":["#","Intrinsics-free"]}],["$","span","Real-time",{"className":"page__taxonomy-item","children":["#","Real-time"]}],["$","span","Two-view Association",{"className":"page__taxonomy-item","children":["#","Two-view Association"]}]]}]]}]]}],["$","article","2025-9-3-VerlTool-Towards-Holistic-Agentic-Reinforcement-Learning-with-Tool-Use",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-VerlTool-Towards-Holistic-Agentic-Reinforcement-Learning-with-Tool-Use/","children":"[논문리뷰] VerlTool: Towards Holistic Agentic Reinforcement Learning with Tool Use"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhiheng Lyu이 [arXiv]에 게시한 'VerlTool: Towards Holistic Agentic Reinforcement Learning with Tool Use' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Agentic Reinforcement Learning"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reinforcement Learning from Verifiable Rewards (RLVR)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning from Verifiable Rewards (RLVR)"]}],["$","span","Asynchronous Execution",{"className":"page__taxonomy-item","children":["#","Asynchronous Execution"]}],["$","span","Multi-modal AI",{"className":"page__taxonomy-item","children":["#","Multi-modal AI"]}],["$","span","Framework",{"className":"page__taxonomy-item","children":["#","Framework"]}]]}]]}]]}],["$","article","2025-9-3-Universal-Deep-Research-Bring-Your-Own-Model-and-Strategy",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-Universal-Deep-Research-Bring-Your-Own-Model-and-Strategy/","children":"[논문리뷰] Universal Deep Research: Bring Your Own Model and Strategy"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Pavlo Molchanov이 [arXiv]에 게시한 'Universal Deep Research: Bring Your Own Model and Strategy' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic Systems",{"className":"page__taxonomy-item","children":["#","Agentic Systems"]}],["$","span","Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Language Models (LLMs)"]}],["$","span","Research Automation",{"className":"page__taxonomy-item","children":["#","Research Automation"]}],["$","span","Customizable Strategies",{"className":"page__taxonomy-item","children":["#","Customizable Strategies"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","Deep Research",{"className":"page__taxonomy-item","children":["#","Deep Research"]}],["$","span","User-Defined Agents",{"className":"page__taxonomy-item","children":["#","User-Defined Agents"]}],["$","span","Sandboxed Execution",{"className":"page__taxonomy-item","children":["#","Sandboxed Execution"]}]]}]]}]]}],["$","article","2025-9-3-UI-TARS-2-Technical-Report-Advancing-GUI-Agent-with-Multi-Turn-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-UI-TARS-2-Technical-Report-Advancing-GUI-Agent-with-Multi-Turn-Reinforcement-Learning/","children":"[논문리뷰] UI-TARS-2 Technical Report: Advancing GUI Agent with Multi-Turn Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Haoyang Zou이 [arXiv]에 게시한 'UI-TARS-2 Technical Report: Advancing GUI Agent with Multi-Turn Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","GUI Agent",{"className":"page__taxonomy-item","children":["#","GUI Agent"]}],["$","span","Multi-Turn RL",{"className":"page__taxonomy-item","children":["#","Multi-Turn RL"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Data Flywheel",{"className":"page__taxonomy-item","children":["#","Data Flywheel"]}],["$","span","Agent Framework",{"className":"page__taxonomy-item","children":["#","Agent Framework"]}],["$","span","Hybrid Environments",{"className":"page__taxonomy-item","children":["#","Hybrid Environments"]}],["$","span","Parameter Interpolation",{"className":"page__taxonomy-item","children":["#","Parameter Interpolation"]}]]}]]}]]}],["$","article","2025-9-3-Towards-More-Diverse-and-Challenging-Pre-training-for-Point-Cloud-Learning-Self-Supervised-Cross-Reconstruction-with-Decoupled-Views",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-Towards-More-Diverse-and-Challenging-Pre-training-for-Point-Cloud-Learning-Self-Supervised-Cross-Reconstruction-with-Decoupled-Views/","children":"[논문리뷰] Towards More Diverse and Challenging Pre-training for Point Cloud Learning: Self-Supervised Cross Reconstruction with Decoupled Views"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Junchi Yan이 [arXiv]에 게시한 'Towards More Diverse and Challenging Pre-training for Point Cloud Learning: Self-Supervised Cross Reconstruction with Decoupled Views' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Point Cloud Learning",{"className":"page__taxonomy-item","children":["#","Point Cloud Learning"]}],["$","span","Self-Supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-Supervised Learning"]}],["$","span","Cross Reconstruction",{"className":"page__taxonomy-item","children":["#","Cross Reconstruction"]}],["$","span","Decoupled Views",{"className":"page__taxonomy-item","children":["#","Decoupled Views"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Positional Encoding",{"className":"page__taxonomy-item","children":["#","Positional Encoding"]}],["$","span","3D Vision",{"className":"page__taxonomy-item","children":["#","3D Vision"]}]]}]]}]]}],["$","article","2025-9-3-The-Landscape-of-Agentic-Reinforcement-Learning-for-LLMs-A-Survey",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-The-Landscape-of-Agentic-Reinforcement-Learning-for-LLMs-A-Survey/","children":"[논문리뷰] The Landscape of Agentic Reinforcement Learning for LLMs: A Survey"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hejia Geng이 [arXiv]에 게시한 'The Landscape of Agentic Reinforcement Learning for LLMs: A Survey' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Agentic Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Sequential Decision Making",{"className":"page__taxonomy-item","children":["#","Sequential Decision Making"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Dynamic Environments",{"className":"page__taxonomy-item","children":["#","Dynamic Environments"]}],["$","span","Autonomous AI",{"className":"page__taxonomy-item","children":["#","Autonomous AI"]}]]}]]}]]}],["$","article","2025-9-3-The-Gold-Medals-in-an-Empty-Room-Diagnosing-Metalinguistic-Reasoning-in-LLMs-with-Camlang",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-The-Gold-Medals-in-an-Empty-Room-Diagnosing-Metalinguistic-Reasoning-in-LLMs-with-Camlang/","children":"[논문리뷰] The Gold Medals in an Empty Room: Diagnosing Metalinguistic Reasoning in LLMs with Camlang"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Solomon Tsai이 [arXiv]에 게시한 'The Gold Medals in an Empty Room: Diagnosing Metalinguistic Reasoning in LLMs with Camlang' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Metalinguistic Reasoning",{"className":"page__taxonomy-item","children":["#","Metalinguistic Reasoning"]}],["$","span","Constructed Language",{"className":"page__taxonomy-item","children":["#","Constructed Language"]}],["$","span","Camlang",{"className":"page__taxonomy-item","children":["#","Camlang"]}],["$","span","Second Language Acquisition",{"className":"page__taxonomy-item","children":["#","Second Language Acquisition"]}],["$","span","Zero-shot Learning",{"className":"page__taxonomy-item","children":["#","Zero-shot Learning"]}],["$","span","Natural Language Understanding",{"className":"page__taxonomy-item","children":["#","Natural Language Understanding"]}],["$","span","Commonsense Reasoning",{"className":"page__taxonomy-item","children":["#","Commonsense Reasoning"]}]]}]]}]]}],["$","article","2025-9-3-SimpleTIR-End-to-End-Reinforcement-Learning-for-Multi-Turn-Tool-Integrated-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-SimpleTIR-End-to-End-Reinforcement-Learning-for-Multi-Turn-Tool-Integrated-Reasoning/","children":"[논문리뷰] SimpleTIR: End-to-End Reinforcement Learning for Multi-Turn Tool-Integrated Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Qian Liu이 [arXiv]에 게시한 'SimpleTIR: End-to-End Reinforcement Learning for Multi-Turn Tool-Integrated Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Tool-Integrated Reasoning",{"className":"page__taxonomy-item","children":["#","Tool-Integrated Reasoning"]}],["$","span","Multi-turn Reasoning",{"className":"page__taxonomy-item","children":["#","Multi-turn Reasoning"]}],["$","span","Gradient Explosion",{"className":"page__taxonomy-item","children":["#","Gradient Explosion"]}],["$","span","Training Stability",{"className":"page__taxonomy-item","children":["#","Training Stability"]}],["$","span","Trajectory Filtering",{"className":"page__taxonomy-item","children":["#","Trajectory Filtering"]}],["$","span","Zero RL",{"className":"page__taxonomy-item","children":["#","Zero RL"]}]]}]]}]]}],["$","article","2025-9-3-SQL-of-Thought-Multi-agentic-Text-to-SQL-with-Guided-Error-Correction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-SQL-of-Thought-Multi-agentic-Text-to-SQL-with-Guided-Error-Correction/","children":"[논문리뷰] SQL-of-Thought: Multi-agentic Text-to-SQL with Guided Error Correction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"bindsch이 [arXiv]에 게시한 'SQL-of-Thought: Multi-agentic Text-to-SQL with Guided Error Correction' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-SQL",{"className":"page__taxonomy-item","children":["#","Text-to-SQL"]}],["$","span","Multi-agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-agent Systems"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Error Correction",{"className":"page__taxonomy-item","children":["#","Error Correction"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Query Planning",{"className":"page__taxonomy-item","children":["#","Query Planning"]}],["$","span","Database Interaction",{"className":"page__taxonomy-item","children":["#","Database Interaction"]}]]}]]}]]}],["$","article","2025-9-3-Reasoning-Vectors-Transferring-Chain-of-Thought-Capabilities-via-Task-Arithmetic",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-Reasoning-Vectors-Transferring-Chain-of-Thought-Capabilities-via-Task-Arithmetic/","children":"[논문리뷰] Reasoning Vectors: Transferring Chain-of-Thought Capabilities via Task Arithmetic"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Bernard Ghanem이 [arXiv]에 게시한 'Reasoning Vectors: Transferring Chain-of-Thought Capabilities via Task Arithmetic' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reasoning Vectors",{"className":"page__taxonomy-item","children":["#","Reasoning Vectors"]}],["$","span","Task Arithmetic",{"className":"page__taxonomy-item","children":["#","Task Arithmetic"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Model Merging",{"className":"page__taxonomy-item","children":["#","Model Merging"]}],["$","span","Parameter Transfer",{"className":"page__taxonomy-item","children":["#","Parameter Transfer"]}]]}]]}]]}],["$","article","2025-9-3-POINTS-Reader-Distillation-Free-Adaptation-of-Vision-Language-Models-for-Document-Conversion",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-POINTS-Reader-Distillation-Free-Adaptation-of-Vision-Language-Models-for-Document-Conversion/","children":"[논문리뷰] POINTS-Reader: Distillation-Free Adaptation of Vision-Language Models for Document Conversion"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Haicheng Wang이 [arXiv]에 게시한 'POINTS-Reader: Distillation-Free Adaptation of Vision-Language Models for Document Conversion' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","문서 변환",{"className":"page__taxonomy-item","children":["#","문서 변환"]}],["$","span","시각-언어 모델",{"className":"page__taxonomy-item","children":["#","시각-언어 모델"]}],["$","span","자가 개선",{"className":"page__taxonomy-item","children":["#","자가 개선"]}],["$","span","합성 데이터",{"className":"page__taxonomy-item","children":["#","합성 데이터"]}],["$","span","증류 없는 학습",{"className":"page__taxonomy-item","children":["#","증류 없는 학습"]}],["$","span","OCR",{"className":"page__taxonomy-item","children":["#","OCR"]}],["$","span","멀티모달 AI",{"className":"page__taxonomy-item","children":["#","멀티모달 AI"]}],["$","span","데이터 필터링",{"className":"page__taxonomy-item","children":["#","데이터 필터링"]}]]}]]}]]}],["$","article","2025-9-3-OpenVision-2-A-Family-of-Generative-Pretrained-Visual-Encoders-for-Multimodal-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-OpenVision-2-A-Family-of-Generative-Pretrained-Visual-Encoders-for-Multimodal-Learning/","children":"[논문리뷰] OpenVision 2: A Family of Generative Pretrained Visual Encoders for Multimodal Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zirui Wang이 [arXiv]에 게시한 'OpenVision 2: A Family of Generative Pretrained Visual Encoders for Multimodal Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Vision Encoder",{"className":"page__taxonomy-item","children":["#","Vision Encoder"]}],["$","span","Generative Pretraining",{"className":"page__taxonomy-item","children":["#","Generative Pretraining"]}],["$","span","Captioning Loss",{"className":"page__taxonomy-item","children":["#","Captioning Loss"]}],["$","span","Training Efficiency",{"className":"page__taxonomy-item","children":["#","Training Efficiency"]}],["$","span","Image-Text Models",{"className":"page__taxonomy-item","children":["#","Image-Text Models"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}]]}]]}]]}],["$","article","2025-9-3-MobiAgent-A-Systematic-Framework-for-Customizable-Mobile-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-MobiAgent-A-Systematic-Framework-for-Customizable-Mobile-Agents/","children":"[논문리뷰] MobiAgent: A Systematic Framework for Customizable Mobile Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wangbo Gong이 [arXiv]에 게시한 'MobiAgent: A Systematic Framework for Customizable Mobile Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Mobile Agents",{"className":"page__taxonomy-item","children":["#","Mobile Agents"]}],["$","span","GUI Agents",{"className":"page__taxonomy-item","children":["#","GUI Agents"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Agent Acceleration",{"className":"page__taxonomy-item","children":["#","Agent Acceleration"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Data Collection",{"className":"page__taxonomy-item","children":["#","Data Collection"]}]]}]]}]]}],["$","article","2025-9-3-Metis-Training-Large-Language-Models-with-Advanced-Low-Bit-Quantization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-Metis-Training-Large-Language-Models-with-Advanced-Low-Bit-Quantization/","children":"[논문리뷰] Metis: Training Large Language Models with Advanced Low-Bit Quantization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hengjie Cao이 [arXiv]에 게시한 'Metis: Training Large Language Models with Advanced Low-Bit Quantization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Low-Bit Quantization",{"className":"page__taxonomy-item","children":["#","Low-Bit Quantization"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Spectral Decomposition",{"className":"page__taxonomy-item","children":["#","Spectral Decomposition"]}],["$","span","Anisotropy",{"className":"page__taxonomy-item","children":["#","Anisotropy"]}],["$","span","Adaptive Learning Rate",{"className":"page__taxonomy-item","children":["#","Adaptive Learning Rate"]}],["$","span","Regularization",{"className":"page__taxonomy-item","children":["#","Regularization"]}],["$","span","FP8 Training",{"className":"page__taxonomy-item","children":["#","FP8 Training"]}],["$","span","FP4 Training",{"className":"page__taxonomy-item","children":["#","FP4 Training"]}]]}]]}]]}],["$","article","2025-9-3-MedDINOv3-How-to-adapt-vision-foundation-models-for-medical-image-segmentation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-MedDINOv3-How-to-adapt-vision-foundation-models-for-medical-image-segmentation/","children":"[논문리뷰] MedDINOv3: How to adapt vision foundation models for medical image segmentation?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiaofeng Yang이 [arXiv]에 게시한 'MedDINOv3: How to adapt vision foundation models for medical image segmentation?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Medical Image Segmentation",{"className":"page__taxonomy-item","children":["#","Medical Image Segmentation"]}],["$","span","Vision Foundation Models",{"className":"page__taxonomy-item","children":["#","Vision Foundation Models"]}],["$","span","Self-supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-supervised Learning"]}],["$","span","Vision Transformers (ViT)",{"className":"page__taxonomy-item","children":["#","Vision Transformers (ViT)"]}],["$","span","Domain Adaptation",{"className":"page__taxonomy-item","children":["#","Domain Adaptation"]}],["$","span","DINOv3",{"className":"page__taxonomy-item","children":["#","DINOv3"]}],["$","span","CT Imaging",{"className":"page__taxonomy-item","children":["#","CT Imaging"]}]]}]]}]]}],["$","article","2025-9-3-M3Ret-Unleashing-Zero-shot-Multimodal-Medical-Image-Retrieval-via-Self-Supervision",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-M3Ret-Unleashing-Zero-shot-Multimodal-Medical-Image-Retrieval-via-Self-Supervision/","children":"[논문리뷰] M3Ret: Unleashing Zero-shot Multimodal Medical Image Retrieval via Self-Supervision"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yan-Jie Zhou이 [arXiv]에 게시한 'M3Ret: Unleashing Zero-shot Multimodal Medical Image Retrieval via Self-Supervision' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Medical Image Retrieval",{"className":"page__taxonomy-item","children":["#","Medical Image Retrieval"]}],["$","span","Self-Supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-Supervised Learning"]}],["$","span","Multimodal",{"className":"page__taxonomy-item","children":["#","Multimodal"]}],["$","span","Zero-shot",{"className":"page__taxonomy-item","children":["#","Zero-shot"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","MAE",{"className":"page__taxonomy-item","children":["#","MAE"]}],["$","span","SimDINO",{"className":"page__taxonomy-item","children":["#","SimDINO"]}],["$","span","Vision Transformer",{"className":"page__taxonomy-item","children":["#","Vision Transformer"]}]]}]]}]]}],["$","article","2025-9-3-LLaVA-Critic-R1-Your-Critic-Model-is-Secretly-a-Strong-Policy-Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-LLaVA-Critic-R1-Your-Critic-Model-is-Secretly-a-Strong-Policy-Model/","children":"[논문리뷰] LLaVA-Critic-R1: Your Critic Model is Secretly a Strong Policy Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jianwei Yang이 [arXiv]에 게시한 'LLaVA-Critic-R1: Your Critic Model is Secretly a Strong Policy Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision-Language Models (VLMs)"]}],["$","span","Critic Models",{"className":"page__taxonomy-item","children":["#","Critic Models"]}],["$","span","Policy Models",{"className":"page__taxonomy-item","children":["#","Policy Models"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Self-Criticism",{"className":"page__taxonomy-item","children":["#","Self-Criticism"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","span","Preference Learning",{"className":"page__taxonomy-item","children":["#","Preference Learning"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}]]}]]}]]}],["$","article","2025-9-3-Kwai-Keye-VL-1-5-Technical-Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-Kwai-Keye-VL-1-5-Technical-Report/","children":"[논문리뷰] Kwai Keye-VL 1.5 Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"SXxtyz이 [arXiv]에 게시한 'Kwai Keye-VL 1.5 Technical Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Video Understanding",{"className":"page__taxonomy-item","children":["#","Video Understanding"]}],["$","span","Slow-Fast Encoding",{"className":"page__taxonomy-item","children":["#","Slow-Fast Encoding"]}],["$","span","Long Context",{"className":"page__taxonomy-item","children":["#","Long Context"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Human Alignment",{"className":"page__taxonomy-item","children":["#","Human Alignment"]}],["$","span","Native-Resolution Vision Encoder",{"className":"page__taxonomy-item","children":["#","Native-Resolution Vision Encoder"]}]]}]]}]]}],["$","article","2025-9-3-Jointly-Reinforcing-Diversity-and-Quality-in-Language-Model-Generations",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-Jointly-Reinforcing-Diversity-and-Quality-in-Language-Model-Generations/","children":"[논문리뷰] Jointly Reinforcing Diversity and Quality in Language Model Generations"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Tianlu이 [arXiv]에 게시한 'Jointly Reinforcing Diversity and Quality in Language Model Generations' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Language Models",{"className":"page__taxonomy-item","children":["#","Language Models"]}],["$","span","Diversity Optimization",{"className":"page__taxonomy-item","children":["#","Diversity Optimization"]}],["$","span","Quality Enhancement",{"className":"page__taxonomy-item","children":["#","Quality Enhancement"]}],["$","span","Semantic Clustering",{"className":"page__taxonomy-item","children":["#","Semantic Clustering"]}],["$","span","Post-training",{"className":"page__taxonomy-item","children":["#","Post-training"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}]]}]]}]]}],["$","article","2025-9-3-Improving-Large-Vision-and-Language-Models-by-Learning-from-a-Panel-of-Peers",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-Improving-Large-Vision-and-Language-Models-by-Learning-from-a-Panel-of-Peers/","children":"[논문리뷰] Improving Large Vision and Language Models by Learning from a Panel of Peers"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Simon Jenni이 [arXiv]에 게시한 'Improving Large Vision and Language Models by Learning from a Panel of Peers' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Vision and Language Models (LVLMs)",{"className":"page__taxonomy-item","children":["#","Large Vision and Language Models (LVLMs)"]}],["$","span","Self-Improvement",{"className":"page__taxonomy-item","children":["#","Self-Improvement"]}],["$","span","Peer Learning",{"className":"page__taxonomy-item","children":["#","Peer Learning"]}],["$","span","Preference Alignment",{"className":"page__taxonomy-item","children":["#","Preference Alignment"]}],["$","span","Reward Modeling",{"className":"page__taxonomy-item","children":["#","Reward Modeling"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Knowledge Transfer",{"className":"page__taxonomy-item","children":["#","Knowledge Transfer"]}]]}]]}]]}],["$","article","2025-9-3-Implicit-Actor-Critic-Coupling-via-a-Supervised-Learning-Framework-for-RLVR",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-Implicit-Actor-Critic-Coupling-via-a-Supervised-Learning-Framework-for-RLVR/","children":"[논문리뷰] Implicit Actor Critic Coupling via a Supervised Learning Framework for RLVR"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Lu Wang이 [arXiv]에 게시한 'Implicit Actor Critic Coupling via a Supervised Learning Framework for RLVR' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","RLVR",{"className":"page__taxonomy-item","children":["#","RLVR"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Actor-Critic",{"className":"page__taxonomy-item","children":["#","Actor-Critic"]}],["$","span","Supervised Learning",{"className":"page__taxonomy-item","children":["#","Supervised Learning"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Cross-Entropy Loss",{"className":"page__taxonomy-item","children":["#","Cross-Entropy Loss"]}]]}]]}]]}],["$","article","2025-9-3-GenCompositor-Generative-Video-Compositing-with-Diffusion-Transformer",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-GenCompositor-Generative-Video-Compositing-with-Diffusion-Transformer/","children":"[논문리뷰] GenCompositor: Generative Video Compositing with Diffusion Transformer"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Lingen Li이 [arXiv]에 게시한 'GenCompositor: Generative Video Compositing with Diffusion Transformer' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Compositing",{"className":"page__taxonomy-item","children":["#","Video Compositing"]}],["$","span","Diffusion Transformer",{"className":"page__taxonomy-item","children":["#","Diffusion Transformer"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Video Editing",{"className":"page__taxonomy-item","children":["#","Video Editing"]}],["$","span","Position Embedding",{"className":"page__taxonomy-item","children":["#","Position Embedding"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Masked Token Injection",{"className":"page__taxonomy-item","children":["#","Masked Token Injection"]}],["$","span","Video Harmonization",{"className":"page__taxonomy-item","children":["#","Video Harmonization"]}]]}]]}]]}],["$","article","2025-9-3-FlashAdventure-A-Benchmark-for-GUI-Agents-Solving-Full-Story-Arcs-in-Diverse-Adventure-Games",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-FlashAdventure-A-Benchmark-for-GUI-Agents-Solving-Full-Story-Arcs-in-Diverse-Adventure-Games/","children":"[논문리뷰] FlashAdventure: A Benchmark for GUI Agents Solving Full Story Arcs in Diverse Adventure Games"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Dongmin Park이 [arXiv]에 게시한 'FlashAdventure: A Benchmark for GUI Agents Solving Full Story Arcs in Diverse Adventure Games' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","GUI Agents",{"className":"page__taxonomy-item","children":["#","GUI Agents"]}],["$","span","Adventure Games",{"className":"page__taxonomy-item","children":["#","Adventure Games"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Full Story Arc",{"className":"page__taxonomy-item","children":["#","Full Story Arc"]}],["$","span","Observation-Behavior Gap",{"className":"page__taxonomy-item","children":["#","Observation-Behavior Gap"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Automated Evaluation",{"className":"page__taxonomy-item","children":["#","Automated Evaluation"]}]]}]]}]]}],["$","article","2025-9-3-FastFit-Accelerating-Multi-Reference-Virtual-Try-On-via-Cacheable-Diffusion-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-FastFit-Accelerating-Multi-Reference-Virtual-Try-On-via-Cacheable-Diffusion-Models/","children":"[논문리뷰] FastFit: Accelerating Multi-Reference Virtual Try-On via Cacheable Diffusion Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhen Wang이 [arXiv]에 게시한 'FastFit: Accelerating Multi-Reference Virtual Try-On via Cacheable Diffusion Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Virtual Try-On",{"className":"page__taxonomy-item","children":["#","Virtual Try-On"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Cacheable Architecture",{"className":"page__taxonomy-item","children":["#","Cacheable Architecture"]}],["$","span","Multi-Reference",{"className":"page__taxonomy-item","children":["#","Multi-Reference"]}],["$","span","Semi-Attention",{"className":"page__taxonomy-item","children":["#","Semi-Attention"]}],["$","span","Efficiency",{"className":"page__taxonomy-item","children":["#","Efficiency"]}],["$","span","Image Synthesis",{"className":"page__taxonomy-item","children":["#","Image Synthesis"]}]]}]]}]]}],["$","article","2025-9-3-Fantastic-Pretraining-Optimizers-and-Where-to-Find-Them",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-Fantastic-Pretraining-Optimizers-and-Where-to-Find-Them/","children":"[논문리뷰] Fantastic Pretraining Optimizers and Where to Find Them"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Percy Liang이 [arXiv]에 게시한 'Fantastic Pretraining Optimizers and Where to Find Them' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Deep Learning Optimizers",{"className":"page__taxonomy-item","children":["#","Deep Learning Optimizers"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Hyperparameter Tuning",{"className":"page__taxonomy-item","children":["#","Hyperparameter Tuning"]}],["$","span","Pretraining Speedup",{"className":"page__taxonomy-item","children":["#","Pretraining Speedup"]}],["$","span","Scaling Laws",{"className":"page__taxonomy-item","children":["#","Scaling Laws"]}],["$","span","AdamW",{"className":"page__taxonomy-item","children":["#","AdamW"]}],["$","span","Matrix-based Optimizers",{"className":"page__taxonomy-item","children":["#","Matrix-based Optimizers"]}],["$","span","Data-to-Model Ratio",{"className":"page__taxonomy-item","children":["#","Data-to-Model Ratio"]}]]}]]}]]}],["$","article","2025-9-3-ELV-Halluc-Benchmarking-Semantic-Aggregation-Hallucinations-in-Long-Video-Understanding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-ELV-Halluc-Benchmarking-Semantic-Aggregation-Hallucinations-in-Long-Video-Understanding/","children":"[논문리뷰] ELV-Halluc: Benchmarking Semantic Aggregation Hallucinations in Long Video Understanding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xuanyu Zheng이 [arXiv]에 게시한 'ELV-Halluc: Benchmarking Semantic Aggregation Hallucinations in Long Video Understanding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Long Video Understanding",{"className":"page__taxonomy-item","children":["#","Long Video Understanding"]}],["$","span","Hallucination",{"className":"page__taxonomy-item","children":["#","Hallucination"]}],["$","span","Semantic Aggregation",{"className":"page__taxonomy-item","children":["#","Semantic Aggregation"]}],["$","span","Video MLLM",{"className":"page__taxonomy-item","children":["#","Video MLLM"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","DPO",{"className":"page__taxonomy-item","children":["#","DPO"]}],["$","span","Positional Encoding",{"className":"page__taxonomy-item","children":["#","Positional Encoding"]}],["$","span","VideoQA",{"className":"page__taxonomy-item","children":["#","VideoQA"]}]]}]]}]]}],["$","article","2025-9-3-Discrete-Noise-Inversion-for-Next-scale-Autoregressive-Text-based-Image-Editing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-Discrete-Noise-Inversion-for-Next-scale-Autoregressive-Text-based-Image-Editing/","children":"[논문리뷰] Discrete Noise Inversion for Next-scale Autoregressive Text-based Image Editing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Amin Heyrani Nobar이 [arXiv]에 게시한 'Discrete Noise Inversion for Next-scale Autoregressive Text-based Image Editing' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Autoregressive Models",{"className":"page__taxonomy-item","children":["#","Autoregressive Models"]}],["$","span","Noise Inversion",{"className":"page__taxonomy-item","children":["#","Noise Inversion"]}],["$","span","Text-to-Image",{"className":"page__taxonomy-item","children":["#","Text-to-Image"]}],["$","span","Gumbel-max Trick",{"className":"page__taxonomy-item","children":["#","Gumbel-max Trick"]}],["$","span","Training-free",{"className":"page__taxonomy-item","children":["#","Training-free"]}],["$","span","Location-aware Argmax Inversion",{"className":"page__taxonomy-item","children":["#","Location-aware Argmax Inversion"]}]]}]]}]]}],["$","article","2025-9-3-DCPO-Dynamic-Clipping-Policy-Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-DCPO-Dynamic-Clipping-Policy-Optimization/","children":"[논문리뷰] DCPO: Dynamic Clipping Policy Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kai Lu이 [arXiv]에 게시한 'DCPO: Dynamic Clipping Policy Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Dynamic Clipping",{"className":"page__taxonomy-item","children":["#","Dynamic Clipping"]}],["$","span","Advantage Standardization",{"className":"page__taxonomy-item","children":["#","Advantage Standardization"]}],["$","span","RLVR",{"className":"page__taxonomy-item","children":["#","RLVR"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}]]}]]}]]}],["$","article","2025-9-3-C-DiffDet-Fusing-Global-Scene-Context-with-Generative-Denoising-for-High-Fidelity-Object-Detection",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-C-DiffDet-Fusing-Global-Scene-Context-with-Generative-Denoising-for-High-Fidelity-Object-Detection/","children":"[논문리뷰] C-DiffDet+: Fusing Global Scene Context with Generative Denoising for High-Fidelity Object Detection"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Vito Renó이 [arXiv]에 게시한 'C-DiffDet+: Fusing Global Scene Context with Generative Denoising for High-Fidelity Object Detection' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Object Detection",{"className":"page__taxonomy-item","children":["#","Object Detection"]}],["$","span","Diffusion Model",{"className":"page__taxonomy-item","children":["#","Diffusion Model"]}],["$","span","Global Scene Context",{"className":"page__taxonomy-item","children":["#","Global Scene Context"]}],["$","span","Context-Aware Fusion",{"className":"page__taxonomy-item","children":["#","Context-Aware Fusion"]}],["$","span","Fine-grained Detection",{"className":"page__taxonomy-item","children":["#","Fine-grained Detection"]}],["$","span","Automotive Damage Assessment",{"className":"page__taxonomy-item","children":["#","Automotive Damage Assessment"]}],["$","span","Generative Denoising",{"className":"page__taxonomy-item","children":["#","Generative Denoising"]}],["$","span","Cross-Attention",{"className":"page__taxonomy-item","children":["#","Cross-Attention"]}]]}]]}]]}],["$","article","2025-9-3-Benchmarking-Optimizers-for-Large-Language-Model-Pretraining",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-Benchmarking-Optimizers-for-Large-Language-Model-Pretraining/","children":"[논문리뷰] Benchmarking Optimizers for Large Language Model Pretraining"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"mjaggi이 [arXiv]에 게시한 'Benchmarking Optimizers for Large Language Model Pretraining' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Optimizers",{"className":"page__taxonomy-item","children":["#","LLM Optimizers"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Hyperparameter Tuning",{"className":"page__taxonomy-item","children":["#","Hyperparameter Tuning"]}],["$","span","AdamW",{"className":"page__taxonomy-item","children":["#","AdamW"]}],["$","span","AdEMAMix",{"className":"page__taxonomy-item","children":["#","AdEMAMix"]}],["$","span","MARS",{"className":"page__taxonomy-item","children":["#","MARS"]}],["$","span","Mixture of Experts (MoE)",{"className":"page__taxonomy-item","children":["#","Mixture of Experts (MoE)"]}],["$","span","Weight Decay",{"className":"page__taxonomy-item","children":["#","Weight Decay"]}]]}]]}]]}],["$","article","2025-9-3-Baichuan-M2-Scaling-Medical-Capability-with-Large-Verifier-System",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-Baichuan-M2-Scaling-Medical-Capability-with-Large-Verifier-System/","children":"[논문리뷰] Baichuan-M2: Scaling Medical Capability with Large Verifier System"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jayok6이 [arXiv]에 게시한 'Baichuan-M2: Scaling Medical Capability with Large Verifier System' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Medical AI",{"className":"page__taxonomy-item","children":["#","Medical AI"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Verifier System",{"className":"page__taxonomy-item","children":["#","Verifier System"]}],["$","span","Patient Simulator",{"className":"page__taxonomy-item","children":["#","Patient Simulator"]}],["$","span","Clinical Rubrics",{"className":"page__taxonomy-item","children":["#","Clinical Rubrics"]}],["$","span","Baichuan-M2",{"className":"page__taxonomy-item","children":["#","Baichuan-M2"]}],["$","span","HealthBench",{"className":"page__taxonomy-item","children":["#","HealthBench"]}]]}]]}]]}],["$","article","2025-9-3-Attributes-as-Textual-Genes-Leveraging-LLMs-as-Genetic-Algorithm-Simulators-for-Conditional-Synthetic-Data-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-Attributes-as-Textual-Genes-Leveraging-LLMs-as-Genetic-Algorithm-Simulators-for-Conditional-Synthetic-Data-Generation/","children":"[논문리뷰] Attributes as Textual Genes: Leveraging LLMs as Genetic Algorithm Simulators for Conditional Synthetic Data Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiaolei Huang이 [arXiv]에 게시한 'Attributes as Textual Genes: Leveraging LLMs as Genetic Algorithm Simulators for Conditional Synthetic Data Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Synthetic Data Generation",{"className":"page__taxonomy-item","children":["#","Synthetic Data Generation"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Genetic Algorithms",{"className":"page__taxonomy-item","children":["#","Genetic Algorithms"]}],["$","span","Textual Data Augmentation",{"className":"page__taxonomy-item","children":["#","Textual Data Augmentation"]}],["$","span","Active Learning",{"className":"page__taxonomy-item","children":["#","Active Learning"]}],["$","span","NLP",{"className":"page__taxonomy-item","children":["#","NLP"]}],["$","span","Data Diversity",{"className":"page__taxonomy-item","children":["#","Data Diversity"]}]]}]]}]]}],["$","article","2025-9-3-AMBEDKAR-A-Multi-level-Bias-Elimination-through-a-Decoding-Approach-with-Knowledge-Augmentation-for-Robust-Constitutional-Alignment-of-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-AMBEDKAR-A-Multi-level-Bias-Elimination-through-a-Decoding-Approach-with-Knowledge-Augmentation-for-Robust-Constitutional-Alignment-of-Language-Models/","children":"[논문리뷰] AMBEDKAR-A Multi-level Bias Elimination through a Decoding Approach with Knowledge Augmentation for Robust Constitutional Alignment of Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Rahul Karthikeyan이 [arXiv]에 게시한 'AMBEDKAR-A Multi-level Bias Elimination through a Decoding Approach with Knowledge Augmentation for Robust Constitutional Alignment of Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Bias Mitigation",{"className":"page__taxonomy-item","children":["#","Bias Mitigation"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Speculative Decoding",{"className":"page__taxonomy-item","children":["#","Speculative Decoding"]}],["$","span","Constitutional AI",{"className":"page__taxonomy-item","children":["#","Constitutional AI"]}],["$","span","Fairness",{"className":"page__taxonomy-item","children":["#","Fairness"]}],["$","span","Inference-Time Control",{"className":"page__taxonomy-item","children":["#","Inference-Time Control"]}],["$","span","Indian Sociocultural Context",{"className":"page__taxonomy-item","children":["#","Indian Sociocultural Context"]}]]}]]}]]}],["$","article","2025-9-2-UI-Level-Evaluation-of-ALLaM-34B-Measuring-an-Arabic-Centric-LLM-via-HUMAIN-Chat",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-2-UI-Level-Evaluation-of-ALLaM-34B-Measuring-an-Arabic-Centric-LLM-via-HUMAIN-Chat/","children":"[논문리뷰] UI-Level Evaluation of ALLaM 34B: Measuring an Arabic-Centric LLM via HUMAIN Chat"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Omartificial-Intelligence-Space이 [arXiv]에 게시한 'UI-Level Evaluation of ALLaM 34B: Measuring an Arabic-Centric LLM via HUMAIN Chat' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-02 13:01:41+0900","children":"2025년 9월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Arabic LLM",{"className":"page__taxonomy-item","children":["#","Arabic LLM"]}],["$","span","UI-level Evaluation",{"className":"page__taxonomy-item","children":["#","UI-level Evaluation"]}],["$","span","ALLaM 34B",{"className":"page__taxonomy-item","children":["#","ALLaM 34B"]}],["$","span","HUMAIN Chat",{"className":"page__taxonomy-item","children":["#","HUMAIN Chat"]}],["$","span","Dialectal Arabic",{"className":"page__taxonomy-item","children":["#","Dialectal Arabic"]}],["$","span","LLM as a Judge",{"className":"page__taxonomy-item","children":["#","LLM as a Judge"]}],["$","span","Safety Evaluation",{"className":"page__taxonomy-item","children":["#","Safety Evaluation"]}]]}]]}]]}],["$","article","2025-9-2-T2R-bench-A-Benchmark-for-Generating-Article-Level-Reports-from-Real-World-Industrial-Tables",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-2-T2R-bench-A-Benchmark-for-Generating-Article-Level-Reports-from-Real-World-Industrial-Tables/","children":"[논문리뷰] T2R-bench: A Benchmark for Generating Article-Level Reports from Real World Industrial Tables"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yu Zhao이 [arXiv]에 게시한 'T2R-bench: A Benchmark for Generating Article-Level Reports from Real World Industrial Tables' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-02 13:01:41+0900","children":"2025년 9월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Table-to-Report Generation",{"className":"page__taxonomy-item","children":["#","Table-to-Report Generation"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Benchmark Dataset",{"className":"page__taxonomy-item","children":["#","Benchmark Dataset"]}],["$","span","Industrial Applications",{"className":"page__taxonomy-item","children":["#","Industrial Applications"]}],["$","span","Table Reasoning",{"className":"page__taxonomy-item","children":["#","Table Reasoning"]}],["$","span","Evaluation Metrics",{"className":"page__taxonomy-item","children":["#","Evaluation Metrics"]}],["$","span","Real-world Data",{"className":"page__taxonomy-item","children":["#","Real-world Data"]}]]}]]}]]}],["$","article","2025-9-2-PVPO-Pre-Estimated-Value-Based-Policy-Optimization-for-Agentic-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-2-PVPO-Pre-Estimated-Value-Based-Policy-Optimization-for-Agentic-Reasoning/","children":"[논문리뷰] PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuewei Zhang이 [arXiv]에 게시한 'PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-02 13:01:41+0900","children":"2025년 9월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Critic-Free RL",{"className":"page__taxonomy-item","children":["#","Critic-Free RL"]}],["$","span","Agentic Reasoning",{"className":"page__taxonomy-item","children":["#","Agentic Reasoning"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Advantage Estimation",{"className":"page__taxonomy-item","children":["#","Advantage Estimation"]}],["$","span","Group Sampling",{"className":"page__taxonomy-item","children":["#","Group Sampling"]}],["$","span","Static Value Estimation",{"className":"page__taxonomy-item","children":["#","Static Value Estimation"]}]]}]]}]]}],["$","article","2025-9-2-No-Label-Left-Behind-A-Unified-Surface-Defect-Detection-Model-for-all-Supervision-Regimes",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-2-No-Label-Left-Behind-A-Unified-Surface-Defect-Detection-Model-for-all-Supervision-Regimes/","children":"[논문리뷰] No Label Left Behind: A Unified Surface Defect Detection Model for all Supervision Regimes"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Danijel Skočaj이 [arXiv]에 게시한 'No Label Left Behind: A Unified Surface Defect Detection Model for all Supervision Regimes' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-02 13:01:41+0900","children":"2025년 9월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Surface Defect Detection",{"className":"page__taxonomy-item","children":["#","Surface Defect Detection"]}],["$","span","Anomaly Detection",{"className":"page__taxonomy-item","children":["#","Anomaly Detection"]}],["$","span","Mixed Supervision",{"className":"page__taxonomy-item","children":["#","Mixed Supervision"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}],["$","span","Industrial Inspection",{"className":"page__taxonomy-item","children":["#","Industrial Inspection"]}],["$","span","Unified Model",{"className":"page__taxonomy-item","children":["#","Unified Model"]}]]}]]}]]}],["$","article","2025-9-2-How-Can-Input-Reformulation-Improve-Tool-Usage-Accuracy-in-a-Complex-Dynamic-Environment-A-Study-on-τ-bench",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-2-How-Can-Input-Reformulation-Improve-Tool-Usage-Accuracy-in-a-Complex-Dynamic-Environment-A-Study-on-τ-bench/","children":"[논문리뷰] How Can Input Reformulation Improve Tool Usage Accuracy in a Complex Dynamic Environment? A Study on τ-bench"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jayanth Srinivasa이 [arXiv]에 게시한 'How Can Input Reformulation Improve Tool Usage Accuracy in a Complex Dynamic Environment? A Study on τ-bench' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-02 13:01:41+0900","children":"2025년 9월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Function Calling",{"className":"page__taxonomy-item","children":["#","Function Calling"]}],["$","span","Input Reformulation",{"className":"page__taxonomy-item","children":["#","Input Reformulation"]}],["$","span","Dynamic Environments",{"className":"page__taxonomy-item","children":["#","Dynamic Environments"]}],["$","span","τ-bench",{"className":"page__taxonomy-item","children":["#","τ-bench"]}],["$","span","Context Engineering",{"className":"page__taxonomy-item","children":["#","Context Engineering"]}],["$","span","Multi-Agent Framework",{"className":"page__taxonomy-item","children":["#","Multi-Agent Framework"]}]]}]]}]]}],["$","article","2025-9-2-From-reactive-to-cognitive-brain-inspired-spatial-intelligence-for-embodied-agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-2-From-reactive-to-cognitive-brain-inspired-spatial-intelligence-for-embodied-agents/","children":"[논문리뷰] From reactive to cognitive: brain-inspired spatial intelligence for embodied agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Songming Liu이 [arXiv]에 게시한 'From reactive to cognitive: brain-inspired spatial intelligence for embodied agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-02 13:01:41+0900","children":"2025년 9월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Spatial Cognition",{"className":"page__taxonomy-item","children":["#","Spatial Cognition"]}],["$","span","Embodied Agents",{"className":"page__taxonomy-item","children":["#","Embodied Agents"]}],["$","span","Brain-inspired AI",{"className":"page__taxonomy-item","children":["#","Brain-inspired AI"]}],["$","span","Cognitive Map",{"className":"page__taxonomy-item","children":["#","Cognitive Map"]}],["$","span","Spatial Memory",{"className":"page__taxonomy-item","children":["#","Spatial Memory"]}],["$","span","MLLMs",{"className":"page__taxonomy-item","children":["#","MLLMs"]}],["$","span","Navigation",{"className":"page__taxonomy-item","children":["#","Navigation"]}]]}]]}]]}],["$","article","2025-9-1-UItron-Foundational-GUI-Agent-with-Advanced-Perception-and-Planning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-1-UItron-Foundational-GUI-Agent-with-Advanced-Perception-and-Planning/","children":"[논문리뷰] UItron: Foundational GUI Agent with Advanced Perception and Planning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yufeng Zhong이 [arXiv]에 게시한 'UItron: Foundational GUI Agent with Advanced Perception and Planning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-01 13:14:34+0900","children":"2025년 9월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","GUI Agent",{"className":"page__taxonomy-item","children":["#","GUI Agent"]}],["$","span","Foundational Model",{"className":"page__taxonomy-item","children":["#","Foundational Model"]}],["$","span","Multimodal LLM",{"className":"page__taxonomy-item","children":["#","Multimodal LLM"]}],["$","span","Perception",{"className":"page__taxonomy-item","children":["#","Perception"]}],["$","span","Planning",{"className":"page__taxonomy-item","children":["#","Planning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Data Engineering",{"className":"page__taxonomy-item","children":["#","Data Engineering"]}],["$","span","Chinese App Scenarios",{"className":"page__taxonomy-item","children":["#","Chinese App Scenarios"]}]]}]]}]]}],["$","article","2025-9-1-TiKMiX-Take-Data-Influence-into-Dynamic-Mixture-for-Language-Model-Pre-training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-1-TiKMiX-Take-Data-Influence-into-Dynamic-Mixture-for-Language-Model-Pre-training/","children":"[논문리뷰] TiKMiX: Take Data Influence into Dynamic Mixture for Language Model Pre-training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiyao Deng이 [arXiv]에 게시한 'TiKMiX: Take Data Influence into Dynamic Mixture for Language Model Pre-training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-01 13:14:34+0900","children":"2025년 9월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Language Model Pre-training",{"className":"page__taxonomy-item","children":["#","Language Model Pre-training"]}],["$","span","Dynamic Data Mixing",{"className":"page__taxonomy-item","children":["#","Dynamic Data Mixing"]}],["$","span","Data Influence",{"className":"page__taxonomy-item","children":["#","Data Influence"]}],["$","span","Group Influence",{"className":"page__taxonomy-item","children":["#","Group Influence"]}],["$","span","Optimization",{"className":"page__taxonomy-item","children":["#","Optimization"]}],["$","span","Regression Model",{"className":"page__taxonomy-item","children":["#","Regression Model"]}],["$","span","LLM Training",{"className":"page__taxonomy-item","children":["#","LLM Training"]}]]}]]}]]}],["$","article","2025-9-1-Think-in-Games-Learning-to-Reason-in-Games-via-Reinforcement-Learning-with-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-1-Think-in-Games-Learning-to-Reason-in-Games-via-Reinforcement-Learning-with-Large-Language-Models/","children":"[논문리뷰] Think in Games: Learning to Reason in Games via Reinforcement Learning with Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yifan Lu이 [arXiv]에 게시한 'Think in Games: Learning to Reason in Games via Reinforcement Learning with Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-01 13:14:34+0900","children":"2025년 9월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Game AI",{"className":"page__taxonomy-item","children":["#","Game AI"]}],["$","span","Procedural Knowledge",{"className":"page__taxonomy-item","children":["#","Procedural Knowledge"]}],["$","span","Declarative Knowledge",{"className":"page__taxonomy-item","children":["#","Declarative Knowledge"]}],["$","span","Explainable AI",{"className":"page__taxonomy-item","children":["#","Explainable AI"]}],["$","span","Strategic Decision-Making",{"className":"page__taxonomy-item","children":["#","Strategic Decision-Making"]}]]}]]}]]}],["$","article","2025-9-1-TalkVid-A-Large-Scale-Diversified-Dataset-for-Audio-Driven-Talking-Head-Synthesis",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-1-TalkVid-A-Large-Scale-Diversified-Dataset-for-Audio-Driven-Talking-Head-Synthesis/","children":"[논문리뷰] TalkVid: A Large-Scale Diversified Dataset for Audio-Driven Talking Head Synthesis"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Pengcheng Chen이 [arXiv]에 게시한 'TalkVid: A Large-Scale Diversified Dataset for Audio-Driven Talking Head Synthesis' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-01 13:14:34+0900","children":"2025년 9월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Audio-Driven Talking Head Synthesis",{"className":"page__taxonomy-item","children":["#","Audio-Driven Talking Head Synthesis"]}],["$","span","Large-Scale Dataset",{"className":"page__taxonomy-item","children":["#","Large-Scale Dataset"]}],["$","span","Data Diversity",{"className":"page__taxonomy-item","children":["#","Data Diversity"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Evaluation Benchmark",{"className":"page__taxonomy-item","children":["#","Evaluation Benchmark"]}],["$","span","Generalization Gap",{"className":"page__taxonomy-item","children":["#","Generalization Gap"]}],["$","span","Algorithmic Fairness",{"className":"page__taxonomy-item","children":["#","Algorithmic Fairness"]}]]}]]}]]}],["$","article","2025-9-1-R-4B-Incentivizing-General-Purpose-Auto-Thinking-Capability-in-MLLMs-via-Bi-Mode-Annealing-and-Reinforce-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-1-R-4B-Incentivizing-General-Purpose-Auto-Thinking-Capability-in-MLLMs-via-Bi-Mode-Annealing-and-Reinforce-Learning/","children":"[논문리뷰] R-4B: Incentivizing General-Purpose Auto-Thinking Capability in MLLMs via Bi-Mode Annealing and Reinforce Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Han Hu이 [arXiv]에 게시한 'R-4B: Incentivizing General-Purpose Auto-Thinking Capability in MLLMs via Bi-Mode Annealing and Reinforce Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-01 13:14:34+0900","children":"2025년 9월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models (MLLMs)"]}],["$","span","Auto-Thinking",{"className":"page__taxonomy-item","children":["#","Auto-Thinking"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Bi-mode Annealing",{"className":"page__taxonomy-item","children":["#","Bi-mode Annealing"]}],["$","span","Bi-mode Policy Optimization (BPO)",{"className":"page__taxonomy-item","children":["#","Bi-mode Policy Optimization (BPO)"]}],["$","span","General-Purpose AI",{"className":"page__taxonomy-item","children":["#","General-Purpose AI"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Efficiency",{"className":"page__taxonomy-item","children":["#","Efficiency"]}]]}]]}]]}],["$","article","2025-9-1-Morae-Proactively-Pausing-UI-Agents-for-User-Choices",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-1-Morae-Proactively-Pausing-UI-Agents-for-User-Choices/","children":"[논문리뷰] Morae: Proactively Pausing UI Agents for User Choices"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Amy Pavel이 [arXiv]에 게시한 'Morae: Proactively Pausing UI Agents for User Choices' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-01 13:14:34+0900","children":"2025년 9월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","UI Agents",{"className":"page__taxonomy-item","children":["#","UI Agents"]}],["$","span","Accessibility",{"className":"page__taxonomy-item","children":["#","Accessibility"]}],["$","span","Human-Agent Interaction",{"className":"page__taxonomy-item","children":["#","Human-Agent Interaction"]}],["$","span","Mixed-Initiative AI",{"className":"page__taxonomy-item","children":["#","Mixed-Initiative AI"]}],["$","span","Large Multimodal Models",{"className":"page__taxonomy-item","children":["#","Large Multimodal Models"]}],["$","span","Proactive AI",{"className":"page__taxonomy-item","children":["#","Proactive AI"]}],["$","span","User Choice",{"className":"page__taxonomy-item","children":["#","User Choice"]}],["$","span","Blind and Low-Vision Users",{"className":"page__taxonomy-item","children":["#","Blind and Low-Vision Users"]}]]}]]}]]}],["$","article","2025-9-1-Mimicking-the-Physicists-EyeA-VLM-centric-Approach-for-Physics-Formula-Discovery",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-1-Mimicking-the-Physicists-EyeA-VLM-centric-Approach-for-Physics-Formula-Discovery/","children":"[논문리뷰] Mimicking the Physicist's Eye:A VLM-centric Approach for Physics Formula Discovery"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wenjie Zhou이 [arXiv]에 게시한 'Mimicking the Physicist's Eye:A VLM-centric Approach for Physics Formula Discovery' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-01 13:14:34+0900","children":"2025년 9월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Physics Formula Discovery",{"className":"page__taxonomy-item","children":["#","Physics Formula Discovery"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Symbolic Regression",{"className":"page__taxonomy-item","children":["#","Symbolic Regression"]}],["$","span","Causal Chain of Thought",{"className":"page__taxonomy-item","children":["#","Causal Chain of Thought"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}]]}]]}]]}],["$","article","2025-9-1-HERMES-Human-to-Robot-Embodied-Learning-from-Multi-Source-Motion-Data-for-Mobile-Dexterous-Manipulation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-1-HERMES-Human-to-Robot-Embodied-Learning-from-Multi-Source-Motion-Data-for-Mobile-Dexterous-Manipulation/","children":"[논문리뷰] HERMES: Human-to-Robot Embodied Learning from Multi-Source Motion Data for Mobile Dexterous Manipulation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Tianhai Liang이 [arXiv]에 게시한 'HERMES: Human-to-Robot Embodied Learning from Multi-Source Motion Data for Mobile Dexterous Manipulation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-01 13:14:34+0900","children":"2025년 9월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Dexterous Manipulation",{"className":"page__taxonomy-item","children":["#","Dexterous Manipulation"]}],["$","span","Mobile Manipulation",{"className":"page__taxonomy-item","children":["#","Mobile Manipulation"]}],["$","span","Human-to-Robot Learning",{"className":"page__taxonomy-item","children":["#","Human-to-Robot Learning"]}],["$","span","Sim2Real",{"className":"page__taxonomy-item","children":["#","Sim2Real"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Depth Image",{"className":"page__taxonomy-item","children":["#","Depth Image"]}],["$","span","Visual Localization",{"className":"page__taxonomy-item","children":["#","Visual Localization"]}],["$","span","Bimanual Control",{"className":"page__taxonomy-item","children":["#","Bimanual Control"]}]]}]]}]]}],["$","article","2025-9-1-EmbodiedOneVision-Interleaved-Vision-Text-Action-Pretraining-for-General-Robot-Control",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-1-EmbodiedOneVision-Interleaved-Vision-Text-Action-Pretraining-for-General-Robot-Control/","children":"[논문리뷰] EmbodiedOneVision: Interleaved Vision-Text-Action Pretraining for General Robot Control"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhaoqing Chen이 [arXiv]에 게시한 'EmbodiedOneVision: Interleaved Vision-Text-Action Pretraining for General Robot Control' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-01 13:14:34+0900","children":"2025년 9월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Robot Control",{"className":"page__taxonomy-item","children":["#","Robot Control"]}],["$","span","Vision-Language-Action Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action Models"]}],["$","span","Multimodal Pretraining",{"className":"page__taxonomy-item","children":["#","Multimodal Pretraining"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Real-world Robotics",{"className":"page__taxonomy-item","children":["#","Real-world Robotics"]}]]}]]}]]}],["$","article","2025-9-1-Efficient-Code-Embeddings-from-Code-Generation-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-1-Efficient-Code-Embeddings-from-Code-Generation-Models/","children":"[논문리뷰] Efficient Code Embeddings from Code Generation Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Han Xiao이 [arXiv]에 게시한 'Efficient Code Embeddings from Code Generation Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-01 13:14:34+0900","children":"2025년 9월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Code Embeddings",{"className":"page__taxonomy-item","children":["#","Code Embeddings"]}],["$","span","Code Generation Models",{"className":"page__taxonomy-item","children":["#","Code Generation Models"]}],["$","span","Autoregressive Backbones",{"className":"page__taxonomy-item","children":["#","Autoregressive Backbones"]}],["$","span","Last-Token Pooling",{"className":"page__taxonomy-item","children":["#","Last-Token Pooling"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","MTEB Benchmark",{"className":"page__taxonomy-item","children":["#","MTEB Benchmark"]}]]}]]}]]}],["$","article","2025-9-1-Droplet3D-Commonsense-Priors-from-Videos-Facilitate-3D-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-1-Droplet3D-Commonsense-Priors-from-Videos-Facilitate-3D-Generation/","children":"[논문리뷰] Droplet3D: Commonsense Priors from Videos Facilitate 3D Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Qi Jia이 [arXiv]에 게시한 'Droplet3D: Commonsense Priors from Videos Facilitate 3D Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-01 13:14:34+0900","children":"2025년 9월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Generation",{"className":"page__taxonomy-item","children":["#","3D Generation"]}],["$","span","Video Diffusion Models",{"className":"page__taxonomy-item","children":["#","Video Diffusion Models"]}],["$","span","Spatial Consistency",{"className":"page__taxonomy-item","children":["#","Spatial Consistency"]}],["$","span","Semantic Knowledge",{"className":"page__taxonomy-item","children":["#","Semantic Knowledge"]}],["$","span","Multi-view Synthesis",{"className":"page__taxonomy-item","children":["#","Multi-view Synthesis"]}],["$","span","Large-scale Dataset",{"className":"page__taxonomy-item","children":["#","Large-scale Dataset"]}],["$","span","Image-to-3D",{"className":"page__taxonomy-item","children":["#","Image-to-3D"]}],["$","span","Text-to-3D",{"className":"page__taxonomy-item","children":["#","Text-to-3D"]}]]}]]}]]}],["$","article","2025-9-1-CLIPSym-Delving-into-Symmetry-Detection-with-CLIP",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-1-CLIPSym-Delving-into-Symmetry-Detection-with-CLIP/","children":"[논문리뷰] CLIPSym: Delving into Symmetry Detection with CLIP"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Raymond A. Yeh이 [arXiv]에 게시한 'CLIPSym: Delving into Symmetry Detection with CLIP' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-01 13:14:34+0900","children":"2025년 9월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Symmetry Detection",{"className":"page__taxonomy-item","children":["#","Symmetry Detection"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","CLIP",{"className":"page__taxonomy-item","children":["#","CLIP"]}],["$","span","Equivariant Networks",{"className":"page__taxonomy-item","children":["#","Equivariant Networks"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","Geometric Deep Learning",{"className":"page__taxonomy-item","children":["#","Geometric Deep Learning"]}]]}]]}]]}],["$","article","2025-9-1-AHELM-A-Holistic-Evaluation-of-Audio-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-1-AHELM-A-Holistic-Evaluation-of-Audio-Language-Models/","children":"[논문리뷰] AHELM: A Holistic Evaluation of Audio-Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Siwei Yang이 [arXiv]에 게시한 'AHELM: A Holistic Evaluation of Audio-Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-01 13:14:34+0900","children":"2025년 9월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Audio-Language Models",{"className":"page__taxonomy-item","children":["#","Audio-Language Models"]}],["$","span","Holistic Evaluation",{"className":"page__taxonomy-item","children":["#","Holistic Evaluation"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Multimodality",{"className":"page__taxonomy-item","children":["#","Multimodality"]}],["$","span","Fairness",{"className":"page__taxonomy-item","children":["#","Fairness"]}],["$","span","Robustness",{"className":"page__taxonomy-item","children":["#","Robustness"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Bias Detection",{"className":"page__taxonomy-item","children":["#","Bias Detection"]}]]}]]}]]}],["$","article","2025-9-1-A-Survey-of-Scientific-Large-Language-Models-From-Data-Foundations-to-Agent-Frontiers",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-1-A-Survey-of-Scientific-Large-Language-Models-From-Data-Foundations-to-Agent-Frontiers/","children":"[논문리뷰] A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiamin Wu이 [arXiv]에 게시한 'A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-01 13:14:34+0900","children":"2025년 9월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Scientific LLMs",{"className":"page__taxonomy-item","children":["#","Scientific LLMs"]}],["$","span","AI for Science",{"className":"page__taxonomy-item","children":["#","AI for Science"]}],["$","span","Scientific Data",{"className":"page__taxonomy-item","children":["#","Scientific Data"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Multimodal Integration",{"className":"page__taxonomy-item","children":["#","Multimodal Integration"]}],["$","span","Knowledge Representation",{"className":"page__taxonomy-item","children":["#","Knowledge Representation"]}],["$","span","Autonomous Discovery",{"className":"page__taxonomy-item","children":["#","Autonomous Discovery"]}],["$","span","Data Ecosystems",{"className":"page__taxonomy-item","children":["#","Data Ecosystems"]}]]}]]}]]}],["$","article","2025-9-1-A-S-E-A-Repository-Level-Benchmark-for-Evaluating-Security-in-AI-Generated-Code",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-1-A-S-E-A-Repository-Level-Benchmark-for-Evaluating-Security-in-AI-Generated-Code/","children":"[논문리뷰] A.S.E: A Repository-Level Benchmark for Evaluating Security in AI-Generated Code"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Libo Chen이 [arXiv]에 게시한 'A.S.E: A Repository-Level Benchmark for Evaluating Security in AI-Generated Code' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-01 13:14:34+0900","children":"2025년 9월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI-Generated Code Security",{"className":"page__taxonomy-item","children":["#","AI-Generated Code Security"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Repository-Level Benchmark",{"className":"page__taxonomy-item","children":["#","Repository-Level Benchmark"]}],["$","span","Code Security",{"className":"page__taxonomy-item","children":["#","Code Security"]}],["$","span","Vulnerability Detection",{"className":"page__taxonomy-item","children":["#","Vulnerability Detection"]}],["$","span","Static Analysis",{"className":"page__taxonomy-item","children":["#","Static Analysis"]}],["$","span","Reproducibility",{"className":"page__taxonomy-item","children":["#","Reproducibility"]}],["$","span","Context-Awareness",{"className":"page__taxonomy-item","children":["#","Context-Awareness"]}]]}]]}]]}],["$","article","2025-8-29-rStar2-Agent-Agentic-Reasoning-Technical-Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-rStar2-Agent-Agentic-Reasoning-Technical-Report/","children":"[논문리뷰] rStar2-Agent: Agentic Reasoning Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Weijiang Xu이 [arXiv]에 게시한 'rStar2-Agent: Agentic Reasoning Technical Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Agentic Reinforcement Learning"]}],["$","span","Math Reasoning",{"className":"page__taxonomy-item","children":["#","Math Reasoning"]}],["$","span","Code Interpreter",{"className":"page__taxonomy-item","children":["#","Code Interpreter"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","GRPO-RoC",{"className":"page__taxonomy-item","children":["#","GRPO-RoC"]}],["$","span","LLM Training Efficiency",{"className":"page__taxonomy-item","children":["#","LLM Training Efficiency"]}],["$","span","Self-Reflection",{"className":"page__taxonomy-item","children":["#","Self-Reflection"]}]]}]]}]]}],["$","article","2025-8-29-USO-Unified-Style-and-Subject-Driven-Generation-via-Disentangled-and-Reward-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-USO-Unified-Style-and-Subject-Driven-Generation-via-Disentangled-and-Reward-Learning/","children":"[논문리뷰] USO: Unified Style and Subject-Driven Generation via Disentangled and Reward Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiahe Tian이 [arXiv]에 게시한 'USO: Unified Style and Subject-Driven Generation via Disentangled and Reward Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Style-Driven Generation",{"className":"page__taxonomy-item","children":["#","Style-Driven Generation"]}],["$","span","Subject-Driven Generation",{"className":"page__taxonomy-item","children":["#","Subject-Driven Generation"]}],["$","span","Disentangled Representation",{"className":"page__taxonomy-item","children":["#","Disentangled Representation"]}],["$","span","Reward Learning",{"className":"page__taxonomy-item","children":["#","Reward Learning"]}],["$","span","Cross-Task Learning",{"className":"page__taxonomy-item","children":["#","Cross-Task Learning"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Image Customization",{"className":"page__taxonomy-item","children":["#","Image Customization"]}],["$","span","Unified Framework",{"className":"page__taxonomy-item","children":["#","Unified Framework"]}]]}]]}]]}],["$","article","2025-8-29-Turning-the-Spell-Around-Lightweight-Alignment-Amplification-via-Rank-One-Safety-Injection",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-Turning-the-Spell-Around-Lightweight-Alignment-Amplification-via-Rank-One-Safety-Injection/","children":"[논문리뷰] Turning the Spell Around: Lightweight Alignment Amplification via Rank-One Safety Injection"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Bernard Ghanem이 [arXiv]에 게시한 'Turning the Spell Around: Lightweight Alignment Amplification via Rank-One Safety Injection' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Safety",{"className":"page__taxonomy-item","children":["#","LLM Safety"]}],["$","span","Alignment Amplification",{"className":"page__taxonomy-item","children":["#","Alignment Amplification"]}],["$","span","Rank-One Update",{"className":"page__taxonomy-item","children":["#","Rank-One Update"]}],["$","span","Mechanistic Interpretability",{"className":"page__taxonomy-item","children":["#","Mechanistic Interpretability"]}],["$","span","Weight Steering",{"className":"page__taxonomy-item","children":["#","Weight Steering"]}],["$","span","Jailbreak Robustness",{"className":"page__taxonomy-item","children":["#","Jailbreak Robustness"]}],["$","span","Fine-tuning-free",{"className":"page__taxonomy-item","children":["#","Fine-tuning-free"]}],["$","span","Safety Injection",{"className":"page__taxonomy-item","children":["#","Safety Injection"]}]]}]]}]]}],["$","article","2025-8-29-TCIA-A-Task-Centric-Instruction-Augmentation-Method-for-Instruction-Finetuning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-TCIA-A-Task-Centric-Instruction-Augmentation-Method-for-Instruction-Finetuning/","children":"[논문리뷰] TCIA: A Task-Centric Instruction Augmentation Method for Instruction Finetuning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Simin Ma이 [arXiv]에 게시한 'TCIA: A Task-Centric Instruction Augmentation Method for Instruction Finetuning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Instruction Augmentation",{"className":"page__taxonomy-item","children":["#","Instruction Augmentation"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Task-Centric",{"className":"page__taxonomy-item","children":["#","Task-Centric"]}],["$","span","Data Diversity",{"className":"page__taxonomy-item","children":["#","Data Diversity"]}],["$","span","Task Alignment",{"className":"page__taxonomy-item","children":["#","Task Alignment"]}],["$","span","Breadth-First Search",{"className":"page__taxonomy-item","children":["#","Breadth-First Search"]}],["$","span","Constraint Generation",{"className":"page__taxonomy-item","children":["#","Constraint Generation"]}]]}]]}]]}],["$","article","2025-8-29-ROSE-Remove-Objects-with-Side-Effects-in-Videos",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-ROSE-Remove-Objects-with-Side-Effects-in-Videos/","children":"[논문리뷰] ROSE: Remove Objects with Side Effects in Videos"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hantang Liu이 [arXiv]에 게시한 'ROSE: Remove Objects with Side Effects in Videos' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Object Removal",{"className":"page__taxonomy-item","children":["#","Video Object Removal"]}],["$","span","Side Effects",{"className":"page__taxonomy-item","children":["#","Side Effects"]}],["$","span","3D Rendering",{"className":"page__taxonomy-item","children":["#","3D Rendering"]}],["$","span","Diffusion Transformer",{"className":"page__taxonomy-item","children":["#","Diffusion Transformer"]}],["$","span","Video Inpainting",{"className":"page__taxonomy-item","children":["#","Video Inpainting"]}],["$","span","Synthetic Data",{"className":"page__taxonomy-item","children":["#","Synthetic Data"]}],["$","span","Difference Mask",{"className":"page__taxonomy-item","children":["#","Difference Mask"]}]]}]]}]]}],["$","article","2025-8-29-Provable-Benefits-of-In-Tool-Learning-for-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-Provable-Benefits-of-In-Tool-Learning-for-Large-Language-Models/","children":"[논문리뷰] Provable Benefits of In-Tool Learning for Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Vivien Cabannes이 [arXiv]에 게시한 'Provable Benefits of In-Tool Learning for Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","In-Tool Learning",{"className":"page__taxonomy-item","children":["#","In-Tool Learning"]}],["$","span","In-Weight Learning",{"className":"page__taxonomy-item","children":["#","In-Weight Learning"]}],["$","span","Factual Recall",{"className":"page__taxonomy-item","children":["#","Factual Recall"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","Scaling Laws",{"className":"page__taxonomy-item","children":["#","Scaling Laws"]}],["$","span","Parameter Efficiency",{"className":"page__taxonomy-item","children":["#","Parameter Efficiency"]}],["$","span","Catastrophic Forgetting",{"className":"page__taxonomy-item","children":["#","Catastrophic Forgetting"]}]]}]]}]]}],["$","article","2025-8-29-Pref-GRPO-Pairwise-Preference-Reward-based-GRPO-for-Stable-Text-to-Image-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-Pref-GRPO-Pairwise-Preference-Reward-based-GRPO-for-Stable-Text-to-Image-Reinforcement-Learning/","children":"[논문리뷰] Pref-GRPO: Pairwise Preference Reward-based GRPO for Stable Text-to-Image Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiazi Bu이 [arXiv]에 게시한 'Pref-GRPO: Pairwise Preference Reward-based GRPO for Stable Text-to-Image Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","GRPO",{"className":"page__taxonomy-item","children":["#","GRPO"]}],["$","span","Reward Hacking",{"className":"page__taxonomy-item","children":["#","Reward Hacking"]}],["$","span","Pairwise Preference",{"className":"page__taxonomy-item","children":["#","Pairwise Preference"]}],["$","span","Reward Model",{"className":"page__taxonomy-item","children":["#","Reward Model"]}],["$","span","Stable Optimization",{"className":"page__taxonomy-item","children":["#","Stable Optimization"]}],["$","span","UniGenBench",{"className":"page__taxonomy-item","children":["#","UniGenBench"]}]]}]]}]]}],["$","article","2025-8-29-Persuasion-Dynamics-in-LLMs-Investigating-Robustness-and-Adaptability-in-Knowledge-and-Safety-with-DuET-PD",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-Persuasion-Dynamics-in-LLMs-Investigating-Robustness-and-Adaptability-in-Knowledge-and-Safety-with-DuET-PD/","children":"[논문리뷰] Persuasion Dynamics in LLMs: Investigating Robustness and Adaptability in Knowledge and Safety with DuET-PD"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Roy Ka-Wei Lee이 [arXiv]에 게시한 'Persuasion Dynamics in LLMs: Investigating Robustness and Adaptability in Knowledge and Safety with DuET-PD' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Persuasion Dynamics",{"className":"page__taxonomy-item","children":["#","Persuasion Dynamics"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Robustness",{"className":"page__taxonomy-item","children":["#","Robustness"]}],["$","span","Gullibility",{"className":"page__taxonomy-item","children":["#","Gullibility"]}],["$","span","Receptiveness",{"className":"page__taxonomy-item","children":["#","Receptiveness"]}],["$","span","Direct Preference Optimization (DPO)",{"className":"page__taxonomy-item","children":["#","Direct Preference Optimization (DPO)"]}],["$","span","Safety Alignment",{"className":"page__taxonomy-item","children":["#","Safety Alignment"]}],["$","span","Multi-turn Dialogue",{"className":"page__taxonomy-item","children":["#","Multi-turn Dialogue"]}]]}]]}]]}],["$","article","2025-8-29-OneReward-Unified-Mask-Guided-Image-Generation-via-Multi-Task-Human-Preference-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-OneReward-Unified-Mask-Guided-Image-Generation-via-Multi-Task-Human-Preference-Learning/","children":"[논문리뷰] OneReward: Unified Mask-Guided Image Generation via Multi-Task Human Preference Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yitong Wang이 [arXiv]에 게시한 'OneReward: Unified Mask-Guided Image Generation via Multi-Task Human Preference Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Mask-Guided Editing",{"className":"page__taxonomy-item","children":["#","Mask-Guided Editing"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Human Preference Learning",{"className":"page__taxonomy-item","children":["#","Human Preference Learning"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Multi-Task Learning",{"className":"page__taxonomy-item","children":["#","Multi-Task Learning"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}]]}]]}]]}],["$","article","2025-8-29-OnGoal-Tracking-and-Visualizing-Conversational-Goals-in-Multi-Turn-Dialogue-with-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-OnGoal-Tracking-and-Visualizing-Conversational-Goals-in-Multi-Turn-Dialogue-with-Large-Language-Models/","children":"[논문리뷰] OnGoal: Tracking and Visualizing Conversational Goals in Multi-Turn Dialogue with Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Alex Endert이 [arXiv]에 게시한 'OnGoal: Tracking and Visualizing Conversational Goals in Multi-Turn Dialogue with Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Human-Computer Interaction (HCI)",{"className":"page__taxonomy-item","children":["#","Human-Computer Interaction (HCI)"]}],["$","span","Conversational AI",{"className":"page__taxonomy-item","children":["#","Conversational AI"]}],["$","span","Goal Tracking",{"className":"page__taxonomy-item","children":["#","Goal Tracking"]}],["$","span","Visualization",{"className":"page__taxonomy-item","children":["#","Visualization"]}],["$","span","Multi-Turn Dialogue",{"className":"page__taxonomy-item","children":["#","Multi-Turn Dialogue"]}],["$","span","User Interface Design",{"className":"page__taxonomy-item","children":["#","User Interface Design"]}],["$","span","Sensemaking",{"className":"page__taxonomy-item","children":["#","Sensemaking"]}]]}]]}]]}],["$","article","2025-8-29-Multi-View-3D-Point-Tracking",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-Multi-View-3D-Point-Tracking/","children":"[논문리뷰] Multi-View 3D Point Tracking"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Irem Demir이 [arXiv]에 게시한 'Multi-View 3D Point Tracking' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Point Tracking",{"className":"page__taxonomy-item","children":["#","3D Point Tracking"]}],["$","span","Multi-View",{"className":"page__taxonomy-item","children":["#","Multi-View"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","kNN Correlation",{"className":"page__taxonomy-item","children":["#","kNN Correlation"]}],["$","span","Depth Estimation",{"className":"page__taxonomy-item","children":["#","Depth Estimation"]}],["$","span","Dynamic Scenes",{"className":"page__taxonomy-item","children":["#","Dynamic Scenes"]}],["$","span","Occlusion Handling",{"className":"page__taxonomy-item","children":["#","Occlusion Handling"]}],["$","span","Feature Fusion",{"className":"page__taxonomy-item","children":["#","Feature Fusion"]}]]}]]}]]}],["$","article","2025-8-29-Mixture-of-Contexts-for-Long-Video-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-Mixture-of-Contexts-for-Long-Video-Generation/","children":"[논문리뷰] Mixture of Contexts for Long Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Junfei Xiao이 [arXiv]에 게시한 'Mixture of Contexts for Long Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Long Video Generation",{"className":"page__taxonomy-item","children":["#","Long Video Generation"]}],["$","span","Diffusion Transformers (DiT)",{"className":"page__taxonomy-item","children":["#","Diffusion Transformers (DiT)"]}],["$","span","Sparse Attention",{"className":"page__taxonomy-item","children":["#","Sparse Attention"]}],["$","span","Context Routing",{"className":"page__taxonomy-item","children":["#","Context Routing"]}],["$","span","Memory Management",{"className":"page__taxonomy-item","children":["#","Memory Management"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Video Synthesis",{"className":"page__taxonomy-item","children":["#","Video Synthesis"]}]]}]]}]]}],["$","article","2025-8-29-MCP-Bench-Benchmarking-Tool-Using-LLM-Agents-with-Complex-Real-World-Tasks-via-MCP-Servers",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-MCP-Bench-Benchmarking-Tool-Using-LLM-Agents-with-Complex-Real-World-Tasks-via-MCP-Servers/","children":"[논문리뷰] MCP-Bench: Benchmarking Tool-Using LLM Agents with Complex Real-World Tasks via MCP Servers"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shashank Biju이 [arXiv]에 게시한 'MCP-Bench: Benchmarking Tool-Using LLM Agents with Complex Real-World Tasks via MCP Servers' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Model Context Protocol (MCP)",{"className":"page__taxonomy-item","children":["#","Model Context Protocol (MCP)"]}],["$","span","Cross-Domain Orchestration",{"className":"page__taxonomy-item","children":["#","Cross-Domain Orchestration"]}],["$","span","Fuzzy Instructions",{"className":"page__taxonomy-item","children":["#","Fuzzy Instructions"]}],["$","span","Multi-Step Tasks",{"className":"page__taxonomy-item","children":["#","Multi-Step Tasks"]}],["$","span","Real-World Scenarios",{"className":"page__taxonomy-item","children":["#","Real-World Scenarios"]}]]}]]}]]}],["$","article","2025-8-29-FakeParts-a-New-Family-of-AI-Generated-DeepFakes",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-FakeParts-a-New-Family-of-AI-Generated-DeepFakes/","children":"[논문리뷰] FakeParts: a New Family of AI-Generated DeepFakes"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xi Wang이 [arXiv]에 게시한 'FakeParts: a New Family of AI-Generated DeepFakes' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Deepfake Detection",{"className":"page__taxonomy-item","children":["#","Deepfake Detection"]}],["$","span","Partial Deepfakes",{"className":"page__taxonomy-item","children":["#","Partial Deepfakes"]}],["$","span","AI-Generated Video",{"className":"page__taxonomy-item","children":["#","AI-Generated Video"]}],["$","span","Benchmark Dataset",{"className":"page__taxonomy-item","children":["#","Benchmark Dataset"]}],["$","span","Video Forensics",{"className":"page__taxonomy-item","children":["#","Video Forensics"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Manipulation Detection",{"className":"page__taxonomy-item","children":["#","Manipulation Detection"]}],["$","span","Human Perception",{"className":"page__taxonomy-item","children":["#","Human Perception"]}]]}]]}]]}],["$","article","2025-8-29-DressDance-Dress-up-and-Dance-as-You-Like-It-Technical-Preview",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-DressDance-Dress-up-and-Dance-as-You-Like-It-Technical-Preview/","children":"[논문리뷰] Dress&Dance: Dress up and Dance as You Like It - Technical Preview"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yu-Xiong Wang이 [arXiv]에 게시한 'Dress&Dance: Dress up and Dance as You Like It - Technical Preview' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Virtual Try-On",{"className":"page__taxonomy-item","children":["#","Virtual Try-On"]}],["$","span","Video Diffusion",{"className":"page__taxonomy-item","children":["#","Video Diffusion"]}],["$","span","Multi-modal Conditioning",{"className":"page__taxonomy-item","children":["#","Multi-modal Conditioning"]}],["$","span","Garment Transfer",{"className":"page__taxonomy-item","children":["#","Garment Transfer"]}],["$","span","Pose Animation",{"className":"page__taxonomy-item","children":["#","Pose Animation"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Fashion Tech",{"className":"page__taxonomy-item","children":["#","Fashion Tech"]}],["$","span","CondNet",{"className":"page__taxonomy-item","children":["#","CondNet"]}]]}]]}]]}],["$","article","2025-8-29-Collaborative-Multi-Modal-Coding-for-High-Quality-3D-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-Collaborative-Multi-Modal-Coding-for-High-Quality-3D-Generation/","children":"[논문리뷰] Collaborative Multi-Modal Coding for High-Quality 3D Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ziwei Liu이 [arXiv]에 게시한 'Collaborative Multi-Modal Coding for High-Quality 3D Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Generation",{"className":"page__taxonomy-item","children":["#","3D Generation"]}],["$","span","Multi-modal Learning",{"className":"page__taxonomy-item","children":["#","Multi-modal Learning"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Triplane Representation",{"className":"page__taxonomy-item","children":["#","Triplane Representation"]}],["$","span","Collaborative Coding",{"className":"page__taxonomy-item","children":["#","Collaborative Coding"]}],["$","span","Image-to-3D",{"className":"page__taxonomy-item","children":["#","Image-to-3D"]}],["$","span","Latent Space",{"className":"page__taxonomy-item","children":["#","Latent Space"]}]]}]]}]]}],["$","article","2025-8-29-CogVLA-Cognition-Aligned-Vision-Language-Action-Model-via-Instruction-Driven-Routing-Sparsification",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-CogVLA-Cognition-Aligned-Vision-Language-Action-Model-via-Instruction-Driven-Routing-Sparsification/","children":"[논문리뷰] CogVLA: Cognition-Aligned Vision-Language-Action Model via Instruction-Driven Routing & Sparsification"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Liqiang Nie이 [arXiv]에 게시한 'CogVLA: Cognition-Aligned Vision-Language-Action Model via Instruction-Driven Routing & Sparsification' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action Model",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action Model"]}],["$","span","Sparsification",{"className":"page__taxonomy-item","children":["#","Sparsification"]}],["$","span","Instruction-Driven Routing",{"className":"page__taxonomy-item","children":["#","Instruction-Driven Routing"]}],["$","span","Cognition-Aligned AI",{"className":"page__taxonomy-item","children":["#","Cognition-Aligned AI"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}]]}]]}]]}],["$","article","2025-8-29-AWorld-Orchestrating-the-Training-Recipe-for-Agentic-AI",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-AWorld-Orchestrating-the-Training-Recipe-for-Agentic-AI/","children":"[논문리뷰] AWorld: Orchestrating the Training Recipe for Agentic AI"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Qintong Wu이 [arXiv]에 게시한 'AWorld: Orchestrating the Training Recipe for Agentic AI' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Distributed Systems",{"className":"page__taxonomy-item","children":["#","Distributed Systems"]}],["$","span","Experience Generation",{"className":"page__taxonomy-item","children":["#","Experience Generation"]}],["$","span","LLM Fine-tuning",{"className":"page__taxonomy-item","children":["#","LLM Fine-tuning"]}],["$","span","GAIA Benchmark",{"className":"page__taxonomy-item","children":["#","GAIA Benchmark"]}],["$","span","Scalability",{"className":"page__taxonomy-item","children":["#","Scalability"]}],["$","span","AWORLD Framework",{"className":"page__taxonomy-item","children":["#","AWORLD Framework"]}]]}]]}]]}],["$","article","2025-8-28-Taming-the-Chaos-Coordinated-Autoscaling-for-Heterogeneous-and-Disaggregated-LLM-Inference",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-28-Taming-the-Chaos-Coordinated-Autoscaling-for-Heterogeneous-and-Disaggregated-LLM-Inference/","children":"[논문리뷰] Taming the Chaos: Coordinated Autoscaling for Heterogeneous and Disaggregated LLM Inference"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chunlei Han이 [arXiv]에 게시한 'Taming the Chaos: Coordinated Autoscaling for Heterogeneous and Disaggregated LLM Inference' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-28 13:10:39+0900","children":"2025년 8월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Inference",{"className":"page__taxonomy-item","children":["#","LLM Inference"]}],["$","span","Autoscaling",{"className":"page__taxonomy-item","children":["#","Autoscaling"]}],["$","span","Disaggregated Architecture",{"className":"page__taxonomy-item","children":["#","Disaggregated Architecture"]}],["$","span","Heterogeneous Hardware",{"className":"page__taxonomy-item","children":["#","Heterogeneous Hardware"]}],["$","span","Resource Management",{"className":"page__taxonomy-item","children":["#","Resource Management"]}],["$","span","Topology-aware Scheduling",{"className":"page__taxonomy-item","children":["#","Topology-aware Scheduling"]}],["$","span","GPU Utilization",{"className":"page__taxonomy-item","children":["#","GPU Utilization"]}]]}]]}]]}],["$","article","2025-8-28-StepWiser-Stepwise-Generative-Judges-for-Wiser-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-28-StepWiser-Stepwise-Generative-Judges-for-Wiser-Reasoning/","children":"[논문리뷰] StepWiser: Stepwise Generative Judges for Wiser Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Olga Golovneva이 [arXiv]에 게시한 'StepWiser: Stepwise Generative Judges for Wiser Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-28 13:10:39+0900","children":"2025년 8월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Reasoning",{"className":"page__taxonomy-item","children":["#","LLM Reasoning"]}],["$","span","Process Reward Models",{"className":"page__taxonomy-item","children":["#","Process Reward Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Generative Judges",{"className":"page__taxonomy-item","children":["#","Generative Judges"]}],["$","span","Stepwise Feedback",{"className":"page__taxonomy-item","children":["#","Stepwise Feedback"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Meta-Reasoning",{"className":"page__taxonomy-item","children":["#","Meta-Reasoning"]}]]}]]}]]}],["$","article","2025-8-28-Self-Rewarding-Vision-Language-Model-via-Reasoning-Decomposition",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-28-Self-Rewarding-Vision-Language-Model-via-Reasoning-Decomposition/","children":"[논문리뷰] Self-Rewarding Vision-Language Model via Reasoning Decomposition"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhenwen Liang이 [arXiv]에 게시한 'Self-Rewarding Vision-Language Model via Reasoning Decomposition' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-28 13:10:39+0900","children":"2025년 8월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Self-Rewarding",{"className":"page__taxonomy-item","children":["#","Self-Rewarding"]}],["$","span","Reasoning Decomposition",{"className":"page__taxonomy-item","children":["#","Reasoning Decomposition"]}],["$","span","Visual Perception",{"className":"page__taxonomy-item","children":["#","Visual Perception"]}],["$","span","Language Reasoning",{"className":"page__taxonomy-item","children":["#","Language Reasoning"]}],["$","span","Hallucinations",{"className":"page__taxonomy-item","children":["#","Hallucinations"]}],["$","span","Language Shortcuts",{"className":"page__taxonomy-item","children":["#","Language Shortcuts"]}]]}]]}]]}],["$","article","2025-8-28-Predicting-the-Order-of-Upcoming-Tokens-Improves-Language-Modeling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-28-Predicting-the-Order-of-Upcoming-Tokens-Improves-Language-Modeling/","children":"[논문리뷰] Predicting the Order of Upcoming Tokens Improves Language Modeling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Alham Fikri Aji이 [arXiv]에 게시한 'Predicting the Order of Upcoming Tokens Improves Language Modeling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-28 13:10:39+0900","children":"2025년 8월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Language Modeling",{"className":"page__taxonomy-item","children":["#","Language Modeling"]}],["$","span","Next-Token Prediction",{"className":"page__taxonomy-item","children":["#","Next-Token Prediction"]}],["$","span","Multi-Token Prediction",{"className":"page__taxonomy-item","children":["#","Multi-Token Prediction"]}],["$","span","Token Order Prediction",{"className":"page__taxonomy-item","children":["#","Token Order Prediction"]}],["$","span","Auxiliary Objective",{"className":"page__taxonomy-item","children":["#","Auxiliary Objective"]}],["$","span","Learning-to-Rank",{"className":"page__taxonomy-item","children":["#","Learning-to-Rank"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}]]}]]}]]}],["$","article","2025-8-28-MotionFlux-Efficient-Text-Guided-Motion-Generation-through-Rectified-Flow-Matching-and-Preference-Alignment",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-28-MotionFlux-Efficient-Text-Guided-Motion-Generation-through-Rectified-Flow-Matching-and-Preference-Alignment/","children":"[논문리뷰] MotionFlux: Efficient Text-Guided Motion Generation through Rectified Flow Matching and Preference Alignment"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"An-An Liu이 [arXiv]에 게시한 'MotionFlux: Efficient Text-Guided Motion Generation through Rectified Flow Matching and Preference Alignment' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-28 13:10:39+0900","children":"2025년 8월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-Guided Motion Generation",{"className":"page__taxonomy-item","children":["#","Text-Guided Motion Generation"]}],["$","span","Rectified Flow Matching",{"className":"page__taxonomy-item","children":["#","Rectified Flow Matching"]}],["$","span","Preference Alignment",{"className":"page__taxonomy-item","children":["#","Preference Alignment"]}],["$","span","Human Motion Synthesis",{"className":"page__taxonomy-item","children":["#","Human Motion Synthesis"]}],["$","span","Real-time AI",{"className":"page__taxonomy-item","children":["#","Real-time AI"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Self-supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-supervised Learning"]}]]}]]}]]}],["$","article","2025-8-28-Mind-the-Third-Eye-Benchmarking-Privacy-Awareness-in-MLLM-powered-Smartphone-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-28-Mind-the-Third-Eye-Benchmarking-Privacy-Awareness-in-MLLM-powered-Smartphone-Agents/","children":"[논문리뷰] Mind the Third Eye! Benchmarking Privacy Awareness in MLLM-powered Smartphone Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yue Yao이 [arXiv]에 게시한 'Mind the Third Eye! Benchmarking Privacy Awareness in MLLM-powered Smartphone Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-28 13:10:39+0900","children":"2025년 8월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLMs (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs (MLLMs)"]}],["$","span","Smartphone Agents",{"className":"page__taxonomy-item","children":["#","Smartphone Agents"]}],["$","span","Privacy Awareness",{"className":"page__taxonomy-item","children":["#","Privacy Awareness"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Sensitive Data Detection",{"className":"page__taxonomy-item","children":["#","Sensitive Data Detection"]}],["$","span","Risk Assessment",{"className":"page__taxonomy-item","children":["#","Risk Assessment"]}],["$","span","UI Automation",{"className":"page__taxonomy-item","children":["#","UI Automation"]}]]}]]}]]}],["$","article","2025-8-28-MIDAS-Multimodal-Interactive-Digital-human-Synthesis-via-Real-time-Autoregressive-Video-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-28-MIDAS-Multimodal-Interactive-Digital-human-Synthesis-via-Real-time-Autoregressive-Video-Generation/","children":"[논문리뷰] MIDAS: Multimodal Interactive Digital-human Synthesis via Real-time Autoregressive Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yan Zhou이 [arXiv]에 게시한 'MIDAS: Multimodal Interactive Digital-human Synthesis via Real-time Autoregressive Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-28 13:10:39+0900","children":"2025년 8월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Generation",{"className":"page__taxonomy-item","children":["#","Multimodal Generation"]}],["$","span","Digital Human Synthesis",{"className":"page__taxonomy-item","children":["#","Digital Human Synthesis"]}],["$","span","Real-time Video Generation",{"className":"page__taxonomy-item","children":["#","Real-time Video Generation"]}],["$","span","Autoregressive LLM",{"className":"page__taxonomy-item","children":["#","Autoregressive LLM"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Deep Compression Autoencoder",{"className":"page__taxonomy-item","children":["#","Deep Compression Autoencoder"]}],["$","span","Exposure Bias Mitigation",{"className":"page__taxonomy-item","children":["#","Exposure Bias Mitigation"]}],["$","span","Streaming Inference",{"className":"page__taxonomy-item","children":["#","Streaming Inference"]}]]}]]}]]}],["$","article","2025-8-28-Gaze-into-the-Heart-A-Multi-View-Video-Dataset-for-rPPG-and-Health-Biomarkers-Estimation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-28-Gaze-into-the-Heart-A-Multi-View-Video-Dataset-for-rPPG-and-Health-Biomarkers-Estimation/","children":"[논문리뷰] Gaze into the Heart: A Multi-View Video Dataset for rPPG and Health Biomarkers Estimation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Anton Ivaschenko이 [arXiv]에 게시한 'Gaze into the Heart: A Multi-View Video Dataset for rPPG and Health Biomarkers Estimation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-28 13:10:39+0900","children":"2025년 8월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","rPPG",{"className":"page__taxonomy-item","children":["#","rPPG"]}],["$","span","Multi-View Video Dataset",{"className":"page__taxonomy-item","children":["#","Multi-View Video Dataset"]}],["$","span","Health Biomarkers",{"className":"page__taxonomy-item","children":["#","Health Biomarkers"]}],["$","span","Physiological Monitoring",{"className":"page__taxonomy-item","children":["#","Physiological Monitoring"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}],["$","span","Telemedicine",{"className":"page__taxonomy-item","children":["#","Telemedicine"]}],["$","span","Biosignals",{"className":"page__taxonomy-item","children":["#","Biosignals"]}]]}]]}]]}],["$","article","2025-8-28-Discrete-Diffusion-VLA-Bringing-Discrete-Diffusion-to-Action-Decoding-in-Vision-Language-Action-Policies",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-28-Discrete-Diffusion-VLA-Bringing-Discrete-Diffusion-to-Action-Decoding-in-Vision-Language-Action-Policies/","children":"[논문리뷰] Discrete Diffusion VLA: Bringing Discrete Diffusion to Action Decoding in Vision-Language-Action Policies"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Sitong Mao이 [arXiv]에 게시한 'Discrete Diffusion VLA: Bringing Discrete Diffusion to Action Decoding in Vision-Language-Action Policies' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-28 13:10:39+0900","children":"2025년 8월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action (VLA)",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action (VLA)"]}],["$","span","Discrete Diffusion",{"className":"page__taxonomy-item","children":["#","Discrete Diffusion"]}],["$","span","Action Decoding",{"className":"page__taxonomy-item","children":["#","Action Decoding"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Robot Control",{"className":"page__taxonomy-item","children":["#","Robot Control"]}],["$","span","Masked Modeling",{"className":"page__taxonomy-item","children":["#","Masked Modeling"]}],["$","span","Adaptive Decoding",{"className":"page__taxonomy-item","children":["#","Adaptive Decoding"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}]]}]]}]]}],["$","article","2025-8-28-Diffusion-Language-Models-Know-the-Answer-Before-Decoding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-28-Diffusion-Language-Models-Know-the-Answer-Before-Decoding/","children":"[논문리뷰] Diffusion Language Models Know the Answer Before Decoding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shilin Yan이 [arXiv]에 게시한 'Diffusion Language Models Know the Answer Before Decoding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-28 13:10:39+0900","children":"2025년 8월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Language Models",{"className":"page__taxonomy-item","children":["#","Diffusion Language Models"]}],["$","span","DLM Acceleration",{"className":"page__taxonomy-item","children":["#","DLM Acceleration"]}],["$","span","Early Answer Convergence",{"className":"page__taxonomy-item","children":["#","Early Answer Convergence"]}],["$","span","Early Commit Decoding",{"className":"page__taxonomy-item","children":["#","Early Commit Decoding"]}],["$","span","Confidence Gap",{"className":"page__taxonomy-item","children":["#","Confidence Gap"]}],["$","span","Inference Speedup",{"className":"page__taxonomy-item","children":["#","Inference Speedup"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}]]}]]}]]}],["$","article","2025-8-28-DeepScholar-Bench-A-Live-Benchmark-and-Automated-Evaluation-for-Generative-Research-Synthesis",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-28-DeepScholar-Bench-A-Live-Benchmark-and-Automated-Evaluation-for-Generative-Research-Synthesis/","children":"[논문리뷰] DeepScholar-Bench: A Live Benchmark and Automated Evaluation for Generative Research Synthesis"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ion Stoica이 [arXiv]에 게시한 'DeepScholar-Bench: A Live Benchmark and Automated Evaluation for Generative Research Synthesis' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-28 13:10:39+0900","children":"2025년 8월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Generative Research Synthesis",{"className":"page__taxonomy-item","children":["#","Generative Research Synthesis"]}],["$","span","Live Benchmark",{"className":"page__taxonomy-item","children":["#","Live Benchmark"]}],["$","span","Automated Evaluation",{"className":"page__taxonomy-item","children":["#","Automated Evaluation"]}],["$","span","LLM-as-a-judge",{"className":"page__taxonomy-item","children":["#","LLM-as-a-judge"]}],["$","span","Related Work Generation",{"className":"page__taxonomy-item","children":["#","Related Work Generation"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","Verifiability",{"className":"page__taxonomy-item","children":["#","Verifiability"]}]]}]]}]]}],["$","article","2025-8-28-CODA-Coordinating-the-Cerebrum-and-Cerebellum-for-a-Dual-Brain-Computer-Use-Agent-with-Decoupled-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-28-CODA-Coordinating-the-Cerebrum-and-Cerebellum-for-a-Dual-Brain-Computer-Use-Agent-with-Decoupled-Reinforcement-Learning/","children":"[논문리뷰] CODA: Coordinating the Cerebrum and Cerebellum for a Dual-Brain Computer Use Agent with Decoupled Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jianze Liang이 [arXiv]에 게시한 'CODA: Coordinating the Cerebrum and Cerebellum for a Dual-Brain Computer Use Agent with Decoupled Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-28 13:10:39+0900","children":"2025년 8월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","GUI Agents",{"className":"page__taxonomy-item","children":["#","GUI Agents"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Planner-Executor Architecture",{"className":"page__taxonomy-item","children":["#","Planner-Executor Architecture"]}],["$","span","Decoupled Training",{"className":"page__taxonomy-item","children":["#","Decoupled Training"]}],["$","span","Large Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Large Vision-Language Models"]}],["$","span","Specialization",{"className":"page__taxonomy-item","children":["#","Specialization"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Computer Use Agent",{"className":"page__taxonomy-item","children":["#","Computer Use Agent"]}]]}]]}]]}],["$","article","2025-8-28-Beyond-Transcription-Mechanistic-Interpretability-in-ASR",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-28-Beyond-Transcription-Mechanistic-Interpretability-in-ASR/","children":"[논문리뷰] Beyond Transcription: Mechanistic Interpretability in ASR"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Aviv Shamsian이 [arXiv]에 게시한 'Beyond Transcription: Mechanistic Interpretability in ASR' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-28 13:10:39+0900","children":"2025년 8월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","ASR",{"className":"page__taxonomy-item","children":["#","ASR"]}],["$","span","Mechanistic Interpretability",{"className":"page__taxonomy-item","children":["#","Mechanistic Interpretability"]}],["$","span","Logit Lens",{"className":"page__taxonomy-item","children":["#","Logit Lens"]}],["$","span","Linear Probing",{"className":"page__taxonomy-item","children":["#","Linear Probing"]}],["$","span","Activation Patching",{"className":"page__taxonomy-item","children":["#","Activation Patching"]}],["$","span","Hallucinations",{"className":"page__taxonomy-item","children":["#","Hallucinations"]}],["$","span","Repetitions",{"className":"page__taxonomy-item","children":["#","Repetitions"]}],["$","span","Encoder-Decoder",{"className":"page__taxonomy-item","children":["#","Encoder-Decoder"]}]]}]]}]]}],["$","article","2025-8-28-AudioStory-Generating-Long-Form-Narrative-Audio-with-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-28-AudioStory-Generating-Long-Form-Narrative-Audio-with-Large-Language-Models/","children":"[논문리뷰] AudioStory: Generating Long-Form Narrative Audio with Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yixiao Ge이 [arXiv]에 게시한 'AudioStory: Generating Long-Form Narrative Audio with Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-28 13:10:39+0900","children":"2025년 8월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Audio",{"className":"page__taxonomy-item","children":["#","Text-to-Audio"]}],["$","span","Long-Form Audio Generation",{"className":"page__taxonomy-item","children":["#","Long-Form Audio Generation"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Narrative Reasoning",{"className":"page__taxonomy-item","children":["#","Narrative Reasoning"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Progressive Training",{"className":"page__taxonomy-item","children":["#","Progressive Training"]}]]}]]}]]}],["$","article","2025-8-27-Wan-S2V-Audio-Driven-Cinematic-Video-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-Wan-S2V-Audio-Driven-Cinematic-Video-Generation/","children":"[논문리뷰] Wan-S2V: Audio-Driven Cinematic Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chaonan Ji이 [arXiv]에 게시한 'Wan-S2V: Audio-Driven Cinematic Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Audio-Driven Video Generation",{"className":"page__taxonomy-item","children":["#","Audio-Driven Video Generation"]}],["$","span","Cinematic Video",{"className":"page__taxonomy-item","children":["#","Cinematic Video"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Long Video Consistency",{"className":"page__taxonomy-item","children":["#","Long Video Consistency"]}],["$","span","Human Animation",{"className":"page__taxonomy-item","children":["#","Human Animation"]}],["$","span","Multimodal Control",{"className":"page__taxonomy-item","children":["#","Multimodal Control"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}]]}]]}]]}],["$","article","2025-8-27-VoxHammer-Training-Free-Precise-and-Coherent-3D-Editing-in-Native-3D-Space",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-VoxHammer-Training-Free-Precise-and-Coherent-3D-Editing-in-Native-3D-Space/","children":"[논문리뷰] VoxHammer: Training-Free Precise and Coherent 3D Editing in Native 3D Space"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Rui Chen이 [arXiv]에 게시한 'VoxHammer: Training-Free Precise and Coherent 3D Editing in Native 3D Space' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Editing",{"className":"page__taxonomy-item","children":["#","3D Editing"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Latent Space",{"className":"page__taxonomy-item","children":["#","Latent Space"]}],["$","span","3D Inversion",{"className":"page__taxonomy-item","children":["#","3D Inversion"]}],["$","span","Contextual Feature Replacement",{"className":"page__taxonomy-item","children":["#","Contextual Feature Replacement"]}],["$","span","3D Consistency",{"className":"page__taxonomy-item","children":["#","3D Consistency"]}],["$","span","Edit3D-Bench",{"className":"page__taxonomy-item","children":["#","Edit3D-Bench"]}]]}]]}]]}],["$","article","2025-8-27-VibeVoice-Technical-Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-VibeVoice-Technical-Report/","children":"[논문리뷰] VibeVoice Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yaoyao Chang이 [arXiv]에 게시한 'VibeVoice Technical Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Speech Synthesis",{"className":"page__taxonomy-item","children":["#","Speech Synthesis"]}],["$","span","Long-form Audio",{"className":"page__taxonomy-item","children":["#","Long-form Audio"]}],["$","span","Multi-speaker",{"className":"page__taxonomy-item","children":["#","Multi-speaker"]}],["$","span","Next-token Diffusion",{"className":"page__taxonomy-item","children":["#","Next-token Diffusion"]}],["$","span","Speech Tokenizer",{"className":"page__taxonomy-item","children":["#","Speech Tokenizer"]}],["$","span","Large Language Model",{"className":"page__taxonomy-item","children":["#","Large Language Model"]}],["$","span","Variational Autoencoder",{"className":"page__taxonomy-item","children":["#","Variational Autoencoder"]}],["$","span","Audio Compression",{"className":"page__taxonomy-item","children":["#","Audio Compression"]}]]}]]}]]}],["$","article","2025-8-27-Unraveling-the-cognitive-patterns-of-Large-Language-Models-through-module-communities",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-Unraveling-the-cognitive-patterns-of-Large-Language-Models-through-module-communities/","children":"[논문리뷰] Unraveling the cognitive patterns of Large Language Models through module communities"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jianxi Gao이 [arXiv]에 게시한 'Unraveling the cognitive patterns of Large Language Models through module communities' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Network Community Structure",{"className":"page__taxonomy-item","children":["#","Network Community Structure"]}],["$","span","Cognitive Skills",{"className":"page__taxonomy-item","children":["#","Cognitive Skills"]}],["$","span","AI Interpretability",{"className":"page__taxonomy-item","children":["#","AI Interpretability"]}],["$","span","Module Communities",{"className":"page__taxonomy-item","children":["#","Module Communities"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Neural Plasticity",{"className":"page__taxonomy-item","children":["#","Neural Plasticity"]}]]}]]}]]}],["$","article","2025-8-27-UltraMemV2-Memory-Networks-Scaling-to-120B-Parameters-with-Superior-Long-Context-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-UltraMemV2-Memory-Networks-Scaling-to-120B-Parameters-with-Superior-Long-Context-Learning/","children":"[논문리뷰] UltraMemV2: Memory Networks Scaling to 120B Parameters with Superior Long-Context Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ran Guo이 [arXiv]에 게시한 'UltraMemV2: Memory Networks Scaling to 120B Parameters with Superior Long-Context Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Memory Networks",{"className":"page__taxonomy-item","children":["#","Memory Networks"]}],["$","span","Mixture of Experts (MoE)",{"className":"page__taxonomy-item","children":["#","Mixture of Experts (MoE)"]}],["$","span","Long-Context Learning",{"className":"page__taxonomy-item","children":["#","Long-Context Learning"]}],["$","span","Sparse Models",{"className":"page__taxonomy-item","children":["#","Sparse Models"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Efficient Inference",{"className":"page__taxonomy-item","children":["#","Efficient Inference"]}]]}]]}]]}],["$","article","2025-8-27-TreePO-Bridging-the-Gap-of-Policy-Optimization-and-Efficacy-and-Inference-Efficiency-with-Heuristic-Tree-based-Modeling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-TreePO-Bridging-the-Gap-of-Policy-Optimization-and-Efficacy-and-Inference-Efficiency-with-Heuristic-Tree-based-Modeling/","children":"[논문리뷰] TreePO: Bridging the Gap of Policy Optimization and Efficacy and Inference Efficiency with Heuristic Tree-based Modeling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhoufutu Wen이 [arXiv]에 게시한 'TreePO: Bridging the Gap of Policy Optimization and Efficacy and Inference Efficiency with Heuristic Tree-based Modeling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Inference Efficiency",{"className":"page__taxonomy-item","children":["#","Inference Efficiency"]}],["$","span","Tree Search",{"className":"page__taxonomy-item","children":["#","Tree Search"]}],["$","span","Segment-level Decoding",{"className":"page__taxonomy-item","children":["#","Segment-level Decoding"]}],["$","span","Advantage Estimation",{"className":"page__taxonomy-item","children":["#","Advantage Estimation"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}]]}]]}]]}],["$","article","2025-8-27-Training-Language-Model-Agents-to-Find-Vulnerabilities-with-CTF-Dojo",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-Training-Language-Model-Agents-to-Find-Vulnerabilities-with-CTF-Dojo/","children":"[논문리뷰] Training Language Model Agents to Find Vulnerabilities with CTF-Dojo"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zijian Wang이 [arXiv]에 게시한 'Training Language Model Agents to Find Vulnerabilities with CTF-Dojo' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Cybersecurity",{"className":"page__taxonomy-item","children":["#","Cybersecurity"]}],["$","span","CTF Challenges",{"className":"page__taxonomy-item","children":["#","CTF Challenges"]}],["$","span","Vulnerability Detection",{"className":"page__taxonomy-item","children":["#","Vulnerability Detection"]}],["$","span","Execution Environments",{"className":"page__taxonomy-item","children":["#","Execution Environments"]}],["$","span","Docker",{"className":"page__taxonomy-item","children":["#","Docker"]}],["$","span","Automated Training",{"className":"page__taxonomy-item","children":["#","Automated Training"]}],["$","span","Verifiable Feedback",{"className":"page__taxonomy-item","children":["#","Verifiable Feedback"]}]]}]]}]]}],["$","article","2025-8-27-ThinkDial-An-Open-Recipe-for-Controlling-Reasoning-Effort-in-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-ThinkDial-An-Open-Recipe-for-Controlling-Reasoning-Effort-in-Large-Language-Models/","children":"[논문리뷰] ThinkDial: An Open Recipe for Controlling Reasoning Effort in Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiangjie Chen이 [arXiv]에 게시한 'ThinkDial: An Open Recipe for Controlling Reasoning Effort in Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Controllable Reasoning",{"className":"page__taxonomy-item","children":["#","Controllable Reasoning"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Reasoning Compression",{"className":"page__taxonomy-item","children":["#","Reasoning Compression"]}],["$","span","Budget-Aware Training",{"className":"page__taxonomy-item","children":["#","Budget-Aware Training"]}]]}]]}]]}],["$","article","2025-8-27-Spacer-Towards-Engineered-Scientific-Inspiration",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-Spacer-Towards-Engineered-Scientific-Inspiration/","children":"[논문리뷰] Spacer: Towards Engineered Scientific Inspiration"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"zerojun48이 [arXiv]에 게시한 'Spacer: Towards Engineered Scientific Inspiration' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Scientific Discovery",{"className":"page__taxonomy-item","children":["#","Scientific Discovery"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Decontextualization",{"className":"page__taxonomy-item","children":["#","Decontextualization"]}],["$","span","Keyword Graph",{"className":"page__taxonomy-item","children":["#","Keyword Graph"]}],["$","span","Multi-Agent System",{"className":"page__taxonomy-item","children":["#","Multi-Agent System"]}],["$","span","Scientific Ideation",{"className":"page__taxonomy-item","children":["#","Scientific Ideation"]}],["$","span","Research Automation",{"className":"page__taxonomy-item","children":["#","Research Automation"]}],["$","span","Inspiration Engine",{"className":"page__taxonomy-item","children":["#","Inspiration Engine"]}]]}]]}]]}],["$","article","2025-8-27-ReportBench-Evaluating-Deep-Research-Agents-via-Academic-Survey-Tasks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-ReportBench-Evaluating-Deep-Research-Agents-via-Academic-Survey-Tasks/","children":"[논문리뷰] ReportBench: Evaluating Deep Research Agents via Academic Survey Tasks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kai Jia이 [arXiv]에 게시한 'ReportBench: Evaluating Deep Research Agents via Academic Survey Tasks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Deep Research Agents",{"className":"page__taxonomy-item","children":["#","Deep Research Agents"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Academic Survey",{"className":"page__taxonomy-item","children":["#","Academic Survey"]}],["$","span","Factual Accuracy",{"className":"page__taxonomy-item","children":["#","Factual Accuracy"]}],["$","span","Citation Verification",{"className":"page__taxonomy-item","children":["#","Citation Verification"]}],["$","span","Report Generation",{"className":"page__taxonomy-item","children":["#","Report Generation"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Hallucination",{"className":"page__taxonomy-item","children":["#","Hallucination"]}]]}]]}]]}],["$","article","2025-8-27-QueryBandits-for-Hallucination-Mitigation-Exploiting-Semantic-Features-for-No-Regret-Rewriting",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-QueryBandits-for-Hallucination-Mitigation-Exploiting-Semantic-Features-for-No-Regret-Rewriting/","children":"[논문리뷰] QueryBandits for Hallucination Mitigation: Exploiting Semantic Features for No-Regret Rewriting"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Manuela Veloso이 [arXiv]에 게시한 'QueryBandits for Hallucination Mitigation: Exploiting Semantic Features for No-Regret Rewriting' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Hallucination Mitigation",{"className":"page__taxonomy-item","children":["#","Hallucination Mitigation"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Contextual Bandits",{"className":"page__taxonomy-item","children":["#","Contextual Bandits"]}],["$","span","Query Rewriting",{"className":"page__taxonomy-item","children":["#","Query Rewriting"]}],["$","span","Semantic Features",{"className":"page__taxonomy-item","children":["#","Semantic Features"]}],["$","span","No-Regret Learning",{"className":"page__taxonomy-item","children":["#","No-Regret Learning"]}]]}]]}]]}],["$","article","2025-8-27-Pixie-Fast-and-Generalizable-Supervised-Learning-of-3D-Physics-from-Pixels",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-Pixie-Fast-and-Generalizable-Supervised-Learning-of-3D-Physics-from-Pixels/","children":"[논문리뷰] Pixie: Fast and Generalizable Supervised Learning of 3D Physics from Pixels"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Dinesh Jayaraman이 [arXiv]에 게시한 'Pixie: Fast and Generalizable Supervised Learning of 3D Physics from Pixels' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Physics Prediction",{"className":"page__taxonomy-item","children":["#","3D Physics Prediction"]}],["$","span","Supervised Learning",{"className":"page__taxonomy-item","children":["#","Supervised Learning"]}],["$","span","CLIP Features",{"className":"page__taxonomy-item","children":["#","CLIP Features"]}],["$","span","Neural Radiance Fields",{"className":"page__taxonomy-item","children":["#","Neural Radiance Fields"]}],["$","span","Material Point Method",{"className":"page__taxonomy-item","children":["#","Material Point Method"]}],["$","span","PIXIEVERSE Dataset",{"className":"page__taxonomy-item","children":["#","PIXIEVERSE Dataset"]}],["$","span","Zero-Shot Generalization",{"className":"page__taxonomy-item","children":["#","Zero-Shot Generalization"]}]]}]]}]]}],["$","article","2025-8-27-Optimal-Sparsity-of-Mixture-of-Experts-Language-Models-for-Reasoning-Tasks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-Optimal-Sparsity-of-Mixture-of-Experts-Language-Models-for-Reasoning-Tasks/","children":"[논문리뷰] Optimal Sparsity of Mixture-of-Experts Language Models for Reasoning Tasks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Daisuke Nohara이 [arXiv]에 게시한 'Optimal Sparsity of Mixture-of-Experts Language Models for Reasoning Tasks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Mixture-of-Experts (MoE)",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts (MoE)"]}],["$","span","Sparsity",{"className":"page__taxonomy-item","children":["#","Sparsity"]}],["$","span","Scaling Laws",{"className":"page__taxonomy-item","children":["#","Scaling Laws"]}],["$","span","Reasoning Tasks",{"className":"page__taxonomy-item","children":["#","Reasoning Tasks"]}],["$","span","Memorization",{"className":"page__taxonomy-item","children":["#","Memorization"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Generalization Gap",{"className":"page__taxonomy-item","children":["#","Generalization Gap"]}],["$","span","Top-k Routing",{"className":"page__taxonomy-item","children":["#","Top-k Routing"]}]]}]]}]]}],["$","article","2025-8-27-OmniHuman-1-5-Instilling-an-Active-Mind-in-Avatars-via-Cognitive-Simulation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-OmniHuman-1-5-Instilling-an-Active-Mind-in-Avatars-via-Cognitive-Simulation/","children":"[논문리뷰] OmniHuman-1.5: Instilling an Active Mind in Avatars via Cognitive Simulation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiaqi Yang이 [arXiv]에 게시한 'OmniHuman-1.5: Instilling an Active Mind in Avatars via Cognitive Simulation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Avatar Generation",{"className":"page__taxonomy-item","children":["#","Video Avatar Generation"]}],["$","span","Cognitive Simulation",{"className":"page__taxonomy-item","children":["#","Cognitive Simulation"]}],["$","span","Multimodal Large Language Models (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models (MLLMs)"]}],["$","span","Diffusion Transformers (DiT)",{"className":"page__taxonomy-item","children":["#","Diffusion Transformers (DiT)"]}],["$","span","Multimodal Fusion",{"className":"page__taxonomy-item","children":["#","Multimodal Fusion"]}],["$","span","Human Motion Synthesis",{"className":"page__taxonomy-item","children":["#","Human Motion Synthesis"]}],["$","span","Contextual Animation",{"className":"page__taxonomy-item","children":["#","Contextual Animation"]}]]}]]}]]}],["$","article","2025-8-27-ObjFiller-3D-Consistent-Multi-view-3D-Inpainting-via-Video-Diffusion-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-ObjFiller-3D-Consistent-Multi-view-3D-Inpainting-via-Video-Diffusion-Models/","children":"[논문리뷰] ObjFiller-3D: Consistent Multi-view 3D Inpainting via Video Diffusion Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Beiqi Chen이 [arXiv]에 게시한 'ObjFiller-3D: Consistent Multi-view 3D Inpainting via Video Diffusion Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Inpainting",{"className":"page__taxonomy-item","children":["#","3D Inpainting"]}],["$","span","Multi-view Consistency",{"className":"page__taxonomy-item","children":["#","Multi-view Consistency"]}],["$","span","Video Diffusion Models",{"className":"page__taxonomy-item","children":["#","Video Diffusion Models"]}],["$","span","3D Object Completion",{"className":"page__taxonomy-item","children":["#","3D Object Completion"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","LoRA",{"className":"page__taxonomy-item","children":["#","LoRA"]}],["$","span","3D Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","3D Gaussian Splatting"]}]]}]]}]]}],["$","article","2025-8-27-MovieCORE-COgnitive-REasoning-in-Movies",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-MovieCORE-COgnitive-REasoning-in-Movies/","children":"[논문리뷰] MovieCORE: COgnitive REasoning in Movies"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hung-Ting Su이 [arXiv]에 게시한 'MovieCORE: COgnitive REasoning in Movies' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Question Answering (VQA)",{"className":"page__taxonomy-item","children":["#","Video Question Answering (VQA)"]}],["$","span","Cognitive Reasoning",{"className":"page__taxonomy-item","children":["#","Cognitive Reasoning"]}],["$","span","System-2 Thinking",{"className":"page__taxonomy-item","children":["#","System-2 Thinking"]}],["$","span","Multi-agent LLMs",{"className":"page__taxonomy-item","children":["#","Multi-agent LLMs"]}],["$","span","Dataset Creation",{"className":"page__taxonomy-item","children":["#","Dataset Creation"]}],["$","span","Movie Understanding",{"className":"page__taxonomy-item","children":["#","Movie Understanding"]}],["$","span","Cinematic Content",{"className":"page__taxonomy-item","children":["#","Cinematic Content"]}],["$","span","Agentic Enhancement",{"className":"page__taxonomy-item","children":["#","Agentic Enhancement"]}]]}]]}]]}],["$","article","2025-8-27-FastMeshEfficient-Artistic-Mesh-Generation-via-Component-Decoupling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-FastMeshEfficient-Artistic-Mesh-Generation-via-Component-Decoupling/","children":"[논문리뷰] FastMesh:Efficient Artistic Mesh Generation via Component Decoupling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xingang Pan이 [arXiv]에 게시한 'FastMesh:Efficient Artistic Mesh Generation via Component Decoupling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Mesh Generation",{"className":"page__taxonomy-item","children":["#","3D Mesh Generation"]}],["$","span","Component Decoupling",{"className":"page__taxonomy-item","children":["#","Component Decoupling"]}],["$","span","Autoregressive Models",{"className":"page__taxonomy-item","children":["#","Autoregressive Models"]}],["$","span","Bidirectional Transformer",{"className":"page__taxonomy-item","children":["#","Bidirectional Transformer"]}],["$","span","Fidelity Enhancement",{"className":"page__taxonomy-item","children":["#","Fidelity Enhancement"]}],["$","span","Prediction Filtering",{"className":"page__taxonomy-item","children":["#","Prediction Filtering"]}],["$","span","Token Efficiency",{"className":"page__taxonomy-item","children":["#","Token Efficiency"]}],["$","span","Artistic Meshes",{"className":"page__taxonomy-item","children":["#","Artistic Meshes"]}]]}]]}]]}],["$","article","2025-8-27-Demystifying-Scientific-Problem-Solving-in-LLMs-by-Probing-Knowledge-and-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-Demystifying-Scientific-Problem-Solving-in-LLMs-by-Probing-Knowledge-and-Reasoning/","children":"[논문리뷰] Demystifying Scientific Problem-Solving in LLMs by Probing Knowledge and Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Arman Cohan이 [arXiv]에 게시한 'Demystifying Scientific Problem-Solving in LLMs by Probing Knowledge and Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Scientific Reasoning",{"className":"page__taxonomy-item","children":["#","Scientific Reasoning"]}],["$","span","Knowledge Retrieval",{"className":"page__taxonomy-item","children":["#","Knowledge Retrieval"]}],["$","span","Reasoning Probing",{"className":"page__taxonomy-item","children":["#","Reasoning Probing"]}],["$","span","Benchmarks",{"className":"page__taxonomy-item","children":["#","Benchmarks"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}]]}]]}]]}],["$","article","2025-8-27-ClaimGen-CN-A-Large-scale-Chinese-Dataset-for-Legal-Claim-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-ClaimGen-CN-A-Large-scale-Chinese-Dataset-for-Legal-Claim-Generation/","children":"[논문리뷰] ClaimGen-CN: A Large-scale Chinese Dataset for Legal Claim Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kun Kuang이 [arXiv]에 게시한 'ClaimGen-CN: A Large-scale Chinese Dataset for Legal Claim Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Legal AI",{"className":"page__taxonomy-item","children":["#","Legal AI"]}],["$","span","Natural Language Processing",{"className":"page__taxonomy-item","children":["#","Natural Language Processing"]}],["$","span","Claim Generation",{"className":"page__taxonomy-item","children":["#","Claim Generation"]}],["$","span","Chinese Legal Dataset",{"className":"page__taxonomy-item","children":["#","Chinese Legal Dataset"]}],["$","span","Factuality",{"className":"page__taxonomy-item","children":["#","Factuality"]}],["$","span","Clarity",{"className":"page__taxonomy-item","children":["#","Clarity"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Zero-shot Evaluation",{"className":"page__taxonomy-item","children":["#","Zero-shot Evaluation"]}]]}]]}]]}],["$","article","2025-8-27-CineScale-Free-Lunch-in-High-Resolution-Cinematic-Visual-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-CineScale-Free-Lunch-in-High-Resolution-Cinematic-Visual-Generation/","children":"[논문리뷰] CineScale: Free Lunch in High-Resolution Cinematic Visual Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ziwei Liu이 [arXiv]에 게시한 'CineScale: Free Lunch in High-Resolution Cinematic Visual Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","High-Resolution Generation",{"className":"page__taxonomy-item","children":["#","High-Resolution Generation"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","UNet Architecture",{"className":"page__taxonomy-item","children":["#","UNet Architecture"]}],["$","span","DiT Architecture",{"className":"page__taxonomy-item","children":["#","DiT Architecture"]}],["$","span","Scale Fusion",{"className":"page__taxonomy-item","children":["#","Scale Fusion"]}],["$","span","LoRA Fine-tuning",{"className":"page__taxonomy-item","children":["#","LoRA Fine-tuning"]}]]}]]}]]}],["$","article","2025-8-27-CMPhysBench-A-Benchmark-for-Evaluating-Large-Language-Models-in-Condensed-Matter-Physics",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-CMPhysBench-A-Benchmark-for-Evaluating-Large-Language-Models-in-Condensed-Matter-Physics/","children":"[논문리뷰] CMPhysBench: A Benchmark for Evaluating Large Language Models in Condensed Matter Physics"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Dongchen Huang이 [arXiv]에 게시한 'CMPhysBench: A Benchmark for Evaluating Large Language Models in Condensed Matter Physics' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Condensed Matter Physics",{"className":"page__taxonomy-item","children":["#","Condensed Matter Physics"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Scientific Reasoning",{"className":"page__taxonomy-item","children":["#","Scientific Reasoning"]}],["$","span","Evaluation Metric",{"className":"page__taxonomy-item","children":["#","Evaluation Metric"]}],["$","span","Expression Edit Distance",{"className":"page__taxonomy-item","children":["#","Expression Edit Distance"]}],["$","span","Problem Solving",{"className":"page__taxonomy-item","children":["#","Problem Solving"]}]]}]]}]]}],["$","article","2025-8-27-Autoregressive-Universal-Video-Segmentation-Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-Autoregressive-Universal-Video-Segmentation-Model/","children":"[논문리뷰] Autoregressive Universal Video Segmentation Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Albert Gu이 [arXiv]에 게시한 'Autoregressive Universal Video Segmentation Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Segmentation",{"className":"page__taxonomy-item","children":["#","Video Segmentation"]}],["$","span","Autoregressive Model",{"className":"page__taxonomy-item","children":["#","Autoregressive Model"]}],["$","span","Universal Model",{"className":"page__taxonomy-item","children":["#","Universal Model"]}],["$","span","State Space Models",{"className":"page__taxonomy-item","children":["#","State Space Models"]}],["$","span","Mamba",{"className":"page__taxonomy-item","children":["#","Mamba"]}],["$","span","Parallel Training",{"className":"page__taxonomy-item","children":["#","Parallel Training"]}],["$","span","Streaming Video",{"className":"page__taxonomy-item","children":["#","Streaming Video"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}]]}]]}]]}],["$","article","2025-8-26-Visual-CoG-Stage-Aware-Reinforcement-Learning-with-Chain-of-Guidance-for-Text-to-Image-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-Visual-CoG-Stage-Aware-Reinforcement-Learning-with-Chain-of-Guidance-for-Text-to-Image-Generation/","children":"[논문리뷰] Visual-CoG: Stage-Aware Reinforcement Learning with Chain of Guidance for Text-to-Image Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Haoxiang Shi이 [arXiv]에 게시한 'Visual-CoG: Stage-Aware Reinforcement Learning with Chain of Guidance for Text-to-Image Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-26 13:21:57+0900","children":"2025년 8월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Chain of Thought",{"className":"page__taxonomy-item","children":["#","Chain of Thought"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Stage-Aware Rewards",{"className":"page__taxonomy-item","children":["#","Stage-Aware Rewards"]}],["$","span","Semantic Reasoning",{"className":"page__taxonomy-item","children":["#","Semantic Reasoning"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}]]}]]}]]}],["$","article","2025-8-26-UQ-Assessing-Language-Models-on-Unsolved-Questions",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-UQ-Assessing-Language-Models-on-Unsolved-Questions/","children":"[논문리뷰] UQ: Assessing Language Models on Unsolved Questions"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wei Liu이 [arXiv]에 게시한 'UQ: Assessing Language Models on Unsolved Questions' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-26 13:21:57+0900","children":"2025년 8월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Unsolved Questions",{"className":"page__taxonomy-item","children":["#","Unsolved Questions"]}],["$","span","AI Benchmark",{"className":"page__taxonomy-item","children":["#","AI Benchmark"]}],["$","span","Oracle-Free Validation",{"className":"page__taxonomy-item","children":["#","Oracle-Free Validation"]}],["$","span","Generator-Validator Gap",{"className":"page__taxonomy-item","children":["#","Generator-Validator Gap"]}],["$","span","Community Evaluation",{"className":"page__taxonomy-item","children":["#","Community Evaluation"]}],["$","span","Stack Exchange",{"className":"page__taxonomy-item","children":["#","Stack Exchange"]}]]}]]}]]}],["$","article","2025-8-26-TaDiCodec-Text-aware-Diffusion-Speech-Tokenizer-for-Speech-Language-Modeling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-TaDiCodec-Text-aware-Diffusion-Speech-Tokenizer-for-Speech-Language-Modeling/","children":"[논문리뷰] TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiaqi Li이 [arXiv]에 게시한 'TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-26 13:21:57+0900","children":"2025년 8월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Speech Tokenizer",{"className":"page__taxonomy-item","children":["#","Speech Tokenizer"]}],["$","span","Diffusion Model",{"className":"page__taxonomy-item","children":["#","Diffusion Model"]}],["$","span","Text-to-Speech",{"className":"page__taxonomy-item","children":["#","Text-to-Speech"]}],["$","span","Speech Language Modeling",{"className":"page__taxonomy-item","children":["#","Speech Language Modeling"]}],["$","span","Low Bitrate Codec",{"className":"page__taxonomy-item","children":["#","Low Bitrate Codec"]}],["$","span","End-to-End Training",{"className":"page__taxonomy-item","children":["#","End-to-End Training"]}],["$","span","Binary Spherical Quantization",{"className":"page__taxonomy-item","children":["#","Binary Spherical Quantization"]}]]}]]}]]}],["$","article","2025-8-26-T2I-ReasonBench-Benchmarking-Reasoning-Informed-Text-to-Image-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-T2I-ReasonBench-Benchmarking-Reasoning-Informed-Text-to-Image-Generation/","children":"[논문리뷰] T2I-ReasonBench: Benchmarking Reasoning-Informed Text-to-Image Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xihui Liu이 [arXiv]에 게시한 'T2I-ReasonBench: Benchmarking Reasoning-Informed Text-to-Image Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-26 13:21:57+0900","children":"2025년 8월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Reasoning Benchmark",{"className":"page__taxonomy-item","children":["#","Reasoning Benchmark"]}],["$","span","Idiom Interpretation",{"className":"page__taxonomy-item","children":["#","Idiom Interpretation"]}],["$","span","Textual Image Design",{"className":"page__taxonomy-item","children":["#","Textual Image Design"]}],["$","span","Entity Reasoning",{"className":"page__taxonomy-item","children":["#","Entity Reasoning"]}],["$","span","Scientific Reasoning",{"className":"page__taxonomy-item","children":["#","Scientific Reasoning"]}],["$","span","Multimodal LLM Evaluation",{"className":"page__taxonomy-item","children":["#","Multimodal LLM Evaluation"]}]]}]]}]]}],["$","article","2025-8-26-SpotEdit-Evaluating-Visually-Guided-Image-Editing-Methods",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-SpotEdit-Evaluating-Visually-Guided-Image-Editing-Methods/","children":"[논문리뷰] SpotEdit: Evaluating Visually-Guided Image Editing Methods"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ersin Yumer이 [arXiv]에 게시한 'SpotEdit: Evaluating Visually-Guided Image Editing Methods' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-26 13:21:57+0900","children":"2025년 8월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Visually-Guided Image Editing",{"className":"page__taxonomy-item","children":["#","Visually-Guided Image Editing"]}],["$","span","Multimodal Models",{"className":"page__taxonomy-item","children":["#","Multimodal Models"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Hallucination",{"className":"page__taxonomy-item","children":["#","Hallucination"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Autoregressive Models",{"className":"page__taxonomy-item","children":["#","Autoregressive Models"]}],["$","span","Evaluation Metrics",{"className":"page__taxonomy-item","children":["#","Evaluation Metrics"]}]]}]]}]]}],["$","article","2025-8-26-ST-Raptor-LLM-Powered-Semi-Structured-Table-Question-Answering",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-ST-Raptor-LLM-Powered-Semi-Structured-Table-Question-Answering/","children":"[논문리뷰] ST-Raptor: LLM-Powered Semi-Structured Table Question Answering"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wei Zhou이 [arXiv]에 게시한 'ST-Raptor: LLM-Powered Semi-Structured Table Question Answering' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-26 13:21:57+0900","children":"2025년 8월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Semi-structured Tables",{"className":"page__taxonomy-item","children":["#","Semi-structured Tables"]}],["$","span","Question Answering",{"className":"page__taxonomy-item","children":["#","Question Answering"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Hierarchical Orthogonal Tree",{"className":"page__taxonomy-item","children":["#","Hierarchical Orthogonal Tree"]}],["$","span","Table Layout Understanding",{"className":"page__taxonomy-item","children":["#","Table Layout Understanding"]}],["$","span","Pipeline Generation",{"className":"page__taxonomy-item","children":["#","Pipeline Generation"]}],["$","span","Verification Mechanism",{"className":"page__taxonomy-item","children":["#","Verification Mechanism"]}]]}]]}]]}],["$","article","2025-8-26-PosterGen-Aesthetic-Aware-Paper-to-Poster-Generation-via-Multi-Agent-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-PosterGen-Aesthetic-Aware-Paper-to-Poster-Generation-via-Multi-Agent-LLMs/","children":"[논문리뷰] PosterGen: Aesthetic-Aware Paper-to-Poster Generation via Multi-Agent LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chenyu You이 [arXiv]에 게시한 'PosterGen: Aesthetic-Aware Paper-to-Poster Generation via Multi-Agent LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-26 13:21:57+0900","children":"2025년 8월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-Agent LLMs",{"className":"page__taxonomy-item","children":["#","Multi-Agent LLMs"]}],["$","span","Academic Poster Generation",{"className":"page__taxonomy-item","children":["#","Academic Poster Generation"]}],["$","span","Aesthetic Design",{"className":"page__taxonomy-item","children":["#","Aesthetic Design"]}],["$","span","Layout Optimization",{"className":"page__taxonomy-item","children":["#","Layout Optimization"]}],["$","span","Typography",{"className":"page__taxonomy-item","children":["#","Typography"]}],["$","span","Color Palette",{"className":"page__taxonomy-item","children":["#","Color Palette"]}],["$","span","VLM-as-Judge",{"className":"page__taxonomy-item","children":["#","VLM-as-Judge"]}],["$","span","Content Fidelity",{"className":"page__taxonomy-item","children":["#","Content Fidelity"]}]]}]]}]]}],["$","article","2025-8-26-Neither-Valid-nor-Reliable-Investigating-the-Use-of-LLMs-as-Judges",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-Neither-Valid-nor-Reliable-Investigating-the-Use-of-LLMs-as-Judges/","children":"[논문리뷰] Neither Valid nor Reliable? Investigating the Use of LLMs as Judges"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Golnoosh Farnadi이 [arXiv]에 게시한 'Neither Valid nor Reliable? Investigating the Use of LLMs as Judges' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-26 13:21:57+0900","children":"2025년 8월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLMs as Judges",{"className":"page__taxonomy-item","children":["#","LLMs as Judges"]}],["$","span","NLG Evaluation",{"className":"page__taxonomy-item","children":["#","NLG Evaluation"]}],["$","span","Measurement Theory",{"className":"page__taxonomy-item","children":["#","Measurement Theory"]}],["$","span","Validity",{"className":"page__taxonomy-item","children":["#","Validity"]}],["$","span","Reliability",{"className":"page__taxonomy-item","children":["#","Reliability"]}],["$","span","Evaluation Bias",{"className":"page__taxonomy-item","children":["#","Evaluation Bias"]}],["$","span","Scalability",{"className":"page__taxonomy-item","children":["#","Scalability"]}],["$","span","Responsible AI",{"className":"page__taxonomy-item","children":["#","Responsible AI"]}]]}]]}]]}],["$","article","2025-8-26-MeshSplat-Generalizable-Sparse-View-Surface-Reconstruction-via-Gaussian-Splatting",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-MeshSplat-Generalizable-Sparse-View-Surface-Reconstruction-via-Gaussian-Splatting/","children":"[논문리뷰] MeshSplat: Generalizable Sparse-View Surface Reconstruction via Gaussian Splatting"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yanzhe Liang이 [arXiv]에 게시한 'MeshSplat: Generalizable Sparse-View Surface Reconstruction via Gaussian Splatting' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-26 13:21:57+0900","children":"2025년 8월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Sparse-View",{"className":"page__taxonomy-item","children":["#","Sparse-View"]}],["$","span","Surface Reconstruction",{"className":"page__taxonomy-item","children":["#","Surface Reconstruction"]}],["$","span","Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","Gaussian Splatting"]}],["$","span","2DGS",{"className":"page__taxonomy-item","children":["#","2DGS"]}],["$","span","Novel View Synthesis",{"className":"page__taxonomy-item","children":["#","Novel View Synthesis"]}],["$","span","Generalizable",{"className":"page__taxonomy-item","children":["#","Generalizable"]}],["$","span","Mesh Extraction",{"className":"page__taxonomy-item","children":["#","Mesh Extraction"]}],["$","span","3D Vision",{"className":"page__taxonomy-item","children":["#","3D Vision"]}]]}]]}]]}],["$","article","2025-8-26-MV-RAG-Retrieval-Augmented-Multiview-Diffusion",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-MV-RAG-Retrieval-Augmented-Multiview-Diffusion/","children":"[논문리뷰] MV-RAG: Retrieval Augmented Multiview Diffusion"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"sagiebenaim이 [arXiv]에 게시한 'MV-RAG: Retrieval Augmented Multiview Diffusion' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-26 13:21:57+0900","children":"2025년 8월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Retrieval Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval Augmented Generation"]}],["$","span","Multiview Diffusion",{"className":"page__taxonomy-item","children":["#","Multiview Diffusion"]}],["$","span","Text-to-3D Generation",{"className":"page__taxonomy-item","children":["#","Text-to-3D Generation"]}],["$","span","Out-of-Domain",{"className":"page__taxonomy-item","children":["#","Out-of-Domain"]}],["$","span","Image Retrieval",{"className":"page__taxonomy-item","children":["#","Image Retrieval"]}],["$","span","3D Consistency",{"className":"page__taxonomy-item","children":["#","3D Consistency"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Hybrid Training",{"className":"page__taxonomy-item","children":["#","Hybrid Training"]}]]}]]}]]}],["$","article","2025-8-26-MEENA-PersianMMMU-Multimodal-Multilingual-Educational-Exams-for-N-level-Assessment",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-MEENA-PersianMMMU-Multimodal-Multilingual-Educational-Exams-for-N-level-Assessment/","children":"[논문리뷰] MEENA (PersianMMMU): Multimodal-Multilingual Educational Exams for N-level Assessment"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Doratossadat Dastgheib이 [arXiv]에 게시한 'MEENA (PersianMMMU): Multimodal-Multilingual Educational Exams for N-level Assessment' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-26 13:21:57+0900","children":"2025년 8월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Language Models",{"className":"page__taxonomy-item","children":["#","Multimodal Language Models"]}],["$","span","Multilingual Benchmarking",{"className":"page__taxonomy-item","children":["#","Multilingual Benchmarking"]}],["$","span","Persian Language",{"className":"page__taxonomy-item","children":["#","Persian Language"]}],["$","span","Educational Assessment",{"className":"page__taxonomy-item","children":["#","Educational Assessment"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Cultural Nuance",{"className":"page__taxonomy-item","children":["#","Cultural Nuance"]}],["$","span","Reasoning Tasks",{"className":"page__taxonomy-item","children":["#","Reasoning Tasks"]}]]}]]}]]}],["$","article","2025-8-26-Limitations-of-Normalization-in-Attention-Mechanism",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-Limitations-of-Normalization-in-Attention-Mechanism/","children":"[논문리뷰] Limitations of Normalization in Attention Mechanism"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Radu State이 [arXiv]에 게시한 'Limitations of Normalization in Attention Mechanism' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-26 13:21:57+0900","children":"2025년 8월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Attention Mechanism",{"className":"page__taxonomy-item","children":["#","Attention Mechanism"]}],["$","span","Normalization",{"className":"page__taxonomy-item","children":["#","Normalization"]}],["$","span","Softmax",{"className":"page__taxonomy-item","children":["#","Softmax"]}],["$","span","Transformer Models",{"className":"page__taxonomy-item","children":["#","Transformer Models"]}],["$","span","Gradient Sensitivity",{"className":"page__taxonomy-item","children":["#","Gradient Sensitivity"]}],["$","span","Token Separability",{"className":"page__taxonomy-item","children":["#","Token Separability"]}],["$","span","Context Length",{"className":"page__taxonomy-item","children":["#","Context Length"]}],["$","span","GPT-2",{"className":"page__taxonomy-item","children":["#","GPT-2"]}]]}]]}]]}],["$","article","2025-8-26-InternVL3-5-Advancing-Open-Source-Multimodal-Models-in-Versatility-Reasoning-and-Efficiency",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-InternVL3-5-Advancing-Open-Source-Multimodal-Models-in-Versatility-Reasoning-and-Efficiency/","children":"[논문리뷰] InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"jinglinglin이 [arXiv]에 게시한 'InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-26 13:21:57+0900","children":"2025년 8월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Inference Efficiency",{"className":"page__taxonomy-item","children":["#","Inference Efficiency"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Open-Source",{"className":"page__taxonomy-item","children":["#","Open-Source"]}],["$","span","Versatility",{"className":"page__taxonomy-item","children":["#","Versatility"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}]]}]]}]]}],["$","article","2025-8-26-German4All-A-Dataset-and-Model-for-Readability-Controlled-Paraphrasing-in-German",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-German4All-A-Dataset-and-Model-for-Readability-Controlled-Paraphrasing-in-German/","children":"[논문리뷰] German4All - A Dataset and Model for Readability-Controlled Paraphrasing in German"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Cristian-George Craciun이 [arXiv]에 게시한 'German4All - A Dataset and Model for Readability-Controlled Paraphrasing in German' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-26 13:21:57+0900","children":"2025년 8월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text Simplification",{"className":"page__taxonomy-item","children":["#","Text Simplification"]}],["$","span","Paraphrasing",{"className":"page__taxonomy-item","children":["#","Paraphrasing"]}],["$","span","Readability Control",{"className":"page__taxonomy-item","children":["#","Readability Control"]}],["$","span","German NLP",{"className":"page__taxonomy-item","children":["#","German NLP"]}],["$","span","Dataset Generation",{"className":"page__taxonomy-item","children":["#","Dataset Generation"]}],["$","span","LLM Distillation",{"className":"page__taxonomy-item","children":["#","LLM Distillation"]}],["$","span","Multi-level Text Generation",{"className":"page__taxonomy-item","children":["#","Multi-level Text Generation"]}],["$","span","Accessibility",{"className":"page__taxonomy-item","children":["#","Accessibility"]}]]}]]}]]}],["$","article","2025-8-26-Explain-Before-You-Answer-A-Survey-on-Compositional-Visual-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-Explain-Before-You-Answer-A-Survey-on-Compositional-Visual-Reasoning/","children":"[논문리뷰] Explain Before You Answer: A Survey on Compositional Visual Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xin Zheng이 [arXiv]에 게시한 'Explain Before You Answer: A Survey on Compositional Visual Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-26 13:21:57+0900","children":"2025년 8월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Compositional Visual Reasoning",{"className":"page__taxonomy-item","children":["#","Compositional Visual Reasoning"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Tool Learning",{"className":"page__taxonomy-item","children":["#","Tool Learning"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Survey",{"className":"page__taxonomy-item","children":["#","Survey"]}]]}]]}]]}],["$","article","2025-8-26-Breaking-the-Exploration-Bottleneck-Rubric-Scaffolded-Reinforcement-Learning-for-General-LLM-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-Breaking-the-Exploration-Bottleneck-Rubric-Scaffolded-Reinforcement-Learning-for-General-LLM-Reasoning/","children":"[논문리뷰] Breaking the Exploration Bottleneck: Rubric-Scaffolded Reinforcement Learning for General LLM Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiale Zhao이 [arXiv]에 게시한 'Breaking the Exploration Bottleneck: Rubric-Scaffolded Reinforcement Learning for General LLM Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-26 13:21:57+0900","children":"2025년 8월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Exploration Bottleneck",{"className":"page__taxonomy-item","children":["#","Exploration Bottleneck"]}],["$","span","Instructional Scaffolding",{"className":"page__taxonomy-item","children":["#","Instructional Scaffolding"]}],["$","span","Rubric-based Rewards",{"className":"page__taxonomy-item","children":["#","Rubric-based Rewards"]}],["$","span","General Reasoning",{"className":"page__taxonomy-item","children":["#","General Reasoning"]}],["$","span","RL with Verifiable Rewards",{"className":"page__taxonomy-item","children":["#","RL with Verifiable Rewards"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}]]}]]}]]}],["$","article","2025-8-26-Beyond-Memorization-Extending-Reasoning-Depth-with-Recurrence-Memory-and-Test-Time-Compute-Scaling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-Beyond-Memorization-Extending-Reasoning-Depth-with-Recurrence-Memory-and-Test-Time-Compute-Scaling/","children":"[논문리뷰] Beyond Memorization: Extending Reasoning Depth with Recurrence, Memory and Test-Time Compute Scaling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Daniil Orel이 [arXiv]에 게시한 'Beyond Memorization: Extending Reasoning Depth with Recurrence, Memory and Test-Time Compute Scaling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-26 13:21:57+0900","children":"2025년 8월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reasoning Depth",{"className":"page__taxonomy-item","children":["#","Reasoning Depth"]}],["$","span","Cellular Automata",{"className":"page__taxonomy-item","children":["#","Cellular Automata"]}],["$","span","Transformer Architectures",{"className":"page__taxonomy-item","children":["#","Transformer Architectures"]}],["$","span","Recurrence",{"className":"page__taxonomy-item","children":["#","Recurrence"]}],["$","span","Adaptive Computation Time",{"className":"page__taxonomy-item","children":["#","Adaptive Computation Time"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}]]}]]}]]}],["$","article","2025-8-25-TPLA-Tensor-Parallel-Latent-Attention-for-Efficient-Disaggregated-Prefill-Decode-Inference",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-25-TPLA-Tensor-Parallel-Latent-Attention-for-Efficient-Disaggregated-Prefill-Decode-Inference/","children":"[논문리뷰] TPLA: Tensor Parallel Latent Attention for Efficient Disaggregated Prefill & Decode Inference"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Di Yin이 [arXiv]에 게시한 'TPLA: Tensor Parallel Latent Attention for Efficient Disaggregated Prefill & Decode Inference' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-25 13:13:07+0900","children":"2025년 8월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Inference",{"className":"page__taxonomy-item","children":["#","LLM Inference"]}],["$","span","Tensor Parallelism",{"className":"page__taxonomy-item","children":["#","Tensor Parallelism"]}],["$","span","KV Cache Optimization",{"className":"page__taxonomy-item","children":["#","KV Cache Optimization"]}],["$","span","Latent Attention",{"className":"page__taxonomy-item","children":["#","Latent Attention"]}],["$","span","Memory Efficiency",{"className":"page__taxonomy-item","children":["#","Memory Efficiency"]}],["$","span","Decoding Speedup",{"className":"page__taxonomy-item","children":["#","Decoding Speedup"]}],["$","span","Prefill/Decode Separation",{"className":"page__taxonomy-item","children":["#","Prefill/Decode Separation"]}],["$","span","Reparameterization",{"className":"page__taxonomy-item","children":["#","Reparameterization"]}]]}]]}]]}],["$","article","2025-8-25-Selective-Contrastive-Learning-for-Weakly-Supervised-Affordance-Grounding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-25-Selective-Contrastive-Learning-for-Weakly-Supervised-Affordance-Grounding/","children":"[논문리뷰] Selective Contrastive Learning for Weakly Supervised Affordance Grounding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jae-Pil Heo이 [arXiv]에 게시한 'Selective Contrastive Learning for Weakly Supervised Affordance Grounding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-25 13:13:07+0900","children":"2025년 8월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Weakly Supervised Learning",{"className":"page__taxonomy-item","children":["#","Weakly Supervised Learning"]}],["$","span","Affordance Grounding",{"className":"page__taxonomy-item","children":["#","Affordance Grounding"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","CLIP",{"className":"page__taxonomy-item","children":["#","CLIP"]}],["$","span","Part Discovery",{"className":"page__taxonomy-item","children":["#","Part Discovery"]}],["$","span","Object Localization",{"className":"page__taxonomy-item","children":["#","Object Localization"]}],["$","span","DINO",{"className":"page__taxonomy-item","children":["#","DINO"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}]]}]]}]]}],["$","article","2025-8-25-Learnable-SMPLify-A-Neural-Solution-for-Optimization-Free-Human-Pose-Inverse-Kinematics",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-25-Learnable-SMPLify-A-Neural-Solution-for-Optimization-Free-Human-Pose-Inverse-Kinematics/","children":"[논문리뷰] Learnable SMPLify: A Neural Solution for Optimization-Free Human Pose Inverse Kinematics"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiao Sun이 [arXiv]에 게시한 'Learnable SMPLify: A Neural Solution for Optimization-Free Human Pose Inverse Kinematics' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-25 13:13:07+0900","children":"2025년 8월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Inverse Kinematics",{"className":"page__taxonomy-item","children":["#","Inverse Kinematics"]}],["$","span","Human Pose Estimation",{"className":"page__taxonomy-item","children":["#","Human Pose Estimation"]}],["$","span","SMPL Model",{"className":"page__taxonomy-item","children":["#","SMPL Model"]}],["$","span","Neural Networks",{"className":"page__taxonomy-item","children":["#","Neural Networks"]}],["$","span","Optimization-Free",{"className":"page__taxonomy-item","children":["#","Optimization-Free"]}],["$","span","Residual Learning",{"className":"page__taxonomy-item","children":["#","Residual Learning"]}],["$","span","Data-Driven",{"className":"page__taxonomy-item","children":["#","Data-Driven"]}]]}]]}]]}],["$","article","2025-8-25-Jailbreaking-Commercial-Black-Box-LLMs-with-Explicitly-Harmful-Prompts",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-25-Jailbreaking-Commercial-Black-Box-LLMs-with-Explicitly-Harmful-Prompts/","children":"[논문리뷰] Jailbreaking Commercial Black-Box LLMs with Explicitly Harmful Prompts"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Liming Fang이 [arXiv]에 게시한 'Jailbreaking Commercial Black-Box LLMs with Explicitly Harmful Prompts' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-25 13:13:07+0900","children":"2025년 8월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Jailbreaking",{"className":"page__taxonomy-item","children":["#","LLM Jailbreaking"]}],["$","span","Red Teaming",{"className":"page__taxonomy-item","children":["#","Red Teaming"]}],["$","span","Malicious Content Detection",{"className":"page__taxonomy-item","children":["#","Malicious Content Detection"]}],["$","span","Developer Messages",{"className":"page__taxonomy-item","children":["#","Developer Messages"]}],["$","span","D-Attack",{"className":"page__taxonomy-item","children":["#","D-Attack"]}],["$","span","DH-CoT",{"className":"page__taxonomy-item","children":["#","DH-CoT"]}],["$","span","Adversarial Attacks",{"className":"page__taxonomy-item","children":["#","Adversarial Attacks"]}],["$","span","Dataset Cleaning",{"className":"page__taxonomy-item","children":["#","Dataset Cleaning"]}]]}]]}]]}],["$","article","2025-8-25-InMind-Evaluating-LLMs-in-Capturing-and-Applying-Individual-Human-Reasoning-Styles",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-25-InMind-Evaluating-LLMs-in-Capturing-and-Applying-Individual-Human-Reasoning-Styles/","children":"[논문리뷰] InMind: Evaluating LLMs in Capturing and Applying Individual Human Reasoning Styles"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Diping Song이 [arXiv]에 게시한 'InMind: Evaluating LLMs in Capturing and Applying Individual Human Reasoning Styles' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-25 13:13:07+0900","children":"2025년 8월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Human Reasoning Styles",{"className":"page__taxonomy-item","children":["#","Human Reasoning Styles"]}],["$","span","Social Deduction Games",{"className":"page__taxonomy-item","children":["#","Social Deduction Games"]}],["$","span","Theory of Mind",{"className":"page__taxonomy-item","children":["#","Theory of Mind"]}],["$","span","Adaptive Reasoning",{"className":"page__taxonomy-item","children":["#","Adaptive Reasoning"]}],["$","span","Avalon Game",{"className":"page__taxonomy-item","children":["#","Avalon Game"]}],["$","span","Cognitive Grounding",{"className":"page__taxonomy-item","children":["#","Cognitive Grounding"]}]]}]]}]]}],["$","article","2025-8-25-End-to-End-Agentic-RAG-System-Training-for-Traceable-Diagnostic-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-25-End-to-End-Agentic-RAG-System-Training-for-Traceable-Diagnostic-Reasoning/","children":"[논문리뷰] End-to-End Agentic RAG System Training for Traceable Diagnostic Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Pengcheng Qiu이 [arXiv]에 게시한 'End-to-End Agentic RAG System Training for Traceable Diagnostic Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-25 13:13:07+0900","children":"2025년 8월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic RAG",{"className":"page__taxonomy-item","children":["#","Agentic RAG"]}],["$","span","Medical Diagnosis",{"className":"page__taxonomy-item","children":["#","Medical Diagnosis"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Traceable AI",{"className":"page__taxonomy-item","children":["#","Traceable AI"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Clinical Decision Support",{"className":"page__taxonomy-item","children":["#","Clinical Decision Support"]}],["$","span","Out-of-Distribution Generalization",{"className":"page__taxonomy-item","children":["#","Out-of-Distribution Generalization"]}],["$","span","Reward Design",{"className":"page__taxonomy-item","children":["#","Reward Design"]}]]}]]}]]}],["$","article","2025-8-25-EgoTwin-Dreaming-Body-and-View-in-First-Person",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-25-EgoTwin-Dreaming-Body-and-View-in-First-Person/","children":"[논문리뷰] EgoTwin: Dreaming Body and View in First Person"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wentao Wang이 [arXiv]에 게시한 'EgoTwin: Dreaming Body and View in First Person' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-25 13:13:07+0900","children":"2025년 8월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Egocentric Video Generation",{"className":"page__taxonomy-item","children":["#","Egocentric Video Generation"]}],["$","span","Human Motion Synthesis",{"className":"page__taxonomy-item","children":["#","Human Motion Synthesis"]}],["$","span","Diffusion Transformers",{"className":"page__taxonomy-item","children":["#","Diffusion Transformers"]}],["$","span","Multimodal Generation",{"className":"page__taxonomy-item","children":["#","Multimodal Generation"]}],["$","span","Viewpoint Alignment",{"className":"page__taxonomy-item","children":["#","Viewpoint Alignment"]}],["$","span","Causal Interplay",{"className":"page__taxonomy-item","children":["#","Causal Interplay"]}],["$","span","First-Person Vision",{"className":"page__taxonomy-item","children":["#","First-Person Vision"]}]]}]]}]]}],["$","article","2025-8-25-Do-What-Teaching-Vision-Language-Action-Models-to-Reject-the-Impossible",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-25-Do-What-Teaching-Vision-Language-Action-Models-to-Reject-the-Impossible/","children":"[논문리뷰] Do What? Teaching Vision-Language-Action Models to Reject the Impossible"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Roei Herzig이 [arXiv]에 게시한 'Do What? Teaching Vision-Language-Action Models to Reject the Impossible' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-25 13:13:07+0900","children":"2025년 8월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action Models"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","False Premise Detection",{"className":"page__taxonomy-item","children":["#","False Premise Detection"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}],["$","span","Human-Robot Interaction",{"className":"page__taxonomy-item","children":["#","Human-Robot Interaction"]}],["$","span","Clarification",{"className":"page__taxonomy-item","children":["#","Clarification"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}]]}]]}]]}],["$","article","2025-8-25-CRISP-Persistent-Concept-Unlearning-via-Sparse-Autoencoders",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-25-CRISP-Persistent-Concept-Unlearning-via-Sparse-Autoencoders/","children":"[논문리뷰] CRISP: Persistent Concept Unlearning via Sparse Autoencoders"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yonatan Belinkov이 [arXiv]에 게시한 'CRISP: Persistent Concept Unlearning via Sparse Autoencoders' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-25 13:13:07+0900","children":"2025년 8월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Concept Unlearning",{"className":"page__taxonomy-item","children":["#","Concept Unlearning"]}],["$","span","Sparse Autoencoders (SAEs)",{"className":"page__taxonomy-item","children":["#","Sparse Autoencoders (SAEs)"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Parameter-Efficient Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Parameter-Efficient Fine-Tuning"]}],["$","span","Model Interpretability",{"className":"page__taxonomy-item","children":["#","Model Interpretability"]}],["$","span","Safety-Critical AI",{"className":"page__taxonomy-item","children":["#","Safety-Critical AI"]}],["$","span","Feature Suppression",{"className":"page__taxonomy-item","children":["#","Feature Suppression"]}],["$","span","WMDP Benchmark",{"className":"page__taxonomy-item","children":["#","WMDP Benchmark"]}]]}]]}]]}],["$","article","2025-8-25-CARFT-Boosting-LLM-Reasoning-via-Contrastive-Learning-with-Annotated-Chain-of-Thought-based-Reinforced-Fine-Tuning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-25-CARFT-Boosting-LLM-Reasoning-via-Contrastive-Learning-with-Annotated-Chain-of-Thought-based-Reinforced-Fine-Tuning/","children":"[논문리뷰] CARFT: Boosting LLM Reasoning via Contrastive Learning with Annotated Chain-of-Thought-based Reinforced Fine-Tuning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yulun Zhang이 [arXiv]에 게시한 'CARFT: Boosting LLM Reasoning via Contrastive Learning with Annotated Chain-of-Thought-based Reinforced Fine-Tuning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-25 13:13:07+0900","children":"2025년 8월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Reasoning",{"className":"page__taxonomy-item","children":["#","LLM Reasoning"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Chain-of-Thought (CoT)",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought (CoT)"]}],["$","span","Annotated Data",{"className":"page__taxonomy-item","children":["#","Annotated Data"]}],["$","span","Model Stability",{"className":"page__taxonomy-item","children":["#","Model Stability"]}]]}]]}]]}],["$","article","2025-8-25-Beyond-Pass1-Self-Play-with-Variational-Problem-Synthesis-Sustains-RLVR",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-25-Beyond-Pass1-Self-Play-with-Variational-Problem-Synthesis-Sustains-RLVR/","children":"[논문리뷰] Beyond Pass@1: Self-Play with Variational Problem Synthesis Sustains RLVR"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ying Nian Wu이 [arXiv]에 게시한 'Beyond Pass@1: Self-Play with Variational Problem Synthesis Sustains RLVR' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-25 13:13:07+0900","children":"2025년 8월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Self-Play",{"className":"page__taxonomy-item","children":["#","Self-Play"]}],["$","span","Variational Problem Synthesis",{"className":"page__taxonomy-item","children":["#","Variational Problem Synthesis"]}],["$","span","Policy Entropy",{"className":"page__taxonomy-item","children":["#","Policy Entropy"]}],["$","span","Pass@k",{"className":"page__taxonomy-item","children":["#","Pass@k"]}],["$","span","Reasoning Benchmarks",{"className":"page__taxonomy-item","children":["#","Reasoning Benchmarks"]}]]}]]}]]}],["$","article","2025-8-25-AgentScope-1-0-A-Developer-Centric-Framework-for-Building-Agentic-Applications",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-25-AgentScope-1-0-A-Developer-Centric-Framework-for-Building-Agentic-Applications/","children":"[논문리뷰] AgentScope 1.0: A Developer-Centric Framework for Building Agentic Applications"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Liuyi Yao이 [arXiv]에 게시한 'AgentScope 1.0: A Developer-Centric Framework for Building Agentic Applications' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-25 13:13:07+0900","children":"2025년 8월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Agentic Applications",{"className":"page__taxonomy-item","children":["#","Agentic Applications"]}],["$","span","ReAct Paradigm",{"className":"page__taxonomy-item","children":["#","ReAct Paradigm"]}],["$","span","Framework",{"className":"page__taxonomy-item","children":["#","Framework"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Developer Experience",{"className":"page__taxonomy-item","children":["#","Developer Experience"]}],["$","span","Evaluation",{"className":"page__taxonomy-item","children":["#","Evaluation"]}]]}]]}]]}],["$","article","2025-8-25-AetherCode-Evaluating-LLMs-Ability-to-Win-In-Premier-Programming-Competitions",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-25-AetherCode-Evaluating-LLMs-Ability-to-Win-In-Premier-Programming-Competitions/","children":"[논문리뷰] AetherCode: Evaluating LLMs' Ability to Win In Premier Programming Competitions"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yidi Du이 [arXiv]에 게시한 'AetherCode: Evaluating LLMs' Ability to Win In Premier Programming Competitions' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-25 13:13:07+0900","children":"2025년 8월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Competitive Programming",{"className":"page__taxonomy-item","children":["#","Competitive Programming"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Code Reasoning",{"className":"page__taxonomy-item","children":["#","Code Reasoning"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Test Case Generation",{"className":"page__taxonomy-item","children":["#","Test Case Generation"]}],["$","span","Programming Competitions",{"className":"page__taxonomy-item","children":["#","Programming Competitions"]}],["$","span","Algorithmic Problems",{"className":"page__taxonomy-item","children":["#","Algorithmic Problems"]}]]}]]}]]}],["$","article","2025-8-22-aiXiv-A-Next-Generation-Open-Access-Ecosystem-for-Scientific-Discovery-Generated-by-AI-Scientists",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-22-aiXiv-A-Next-Generation-Open-Access-Ecosystem-for-Scientific-Discovery-Generated-by-AI-Scientists/","children":"[논문리뷰] aiXiv: A Next-Generation Open Access Ecosystem for Scientific Discovery Generated by AI Scientists"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Heng Zhang이 [arXiv]에 게시한 'aiXiv: A Next-Generation Open Access Ecosystem for Scientific Discovery Generated by AI Scientists' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-22 13:10:52+0900","children":"2025년 8월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Agents",{"className":"page__taxonomy-item","children":["#","AI Agents"]}],["$","span","Open Access",{"className":"page__taxonomy-item","children":["#","Open Access"]}],["$","span","Scientific Discovery",{"className":"page__taxonomy-item","children":["#","Scientific Discovery"]}],["$","span","Peer Review",{"className":"page__taxonomy-item","children":["#","Peer Review"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Multi-agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-agent Systems"]}],["$","span","Prompt Injection",{"className":"page__taxonomy-item","children":["#","Prompt Injection"]}],["$","span","Iterative Refinement",{"className":"page__taxonomy-item","children":["#","Iterative Refinement"]}]]}]]}]]}],["$","article","2025-8-22-When-and-What-Diffusion-Grounded-VideoLLM-with-Entity-Aware-Segmentation-for-Long-Video-Understanding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-22-When-and-What-Diffusion-Grounded-VideoLLM-with-Entity-Aware-Segmentation-for-Long-Video-Understanding/","children":"[논문리뷰] When and What: Diffusion-Grounded VideoLLM with Entity Aware Segmentation for Long Video Understanding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Rui Guo이 [arXiv]에 게시한 'When and What: Diffusion-Grounded VideoLLM with Entity Aware Segmentation for Long Video Understanding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-22 13:10:52+0900","children":"2025년 8월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video-LLM",{"className":"page__taxonomy-item","children":["#","Video-LLM"]}],["$","span","Diffusion Model",{"className":"page__taxonomy-item","children":["#","Diffusion Model"]}],["$","span","Temporal Grounding",{"className":"page__taxonomy-item","children":["#","Temporal Grounding"]}],["$","span","Object Segmentation",{"className":"page__taxonomy-item","children":["#","Object Segmentation"]}],["$","span","Long Video Understanding",{"className":"page__taxonomy-item","children":["#","Long Video Understanding"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Video Question Answering",{"className":"page__taxonomy-item","children":["#","Video Question Answering"]}]]}]]}]]}],["$","article","2025-8-22-Waver-Wave-Your-Way-to-Lifelike-Video-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-22-Waver-Wave-Your-Way-to-Lifelike-Video-Generation/","children":"[논문리뷰] Waver: Wave Your Way to Lifelike Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yifu Zhang이 [arXiv]에 게시한 'Waver: Wave Your Way to Lifelike Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-22 13:10:52+0900","children":"2025년 8월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Foundation Model",{"className":"page__taxonomy-item","children":["#","Foundation Model"]}],["$","span","Diffusion Model",{"className":"page__taxonomy-item","children":["#","Diffusion Model"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Text-to-Video",{"className":"page__taxonomy-item","children":["#","Text-to-Video"]}],["$","span","Image-to-Video",{"className":"page__taxonomy-item","children":["#","Image-to-Video"]}],["$","span","Super-Resolution",{"className":"page__taxonomy-item","children":["#","Super-Resolution"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}]]}]]}]]}],["$","article","2025-8-22-Snap-Snap-Taking-Two-Images-to-Reconstruct-3D-Human-Gaussians-in-Milliseconds",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-22-Snap-Snap-Taking-Two-Images-to-Reconstruct-3D-Human-Gaussians-in-Milliseconds/","children":"[논문리뷰] Snap-Snap: Taking Two Images to Reconstruct 3D Human Gaussians in Milliseconds"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chuiyun Wu이 [arXiv]에 게시한 'Snap-Snap: Taking Two Images to Reconstruct 3D Human Gaussians in Milliseconds' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-22 13:10:52+0900","children":"2025년 8월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Human Reconstruction",{"className":"page__taxonomy-item","children":["#","3D Human Reconstruction"]}],["$","span","Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","Gaussian Splatting"]}],["$","span","Sparse View",{"className":"page__taxonomy-item","children":["#","Sparse View"]}],["$","span","Two-Image Input",{"className":"page__taxonomy-item","children":["#","Two-Image Input"]}],["$","span","Real-time Inference",{"className":"page__taxonomy-item","children":["#","Real-time Inference"]}],["$","span","Point Cloud Prediction",{"className":"page__taxonomy-item","children":["#","Point Cloud Prediction"]}],["$","span","Feed-forward Network",{"className":"page__taxonomy-item","children":["#","Feed-forward Network"]}]]}]]}]]}],["$","article","2025-8-22-SceneGen-Single-Image-3D-Scene-Generation-in-One-Feedforward-Pass",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-22-SceneGen-Single-Image-3D-Scene-Generation-in-One-Feedforward-Pass/","children":"[논문리뷰] SceneGen: Single-Image 3D Scene Generation in One Feedforward Pass"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ya Zhang이 [arXiv]에 게시한 'SceneGen: Single-Image 3D Scene Generation in One Feedforward Pass' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-22 13:10:52+0900","children":"2025년 8월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Scene Generation",{"className":"page__taxonomy-item","children":["#","3D Scene Generation"]}],["$","span","Single-Image Input",{"className":"page__taxonomy-item","children":["#","Single-Image Input"]}],["$","span","Feedforward Networks",{"className":"page__taxonomy-item","children":["#","Feedforward Networks"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Geometric Modeling",{"className":"page__taxonomy-item","children":["#","Geometric Modeling"]}],["$","span","Texture Synthesis",{"className":"page__taxonomy-item","children":["#","Texture Synthesis"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Feature Aggregation",{"className":"page__taxonomy-item","children":["#","Feature Aggregation"]}]]}]]}]]}],["$","article","2025-8-22-Mobile-Agent-v3-Foundamental-Agents-for-GUI-Automation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-22-Mobile-Agent-v3-Foundamental-Agents-for-GUI-Automation/","children":"[논문리뷰] Mobile-Agent-v3: Foundamental Agents for GUI Automation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Haowei Liu이 [arXiv]에 게시한 'Mobile-Agent-v3: Foundamental Agents for GUI Automation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-22 13:10:52+0900","children":"2025년 8월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","GUI Automation",{"className":"page__taxonomy-item","children":["#","GUI Automation"]}],["$","span","Multimodal Agents",{"className":"page__taxonomy-item","children":["#","Multimodal Agents"]}],["$","span","Foundational Models",{"className":"page__taxonomy-item","children":["#","Foundational Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Cross-Platform",{"className":"page__taxonomy-item","children":["#","Cross-Platform"]}],["$","span","Self-Supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-Supervised Learning"]}]]}]]}]]}],["$","article","2025-8-22-LiveMCP-101-Stress-Testing-and-Diagnosing-MCP-enabled-Agents-on-Challenging-Queries",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-22-LiveMCP-101-Stress-Testing-and-Diagnosing-MCP-enabled-Agents-on-Challenging-Queries/","children":"[논문리뷰] LiveMCP-101: Stress Testing and Diagnosing MCP-enabled Agents on Challenging Queries"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"huuuyeah이 [arXiv]에 게시한 'LiveMCP-101: Stress Testing and Diagnosing MCP-enabled Agents on Challenging Queries' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-22 13:10:52+0900","children":"2025년 8월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Agents",{"className":"page__taxonomy-item","children":["#","AI Agents"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Model Context Protocol (MCP)",{"className":"page__taxonomy-item","children":["#","Model Context Protocol (MCP)"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Real-world Tasks",{"className":"page__taxonomy-item","children":["#","Real-world Tasks"]}],["$","span","Evaluation",{"className":"page__taxonomy-item","children":["#","Evaluation"]}],["$","span","Error Analysis",{"className":"page__taxonomy-item","children":["#","Error Analysis"]}]]}]]}]]}],["$","article","2025-8-22-Intern-S1-A-Scientific-Multimodal-Foundation-Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-22-Intern-S1-A-Scientific-Multimodal-Foundation-Model/","children":"[논문리뷰] Intern-S1: A Scientific Multimodal Foundation Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"xuhuang87이 [arXiv]에 게시한 'Intern-S1: A Scientific Multimodal Foundation Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-22 13:10:52+0900","children":"2025년 8월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Foundation Model",{"className":"page__taxonomy-item","children":["#","Multimodal Foundation Model"]}],["$","span","Scientific AI",{"className":"page__taxonomy-item","children":["#","Scientific AI"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Mixture-of-Experts (MoE)",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts (MoE)"]}],["$","span","Dynamic Tokenizer",{"className":"page__taxonomy-item","children":["#","Dynamic Tokenizer"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Low-Resource Learning",{"className":"page__taxonomy-item","children":["#","Low-Resource Learning"]}]]}]]}]]}],["$","article","2025-8-22-INTIMA-A-Benchmark-for-Human-AI-Companionship-Behavior",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-22-INTIMA-A-Benchmark-for-Human-AI-Companionship-Behavior/","children":"[논문리뷰] INTIMA: A Benchmark for Human-AI Companionship Behavior"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yacine Jernite이 [arXiv]에 게시한 'INTIMA: A Benchmark for Human-AI Companionship Behavior' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-22 13:10:52+0900","children":"2025년 8월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Companionship",{"className":"page__taxonomy-item","children":["#","AI Companionship"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Language Models (LLMs)"]}],["$","span","Human-AI Interaction",{"className":"page__taxonomy-item","children":["#","Human-AI Interaction"]}],["$","span","Emotional AI",{"className":"page__taxonomy-item","children":["#","Emotional AI"]}],["$","span","Boundary Setting",{"className":"page__taxonomy-item","children":["#","Boundary Setting"]}],["$","span","Psychological Frameworks",{"className":"page__taxonomy-item","children":["#","Psychological Frameworks"]}],["$","span","Evaluation Metrics",{"className":"page__taxonomy-item","children":["#","Evaluation Metrics"]}]]}]]}]]}],["$","article","2025-8-22-Fin-PRM-A-Domain-Specialized-Process-Reward-Model-for-Financial-Reasoning-in-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-22-Fin-PRM-A-Domain-Specialized-Process-Reward-Model-for-Financial-Reasoning-in-Large-Language-Models/","children":"[논문리뷰] Fin-PRM: A Domain-Specialized Process Reward Model for Financial Reasoning in Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Lifan Guo이 [arXiv]에 게시한 'Fin-PRM: A Domain-Specialized Process Reward Model for Financial Reasoning in Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-22 13:10:52+0900","children":"2025년 8월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Process Reward Models",{"className":"page__taxonomy-item","children":["#","Process Reward Models"]}],["$","span","Financial Reasoning",{"className":"page__taxonomy-item","children":["#","Financial Reasoning"]}],["$","span","Domain Specialization",{"className":"page__taxonomy-item","children":["#","Domain Specialization"]}],["$","span","RLHF",{"className":"page__taxonomy-item","children":["#","RLHF"]}],["$","span","Best-of-N Selection",{"className":"page__taxonomy-item","children":["#","Best-of-N Selection"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}]]}]]}]]}],["$","article","2025-8-22-Does-the-cafe-entrance-look-accessible-Where-is-the-door-Towards-Geospatial-AI-Agents-for-Visual-Inquiries",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-22-Does-the-cafe-entrance-look-accessible-Where-is-the-door-Towards-Geospatial-AI-Agents-for-Visual-Inquiries/","children":"[논문리뷰] 'Does the cafe entrance look accessible? Where is the door?' Towards Geospatial AI Agents for Visual Inquiries"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xia Su이 [arXiv]에 게시한 'Does the cafe entrance look accessible? Where is the door? Towards Geospatial AI Agents for Visual Inquiries' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-22 13:10:52+0900","children":"2025년 8월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Geospatial AI",{"className":"page__taxonomy-item","children":["#","Geospatial AI"]}],["$","span","Multimodal AI Agents",{"className":"page__taxonomy-item","children":["#","Multimodal AI Agents"]}],["$","span","Visual Question Answering",{"className":"page__taxonomy-item","children":["#","Visual Question Answering"]}],["$","span","Accessibility",{"className":"page__taxonomy-item","children":["#","Accessibility"]}],["$","span","Street View Imagery",{"className":"page__taxonomy-item","children":["#","Street View Imagery"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}],["$","span","Human-Computer Interaction",{"className":"page__taxonomy-item","children":["#","Human-Computer Interaction"]}]]}]]}]]}],["$","article","2025-8-22-Deep-Think-with-Confidence",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-22-Deep-Think-with-Confidence/","children":"[논문리뷰] Deep Think with Confidence"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xuewei Wang이 [arXiv]에 게시한 'Deep Think with Confidence' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-22 13:10:52+0900","children":"2025년 8월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Reasoning",{"className":"page__taxonomy-item","children":["#","LLM Reasoning"]}],["$","span","Confidence Filtering",{"className":"page__taxonomy-item","children":["#","Confidence Filtering"]}],["$","span","Self-Consistency",{"className":"page__taxonomy-item","children":["#","Self-Consistency"]}],["$","span","Test-Time Optimization",{"className":"page__taxonomy-item","children":["#","Test-Time Optimization"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}],["$","span","Adaptive Sampling",{"className":"page__taxonomy-item","children":["#","Adaptive Sampling"]}],["$","span","Early Stopping",{"className":"page__taxonomy-item","children":["#","Early Stopping"]}],["$","span","Majority Voting",{"className":"page__taxonomy-item","children":["#","Majority Voting"]}]]}]]}]]}],["$","article","2025-8-22-ATLAS-Decoupling-Skeletal-and-Shape-Parameters-for-Expressive-Parametric-Human-Modeling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-22-ATLAS-Decoupling-Skeletal-and-Shape-Parameters-for-Expressive-Parametric-Human-Modeling/","children":"[논문리뷰] ATLAS: Decoupling Skeletal and Shape Parameters for Expressive Parametric Human Modeling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shunsuke Saito이 [arXiv]에 게시한 'ATLAS: Decoupling Skeletal and Shape Parameters for Expressive Parametric Human Modeling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-22 13:10:52+0900","children":"2025년 8월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Parametric Human Model",{"className":"page__taxonomy-item","children":["#","Parametric Human Model"]}],["$","span","3D Human Modeling",{"className":"page__taxonomy-item","children":["#","3D Human Modeling"]}],["$","span","Shape-Skeleton Decoupling",{"className":"page__taxonomy-item","children":["#","Shape-Skeleton Decoupling"]}],["$","span","Pose Correctives",{"className":"page__taxonomy-item","children":["#","Pose Correctives"]}],["$","span","Single Image Mesh Fitting",{"className":"page__taxonomy-item","children":["#","Single Image Mesh Fitting"]}],["$","span","Expressive Modeling",{"className":"page__taxonomy-item","children":["#","Expressive Modeling"]}],["$","span","Goliath Dataset",{"className":"page__taxonomy-item","children":["#","Goliath Dataset"]}]]}]]}]]}],["$","article","2025-8-22-A-Survey-on-Large-Language-Model-Benchmarks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-22-A-Survey-on-Large-Language-Model-Benchmarks/","children":"[논문리뷰] A Survey on Large Language Model Benchmarks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Siyi Li이 [arXiv]에 게시한 'A Survey on Large Language Model Benchmarks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-22 13:10:52+0900","children":"2025년 8월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Benchmarks",{"className":"page__taxonomy-item","children":["#","LLM Benchmarks"]}],["$","span","Evaluation",{"className":"page__taxonomy-item","children":["#","Evaluation"]}],["$","span","Systematic Review",{"className":"page__taxonomy-item","children":["#","Systematic Review"]}],["$","span","General Capabilities",{"className":"page__taxonomy-item","children":["#","General Capabilities"]}],["$","span","Domain-Specific Benchmarks",{"className":"page__taxonomy-item","children":["#","Domain-Specific Benchmarks"]}],["$","span","Target-Specific Benchmarks",{"className":"page__taxonomy-item","children":["#","Target-Specific Benchmarks"]}],["$","span","Data Contamination",{"className":"page__taxonomy-item","children":["#","Data Contamination"]}],["$","span","AI Ethics",{"className":"page__taxonomy-item","children":["#","AI Ethics"]}]]}]]}]]}],["$","article","2025-8-21-mSCoRe-a-Multilingual-and-Scalable-Benchmark-for-Skill-based-Commonsense-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-mSCoRe-a-Multilingual-and-Scalable-Benchmark-for-Skill-based-Commonsense-Reasoning/","children":"[논문리뷰] mSCoRe: a Multilingual and Scalable Benchmark for Skill-based Commonsense Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"anoperson이 [arXiv]에 게시한 'mSCoRe: a Multilingual and Scalable Benchmark for Skill-based Commonsense Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-21 13:15:28+0900","children":"2025년 8월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multilingual Benchmark",{"className":"page__taxonomy-item","children":["#","Multilingual Benchmark"]}],["$","span","Commonsense Reasoning",{"className":"page__taxonomy-item","children":["#","Commonsense Reasoning"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Reasoning Taxonomy",{"className":"page__taxonomy-item","children":["#","Reasoning Taxonomy"]}],["$","span","Benchmark Scaling",{"className":"page__taxonomy-item","children":["#","Benchmark Scaling"]}],["$","span","Data Synthesis",{"className":"page__taxonomy-item","children":["#","Data Synthesis"]}],["$","span","Cultural Nuances",{"className":"page__taxonomy-item","children":["#","Cultural Nuances"]}]]}]]}]]}],["$","article","2025-8-21-ViExam-Are-Vision-Language-Models-Better-than-Humans-on-Vietnamese-Multimodal-Exam-Questions",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-ViExam-Are-Vision-Language-Models-Better-than-Humans-on-Vietnamese-Multimodal-Exam-Questions/","children":"[논문리뷰] ViExam: Are Vision Language Models Better than Humans on Vietnamese Multimodal Exam Questions?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Daeyoung Kim이 [arXiv]에 게시한 'ViExam: Are Vision Language Models Better than Humans on Vietnamese Multimodal Exam Questions?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-21 13:15:28+0900","children":"2025년 8월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision Language Models",{"className":"page__taxonomy-item","children":["#","Vision Language Models"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Vietnamese Language",{"className":"page__taxonomy-item","children":["#","Vietnamese Language"]}],["$","span","Educational Assessment",{"className":"page__taxonomy-item","children":["#","Educational Assessment"]}],["$","span","Low-Resource Languages",{"className":"page__taxonomy-item","children":["#","Low-Resource Languages"]}],["$","span","Cross-Lingual Reasoning",{"className":"page__taxonomy-item","children":["#","Cross-Lingual Reasoning"]}],["$","span","ViExam",{"className":"page__taxonomy-item","children":["#","ViExam"]}],["$","span","Human-in-the-Loop",{"className":"page__taxonomy-item","children":["#","Human-in-the-Loop"]}]]}]]}]]}],["$","article","2025-8-21-Tinker-Diffusions-Gift-to-3D-Multi-View-Consistent-Editing-From-Sparse-Inputs-without-Per-Scene-Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-Tinker-Diffusions-Gift-to-3D-Multi-View-Consistent-Editing-From-Sparse-Inputs-without-Per-Scene-Optimization/","children":"[논문리뷰] Tinker: Diffusion's Gift to 3D--Multi-View Consistent Editing From Sparse Inputs without Per-Scene Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hao Chen이 [arXiv]에 게시한 'Tinker: Diffusion's Gift to 3D--Multi-View Consistent Editing From Sparse Inputs without Per-Scene Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-21 13:15:28+0900","children":"2025년 8월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Editing",{"className":"page__taxonomy-item","children":["#","3D Editing"]}],["$","span","Multi-View Consistency",{"className":"page__taxonomy-item","children":["#","Multi-View Consistency"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Sparse Input",{"className":"page__taxonomy-item","children":["#","Sparse Input"]}],["$","span","Zero-Shot Learning",{"className":"page__taxonomy-item","children":["#","Zero-Shot Learning"]}],["$","span","Scene Completion",{"className":"page__taxonomy-item","children":["#","Scene Completion"]}],["$","span","Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","Gaussian Splatting"]}]]}]]}]]}],["$","article","2025-8-21-RynnEC-Bringing-MLLMs-into-Embodied-World",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-RynnEC-Bringing-MLLMs-into-Embodied-World/","children":"[논문리뷰] RynnEC: Bringing MLLMs into Embodied World"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"jiangpinliu이 [arXiv]에 게시한 'RynnEC: Bringing MLLMs into Embodied World' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-21 13:15:28+0900","children":"2025년 8월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-modal Large Language Models",{"className":"page__taxonomy-item","children":["#","Multi-modal Large Language Models"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Embodied Cognition",{"className":"page__taxonomy-item","children":["#","Embodied Cognition"]}],["$","span","Video Understanding",{"className":"page__taxonomy-item","children":["#","Video Understanding"]}],["$","span","Instance Segmentation",{"className":"page__taxonomy-item","children":["#","Instance Segmentation"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}]]}]]}]]}],["$","article","2025-8-21-Refining-Contrastive-Learning-and-Homography-Relations-for-Multi-Modal-Recommendation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-Refining-Contrastive-Learning-and-Homography-Relations-for-Multi-Modal-Recommendation/","children":"[논문리뷰] Refining Contrastive Learning and Homography Relations for Multi-Modal Recommendation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shiqing Wu이 [arXiv]에 게시한 'Refining Contrastive Learning and Homography Relations for Multi-Modal Recommendation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-21 13:15:28+0900","children":"2025년 8월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-modal Recommendation",{"className":"page__taxonomy-item","children":["#","Multi-modal Recommendation"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Graph Neural Network",{"className":"page__taxonomy-item","children":["#","Graph Neural Network"]}],["$","span","Homography Relations",{"className":"page__taxonomy-item","children":["#","Homography Relations"]}],["$","span","Meta-network",{"className":"page__taxonomy-item","children":["#","Meta-network"]}],["$","span","Orthogonal Constraint",{"className":"page__taxonomy-item","children":["#","Orthogonal Constraint"]}],["$","span","Data Sparsity",{"className":"page__taxonomy-item","children":["#","Data Sparsity"]}]]}]]}]]}],["$","article","2025-8-21-Quantization-Meets-dLLMs-A-Systematic-Study-of-Post-training-Quantization-for-Diffusion-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-Quantization-Meets-dLLMs-A-Systematic-Study-of-Post-training-Quantization-for-Diffusion-LLMs/","children":"[논문리뷰] Quantization Meets dLLMs: A Systematic Study of Post-training Quantization for Diffusion LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Haobo Xu이 [arXiv]에 게시한 'Quantization Meets dLLMs: A Systematic Study of Post-training Quantization for Diffusion LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-21 13:15:28+0900","children":"2025년 8월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion LLMs",{"className":"page__taxonomy-item","children":["#","Diffusion LLMs"]}],["$","span","Post-training Quantization (PTQ)",{"className":"page__taxonomy-item","children":["#","Post-training Quantization (PTQ)"]}],["$","span","Model Compression",{"className":"page__taxonomy-item","children":["#","Model Compression"]}],["$","span","Activation Outliers",{"className":"page__taxonomy-item","children":["#","Activation Outliers"]}],["$","span","Quantization Methods",{"className":"page__taxonomy-item","children":["#","Quantization Methods"]}],["$","span","Efficient Deployment",{"className":"page__taxonomy-item","children":["#","Efficient Deployment"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}]]}]]}]]}],["$","article","2025-8-21-On-Policy-RL-Meets-Off-Policy-Experts-Harmonizing-Supervised-Fine-Tuning-and-Reinforcement-Learning-via-Dynamic-Weighting",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-On-Policy-RL-Meets-Off-Policy-Experts-Harmonizing-Supervised-Fine-Tuning-and-Reinforcement-Learning-via-Dynamic-Weighting/","children":"[논문리뷰] On-Policy RL Meets Off-Policy Experts: Harmonizing Supervised Fine-Tuning and Reinforcement Learning via Dynamic Weighting"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Guoyin Wang이 [arXiv]에 게시한 'On-Policy RL Meets Off-Policy Experts: Harmonizing Supervised Fine-Tuning and Reinforcement Learning via Dynamic Weighting' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-21 13:15:28+0900","children":"2025년 8월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Supervised Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning"]}],["$","span","On-Policy RL",{"className":"page__taxonomy-item","children":["#","On-Policy RL"]}],["$","span","Off-Policy Experts",{"className":"page__taxonomy-item","children":["#","Off-Policy Experts"]}],["$","span","Dynamic Weighting",{"className":"page__taxonomy-item","children":["#","Dynamic Weighting"]}],["$","span","LLM Alignment",{"className":"page__taxonomy-item","children":["#","LLM Alignment"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}]]}]]}]]}],["$","article","2025-8-21-NVIDIA-Nemotron-Nano-2-An-Accurate-and-Efficient-Hybrid-Mamba-Transformer-Reasoning-Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-NVIDIA-Nemotron-Nano-2-An-Accurate-and-Efficient-Hybrid-Mamba-Transformer-Reasoning-Model/","children":"[논문리뷰] NVIDIA Nemotron Nano 2: An Accurate and Efficient Hybrid Mamba-Transformer Reasoning Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"abercovich이 [arXiv]에 게시한 'NVIDIA Nemotron Nano 2: An Accurate and Efficient Hybrid Mamba-Transformer Reasoning Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-21 13:15:28+0900","children":"2025년 8월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Hybrid Architecture",{"className":"page__taxonomy-item","children":["#","Hybrid Architecture"]}],["$","span","Mamba-Transformer",{"className":"page__taxonomy-item","children":["#","Mamba-Transformer"]}],["$","span","Reasoning LLM",{"className":"page__taxonomy-item","children":["#","Reasoning LLM"]}],["$","span","Model Compression",{"className":"page__taxonomy-item","children":["#","Model Compression"]}],["$","span","Knowledge Distillation",{"className":"page__taxonomy-item","children":["#","Knowledge Distillation"]}],["$","span","Long Context",{"className":"page__taxonomy-item","children":["#","Long Context"]}],["$","span","High Throughput",{"className":"page__taxonomy-item","children":["#","High Throughput"]}],["$","span","FP8 Training",{"className":"page__taxonomy-item","children":["#","FP8 Training"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}]]}]]}]]}],["$","article","2025-8-21-MeshCoder-LLM-Powered-Structured-Mesh-Code-Generation-from-Point-Clouds",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-MeshCoder-LLM-Powered-Structured-Mesh-Code-Generation-from-Point-Clouds/","children":"[논문리뷰] MeshCoder: LLM-Powered Structured Mesh Code Generation from Point Clouds"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiangmiao이 [arXiv]에 게시한 'MeshCoder: LLM-Powered Structured Mesh Code Generation from Point Clouds' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-21 13:15:28+0900","children":"2025년 8월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Point Clouds",{"className":"page__taxonomy-item","children":["#","Point Clouds"]}],["$","span","3D Reconstruction",{"className":"page__taxonomy-item","children":["#","3D Reconstruction"]}],["$","span","Structured Mesh",{"className":"page__taxonomy-item","children":["#","Structured Mesh"]}],["$","span","Blender Python",{"className":"page__taxonomy-item","children":["#","Blender Python"]}],["$","span","Shape Editing",{"className":"page__taxonomy-item","children":["#","Shape Editing"]}],["$","span","Part-based Representation",{"className":"page__taxonomy-item","children":["#","Part-based Representation"]}],["$","span","Large Language Model",{"className":"page__taxonomy-item","children":["#","Large Language Model"]}]]}]]}]]}],["$","article","2025-8-21-MCP-Universe-Benchmarking-Large-Language-Models-with-Real-World-Model-Context-Protocol-Servers",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-MCP-Universe-Benchmarking-Large-Language-Models-with-Real-World-Model-Context-Protocol-Servers/","children":"[논문리뷰] MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Prathyusha Jwalapuram이 [arXiv]에 게시한 'MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-21 13:15:28+0900","children":"2025년 8월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Model Context Protocol",{"className":"page__taxonomy-item","children":["#","Model Context Protocol"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Real-World Applications",{"className":"page__taxonomy-item","children":["#","Real-World Applications"]}],["$","span","Agent Evaluation",{"className":"page__taxonomy-item","children":["#","Agent Evaluation"]}],["$","span","Long Context",{"className":"page__taxonomy-item","children":["#","Long Context"]}],["$","span","Unknown Tools",{"className":"page__taxonomy-item","children":["#","Unknown Tools"]}]]}]]}]]}],["$","article","2025-8-21-Local-Scale-Equivariance-with-Latent-Deep-Equilibrium-Canonicalizer",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-Local-Scale-Equivariance-with-Latent-Deep-Equilibrium-Canonicalizer/","children":"[논문리뷰] Local Scale Equivariance with Latent Deep Equilibrium Canonicalizer"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jeremiah Jiang이 [arXiv]에 게시한 'Local Scale Equivariance with Latent Deep Equilibrium Canonicalizer' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-21 13:15:28+0900","children":"2025년 8월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Scale Equivariance",{"className":"page__taxonomy-item","children":["#","Scale Equivariance"]}],["$","span","Deep Equilibrium Models",{"className":"page__taxonomy-item","children":["#","Deep Equilibrium Models"]}],["$","span","Canonicalization",{"className":"page__taxonomy-item","children":["#","Canonicalization"]}],["$","span","Computer Vision",{"className":"page__taxonomy-item","children":["#","Computer Vision"]}],["$","span","Image Classification",{"className":"page__taxonomy-item","children":["#","Image Classification"]}],["$","span","Semantic Segmentation",{"className":"page__taxonomy-item","children":["#","Semantic Segmentation"]}],["$","span","Latent Representation",{"className":"page__taxonomy-item","children":["#","Latent Representation"]}],["$","span","Monotone Scaling",{"className":"page__taxonomy-item","children":["#","Monotone Scaling"]}]]}]]}]]}],["$","article","2025-8-21-Leuvenshtein-Efficient-FHE-based-Edit-Distance-Computation-with-Single-Bootstrap-per-Cell",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-Leuvenshtein-Efficient-FHE-based-Edit-Distance-Computation-with-Single-Bootstrap-per-Cell/","children":"[논문리뷰] Leuvenshtein: Efficient FHE-based Edit Distance Computation with Single Bootstrap per Cell"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ingrid Verbauwhede이 [arXiv]에 게시한 'Leuvenshtein: Efficient FHE-based Edit Distance Computation with Single Bootstrap per Cell' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-21 13:15:28+0900","children":"2025년 8월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Fully Homomorphic Encryption (FHE)",{"className":"page__taxonomy-item","children":["#","Fully Homomorphic Encryption (FHE)"]}],["$","span","TFHE",{"className":"page__taxonomy-item","children":["#","TFHE"]}],["$","span","Levenshtein Distance",{"className":"page__taxonomy-item","children":["#","Levenshtein Distance"]}],["$","span","Programmable Bootstrapping (PBS)",{"className":"page__taxonomy-item","children":["#","Programmable Bootstrapping (PBS)"]}],["$","span","Privacy-Preserving Computation",{"className":"page__taxonomy-item","children":["#","Privacy-Preserving Computation"]}],["$","span","String Similarity",{"className":"page__taxonomy-item","children":["#","String Similarity"]}]]}]]}]]}],["$","article","2025-8-21-FutureX-An-Advanced-Live-Benchmark-for-LLM-Agents-in-Future-Prediction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-FutureX-An-Advanced-Live-Benchmark-for-LLM-Agents-in-Future-Prediction/","children":"[논문리뷰] FutureX: An Advanced Live Benchmark for LLM Agents in Future Prediction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"tianlecai이 [arXiv]에 게시한 'FutureX: An Advanced Live Benchmark for LLM Agents in Future Prediction' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-21 13:15:28+0900","children":"2025년 8월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Future Prediction",{"className":"page__taxonomy-item","children":["#","Future Prediction"]}],["$","span","Live Benchmark",{"className":"page__taxonomy-item","children":["#","Live Benchmark"]}],["$","span","Dynamic Evaluation",{"className":"page__taxonomy-item","children":["#","Dynamic Evaluation"]}],["$","span","Data Contamination",{"className":"page__taxonomy-item","children":["#","Data Contamination"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Web Search",{"className":"page__taxonomy-item","children":["#","Web Search"]}],["$","span","Financial Forecasting",{"className":"page__taxonomy-item","children":["#","Financial Forecasting"]}],["$","span","Misinformation",{"className":"page__taxonomy-item","children":["#","Misinformation"]}]]}]]}]]}],["$","article","2025-8-21-From-Scores-to-Skills-A-Cognitive-Diagnosis-Framework-for-Evaluating-Financial-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-From-Scores-to-Skills-A-Cognitive-Diagnosis-Framework-for-Evaluating-Financial-Large-Language-Models/","children":"[논문리뷰] From Scores to Skills: A Cognitive Diagnosis Framework for Evaluating Financial Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ziyan Kuang이 [arXiv]에 게시한 'From Scores to Skills: A Cognitive Diagnosis Framework for Evaluating Financial Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-21 13:15:28+0900","children":"2025년 8월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Financial LLMs",{"className":"page__taxonomy-item","children":["#","Financial LLMs"]}],["$","span","Cognitive Diagnosis Model",{"className":"page__taxonomy-item","children":["#","Cognitive Diagnosis Model"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Knowledge Assessment",{"className":"page__taxonomy-item","children":["#","Knowledge Assessment"]}],["$","span","Matrix Factorization",{"className":"page__taxonomy-item","children":["#","Matrix Factorization"]}],["$","span","CPA-QKA",{"className":"page__taxonomy-item","children":["#","CPA-QKA"]}],["$","span","Interpretability",{"className":"page__taxonomy-item","children":["#","Interpretability"]}]]}]]}]]}],["$","article","2025-8-21-From-AI-for-Science-to-Agentic-Science-A-Survey-on-Autonomous-Scientific-Discovery",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-From-AI-for-Science-to-Agentic-Science-A-Survey-on-Autonomous-Scientific-Discovery/","children":"[논문리뷰] From AI for Science to Agentic Science: A Survey on Autonomous Scientific Discovery"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"zijieqiu이 [arXiv]에 게시한 'From AI for Science to Agentic Science: A Survey on Autonomous Scientific Discovery' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-21 13:15:28+0900","children":"2025년 8월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Autonomous Scientific Discovery",{"className":"page__taxonomy-item","children":["#","Autonomous Scientific Discovery"]}],["$","span","AI for Science",{"className":"page__taxonomy-item","children":["#","AI for Science"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Multi-agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-agent Systems"]}],["$","span","Scientific Workflow Automation",{"className":"page__taxonomy-item","children":["#","Scientific Workflow Automation"]}],["$","span","Natural Sciences",{"className":"page__taxonomy-item","children":["#","Natural Sciences"]}]]}]]}]]}],["$","article","2025-8-21-DuPO-Enabling-Reliable-LLM-Self-Verification-via-Dual-Preference-Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-DuPO-Enabling-Reliable-LLM-Self-Verification-via-Dual-Preference-Optimization/","children":"[논문리뷰] DuPO: Enabling Reliable LLM Self-Verification via Dual Preference Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yu Lu이 [arXiv]에 게시한 'DuPO: Enabling Reliable LLM Self-Verification via Dual Preference Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-21 13:15:28+0900","children":"2025년 8월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Optimization",{"className":"page__taxonomy-item","children":["#","LLM Optimization"]}],["$","span","Self-Verification",{"className":"page__taxonomy-item","children":["#","Self-Verification"]}],["$","span","Dual Learning",{"className":"page__taxonomy-item","children":["#","Dual Learning"]}],["$","span","Preference Optimization",{"className":"page__taxonomy-item","children":["#","Preference Optimization"]}],["$","span","Self-Supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-Supervised Learning"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Multilingual Translation",{"className":"page__taxonomy-item","children":["#","Multilingual Translation"]}],["$","span","RLHF",{"className":"page__taxonomy-item","children":["#","RLHF"]}]]}]]}]]}],["$","article","2025-8-20-ZARA-Zero-shot-Motion-Time-Series-Analysis-via-Knowledge-and-Retrieval-Driven-LLM-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-ZARA-Zero-shot-Motion-Time-Series-Analysis-via-Knowledge-and-Retrieval-Driven-LLM-Agents/","children":"[논문리뷰] ZARA: Zero-shot Motion Time-Series Analysis via Knowledge and Retrieval Driven LLM Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Flora D. Salim이 [arXiv]에 게시한 'ZARA: Zero-shot Motion Time-Series Analysis via Knowledge and Retrieval Driven LLM Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Zero-shot HAR",{"className":"page__taxonomy-item","children":["#","Zero-shot HAR"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Time-Series Analysis",{"className":"page__taxonomy-item","children":["#","Time-Series Analysis"]}],["$","span","Knowledge Base",{"className":"page__taxonomy-item","children":["#","Knowledge Base"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","Multi-sensor Fusion",{"className":"page__taxonomy-item","children":["#","Multi-sensor Fusion"]}],["$","span","Interpretability",{"className":"page__taxonomy-item","children":["#","Interpretability"]}]]}]]}]]}],["$","article","2025-8-20-Training-Free-Text-Guided-Color-Editing-with-Multi-Modal-Diffusion-Transformer",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-Training-Free-Text-Guided-Color-Editing-with-Multi-Modal-Diffusion-Transformer/","children":"[논문리뷰] Training-Free Text-Guided Color Editing with Multi-Modal Diffusion Transformer"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Deyu Zhou이 [arXiv]에 게시한 'Training-Free Text-Guided Color Editing with Multi-Modal Diffusion Transformer' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-Guided Editing",{"className":"page__taxonomy-item","children":["#","Text-Guided Editing"]}],["$","span","Color Editing",{"className":"page__taxonomy-item","children":["#","Color Editing"]}],["$","span","Diffusion Transformers",{"className":"page__taxonomy-item","children":["#","Diffusion Transformers"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}],["$","span","Multi-Modal AI",{"className":"page__taxonomy-item","children":["#","Multi-Modal AI"]}],["$","span","Attention Control",{"className":"page__taxonomy-item","children":["#","Attention Control"]}],["$","span","Image Manipulation",{"className":"page__taxonomy-item","children":["#","Image Manipulation"]}]]}]]}]]}],["$","article","2025-8-20-TempFlow-GRPO-When-Timing-Matters-for-GRPO-in-Flow-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-TempFlow-GRPO-When-Timing-Matters-for-GRPO-in-Flow-Models/","children":"[논문리뷰] TempFlow-GRPO: When Timing Matters for GRPO in Flow Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jian Yang이 [arXiv]에 게시한 'TempFlow-GRPO: When Timing Matters for GRPO in Flow Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Human Preference Alignment",{"className":"page__taxonomy-item","children":["#","Human Preference Alignment"]}],["$","span","GRPO",{"className":"page__taxonomy-item","children":["#","GRPO"]}],["$","span","Temporal Credit Assignment",{"className":"page__taxonomy-item","children":["#","Temporal Credit Assignment"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Text-to-Image",{"className":"page__taxonomy-item","children":["#","Text-to-Image"]}]]}]]}]]}],["$","article","2025-8-20-Semantic-IDs-for-Joint-Generative-Search-and-Recommendation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-Semantic-IDs-for-Joint-Generative-Search-and-Recommendation/","children":"[논문리뷰] Semantic IDs for Joint Generative Search and Recommendation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Enrico Palumbo이 [arXiv]에 게시한 'Semantic IDs for Joint Generative Search and Recommendation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Search and Recommendation",{"className":"page__taxonomy-item","children":["#","Search and Recommendation"]}],["$","span","Semantic IDs",{"className":"page__taxonomy-item","children":["#","Semantic IDs"]}],["$","span","Bi-Encoder",{"className":"page__taxonomy-item","children":["#","Bi-Encoder"]}],["$","span","Quantization",{"className":"page__taxonomy-item","children":["#","Quantization"]}],["$","span","Multi-Task Learning",{"className":"page__taxonomy-item","children":["#","Multi-Task Learning"]}],["$","span","Retrieval Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval Augmented Generation"]}]]}]]}]]}],["$","article","2025-8-20-Radiance-Fields-in-XR-A-Survey-on-How-Radiance-Fields-are-Envisioned-and-Addressed-for-XR-Research",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-Radiance-Fields-in-XR-A-Survey-on-How-Radiance-Fields-are-Envisioned-and-Addressed-for-XR-Research/","children":"[논문리뷰] Radiance Fields in XR: A Survey on How Radiance Fields are Envisioned and Addressed for XR Research"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Susanne Schmidt이 [arXiv]에 게시한 'Radiance Fields in XR: A Survey on How Radiance Fields are Envisioned and Addressed for XR Research' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Radiance Fields",{"className":"page__taxonomy-item","children":["#","Radiance Fields"]}],["$","span","XR",{"className":"page__taxonomy-item","children":["#","XR"]}],["$","span","NeRF",{"className":"page__taxonomy-item","children":["#","NeRF"]}],["$","span","3D Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","3D Gaussian Splatting"]}],["$","span","View Synthesis",{"className":"page__taxonomy-item","children":["#","View Synthesis"]}],["$","span","Systematic Review",{"className":"page__taxonomy-item","children":["#","Systematic Review"]}],["$","span","Immersive Technology",{"className":"page__taxonomy-item","children":["#","Immersive Technology"]}]]}]]}]]}],["$","article","2025-8-20-Prompt-Orchestration-Markup-Language",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-Prompt-Orchestration-Markup-Language/","children":"[논문리뷰] Prompt Orchestration Markup Language"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuqing Yang이 [arXiv]에 게시한 'Prompt Orchestration Markup Language' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Markup Language",{"className":"page__taxonomy-item","children":["#","Markup Language"]}],["$","span","Structured Prompting",{"className":"page__taxonomy-item","children":["#","Structured Prompting"]}],["$","span","IDE Support",{"className":"page__taxonomy-item","children":["#","IDE Support"]}],["$","span","Multimodal Data",{"className":"page__taxonomy-item","children":["#","Multimodal Data"]}],["$","span","Styling System",{"className":"page__taxonomy-item","children":["#","Styling System"]}],["$","span","Development Toolkit",{"className":"page__taxonomy-item","children":["#","Development Toolkit"]}]]}]]}]]}],["$","article","2025-8-20-OmniTry-Virtual-Try-On-Anything-without-Masks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-OmniTry-Virtual-Try-On-Anything-without-Masks/","children":"[논문리뷰] OmniTry: Virtual Try-On Anything without Masks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiaoduan Feng이 [arXiv]에 게시한 'OmniTry: Virtual Try-On Anything without Masks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Virtual Try-On",{"className":"page__taxonomy-item","children":["#","Virtual Try-On"]}],["$","span","Diffusion Model",{"className":"page__taxonomy-item","children":["#","Diffusion Model"]}],["$","span","Mask-Free",{"className":"page__taxonomy-item","children":["#","Mask-Free"]}],["$","span","Image Inpainting",{"className":"page__taxonomy-item","children":["#","Image Inpainting"]}],["$","span","ID Consistency",{"className":"page__taxonomy-item","children":["#","ID Consistency"]}],["$","span","Wearable Objects",{"className":"page__taxonomy-item","children":["#","Wearable Objects"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}]]}]]}]]}],["$","article","2025-8-20-MultiRef-Controllable-Image-Generation-with-Multiple-Visual-References",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-MultiRef-Controllable-Image-Generation-with-Multiple-Visual-References/","children":"[논문리뷰] MultiRef: Controllable Image Generation with Multiple Visual References"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shiyun Lang이 [arXiv]에 게시한 'MultiRef: Controllable Image Generation with Multiple Visual References' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Controllable Image Generation",{"className":"page__taxonomy-item","children":["#","Controllable Image Generation"]}],["$","span","Multi-modal Generation",{"className":"page__taxonomy-item","children":["#","Multi-modal Generation"]}],["$","span","Visual References",{"className":"page__taxonomy-item","children":["#","Visual References"]}],["$","span","Image-to-Image",{"className":"page__taxonomy-item","children":["#","Image-to-Image"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}],["$","span","MLLM-as-a-Judge",{"className":"page__taxonomy-item","children":["#","MLLM-as-a-Judge"]}]]}]]}]]}],["$","article","2025-8-20-Motion2Motion-Cross-topology-Motion-Transfer-with-Sparse-Correspondence",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-Motion2Motion-Cross-topology-Motion-Transfer-with-Sparse-Correspondence/","children":"[논문리뷰] Motion2Motion: Cross-topology Motion Transfer with Sparse Correspondence"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xin Chen이 [arXiv]에 게시한 'Motion2Motion: Cross-topology Motion Transfer with Sparse Correspondence' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Motion Transfer",{"className":"page__taxonomy-item","children":["#","Motion Transfer"]}],["$","span","Cross-topology",{"className":"page__taxonomy-item","children":["#","Cross-topology"]}],["$","span","Sparse Correspondence",{"className":"page__taxonomy-item","children":["#","Sparse Correspondence"]}],["$","span","Motion Matching",{"className":"page__taxonomy-item","children":["#","Motion Matching"]}],["$","span","Animation",{"className":"page__taxonomy-item","children":["#","Animation"]}],["$","span","Training-free",{"className":"page__taxonomy-item","children":["#","Training-free"]}],["$","span","Few-shot Learning",{"className":"page__taxonomy-item","children":["#","Few-shot Learning"]}]]}]]}]]}],["$","article","2025-8-20-Mind-the-Generation-Process-Fine-Grained-Confidence-Estimation-During-LLM-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-Mind-the-Generation-Process-Fine-Grained-Confidence-Estimation-During-LLM-Generation/","children":"[논문리뷰] Mind the Generation Process: Fine-Grained Confidence Estimation During LLM Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xinyi Wang이 [arXiv]에 게시한 'Mind the Generation Process: Fine-Grained Confidence Estimation During LLM Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Confidence Estimation",{"className":"page__taxonomy-item","children":["#","Confidence Estimation"]}],["$","span","Fine-Grained",{"className":"page__taxonomy-item","children":["#","Fine-Grained"]}],["$","span","Generation Process",{"className":"page__taxonomy-item","children":["#","Generation Process"]}],["$","span","Calibration",{"className":"page__taxonomy-item","children":["#","Calibration"]}],["$","span","Monte Carlo Sampling",{"className":"page__taxonomy-item","children":["#","Monte Carlo Sampling"]}],["$","span","Backward Confidence Integration",{"className":"page__taxonomy-item","children":["#","Backward Confidence Integration"]}]]}]]}]]}],["$","article","2025-8-20-MedSAMix-A-Training-Free-Model-Merging-Approach-for-Medical-Image-Segmentation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-MedSAMix-A-Training-Free-Model-Merging-Approach-for-Medical-Image-Segmentation/","children":"[논문리뷰] MedSAMix: A Training-Free Model Merging Approach for Medical Image Segmentation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jonas Geiping이 [arXiv]에 게시한 'MedSAMix: A Training-Free Model Merging Approach for Medical Image Segmentation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Medical Image Segmentation",{"className":"page__taxonomy-item","children":["#","Medical Image Segmentation"]}],["$","span","Model Merging",{"className":"page__taxonomy-item","children":["#","Model Merging"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}],["$","span","SAM",{"className":"page__taxonomy-item","children":["#","SAM"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Zero-Order Optimization",{"className":"page__taxonomy-item","children":["#","Zero-Order Optimization"]}],["$","span","Bayesian Optimization",{"className":"page__taxonomy-item","children":["#","Bayesian Optimization"]}]]}]]}]]}],["$","article","2025-8-20-MMAU-Pro-A-Challenging-and-Comprehensive-Benchmark-for-Holistic-Evaluation-of-Audio-General-Intelligence",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-MMAU-Pro-A-Challenging-and-Comprehensive-Benchmark-for-Holistic-Evaluation-of-Audio-General-Intelligence/","children":"[논문리뷰] MMAU-Pro: A Challenging and Comprehensive Benchmark for Holistic Evaluation of Audio General Intelligence"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Fernando López이 [arXiv]에 게시한 'MMAU-Pro: A Challenging and Comprehensive Benchmark for Holistic Evaluation of Audio General Intelligence' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Audio Intelligence",{"className":"page__taxonomy-item","children":["#","Audio Intelligence"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Audio-Language Models",{"className":"page__taxonomy-item","children":["#","Audio-Language Models"]}],["$","span","Holistic Evaluation",{"className":"page__taxonomy-item","children":["#","Holistic Evaluation"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Long-Form Audio",{"className":"page__taxonomy-item","children":["#","Long-Form Audio"]}],["$","span","Multicultural Music",{"className":"page__taxonomy-item","children":["#","Multicultural Music"]}]]}]]}]]}],["$","article","2025-8-20-MM-BrowseComp-A-Comprehensive-Benchmark-for-Multimodal-Browsing-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-MM-BrowseComp-A-Comprehensive-Benchmark-for-Multimodal-Browsing-Agents/","children":"[논문리뷰] MM-BrowseComp: A Comprehensive Benchmark for Multimodal Browsing Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jun Dong이 [arXiv]에 게시한 'MM-BrowseComp: A Comprehensive Benchmark for Multimodal Browsing Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Browsing",{"className":"page__taxonomy-item","children":["#","Multimodal Browsing"]}],["$","span","AI Agents",{"className":"page__taxonomy-item","children":["#","AI Agents"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Deep Search",{"className":"page__taxonomy-item","children":["#","Deep Search"]}]]}]]}]]}],["$","article","2025-8-20-LongSplat-Robust-Unposed-3D-Gaussian-Splatting-for-Casual-Long-Videos",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-LongSplat-Robust-Unposed-3D-Gaussian-Splatting-for-Casual-Long-Videos/","children":"[논문리뷰] LongSplat: Robust Unposed 3D Gaussian Splatting for Casual Long Videos"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yen-Yu Lin이 [arXiv]에 게시한 'LongSplat: Robust Unposed 3D Gaussian Splatting for Casual Long Videos' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Novel View Synthesis",{"className":"page__taxonomy-item","children":["#","Novel View Synthesis"]}],["$","span","3D Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","3D Gaussian Splatting"]}],["$","span","Unposed Reconstruction",{"className":"page__taxonomy-item","children":["#","Unposed Reconstruction"]}],["$","span","Camera Pose Estimation",{"className":"page__taxonomy-item","children":["#","Camera Pose Estimation"]}],["$","span","Incremental Optimization",{"className":"page__taxonomy-item","children":["#","Incremental Optimization"]}],["$","span","Octree",{"className":"page__taxonomy-item","children":["#","Octree"]}],["$","span","Long Videos",{"className":"page__taxonomy-item","children":["#","Long Videos"]}]]}]]}]]}],["$","article","2025-8-20-Leveraging-Large-Language-Models-for-Predictive-Analysis-of-Human-Misery",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-Leveraging-Large-Language-Models-for-Predictive-Analysis-of-Human-Misery/","children":"[논문리뷰] Leveraging Large Language Models for Predictive Analysis of Human Misery"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Abhilash Nandy이 [arXiv]에 게시한 'Leveraging Large Language Models for Predictive Analysis of Human Misery' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Affective Computing",{"className":"page__taxonomy-item","children":["#","Affective Computing"]}],["$","span","Misery Score Prediction",{"className":"page__taxonomy-item","children":["#","Misery Score Prediction"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","Few-shot Learning",{"className":"page__taxonomy-item","children":["#","Few-shot Learning"]}],["$","span","Gamified Evaluation",{"className":"page__taxonomy-item","children":["#","Gamified Evaluation"]}],["$","span","Feedback-driven Adaptation",{"className":"page__taxonomy-item","children":["#","Feedback-driven Adaptation"]}]]}]]}]]}],["$","article","2025-8-20-Evaluating-Podcast-Recommendations-with-Profile-Aware-LLM-as-a-Judge",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-Evaluating-Podcast-Recommendations-with-Profile-Aware-LLM-as-a-Judge/","children":"[논문리뷰] Evaluating Podcast Recommendations with Profile-Aware LLM-as-a-Judge"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Alice Wang이 [arXiv]에 게시한 'Evaluating Podcast Recommendations with Profile-Aware LLM-as-a-Judge' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Podcast Recommendation",{"className":"page__taxonomy-item","children":["#","Podcast Recommendation"]}],["$","span","LLM-as-a-Judge",{"className":"page__taxonomy-item","children":["#","LLM-as-a-Judge"]}],["$","span","Offline Evaluation",{"className":"page__taxonomy-item","children":["#","Offline Evaluation"]}],["$","span","User Profiling",{"className":"page__taxonomy-item","children":["#","User Profiling"]}],["$","span","Recommender Systems",{"className":"page__taxonomy-item","children":["#","Recommender Systems"]}],["$","span","Natural Language Processing",{"className":"page__taxonomy-item","children":["#","Natural Language Processing"]}]]}]]}]]}],["$","article","2025-8-20-Embodied-R1-Reinforced-Embodied-Reasoning-for-General-Robotic-Manipulation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-Embodied-R1-Reinforced-Embodied-Reasoning-for-General-Robotic-Manipulation/","children":"[논문리뷰] Embodied-R1: Reinforced Embodied Reasoning for General Robotic Manipulation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Fei Ni이 [arXiv]에 게시한 'Embodied-R1: Reinforced Embodied Reasoning for General Robotic Manipulation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Robotic Manipulation",{"className":"page__taxonomy-item","children":["#","Robotic Manipulation"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Vision-Language Model",{"className":"page__taxonomy-item","children":["#","Vision-Language Model"]}],["$","span","Pointing",{"className":"page__taxonomy-item","children":["#","Pointing"]}],["$","span","Zero-shot Generalization",{"className":"page__taxonomy-item","children":["#","Zero-shot Generalization"]}]]}]]}]]}],["$","article","2025-8-20-Describe-What-You-See-with-Multimodal-Large-Language-Models-to-Enhance-Video-Recommendations",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-Describe-What-You-See-with-Multimodal-Large-Language-Models-to-Enhance-Video-Recommendations/","children":"[논문리뷰] Describe What You See with Multimodal Large Language Models to Enhance Video Recommendations"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Mounia Lalmas이 [arXiv]에 게시한 'Describe What You See with Multimodal Large Language Models to Enhance Video Recommendations' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models"]}],["$","span","Video Recommendation",{"className":"page__taxonomy-item","children":["#","Video Recommendation"]}],["$","span","Zero-Shot Learning",{"className":"page__taxonomy-item","children":["#","Zero-Shot Learning"]}],["$","span","Content-Based Filtering",{"className":"page__taxonomy-item","children":["#","Content-Based Filtering"]}],["$","span","Natural Language Processing",{"className":"page__taxonomy-item","children":["#","Natural Language Processing"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}]]}]]}]]}],["$","article","2025-8-20-CorrSteer-Steering-Improves-Task-Performance-and-Safety-in-LLMs-through-Correlation-based-Sparse-Autoencoder-Feature-Selection",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-CorrSteer-Steering-Improves-Task-Performance-and-Safety-in-LLMs-through-Correlation-based-Sparse-Autoencoder-Feature-Selection/","children":"[논문리뷰] CorrSteer: Steering Improves Task Performance and Safety in LLMs through Correlation-based Sparse Autoencoder Feature Selection"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Adriano Koshiyama이 [arXiv]에 게시한 'CorrSteer: Steering Improves Task Performance and Safety in LLMs through Correlation-based Sparse Autoencoder Feature Selection' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Sparse Autoencoders",{"className":"page__taxonomy-item","children":["#","Sparse Autoencoders"]}],["$","span","LLM Steering",{"className":"page__taxonomy-item","children":["#","LLM Steering"]}],["$","span","Feature Selection",{"className":"page__taxonomy-item","children":["#","Feature Selection"]}],["$","span","Correlation Analysis",{"className":"page__taxonomy-item","children":["#","Correlation Analysis"]}],["$","span","AI Safety",{"className":"page__taxonomy-item","children":["#","AI Safety"]}],["$","span","Bias Mitigation",{"className":"page__taxonomy-item","children":["#","Bias Mitigation"]}],["$","span","Mechanistic Interpretability",{"className":"page__taxonomy-item","children":["#","Mechanistic Interpretability"]}]]}]]}]]}],["$","article","2025-8-20-Copyright-Protection-for-Large-Language-Models-A-Survey-of-Methods-Challenges-and-Trends",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-Copyright-Protection-for-Large-Language-Models-A-Survey-of-Methods-Challenges-and-Trends/","children":"[논문리뷰] Copyright Protection for Large Language Models: A Survey of Methods, Challenges, and Trends"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xixiang Zhao이 [arXiv]에 게시한 'Copyright Protection for Large Language Models: A Survey of Methods, Challenges, and Trends' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Copyright Protection",{"className":"page__taxonomy-item","children":["#","LLM Copyright Protection"]}],["$","span","Model Fingerprinting",{"className":"page__taxonomy-item","children":["#","Model Fingerprinting"]}],["$","span","Text Watermarking",{"className":"page__taxonomy-item","children":["#","Text Watermarking"]}],["$","span","Invasive Fingerprinting",{"className":"page__taxonomy-item","children":["#","Invasive Fingerprinting"]}],["$","span","Intrinsic Fingerprinting",{"className":"page__taxonomy-item","children":["#","Intrinsic Fingerprinting"]}],["$","span","Intellectual Property",{"className":"page__taxonomy-item","children":["#","Intellectual Property"]}],["$","span","Digital Rights Management",{"className":"page__taxonomy-item","children":["#","Digital Rights Management"]}],["$","span","Backdoor Watermarking",{"className":"page__taxonomy-item","children":["#","Backdoor Watermarking"]}]]}]]}]]}],["$","article","2025-8-20-Chain-of-Agents-End-to-End-Agent-Foundation-Models-via-Multi-Agent-Distillation-and-Agentic-RL",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-Chain-of-Agents-End-to-End-Agent-Foundation-Models-via-Multi-Agent-Distillation-and-Agentic-RL/","children":"[논문리뷰] Chain-of-Agents: End-to-End Agent Foundation Models via Multi-Agent Distillation and Agentic RL"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Liam-Liu이 [arXiv]에 게시한 'Chain-of-Agents: End-to-End Agent Foundation Models via Multi-Agent Distillation and Agentic RL' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Chain-of-Agents",{"className":"page__taxonomy-item","children":["#","Chain-of-Agents"]}],["$","span","Agent Foundation Models",{"className":"page__taxonomy-item","children":["#","Agent Foundation Models"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Tool-Integrated Reasoning",{"className":"page__taxonomy-item","children":["#","Tool-Integrated Reasoning"]}],["$","span","Multi-agent Distillation",{"className":"page__taxonomy-item","children":["#","Multi-agent Distillation"]}],["$","span","Agentic Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Agentic Reinforcement Learning"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","End-to-End Learning",{"className":"page__taxonomy-item","children":["#","End-to-End Learning"]}]]}]]}]]}],["$","article","2025-8-20-CAMAR-Continuous-Actions-Multi-Agent-Routing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-CAMAR-Continuous-Actions-Multi-Agent-Routing/","children":"[논문리뷰] CAMAR: Continuous Actions Multi-Agent Routing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Alexey Skrynnik이 [arXiv]에 게시한 'CAMAR: Continuous Actions Multi-Agent Routing' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-Agent Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Multi-Agent Reinforcement Learning"]}],["$","span","Continuous Control",{"className":"page__taxonomy-item","children":["#","Continuous Control"]}],["$","span","Pathfinding",{"className":"page__taxonomy-item","children":["#","Pathfinding"]}],["$","span","MARL Benchmark",{"className":"page__taxonomy-item","children":["#","MARL Benchmark"]}],["$","span","GPU Acceleration",{"className":"page__taxonomy-item","children":["#","GPU Acceleration"]}],["$","span","Robotics Simulation",{"className":"page__taxonomy-item","children":["#","Robotics Simulation"]}],["$","span","Scalability",{"className":"page__taxonomy-item","children":["#","Scalability"]}],["$","span","Heterogeneous Agents",{"className":"page__taxonomy-item","children":["#","Heterogeneous Agents"]}]]}]]}]]}],["$","article","2025-8-20-Beyond-Human-Judgment-A-Bayesian-Evaluation-of-LLMs-Moral-Values-Understanding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-Beyond-Human-Judgment-A-Bayesian-Evaluation-of-LLMs-Moral-Values-Understanding/","children":"[논문리뷰] Beyond Human Judgment: A Bayesian Evaluation of LLMs' Moral Values Understanding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Alina Landowska이 [arXiv]에 게시한 'Beyond Human Judgment: A Bayesian Evaluation of LLMs' Moral Values Understanding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Moral Reasoning",{"className":"page__taxonomy-item","children":["#","Moral Reasoning"]}],["$","span","Bayesian Evaluation",{"className":"page__taxonomy-item","children":["#","Bayesian Evaluation"]}],["$","span","Uncertainty Quantification",{"className":"page__taxonomy-item","children":["#","Uncertainty Quantification"]}],["$","span","Natural Language Processing",{"className":"page__taxonomy-item","children":["#","Natural Language Processing"]}],["$","span","Soft Labels",{"className":"page__taxonomy-item","children":["#","Soft Labels"]}]]}]]}]]}],["$","article","2025-8-20-Advances-in-Speech-Separation-Techniques-Challenges-and-Future-Trends",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-Advances-in-Speech-Separation-Techniques-Challenges-and-Future-Trends/","children":"[논문리뷰] Advances in Speech Separation: Techniques, Challenges, and Future Trends"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhuo Chen이 [arXiv]에 게시한 'Advances in Speech Separation: Techniques, Challenges, and Future Trends' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Speech Separation",{"className":"page__taxonomy-item","children":["#","Speech Separation"]}],["$","span","Deep Neural Networks",{"className":"page__taxonomy-item","children":["#","Deep Neural Networks"]}],["$","span","Cocktail Party Problem",{"className":"page__taxonomy-item","children":["#","Cocktail Party Problem"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Unsupervised Learning",{"className":"page__taxonomy-item","children":["#","Unsupervised Learning"]}],["$","span","Supervised Learning",{"className":"page__taxonomy-item","children":["#","Supervised Learning"]}],["$","span","Evaluation Metrics",{"className":"page__taxonomy-item","children":["#","Evaluation Metrics"]}],["$","span","Datasets",{"className":"page__taxonomy-item","children":["#","Datasets"]}]]}]]}]]}],["$","article","2025-8-20-A-Stitch-in-Time-Saves-Nine-Proactive-Self-Refinement-for-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-A-Stitch-in-Time-Saves-Nine-Proactive-Self-Refinement-for-Language-Models/","children":"[논문리뷰] A Stitch in Time Saves Nine: Proactive Self-Refinement for Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zishang Jiang이 [arXiv]에 게시한 'A Stitch in Time Saves Nine: Proactive Self-Refinement for Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Self-Refinement",{"className":"page__taxonomy-item","children":["#","Self-Refinement"]}],["$","span","Language Models",{"className":"page__taxonomy-item","children":["#","Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Proactive AI",{"className":"page__taxonomy-item","children":["#","Proactive AI"]}],["$","span","Generation Process",{"className":"page__taxonomy-item","children":["#","Generation Process"]}],["$","span","Markov Decision Process",{"className":"page__taxonomy-item","children":["#","Markov Decision Process"]}],["$","span","Adaptive Learning",{"className":"page__taxonomy-item","children":["#","Adaptive Learning"]}],["$","span","LLM Efficiency",{"className":"page__taxonomy-item","children":["#","LLM Efficiency"]}]]}]]}]]}],["$","article","2025-8-19-When-Punctuation-Matters-A-Large-Scale-Comparison-of-Prompt-Robustness-Methods-for-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-When-Punctuation-Matters-A-Large-Scale-Comparison-of-Prompt-Robustness-Methods-for-LLMs/","children":"[논문리뷰] When Punctuation Matters: A Large-Scale Comparison of Prompt Robustness Methods for LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Elena Tutubalina이 [arXiv]에 게시한 'When Punctuation Matters: A Large-Scale Comparison of Prompt Robustness Methods for LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-19 13:15:01+0900","children":"2025년 8월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Robustness",{"className":"page__taxonomy-item","children":["#","LLM Robustness"]}],["$","span","Prompt Sensitivity",{"className":"page__taxonomy-item","children":["#","Prompt Sensitivity"]}],["$","span","In-Context Learning",{"className":"page__taxonomy-item","children":["#","In-Context Learning"]}],["$","span","Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Fine-Tuning"]}],["$","span","Batch Calibration",{"className":"page__taxonomy-item","children":["#","Batch Calibration"]}],["$","span","Template Ensembles",{"className":"page__taxonomy-item","children":["#","Template Ensembles"]}],["$","span","Distribution Shift",{"className":"page__taxonomy-item","children":["#","Distribution Shift"]}]]}]]}]]}],["$","article","2025-8-19-Speed-Always-Wins-A-Survey-on-Efficient-Architectures-for-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-Speed-Always-Wins-A-Survey-on-Efficient-Architectures-for-Large-Language-Models/","children":"[논문리뷰] Speed Always Wins: A Survey on Efficient Architectures for Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jusen Du이 [arXiv]에 게시한 'Speed Always Wins: A Survey on Efficient Architectures for Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-19 13:15:01+0900","children":"2025년 8월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Efficient Architectures",{"className":"page__taxonomy-item","children":["#","Efficient Architectures"]}],["$","span","Transformer Optimization",{"className":"page__taxonomy-item","children":["#","Transformer Optimization"]}],["$","span","Linear Attention",{"className":"page__taxonomy-item","children":["#","Linear Attention"]}],["$","span","State Space Models",{"className":"page__taxonomy-item","children":["#","State Space Models"]}],["$","span","Mixture-of-Experts",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts"]}],["$","span","Sparse Attention",{"className":"page__taxonomy-item","children":["#","Sparse Attention"]}],["$","span","Diffusion LLMs",{"className":"page__taxonomy-item","children":["#","Diffusion LLMs"]}]]}]]}]]}],["$","article","2025-8-19-S2-Guidance-Stochastic-Self-Guidance-for-Training-Free-Enhancement-of-Diffusion-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-S2-Guidance-Stochastic-Self-Guidance-for-Training-Free-Enhancement-of-Diffusion-Models/","children":"[논문리뷰] S^2-Guidance: Stochastic Self Guidance for Training-Free Enhancement of Diffusion Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Meiqi Wu이 [arXiv]에 게시한 'S^2-Guidance: Stochastic Self Guidance for Training-Free Enhancement of Diffusion Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-19 13:15:01+0900","children":"2025년 8월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Classifier-free Guidance",{"className":"page__taxonomy-item","children":["#","Classifier-free Guidance"]}],["$","span","Self-Guidance",{"className":"page__taxonomy-item","children":["#","Self-Guidance"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}],["$","span","Stochastic Block-Dropping",{"className":"page__taxonomy-item","children":["#","Stochastic Block-Dropping"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Text-to-Image",{"className":"page__taxonomy-item","children":["#","Text-to-Image"]}]]}]]}]]}],["$","article","2025-8-19-Representing-Speech-Through-Autoregressive-Prediction-of-Cochlear-Tokens",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-Representing-Speech-Through-Autoregressive-Prediction-of-Cochlear-Tokens/","children":"[논문리뷰] Representing Speech Through Autoregressive Prediction of Cochlear Tokens"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Daniel L. K. Yamins이 [arXiv]에 게시한 'Representing Speech Through Autoregressive Prediction of Cochlear Tokens' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-19 13:15:01+0900","children":"2025년 8월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Speech Representation Learning",{"className":"page__taxonomy-item","children":["#","Speech Representation Learning"]}],["$","span","Autoregressive Models",{"className":"page__taxonomy-item","children":["#","Autoregressive Models"]}],["$","span","Cochlear Tokens",{"className":"page__taxonomy-item","children":["#","Cochlear Tokens"]}],["$","span","Biologically Inspired AI",{"className":"page__taxonomy-item","children":["#","Biologically Inspired AI"]}],["$","span","Self-Supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-Supervised Learning"]}],["$","span","Audio Processing",{"className":"page__taxonomy-item","children":["#","Audio Processing"]}],["$","span","Transformer Networks",{"className":"page__taxonomy-item","children":["#","Transformer Networks"]}]]}]]}]]}],["$","article","2025-8-19-Reinforcement-Learning-with-Rubric-Anchors",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-Reinforcement-Learning-with-Rubric-Anchors/","children":"[논문리뷰] Reinforcement Learning with Rubric Anchors"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Haokai Xu이 [arXiv]에 게시한 'Reinforcement Learning with Rubric Anchors' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-19 13:15:01+0900","children":"2025년 8월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Rubric-based Reward",{"className":"page__taxonomy-item","children":["#","Rubric-based Reward"]}],["$","span","RLVR Extension",{"className":"page__taxonomy-item","children":["#","RLVR Extension"]}],["$","span","Human-centric AI",{"className":"page__taxonomy-item","children":["#","Human-centric AI"]}],["$","span","Controllable Generation",{"className":"page__taxonomy-item","children":["#","Controllable Generation"]}],["$","span","Reward Hacking Mitigation",{"className":"page__taxonomy-item","children":["#","Reward Hacking Mitigation"]}]]}]]}]]}],["$","article","2025-8-19-Precise-Action-to-Video-Generation-Through-Visual-Action-Prompts",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-Precise-Action-to-Video-Generation-Through-Visual-Action-Prompts/","children":"[논문리뷰] Precise Action-to-Video Generation Through Visual Action Prompts"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Minghan Qin이 [arXiv]에 게시한 'Precise Action-to-Video Generation Through Visual Action Prompts' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-19 13:15:01+0900","children":"2025년 8월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Action-to-Video Generation",{"className":"page__taxonomy-item","children":["#","Action-to-Video Generation"]}],["$","span","Visual Action Prompts",{"className":"page__taxonomy-item","children":["#","Visual Action Prompts"]}],["$","span","Skeleton Representation",{"className":"page__taxonomy-item","children":["#","Skeleton Representation"]}],["$","span","Human-Object Interaction",{"className":"page__taxonomy-item","children":["#","Human-Object Interaction"]}],["$","span","Robotic Manipulation",{"className":"page__taxonomy-item","children":["#","Robotic Manipulation"]}],["$","span","Cross-Domain Transfer",{"className":"page__taxonomy-item","children":["#","Cross-Domain Transfer"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}]]}]]}]]}],["$","article","2025-8-19-Ovis2-5-Technical-Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-Ovis2-5-Technical-Report/","children":"[논문리뷰] Ovis2.5 Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yang Li이 [arXiv]에 게시한 'Ovis2.5 Technical Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-19 13:15:01+0900","children":"2025년 8월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Native Resolution Vision",{"className":"page__taxonomy-item","children":["#","Native Resolution Vision"]}],["$","span","Deep Reasoning",{"className":"page__taxonomy-item","children":["#","Deep Reasoning"]}],["$","span","Chart Analysis",{"className":"page__taxonomy-item","children":["#","Chart Analysis"]}],["$","span","OCR",{"className":"page__taxonomy-item","children":["#","OCR"]}],["$","span","Visual Grounding",{"className":"page__taxonomy-item","children":["#","Visual Grounding"]}],["$","span","Training Efficiency",{"className":"page__taxonomy-item","children":["#","Training Efficiency"]}],["$","span","Preference Optimization",{"className":"page__taxonomy-item","children":["#","Preference Optimization"]}]]}]]}]]}],["$","article","2025-8-19-Next-Visual-Granularity-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-Next-Visual-Granularity-Generation/","children":"[논문리뷰] Next Visual Granularity Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kang Liao이 [arXiv]에 게시한 'Next Visual Granularity Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-19 13:15:01+0900","children":"2025년 8월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Granularity Control",{"className":"page__taxonomy-item","children":["#","Granularity Control"]}],["$","span","Structured Representation",{"className":"page__taxonomy-item","children":["#","Structured Representation"]}],["$","span","Hierarchical Generation",{"className":"page__taxonomy-item","children":["#","Hierarchical Generation"]}],["$","span","Coarse-to-fine",{"className":"page__taxonomy-item","children":["#","Coarse-to-fine"]}],["$","span","Visual Tokenization",{"className":"page__taxonomy-item","children":["#","Visual Tokenization"]}],["$","span","Latent Space",{"className":"page__taxonomy-item","children":["#","Latent Space"]}]]}]]}]]}],["$","article","2025-8-19-Matrix-Game-2-0-An-Open-Source-Real-Time-and-Streaming-Interactive-World-Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-Matrix-Game-2-0-An-Open-Source-Real-Time-and-Streaming-Interactive-World-Model/","children":"[논문리뷰] Matrix-Game 2.0: An Open-Source, Real-Time, and Streaming Interactive World Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yifan Zhang이 [arXiv]에 게시한 'Matrix-Game 2.0: An Open-Source, Real-Time, and Streaming Interactive World Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-19 13:15:01+0900","children":"2025년 8월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","World Model",{"className":"page__taxonomy-item","children":["#","World Model"]}],["$","span","Interactive Video Generation",{"className":"page__taxonomy-item","children":["#","Interactive Video Generation"]}],["$","span","Real-Time AI",{"className":"page__taxonomy-item","children":["#","Real-Time AI"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Auto-Regressive Generation",{"className":"page__taxonomy-item","children":["#","Auto-Regressive Generation"]}],["$","span","Data Pipeline",{"className":"page__taxonomy-item","children":["#","Data Pipeline"]}],["$","span","Self-Forcing",{"className":"page__taxonomy-item","children":["#","Self-Forcing"]}],["$","span","KV Caching",{"className":"page__taxonomy-item","children":["#","KV Caching"]}]]}]]}]]}],["$","article","2025-8-19-Lumen-Consistent-Video-Relighting-and-Harmonious-Background-Replacement-with-Video-Generative-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-Lumen-Consistent-Video-Relighting-and-Harmonious-Background-Replacement-with-Video-Generative-Models/","children":"[논문리뷰] Lumen: Consistent Video Relighting and Harmonious Background Replacement with Video Generative Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zixiang Gao이 [arXiv]에 게시한 'Lumen: Consistent Video Relighting and Harmonious Background Replacement with Video Generative Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-19 13:15:01+0900","children":"2025년 8월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Relighting",{"className":"page__taxonomy-item","children":["#","Video Relighting"]}],["$","span","Background Replacement",{"className":"page__taxonomy-item","children":["#","Background Replacement"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Temporal Consistency",{"className":"page__taxonomy-item","children":["#","Temporal Consistency"]}],["$","span","Dataset Generation",{"className":"page__taxonomy-item","children":["#","Dataset Generation"]}],["$","span","Video Editing",{"className":"page__taxonomy-item","children":["#","Video Editing"]}]]}]]}]]}],["$","article","2025-8-19-Inverse-LLaVA-Eliminating-Alignment-Pre-training-Through-Text-to-Vision-Mapping",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-Inverse-LLaVA-Eliminating-Alignment-Pre-training-Through-Text-to-Vision-Mapping/","children":"[논문리뷰] Inverse-LLaVA: Eliminating Alignment Pre-training Through Text-to-Vision Mapping"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Tyler Derr이 [arXiv]에 게시한 'Inverse-LLaVA: Eliminating Alignment Pre-training Through Text-to-Vision Mapping' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-19 13:15:01+0900","children":"2025년 8월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Alignment Pre-training",{"className":"page__taxonomy-item","children":["#","Alignment Pre-training"]}],["$","span","Text-to-Vision Mapping",{"className":"page__taxonomy-item","children":["#","Text-to-Vision Mapping"]}],["$","span","Continuous Representations",{"className":"page__taxonomy-item","children":["#","Continuous Representations"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}]]}]]}]]}],["$","article","2025-8-19-HeroBench-A-Benchmark-for-Long-Horizon-Planning-and-Structured-Reasoning-in-Virtual-Worlds",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-HeroBench-A-Benchmark-for-Long-Horizon-Planning-and-Structured-Reasoning-in-Virtual-Worlds/","children":"[논문리뷰] HeroBench: A Benchmark for Long-Horizon Planning and Structured Reasoning in Virtual Worlds"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Artyom Sorokin이 [arXiv]에 게시한 'HeroBench: A Benchmark for Long-Horizon Planning and Structured Reasoning in Virtual Worlds' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-19 13:15:01+0900","children":"2025년 8월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Long-Horizon Planning",{"className":"page__taxonomy-item","children":["#","Long-Horizon Planning"]}],["$","span","Structured Reasoning",{"className":"page__taxonomy-item","children":["#","Structured Reasoning"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Virtual Worlds",{"className":"page__taxonomy-item","children":["#","Virtual Worlds"]}],["$","span","RPG",{"className":"page__taxonomy-item","children":["#","RPG"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Agent Systems",{"className":"page__taxonomy-item","children":["#","Agent Systems"]}],["$","span","Combat Simulation",{"className":"page__taxonomy-item","children":["#","Combat Simulation"]}]]}]]}]]}],["$","article","2025-8-19-Has-GPT-5-Achieved-Spatial-Intelligence-An-Empirical-Study",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-Has-GPT-5-Achieved-Spatial-Intelligence-An-Empirical-Study/","children":"[논문리뷰] Has GPT-5 Achieved Spatial Intelligence? An Empirical Study"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ruisi Wang이 [arXiv]에 게시한 'Has GPT-5 Achieved Spatial Intelligence? An Empirical Study' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-19 13:15:01+0900","children":"2025년 8월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Spatial Intelligence",{"className":"page__taxonomy-item","children":["#","Spatial Intelligence"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Benchmark Evaluation",{"className":"page__taxonomy-item","children":["#","Benchmark Evaluation"]}],["$","span","GPT-5",{"className":"page__taxonomy-item","children":["#","GPT-5"]}],["$","span","Cognitive AI",{"className":"page__taxonomy-item","children":["#","Cognitive AI"]}],["$","span","AGI",{"className":"page__taxonomy-item","children":["#","AGI"]}]]}]]}]]}],["$","article","2025-8-19-G-CUT3R-Guided-3D-Reconstruction-with-Camera-and-Depth-Prior-Integration",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-G-CUT3R-Guided-3D-Reconstruction-with-Camera-and-Depth-Prior-Integration/","children":"[논문리뷰] G-CUT3R: Guided 3D Reconstruction with Camera and Depth Prior Integration"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Evgeny Burnaev이 [arXiv]에 게시한 'G-CUT3R: Guided 3D Reconstruction with Camera and Depth Prior Integration' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-19 13:15:01+0900","children":"2025년 8월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Reconstruction",{"className":"page__taxonomy-item","children":["#","3D Reconstruction"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}],["$","span","Multi-Modal Fusion",{"className":"page__taxonomy-item","children":["#","Multi-Modal Fusion"]}],["$","span","Camera Pose Estimation",{"className":"page__taxonomy-item","children":["#","Camera Pose Estimation"]}],["$","span","Depth Estimation",{"className":"page__taxonomy-item","children":["#","Depth Estimation"]}],["$","span","Transformer Networks",{"className":"page__taxonomy-item","children":["#","Transformer Networks"]}],["$","span","Prior Information",{"className":"page__taxonomy-item","children":["#","Prior Information"]}]]}]]}]]}],["$","article","2025-8-19-ComoRAG-A-Cognitive-Inspired-Memory-Organized-RAG-for-Stateful-Long-Narrative-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-ComoRAG-A-Cognitive-Inspired-Memory-Organized-RAG-for-Stateful-Long-Narrative-Reasoning/","children":"[논문리뷰] ComoRAG: A Cognitive-Inspired Memory-Organized RAG for Stateful Long Narrative Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yufeng Wang이 [arXiv]에 게시한 'ComoRAG: A Cognitive-Inspired Memory-Organized RAG for Stateful Long Narrative Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-19 13:15:01+0900","children":"2025년 8월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Cognitive-Inspired RAG",{"className":"page__taxonomy-item","children":["#","Cognitive-Inspired RAG"]}],["$","span","Stateful Reasoning",{"className":"page__taxonomy-item","children":["#","Stateful Reasoning"]}],["$","span","Long Narrative Comprehension",{"className":"page__taxonomy-item","children":["#","Long Narrative Comprehension"]}],["$","span","Dynamic Memory",{"className":"page__taxonomy-item","children":["#","Dynamic Memory"]}],["$","span","Metacognitive Regulation",{"className":"page__taxonomy-item","children":["#","Metacognitive Regulation"]}],["$","span","Multi-step Retrieval",{"className":"page__taxonomy-item","children":["#","Multi-step Retrieval"]}],["$","span","Hierarchical Knowledge Source",{"className":"page__taxonomy-item","children":["#","Hierarchical Knowledge Source"]}]]}]]}]]}],["$","article","2025-8-19-Beyond-Solving-Math-Quiz-Evaluating-the-Ability-of-Large-Reasoning-Models-to-Ask-for-Information",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-Beyond-Solving-Math-Quiz-Evaluating-the-Ability-of-Large-Reasoning-Models-to-Ask-for-Information/","children":"[논문리뷰] Beyond Solving Math Quiz: Evaluating the Ability of Large Reasoning Models to Ask for Information"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xi Yang이 [arXiv]에 게시한 'Beyond Solving Math Quiz: Evaluating the Ability of Large Reasoning Models to Ask for Information' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-19 13:15:01+0900","children":"2025년 8월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Reasoning Models (LRMs)",{"className":"page__taxonomy-item","children":["#","Large Reasoning Models (LRMs)"]}],["$","span","Information Seeking",{"className":"page__taxonomy-item","children":["#","Information Seeking"]}],["$","span","Incomplete Problems",{"className":"page__taxonomy-item","children":["#","Incomplete Problems"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Supervised Fine-tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning (SFT)"]}],["$","span","Overthinking",{"className":"page__taxonomy-item","children":["#","Overthinking"]}],["$","span","Hallucination",{"className":"page__taxonomy-item","children":["#","Hallucination"]}],["$","span","CRITIC-math",{"className":"page__taxonomy-item","children":["#","CRITIC-math"]}]]}]]}]]}],["$","article","2025-8-19-4DNeX-Feed-Forward-4D-Generative-Modeling-Made-Easy",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-4DNeX-Feed-Forward-4D-Generative-Modeling-Made-Easy/","children":"[논문리뷰] 4DNeX: Feed-Forward 4D Generative Modeling Made Easy"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zeng Tao이 [arXiv]에 게시한 '4DNeX: Feed-Forward 4D Generative Modeling Made Easy' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-19 13:15:01+0900","children":"2025년 8월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","4D Generation",{"className":"page__taxonomy-item","children":["#","4D Generation"]}],["$","span","Dynamic 3D",{"className":"page__taxonomy-item","children":["#","Dynamic 3D"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Single Image Input",{"className":"page__taxonomy-item","children":["#","Single Image Input"]}],["$","span","Video Synthesis",{"className":"page__taxonomy-item","children":["#","Video Synthesis"]}],["$","span","Point Clouds",{"className":"page__taxonomy-item","children":["#","Point Clouds"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}]]}]]}]]}],["$","article","2025-8-18-X-Node-Self-Explanation-is-All-We-Need",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-18-X-Node-Self-Explanation-is-All-We-Need/","children":"[논문리뷰] X-Node: Self-Explanation is All We Need"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Islem Rekik이 [arXiv]에 게시한 'X-Node: Self-Explanation is All We Need' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-18 13:14:38+0900","children":"2025년 8월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Graph Neural Networks",{"className":"page__taxonomy-item","children":["#","Graph Neural Networks"]}],["$","span","Explainable AI",{"className":"page__taxonomy-item","children":["#","Explainable AI"]}],["$","span","Self-Explanation",{"className":"page__taxonomy-item","children":["#","Self-Explanation"]}],["$","span","Node Classification",{"className":"page__taxonomy-item","children":["#","Node Classification"]}],["$","span","Medical Imaging",{"className":"page__taxonomy-item","children":["#","Medical Imaging"]}],["$","span","Natural Language Processing",{"className":"page__taxonomy-item","children":["#","Natural Language Processing"]}],["$","span","Interpretability",{"className":"page__taxonomy-item","children":["#","Interpretability"]}]]}]]}]]}],["$","article","2025-8-18-Thyme-Think-Beyond-Images",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-18-Thyme-Think-Beyond-Images/","children":"[논문리뷰] Thyme: Think Beyond Images"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wei Chen이 [arXiv]에 게시한 'Thyme: Think Beyond Images' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-18 13:14:38+0900","children":"2025년 8월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","Image Processing",{"className":"page__taxonomy-item","children":["#","Image Processing"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Supervised Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning"]}],["$","span","Visual Reasoning",{"className":"page__taxonomy-item","children":["#","Visual Reasoning"]}],["$","span","Sandbox",{"className":"page__taxonomy-item","children":["#","Sandbox"]}]]}]]}]]}],["$","article","2025-8-18-TexVerse-A-Universe-of-3D-Objects-with-High-Resolution-Textures",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-18-TexVerse-A-Universe-of-3D-Objects-with-High-Resolution-Textures/","children":"[논문리뷰] TexVerse: A Universe of 3D Objects with High-Resolution Textures"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Nan Cao이 [arXiv]에 게시한 'TexVerse: A Universe of 3D Objects with High-Resolution Textures' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-18 13:14:38+0900","children":"2025년 8월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Dataset",{"className":"page__taxonomy-item","children":["#","3D Dataset"]}],["$","span","High-Resolution Textures",{"className":"page__taxonomy-item","children":["#","High-Resolution Textures"]}],["$","span","Physically Based Rendering (PBR)",{"className":"page__taxonomy-item","children":["#","Physically Based Rendering (PBR)"]}],["$","span","3D Animation",{"className":"page__taxonomy-item","children":["#","3D Animation"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","GPT-5 Annotations",{"className":"page__taxonomy-item","children":["#","GPT-5 Annotations"]}],["$","span","Sketchfab",{"className":"page__taxonomy-item","children":["#","Sketchfab"]}]]}]]}]]}],["$","article","2025-8-18-StyleMM-Stylized-3D-Morphable-Face-Model-via-Text-Driven-Aligned-Image-Translation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-18-StyleMM-Stylized-3D-Morphable-Face-Model-via-Text-Driven-Aligned-Image-Translation/","children":"[논문리뷰] StyleMM: Stylized 3D Morphable Face Model via Text-Driven Aligned Image Translation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Junyong Noh이 [arXiv]에 게시한 'StyleMM: Stylized 3D Morphable Face Model via Text-Driven Aligned Image Translation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-18 13:14:38+0900","children":"2025년 8월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Morphable Model",{"className":"page__taxonomy-item","children":["#","3D Morphable Model"]}],["$","span","Face Stylization",{"className":"page__taxonomy-item","children":["#","Face Stylization"]}],["$","span","Text-to-Image Translation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Translation"]}],["$","span","Diffusion Model",{"className":"page__taxonomy-item","children":["#","Diffusion Model"]}],["$","span","Attribute Preservation",{"className":"page__taxonomy-item","children":["#","Attribute Preservation"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Computer Graphics",{"className":"page__taxonomy-item","children":["#","Computer Graphics"]}]]}]]}]]}],["$","article","2025-8-18-SSRL-Self-Search-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-18-SSRL-Self-Search-Reinforcement-Learning/","children":"[논문리뷰] SSRL: Self-Search Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yanxu Chen이 [arXiv]에 게시한 'SSRL: Self-Search Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-18 13:14:38+0900","children":"2025년 8월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Self-Search",{"className":"page__taxonomy-item","children":["#","Self-Search"]}],["$","span","Sim-to-Real Transfer",{"className":"page__taxonomy-item","children":["#","Sim-to-Real Transfer"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Knowledge Retrieval",{"className":"page__taxonomy-item","children":["#","Knowledge Retrieval"]}],["$","span","Reward Modeling",{"className":"page__taxonomy-item","children":["#","Reward Modeling"]}]]}]]}]]}],["$","article","2025-8-18-SPARSE-Data-Rich-Results-Few-Shot-Semi-Supervised-Learning-via-Class-Conditioned-Image-Translation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-18-SPARSE-Data-Rich-Results-Few-Shot-Semi-Supervised-Learning-via-Class-Conditioned-Image-Translation/","children":"[논문리뷰] SPARSE Data, Rich Results: Few-Shot Semi-Supervised Learning via Class-Conditioned Image Translation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Paolo Soda이 [arXiv]에 게시한 'SPARSE Data, Rich Results: Few-Shot Semi-Supervised Learning via Class-Conditioned Image Translation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-18 13:14:38+0900","children":"2025년 8월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Semi-supervised Learning",{"className":"page__taxonomy-item","children":["#","Semi-supervised Learning"]}],["$","span","Few-shot Learning",{"className":"page__taxonomy-item","children":["#","Few-shot Learning"]}],["$","span","Medical Imaging",{"className":"page__taxonomy-item","children":["#","Medical Imaging"]}],["$","span","GAN-based Methods",{"className":"page__taxonomy-item","children":["#","GAN-based Methods"]}],["$","span","Image-to-image Translation",{"className":"page__taxonomy-item","children":["#","Image-to-image Translation"]}],["$","span","Pseudo-labeling",{"className":"page__taxonomy-item","children":["#","Pseudo-labeling"]}],["$","span","Ensemble Learning",{"className":"page__taxonomy-item","children":["#","Ensemble Learning"]}]]}]]}]]}],["$","article","2025-8-18-PaperRegister-Boosting-Flexible-grained-Paper-Search-via-Hierarchical-Register-Indexing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-18-PaperRegister-Boosting-Flexible-grained-Paper-Search-via-Hierarchical-Register-Indexing/","children":"[논문리뷰] PaperRegister: Boosting Flexible-grained Paper Search via Hierarchical Register Indexing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xianpei Han이 [arXiv]에 게시한 'PaperRegister: Boosting Flexible-grained Paper Search via Hierarchical Register Indexing' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-18 13:14:38+0900","children":"2025년 8월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","논문 검색",{"className":"page__taxonomy-item","children":["#","논문 검색"]}],["$","span","계층적 인덱싱",{"className":"page__taxonomy-item","children":["#","계층적 인덱싱"]}],["$","span","유연한 검색",{"className":"page__taxonomy-item","children":["#","유연한 검색"]}],["$","span","대규모 언어 모델",{"className":"page__taxonomy-item","children":["#","대규모 언어 모델"]}],["$","span","정보 추출",{"className":"page__taxonomy-item","children":["#","정보 추출"]}],["$","span","뷰 인식",{"className":"page__taxonomy-item","children":["#","뷰 인식"]}],["$","span","강화 학습",{"className":"page__taxonomy-item","children":["#","강화 학습"]}]]}]]}]]}],["$","article","2025-8-18-MAESTRO-Masked-AutoEncoders-for-Multimodal-Multitemporal-and-Multispectral-Earth-Observation-Data",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-18-MAESTRO-Masked-AutoEncoders-for-Multimodal-Multitemporal-and-Multispectral-Earth-Observation-Data/","children":"[논문리뷰] MAESTRO: Masked AutoEncoders for Multimodal, Multitemporal, and Multispectral Earth Observation Data"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Nicolas Gonthier이 [arXiv]에 게시한 'MAESTRO: Masked AutoEncoders for Multimodal, Multitemporal, and Multispectral Earth Observation Data' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-18 13:14:38+0900","children":"2025년 8월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Self-supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-supervised Learning"]}],["$","span","Masked Autoencoder",{"className":"page__taxonomy-item","children":["#","Masked Autoencoder"]}],["$","span","Earth Observation",{"className":"page__taxonomy-item","children":["#","Earth Observation"]}],["$","span","Multimodal",{"className":"page__taxonomy-item","children":["#","Multimodal"]}],["$","span","Multitemporal",{"className":"page__taxonomy-item","children":["#","Multitemporal"]}],["$","span","Multispectral",{"className":"page__taxonomy-item","children":["#","Multispectral"]}],["$","span","Fusion Strategies",{"className":"page__taxonomy-item","children":["#","Fusion Strategies"]}],["$","span","Target Normalization",{"className":"page__taxonomy-item","children":["#","Target Normalization"]}]]}]]}]]}],["$","article","2025-8-18-FantasyTalking2-Timestep-Layer-Adaptive-Preference-Optimization-for-Audio-Driven-Portrait-Animation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-18-FantasyTalking2-Timestep-Layer-Adaptive-Preference-Optimization-for-Audio-Driven-Portrait-Animation/","children":"[논문리뷰] FantasyTalking2: Timestep-Layer Adaptive Preference Optimization for Audio-Driven Portrait Animation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Mu Xu이 [arXiv]에 게시한 'FantasyTalking2: Timestep-Layer Adaptive Preference Optimization for Audio-Driven Portrait Animation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-18 13:14:38+0900","children":"2025년 8월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Audio-Driven Animation",{"className":"page__taxonomy-item","children":["#","Audio-Driven Animation"]}],["$","span","Preference Optimization",{"className":"page__taxonomy-item","children":["#","Preference Optimization"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Reward Modeling",{"className":"page__taxonomy-item","children":["#","Reward Modeling"]}],["$","span","Human Feedback",{"className":"page__taxonomy-item","children":["#","Human Feedback"]}],["$","span","Multi-Objective Optimization",{"className":"page__taxonomy-item","children":["#","Multi-Objective Optimization"]}],["$","span","Timestep-Layer Adaptive",{"className":"page__taxonomy-item","children":["#","Timestep-Layer Adaptive"]}]]}]]}]]}],["$","article","2025-8-18-DINOv3",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-18-DINOv3/","children":"[논문리뷰] DINOv3"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Maxime Oquab이 [arXiv]에 게시한 'DINOv3' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-18 13:14:38+0900","children":"2025년 8월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Self-supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-supervised Learning"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Vision Transformer",{"className":"page__taxonomy-item","children":["#","Vision Transformer"]}],["$","span","Dense Feature Maps",{"className":"page__taxonomy-item","children":["#","Dense Feature Maps"]}],["$","span","Gram Anchoring",{"className":"page__taxonomy-item","children":["#","Gram Anchoring"]}],["$","span","Model Distillation",{"className":"page__taxonomy-item","children":["#","Model Distillation"]}],["$","span","Geospatial AI",{"className":"page__taxonomy-item","children":["#","Geospatial AI"]}]]}]]}]]}],["$","article","2025-8-18-Controlling-Multimodal-LLMs-via-Reward-guided-Decoding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-18-Controlling-Multimodal-LLMs-via-Reward-guided-Decoding/","children":"[논문리뷰] Controlling Multimodal LLMs via Reward-guided Decoding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Michal Drozdzal이 [arXiv]에 게시한 'Controlling Multimodal LLMs via Reward-guided Decoding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-18 13:14:38+0900","children":"2025년 8월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Reward Models",{"className":"page__taxonomy-item","children":["#","Reward Models"]}],["$","span","Guided Decoding",{"className":"page__taxonomy-item","children":["#","Guided Decoding"]}],["$","span","Visual Grounding",{"className":"page__taxonomy-item","children":["#","Visual Grounding"]}],["$","span","Hallucination Mitigation",{"className":"page__taxonomy-item","children":["#","Hallucination Mitigation"]}],["$","span","Object Precision",{"className":"page__taxonomy-item","children":["#","Object Precision"]}],["$","span","Object Recall",{"className":"page__taxonomy-item","children":["#","Object Recall"]}],["$","span","Inference-time Control",{"className":"page__taxonomy-item","children":["#","Inference-time Control"]}]]}]]}]]}],["$","article","2025-8-15-We-Math-2-0-A-Versatile-MathBook-System-for-Incentivizing-Visual-Mathematical-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-15-We-Math-2-0-A-Versatile-MathBook-System-for-Incentivizing-Visual-Mathematical-Reasoning/","children":"[논문리뷰] We-Math 2.0: A Versatile MathBook System for Incentivizing Visual Mathematical Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiaowan Wang이 [arXiv]에 게시한 'We-Math 2.0: A Versatile MathBook System for Incentivizing Visual Mathematical Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-15 13:09:31+0900","children":"2025년 8월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Visual Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Visual Mathematical Reasoning"]}],["$","span","MLLMs",{"className":"page__taxonomy-item","children":["#","MLLMs"]}],["$","span","Knowledge System",{"className":"page__taxonomy-item","children":["#","Knowledge System"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Dataset Construction",{"className":"page__taxonomy-item","children":["#","Dataset Construction"]}],["$","span","Mathematical Benchmark",{"className":"page__taxonomy-item","children":["#","Mathematical Benchmark"]}]]}]]}]]}],["$","article","2025-8-15-UI-Venus-Technical-Report-Building-High-performance-UI-Agents-with-RFT",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-15-UI-Venus-Technical-Report-Building-High-performance-UI-Agents-with-RFT/","children":"[논문리뷰] UI-Venus Technical Report: Building High-performance UI Agents with RFT"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shuheng Shen이 [arXiv]에 게시한 'UI-Venus Technical Report: Building High-performance UI Agents with RFT' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-15 13:09:31+0900","children":"2025년 8월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","UI Agent",{"className":"page__taxonomy-item","children":["#","UI Agent"]}],["$","span","MLLM",{"className":"page__taxonomy-item","children":["#","MLLM"]}],["$","span","RFT",{"className":"page__taxonomy-item","children":["#","RFT"]}],["$","span","UI Grounding",{"className":"page__taxonomy-item","children":["#","UI Grounding"]}],["$","span","UI Navigation",{"className":"page__taxonomy-item","children":["#","UI Navigation"]}],["$","span","GRPO",{"className":"page__taxonomy-item","children":["#","GRPO"]}],["$","span","Data Cleaning",{"className":"page__taxonomy-item","children":["#","Data Cleaning"]}],["$","span","Self-Evolving Trajectory",{"className":"page__taxonomy-item","children":["#","Self-Evolving Trajectory"]}]]}]]}]]}],["$","article","2025-8-15-ToonComposer-Streamlining-Cartoon-Production-with-Generative-Post-Keyframing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-15-ToonComposer-Streamlining-Cartoon-Production-with-Generative-Post-Keyframing/","children":"[논문리뷰] ToonComposer: Streamlining Cartoon Production with Generative Post-Keyframing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiaoyu Li이 [arXiv]에 게시한 'ToonComposer: Streamlining Cartoon Production with Generative Post-Keyframing' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-15 13:09:31+0900","children":"2025년 8월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Cartoon Generation",{"className":"page__taxonomy-item","children":["#","Cartoon Generation"]}],["$","span","Video Diffusion Models",{"className":"page__taxonomy-item","children":["#","Video Diffusion Models"]}],["$","span","DiT",{"className":"page__taxonomy-item","children":["#","DiT"]}],["$","span","Post-Keyframing",{"className":"page__taxonomy-item","children":["#","Post-Keyframing"]}],["$","span","Low-Rank Adaptation",{"className":"page__taxonomy-item","children":["#","Low-Rank Adaptation"]}],["$","span","Sparse Control",{"className":"page__taxonomy-item","children":["#","Sparse Control"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Animation",{"className":"page__taxonomy-item","children":["#","Animation"]}]]}]]}]]}],["$","article","2025-8-15-STream3R-Scalable-Sequential-3D-Reconstruction-with-Causal-Transformer",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-15-STream3R-Scalable-Sequential-3D-Reconstruction-with-Causal-Transformer/","children":"[논문리뷰] STream3R: Scalable Sequential 3D Reconstruction with Causal Transformer"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Honghua Chen이 [arXiv]에 게시한 'STream3R: Scalable Sequential 3D Reconstruction with Causal Transformer' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-15 13:09:31+0900","children":"2025년 8월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Reconstruction",{"className":"page__taxonomy-item","children":["#","3D Reconstruction"]}],["$","span","Causal Transformer",{"className":"page__taxonomy-item","children":["#","Causal Transformer"]}],["$","span","Sequential Modeling",{"className":"page__taxonomy-item","children":["#","Sequential Modeling"]}],["$","span","Streaming Data",{"className":"page__taxonomy-item","children":["#","Streaming Data"]}],["$","span","Pointmap Prediction",{"className":"page__taxonomy-item","children":["#","Pointmap Prediction"]}],["$","span","Online Perception",{"className":"page__taxonomy-item","children":["#","Online Perception"]}],["$","span","KVCache",{"className":"page__taxonomy-item","children":["#","KVCache"]}]]}]]}]]}],["$","article","2025-8-15-Processing-and-acquisition-traces-in-visual-encoders-What-does-CLIP-know-about-your-camera",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-15-Processing-and-acquisition-traces-in-visual-encoders-What-does-CLIP-know-about-your-camera/","children":"[논문리뷰] Processing and acquisition traces in visual encoders: What does CLIP know about your camera?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Giorgos Tolias이 [arXiv]에 게시한 'Processing and acquisition traces in visual encoders: What does CLIP know about your camera?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-15 13:09:31+0900","children":"2025년 8월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Visual Encoders",{"className":"page__taxonomy-item","children":["#","Visual Encoders"]}],["$","span","Metadata",{"className":"page__taxonomy-item","children":["#","Metadata"]}],["$","span","Image Processing",{"className":"page__taxonomy-item","children":["#","Image Processing"]}],["$","span","Image Acquisition",{"className":"page__taxonomy-item","children":["#","Image Acquisition"]}],["$","span","Robustness",{"className":"page__taxonomy-item","children":["#","Robustness"]}],["$","span","CLIP",{"className":"page__taxonomy-item","children":["#","CLIP"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Distribution Shift",{"className":"page__taxonomy-item","children":["#","Distribution Shift"]}]]}]]}]]}],["$","article","2025-8-15-Passk-Training-for-Adaptively-Balancing-Exploration-and-Exploitation-of-Large-Reasoning-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-15-Passk-Training-for-Adaptively-Balancing-Exploration-and-Exploitation-of-Large-Reasoning-Models/","children":"[논문리뷰] Pass@k Training for Adaptively Balancing Exploration and Exploitation of Large Reasoning Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Qinghao Ye이 [arXiv]에 게시한 'Pass@k Training for Adaptively Balancing Exploration and Exploitation of Large Reasoning Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-15 13:09:31+0900","children":"2025년 8월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Exploration-Exploitation",{"className":"page__taxonomy-item","children":["#","Exploration-Exploitation"]}],["$","span","Reward Design",{"className":"page__taxonomy-item","children":["#","Reward Design"]}],["$","span","Reasoning Tasks",{"className":"page__taxonomy-item","children":["#","Reasoning Tasks"]}],["$","span","Pass@k",{"className":"page__taxonomy-item","children":["#","Pass@k"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}]]}]]}]]}],["$","article","2025-8-15-PRELUDE-A-Benchmark-Designed-to-Require-Global-Comprehension-and-Reasoning-over-Long-Contexts",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-15-PRELUDE-A-Benchmark-Designed-to-Require-Global-Comprehension-and-Reasoning-over-Long-Contexts/","children":"[논문리뷰] PRELUDE: A Benchmark Designed to Require Global Comprehension and Reasoning over Long Contexts"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Rui Lu이 [arXiv]에 게시한 'PRELUDE: A Benchmark Designed to Require Global Comprehension and Reasoning over Long Contexts' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-15 13:09:31+0900","children":"2025년 8월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Long-Context Understanding",{"className":"page__taxonomy-item","children":["#","Long-Context Understanding"]}],["$","span","Reasoning Benchmark",{"className":"page__taxonomy-item","children":["#","Reasoning Benchmark"]}],["$","span","LLMs Evaluation",{"className":"page__taxonomy-item","children":["#","LLMs Evaluation"]}],["$","span","Natural Language Processing",{"className":"page__taxonomy-item","children":["#","Natural Language Processing"]}],["$","span","Global Comprehension",{"className":"page__taxonomy-item","children":["#","Global Comprehension"]}],["$","span","Fluid Intelligence",{"className":"page__taxonomy-item","children":["#","Fluid Intelligence"]}],["$","span","Prequel Entailment",{"className":"page__taxonomy-item","children":["#","Prequel Entailment"]}],["$","span","RAG",{"className":"page__taxonomy-item","children":["#","RAG"]}]]}]]}]]}],["$","article","2025-8-15-NextStep-1-Toward-Autoregressive-Image-Generation-with-Continuous-Tokens-at-Scale",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-15-NextStep-1-Toward-Autoregressive-Image-Generation-with-Continuous-Tokens-at-Scale/","children":"[논문리뷰] NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Quan Sun이 [arXiv]에 게시한 'NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-15 13:09:31+0900","children":"2025년 8월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Autoregressive Models",{"className":"page__taxonomy-item","children":["#","Autoregressive Models"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Continuous Latent Tokens",{"className":"page__taxonomy-item","children":["#","Continuous Latent Tokens"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}]]}]]}]]}],["$","article","2025-8-15-HumanSense-From-Multimodal-Perception-to-Empathetic-Context-Aware-Responses-through-Reasoning-MLLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-15-HumanSense-From-Multimodal-Perception-to-Empathetic-Context-Aware-Responses-through-Reasoning-MLLMs/","children":"[논문리뷰] HumanSense: From Multimodal Perception to Empathetic Context-Aware Responses through Reasoning MLLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yi Yuan이 [arXiv]에 게시한 'HumanSense: From Multimodal Perception to Empathetic Context-Aware Responses through Reasoning MLLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-15 13:09:31+0900","children":"2025년 8월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Human-Centered AI",{"className":"page__taxonomy-item","children":["#","Human-Centered AI"]}],["$","span","Empathy",{"className":"page__taxonomy-item","children":["#","Empathy"]}],["$","span","Context-Awareness",{"className":"page__taxonomy-item","children":["#","Context-Awareness"]}],["$","span","MLLM Benchmark",{"className":"page__taxonomy-item","children":["#","MLLM Benchmark"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}]]}]]}]]}],["$","article","2025-8-15-From-Black-Box-to-Transparency-Enhancing-Automated-Interpreting-Assessment-with-Explainable-AI-in-College-Classrooms",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-15-From-Black-Box-to-Transparency-Enhancing-Automated-Interpreting-Assessment-with-Explainable-AI-in-College-Classrooms/","children":"[논문리뷰] From Black Box to Transparency: Enhancing Automated Interpreting Assessment with Explainable AI in College Classrooms"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ziyin Zhang이 [arXiv]에 게시한 'From Black Box to Transparency: Enhancing Automated Interpreting Assessment with Explainable AI in College Classrooms' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-15 13:09:31+0900","children":"2025년 8월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Automated Interpreting Assessment",{"className":"page__taxonomy-item","children":["#","Automated Interpreting Assessment"]}],["$","span","Explainable AI",{"className":"page__taxonomy-item","children":["#","Explainable AI"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}],["$","span","Variational Autoencoder",{"className":"page__taxonomy-item","children":["#","Variational Autoencoder"]}],["$","span","SHAP",{"className":"page__taxonomy-item","children":["#","SHAP"]}],["$","span","Interpreting Quality",{"className":"page__taxonomy-item","children":["#","Interpreting Quality"]}],["$","span","Natural Language Processing",{"className":"page__taxonomy-item","children":["#","Natural Language Processing"]}]]}]]}]]}],["$","article","2025-8-15-A-Survey-on-Diffusion-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-15-A-Survey-on-Diffusion-Language-Models/","children":"[논문리뷰] A Survey on Diffusion Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhiqiang Shen이 [arXiv]에 게시한 'A Survey on Diffusion Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-15 13:09:31+0900","children":"2025년 8월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Language Models",{"className":"page__taxonomy-item","children":["#","Diffusion Language Models"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Parallel Decoding",{"className":"page__taxonomy-item","children":["#","Parallel Decoding"]}],["$","span","Text Generation",{"className":"page__taxonomy-item","children":["#","Text Generation"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Model Compression",{"className":"page__taxonomy-item","children":["#","Model Compression"]}],["$","span","Reinforcement Learning from Human Feedback",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning from Human Feedback"]}],["$","span","Inference Optimization",{"className":"page__taxonomy-item","children":["#","Inference Optimization"]}]]}]]}]]}],["$","article","2025-8-15-2025-8-15-Explainability-and-Privacy-in-NLP",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-15-2025-8-15-Explainability-and-Privacy-in-NLP/","children":"[논문리뷰] When Explainability Meets Privacy: An Investigation at the Intersection of Post-hoc Explainability and Differential Privacy in the Context of Natural Language Processing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Gjergji Kasneci이 [arXiv]에 게시한 'When Explainability Meets Privacy: An Investigation at the Intersection of Post-hoc Explainability and Differential Privacy in the Context of Natural Language Processing' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-15 13:09:31+0900","children":"2025년 8월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Natural Language Processing (NLP)",{"className":"page__taxonomy-item","children":["#","Natural Language Processing (NLP)"]}],["$","span","Explainable AI (XAI)",{"className":"page__taxonomy-item","children":["#","Explainable AI (XAI)"]}],["$","span","Post-hoc Explainability",{"className":"page__taxonomy-item","children":["#","Post-hoc Explainability"]}],["$","span","Differential Privacy (DP)",{"className":"page__taxonomy-item","children":["#","Differential Privacy (DP)"]}],["$","span","Privacy-Utility Trade-off",{"className":"page__taxonomy-item","children":["#","Privacy-Utility Trade-off"]}],["$","span","Model Faithfulness",{"className":"page__taxonomy-item","children":["#","Model Faithfulness"]}],["$","span","Text Privatization",{"className":"page__taxonomy-item","children":["#","Text Privatization"]}]]}]]}]]}],["$","article","2025-8-14-VisCodex-Unified-Multimodal-Code-Generation-via-Merging-Vision-and-Coding-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-VisCodex-Unified-Multimodal-Code-Generation-via-Merging-Vision-and-Coding-Models/","children":"[논문리뷰] VisCodex: Unified Multimodal Code Generation via Merging Vision and Coding Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Dongdong Zhang이 [arXiv]에 게시한 'VisCodex: Unified Multimodal Code Generation via Merging Vision and Coding Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-14 13:19:02+0900","children":"2025년 8월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLM",{"className":"page__taxonomy-item","children":["#","Multimodal LLM"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","Model Merging",{"className":"page__taxonomy-item","children":["#","Model Merging"]}],["$","span","Task Vectors",{"className":"page__taxonomy-item","children":["#","Task Vectors"]}],["$","span","Vision-Language Model",{"className":"page__taxonomy-item","children":["#","Vision-Language Model"]}],["$","span","Coding LLM",{"className":"page__taxonomy-item","children":["#","Coding LLM"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}]]}]]}]]}],["$","article","2025-8-14-Story2Board-A-Training-Free-Approach-for-Expressive-Storyboard-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-Story2Board-A-Training-Free-Approach-for-Expressive-Storyboard-Generation/","children":"[논문리뷰] Story2Board: A Training-Free Approach for Expressive Storyboard Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Dani Lischinski이 [arXiv]에 게시한 'Story2Board: A Training-Free Approach for Expressive Storyboard Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-14 13:19:02+0900","children":"2025년 8월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Storyboard Generation",{"className":"page__taxonomy-item","children":["#","Storyboard Generation"]}],["$","span","Text-to-Image",{"className":"page__taxonomy-item","children":["#","Text-to-Image"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}],["$","span","Character Consistency",{"className":"page__taxonomy-item","children":["#","Character Consistency"]}],["$","span","Scene Diversity",{"className":"page__taxonomy-item","children":["#","Scene Diversity"]}],["$","span","Visual Storytelling",{"className":"page__taxonomy-item","children":["#","Visual Storytelling"]}]]}]]}]]}],["$","article","2025-8-14-Stand-In-A-Lightweight-and-Plug-and-Play-Identity-Control-for-Video-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-Stand-In-A-Lightweight-and-Plug-and-Play-Identity-Control-for-Video-Generation/","children":"[논문리뷰] Stand-In: A Lightweight and Plug-and-Play Identity Control for Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chen Li이 [arXiv]에 게시한 'Stand-In: A Lightweight and Plug-and-Play Identity Control for Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-14 13:19:02+0900","children":"2025년 8월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Identity Preservation",{"className":"page__taxonomy-item","children":["#","Identity Preservation"]}],["$","span","Plug-and-Play",{"className":"page__taxonomy-item","children":["#","Plug-and-Play"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Self-Attention",{"className":"page__taxonomy-item","children":["#","Self-Attention"]}],["$","span","Lightweight AI",{"className":"page__taxonomy-item","children":["#","Lightweight AI"]}],["$","span","Conditional Image Branch",{"className":"page__taxonomy-item","children":["#","Conditional Image Branch"]}]]}]]}]]}],["$","article","2025-8-14-Seeing-Listening-Remembering-and-Reasoning-A-Multimodal-Agent-with-Long-Term-Memory",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-Seeing-Listening-Remembering-and-Reasoning-A-Multimodal-Agent-with-Long-Term-Memory/","children":"[논문리뷰] Seeing, Listening, Remembering, and Reasoning: A Multimodal Agent with Long-Term Memory"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuan Lin이 [arXiv]에 게시한 'Seeing, Listening, Remembering, and Reasoning: A Multimodal Agent with Long-Term Memory' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-14 13:19:02+0900","children":"2025년 8월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Agent",{"className":"page__taxonomy-item","children":["#","Multimodal Agent"]}],["$","span","Long-Term Memory",{"className":"page__taxonomy-item","children":["#","Long-Term Memory"]}],["$","span","Episodic Memory",{"className":"page__taxonomy-item","children":["#","Episodic Memory"]}],["$","span","Semantic Memory",{"className":"page__taxonomy-item","children":["#","Semantic Memory"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Video Question Answering",{"className":"page__taxonomy-item","children":["#","Video Question Answering"]}],["$","span","Entity-Centric Memory",{"className":"page__taxonomy-item","children":["#","Entity-Centric Memory"]}]]}]]}]]}],["$","article","2025-8-14-Noise-Hypernetworks-Amortizing-Test-Time-Compute-in-Diffusion-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-Noise-Hypernetworks-Amortizing-Test-Time-Compute-in-Diffusion-Models/","children":"[논문리뷰] Noise Hypernetworks: Amortizing Test-Time Compute in Diffusion Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zeynep Akata이 [arXiv]에 게시한 'Noise Hypernetworks: Amortizing Test-Time Compute in Diffusion Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-14 13:19:02+0900","children":"2025년 8월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Hypernetworks",{"className":"page__taxonomy-item","children":["#","Hypernetworks"]}],["$","span","Test-Time Optimization",{"className":"page__taxonomy-item","children":["#","Test-Time Optimization"]}],["$","span","Reward-Guided Generation",{"className":"page__taxonomy-item","children":["#","Reward-Guided Generation"]}],["$","span","Latent Space Optimization",{"className":"page__taxonomy-item","children":["#","Latent Space Optimization"]}],["$","span","LoRA",{"className":"page__taxonomy-item","children":["#","LoRA"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}]]}]]}]]}],["$","article","2025-8-14-Mol-R1-Towards-Explicit-Long-CoT-Reasoning-in-Molecule-Discovery",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-Mol-R1-Towards-Explicit-Long-CoT-Reasoning-in-Molecule-Discovery/","children":"[논문리뷰] Mol-R1: Towards Explicit Long-CoT Reasoning in Molecule Discovery"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Di Zhang이 [arXiv]에 게시한 'Mol-R1: Towards Explicit Long-CoT Reasoning in Molecule Discovery' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-14 13:19:02+0900","children":"2025년 8월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Molecule Discovery",{"className":"page__taxonomy-item","children":["#","Molecule Discovery"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Molecular Generation",{"className":"page__taxonomy-item","children":["#","Molecular Generation"]}],["$","span","Explainable AI",{"className":"page__taxonomy-item","children":["#","Explainable AI"]}]]}]]}]]}],["$","article","2025-8-14-MathReal-We-Keep-It-Real-A-Real-Scene-Benchmark-for-Evaluating-Math-Reasoning-in-Multimodal-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-MathReal-We-Keep-It-Real-A-Real-Scene-Benchmark-for-Evaluating-Math-Reasoning-in-Multimodal-Large-Language-Models/","children":"[논문리뷰] MathReal: We Keep It Real! A Real Scene Benchmark for Evaluating Math Reasoning in Multimodal Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhihan Zhou이 [arXiv]에 게시한 'MathReal: We Keep It Real! A Real Scene Benchmark for Evaluating Math Reasoning in Multimodal Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-14 13:19:02+0900","children":"2025년 8월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models (MLLMs)"]}],["$","span","Math Reasoning",{"className":"page__taxonomy-item","children":["#","Math Reasoning"]}],["$","span","Real-World Benchmark",{"className":"page__taxonomy-item","children":["#","Real-World Benchmark"]}],["$","span","Visual Perception",{"className":"page__taxonomy-item","children":["#","Visual Perception"]}],["$","span","Robustness",{"className":"page__taxonomy-item","children":["#","Robustness"]}],["$","span","K-12 Education",{"className":"page__taxonomy-item","children":["#","K-12 Education"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}]]}]]}]]}],["$","article","2025-8-14-Learning-to-Align-Aligning-to-Learn-A-Unified-Approach-for-Self-Optimized-Alignment",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-Learning-to-Align-Aligning-to-Learn-A-Unified-Approach-for-Self-Optimized-Alignment/","children":"[논문리뷰] Learning to Align, Aligning to Learn: A Unified Approach for Self-Optimized Alignment"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Lei Fan이 [arXiv]에 게시한 'Learning to Align, Aligning to Learn: A Unified Approach for Self-Optimized Alignment' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-14 13:19:02+0900","children":"2025년 8월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Alignment",{"className":"page__taxonomy-item","children":["#","LLM Alignment"]}],["$","span","Reinforcement Learning from Human Feedback",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning from Human Feedback"]}],["$","span","Preference Learning",{"className":"page__taxonomy-item","children":["#","Preference Learning"]}],["$","span","Group Relative Alignment Optimization",{"className":"page__taxonomy-item","children":["#","Group Relative Alignment Optimization"]}],["$","span","Self-Optimization",{"className":"page__taxonomy-item","children":["#","Self-Optimization"]}],["$","span","Mixture-of-Experts",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts"]}],["$","span","Imitation Learning",{"className":"page__taxonomy-item","children":["#","Imitation Learning"]}]]}]]}]]}],["$","article","2025-8-14-IAG-Input-aware-Backdoor-Attack-on-VLMs-for-Visual-Grounding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-IAG-Input-aware-Backdoor-Attack-on-VLMs-for-Visual-Grounding/","children":"[논문리뷰] IAG: Input-aware Backdoor Attack on VLMs for Visual Grounding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Di Zhang이 [arXiv]에 게시한 'IAG: Input-aware Backdoor Attack on VLMs for Visual Grounding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-14 13:19:02+0900","children":"2025년 8월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Backdoor Attack",{"className":"page__taxonomy-item","children":["#","Backdoor Attack"]}],["$","span","Vision-Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision-Language Models (VLMs)"]}],["$","span","Visual Grounding",{"className":"page__taxonomy-item","children":["#","Visual Grounding"]}],["$","span","Input-aware Trigger",{"className":"page__taxonomy-item","children":["#","Input-aware Trigger"]}],["$","span","Adversarial Attack",{"className":"page__taxonomy-item","children":["#","Adversarial Attack"]}],["$","span","Security",{"className":"page__taxonomy-item","children":["#","Security"]}],["$","span","U-Net",{"className":"page__taxonomy-item","children":["#","U-Net"]}],["$","span","Open-vocabulary",{"className":"page__taxonomy-item","children":["#","Open-vocabulary"]}]]}]]}]]}],["$","article","2025-8-14-GSFixer-Improving-3D-Gaussian-Splatting-with-Reference-Guided-Video-Diffusion-Priors",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-GSFixer-Improving-3D-Gaussian-Splatting-with-Reference-Guided-Video-Diffusion-Priors/","children":"[논문리뷰] GSFixer: Improving 3D Gaussian Splatting with Reference-Guided Video Diffusion Priors"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Qingnan Fan이 [arXiv]에 게시한 'GSFixer: Improving 3D Gaussian Splatting with Reference-Guided Video Diffusion Priors' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-14 13:19:02+0900","children":"2025년 8월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","3D Gaussian Splatting"]}],["$","span","Novel View Synthesis",{"className":"page__taxonomy-item","children":["#","Novel View Synthesis"]}],["$","span","Diffusion Model",{"className":"page__taxonomy-item","children":["#","Diffusion Model"]}],["$","span","Artifact Restoration",{"className":"page__taxonomy-item","children":["#","Artifact Restoration"]}],["$","span","Sparse-view 3D Reconstruction",{"className":"page__taxonomy-item","children":["#","Sparse-view 3D Reconstruction"]}],["$","span","Reference-Guided",{"className":"page__taxonomy-item","children":["#","Reference-Guided"]}]]}]]}]]}],["$","article","2025-8-14-Echo-4o-Harnessing-the-Power-of-GPT-4o-Synthetic-Images-for-Improved-Image-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-Echo-4o-Harnessing-the-Power-of-GPT-4o-Synthetic-Images-for-Improved-Image-Generation/","children":"[논문리뷰] Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhenghao Hu이 [arXiv]에 게시한 'Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-14 13:19:02+0900","children":"2025년 8월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Synthetic Data",{"className":"page__taxonomy-item","children":["#","Synthetic Data"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","GPT-4o",{"className":"page__taxonomy-item","children":["#","GPT-4o"]}],["$","span","Multimodal Models",{"className":"page__taxonomy-item","children":["#","Multimodal Models"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}],["$","span","Surreal Image Generation",{"className":"page__taxonomy-item","children":["#","Surreal Image Generation"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}]]}]]}]]}],["$","article","2025-8-14-Diffusion-LLMs-Can-Do-Faster-Than-AR-Inference-via-Discrete-Diffusion-Forcing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-Diffusion-LLMs-Can-Do-Faster-Than-AR-Inference-via-Discrete-Diffusion-Forcing/","children":"[논문리뷰] Diffusion LLMs Can Do Faster-Than-AR Inference via Discrete Diffusion Forcing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hao Zhang이 [arXiv]에 게시한 'Diffusion LLMs Can Do Faster-Than-AR Inference via Discrete Diffusion Forcing' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-14 13:19:02+0900","children":"2025년 8월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion LLMs",{"className":"page__taxonomy-item","children":["#","Diffusion LLMs"]}],["$","span","Faster Inference",{"className":"page__taxonomy-item","children":["#","Faster Inference"]}],["$","span","Discrete Diffusion Forcing (D2F)",{"className":"page__taxonomy-item","children":["#","Discrete Diffusion Forcing (D2F)"]}],["$","span","Autoregressive Generation",{"className":"page__taxonomy-item","children":["#","Autoregressive Generation"]}],["$","span","KV Cache Optimization",{"className":"page__taxonomy-item","children":["#","KV Cache Optimization"]}],["$","span","Parallel Decoding",{"className":"page__taxonomy-item","children":["#","Parallel Decoding"]}],["$","span","Text Generation",{"className":"page__taxonomy-item","children":["#","Text Generation"]}],["$","span","Model Distillation",{"className":"page__taxonomy-item","children":["#","Model Distillation"]}]]}]]}]]}],["$","article","2025-8-14-Cooper-Co-Optimizing-Policy-and-Reward-Models-in-Reinforcement-Learning-for-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-Cooper-Co-Optimizing-Policy-and-Reward-Models-in-Reinforcement-Learning-for-Large-Language-Models/","children":"[논문리뷰] Cooper: Co-Optimizing Policy and Reward Models in Reinforcement Learning for Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Guiyang Hou이 [arXiv]에 게시한 'Cooper: Co-Optimizing Policy and Reward Models in Reinforcement Learning for Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-14 13:19:02+0900","children":"2025년 8월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reward Model",{"className":"page__taxonomy-item","children":["#","Reward Model"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Reward Hacking",{"className":"page__taxonomy-item","children":["#","Reward Hacking"]}],["$","span","Hybrid Annotation",{"className":"page__taxonomy-item","children":["#","Hybrid Annotation"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Verifiable Rewards",{"className":"page__taxonomy-item","children":["#","Verifiable Rewards"]}]]}]]}]]}],["$","article","2025-8-14-Can-LLM-Generated-Textual-Explanations-Enhance-Model-Classification-Performance-An-Empirical-Study",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-Can-LLM-Generated-Textual-Explanations-Enhance-Model-Classification-Performance-An-Empirical-Study/","children":"[논문리뷰] Can LLM-Generated Textual Explanations Enhance Model Classification Performance? An Empirical Study"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Gjergji Kasneci이 [arXiv]에 게시한 'Can LLM-Generated Textual Explanations Enhance Model Classification Performance? An Empirical Study' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-14 13:19:02+0900","children":"2025년 8월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Explainable NLP",{"className":"page__taxonomy-item","children":["#","Explainable NLP"]}],["$","span","Natural Language Explanations",{"className":"page__taxonomy-item","children":["#","Natural Language Explanations"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Pre-trained Language Models",{"className":"page__taxonomy-item","children":["#","Pre-trained Language Models"]}],["$","span","Natural Language Inference",{"className":"page__taxonomy-item","children":["#","Natural Language Inference"]}],["$","span","Model Performance Enhancement",{"className":"page__taxonomy-item","children":["#","Model Performance Enhancement"]}],["$","span","Text Generation",{"className":"page__taxonomy-item","children":["#","Text Generation"]}]]}]]}]]}],["$","article","2025-8-14-AWorld-Dynamic-Multi-Agent-System-with-Stable-Maneuvering-for-Robust-GAIA-Problem-Solving",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-AWorld-Dynamic-Multi-Agent-System-with-Stable-Maneuvering-for-Robust-GAIA-Problem-Solving/","children":"[논문리뷰] AWorld: Dynamic Multi-Agent System with Stable Maneuvering for Robust GAIA Problem Solving"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jinjie Gu이 [arXiv]에 게시한 'AWorld: Dynamic Multi-Agent System with Stable Maneuvering for Robust GAIA Problem Solving' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-14 13:19:02+0900","children":"2025년 8월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-Agent System",{"className":"page__taxonomy-item","children":["#","Multi-Agent System"]}],["$","span","Agent Stability",{"className":"page__taxonomy-item","children":["#","Agent Stability"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","GAIA Benchmark",{"className":"page__taxonomy-item","children":["#","GAIA Benchmark"]}],["$","span","Robustness",{"className":"page__taxonomy-item","children":["#","Robustness"]}],["$","span","Dynamic Supervision",{"className":"page__taxonomy-item","children":["#","Dynamic Supervision"]}],["$","span","Maneuvering",{"className":"page__taxonomy-item","children":["#","Maneuvering"]}]]}]]}]]}],["$","article","2025-8-14-AMFT-Aligning-LLM-Reasoners-by-Meta-Learning-the-Optimal-Imitation-Exploration-Balance",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-AMFT-Aligning-LLM-Reasoners-by-Meta-Learning-the-Optimal-Imitation-Exploration-Balance/","children":"[논문리뷰] AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yong Li이 [arXiv]에 게시한 'AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-14 13:19:02+0900","children":"2025년 8월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Meta-learning",{"className":"page__taxonomy-item","children":["#","Meta-learning"]}],["$","span","Adaptive Control",{"className":"page__taxonomy-item","children":["#","Adaptive Control"]}],["$","span","Imitation Learning",{"className":"page__taxonomy-item","children":["#","Imitation Learning"]}],["$","span","Exploration",{"className":"page__taxonomy-item","children":["#","Exploration"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}]]}]]}]]}],["$","article","2025-8-13-WGAST-Weakly-Supervised-Generative-Network-for-Daily-10-m-Land-Surface-Temperature-Estimation-via-Spatio-Temporal-Fusion",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-WGAST-Weakly-Supervised-Generative-Network-for-Daily-10-m-Land-Surface-Temperature-Estimation-via-Spatio-Temporal-Fusion/","children":"[논문리뷰] WGAST: Weakly-Supervised Generative Network for Daily 10 m Land Surface Temperature Estimation via Spatio-Temporal Fusion"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Rachid Nedjai이 [arXiv]에 게시한 'WGAST: Weakly-Supervised Generative Network for Daily 10 m Land Surface Temperature Estimation via Spatio-Temporal Fusion' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Spatio-Temporal Fusion",{"className":"page__taxonomy-item","children":["#","Spatio-Temporal Fusion"]}],["$","span","Land Surface Temperature",{"className":"page__taxonomy-item","children":["#","Land Surface Temperature"]}],["$","span","Generative Adversarial Network",{"className":"page__taxonomy-item","children":["#","Generative Adversarial Network"]}],["$","span","Weakly-Supervised Learning",{"className":"page__taxonomy-item","children":["#","Weakly-Supervised Learning"]}],["$","span","Remote Sensing",{"className":"page__taxonomy-item","children":["#","Remote Sensing"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}]]}]]}]]}],["$","article","2025-8-13-VertexRegen-Mesh-Generation-with-Continuous-Level-of-Detail",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-VertexRegen-Mesh-Generation-with-Continuous-Level-of-Detail/","children":"[논문리뷰] VertexRegen: Mesh Generation with Continuous Level of Detail"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jakob Engel이 [arXiv]에 게시한 'VertexRegen: Mesh Generation with Continuous Level of Detail' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Mesh Generation",{"className":"page__taxonomy-item","children":["#","Mesh Generation"]}],["$","span","Level of Detail (LOD)",{"className":"page__taxonomy-item","children":["#","Level of Detail (LOD)"]}],["$","span","Progressive Meshes",{"className":"page__taxonomy-item","children":["#","Progressive Meshes"]}],["$","span","Vertex Split",{"className":"page__taxonomy-item","children":["#","Vertex Split"]}],["$","span","Autoregressive Models",{"className":"page__taxonomy-item","children":["#","Autoregressive Models"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","3D Graphics",{"className":"page__taxonomy-item","children":["#","3D Graphics"]}]]}]]}]]}],["$","article","2025-8-13-UNCAGE-Contrastive-Attention-Guidance-for-Masked-Generative-Transformers-in-Text-to-Image-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-UNCAGE-Contrastive-Attention-Guidance-for-Masked-Generative-Transformers-in-Text-to-Image-Generation/","children":"[논문리뷰] UNCAGE: Contrastive Attention Guidance for Masked Generative Transformers in Text-to-Image Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kevin Galim이 [arXiv]에 게시한 'UNCAGE: Contrastive Attention Guidance for Masked Generative Transformers in Text-to-Image Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Masked Generative Transformers",{"className":"page__taxonomy-item","children":["#","Masked Generative Transformers"]}],["$","span","Compositional Generation",{"className":"page__taxonomy-item","children":["#","Compositional Generation"]}],["$","span","Attention Guidance",{"className":"page__taxonomy-item","children":["#","Attention Guidance"]}],["$","span","Unmasking Strategy",{"className":"page__taxonomy-item","children":["#","Unmasking Strategy"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}],["$","span","Attribute Binding",{"className":"page__taxonomy-item","children":["#","Attribute Binding"]}]]}]]}]]}],["$","article","2025-8-13-Train-Long-Think-Short-Curriculum-Learning-for-Efficient-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-Train-Long-Think-Short-Curriculum-Learning-for-Efficient-Reasoning/","children":"[논문리뷰] Train Long, Think Short: Curriculum Learning for Efficient Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Marzyeh Ghassemi이 [arXiv]에 게시한 'Train Long, Think Short: Curriculum Learning for Efficient Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reasoning Efficiency",{"className":"page__taxonomy-item","children":["#","Reasoning Efficiency"]}],["$","span","Token Budget Control",{"className":"page__taxonomy-item","children":["#","Token Budget Control"]}],["$","span","Group Relative Policy Optimization",{"className":"page__taxonomy-item","children":["#","Group Relative Policy Optimization"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}]]}]]}]]}],["$","article","2025-8-13-Towards-Affordance-Aware-Robotic-Dexterous-Grasping-with-Human-like-Priors",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-Towards-Affordance-Aware-Robotic-Dexterous-Grasping-with-Human-like-Priors/","children":"[논문리뷰] Towards Affordance-Aware Robotic Dexterous Grasping with Human-like Priors"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Haoran Xu이 [arXiv]에 게시한 'Towards Affordance-Aware Robotic Dexterous Grasping with Human-like Priors' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Robotic Dexterous Grasping",{"className":"page__taxonomy-item","children":["#","Robotic Dexterous Grasping"]}],["$","span","Affordance-Aware",{"className":"page__taxonomy-item","children":["#","Affordance-Aware"]}],["$","span","Human-like Priors",{"className":"page__taxonomy-item","children":["#","Human-like Priors"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Two-Stage Training",{"className":"page__taxonomy-item","children":["#","Two-Stage Training"]}],["$","span","Manipulation",{"className":"page__taxonomy-item","children":["#","Manipulation"]}]]}]]}]]}],["$","article","2025-8-13-TopXGen-Topic-Diverse-Parallel-Data-Generation-for-Low-Resource-Machine-Translation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-TopXGen-Topic-Diverse-Parallel-Data-Generation-for-Low-Resource-Machine-Translation/","children":"[논문리뷰] TopXGen: Topic-Diverse Parallel Data Generation for Low-Resource Machine Translation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Rachel Bawden이 [arXiv]에 게시한 'TopXGen: Topic-Diverse Parallel Data Generation for Low-Resource Machine Translation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Low-Resource MT",{"className":"page__taxonomy-item","children":["#","Low-Resource MT"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Back-Translation",{"className":"page__taxonomy-item","children":["#","Back-Translation"]}],["$","span","In-Context Learning (ICL)",{"className":"page__taxonomy-item","children":["#","In-Context Learning (ICL)"]}],["$","span","Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Fine-Tuning"]}],["$","span","Topic-Guided Generation",{"className":"page__taxonomy-item","children":["#","Topic-Guided Generation"]}],["$","span","Parallel Data Synthesis",{"className":"page__taxonomy-item","children":["#","Parallel Data Synthesis"]}]]}]]}]]}],["$","article","2025-8-13-Time-Is-a-Feature-Exploiting-Temporal-Dynamics-in-Diffusion-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-Time-Is-a-Feature-Exploiting-Temporal-Dynamics-in-Diffusion-Language-Models/","children":"[논문리뷰] Time Is a Feature: Exploiting Temporal Dynamics in Diffusion Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chenchen Jing이 [arXiv]에 게시한 'Time Is a Feature: Exploiting Temporal Dynamics in Diffusion Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Language Models",{"className":"page__taxonomy-item","children":["#","Diffusion Language Models"]}],["$","span","Temporal Oscillation",{"className":"page__taxonomy-item","children":["#","Temporal Oscillation"]}],["$","span","Self-Consistency Voting",{"className":"page__taxonomy-item","children":["#","Self-Consistency Voting"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Temporal Semantic Entropy",{"className":"page__taxonomy-item","children":["#","Temporal Semantic Entropy"]}],["$","span","Text Generation",{"className":"page__taxonomy-item","children":["#","Text Generation"]}]]}]]}]]}],["$","article","2025-8-13-Test-Time-Reinforcement-Learning-for-GUI-Grounding-via-Region-Consistency",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-Test-Time-Reinforcement-Learning-for-GUI-Grounding-via-Region-Consistency/","children":"[논문리뷰] Test-Time Reinforcement Learning for GUI Grounding via Region Consistency"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhengxi Lu이 [arXiv]에 게시한 'Test-Time Reinforcement Learning for GUI Grounding via Region Consistency' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","GUI Grounding",{"className":"page__taxonomy-item","children":["#","GUI Grounding"]}],["$","span","Test-Time Scaling",{"className":"page__taxonomy-item","children":["#","Test-Time Scaling"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Region Consistency",{"className":"page__taxonomy-item","children":["#","Region Consistency"]}],["$","span","Spatial Voting",{"className":"page__taxonomy-item","children":["#","Spatial Voting"]}],["$","span","Self-Supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-Supervised Learning"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}]]}]]}]]}],["$","article","2025-8-13-OpenCUA-Open-Foundations-for-Computer-Use-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-OpenCUA-Open-Foundations-for-Computer-Use-Agents/","children":"[논문리뷰] OpenCUA: Open Foundations for Computer-Use Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Tianbao Xie이 [arXiv]에 게시한 'OpenCUA: Open Foundations for Computer-Use Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Computer-Use Agents",{"className":"page__taxonomy-item","children":["#","Computer-Use Agents"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Chain-of-Thought Reasoning",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought Reasoning"]}],["$","span","Large-scale Dataset",{"className":"page__taxonomy-item","children":["#","Large-scale Dataset"]}],["$","span","Open-source Framework",{"className":"page__taxonomy-item","children":["#","Open-source Framework"]}],["$","span","Desktop Automation",{"className":"page__taxonomy-item","children":["#","Desktop Automation"]}],["$","span","Agent Evaluation",{"className":"page__taxonomy-item","children":["#","Agent Evaluation"]}]]}]]}]]}],["$","article","2025-8-13-NVSpeech-An-Integrated-and-Scalable-Pipeline-for-Human-Like-Speech-Modeling-with-Paralinguistic-Vocalizations",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-NVSpeech-An-Integrated-and-Scalable-Pipeline-for-Human-Like-Speech-Modeling-with-Paralinguistic-Vocalizations/","children":"[논문리뷰] NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Haoyue Zhan이 [arXiv]에 게시한 'NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Paralinguistic Vocalizations",{"className":"page__taxonomy-item","children":["#","Paralinguistic Vocalizations"]}],["$","span","Speech Recognition",{"className":"page__taxonomy-item","children":["#","Speech Recognition"]}],["$","span","Text-to-Speech",{"className":"page__taxonomy-item","children":["#","Text-to-Speech"]}],["$","span","Speech Synthesis",{"className":"page__taxonomy-item","children":["#","Speech Synthesis"]}],["$","span","Data Annotation",{"className":"page__taxonomy-item","children":["#","Data Annotation"]}],["$","span","Mandarin Speech",{"className":"page__taxonomy-item","children":["#","Mandarin Speech"]}],["$","span","Expressive Speech",{"className":"page__taxonomy-item","children":["#","Expressive Speech"]}]]}]]}]]}],["$","article","2025-8-13-Matrix-3D-Omnidirectional-Explorable-3D-World-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-Matrix-3D-Omnidirectional-Explorable-3D-World-Generation/","children":"[논문리뷰] Matrix-3D: Omnidirectional Explorable 3D World Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuqi Li이 [arXiv]에 게시한 'Matrix-3D: Omnidirectional Explorable 3D World Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D World Generation",{"className":"page__taxonomy-item","children":["#","3D World Generation"]}],["$","span","Panoramic Video Generation",{"className":"page__taxonomy-item","children":["#","Panoramic Video Generation"]}],["$","span","3D Reconstruction",{"className":"page__taxonomy-item","children":["#","3D Reconstruction"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","Gaussian Splatting"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}],["$","span","Camera Control",{"className":"page__taxonomy-item","children":["#","Camera Control"]}]]}]]}]]}],["$","article","2025-8-13-HierSearch-A-Hierarchical-Enterprise-Deep-Search-Framework-Integrating-Local-and-Web-Searches",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-HierSearch-A-Hierarchical-Enterprise-Deep-Search-Framework-Integrating-Local-and-Web-Searches/","children":"[논문리뷰] HierSearch: A Hierarchical Enterprise Deep Search Framework Integrating Local and Web Searches"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Qiang Ju이 [arXiv]에 게시한 'HierSearch: A Hierarchical Enterprise Deep Search Framework Integrating Local and Web Searches' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Hierarchical Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Hierarchical Reinforcement Learning"]}],["$","span","Deep Search",{"className":"page__taxonomy-item","children":["#","Deep Search"]}],["$","span","Multi-source RAG",{"className":"page__taxonomy-item","children":["#","Multi-source RAG"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Knowledge Integration",{"className":"page__taxonomy-item","children":["#","Knowledge Integration"]}],["$","span","Enterprise Search",{"className":"page__taxonomy-item","children":["#","Enterprise Search"]}],["$","span","Large Reasoning Models",{"className":"page__taxonomy-item","children":["#","Large Reasoning Models"]}]]}]]}]]}],["$","article","2025-8-13-GeRe-Towards-Efficient-Anti-Forgetting-in-Continual-Learning-of-LLM-via-General-Samples-Replay",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-GeRe-Towards-Efficient-Anti-Forgetting-in-Continual-Learning-of-LLM-via-General-Samples-Replay/","children":"[논문리뷰] GeRe: Towards Efficient Anti-Forgetting in Continual Learning of LLM via General Samples Replay"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yang Fan이 [arXiv]에 게시한 'GeRe: Towards Efficient Anti-Forgetting in Continual Learning of LLM via General Samples Replay' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Continual Learning",{"className":"page__taxonomy-item","children":["#","Continual Learning"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Catastrophic Forgetting",{"className":"page__taxonomy-item","children":["#","Catastrophic Forgetting"]}],["$","span","Replay",{"className":"page__taxonomy-item","children":["#","Replay"]}],["$","span","Knowledge Distillation",{"className":"page__taxonomy-item","children":["#","Knowledge Distillation"]}],["$","span","Activation States",{"className":"page__taxonomy-item","children":["#","Activation States"]}],["$","span","Anti-forgetting",{"className":"page__taxonomy-item","children":["#","Anti-forgetting"]}],["$","span","Threshold-based Margin Loss",{"className":"page__taxonomy-item","children":["#","Threshold-based Margin Loss"]}]]}]]}]]}],["$","article","2025-8-13-Feedback-Driven-Tool-Use-Improvements-in-Large-Language-Models-via-Automated-Build-Environments",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-Feedback-Driven-Tool-Use-Improvements-in-Large-Language-Models-via-Automated-Build-Environments/","children":"[논문리뷰] Feedback-Driven Tool-Use Improvements in Large Language Models via Automated Build Environments"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xuesong Yao이 [arXiv]에 게시한 'Feedback-Driven Tool-Use Improvements in Large Language Models via Automated Build Environments' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Automated Environment Generation",{"className":"page__taxonomy-item","children":["#","Automated Environment Generation"]}],["$","span","Feedback-Driven Training",{"className":"page__taxonomy-item","children":["#","Feedback-Driven Training"]}],["$","span","Reward Mechanism",{"className":"page__taxonomy-item","children":["#","Reward Mechanism"]}],["$","span","Contextual Understanding",{"className":"page__taxonomy-item","children":["#","Contextual Understanding"]}]]}]]}]]}],["$","article","2025-8-13-Democratizing-Diplomacy-A-Harness-for-Evaluating-Any-Large-Language-Model-on-Full-Press-Diplomacy",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-Democratizing-Diplomacy-A-Harness-for-Evaluating-Any-Large-Language-Model-on-Full-Press-Diplomacy/","children":"[논문리뷰] Democratizing Diplomacy: A Harness for Evaluating Any Large Language Model on Full-Press Diplomacy"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Elizabeth Karpinski이 [arXiv]에 게시한 'Democratizing Diplomacy: A Harness for Evaluating Any Large Language Model on Full-Press Diplomacy' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Diplomacy Game",{"className":"page__taxonomy-item","children":["#","Diplomacy Game"]}],["$","span","Multi-agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-agent Systems"]}],["$","span","Strategic Reasoning",{"className":"page__taxonomy-item","children":["#","Strategic Reasoning"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","Behavioral Analysis",{"className":"page__taxonomy-item","children":["#","Behavioral Analysis"]}],["$","span","Game AI",{"className":"page__taxonomy-item","children":["#","Game AI"]}]]}]]}]]}],["$","article","2025-8-13-DeCRED-Decoder-Centric-Regularization-for-Encoder-Decoder-Based-Speech-Recognition",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-DeCRED-Decoder-Centric-Regularization-for-Encoder-Decoder-Based-Speech-Recognition/","children":"[논문리뷰] DeCRED: Decoder-Centric Regularization for Encoder-Decoder Based Speech Recognition"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Lukáš Burget이 [arXiv]에 게시한 'DeCRED: Decoder-Centric Regularization for Encoder-Decoder Based Speech Recognition' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Speech Recognition",{"className":"page__taxonomy-item","children":["#","Speech Recognition"]}],["$","span","Encoder-Decoder",{"className":"page__taxonomy-item","children":["#","Encoder-Decoder"]}],["$","span","Regularization",{"className":"page__taxonomy-item","children":["#","Regularization"]}],["$","span","Decoder-Centric",{"className":"page__taxonomy-item","children":["#","Decoder-Centric"]}],["$","span","Intermediate Supervision",{"className":"page__taxonomy-item","children":["#","Intermediate Supervision"]}],["$","span","Out-of-Domain Generalization",{"className":"page__taxonomy-item","children":["#","Out-of-Domain Generalization"]}],["$","span","Internal Language Model",{"className":"page__taxonomy-item","children":["#","Internal Language Model"]}]]}]]}]]}],["$","article","2025-8-13-Cut2Next-Generating-Next-Shot-via-In-Context-Tuning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-Cut2Next-Generating-Next-Shot-via-In-Context-Tuning/","children":"[논문리뷰] Cut2Next: Generating Next Shot via In-Context Tuning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yu Qiao이 [arXiv]에 게시한 'Cut2Next: Generating Next Shot via In-Context Tuning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Next Shot Generation",{"className":"page__taxonomy-item","children":["#","Next Shot Generation"]}],["$","span","In-Context Tuning",{"className":"page__taxonomy-item","children":["#","In-Context Tuning"]}],["$","span","Diffusion Transformer",{"className":"page__taxonomy-item","children":["#","Diffusion Transformer"]}],["$","span","Cinematic Continuity",{"className":"page__taxonomy-item","children":["#","Cinematic Continuity"]}],["$","span","Hierarchical Prompting",{"className":"page__taxonomy-item","children":["#","Hierarchical Prompting"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Shot Editing",{"className":"page__taxonomy-item","children":["#","Shot Editing"]}]]}]]}]]}],["$","article","2025-8-13-CharacterShot-Controllable-and-Consistent-4D-Character-Animation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-CharacterShot-Controllable-and-Consistent-4D-Character-Animation/","children":"[논문리뷰] CharacterShot: Controllable and Consistent 4D Character Animation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Fei Shen이 [arXiv]에 게시한 'CharacterShot: Controllable and Consistent 4D Character Animation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","4D Character Animation",{"className":"page__taxonomy-item","children":["#","4D Character Animation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","Gaussian Splatting"]}],["$","span","Pose Control",{"className":"page__taxonomy-item","children":["#","Pose Control"]}],["$","span","Multi-view Synthesis",{"className":"page__taxonomy-item","children":["#","Multi-view Synthesis"]}],["$","span","Temporal Consistency",{"className":"page__taxonomy-item","children":["#","Temporal Consistency"]}],["$","span","Character Dataset",{"className":"page__taxonomy-item","children":["#","Character Dataset"]}]]}]]}]]}],["$","article","2025-8-13-Bridging-Theory-and-Practice-in-Quantum-Game-Theory-Optimized-Implementation-of-the-Battle-of-the-Sexes-with-Error-Mitigation-on-NISQ-Hardware",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-Bridging-Theory-and-Practice-in-Quantum-Game-Theory-Optimized-Implementation-of-the-Battle-of-the-Sexes-with-Error-Mitigation-on-NISQ-Hardware/","children":"[논문리뷰] Bridging Theory and Practice in Quantum Game Theory: Optimized Implementation of the Battle of the Sexes with Error Mitigation on NISQ Hardware"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jhon Alejandro Andrade이 [arXiv]에 게시한 'Bridging Theory and Practice in Quantum Game Theory: Optimized Implementation of the Battle of the Sexes with Error Mitigation on NISQ Hardware' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Quantum Game Theory",{"className":"page__taxonomy-item","children":["#","Quantum Game Theory"]}],["$","span","NISQ Hardware",{"className":"page__taxonomy-item","children":["#","NISQ Hardware"]}],["$","span","Error Mitigation",{"className":"page__taxonomy-item","children":["#","Error Mitigation"]}],["$","span","Battle of the Sexes",{"className":"page__taxonomy-item","children":["#","Battle of the Sexes"]}],["$","span","Qiskit",{"className":"page__taxonomy-item","children":["#","Qiskit"]}],["$","span","Quantum Computing",{"className":"page__taxonomy-item","children":["#","Quantum Computing"]}],["$","span","Strategic Coordination",{"className":"page__taxonomy-item","children":["#","Strategic Coordination"]}],["$","span","Payoff Maximization",{"className":"page__taxonomy-item","children":["#","Payoff Maximization"]}]]}]]}]]}],["$","article","2025-8-13-BiasGym-Fantastic-Biases-and-How-to-Find-and-Remove-Them",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-BiasGym-Fantastic-Biases-and-How-to-Find-and-Remove-Them/","children":"[논문리뷰] BiasGym: Fantastic Biases and How to Find (and Remove) Them"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Arnav Arora이 [arXiv]에 게시한 'BiasGym: Fantastic Biases and How to Find (and Remove) Them' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Bias Mitigation",{"className":"page__taxonomy-item","children":["#","Bias Mitigation"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Mechanistic Interpretability",{"className":"page__taxonomy-item","children":["#","Mechanistic Interpretability"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Attention Steering",{"className":"page__taxonomy-item","children":["#","Attention Steering"]}],["$","span","Stereotype Analysis",{"className":"page__taxonomy-item","children":["#","Stereotype Analysis"]}],["$","span","Safety Alignment",{"className":"page__taxonomy-item","children":["#","Safety Alignment"]}]]}]]}]]}],["$","article","2025-8-13-Beyond-Ten-Turns-Unlocking-Long-Horizon-Agentic-Search-with-Large-Scale-Asynchronous-RL",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-Beyond-Ten-Turns-Unlocking-Long-Horizon-Agentic-Search-with-Large-Scale-Asynchronous-RL/","children":"[논문리뷰] Beyond Ten Turns: Unlocking Long-Horizon Agentic Search with Large-Scale Asynchronous RL"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chuyi He이 [arXiv]에 게시한 'Beyond Ten Turns: Unlocking Long-Horizon Agentic Search with Large-Scale Asynchronous RL' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Agentic Search",{"className":"page__taxonomy-item","children":["#","Agentic Search"]}],["$","span","Asynchronous RL",{"className":"page__taxonomy-item","children":["#","Asynchronous RL"]}],["$","span","Long-Horizon Planning",{"className":"page__taxonomy-item","children":["#","Long-Horizon Planning"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Data Synthesis",{"className":"page__taxonomy-item","children":["#","Data Synthesis"]}]]}]]}]]}],["$","article","2025-8-13-AutoCodeBench-Large-Language-Models-are-Automatic-Code-Benchmark-Generators",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-AutoCodeBench-Large-Language-Models-are-Automatic-Code-Benchmark-Generators/","children":"[논문리뷰] AutoCodeBench: Large Language Models are Automatic Code Benchmark Generators"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Tao Zhang이 [arXiv]에 게시한 'AutoCodeBench: Large Language Models are Automatic Code Benchmark Generators' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","코드 생성",{"className":"page__taxonomy-item","children":["#","코드 생성"]}],["$","span","대규모 언어 모델",{"className":"page__taxonomy-item","children":["#","대규모 언어 모델"]}],["$","span","코드 벤치마크",{"className":"page__taxonomy-item","children":["#","코드 벤치마크"]}],["$","span","다국어 프로그래밍",{"className":"page__taxonomy-item","children":["#","다국어 프로그래밍"]}],["$","span","자동화된 데이터 생성",{"className":"page__taxonomy-item","children":["#","자동화된 데이터 생성"]}],["$","span","샌드박스 평가",{"className":"page__taxonomy-item","children":["#","샌드박스 평가"]}],["$","span","멀티모달 AI",{"className":"page__taxonomy-item","children":["#","멀티모달 AI"]}]]}]]}]]}],["$","article","2025-8-13-Aryabhata-An-exam-focused-language-model-for-JEE-Math",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-Aryabhata-An-exam-focused-language-model-for-JEE-Math/","children":"[논문리뷰] Aryabhata: An exam-focused language model for JEE Math"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Sandeep Varma이 [arXiv]에 게시한 'Aryabhata: An exam-focused language model for JEE Math' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Language Model",{"className":"page__taxonomy-item","children":["#","Language Model"]}],["$","span","Math Reasoning",{"className":"page__taxonomy-item","children":["#","Math Reasoning"]}],["$","span","JEE",{"className":"page__taxonomy-item","children":["#","JEE"]}],["$","span","Supervised Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Model Merging",{"className":"page__taxonomy-item","children":["#","Model Merging"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}]]}]]}]]}],["$","article","2025-8-13-Adversarial-Video-Promotion-Against-Text-to-Video-Retrieval",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-Adversarial-Video-Promotion-Against-Text-to-Video-Retrieval/","children":"[논문리뷰] Adversarial Video Promotion Against Text-to-Video Retrieval"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shuai Liu이 [arXiv]에 게시한 'Adversarial Video Promotion Against Text-to-Video Retrieval' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Adversarial Attack",{"className":"page__taxonomy-item","children":["#","Adversarial Attack"]}],["$","span","Video Promotion",{"className":"page__taxonomy-item","children":["#","Video Promotion"]}],["$","span","Text-to-Video Retrieval",{"className":"page__taxonomy-item","children":["#","Text-to-Video Retrieval"]}],["$","span","Modality Refinement",{"className":"page__taxonomy-item","children":["#","Modality Refinement"]}],["$","span","Black-box Attack",{"className":"page__taxonomy-item","children":["#","Black-box Attack"]}],["$","span","Video Manipulation",{"className":"page__taxonomy-item","children":["#","Video Manipulation"]}],["$","span","Transferability",{"className":"page__taxonomy-item","children":["#","Transferability"]}]]}]]}]]}],["$","article","2025-8-12-WideSearch-Benchmarking-Agentic-Broad-Info-Seeking",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-WideSearch-Benchmarking-Agentic-Broad-Info-Seeking/","children":"[논문리뷰] WideSearch: Benchmarking Agentic Broad Info-Seeking"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yan Gao이 [arXiv]에 게시한 'WideSearch: Benchmarking Agentic Broad Info-Seeking' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic Search",{"className":"page__taxonomy-item","children":["#","Agentic Search"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Information Seeking",{"className":"page__taxonomy-item","children":["#","Information Seeking"]}],["$","span","Structured Output",{"className":"page__taxonomy-item","children":["#","Structured Output"]}],["$","span","Evaluation Metrics",{"className":"page__taxonomy-item","children":["#","Evaluation Metrics"]}],["$","span","Multi-agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-agent Systems"]}]]}]]}]]}],["$","article","2025-8-12-When-Good-Sounds-Go-Adversarial-Jailbreaking-Audio-Language-Models-with-Benign-Inputs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-When-Good-Sounds-Go-Adversarial-Jailbreaking-Audio-Language-Models-with-Benign-Inputs/","children":"[논문리뷰] When Good Sounds Go Adversarial: Jailbreaking Audio-Language Models with Benign Inputs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Dasol Choi이 [arXiv]에 게시한 'When Good Sounds Go Adversarial: Jailbreaking Audio-Language Models with Benign Inputs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Audio-Language Models",{"className":"page__taxonomy-item","children":["#","Audio-Language Models"]}],["$","span","Jailbreak Attack",{"className":"page__taxonomy-item","children":["#","Jailbreak Attack"]}],["$","span","Adversarial Audio",{"className":"page__taxonomy-item","children":["#","Adversarial Audio"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Projected Gradient Descent",{"className":"page__taxonomy-item","children":["#","Projected Gradient Descent"]}],["$","span","Native Payload Discovery",{"className":"page__taxonomy-item","children":["#","Native Payload Discovery"]}],["$","span","Multimodal AI Safety",{"className":"page__taxonomy-item","children":["#","Multimodal AI Safety"]}]]}]]}]]}],["$","article","2025-8-12-VisR-Bench-An-Empirical-Study-on-Visual-Retrieval-Augmented-Generation-for-Multilingual-Long-Document-Understanding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-VisR-Bench-An-Empirical-Study-on-Visual-Retrieval-Augmented-Generation-for-Multilingual-Long-Document-Understanding/","children":"[논문리뷰] VisR-Bench: An Empirical Study on Visual Retrieval-Augmented Generation for Multilingual Long Document Understanding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Tong Yu이 [arXiv]에 게시한 'VisR-Bench: An Empirical Study on Visual Retrieval-Augmented Generation for Multilingual Long Document Understanding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Retrieval",{"className":"page__taxonomy-item","children":["#","Multimodal Retrieval"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","Long Document Understanding",{"className":"page__taxonomy-item","children":["#","Long Document Understanding"]}],["$","span","Multilingual NLP",{"className":"page__taxonomy-item","children":["#","Multilingual NLP"]}],["$","span","Visual QA",{"className":"page__taxonomy-item","children":["#","Visual QA"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","MLLMs",{"className":"page__taxonomy-item","children":["#","MLLMs"]}],["$","span","Table Understanding",{"className":"page__taxonomy-item","children":["#","Table Understanding"]}]]}]]}]]}],["$","article","2025-8-12-UserBench-An-Interactive-Gym-Environment-for-User-Centric-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-UserBench-An-Interactive-Gym-Environment-for-User-Centric-Agents/","children":"[논문리뷰] UserBench: An Interactive Gym Environment for User-Centric Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jianguo Zhang이 [arXiv]에 게시한 'UserBench: An Interactive Gym Environment for User-Centric Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","User-Centric AI",{"className":"page__taxonomy-item","children":["#","User-Centric AI"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Interactive Agents",{"className":"page__taxonomy-item","children":["#","Interactive Agents"]}],["$","span","Gym Environment",{"className":"page__taxonomy-item","children":["#","Gym Environment"]}],["$","span","Preference Elicitation",{"className":"page__taxonomy-item","children":["#","Preference Elicitation"]}],["$","span","Multi-turn Dialogue",{"className":"page__taxonomy-item","children":["#","Multi-turn Dialogue"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}]]}]]}]]}],["$","article","2025-8-12-Temporal-Self-Rewarding-Language-Models-Decoupling-Chosen-Rejected-via-Past-Future",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-Temporal-Self-Rewarding-Language-Models-Decoupling-Chosen-Rejected-via-Past-Future/","children":"[논문리뷰] Temporal Self-Rewarding Language Models: Decoupling Chosen-Rejected via Past-Future"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Qiufeng Wang이 [arXiv]에 게시한 'Temporal Self-Rewarding Language Models: Decoupling Chosen-Rejected via Past-Future' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Self-Rewarding LLMs",{"className":"page__taxonomy-item","children":["#","Self-Rewarding LLMs"]}],["$","span","Direct Preference Optimization (DPO)",{"className":"page__taxonomy-item","children":["#","Direct Preference Optimization (DPO)"]}],["$","span","Preference Learning",{"className":"page__taxonomy-item","children":["#","Preference Learning"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Gradient Collapse",{"className":"page__taxonomy-item","children":["#","Gradient Collapse"]}],["$","span","LLM Alignment",{"className":"page__taxonomy-item","children":["#","LLM Alignment"]}],["$","span","Iterative Optimization",{"className":"page__taxonomy-item","children":["#","Iterative Optimization"]}]]}]]}]]}],["$","article","2025-8-12-Speech-to-LaTeX-New-Models-and-Datasets-for-Converting-Spoken-Equations-and-Sentences",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-Speech-to-LaTeX-New-Models-and-Datasets-for-Converting-Spoken-Equations-and-Sentences/","children":"[논문리뷰] Speech-to-LaTeX: New Models and Datasets for Converting Spoken Equations and Sentences"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Matvey Skripkin이 [arXiv]에 게시한 'Speech-to-LaTeX: New Models and Datasets for Converting Spoken Equations and Sentences' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Speech-to-LaTeX",{"className":"page__taxonomy-item","children":["#","Speech-to-LaTeX"]}],["$","span","ASR",{"className":"page__taxonomy-item","children":["#","ASR"]}],["$","span","Language Models",{"className":"page__taxonomy-item","children":["#","Language Models"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Dataset Creation",{"className":"page__taxonomy-item","children":["#","Dataset Creation"]}],["$","span","Mathematical Expression Recognition",{"className":"page__taxonomy-item","children":["#","Mathematical Expression Recognition"]}],["$","span","LaTeX Generation",{"className":"page__taxonomy-item","children":["#","LaTeX Generation"]}]]}]]}]]}],["$","article","2025-8-12-Shortcut-Learning-in-Generalist-Robot-Policies-The-Role-of-Dataset-Diversity-and-Fragmentation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-Shortcut-Learning-in-Generalist-Robot-Policies-The-Role-of-Dataset-Diversity-and-Fragmentation/","children":"[논문리뷰] Shortcut Learning in Generalist Robot Policies: The Role of Dataset Diversity and Fragmentation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hengtao Shen이 [arXiv]에 게시한 'Shortcut Learning in Generalist Robot Policies: The Role of Dataset Diversity and Fragmentation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Robot Learning",{"className":"page__taxonomy-item","children":["#","Robot Learning"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Shortcut Learning",{"className":"page__taxonomy-item","children":["#","Shortcut Learning"]}],["$","span","Dataset Diversity",{"className":"page__taxonomy-item","children":["#","Dataset Diversity"]}],["$","span","Dataset Fragmentation",{"className":"page__taxonomy-item","children":["#","Dataset Fragmentation"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}],["$","span","Imitation Learning",{"className":"page__taxonomy-item","children":["#","Imitation Learning"]}]]}]]}]]}],["$","article","2025-8-12-Reinforcement-Learning-in-Vision-A-Survey",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-Reinforcement-Learning-in-Vision-A-Survey/","children":"[논문리뷰] Reinforcement Learning in Vision: A Survey"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Qingwei Meng이 [arXiv]에 게시한 'Reinforcement Learning in Vision: A Survey' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Computer Vision (CV)",{"className":"page__taxonomy-item","children":["#","Computer Vision (CV)"]}],["$","span","Multimodal Large Language Models (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models (MLLMs)"]}],["$","span","Visual Generation",{"className":"page__taxonomy-item","children":["#","Visual Generation"]}],["$","span","Vision-Language-Action (VLA) Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action (VLA) Models"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Reward Modeling",{"className":"page__taxonomy-item","children":["#","Reward Modeling"]}]]}]]}]]}],["$","article","2025-8-12-ReasonRank-Empowering-Passage-Ranking-with-Strong-Reasoning-Ability",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-ReasonRank-Empowering-Passage-Ranking-with-Strong-Reasoning-Ability/","children":"[논문리뷰] ReasonRank: Empowering Passage Ranking with Strong Reasoning Ability"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuchen Li이 [arXiv]에 게시한 'ReasonRank: Empowering Passage Ranking with Strong Reasoning Ability' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Passage Ranking",{"className":"page__taxonomy-item","children":["#","Passage Ranking"]}],["$","span","Reasoning Models",{"className":"page__taxonomy-item","children":["#","Reasoning Models"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Data Synthesis",{"className":"page__taxonomy-item","children":["#","Data Synthesis"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Listwise Reranking",{"className":"page__taxonomy-item","children":["#","Listwise Reranking"]}],["$","span","Information Retrieval",{"className":"page__taxonomy-item","children":["#","Information Retrieval"]}]]}]]}]]}],["$","article","2025-8-12-Part-I-Tricks-or-Traps-A-Deep-Dive-into-RL-for-LLM-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-Part-I-Tricks-or-Traps-A-Deep-Dive-into-RL-for-LLM-Reasoning/","children":"[논문리뷰] Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiaheng Liu이 [arXiv]에 게시한 'Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","LLM Reasoning",{"className":"page__taxonomy-item","children":["#","LLM Reasoning"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Normalization",{"className":"page__taxonomy-item","children":["#","Normalization"]}],["$","span","Clipping",{"className":"page__taxonomy-item","children":["#","Clipping"]}],["$","span","Loss Aggregation",{"className":"page__taxonomy-item","children":["#","Loss Aggregation"]}],["$","span","Overlong Filtering",{"className":"page__taxonomy-item","children":["#","Overlong Filtering"]}]]}]]}]]}],["$","article","2025-8-12-OmniEAR-Benchmarking-Agent-Reasoning-in-Embodied-Tasks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-OmniEAR-Benchmarking-Agent-Reasoning-in-Embodied-Tasks/","children":"[논문리뷰] OmniEAR: Benchmarking Agent Reasoning in Embodied Tasks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hongxing Li이 [arXiv]에 게시한 'OmniEAR: Benchmarking Agent Reasoning in Embodied Tasks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Agent Reasoning",{"className":"page__taxonomy-item","children":["#","Agent Reasoning"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Physical Interaction",{"className":"page__taxonomy-item","children":["#","Physical Interaction"]}],["$","span","Constraint Reasoning",{"className":"page__taxonomy-item","children":["#","Constraint Reasoning"]}]]}]]}]]}],["$","article","2025-8-12-Omni-Effects-Unified-and-Spatially-Controllable-Visual-Effects-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-Omni-Effects-Unified-and-Spatially-Controllable-Visual-Effects-Generation/","children":"[논문리뷰] Omni-Effects: Unified and Spatially-Controllable Visual Effects Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiaokun Feng이 [arXiv]에 게시한 'Omni-Effects: Unified and Spatially-Controllable Visual Effects Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Visual Effects",{"className":"page__taxonomy-item","children":["#","Visual Effects"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","LoRA",{"className":"page__taxonomy-item","children":["#","LoRA"]}],["$","span","Mixture of Experts",{"className":"page__taxonomy-item","children":["#","Mixture of Experts"]}],["$","span","Spatial Control",{"className":"page__taxonomy-item","children":["#","Spatial Control"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Multi-VFX",{"className":"page__taxonomy-item","children":["#","Multi-VFX"]}]]}]]}]]}],["$","article","2025-8-12-MolmoAct-Action-Reasoning-Models-that-can-Reason-in-Space",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-MolmoAct-Action-Reasoning-Models-that-can-Reason-in-Space/","children":"[논문리뷰] MolmoAct: Action Reasoning Models that can Reason in Space"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shuo Liu이 [arXiv]에 게시한 'MolmoAct: Action Reasoning Models that can Reason in Space' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Action Reasoning",{"className":"page__taxonomy-item","children":["#","Action Reasoning"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Spatial Planning",{"className":"page__taxonomy-item","children":["#","Spatial Planning"]}],["$","span","Depth Perception",{"className":"page__taxonomy-item","children":["#","Depth Perception"]}],["$","span","Trajectory Generation",{"className":"page__taxonomy-item","children":["#","Trajectory Generation"]}],["$","span","Explainable AI",{"className":"page__taxonomy-item","children":["#","Explainable AI"]}]]}]]}]]}],["$","article","2025-8-12-MoBE-Mixture-of-Basis-Experts-for-Compressing-MoE-based-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-MoBE-Mixture-of-Basis-Experts-for-Compressing-MoE-based-LLMs/","children":"[논문리뷰] MoBE: Mixture-of-Basis-Experts for Compressing MoE-based LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jianguo Li이 [arXiv]에 게시한 'MoBE: Mixture-of-Basis-Experts for Compressing MoE-based LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Mixture-of-Experts (MoE)",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts (MoE)"]}],["$","span","LLM Compression",{"className":"page__taxonomy-item","children":["#","LLM Compression"]}],["$","span","Matrix Decomposition",{"className":"page__taxonomy-item","children":["#","Matrix Decomposition"]}],["$","span","Parameter Efficiency",{"className":"page__taxonomy-item","children":["#","Parameter Efficiency"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}],["$","span","Memory Optimization",{"className":"page__taxonomy-item","children":["#","Memory Optimization"]}]]}]]}]]}],["$","article","2025-8-12-Less-Is-More-Training-Free-Sparse-Attention-with-Global-Locality-for-Efficient-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-Less-Is-More-Training-Free-Sparse-Attention-with-Global-Locality-for-Efficient-Reasoning/","children":"[논문리뷰] Less Is More: Training-Free Sparse Attention with Global Locality for Efficient Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Baihong Yuan이 [arXiv]에 게시한 'Less Is More: Training-Free Sparse Attention with Global Locality for Efficient Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Sparse Attention",{"className":"page__taxonomy-item","children":["#","Sparse Attention"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Reasoning Tasks",{"className":"page__taxonomy-item","children":["#","Reasoning Tasks"]}],["$","span","Efficiency",{"className":"page__taxonomy-item","children":["#","Efficiency"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}],["$","span","Global Locality",{"className":"page__taxonomy-item","children":["#","Global Locality"]}],["$","span","KV Cache Optimization",{"className":"page__taxonomy-item","children":["#","KV Cache Optimization"]}]]}]]}]]}],["$","article","2025-8-12-Klear-Reasoner-Advancing-Reasoning-Capability-via-Gradient-Preserving-Clipping-Policy-Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-Klear-Reasoner-Advancing-Reasoning-Capability-via-Gradient-Preserving-Clipping-Policy-Optimization/","children":"[논문리뷰] Klear-Reasoner: Advancing Reasoning Capability via Gradient-Preserving Clipping Policy Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Guanting Dong이 [arXiv]에 게시한 'Klear-Reasoner: Advancing Reasoning Capability via Gradient-Preserving Clipping Policy Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reasoning LLMs",{"className":"page__taxonomy-item","children":["#","Reasoning LLMs"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","PPO",{"className":"page__taxonomy-item","children":["#","PPO"]}],["$","span","Gradient Clipping",{"className":"page__taxonomy-item","children":["#","Gradient Clipping"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Math Reasoning",{"className":"page__taxonomy-item","children":["#","Math Reasoning"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}]]}]]}]]}],["$","article","2025-8-12-Grove-MoE-Towards-Efficient-and-Superior-MoE-LLMs-with-Adjugate-Experts",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-Grove-MoE-Towards-Efficient-and-Superior-MoE-LLMs-with-Adjugate-Experts/","children":"[논문리뷰] Grove MoE: Towards Efficient and Superior MoE LLMs with Adjugate Experts"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Tieyuan Chen이 [arXiv]에 게시한 'Grove MoE: Towards Efficient and Superior MoE LLMs with Adjugate Experts' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Mixture of Experts",{"className":"page__taxonomy-item","children":["#","Mixture of Experts"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","MoE Architecture",{"className":"page__taxonomy-item","children":["#","MoE Architecture"]}],["$","span","Dynamic Activation",{"className":"page__taxonomy-item","children":["#","Dynamic Activation"]}],["$","span","Adjugate Experts",{"className":"page__taxonomy-item","children":["#","Adjugate Experts"]}],["$","span","Upcycling Strategy",{"className":"page__taxonomy-item","children":["#","Upcycling Strategy"]}],["$","span","Load Balancing",{"className":"page__taxonomy-item","children":["#","Load Balancing"]}]]}]]}]]}],["$","article","2025-8-12-GLiClass-Generalist-Lightweight-Model-for-Sequence-Classification-Tasks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-GLiClass-Generalist-Lightweight-Model-for-Sequence-Classification-Tasks/","children":"[논문리뷰] GLiClass: Generalist Lightweight Model for Sequence Classification Tasks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Alexander Yavorskyi이 [arXiv]에 게시한 'GLiClass: Generalist Lightweight Model for Sequence Classification Tasks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Sequence Classification",{"className":"page__taxonomy-item","children":["#","Sequence Classification"]}],["$","span","Zero-shot Learning",{"className":"page__taxonomy-item","children":["#","Zero-shot Learning"]}],["$","span","Few-shot Learning",{"className":"page__taxonomy-item","children":["#","Few-shot Learning"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Multi-label Classification",{"className":"page__taxonomy-item","children":["#","Multi-label Classification"]}],["$","span","PPO",{"className":"page__taxonomy-item","children":["#","PPO"]}],["$","span","GLiNER",{"className":"page__taxonomy-item","children":["#","GLiNER"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}]]}]]}]]}],["$","article","2025-8-12-Follow-Your-Shape-Shape-Aware-Image-Editing-via-Trajectory-Guided-Region-Control",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-Follow-Your-Shape-Shape-Aware-Image-Editing-via-Trajectory-Guided-Region-Control/","children":"[논문리뷰] Follow-Your-Shape: Shape-Aware Image Editing via Trajectory-Guided Region Control"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hongyu Liu이 [arXiv]에 게시한 'Follow-Your-Shape: Shape-Aware Image Editing via Trajectory-Guided Region Control' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Shape Transformation",{"className":"page__taxonomy-item","children":["#","Shape Transformation"]}],["$","span","Rectified Flow",{"className":"page__taxonomy-item","children":["#","Rectified Flow"]}],["$","span","Trajectory Divergence Map",{"className":"page__taxonomy-item","children":["#","Trajectory Divergence Map"]}],["$","span","Region Control",{"className":"page__taxonomy-item","children":["#","Region Control"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}]]}]]}]]}],["$","article","2025-8-12-Fact2Fiction-Targeted-Poisoning-Attack-to-Agentic-Fact-checking-System",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-Fact2Fiction-Targeted-Poisoning-Attack-to-Agentic-Fact-checking-System/","children":"[논문리뷰] Fact2Fiction: Targeted Poisoning Attack to Agentic Fact-checking System"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Reynold Cheng이 [arXiv]에 게시한 'Fact2Fiction: Targeted Poisoning Attack to Agentic Fact-checking System' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Adversarial Attack",{"className":"page__taxonomy-item","children":["#","Adversarial Attack"]}],["$","span","Poisoning Attack",{"className":"page__taxonomy-item","children":["#","Poisoning Attack"]}],["$","span","Fact-checking",{"className":"page__taxonomy-item","children":["#","Fact-checking"]}],["$","span","LLM Agent",{"className":"page__taxonomy-item","children":["#","LLM Agent"]}],["$","span","Retrieval Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval Augmented Generation"]}],["$","span","Misinformation",{"className":"page__taxonomy-item","children":["#","Misinformation"]}],["$","span","System Security",{"className":"page__taxonomy-item","children":["#","System Security"]}]]}]]}]]}],["$","article","2025-8-12-Deep-Ignorance-Filtering-Pretraining-Data-Builds-Tamper-Resistant-Safeguards-into-Open-Weight-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-Deep-Ignorance-Filtering-Pretraining-Data-Builds-Tamper-Resistant-Safeguards-into-Open-Weight-LLMs/","children":"[논문리뷰] Deep Ignorance: Filtering Pretraining Data Builds Tamper-Resistant Safeguards into Open-Weight LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Robert Kirk이 [arXiv]에 게시한 'Deep Ignorance: Filtering Pretraining Data Builds Tamper-Resistant Safeguards into Open-Weight LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","데이터 필터링",{"className":"page__taxonomy-item","children":["#","데이터 필터링"]}],["$","span","사전 학습",{"className":"page__taxonomy-item","children":["#","사전 학습"]}],["$","span","변조 저항성",{"className":"page__taxonomy-item","children":["#","변조 저항성"]}],["$","span","바이오위협",{"className":"page__taxonomy-item","children":["#","바이오위협"]}],["$","span","AI 안전",{"className":"page__taxonomy-item","children":["#","AI 안전"]}],["$","span","서킷 브레이킹",{"className":"page__taxonomy-item","children":["#","서킷 브레이킹"]}],["$","span","머신 언러닝",{"className":"page__taxonomy-item","children":["#","머신 언러닝"]}]]}]]}]]}],["$","article","2025-8-12-Compressing-Chain-of-Thought-in-LLMs-via-Step-Entropy",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-Compressing-Chain-of-Thought-in-LLMs-via-Step-Entropy/","children":"[논문리뷰] Compressing Chain-of-Thought in LLMs via Step Entropy"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhijian Xu이 [arXiv]에 게시한 'Compressing Chain-of-Thought in LLMs via Step Entropy' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","CoT Compression",{"className":"page__taxonomy-item","children":["#","CoT Compression"]}],["$","span","Step Entropy",{"className":"page__taxonomy-item","children":["#","Step Entropy"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","SFT",{"className":"page__taxonomy-item","children":["#","SFT"]}],["$","span","GRPO",{"className":"page__taxonomy-item","children":["#","GRPO"]}]]}]]}]]}],["$","article","2025-8-12-BrowseComp-Plus-A-More-Fair-and-Transparent-Evaluation-Benchmark-of-Deep-Research-Agent",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-BrowseComp-Plus-A-More-Fair-and-Transparent-Evaluation-Benchmark-of-Deep-Research-Agent/","children":"[논문리뷰] BrowseComp-Plus: A More Fair and Transparent Evaluation Benchmark of Deep-Research Agent"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kai Zou이 [arXiv]에 게시한 'BrowseComp-Plus: A More Fair and Transparent Evaluation Benchmark of Deep-Research Agent' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Deep-Research Agents",{"className":"page__taxonomy-item","children":["#","Deep-Research Agents"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Retrieval",{"className":"page__taxonomy-item","children":["#","Retrieval"]}],["$","span","Curated Corpus",{"className":"page__taxonomy-item","children":["#","Curated Corpus"]}],["$","span","Evaluation",{"className":"page__taxonomy-item","children":["#","Evaluation"]}],["$","span","Fairness",{"className":"page__taxonomy-item","children":["#","Fairness"]}],["$","span","Transparency",{"className":"page__taxonomy-item","children":["#","Transparency"]}],["$","span","Reproducibility",{"className":"page__taxonomy-item","children":["#","Reproducibility"]}]]}]]}]]}],["$","article","2025-8-12-Bifrost-1-Bridging-Multimodal-LLMs-and-Diffusion-Models-with-Patch-level-CLIP-Latents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-Bifrost-1-Bridging-Multimodal-LLMs-and-Diffusion-Models-with-Patch-level-CLIP-Latents/","children":"[논문리뷰] Bifrost-1: Bridging Multimodal LLMs and Diffusion Models with Patch-level CLIP Latents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Mohit Bansal이 [arXiv]에 게시한 'Bifrost-1: Bridging Multimodal LLMs and Diffusion Models with Patch-level CLIP Latents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLM",{"className":"page__taxonomy-item","children":["#","Multimodal LLM"]}],["$","span","Diffusion Model",{"className":"page__taxonomy-item","children":["#","Diffusion Model"]}],["$","span","CLIP Latent",{"className":"page__taxonomy-item","children":["#","CLIP Latent"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Multimodal Understanding",{"className":"page__taxonomy-item","children":["#","Multimodal Understanding"]}],["$","span","ControlNet",{"className":"page__taxonomy-item","children":["#","ControlNet"]}],["$","span","Training Efficiency",{"className":"page__taxonomy-item","children":["#","Training Efficiency"]}]]}]]}]]}],["$","article","2025-8-12-A-Comprehensive-Survey-of-Self-Evolving-AI-Agents-A-New-Paradigm-Bridging-Foundation-Models-and-Lifelong-Agentic-Systems",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-A-Comprehensive-Survey-of-Self-Evolving-AI-Agents-A-New-Paradigm-Bridging-Foundation-Models-and-Lifelong-Agentic-Systems/","children":"[논문리뷰] A Comprehensive Survey of Self-Evolving AI Agents: A New Paradigm Bridging Foundation Models and Lifelong Agentic Systems"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xinhao Yi이 [arXiv]에 게시한 'A Comprehensive Survey of Self-Evolving AI Agents: A New Paradigm Bridging Foundation Models and Lifelong Agentic Systems' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Self-Evolving AI Agents",{"className":"page__taxonomy-item","children":["#","Self-Evolving AI Agents"]}],["$","span","Lifelong Learning",{"className":"page__taxonomy-item","children":["#","Lifelong Learning"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Agent Optimization",{"className":"page__taxonomy-item","children":["#","Agent Optimization"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","AI Safety",{"className":"page__taxonomy-item","children":["#","AI Safety"]}],["$","span","Survey",{"className":"page__taxonomy-item","children":["#","Survey"]}]]}]]}]]}],["$","article","2025-8-11-Voost-A-Unified-and-Scalable-Diffusion-Transformer-for-Bidirectional-Virtual-Try-On-and-Try-Off",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-11-Voost-A-Unified-and-Scalable-Diffusion-Transformer-for-Bidirectional-Virtual-Try-On-and-Try-Off/","children":"[논문리뷰] Voost: A Unified and Scalable Diffusion Transformer for Bidirectional Virtual Try-On and Try-Off"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"jgkwak이 [arXiv]에 게시한 'Voost: A Unified and Scalable Diffusion Transformer for Bidirectional Virtual Try-On and Try-Off' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-11 13:13:28+0900","children":"2025년 8월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Virtual Try-On",{"className":"page__taxonomy-item","children":["#","Virtual Try-On"]}],["$","span","Virtual Try-Off",{"className":"page__taxonomy-item","children":["#","Virtual Try-Off"]}],["$","span","Diffusion Transformer",{"className":"page__taxonomy-item","children":["#","Diffusion Transformer"]}],["$","span","Bidirectional Learning",{"className":"page__taxonomy-item","children":["#","Bidirectional Learning"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Fashion Synthesis",{"className":"page__taxonomy-item","children":["#","Fashion Synthesis"]}],["$","span","Attention Mechanism",{"className":"page__taxonomy-item","children":["#","Attention Mechanism"]}],["$","span","Self-Correction",{"className":"page__taxonomy-item","children":["#","Self-Correction"]}]]}]]}]]}],["$","article","2025-8-11-UI-AGILE-Advancing-GUI-Agents-with-Effective-Reinforcement-Learning-and-Precise-Inference-Time-Grounding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-11-UI-AGILE-Advancing-GUI-Agents-with-Effective-Reinforcement-Learning-and-Precise-Inference-Time-Grounding/","children":"[논문리뷰] UI-AGILE: Advancing GUI Agents with Effective Reinforcement Learning and Precise Inference-Time Grounding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Bingqi Chen이 [arXiv]에 게시한 'UI-AGILE: Advancing GUI Agents with Effective Reinforcement Learning and Precise Inference-Time Grounding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-11 13:13:28+0900","children":"2025년 8월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","GUI Agents",{"className":"page__taxonomy-item","children":["#","GUI Agents"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Grounding",{"className":"page__taxonomy-item","children":["#","Grounding"]}],["$","span","MLLMs",{"className":"page__taxonomy-item","children":["#","MLLMs"]}],["$","span","Reward Function",{"className":"page__taxonomy-item","children":["#","Reward Function"]}],["$","span","Resampling",{"className":"page__taxonomy-item","children":["#","Resampling"]}],["$","span","Visual Noise Reduction",{"className":"page__taxonomy-item","children":["#","Visual Noise Reduction"]}]]}]]}]]}],["$","article","2025-8-11-Pruning-the-Unsurprising-Efficient-Code-Reasoning-via-First-Token-Surprisal",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-11-Pruning-the-Unsurprising-Efficient-Code-Reasoning-via-First-Token-Surprisal/","children":"[논문리뷰] Pruning the Unsurprising: Efficient Code Reasoning via First-Token Surprisal"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chengcheng Wan이 [arXiv]에 게시한 'Pruning the Unsurprising: Efficient Code Reasoning via First-Token Surprisal' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-11 13:13:28+0900","children":"2025년 8월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Code Reasoning",{"className":"page__taxonomy-item","children":["#","Code Reasoning"]}],["$","span","CoT Compression",{"className":"page__taxonomy-item","children":["#","CoT Compression"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Efficiency",{"className":"page__taxonomy-item","children":["#","Efficiency"]}],["$","span","Surprisal",{"className":"page__taxonomy-item","children":["#","Surprisal"]}],["$","span","Pruning",{"className":"page__taxonomy-item","children":["#","Pruning"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Large Reasoning Models",{"className":"page__taxonomy-item","children":["#","Large Reasoning Models"]}]]}]]}]]}],["$","article","2025-8-11-MeshLLM-Empowering-Large-Language-Models-to-Progressively-Understand-and-Generate-3D-Mesh",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-11-MeshLLM-Empowering-Large-Language-Models-to-Progressively-Understand-and-Generate-3D-Mesh/","children":"[논문리뷰] MeshLLM: Empowering Large Language Models to Progressively Understand and Generate 3D Mesh"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yi Yang이 [arXiv]에 게시한 'MeshLLM: Empowering Large Language Models to Progressively Understand and Generate 3D Mesh' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-11 13:13:28+0900","children":"2025년 8월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Mesh Generation",{"className":"page__taxonomy-item","children":["#","3D Mesh Generation"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Mesh Understanding",{"className":"page__taxonomy-item","children":["#","Mesh Understanding"]}],["$","span","Text-to-3D",{"className":"page__taxonomy-item","children":["#","Text-to-3D"]}],["$","span","Primitive-Mesh Decomposition",{"className":"page__taxonomy-item","children":["#","Primitive-Mesh Decomposition"]}],["$","span","Progressive Training",{"className":"page__taxonomy-item","children":["#","Progressive Training"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}]]}]]}]]}],["$","article","2025-8-11-Memp-Exploring-Agent-Procedural-Memory",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-11-Memp-Exploring-Agent-Procedural-Memory/","children":"[논문리뷰] Memp: Exploring Agent Procedural Memory"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shuofei Qiao이 [arXiv]에 게시한 'Memp: Exploring Agent Procedural Memory' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-11 13:13:28+0900","children":"2025년 8월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Procedural Memory",{"className":"page__taxonomy-item","children":["#","Procedural Memory"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Memory Management",{"className":"page__taxonomy-item","children":["#","Memory Management"]}],["$","span","Task Automation",{"className":"page__taxonomy-item","children":["#","Task Automation"]}],["$","span","Lifelong Learning",{"className":"page__taxonomy-item","children":["#","Lifelong Learning"]}],["$","span","Experience Replay",{"className":"page__taxonomy-item","children":["#","Experience Replay"]}],["$","span","Agent Learning",{"className":"page__taxonomy-item","children":["#","Agent Learning"]}]]}]]}]]}],["$","article","2025-8-11-MELLA-Bridging-Linguistic-Capability-and-Cultural-Groundedness-for-Low-Resource-Language-MLLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-11-MELLA-Bridging-Linguistic-Capability-and-Cultural-Groundedness-for-Low-Resource-Language-MLLMs/","children":"[논문리뷰] MELLA: Bridging Linguistic Capability and Cultural Groundedness for Low-Resource Language MLLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Guohang Yan이 [arXiv]에 게시한 'MELLA: Bridging Linguistic Capability and Cultural Groundedness for Low-Resource Language MLLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-11 13:13:28+0900","children":"2025년 8월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models"]}],["$","span","Low-Resource Languages",{"className":"page__taxonomy-item","children":["#","Low-Resource Languages"]}],["$","span","Cultural Groundedness",{"className":"page__taxonomy-item","children":["#","Cultural Groundedness"]}],["$","span","Linguistic Capability",{"className":"page__taxonomy-item","children":["#","Linguistic Capability"]}],["$","span","Dataset Creation",{"className":"page__taxonomy-item","children":["#","Dataset Creation"]}],["$","span","Multilingual AI",{"className":"page__taxonomy-item","children":["#","Multilingual AI"]}]]}]]}]]}],["$","article","2025-8-11-LightSwitch-Multi-view-Relighting-with-Material-guided-Diffusion",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-11-LightSwitch-Multi-view-Relighting-with-Material-guided-Diffusion/","children":"[논문리뷰] LightSwitch: Multi-view Relighting with Material-guided Diffusion"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shubham Tulsiani이 [arXiv]에 게시한 'LightSwitch: Multi-view Relighting with Material-guided Diffusion' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-11 13:13:28+0900","children":"2025년 8월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-view Relighting",{"className":"page__taxonomy-item","children":["#","Multi-view Relighting"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Material-guided",{"className":"page__taxonomy-item","children":["#","Material-guided"]}],["$","span","Inverse Rendering",{"className":"page__taxonomy-item","children":["#","Inverse Rendering"]}],["$","span","3D Scene Reconstruction",{"className":"page__taxonomy-item","children":["#","3D Scene Reconstruction"]}],["$","span","Image Synthesis",{"className":"page__taxonomy-item","children":["#","Image Synthesis"]}],["$","span","Consistent Relighting",{"className":"page__taxonomy-item","children":["#","Consistent Relighting"]}]]}]]}]]}],["$","article","2025-8-11-InfiGUI-G1-Advancing-GUI-Grounding-with-Adaptive-Exploration-Policy-Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-11-InfiGUI-G1-Advancing-GUI-Grounding-with-Adaptive-Exploration-Policy-Optimization/","children":"[논문리뷰] InfiGUI-G1: Advancing GUI Grounding with Adaptive Exploration Policy Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Pengxiang Li이 [arXiv]에 게시한 'InfiGUI-G1: Advancing GUI Grounding with Adaptive Exploration Policy Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-11 13:13:28+0900","children":"2025년 8월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","GUI Grounding",{"className":"page__taxonomy-item","children":["#","GUI Grounding"]}],["$","span","MLLMs",{"className":"page__taxonomy-item","children":["#","MLLMs"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Exploration Strategy",{"className":"page__taxonomy-item","children":["#","Exploration Strategy"]}],["$","span","Semantic Alignment",{"className":"page__taxonomy-item","children":["#","Semantic Alignment"]}],["$","span","Adaptive Exploration Reward",{"className":"page__taxonomy-item","children":["#","Adaptive Exploration Reward"]}],["$","span","Human-Computer Interaction",{"className":"page__taxonomy-item","children":["#","Human-Computer Interaction"]}]]}]]}]]}],["$","article","2025-8-11-GLM-4-5-Agentic-Reasoning-and-Coding-ARC-Foundation-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-11-GLM-4-5-Agentic-Reasoning-and-Coding-ARC-Foundation-Models/","children":"[논문리뷰] GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"GLM-4. 5 Team이 [arXiv]에 게시한 'GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-11 13:13:28+0900","children":"2025년 8월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Model",{"className":"page__taxonomy-item","children":["#","Large Language Model"]}],["$","span","Mixture-of-Experts",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Foundation Model",{"className":"page__taxonomy-item","children":["#","Foundation Model"]}]]}]]}]]}],["$","article","2025-8-11-GENIE-Gaussian-Encoding-for-Neural-Radiance-Fields-Interactive-Editing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-11-GENIE-Gaussian-Encoding-for-Neural-Radiance-Fields-Interactive-Editing/","children":"[논문리뷰] GENIE: Gaussian Encoding for Neural Radiance Fields Interactive Editing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Przemysław Spurek이 [arXiv]에 게시한 'GENIE: Gaussian Encoding for Neural Radiance Fields Interactive Editing' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-11 13:13:28+0900","children":"2025년 8월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Neural Radiance Fields (NeRF)",{"className":"page__taxonomy-item","children":["#","Neural Radiance Fields (NeRF)"]}],["$","span","Gaussian Splatting (GS)",{"className":"page__taxonomy-item","children":["#","Gaussian Splatting (GS)"]}],["$","span","Interactive Editing",{"className":"page__taxonomy-item","children":["#","Interactive Editing"]}],["$","span","3D Scene Representation",{"className":"page__taxonomy-item","children":["#","3D Scene Representation"]}],["$","span","Physics Simulation",{"className":"page__taxonomy-item","children":["#","Physics Simulation"]}],["$","span","Hybrid Model",{"className":"page__taxonomy-item","children":["#","Hybrid Model"]}],["$","span","Real-time Rendering",{"className":"page__taxonomy-item","children":["#","Real-time Rendering"]}],["$","span","Ray Tracing",{"className":"page__taxonomy-item","children":["#","Ray Tracing"]}]]}]]}]]}],["$","article","2025-8-11-Adapting-Vision-Language-Models-Without-Labels-A-Comprehensive-Survey",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-11-Adapting-Vision-Language-Models-Without-Labels-A-Comprehensive-Survey/","children":"[논문리뷰] Adapting Vision-Language Models Without Labels: A Comprehensive Survey"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Eleni Chatzi이 [arXiv]에 게시한 'Adapting Vision-Language Models Without Labels: A Comprehensive Survey' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-11 13:13:28+0900","children":"2025년 8월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision-Language Models (VLMs)"]}],["$","span","Unsupervised Adaptation",{"className":"page__taxonomy-item","children":["#","Unsupervised Adaptation"]}],["$","span","Test-Time Adaptation (TTA)",{"className":"page__taxonomy-item","children":["#","Test-Time Adaptation (TTA)"]}],["$","span","Domain Transfer",{"className":"page__taxonomy-item","children":["#","Domain Transfer"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Label-Free Learning",{"className":"page__taxonomy-item","children":["#","Label-Free Learning"]}],["$","span","Zero-Shot Learning",{"className":"page__taxonomy-item","children":["#","Zero-Shot Learning"]}]]}]]}]]}],["$","article","2025-8-8-Visual-Document-Understanding-and-Question-Answering-A-Multi-Agent-Collaboration-Framework-with-Test-Time-Scaling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-Visual-Document-Understanding-and-Question-Answering-A-Multi-Agent-Collaboration-Framework-with-Test-Time-Scaling/","children":"[논문리뷰] Visual Document Understanding and Question Answering: A Multi-Agent Collaboration Framework with Test-Time Scaling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ruolin Shen이 [arXiv]에 게시한 'Visual Document Understanding and Question Answering: A Multi-Agent Collaboration Framework with Test-Time Scaling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Visual Document Understanding",{"className":"page__taxonomy-item","children":["#","Visual Document Understanding"]}],["$","span","Visual Question Answering",{"className":"page__taxonomy-item","children":["#","Visual Question Answering"]}],["$","span","Multi-Agent System",{"className":"page__taxonomy-item","children":["#","Multi-Agent System"]}],["$","span","Test-Time Scaling",{"className":"page__taxonomy-item","children":["#","Test-Time Scaling"]}],["$","span","Self-Correction",{"className":"page__taxonomy-item","children":["#","Self-Correction"]}],["$","span","Mixed Reward Modeling",{"className":"page__taxonomy-item","children":["#","Mixed Reward Modeling"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}]]}]]}]]}],["$","article","2025-8-8-StrandDesigner-Towards-Practical-Strand-Generation-with-Sketch-Guidance",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-StrandDesigner-Towards-Practical-Strand-Generation-with-Sketch-Guidance/","children":"[논문리뷰] StrandDesigner: Towards Practical Strand Generation with Sketch Guidance"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiaobin Hu이 [arXiv]에 게시한 'StrandDesigner: Towards Practical Strand Generation with Sketch Guidance' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Strand Generation",{"className":"page__taxonomy-item","children":["#","Strand Generation"]}],["$","span","Sketch Guidance",{"className":"page__taxonomy-item","children":["#","Sketch Guidance"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Multi-scale Learning",{"className":"page__taxonomy-item","children":["#","Multi-scale Learning"]}],["$","span","Adaptive Conditioning",{"className":"page__taxonomy-item","children":["#","Adaptive Conditioning"]}],["$","span","3D Hair Modeling",{"className":"page__taxonomy-item","children":["#","3D Hair Modeling"]}],["$","span","Computer Graphics",{"className":"page__taxonomy-item","children":["#","Computer Graphics"]}]]}]]}]]}],["$","article","2025-8-8-Steering-One-Step-Diffusion-Model-with-Fidelity-Rich-Decoder-for-Fast-Image-Compression",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-Steering-One-Step-Diffusion-Model-with-Fidelity-Rich-Decoder-for-Fast-Image-Compression/","children":"[논문리뷰] Steering One-Step Diffusion Model with Fidelity-Rich Decoder for Fast Image Compression"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yifei Ji이 [arXiv]에 게시한 'Steering One-Step Diffusion Model with Fidelity-Rich Decoder for Fast Image Compression' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Compression",{"className":"page__taxonomy-item","children":["#","Image Compression"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","One-Step Decoding",{"className":"page__taxonomy-item","children":["#","One-Step Decoding"]}],["$","span","Fidelity Guidance",{"className":"page__taxonomy-item","children":["#","Fidelity Guidance"]}],["$","span","Rate Annealing",{"className":"page__taxonomy-item","children":["#","Rate Annealing"]}],["$","span","VAE",{"className":"page__taxonomy-item","children":["#","VAE"]}],["$","span","Perceptual Quality",{"className":"page__taxonomy-item","children":["#","Perceptual Quality"]}]]}]]}]]}],["$","article","2025-8-8-RPCANet-Deep-Interpretable-Robust-PCA-for-Sparse-Object-Segmentation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-RPCANet-Deep-Interpretable-Robust-PCA-for-Sparse-Object-Segmentation/","children":"[논문리뷰] RPCANet++: Deep Interpretable Robust PCA for Sparse Object Segmentation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jian Yang이 [arXiv]에 게시한 'RPCANet++: Deep Interpretable Robust PCA for Sparse Object Segmentation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Robust PCA",{"className":"page__taxonomy-item","children":["#","Robust PCA"]}],["$","span","Deep Unfolding",{"className":"page__taxonomy-item","children":["#","Deep Unfolding"]}],["$","span","Sparse Segmentation",{"className":"page__taxonomy-item","children":["#","Sparse Segmentation"]}],["$","span","Interpretability",{"className":"page__taxonomy-item","children":["#","Interpretability"]}],["$","span","Image Decomposition",{"className":"page__taxonomy-item","children":["#","Image Decomposition"]}],["$","span","Computer Vision",{"className":"page__taxonomy-item","children":["#","Computer Vision"]}]]}]]}]]}],["$","article","2025-8-8-REINA-Regularized-Entropy-Information-Based-Loss-for-Efficient-Simultaneous-Speech-Translation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-REINA-Regularized-Entropy-Information-Based-Loss-for-Efficient-Simultaneous-Speech-Translation/","children":"[논문리뷰] REINA: Regularized Entropy Information-Based Loss for Efficient Simultaneous Speech Translation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiao Yu이 [arXiv]에 게시한 'REINA: Regularized Entropy Information-Based Loss for Efficient Simultaneous Speech Translation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Simultaneous Speech Translation",{"className":"page__taxonomy-item","children":["#","Simultaneous Speech Translation"]}],["$","span","Adaptive Policy",{"className":"page__taxonomy-item","children":["#","Adaptive Policy"]}],["$","span","Entropy-based Loss",{"className":"page__taxonomy-item","children":["#","Entropy-based Loss"]}],["$","span","Mutual Information",{"className":"page__taxonomy-item","children":["#","Mutual Information"]}],["$","span","Latency-Quality Trade-off",{"className":"page__taxonomy-item","children":["#","Latency-Quality Trade-off"]}],["$","span","Speech-to-Text Translation",{"className":"page__taxonomy-item","children":["#","Speech-to-Text Translation"]}],["$","span","REINA",{"className":"page__taxonomy-item","children":["#","REINA"]}]]}]]}]]}],["$","article","2025-8-8-R-Zero-Self-Evolving-Reasoning-LLM-from-Zero-Data",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-R-Zero-Self-Evolving-Reasoning-LLM-from-Zero-Data/","children":"[논문리뷰] R-Zero: Self-Evolving Reasoning LLM from Zero Data"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zongxia Li이 [arXiv]에 게시한 'R-Zero: Self-Evolving Reasoning LLM from Zero Data' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Self-Evolving LLM",{"className":"page__taxonomy-item","children":["#","Self-Evolving LLM"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Self-Play",{"className":"page__taxonomy-item","children":["#","Self-Play"]}],["$","span","Zero-Data Training",{"className":"page__taxonomy-item","children":["#","Zero-Data Training"]}]]}]]}]]}],["$","article","2025-8-8-PRvL-Quantifying-the-Capabilities-and-Risks-of-Large-Language-Models-for-PII-Redaction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-PRvL-Quantifying-the-Capabilities-and-Risks-of-Large-Language-Models-for-PII-Redaction/","children":"[논문리뷰] PRvL: Quantifying the Capabilities and Risks of Large Language Models for PII Redaction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Prajit Das이 [arXiv]에 게시한 'PRvL: Quantifying the Capabilities and Risks of Large Language Models for PII Redaction' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","PII Redaction",{"className":"page__taxonomy-item","children":["#","PII Redaction"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","Privacy Preservation",{"className":"page__taxonomy-item","children":["#","Privacy Preservation"]}],["$","span","Model Evaluation",{"className":"page__taxonomy-item","children":["#","Model Evaluation"]}],["$","span","Cross-Domain Generalization",{"className":"page__taxonomy-item","children":["#","Cross-Domain Generalization"]}],["$","span","Open-Source LLMs",{"className":"page__taxonomy-item","children":["#","Open-Source LLMs"]}]]}]]}]]}],["$","article","2025-8-8-On-the-Generalization-of-SFT-A-Reinforcement-Learning-Perspective-with-Reward-Rectification",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-On-the-Generalization-of-SFT-A-Reinforcement-Learning-Perspective-with-Reward-Rectification/","children":"[논문리뷰] On the Generalization of SFT: A Reinforcement Learning Perspective with Reward Rectification"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xinyu Ye이 [arXiv]에 게시한 'On the Generalization of SFT: A Reinforcement Learning Perspective with Reward Rectification' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Supervised Fine-Tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning (SFT)"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Reward Rectification",{"className":"page__taxonomy-item","children":["#","Reward Rectification"]}],["$","span","Dynamic Fine-Tuning (DFT)",{"className":"page__taxonomy-item","children":["#","Dynamic Fine-Tuning (DFT)"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Policy Gradient",{"className":"page__taxonomy-item","children":["#","Policy Gradient"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}]]}]]}]]}],["$","article","2025-8-8-Marco-Voice-Technical-Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-Marco-Voice-Technical-Report/","children":"[논문리뷰] Marco-Voice Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Qingjuan Li이 [arXiv]에 게시한 'Marco-Voice Technical Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Speech Synthesis",{"className":"page__taxonomy-item","children":["#","Speech Synthesis"]}],["$","span","Voice Cloning",{"className":"page__taxonomy-item","children":["#","Voice Cloning"]}],["$","span","Emotion Control",{"className":"page__taxonomy-item","children":["#","Emotion Control"]}],["$","span","Text-to-Speech",{"className":"page__taxonomy-item","children":["#","Text-to-Speech"]}],["$","span","Disentanglement",{"className":"page__taxonomy-item","children":["#","Disentanglement"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Emotional Speech Dataset",{"className":"page__taxonomy-item","children":["#","Emotional Speech Dataset"]}]]}]]}]]}],["$","article","2025-8-8-MOSEv2-A-More-Challenging-Dataset-for-Video-Object-Segmentation-in-Complex-Scenes",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-MOSEv2-A-More-Challenging-Dataset-for-Video-Object-Segmentation-in-Complex-Scenes/","children":"[논문리뷰] MOSEv2: A More Challenging Dataset for Video Object Segmentation in Complex Scenes"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xudong Jiang이 [arXiv]에 게시한 'MOSEv2: A More Challenging Dataset for Video Object Segmentation in Complex Scenes' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Object Segmentation",{"className":"page__taxonomy-item","children":["#","Video Object Segmentation"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}],["$","span","Complex Scenes",{"className":"page__taxonomy-item","children":["#","Complex Scenes"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Object Tracking",{"className":"page__taxonomy-item","children":["#","Object Tracking"]}],["$","span","Computer Vision",{"className":"page__taxonomy-item","children":["#","Computer Vision"]}],["$","span","Dataset Challenges",{"className":"page__taxonomy-item","children":["#","Dataset Challenges"]}]]}]]}]]}],["$","article","2025-8-8-InfiAlign-A-Scalable-and-Sample-Efficient-Framework-for-Aligning-LLMs-to-Enhance-Reasoning-Capabilities",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-InfiAlign-A-Scalable-and-Sample-Efficient-Framework-for-Aligning-LLMs-to-Enhance-Reasoning-Capabilities/","children":"[논문리뷰] InfiAlign: A Scalable and Sample-Efficient Framework for Aligning LLMs to Enhance Reasoning Capabilities"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhijie Sang이 [arXiv]에 게시한 'InfiAlign: A Scalable and Sample-Efficient Framework for Aligning LLMs to Enhance Reasoning Capabilities' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Alignment",{"className":"page__taxonomy-item","children":["#","LLM Alignment"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Supervised Fine-tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning (SFT)"]}],["$","span","Direct Preference Optimization (DPO)",{"className":"page__taxonomy-item","children":["#","Direct Preference Optimization (DPO)"]}],["$","span","Sample Efficiency",{"className":"page__taxonomy-item","children":["#","Sample Efficiency"]}],["$","span","Scalability",{"className":"page__taxonomy-item","children":["#","Scalability"]}],["$","span","Multi-dimensional Filtering",{"className":"page__taxonomy-item","children":["#","Multi-dimensional Filtering"]}]]}]]}]]}],["$","article","2025-8-8-I2CR-Intra-and-Inter-modal-Collaborative-Reflections-for-Multimodal-Entity-Linking",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-I2CR-Intra-and-Inter-modal-Collaborative-Reflections-for-Multimodal-Entity-Linking/","children":"[논문리뷰] I2CR: Intra- and Inter-modal Collaborative Reflections for Multimodal Entity Linking"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chao Wang이 [arXiv]에 게시한 'I2CR: Intra- and Inter-modal Collaborative Reflections for Multimodal Entity Linking' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Entity Linking",{"className":"page__taxonomy-item","children":["#","Multimodal Entity Linking"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Collaborative Reflection",{"className":"page__taxonomy-item","children":["#","Collaborative Reflection"]}],["$","span","Iterative Reasoning",{"className":"page__taxonomy-item","children":["#","Iterative Reasoning"]}],["$","span","Visual Information",{"className":"page__taxonomy-item","children":["#","Visual Information"]}],["$","span","Text-centric",{"className":"page__taxonomy-item","children":["#","Text-centric"]}]]}]]}]]}],["$","article","2025-8-8-I-Think-Therefore-I-Am-Under-Qualified-A-Benchmark-for-Evaluating-Linguistic-Shibboleth-Detection-in-LLM-Hiring-Evaluations",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-I-Think-Therefore-I-Am-Under-Qualified-A-Benchmark-for-Evaluating-Linguistic-Shibboleth-Detection-in-LLM-Hiring-Evaluations/","children":"[논문리뷰] I Think, Therefore I Am Under-Qualified? A Benchmark for Evaluating Linguistic Shibboleth Detection in LLM Hiring Evaluations"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chirag Shah이 [arXiv]에 게시한 'I Think, Therefore I Am Under-Qualified? A Benchmark for Evaluating Linguistic Shibboleth Detection in LLM Hiring Evaluations' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Bias",{"className":"page__taxonomy-item","children":["#","LLM Bias"]}],["$","span","Hiring Evaluation",{"className":"page__taxonomy-item","children":["#","Hiring Evaluation"]}],["$","span","Linguistic Shibboleth",{"className":"page__taxonomy-item","children":["#","Linguistic Shibboleth"]}],["$","span","Hedging Language",{"className":"page__taxonomy-item","children":["#","Hedging Language"]}],["$","span","Fairness",{"className":"page__taxonomy-item","children":["#","Fairness"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Sociolinguistics",{"className":"page__taxonomy-item","children":["#","Sociolinguistics"]}]]}]]}]]}],["$","article","2025-8-8-Hop-Skip-and-Overthink-Diagnosing-Why-Reasoning-Models-Fumble-during-Multi-Hop-Analysis",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-Hop-Skip-and-Overthink-Diagnosing-Why-Reasoning-Models-Fumble-during-Multi-Hop-Analysis/","children":"[논문리뷰] Hop, Skip, and Overthink: Diagnosing Why Reasoning Models Fumble during Multi-Hop Analysis"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Reshmi Ghosh이 [arXiv]에 게시한 'Hop, Skip, and Overthink: Diagnosing Why Reasoning Models Fumble during Multi-Hop Analysis' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-hop Question Answering",{"className":"page__taxonomy-item","children":["#","Multi-hop Question Answering"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reasoning Errors",{"className":"page__taxonomy-item","children":["#","Reasoning Errors"]}],["$","span","Error Taxonomy",{"className":"page__taxonomy-item","children":["#","Error Taxonomy"]}],["$","span","Human Evaluation",{"className":"page__taxonomy-item","children":["#","Human Evaluation"]}],["$","span","Automated Evaluation",{"className":"page__taxonomy-item","children":["#","Automated Evaluation"]}],["$","span","Overthinking",{"className":"page__taxonomy-item","children":["#","Overthinking"]}]]}]]}]]}],["$","article","2025-8-8-Hi3DEval-Advancing-3D-Generation-Evaluation-with-Hierarchical-Validity",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-Hi3DEval-Advancing-3D-Generation-Evaluation-with-Hierarchical-Validity/","children":"[논문리뷰] Hi3DEval: Advancing 3D Generation Evaluation with Hierarchical Validity"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhibing Li이 [arXiv]에 게시한 'Hi3DEval: Advancing 3D Generation Evaluation with Hierarchical Validity' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Generation Evaluation",{"className":"page__taxonomy-item","children":["#","3D Generation Evaluation"]}],["$","span","Hierarchical Evaluation",{"className":"page__taxonomy-item","children":["#","Hierarchical Evaluation"]}],["$","span","Material Properties",{"className":"page__taxonomy-item","children":["#","Material Properties"]}],["$","span","Multi-Agent Annotation",{"className":"page__taxonomy-item","children":["#","Multi-Agent Annotation"]}],["$","span","Hybrid Scoring System",{"className":"page__taxonomy-item","children":["#","Hybrid Scoring System"]}],["$","span","Video-based Evaluation",{"className":"page__taxonomy-item","children":["#","Video-based Evaluation"]}],["$","span","Part-level Analysis",{"className":"page__taxonomy-item","children":["#","Part-level Analysis"]}]]}]]}]]}],["$","article","2025-8-8-Genie-Envisioner-A-Unified-World-Foundation-Platform-for-Robotic-Manipulation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-Genie-Envisioner-A-Unified-World-Foundation-Platform-for-Robotic-Manipulation/","children":"[논문리뷰] Genie Envisioner: A Unified World Foundation Platform for Robotic Manipulation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shengcong Chen이 [arXiv]에 게시한 'Genie Envisioner: A Unified World Foundation Platform for Robotic Manipulation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Robotic Manipulation",{"className":"page__taxonomy-item","children":["#","Robotic Manipulation"]}],["$","span","World Model",{"className":"page__taxonomy-item","children":["#","World Model"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Diffusion Model",{"className":"page__taxonomy-item","children":["#","Diffusion Model"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Foundation Model",{"className":"page__taxonomy-item","children":["#","Foundation Model"]}],["$","span","Robotics Simulation",{"className":"page__taxonomy-item","children":["#","Robotics Simulation"]}],["$","span","Policy Learning",{"className":"page__taxonomy-item","children":["#","Policy Learning"]}]]}]]}]]}],["$","article","2025-8-8-Evaluating-Synthesizing-and-Enhancing-for-Customer-Support-Conversation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-Evaluating-Synthesizing-and-Enhancing-for-Customer-Support-Conversation/","children":"[논문리뷰] Evaluating, Synthesizing, and Enhancing for Customer Support Conversation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Feng Chen이 [arXiv]에 게시한 'Evaluating, Synthesizing, and Enhancing for Customer Support Conversation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Customer Support",{"className":"page__taxonomy-item","children":["#","Customer Support"]}],["$","span","Dialogue Generation",{"className":"page__taxonomy-item","children":["#","Dialogue Generation"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Role-Playing",{"className":"page__taxonomy-item","children":["#","Role-Playing"]}],["$","span","COPC Framework",{"className":"page__taxonomy-item","children":["#","COPC Framework"]}],["$","span","Synthetic Data",{"className":"page__taxonomy-item","children":["#","Synthetic Data"]}],["$","span","Strategy Prediction",{"className":"page__taxonomy-item","children":["#","Strategy Prediction"]}],["$","span","Empathetic AI",{"className":"page__taxonomy-item","children":["#","Empathetic AI"]}]]}]]}]]}],["$","article","2025-8-8-Dont-Overthink-It-A-Survey-of-Efficient-R1-style-Large-Reasoning-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-Dont-Overthink-It-A-Survey-of-Efficient-R1-style-Large-Reasoning-Models/","children":"[논문리뷰] Don't Overthink It: A Survey of Efficient R1-style Large Reasoning Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Fangzhou Yao이 [arXiv]에 게시한 'Don't Overthink It: A Survey of Efficient R1-style Large Reasoning Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Reasoning Models",{"className":"page__taxonomy-item","children":["#","Large Reasoning Models"]}],["$","span","Efficient Reasoning",{"className":"page__taxonomy-item","children":["#","Efficient Reasoning"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Model Optimization",{"className":"page__taxonomy-item","children":["#","Model Optimization"]}],["$","span","Model Collaboration",{"className":"page__taxonomy-item","children":["#","Model Collaboration"]}],["$","span","Overthinking Problem",{"className":"page__taxonomy-item","children":["#","Overthinking Problem"]}],["$","span","LLM Efficiency",{"className":"page__taxonomy-item","children":["#","LLM Efficiency"]}]]}]]}]]}],["$","article","2025-8-8-DeepPHY-Benchmarking-Agentic-VLMs-on-Physical-Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-DeepPHY-Benchmarking-Agentic-VLMs-on-Physical-Reasoning/","children":"[논문리뷰] DeepPHY: Benchmarking Agentic VLMs on Physical Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ziming Wang이 [arXiv]에 게시한 'DeepPHY: Benchmarking Agentic VLMs on Physical Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision Language Models (VLMs)"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Physical Reasoning",{"className":"page__taxonomy-item","children":["#","Physical Reasoning"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Simulation Environments",{"className":"page__taxonomy-item","children":["#","Simulation Environments"]}],["$","span","Action Planning",{"className":"page__taxonomy-item","children":["#","Action Planning"]}],["$","span","Interactive AI",{"className":"page__taxonomy-item","children":["#","Interactive AI"]}]]}]]}]]}],["$","article","2025-8-8-CoAct-1-Computer-using-Agents-with-Coding-as-Actions",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-CoAct-1-Computer-using-Agents-with-Coding-as-Actions/","children":"[논문리뷰] CoAct-1: Computer-using Agents with Coding as Actions"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Taiwei Shi이 [arXiv]에 게시한 'CoAct-1: Computer-using Agents with Coding as Actions' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Agent",{"className":"page__taxonomy-item","children":["#","AI Agent"]}],["$","span","Multi-agent System",{"className":"page__taxonomy-item","children":["#","Multi-agent System"]}],["$","span","GUI Automation",{"className":"page__taxonomy-item","children":["#","GUI Automation"]}],["$","span","Programmatic Control",{"className":"page__taxonomy-item","children":["#","Programmatic Control"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","OSWorld Benchmark",{"className":"page__taxonomy-item","children":["#","OSWorld Benchmark"]}],["$","span","Hybrid AI",{"className":"page__taxonomy-item","children":["#","Hybrid AI"]}]]}]]}]]}],["$","article","2025-8-8-Can-Large-Multimodal-Models-Actively-Recognize-Faulty-Inputs-A-Systematic-Evaluation-Framework-of-Their-Input-Scrutiny-Ability",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-Can-Large-Multimodal-Models-Actively-Recognize-Faulty-Inputs-A-Systematic-Evaluation-Framework-of-Their-Input-Scrutiny-Ability/","children":"[논문리뷰] Can Large Multimodal Models Actively Recognize Faulty Inputs? A Systematic Evaluation Framework of Their Input Scrutiny Ability"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuan Wu이 [arXiv]에 게시한 'Can Large Multimodal Models Actively Recognize Faulty Inputs? A Systematic Evaluation Framework of Their Input Scrutiny Ability' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Multimodal Models",{"className":"page__taxonomy-item","children":["#","Large Multimodal Models"]}],["$","span","Input Scrutiny",{"className":"page__taxonomy-item","children":["#","Input Scrutiny"]}],["$","span","Error Detection",{"className":"page__taxonomy-item","children":["#","Error Detection"]}],["$","span","Faulty Inputs",{"className":"page__taxonomy-item","children":["#","Faulty Inputs"]}],["$","span","Evaluation Framework",{"className":"page__taxonomy-item","children":["#","Evaluation Framework"]}],["$","span","Modality Preference",{"className":"page__taxonomy-item","children":["#","Modality Preference"]}],["$","span","Cross-Modal Inconsistency",{"className":"page__taxonomy-item","children":["#","Cross-Modal Inconsistency"]}]]}]]}]]}],["$","article","2025-8-8-Are-We-on-the-Right-Way-for-Assessing-Document-Retrieval-Augmented-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-Are-We-on-the-Right-Way-for-Assessing-Document-Retrieval-Augmented-Generation/","children":"[논문리뷰] Are We on the Right Way for Assessing Document Retrieval-Augmented Generation?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Junjie Yang이 [arXiv]에 게시한 'Are We on the Right Way for Assessing Document Retrieval-Augmented Generation?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Benchmark Evaluation",{"className":"page__taxonomy-item","children":["#","Benchmark Evaluation"]}],["$","span","Document Understanding",{"className":"page__taxonomy-item","children":["#","Document Understanding"]}],["$","span","Multi-hop Reasoning",{"className":"page__taxonomy-item","children":["#","Multi-hop Reasoning"]}],["$","span","Information Retrieval",{"className":"page__taxonomy-item","children":["#","Information Retrieval"]}],["$","span","Evaluation Dataset",{"className":"page__taxonomy-item","children":["#","Evaluation Dataset"]}]]}]]}]]}],["$","article","2025-8-8-Are-Todays-LLMs-Ready-to-Explain-Well-Being-Concepts",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-Are-Todays-LLMs-Ready-to-Explain-Well-Being-Concepts/","children":"[논문리뷰] Are Today's LLMs Ready to Explain Well-Being Concepts?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Huan Liu이 [arXiv]에 게시한 'Are Today's LLMs Ready to Explain Well-Being Concepts?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Well-being Concepts",{"className":"page__taxonomy-item","children":["#","Well-being Concepts"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Principle-Guided Evaluation",{"className":"page__taxonomy-item","children":["#","Principle-Guided Evaluation"]}],["$","span","LLM-as-a-Judge",{"className":"page__taxonomy-item","children":["#","LLM-as-a-Judge"]}],["$","span","Supervised Fine-Tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning (SFT)"]}],["$","span","Direct Preference Optimization (DPO)",{"className":"page__taxonomy-item","children":["#","Direct Preference Optimization (DPO)"]}],["$","span","Explanation Generation",{"className":"page__taxonomy-item","children":["#","Explanation Generation"]}]]}]]}]]}],["$","article","2025-8-7-Web-CogReasoner-Towards-Knowledge-Induced-Cognitive-Reasoning-for-Web-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-Web-CogReasoner-Towards-Knowledge-Induced-Cognitive-Reasoning-for-Web-Agents/","children":"[논문리뷰] Web-CogReasoner: Towards Knowledge-Induced Cognitive Reasoning for Web Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xinyu Yang이 [arXiv]에 게시한 'Web-CogReasoner: Towards Knowledge-Induced Cognitive Reasoning for Web Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Web Agent",{"className":"page__taxonomy-item","children":["#","Web Agent"]}],["$","span","Cognitive Reasoning",{"className":"page__taxonomy-item","children":["#","Cognitive Reasoning"]}],["$","span","Knowledge-Induced",{"className":"page__taxonomy-item","children":["#","Knowledge-Induced"]}],["$","span","Large Multimodal Models (LMMs)",{"className":"page__taxonomy-item","children":["#","Large Multimodal Models (LMMs)"]}],["$","span","Bloom's Taxonomy",{"className":"page__taxonomy-item","children":["#","Bloom's Taxonomy"]}],["$","span","Chain-of-Thought (CoT)",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought (CoT)"]}],["$","span","Web-CogDataset",{"className":"page__taxonomy-item","children":["#","Web-CogDataset"]}],["$","span","Web-CogBench",{"className":"page__taxonomy-item","children":["#","Web-CogBench"]}]]}]]}]]}],["$","article","2025-8-7-Training-Long-Context-Multi-Turn-Software-Engineering-Agents-with-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-Training-Long-Context-Multi-Turn-Software-Engineering-Agents-with-Reinforcement-Learning/","children":"[논문리뷰] Training Long-Context, Multi-Turn Software Engineering Agents with Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Maksim Nekrashevich이 [arXiv]에 게시한 'Training Long-Context, Multi-Turn Software Engineering Agents with Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Software Engineering",{"className":"page__taxonomy-item","children":["#","Software Engineering"]}],["$","span","Multi-Turn Interaction",{"className":"page__taxonomy-item","children":["#","Multi-Turn Interaction"]}],["$","span","Long Context",{"className":"page__taxonomy-item","children":["#","Long Context"]}],["$","span","DAPO",{"className":"page__taxonomy-item","children":["#","DAPO"]}],["$","span","Autonomous Agents",{"className":"page__taxonomy-item","children":["#","Autonomous Agents"]}],["$","span","SWE-BENCH",{"className":"page__taxonomy-item","children":["#","SWE-BENCH"]}]]}]]}]]}],["$","article","2025-8-7-The-Cow-of-Rembrandt-Analyzing-Artistic-Prompt-Interpretation-in-Text-to-Image-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-The-Cow-of-Rembrandt-Analyzing-Artistic-Prompt-Interpretation-in-Text-to-Image-Models/","children":"[논문리뷰] The Cow of Rembrandt - Analyzing Artistic Prompt Interpretation in Text-to-Image Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Elisabetta Rocchetti이 [arXiv]에 게시한 'The Cow of Rembrandt - Analyzing Artistic Prompt Interpretation in Text-to-Image Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Cross-Attention Analysis",{"className":"page__taxonomy-item","children":["#","Cross-Attention Analysis"]}],["$","span","Content-Style Disentanglement",{"className":"page__taxonomy-item","children":["#","Content-Style Disentanglement"]}],["$","span","Artistic Style Transfer",{"className":"page__taxonomy-item","children":["#","Artistic Style Transfer"]}],["$","span","Explainable AI",{"className":"page__taxonomy-item","children":["#","Explainable AI"]}],["$","span","SDXL",{"className":"page__taxonomy-item","children":["#","SDXL"]}]]}]]}]]}],["$","article","2025-8-7-Sotopia-RL-Reward-Design-for-Social-Intelligence",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-Sotopia-RL-Reward-Design-for-Social-Intelligence/","children":"[논문리뷰] Sotopia-RL: Reward Design for Social Intelligence"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Keyang Xuan이 [arXiv]에 게시한 'Sotopia-RL: Reward Design for Social Intelligence' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Social Intelligence",{"className":"page__taxonomy-item","children":["#","Social Intelligence"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Reward Design",{"className":"page__taxonomy-item","children":["#","Reward Design"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Utterance-level Rewards",{"className":"page__taxonomy-item","children":["#","Utterance-level Rewards"]}],["$","span","Multi-dimensional Rewards",{"className":"page__taxonomy-item","children":["#","Multi-dimensional Rewards"]}],["$","span","Partial Observability",{"className":"page__taxonomy-item","children":["#","Partial Observability"]}],["$","span","SOTOPIA",{"className":"page__taxonomy-item","children":["#","SOTOPIA"]}]]}]]}]]}],["$","article","2025-8-7-SonicMaster-Towards-Controllable-All-in-One-Music-Restoration-and-Mastering",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-SonicMaster-Towards-Controllable-All-in-One-Music-Restoration-and-Mastering/","children":"[논문리뷰] SonicMaster: Towards Controllable All-in-One Music Restoration and Mastering"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ambuj Mehrish이 [arXiv]에 게시한 'SonicMaster: Towards Controllable All-in-One Music Restoration and Mastering' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Music Restoration",{"className":"page__taxonomy-item","children":["#","Music Restoration"]}],["$","span","Audio Mastering",{"className":"page__taxonomy-item","children":["#","Audio Mastering"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Text-to-Audio",{"className":"page__taxonomy-item","children":["#","Text-to-Audio"]}],["$","span","Audio Quality Enhancement",{"className":"page__taxonomy-item","children":["#","Audio Quality Enhancement"]}],["$","span","Multi-task Learning",{"className":"page__taxonomy-item","children":["#","Multi-task Learning"]}],["$","span","Dataset Creation",{"className":"page__taxonomy-item","children":["#","Dataset Creation"]}]]}]]}]]}],["$","article","2025-8-7-Sel3DCraft-Interactive-Visual-Prompts-for-User-Friendly-Text-to-3D-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-Sel3DCraft-Interactive-Visual-Prompts-for-User-Friendly-Text-to-3D-Generation/","children":"[논문리뷰] Sel3DCraft: Interactive Visual Prompts for User-Friendly Text-to-3D Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hao Huang이 [arXiv]에 게시한 'Sel3DCraft: Interactive Visual Prompts for User-Friendly Text-to-3D Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-3D Generation",{"className":"page__taxonomy-item","children":["#","Text-to-3D Generation"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","Visual Analytics",{"className":"page__taxonomy-item","children":["#","Visual Analytics"]}],["$","span","Human-Computer Interaction",{"className":"page__taxonomy-item","children":["#","Human-Computer Interaction"]}],["$","span","Multi-modal Large Language Models",{"className":"page__taxonomy-item","children":["#","Multi-modal Large Language Models"]}],["$","span","3D Model Evaluation",{"className":"page__taxonomy-item","children":["#","3D Model Evaluation"]}]]}]]}]]}],["$","article","2025-8-7-Sculptor-Empowering-LLMs-with-Cognitive-Agency-via-Active-Context-Management",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-Sculptor-Empowering-LLMs-with-Cognitive-Agency-via-Active-Context-Management/","children":"[논문리뷰] Sculptor: Empowering LLMs with Cognitive Agency via Active Context Management"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yunxin Liu이 [arXiv]에 게시한 'Sculptor: Empowering LLMs with Cognitive Agency via Active Context Management' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Active Context Management",{"className":"page__taxonomy-item","children":["#","Active Context Management"]}],["$","span","Proactive Interference",{"className":"page__taxonomy-item","children":["#","Proactive Interference"]}],["$","span","Tool Augmentation",{"className":"page__taxonomy-item","children":["#","Tool Augmentation"]}],["$","span","Working Memory",{"className":"page__taxonomy-item","children":["#","Working Memory"]}],["$","span","Context Curation",{"className":"page__taxonomy-item","children":["#","Context Curation"]}],["$","span","Long Context",{"className":"page__taxonomy-item","children":["#","Long Context"]}]]}]]}]]}],["$","article","2025-8-7-SEAgent-Self-Evolving-Computer-Use-Agent-with-Autonomous-Learning-from-Experience",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-SEAgent-Self-Evolving-Computer-Use-Agent-with-Autonomous-Learning-from-Experience/","children":"[논문리뷰] SEAgent: Self-Evolving Computer Use Agent with Autonomous Learning from Experience"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiaoyi Dong이 [arXiv]에 게시한 'SEAgent: Self-Evolving Computer Use Agent with Autonomous Learning from Experience' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Computer Use Agent",{"className":"page__taxonomy-item","children":["#","Computer Use Agent"]}],["$","span","Self-Evolving",{"className":"page__taxonomy-item","children":["#","Self-Evolving"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Experiential Learning",{"className":"page__taxonomy-item","children":["#","Experiential Learning"]}],["$","span","Specialist-to-Generalist",{"className":"page__taxonomy-item","children":["#","Specialist-to-Generalist"]}]]}]]}]]}],["$","article","2025-8-7-Reasoning-Language-Models-for-Root-Cause-Analysis-in-5G-Wireless-Networks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-Reasoning-Language-Models-for-Root-Cause-Analysis-in-5G-Wireless-Networks/","children":"[논문리뷰] Reasoning Language Models for Root Cause Analysis in 5G Wireless Networks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Haozhe Zhang이 [arXiv]에 게시한 'Reasoning Language Models for Root Cause Analysis in 5G Wireless Networks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Root Cause Analysis",{"className":"page__taxonomy-item","children":["#","Root Cause Analysis"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","5G Wireless Networks",{"className":"page__taxonomy-item","children":["#","5G Wireless Networks"]}],["$","span","Supervised Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","TeleLogs Dataset",{"className":"page__taxonomy-item","children":["#","TeleLogs Dataset"]}]]}]]}]]}],["$","article","2025-8-7-RL-PLUS-Countering-Capability-Boundary-Collapse-of-LLMs-in-Reinforcement-Learning-with-Hybrid-policy-Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-RL-PLUS-Countering-Capability-Boundary-Collapse-of-LLMs-in-Reinforcement-Learning-with-Hybrid-policy-Optimization/","children":"[논문리뷰] RL-PLUS: Countering Capability Boundary Collapse of LLMs in Reinforcement Learning with Hybrid-policy Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kechi Zhang이 [arXiv]에 게시한 'RL-PLUS: Countering Capability Boundary Collapse of LLMs in Reinforcement Learning with Hybrid-policy Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Capability Collapse",{"className":"page__taxonomy-item","children":["#","Capability Collapse"]}],["$","span","Hybrid Policy Optimization",{"className":"page__taxonomy-item","children":["#","Hybrid Policy Optimization"]}],["$","span","Multiple Importance Sampling",{"className":"page__taxonomy-item","children":["#","Multiple Importance Sampling"]}],["$","span","Exploration",{"className":"page__taxonomy-item","children":["#","Exploration"]}],["$","span","Math Reasoning",{"className":"page__taxonomy-item","children":["#","Math Reasoning"]}],["$","span","Out-of-Distribution",{"className":"page__taxonomy-item","children":["#","Out-of-Distribution"]}]]}]]}]]}],["$","article","2025-8-7-Position-The-Current-AI-Conference-Model-is-Unsustainable-Diagnosing-the-Crisis-of-Centralized-AI-Conference",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-Position-The-Current-AI-Conference-Model-is-Unsustainable-Diagnosing-the-Crisis-of-Centralized-AI-Conference/","children":"[논문리뷰] Position: The Current AI Conference Model is Unsustainable! Diagnosing the Crisis of Centralized AI Conference"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiaying Wu이 [arXiv]에 게시한 'Position: The Current AI Conference Model is Unsustainable! Diagnosing the Crisis of Centralized AI Conference' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Conferences",{"className":"page__taxonomy-item","children":["#","AI Conferences"]}],["$","span","Sustainability",{"className":"page__taxonomy-item","children":["#","Sustainability"]}],["$","span","Peer Review",{"className":"page__taxonomy-item","children":["#","Peer Review"]}],["$","span","Community Building",{"className":"page__taxonomy-item","children":["#","Community Building"]}],["$","span","Environmental Impact",{"className":"page__taxonomy-item","children":["#","Environmental Impact"]}],["$","span","Mental Health",{"className":"page__taxonomy-item","children":["#","Mental Health"]}],["$","span","Centralized Model",{"className":"page__taxonomy-item","children":["#","Centralized Model"]}],["$","span","Decentralized Model",{"className":"page__taxonomy-item","children":["#","Decentralized Model"]}]]}]]}]]}],["$","article","2025-8-7-OpenMed-NER-Open-Source-Domain-Adapted-State-of-the-Art-Transformers-for-Biomedical-NER-Across-12-Public-Datasets",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-OpenMed-NER-Open-Source-Domain-Adapted-State-of-the-Art-Transformers-for-Biomedical-NER-Across-12-Public-Datasets/","children":"[논문리뷰] OpenMed NER: Open-Source, Domain-Adapted State-of-the-Art Transformers for Biomedical NER Across 12 Public Datasets"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"MaziyarPanahi이 [arXiv]에 게시한 'OpenMed NER: Open-Source, Domain-Adapted State-of-the-Art Transformers for Biomedical NER Across 12 Public Datasets' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Biomedical NER",{"className":"page__taxonomy-item","children":["#","Biomedical NER"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Domain Adaptation",{"className":"page__taxonomy-item","children":["#","Domain Adaptation"]}],["$","span","LoRA",{"className":"page__taxonomy-item","children":["#","LoRA"]}],["$","span","Open-Source",{"className":"page__taxonomy-item","children":["#","Open-Source"]}],["$","span","Named Entity Recognition",{"className":"page__taxonomy-item","children":["#","Named Entity Recognition"]}],["$","span","Healthcare AI",{"className":"page__taxonomy-item","children":["#","Healthcare AI"]}]]}]]}]]}],["$","article","2025-8-7-MiDashengLM-Efficient-Audio-Understanding-with-General-Audio-Captions",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-MiDashengLM-Efficient-Audio-Understanding-with-General-Audio-Captions/","children":"[논문리뷰] MiDashengLM: Efficient Audio Understanding with General Audio Captions"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yadong Niu이 [arXiv]에 게시한 'MiDashengLM: Efficient Audio Understanding with General Audio Captions' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Audio-Language Model",{"className":"page__taxonomy-item","children":["#","Audio-Language Model"]}],["$","span","General Audio Captions",{"className":"page__taxonomy-item","children":["#","General Audio Captions"]}],["$","span","Audio Understanding",{"className":"page__taxonomy-item","children":["#","Audio Understanding"]}],["$","span","Speech Recognition",{"className":"page__taxonomy-item","children":["#","Speech Recognition"]}],["$","span","Efficient Inference",{"className":"page__taxonomy-item","children":["#","Efficient Inference"]}],["$","span","Public Datasets",{"className":"page__taxonomy-item","children":["#","Public Datasets"]}],["$","span","Multimodality",{"className":"page__taxonomy-item","children":["#","Multimodality"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}]]}]]}]]}],["$","article","2025-8-7-Light-IF-Endowing-LLMs-with-Generalizable-Reasoning-via-Preview-and-Self-Checking-for-Complex-Instruction-Following",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-Light-IF-Endowing-LLMs-with-Generalizable-Reasoning-via-Preview-and-Self-Checking-for-Complex-Instruction-Following/","children":"[논문리뷰] Light-IF: Endowing LLMs with Generalizable Reasoning via Preview and Self-Checking for Complex Instruction Following"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Liang Xu이 [arXiv]에 게시한 'Light-IF: Endowing LLMs with Generalizable Reasoning via Preview and Self-Checking for Complex Instruction Following' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Entropy Regularization",{"className":"page__taxonomy-item","children":["#","Entropy Regularization"]}],["$","span","Self-Checking",{"className":"page__taxonomy-item","children":["#","Self-Checking"]}],["$","span","Previewing",{"className":"page__taxonomy-item","children":["#","Previewing"]}]]}]]}]]}],["$","article","2025-8-7-LeanK-Learnable-K-Cache-Channel-Pruning-for-Efficient-Decoding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-LeanK-Learnable-K-Cache-Channel-Pruning-for-Efficient-Decoding/","children":"[논문리뷰] LeanK: Learnable K Cache Channel Pruning for Efficient Decoding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuqing Yang이 [arXiv]에 게시한 'LeanK: Learnable K Cache Channel Pruning for Efficient Decoding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","KV Cache Optimization",{"className":"page__taxonomy-item","children":["#","KV Cache Optimization"]}],["$","span","Model Pruning",{"className":"page__taxonomy-item","children":["#","Model Pruning"]}],["$","span","Efficient Decoding",{"className":"page__taxonomy-item","children":["#","Efficient Decoding"]}],["$","span","Memory Optimization",{"className":"page__taxonomy-item","children":["#","Memory Optimization"]}],["$","span","Static Sparsity",{"className":"page__taxonomy-item","children":["#","Static Sparsity"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}]]}]]}]]}],["$","article","2025-8-7-LaTCoder-Converting-Webpage-Design-to-Code-with-Layout-as-Thought",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-LaTCoder-Converting-Webpage-Design-to-Code-with-Layout-as-Thought/","children":"[논문리뷰] LaTCoder: Converting Webpage Design to Code with Layout-as-Thought"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Tianpeng Lv이 [arXiv]에 게시한 'LaTCoder: Converting Webpage Design to Code with Layout-as-Thought' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Design-to-Code",{"className":"page__taxonomy-item","children":["#","Design-to-Code"]}],["$","span","Webpage Generation",{"className":"page__taxonomy-item","children":["#","Webpage Generation"]}],["$","span","Multimodal Large Language Models (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models (MLLMs)"]}],["$","span","Layout Preservation",{"className":"page__taxonomy-item","children":["#","Layout Preservation"]}],["$","span","Chain-of-Thought (CoT)",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought (CoT)"]}],["$","span","UI Automation",{"className":"page__taxonomy-item","children":["#","UI Automation"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}]]}]]}]]}],["$","article","2025-8-7-Is-Chain-of-Thought-Reasoning-of-LLMs-a-Mirage-A-Data-Distribution-Lens",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-Is-Chain-of-Thought-Reasoning-of-LLMs-a-Mirage-A-Data-Distribution-Lens/","children":"[논문리뷰] Is Chain-of-Thought Reasoning of LLMs a Mirage? A Data Distribution Lens"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhen Tan이 [arXiv]에 게시한 'Is Chain-of-Thought Reasoning of LLMs a Mirage? A Data Distribution Lens' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","OOD Generalization",{"className":"page__taxonomy-item","children":["#","OOD Generalization"]}],["$","span","Data Distribution Shift",{"className":"page__taxonomy-item","children":["#","Data Distribution Shift"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Pattern Matching",{"className":"page__taxonomy-item","children":["#","Pattern Matching"]}],["$","span","DataAlchemy",{"className":"page__taxonomy-item","children":["#","DataAlchemy"]}]]}]]}]]}],["$","article","2025-8-7-IFDECORATOR-Wrapping-Instruction-Following-Reinforcement-Learning-with-Verifiable-Rewards",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-IFDECORATOR-Wrapping-Instruction-Following-Reinforcement-Learning-with-Verifiable-Rewards/","children":"[논문리뷰] IFDECORATOR: Wrapping Instruction Following Reinforcement Learning with Verifiable Rewards"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ling-I Wu이 [arXiv]에 게시한 'IFDECORATOR: Wrapping Instruction Following Reinforcement Learning with Verifiable Rewards' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Reward Hacking",{"className":"page__taxonomy-item","children":["#","Reward Hacking"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Data Flywheel",{"className":"page__taxonomy-item","children":["#","Data Flywheel"]}],["$","span","Verifiable Rewards",{"className":"page__taxonomy-item","children":["#","Verifiable Rewards"]}]]}]]}]]}],["$","article","2025-8-7-IAUNet-Instance-Aware-U-Net",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-IAUNet-Instance-Aware-U-Net/","children":"[논문리뷰] IAUNet: Instance-Aware U-Net"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Dmytro Fishman이 [arXiv]에 게시한 'IAUNet: Instance-Aware U-Net' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Instance Segmentation",{"className":"page__taxonomy-item","children":["#","Instance Segmentation"]}],["$","span","U-Net",{"className":"page__taxonomy-item","children":["#","U-Net"]}],["$","span","Query-based Model",{"className":"page__taxonomy-item","children":["#","Query-based Model"]}],["$","span","Transformer Decoder",{"className":"page__taxonomy-item","children":["#","Transformer Decoder"]}],["$","span","Biomedical Imaging",{"className":"page__taxonomy-item","children":["#","Biomedical Imaging"]}],["$","span","Cell Segmentation",{"className":"page__taxonomy-item","children":["#","Cell Segmentation"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}]]}]]}]]}],["$","article","2025-8-7-HPSv3-Towards-Wide-Spectrum-Human-Preference-Score",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-HPSv3-Towards-Wide-Spectrum-Human-Preference-Score/","children":"[논문리뷰] HPSv3: Towards Wide-Spectrum Human Preference Score"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hongsheng Li이 [arXiv]에 게시한 'HPSv3: Towards Wide-Spectrum Human Preference Score' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Human Preference Score",{"className":"page__taxonomy-item","children":["#","Human Preference Score"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Image Evaluation",{"className":"page__taxonomy-item","children":["#","Image Evaluation"]}],["$","span","Vision-Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision-Language Models (VLMs)"]}],["$","span","Uncertainty-Aware Ranking Loss",{"className":"page__taxonomy-item","children":["#","Uncertainty-Aware Ranking Loss"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}],["$","span","Iterative Refinement",{"className":"page__taxonomy-item","children":["#","Iterative Refinement"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}]]}]]}]]}],["$","article","2025-8-7-Gaussian-Variation-Field-Diffusion-for-High-fidelity-Video-to-4D-Synthesis",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-Gaussian-Variation-Field-Diffusion-for-High-fidelity-Video-to-4D-Synthesis/","children":"[논문리뷰] Gaussian Variation Field Diffusion for High-fidelity Video-to-4D Synthesis"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Feng Zhao이 [arXiv]에 게시한 'Gaussian Variation Field Diffusion for High-fidelity Video-to-4D Synthesis' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","4D Generation",{"className":"page__taxonomy-item","children":["#","4D Generation"]}],["$","span","Video-to-3D Synthesis",{"className":"page__taxonomy-item","children":["#","Video-to-3D Synthesis"]}],["$","span","Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","Gaussian Splatting"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Latent Space Modeling",{"className":"page__taxonomy-item","children":["#","Latent Space Modeling"]}],["$","span","Variational Autoencoder",{"className":"page__taxonomy-item","children":["#","Variational Autoencoder"]}],["$","span","Temporal Coherence",{"className":"page__taxonomy-item","children":["#","Temporal Coherence"]}]]}]]}]]}],["$","article","2025-8-7-Enhancing-Vision-Language-Model-Training-with-Reinforcement-Learning-in-Synthetic-Worlds-for-Real-World-Success",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-Enhancing-Vision-Language-Model-Training-with-Reinforcement-Learning-in-Synthetic-Worlds-for-Real-World-Success/","children":"[논문리뷰] Enhancing Vision-Language Model Training with Reinforcement Learning in Synthetic Worlds for Real-World Success"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ruslan Rakhimov이 [arXiv]에 게시한 'Enhancing Vision-Language Model Training with Reinforcement Learning in Synthetic Worlds for Real-World Success' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Synthetic Worlds",{"className":"page__taxonomy-item","children":["#","Synthetic Worlds"]}],["$","span","Transfer Learning",{"className":"page__taxonomy-item","children":["#","Transfer Learning"]}],["$","span","PPO",{"className":"page__taxonomy-item","children":["#","PPO"]}],["$","span","Actor-Critic",{"className":"page__taxonomy-item","children":["#","Actor-Critic"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}]]}]]}]]}],["$","article","2025-8-7-Efficient-Agents-Building-Effective-Agents-While-Reducing-Cost",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-Efficient-Agents-Building-Effective-Agents-While-Reducing-Cost/","children":"[논문리뷰] Efficient Agents: Building Effective Agents While Reducing Cost"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yue Hou이 [arXiv]에 게시한 'Efficient Agents: Building Effective Agents While Reducing Cost' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Cost Efficiency",{"className":"page__taxonomy-item","children":["#","Cost Efficiency"]}],["$","span","Performance-Cost Trade-off",{"className":"page__taxonomy-item","children":["#","Performance-Cost Trade-off"]}],["$","span","Agent Frameworks",{"className":"page__taxonomy-item","children":["#","Agent Frameworks"]}],["$","span","GAIA Benchmark",{"className":"page__taxonomy-item","children":["#","GAIA Benchmark"]}],["$","span","Optimization",{"className":"page__taxonomy-item","children":["#","Optimization"]}],["$","span","Resource Management",{"className":"page__taxonomy-item","children":["#","Resource Management"]}]]}]]}]]}],["$","article","2025-8-7-EVOC2RUST-A-Skeleton-guided-Framework-for-Project-Level-C-to-Rust-Translation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-EVOC2RUST-A-Skeleton-guided-Framework-for-Project-Level-C-to-Rust-Translation/","children":"[논문리뷰] EVOC2RUST: A Skeleton-guided Framework for Project-Level C-to-Rust Translation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Dong Chen이 [arXiv]에 게시한 'EVOC2RUST: A Skeleton-guided Framework for Project-Level C-to-Rust Translation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","C-to-Rust Conversion",{"className":"page__taxonomy-item","children":["#","C-to-Rust Conversion"]}],["$","span","Project-Level Translation",{"className":"page__taxonomy-item","children":["#","Project-Level Translation"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Code Synthesis",{"className":"page__taxonomy-item","children":["#","Code Synthesis"]}],["$","span","Memory Safety",{"className":"page__taxonomy-item","children":["#","Memory Safety"]}],["$","span","Software Migration",{"className":"page__taxonomy-item","children":["#","Software Migration"]}],["$","span","Hybrid Translation",{"className":"page__taxonomy-item","children":["#","Hybrid Translation"]}]]}]]}]]}],["$","article","2025-8-7-DreamVVT-Mastering-Realistic-Video-Virtual-Try-On-in-the-Wild-via-a-Stage-Wise-Diffusion-Transformer-Framework",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-DreamVVT-Mastering-Realistic-Video-Virtual-Try-On-in-the-Wild-via-a-Stage-Wise-Diffusion-Transformer-Framework/","children":"[논문리뷰] DreamVVT: Mastering Realistic Video Virtual Try-On in the Wild via a Stage-Wise Diffusion Transformer Framework"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chao Liang이 [arXiv]에 게시한 'DreamVVT: Mastering Realistic Video Virtual Try-On in the Wild via a Stage-Wise Diffusion Transformer Framework' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Virtual Try-On",{"className":"page__taxonomy-item","children":["#","Video Virtual Try-On"]}],["$","span","Diffusion Transformers",{"className":"page__taxonomy-item","children":["#","Diffusion Transformers"]}],["$","span","Stage-Wise Framework",{"className":"page__taxonomy-item","children":["#","Stage-Wise Framework"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","LoRA",{"className":"page__taxonomy-item","children":["#","LoRA"]}],["$","span","Temporal Consistency",{"className":"page__taxonomy-item","children":["#","Temporal Consistency"]}],["$","span","Garment Preservation",{"className":"page__taxonomy-item","children":["#","Garment Preservation"]}]]}]]}]]}],["$","article","2025-8-7-CoTox-Chain-of-Thought-Based-Molecular-Toxicity-Reasoning-and-Prediction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-CoTox-Chain-of-Thought-Based-Molecular-Toxicity-Reasoning-and-Prediction/","children":"[논문리뷰] CoTox: Chain-of-Thought-Based Molecular Toxicity Reasoning and Prediction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Donghyeon Lee이 [arXiv]에 게시한 'CoTox: Chain-of-Thought-Based Molecular Toxicity Reasoning and Prediction' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Toxicity Prediction",{"className":"page__taxonomy-item","children":["#","Toxicity Prediction"]}],["$","span","Large Language Model",{"className":"page__taxonomy-item","children":["#","Large Language Model"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Drug Development",{"className":"page__taxonomy-item","children":["#","Drug Development"]}],["$","span","Cheminformatics",{"className":"page__taxonomy-item","children":["#","Cheminformatics"]}],["$","span","Interpretable AI",{"className":"page__taxonomy-item","children":["#","Interpretable AI"]}],["$","span","IUPAC Nomenclature",{"className":"page__taxonomy-item","children":["#","IUPAC Nomenclature"]}]]}]]}]]}],["$","article","2025-8-7-C3D-AD-Toward-Continual-3D-Anomaly-Detection-via-Kernel-Attention-with-Learnable-Advisor",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-C3D-AD-Toward-Continual-3D-Anomaly-Detection-via-Kernel-Attention-with-Learnable-Advisor/","children":"[논문리뷰] C3D-AD: Toward Continual 3D Anomaly Detection via Kernel Attention with Learnable Advisor"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jinbao Wang이 [arXiv]에 게시한 'C3D-AD: Toward Continual 3D Anomaly Detection via Kernel Attention with Learnable Advisor' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Anomaly Detection",{"className":"page__taxonomy-item","children":["#","3D Anomaly Detection"]}],["$","span","Continual Learning",{"className":"page__taxonomy-item","children":["#","Continual Learning"]}],["$","span","Kernel Attention",{"className":"page__taxonomy-item","children":["#","Kernel Attention"]}],["$","span","Learnable Advisor",{"className":"page__taxonomy-item","children":["#","Learnable Advisor"]}],["$","span","Parameter Perturbation",{"className":"page__taxonomy-item","children":["#","Parameter Perturbation"]}],["$","span","Point Cloud",{"className":"page__taxonomy-item","children":["#","Point Cloud"]}],["$","span","Industrial AI",{"className":"page__taxonomy-item","children":["#","Industrial AI"]}]]}]]}]]}],["$","article","2025-8-7-Agent-Lightning-Train-ANY-AI-Agents-with-Reinforcement-Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-Agent-Lightning-Train-ANY-AI-Agents-with-Reinforcement-Learning/","children":"[논문리뷰] Agent Lightning: Train ANY AI Agents with Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zilong Wang이 [arXiv]에 게시한 'Agent Lightning: Train ANY AI Agents with Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","AI Agents",{"className":"page__taxonomy-item","children":["#","AI Agents"]}],["$","span","Framework",{"className":"page__taxonomy-item","children":["#","Framework"]}],["$","span","Markov Decision Process",{"className":"page__taxonomy-item","children":["#","Markov Decision Process"]}],["$","span","Hierarchical RL",{"className":"page__taxonomy-item","children":["#","Hierarchical RL"]}],["$","span","Training-Agent Disaggregation",{"className":"page__taxonomy-item","children":["#","Training-Agent Disaggregation"]}],["$","span","Observability",{"className":"page__taxonomy-item","children":["#","Observability"]}]]}]]}]]}],["$","article","2025-8-7-A-Coarse-to-Fine-Approach-to-Multi-Modality-3D-Occupancy-Grounding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-A-Coarse-to-Fine-Approach-to-Multi-Modality-3D-Occupancy-Grounding/","children":"[논문리뷰] A Coarse-to-Fine Approach to Multi-Modality 3D Occupancy Grounding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jianke Zhu이 [arXiv]에 게시한 'A Coarse-to-Fine Approach to Multi-Modality 3D Occupancy Grounding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Occupancy Grounding",{"className":"page__taxonomy-item","children":["#","3D Occupancy Grounding"]}],["$","span","Multi-modal Learning",{"className":"page__taxonomy-item","children":["#","Multi-modal Learning"]}],["$","span","Natural Language Understanding",{"className":"page__taxonomy-item","children":["#","Natural Language Understanding"]}],["$","span","Autonomous Driving",{"className":"page__taxonomy-item","children":["#","Autonomous Driving"]}],["$","span","Voxel-based Prediction",{"className":"page__taxonomy-item","children":["#","Voxel-based Prediction"]}],["$","span","Benchmark Dataset",{"className":"page__taxonomy-item","children":["#","Benchmark Dataset"]}],["$","span","Coarse-to-Fine",{"className":"page__taxonomy-item","children":["#","Coarse-to-Fine"]}]]}]]}]]}],["$","article","2025-8-6-Tool-integrated-Reinforcement-Learning-for-Repo-Deep-Search",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-6-Tool-integrated-Reinforcement-Learning-for-Repo-Deep-Search/","children":"[논문리뷰] Tool-integrated Reinforcement Learning for Repo Deep Search"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yanzhen Zou이 [arXiv]에 게시한 'Tool-integrated Reinforcement Learning for Repo Deep Search' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-06 13:46:36+0900","children":"2025년 8월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Issue Localization",{"className":"page__taxonomy-item","children":["#","Issue Localization"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Supervised Fine-tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning (SFT)"]}],["$","span","Tool-integrated Agents",{"className":"page__taxonomy-item","children":["#","Tool-integrated Agents"]}],["$","span","Software Engineering",{"className":"page__taxonomy-item","children":["#","Software Engineering"]}],["$","span","Code Search",{"className":"page__taxonomy-item","children":["#","Code Search"]}]]}]]}]]}],["$","article","2025-8-6-TRACEALIGN-Tracing-the-Drift-Attributing-Alignment-Failures-to-Training-Time-Belief-Sources-in-LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-6-TRACEALIGN-Tracing-the-Drift-Attributing-Alignment-Failures-to-Training-Time-Belief-Sources-in-LLMs/","children":"[논문리뷰] TRACEALIGN -- Tracing the Drift: Attributing Alignment Failures to Training-Time Belief Sources in LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Aman Chadha이 [arXiv]에 게시한 'TRACEALIGN -- Tracing the Drift: Attributing Alignment Failures to Training-Time Belief Sources in LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-06 13:46:36+0900","children":"2025년 8월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Alignment",{"className":"page__taxonomy-item","children":["#","LLM Alignment"]}],["$","span","Alignment Drift",{"className":"page__taxonomy-item","children":["#","Alignment Drift"]}],["$","span","Training Data Provenance",{"className":"page__taxonomy-item","children":["#","Training Data Provenance"]}],["$","span","Belief Conflict Index (BCI)",{"className":"page__taxonomy-item","children":["#","Belief Conflict Index (BCI)"]}],["$","span","Suffix Array",{"className":"page__taxonomy-item","children":["#","Suffix Array"]}],["$","span","Safety Interventions",{"className":"page__taxonomy-item","children":["#","Safety Interventions"]}],["$","span","Reinforcement Learning from Human Feedback",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning from Human Feedback"]}],["$","span","Explainable AI",{"className":"page__taxonomy-item","children":["#","Explainable AI"]}]]}]]}]]}],["$","article","2025-8-6-Skywork-UniPic-Unified-Autoregressive-Modeling-for-Visual-Understanding-and-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-6-Skywork-UniPic-Unified-Autoregressive-Modeling-for-Visual-Understanding-and-Generation/","children":"[논문리뷰] Skywork UniPic: Unified Autoregressive Modeling for Visual Understanding and Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Tianyidan Xie이 [arXiv]에 게시한 'Skywork UniPic: Unified Autoregressive Modeling for Visual Understanding and Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-06 13:46:36+0900","children":"2025년 8월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Autoregressive Models",{"className":"page__taxonomy-item","children":["#","Autoregressive Models"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Visual Understanding",{"className":"page__taxonomy-item","children":["#","Visual Understanding"]}],["$","span","Unified Architecture",{"className":"page__taxonomy-item","children":["#","Unified Architecture"]}],["$","span","Parameter Efficiency",{"className":"page__taxonomy-item","children":["#","Parameter Efficiency"]}]]}]]}]]}],["$","article","2025-8-6-Seed-Diffusion-A-Large-Scale-Diffusion-Language-Model-with-High-Speed-Inference",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-6-Seed-Diffusion-A-Large-Scale-Diffusion-Language-Model-with-High-Speed-Inference/","children":"[논문리뷰] Seed Diffusion: A Large-Scale Diffusion Language Model with High-Speed Inference"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Fan Xia이 [arXiv]에 게시한 'Seed Diffusion: A Large-Scale Diffusion Language Model with High-Speed Inference' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-06 13:46:36+0900","children":"2025년 8월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Language Models",{"className":"page__taxonomy-item","children":["#","Language Models"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","Non-Autoregressive Inference",{"className":"page__taxonomy-item","children":["#","Non-Autoregressive Inference"]}],["$","span","High-Speed Inference",{"className":"page__taxonomy-item","children":["#","High-Speed Inference"]}],["$","span","Discrete Diffusion",{"className":"page__taxonomy-item","children":["#","Discrete Diffusion"]}],["$","span","LLM Inference",{"className":"page__taxonomy-item","children":["#","LLM Inference"]}]]}]]}]]}],["$","article","2025-8-6-Multi-human-Interactive-Talking-Dataset",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-6-Multi-human-Interactive-Talking-Dataset/","children":"[논문리뷰] Multi-human Interactive Talking Dataset"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Mike Zheng Shou이 [arXiv]에 게시한 'Multi-human Interactive Talking Dataset' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-06 13:46:36+0900","children":"2025년 8월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-human Video Generation",{"className":"page__taxonomy-item","children":["#","Multi-human Video Generation"]}],["$","span","Interactive Talking",{"className":"page__taxonomy-item","children":["#","Interactive Talking"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}],["$","span","Audio-driven Animation",{"className":"page__taxonomy-item","children":["#","Audio-driven Animation"]}],["$","span","Pose Control",{"className":"page__taxonomy-item","children":["#","Pose Control"]}],["$","span","Speech Interaction",{"className":"page__taxonomy-item","children":["#","Speech Interaction"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}]]}]]}]]}],["$","article","2025-8-6-LongVie-Multimodal-Guided-Controllable-Ultra-Long-Video-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-6-LongVie-Multimodal-Guided-Controllable-Ultra-Long-Video-Generation/","children":"[논문리뷰] LongVie: Multimodal-Guided Controllable Ultra-Long Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chenyang Si이 [arXiv]에 게시한 'LongVie: Multimodal-Guided Controllable Ultra-Long Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-06 13:46:36+0900","children":"2025년 8월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Ultra-long Video Generation",{"className":"page__taxonomy-item","children":["#","Ultra-long Video Generation"]}],["$","span","Multimodal Guidance",{"className":"page__taxonomy-item","children":["#","Multimodal Guidance"]}],["$","span","Controllable Video Generation",{"className":"page__taxonomy-item","children":["#","Controllable Video Generation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Temporal Consistency",{"className":"page__taxonomy-item","children":["#","Temporal Consistency"]}],["$","span","Visual Quality",{"className":"page__taxonomy-item","children":["#","Visual Quality"]}],["$","span","Autoregressive Generation",{"className":"page__taxonomy-item","children":["#","Autoregressive Generation"]}],["$","span","Degradation-aware Training",{"className":"page__taxonomy-item","children":["#","Degradation-aware Training"]}]]}]]}]]}],["$","article","2025-8-6-LiveMCPBench-Can-Agents-Navigate-an-Ocean-of-MCP-Tools",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-6-LiveMCPBench-Can-Agents-Navigate-an-Ocean-of-MCP-Tools/","children":"[논문리뷰] LiveMCPBench: Can Agents Navigate an Ocean of MCP Tools?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yaojie Lu이 [arXiv]에 게시한 'LiveMCPBench: Can Agents Navigate an Ocean of MCP Tools?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-06 13:46:36+0900","children":"2025년 8월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agent",{"className":"page__taxonomy-item","children":["#","LLM Agent"]}],["$","span","Tool-use",{"className":"page__taxonomy-item","children":["#","Tool-use"]}],["$","span","MCP",{"className":"page__taxonomy-item","children":["#","MCP"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Large-scale",{"className":"page__taxonomy-item","children":["#","Large-scale"]}],["$","span","Real-world tasks",{"className":"page__taxonomy-item","children":["#","Real-world tasks"]}],["$","span","Automated Evaluation",{"className":"page__taxonomy-item","children":["#","Automated Evaluation"]}],["$","span","Meta-tool-learning",{"className":"page__taxonomy-item","children":["#","Meta-tool-learning"]}]]}]]}]]}],["$","article","2025-8-6-LAMIC-Layout-Aware-Multi-Image-Composition-via-Scalability-of-Multimodal-Diffusion-Transformer",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-6-LAMIC-Layout-Aware-Multi-Image-Composition-via-Scalability-of-Multimodal-Diffusion-Transformer/","children":"[논문리뷰] LAMIC: Layout-Aware Multi-Image Composition via Scalability of Multimodal Diffusion Transformer"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shunyu Yao이 [arXiv]에 게시한 'LAMIC: Layout-Aware Multi-Image Composition via Scalability of Multimodal Diffusion Transformer' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-06 13:46:36+0900","children":"2025년 8월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-Image Composition",{"className":"page__taxonomy-item","children":["#","Multi-Image Composition"]}],["$","span","Layout Control",{"className":"page__taxonomy-item","children":["#","Layout Control"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Attention Mechanisms",{"className":"page__taxonomy-item","children":["#","Attention Mechanisms"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}],["$","span","Zero-Shot Generalization",{"className":"page__taxonomy-item","children":["#","Zero-Shot Generalization"]}]]}]]}]]}],["$","article","2025-8-6-Goedel-Prover-V2-Scaling-Formal-Theorem-Proving-with-Scaffolded-Data-Synthesis-and-Self-Correction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-6-Goedel-Prover-V2-Scaling-Formal-Theorem-Proving-with-Scaffolded-Data-Synthesis-and-Self-Correction/","children":"[논문리뷰] Goedel-Prover-V2: Scaling Formal Theorem Proving with Scaffolded Data Synthesis and Self-Correction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jui-Hui Chung이 [arXiv]에 게시한 'Goedel-Prover-V2: Scaling Formal Theorem Proving with Scaffolded Data Synthesis and Self-Correction' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-06 13:46:36+0900","children":"2025년 8월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Automated Theorem Proving",{"className":"page__taxonomy-item","children":["#","Automated Theorem Proving"]}],["$","span","Formal Verification",{"className":"page__taxonomy-item","children":["#","Formal Verification"]}],["$","span","Language Models",{"className":"page__taxonomy-item","children":["#","Language Models"]}],["$","span","Self-Correction",{"className":"page__taxonomy-item","children":["#","Self-Correction"]}],["$","span","Data Synthesis",{"className":"page__taxonomy-item","children":["#","Data Synthesis"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Model Averaging",{"className":"page__taxonomy-item","children":["#","Model Averaging"]}],["$","span","Lean",{"className":"page__taxonomy-item","children":["#","Lean"]}]]}]]}]]}],["$","article","2025-8-6-CompassVerifier-A-Unified-and-Robust-Verifier-for-LLMs-Evaluation-and-Outcome-Reward",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-6-CompassVerifier-A-Unified-and-Robust-Verifier-for-LLMs-Evaluation-and-Outcome-Reward/","children":"[논문리뷰] CompassVerifier: A Unified and Robust Verifier for LLMs Evaluation and Outcome Reward"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Songyang Gao이 [arXiv]에 게시한 'CompassVerifier: A Unified and Robust Verifier for LLMs Evaluation and Outcome Reward' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-06 13:46:36+0900","children":"2025년 8월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Answer Verification",{"className":"page__taxonomy-item","children":["#","Answer Verification"]}],["$","span","Reward Model",{"className":"page__taxonomy-item","children":["#","Reward Model"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Formula Verification",{"className":"page__taxonomy-item","children":["#","Formula Verification"]}],["$","span","Hallucination Detection",{"className":"page__taxonomy-item","children":["#","Hallucination Detection"]}]]}]]}]]}],["$","article","2025-8-6-ChartCap-Mitigating-Hallucination-of-Dense-Chart-Captioning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-6-ChartCap-Mitigating-Hallucination-of-Dense-Chart-Captioning/","children":"[논문리뷰] ChartCap: Mitigating Hallucination of Dense Chart Captioning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Gunhee Kim이 [arXiv]에 게시한 'ChartCap: Mitigating Hallucination of Dense Chart Captioning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-06 13:46:36+0900","children":"2025년 8월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Chart Captioning",{"className":"page__taxonomy-item","children":["#","Chart Captioning"]}],["$","span","Hallucination Mitigation",{"className":"page__taxonomy-item","children":["#","Hallucination Mitigation"]}],["$","span","Dataset Generation",{"className":"page__taxonomy-item","children":["#","Dataset Generation"]}],["$","span","Visual Language Models",{"className":"page__taxonomy-item","children":["#","Visual Language Models"]}],["$","span","Cycle Consistency",{"className":"page__taxonomy-item","children":["#","Cycle Consistency"]}],["$","span","Reference-Free Metric",{"className":"page__taxonomy-item","children":["#","Reference-Free Metric"]}],["$","span","Data Visualization",{"className":"page__taxonomy-item","children":["#","Data Visualization"]}]]}]]}]]}],["$","article","2025-8-6-CRINN-Contrastive-Reinforcement-Learning-for-Approximate-Nearest-Neighbor-Search",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-6-CRINN-Contrastive-Reinforcement-Learning-for-Approximate-Nearest-Neighbor-Search/","children":"[논문리뷰] CRINN: Contrastive Reinforcement Learning for Approximate Nearest Neighbor Search"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiwei Li이 [arXiv]에 게시한 'CRINN: Contrastive Reinforcement Learning for Approximate Nearest Neighbor Search' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-06 13:46:36+0900","children":"2025년 8월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Approximate Nearest Neighbor Search",{"className":"page__taxonomy-item","children":["#","Approximate Nearest Neighbor Search"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Code Optimization",{"className":"page__taxonomy-item","children":["#","Code Optimization"]}],["$","span","HNSW",{"className":"page__taxonomy-item","children":["#","HNSW"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}]]}]]}]]}],["$","article","2025-8-6-AlignGuard-LoRA-Alignment-Preserving-Fine-Tuning-via-Fisher-Guided-Decomposition-and-Riemannian-Geodesic-Collision-Regularization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-6-AlignGuard-LoRA-Alignment-Preserving-Fine-Tuning-via-Fisher-Guided-Decomposition-and-Riemannian-Geodesic-Collision-Regularization/","children":"[논문리뷰] AlignGuard-LoRA: Alignment-Preserving Fine-Tuning via Fisher-Guided Decomposition and Riemannian-Geodesic Collision Regularization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Aman Chadha이 [arXiv]에 게시한 'AlignGuard-LoRA: Alignment-Preserving Fine-Tuning via Fisher-Guided Decomposition and Riemannian-Geodesic Collision Regularization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-06 13:46:36+0900","children":"2025년 8월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Alignment Preservation",{"className":"page__taxonomy-item","children":["#","Alignment Preservation"]}],["$","span","Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Fine-Tuning"]}],["$","span","LoRA",{"className":"page__taxonomy-item","children":["#","LoRA"]}],["$","span","Fisher Information Matrix",{"className":"page__taxonomy-item","children":["#","Fisher Information Matrix"]}],["$","span","Catastrophic Forgetting",{"className":"page__taxonomy-item","children":["#","Catastrophic Forgetting"]}],["$","span","LLM Safety",{"className":"page__taxonomy-item","children":["#","LLM Safety"]}],["$","span","Riemannian Geometry",{"className":"page__taxonomy-item","children":["#","Riemannian Geometry"]}],["$","span","Parameter-Efficient Learning",{"className":"page__taxonomy-item","children":["#","Parameter-Efficient Learning"]}]]}]]}]]}],["$","article","2025-8-5-VeOmni-Scaling-Any-Modality-Model-Training-with-Model-Centric-Distributed-Recipe-Zoo",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-5-VeOmni-Scaling-Any-Modality-Model-Training-with-Model-Centric-Distributed-Recipe-Zoo/","children":"[논문리뷰] VeOmni: Scaling Any Modality Model Training with Model-Centric Distributed Recipe Zoo"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Bin Jia이 [arXiv]에 게시한 'VeOmni: Scaling Any Modality Model Training with Model-Centric Distributed Recipe Zoo' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-05 11:40:52+0900","children":"2025년 8월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Omni-modal LLMs",{"className":"page__taxonomy-item","children":["#","Omni-modal LLMs"]}],["$","span","Distributed Training",{"className":"page__taxonomy-item","children":["#","Distributed Training"]}],["$","span","Model-centric",{"className":"page__taxonomy-item","children":["#","Model-centric"]}],["$","span","Parallelism",{"className":"page__taxonomy-item","children":["#","Parallelism"]}],["$","span","FSDP",{"className":"page__taxonomy-item","children":["#","FSDP"]}],["$","span","Sequence Parallelism",{"className":"page__taxonomy-item","children":["#","Sequence Parallelism"]}],["$","span","Expert Parallelism",{"className":"page__taxonomy-item","children":["#","Expert Parallelism"]}],["$","span","Mixture-of-Experts",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts"]}]]}]]}]]}],["$","article","2025-8-5-SitEmb-v1-5-Improved-Context-Aware-Dense-Retrieval-for-Semantic-Association-and-Long-Story-Comprehension",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-5-SitEmb-v1-5-Improved-Context-Aware-Dense-Retrieval-for-Semantic-Association-and-Long-Story-Comprehension/","children":"[논문리뷰] SitEmb-v1.5: Improved Context-Aware Dense Retrieval for Semantic Association and Long Story Comprehension"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Liyan Xu이 [arXiv]에 게시한 'SitEmb-v1.5: Improved Context-Aware Dense Retrieval for Semantic Association and Long Story Comprehension' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-05 11:40:52+0900","children":"2025년 8월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Dense Retrieval",{"className":"page__taxonomy-item","children":["#","Dense Retrieval"]}],["$","span","Context-Aware Embedding",{"className":"page__taxonomy-item","children":["#","Context-Aware Embedding"]}],["$","span","RAG",{"className":"page__taxonomy-item","children":["#","RAG"]}],["$","span","Long Document Comprehension",{"className":"page__taxonomy-item","children":["#","Long Document Comprehension"]}],["$","span","Residual Learning",{"className":"page__taxonomy-item","children":["#","Residual Learning"]}],["$","span","Semantic Association",{"className":"page__taxonomy-item","children":["#","Semantic Association"]}],["$","span","Text Embedding",{"className":"page__taxonomy-item","children":["#","Text Embedding"]}]]}]]}]]}],["$","article","2025-8-5-RoboMemory-A-Brain-inspired-Multi-memory-Agentic-Framework-for-Lifelong-Learning-in-Physical-Embodied-Systems",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-5-RoboMemory-A-Brain-inspired-Multi-memory-Agentic-Framework-for-Lifelong-Learning-in-Physical-Embodied-Systems/","children":"[논문리뷰] RoboMemory: A Brain-inspired Multi-memory Agentic Framework for Lifelong Learning in Physical Embodied Systems"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Junkun Hong이 [arXiv]에 게시한 'RoboMemory: A Brain-inspired Multi-memory Agentic Framework for Lifelong Learning in Physical Embodied Systems' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-05 11:40:52+0900","children":"2025년 8월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Brain-inspired AI",{"className":"page__taxonomy-item","children":["#","Brain-inspired AI"]}],["$","span","Lifelong Learning",{"className":"page__taxonomy-item","children":["#","Lifelong Learning"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Multi-memory Systems",{"className":"page__taxonomy-item","children":["#","Multi-memory Systems"]}],["$","span","Knowledge Graph",{"className":"page__taxonomy-item","children":["#","Knowledge Graph"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Closed-Loop Planning",{"className":"page__taxonomy-item","children":["#","Closed-Loop Planning"]}]]}]]}]]}],["$","article","2025-8-5-Qwen-Image-Technical-Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-5-Qwen-Image-Technical-Report/","children":"[논문리뷰] Qwen-Image Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kaiyuan Gao이 [arXiv]에 게시한 'Qwen-Image Technical Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-05 11:40:52+0900","children":"2025년 8월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Text-to-Image",{"className":"page__taxonomy-item","children":["#","Text-to-Image"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Text Rendering",{"className":"page__taxonomy-item","children":["#","Text Rendering"]}],["$","span","Multimodal Diffusion Transformer",{"className":"page__taxonomy-item","children":["#","Multimodal Diffusion Transformer"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Foundation Model",{"className":"page__taxonomy-item","children":["#","Foundation Model"]}]]}]]}]]}],["$","article","2025-8-5-Personalized-Safety-Alignment-for-Text-to-Image-Diffusion-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-5-Personalized-Safety-Alignment-for-Text-to-Image-Diffusion-Models/","children":"[논문리뷰] Personalized Safety Alignment for Text-to-Image Diffusion Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kaidong Yu이 [arXiv]에 게시한 'Personalized Safety Alignment for Text-to-Image Diffusion Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-05 11:40:52+0900","children":"2025년 8월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Personalized Safety Alignment",{"className":"page__taxonomy-item","children":["#","Personalized Safety Alignment"]}],["$","span","Text-to-Image Diffusion Models",{"className":"page__taxonomy-item","children":["#","Text-to-Image Diffusion Models"]}],["$","span","DPO",{"className":"page__taxonomy-item","children":["#","DPO"]}],["$","span","User Preferences",{"className":"page__taxonomy-item","children":["#","User Preferences"]}],["$","span","Content Moderation",{"className":"page__taxonomy-item","children":["#","Content Moderation"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Cross-Attention",{"className":"page__taxonomy-item","children":["#","Cross-Attention"]}],["$","span","Safety Alignment",{"className":"page__taxonomy-item","children":["#","Safety Alignment"]}]]}]]}]]}],["$","article","2025-8-5-Llama-3-1-FoundationAI-SecurityLLM-8B-Instruct-Technical-Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-5-Llama-3-1-FoundationAI-SecurityLLM-8B-Instruct-Technical-Report/","children":"[논문리뷰] Llama-3.1-FoundationAI-SecurityLLM-8B-Instruct Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Anu Vellore이 [arXiv]에 게시한 'Llama-3.1-FoundationAI-SecurityLLM-8B-Instruct Technical Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-05 11:40:52+0900","children":"2025년 8월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Model",{"className":"page__taxonomy-item","children":["#","Large Language Model"]}],["$","span","Cybersecurity",{"className":"page__taxonomy-item","children":["#","Cybersecurity"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}],["$","span","Direct Preference Optimization",{"className":"page__taxonomy-item","children":["#","Direct Preference Optimization"]}],["$","span","Cyber Threat Intelligence",{"className":"page__taxonomy-item","children":["#","Cyber Threat Intelligence"]}],["$","span","Foundation Model",{"className":"page__taxonomy-item","children":["#","Foundation Model"]}],["$","span","Chatbot",{"className":"page__taxonomy-item","children":["#","Chatbot"]}]]}]]}]]}],["$","article","2025-8-5-InstructVLA-Vision-Language-Action-Instruction-Tuning-from-Understanding-to-Manipulation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-5-InstructVLA-Vision-Language-Action-Instruction-Tuning-from-Understanding-to-Manipulation/","children":"[논문리뷰] InstructVLA: Vision-Language-Action Instruction Tuning from Understanding to Manipulation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yang Tian이 [arXiv]에 게시한 'InstructVLA: Vision-Language-Action Instruction Tuning from Understanding to Manipulation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-05 11:40:52+0900","children":"2025년 8월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action (VLA)",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action (VLA)"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","span","Robotic Manipulation",{"className":"page__taxonomy-item","children":["#","Robotic Manipulation"]}],["$","span","Catastrophic Forgetting",{"className":"page__taxonomy-item","children":["#","Catastrophic Forgetting"]}],["$","span","Mixture-of-Experts (MoE)",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts (MoE)"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}]]}]]}]]}],["$","article","2025-8-5-Exploitation-Is-All-You-Need-for-Exploration",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-5-Exploitation-Is-All-You-Need-for-Exploration/","children":"[논문리뷰] Exploitation Is All You Need... for Exploration"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jesse Roberts이 [arXiv]에 게시한 'Exploitation Is All You Need... for Exploration' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-05 11:40:52+0900","children":"2025년 8월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Exploration-Exploitation",{"className":"page__taxonomy-item","children":["#","Exploration-Exploitation"]}],["$","span","Meta-RL",{"className":"page__taxonomy-item","children":["#","Meta-RL"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Emergent Behavior",{"className":"page__taxonomy-item","children":["#","Emergent Behavior"]}],["$","span","Multi-Armed Bandits",{"className":"page__taxonomy-item","children":["#","Multi-Armed Bandits"]}],["$","span","Gridworlds",{"className":"page__taxonomy-item","children":["#","Gridworlds"]}],["$","span","Pseudo-Thompson Sampling",{"className":"page__taxonomy-item","children":["#","Pseudo-Thompson Sampling"]}]]}]]}]]}],["$","article","2025-8-5-Cyber-Zero-Training-Cybersecurity-Agents-without-Runtime",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-5-Cyber-Zero-Training-Cybersecurity-Agents-without-Runtime/","children":"[논문리뷰] Cyber-Zero: Training Cybersecurity Agents without Runtime"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zijian Wang이 [arXiv]에 게시한 'Cyber-Zero: Training Cybersecurity Agents without Runtime' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-05 11:40:52+0900","children":"2025년 8월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Cybersecurity Agents",{"className":"page__taxonomy-item","children":["#","Cybersecurity Agents"]}],["$","span","LLM Training",{"className":"page__taxonomy-item","children":["#","LLM Training"]}],["$","span","Trajectory Synthesis",{"className":"page__taxonomy-item","children":["#","Trajectory Synthesis"]}],["$","span","Runtime-Free Training",{"className":"page__taxonomy-item","children":["#","Runtime-Free Training"]}],["$","span","CTF Challenges",{"className":"page__taxonomy-item","children":["#","CTF Challenges"]}],["$","span","LLM Simulation",{"className":"page__taxonomy-item","children":["#","LLM Simulation"]}]]}]]}]]}],["$","article","2025-8-5-CellForge-Agentic-Design-of-Virtual-Cell-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-5-CellForge-Agentic-Design-of-Virtual-Cell-Models/","children":"[논문리뷰] CellForge: Agentic Design of Virtual Cell Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Daniel Shao이 [arXiv]에 게시한 'CellForge: Agentic Design of Virtual Cell Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-05 11:40:52+0900","children":"2025년 8월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Scientist",{"className":"page__taxonomy-item","children":["#","AI Scientist"]}],["$","span","Multi-Agent System",{"className":"page__taxonomy-item","children":["#","Multi-Agent System"]}],["$","span","Virtual Cell Modeling",{"className":"page__taxonomy-item","children":["#","Virtual Cell Modeling"]}],["$","span","Single-Cell Perturbation Prediction",{"className":"page__taxonomy-item","children":["#","Single-Cell Perturbation Prediction"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}],["$","span","Automated Model Design",{"className":"page__taxonomy-item","children":["#","Automated Model Design"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}]]}]]}]]}],["$","article","2025-8-5-Beyond-the-Trade-off-Self-Supervised-Reinforcement-Learning-for-Reasoning-Models-Instruction-Following",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-5-Beyond-the-Trade-off-Self-Supervised-Reinforcement-Learning-for-Reasoning-Models-Instruction-Following/","children":"[논문리뷰] Beyond the Trade-off: Self-Supervised Reinforcement Learning for Reasoning Models' Instruction Following"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiaqing Liang이 [arXiv]에 게시한 'Beyond the Trade-off: Self-Supervised Reinforcement Learning for Reasoning Models' Instruction Following' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-05 11:40:52+0900","children":"2025년 8월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Self-Supervised RL",{"className":"page__taxonomy-item","children":["#","Self-Supervised RL"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}],["$","span","Reasoning Models",{"className":"page__taxonomy-item","children":["#","Reasoning Models"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reward Modeling",{"className":"page__taxonomy-item","children":["#","Reward Modeling"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}]]}]]}]]}],["$","article","2025-8-5-AgentTTS-Large-Language-Model-Agent-for-Test-time-Compute-optimal-Scaling-Strategy-in-Complex-Tasks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-5-AgentTTS-Large-Language-Model-Agent-for-Test-time-Compute-optimal-Scaling-Strategy-in-Complex-Tasks/","children":"[논문리뷰] AgentTTS: Large Language Model Agent for Test-time Compute-optimal Scaling Strategy in Complex Tasks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhiwei Zhang이 [arXiv]에 게시한 'AgentTTS: Large Language Model Agent for Test-time Compute-optimal Scaling Strategy in Complex Tasks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-05 11:40:52+0900","children":"2025년 8월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Test-time Scaling",{"className":"page__taxonomy-item","children":["#","Test-time Scaling"]}],["$","span","Compute Optimization",{"className":"page__taxonomy-item","children":["#","Compute Optimization"]}],["$","span","Multi-stage Tasks",{"className":"page__taxonomy-item","children":["#","Multi-stage Tasks"]}],["$","span","Resource Allocation",{"className":"page__taxonomy-item","children":["#","Resource Allocation"]}],["$","span","Search Efficiency",{"className":"page__taxonomy-item","children":["#","Search Efficiency"]}]]}]]}]]}],["$","article","2025-8-5-A-Glimpse-to-Compress-Dynamic-Visual-Token-Pruning-for-Large-Vision-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-5-A-Glimpse-to-Compress-Dynamic-Visual-Token-Pruning-for-Large-Vision-Language-Models/","children":"[논문리뷰] A Glimpse to Compress: Dynamic Visual Token Pruning for Large Vision-Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zuxuan Wu이 [arXiv]에 게시한 'A Glimpse to Compress: Dynamic Visual Token Pruning for Large Vision-Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-05 11:40:52+0900","children":"2025년 8월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Vision-Language Models (LVLMs)",{"className":"page__taxonomy-item","children":["#","Large Vision-Language Models (LVLMs)"]}],["$","span","Visual Token Pruning",{"className":"page__taxonomy-item","children":["#","Visual Token Pruning"]}],["$","span","Dynamic Compression",{"className":"page__taxonomy-item","children":["#","Dynamic Compression"]}],["$","span","GlimpsePrune",{"className":"page__taxonomy-item","children":["#","GlimpsePrune"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}],["$","span","VQA",{"className":"page__taxonomy-item","children":["#","VQA"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}]]}]]}]]}],["$","article","2025-8-4-SpA2V-Harnessing-Spatial-Auditory-Cues-for-Audio-driven-Spatially-aware-Video-Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-4-SpA2V-Harnessing-Spatial-Auditory-Cues-for-Audio-driven-Spatially-aware-Video-Generation/","children":"[논문리뷰] SpA2V: Harnessing Spatial Auditory Cues for Audio-driven Spatially-aware Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Long Chen이 [arXiv]에 게시한 'SpA2V: Harnessing Spatial Auditory Cues for Audio-driven Spatially-aware Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-04 12:17:01+0900","children":"2025년 8월 4일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Audio-driven Video Generation",{"className":"page__taxonomy-item","children":["#","Audio-driven Video Generation"]}],["$","span","Spatial Auditory Cues",{"className":"page__taxonomy-item","children":["#","Spatial Auditory Cues"]}],["$","span","Video Scene Layout",{"className":"page__taxonomy-item","children":["#","Video Scene Layout"]}],["$","span","MLLM",{"className":"page__taxonomy-item","children":["#","MLLM"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Training-free",{"className":"page__taxonomy-item","children":["#","Training-free"]}]]}]]}]]}],["$","article","2025-8-4-SWE-Exp-Experience-Driven-Software-Issue-Resolution",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-4-SWE-Exp-Experience-Driven-Software-Issue-Resolution/","children":"[논문리뷰] SWE-Exp: Experience-Driven Software Issue Resolution"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Heng Lian이 [arXiv]에 게시한 'SWE-Exp: Experience-Driven Software Issue Resolution' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-04 12:17:01+0900","children":"2025년 8월 4일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Software Issue Resolution",{"className":"page__taxonomy-item","children":["#","Software Issue Resolution"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Experience-Driven Learning",{"className":"page__taxonomy-item","children":["#","Experience-Driven Learning"]}],["$","span","Automated Program Repair",{"className":"page__taxonomy-item","children":["#","Automated Program Repair"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Knowledge Management",{"className":"page__taxonomy-item","children":["#","Knowledge Management"]}],["$","span","Continuous Learning",{"className":"page__taxonomy-item","children":["#","Continuous Learning"]}]]}]]}]]}],["$","article","2025-8-4-SWE-Debate-Competitive-Multi-Agent-Debate-for-Software-Issue-Resolution",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-4-SWE-Debate-Competitive-Multi-Agent-Debate-for-Software-Issue-Resolution/","children":"[논문리뷰] SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Heng Lian이 [arXiv]에 게시한 'SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-04 12:17:01+0900","children":"2025년 8월 4일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-Agent System",{"className":"page__taxonomy-item","children":["#","Multi-Agent System"]}],["$","span","Software Engineering",{"className":"page__taxonomy-item","children":["#","Software Engineering"]}],["$","span","Fault Localization",{"className":"page__taxonomy-item","children":["#","Fault Localization"]}],["$","span","Issue Resolution",{"className":"page__taxonomy-item","children":["#","Issue Resolution"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Competitive Debate",{"className":"page__taxonomy-item","children":["#","Competitive Debate"]}],["$","span","Graph Traversal",{"className":"page__taxonomy-item","children":["#","Graph Traversal"]}]]}]]}]]}],["$","article","2025-8-4-PixNerd-Pixel-Neural-Field-Diffusion",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-4-PixNerd-Pixel-Neural-Field-Diffusion/","children":"[논문리뷰] PixNerd: Pixel Neural Field Diffusion"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Limin Wang이 [arXiv]에 게시한 'PixNerd: Pixel Neural Field Diffusion' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-04 12:17:01+0900","children":"2025년 8월 4일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Neural Fields",{"className":"page__taxonomy-item","children":["#","Neural Fields"]}],["$","span","Pixel Space",{"className":"page__taxonomy-item","children":["#","Pixel Space"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Image Synthesis",{"className":"page__taxonomy-item","children":["#","Image Synthesis"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","End-to-End Learning",{"className":"page__taxonomy-item","children":["#","End-to-End Learning"]}]]}]]}]]}],["$","article","2025-8-4-Multimodal-Referring-Segmentation-A-Survey",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-4-Multimodal-Referring-Segmentation-A-Survey/","children":"[논문리뷰] Multimodal Referring Segmentation: A Survey"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zuxuan Wu이 [arXiv]에 게시한 'Multimodal Referring Segmentation: A Survey' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-04 12:17:01+0900","children":"2025년 8월 4일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Referring Segmentation",{"className":"page__taxonomy-item","children":["#","Referring Segmentation"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Image Segmentation",{"className":"page__taxonomy-item","children":["#","Image Segmentation"]}],["$","span","Video Segmentation",{"className":"page__taxonomy-item","children":["#","Video Segmentation"]}],["$","span","3D Vision",{"className":"page__taxonomy-item","children":["#","3D Vision"]}],["$","span","Survey",{"className":"page__taxonomy-item","children":["#","Survey"]}]]}]]}]]}],["$","article","2025-8-4-Learning-an-Efficient-Multi-Turn-Dialogue-Evaluator-from-Multiple-Judges",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-4-Learning-an-Efficient-Multi-Turn-Dialogue-Evaluator-from-Multiple-Judges/","children":"[논문리뷰] Learning an Efficient Multi-Turn Dialogue Evaluator from Multiple Judges"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chengfei Lv이 [arXiv]에 게시한 'Learning an Efficient Multi-Turn Dialogue Evaluator from Multiple Judges' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-04 12:17:01+0900","children":"2025년 8월 4일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-Turn Dialogue Evaluation",{"className":"page__taxonomy-item","children":["#","Multi-Turn Dialogue Evaluation"]}],["$","span","LLM-as-a-Judge",{"className":"page__taxonomy-item","children":["#","LLM-as-a-Judge"]}],["$","span","Multi-Judge Aggregation",{"className":"page__taxonomy-item","children":["#","Multi-Judge Aggregation"]}],["$","span","Preference Learning",{"className":"page__taxonomy-item","children":["#","Preference Learning"]}],["$","span","Dialogue Quality Assessment",{"className":"page__taxonomy-item","children":["#","Dialogue Quality Assessment"]}],["$","span","Maximum Likelihood Estimation",{"className":"page__taxonomy-item","children":["#","Maximum Likelihood Estimation"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}]]}]]}]]}],["$","article","2025-8-4-Investigating-Hallucination-in-Conversations-for-Low-Resource-Languages",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-4-Investigating-Hallucination-in-Conversations-for-Low-Resource-Languages/","children":"[논문리뷰] Investigating Hallucination in Conversations for Low Resource Languages"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Fatemeh Jamshidi이 [arXiv]에 게시한 'Investigating Hallucination in Conversations for Low Resource Languages' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-04 12:17:01+0900","children":"2025년 8월 4일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Hallucination",{"className":"page__taxonomy-item","children":["#","LLM Hallucination"]}],["$","span","Low-resource Languages",{"className":"page__taxonomy-item","children":["#","Low-resource Languages"]}],["$","span","Conversational AI",{"className":"page__taxonomy-item","children":["#","Conversational AI"]}],["$","span","ROUGE Score",{"className":"page__taxonomy-item","children":["#","ROUGE Score"]}],["$","span","Cross-lingual Evaluation",{"className":"page__taxonomy-item","children":["#","Cross-lingual Evaluation"]}],["$","span","Factual Consistency",{"className":"page__taxonomy-item","children":["#","Factual Consistency"]}]]}]]}]]}],["$","article","2025-8-4-IGL-Nav-Incremental-3D-Gaussian-Localization-for-Image-goal-Navigation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-4-IGL-Nav-Incremental-3D-Gaussian-Localization-for-Image-goal-Navigation/","children":"[논문리뷰] IGL-Nav: Incremental 3D Gaussian Localization for Image-goal Navigation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jianjiang Feng이 [arXiv]에 게시한 'IGL-Nav: Incremental 3D Gaussian Localization for Image-goal Navigation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-04 12:17:01+0900","children":"2025년 8월 4일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image-goal Navigation",{"className":"page__taxonomy-item","children":["#","Image-goal Navigation"]}],["$","span","3D Gaussian Splatting (3DGS)",{"className":"page__taxonomy-item","children":["#","3D Gaussian Splatting (3DGS)"]}],["$","span","Incremental Scene Representation",{"className":"page__taxonomy-item","children":["#","Incremental Scene Representation"]}],["$","span","Coarse-to-fine Localization",{"className":"page__taxonomy-item","children":["#","Coarse-to-fine Localization"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Differentiable Rendering",{"className":"page__taxonomy-item","children":["#","Differentiable Rendering"]}]]}]]}]]}],["$","article","2025-8-4-Beyond-Fixed-Variable-Length-Denoising-for-Diffusion-Large-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-4-Beyond-Fixed-Variable-Length-Denoising-for-Diffusion-Large-Language-Models/","children":"[논문리뷰] Beyond Fixed: Variable-Length Denoising for Diffusion Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiaqi Wang이 [arXiv]에 게시한 'Beyond Fixed: Variable-Length Denoising for Diffusion Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-04 12:17:01+0900","children":"2025년 8월 4일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Large Language Models",{"className":"page__taxonomy-item","children":["#","Diffusion Large Language Models"]}],["$","span","Variable-Length Generation",{"className":"page__taxonomy-item","children":["#","Variable-Length Generation"]}],["$","span","Dynamic Length Adaptation",{"className":"page__taxonomy-item","children":["#","Dynamic Length Adaptation"]}],["$","span","Denoising Strategy",{"className":"page__taxonomy-item","children":["#","Denoising Strategy"]}],["$","span","Inference Optimization",{"className":"page__taxonomy-item","children":["#","Inference Optimization"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}]]}]]}]]}],["$","article","2025-8-4-3D-R1-Enhancing-Reasoning-in-3D-VLMs-for-Unified-Scene-Understanding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-4-3D-R1-Enhancing-Reasoning-in-3D-VLMs-for-Unified-Scene-Understanding/","children":"[논문리뷰] 3D-R1: Enhancing Reasoning in 3D VLMs for Unified Scene Understanding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hao Tang이 [arXiv]에 게시한 '3D-R1: Enhancing Reasoning in 3D VLMs for Unified Scene Understanding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-04 12:17:01+0900","children":"2025년 8월 4일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Vision-Language Models",{"className":"page__taxonomy-item","children":["#","3D Vision-Language Models"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Scene Understanding",{"className":"page__taxonomy-item","children":["#","Scene Understanding"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Dynamic View Selection",{"className":"page__taxonomy-item","children":["#","Dynamic View Selection"]}],["$","span","Multi-task Learning",{"className":"page__taxonomy-item","children":["#","Multi-task Learning"]}]]}]]}]]}],["$","article","2025-8-3-villa-X-Enhancing-Latent-Action-Modeling-in-Vision-Language-Action-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-villa-X-Enhancing-Latent-Action-Modeling-in-Vision-Language-Action-Models/","children":"[논문리뷰] villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kaixin Wang이 [arXiv]에 게시한 'villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-03 07:35:17+0900","children":"2025년 8월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action Models"]}],["$","span","Latent Actions",{"className":"page__taxonomy-item","children":["#","Latent Actions"]}],["$","span","Robot Manipulation",{"className":"page__taxonomy-item","children":["#","Robot Manipulation"]}],["$","span","Pre-training",{"className":"page__taxonomy-item","children":["#","Pre-training"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Proprioceptive Feedback",{"className":"page__taxonomy-item","children":["#","Proprioceptive Feedback"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}]]}]]}]]}],["$","article","2025-8-3-iLRM-An-Iterative-Large-3D-Reconstruction-Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-iLRM-An-Iterative-Large-3D-Reconstruction-Model/","children":"[논문리뷰] iLRM: An Iterative Large 3D Reconstruction Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Abdelrahman Mohamed이 [arXiv]에 게시한 'iLRM: An Iterative Large 3D Reconstruction Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-03 07:35:17+0900","children":"2025년 8월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Reconstruction",{"className":"page__taxonomy-item","children":["#","3D Reconstruction"]}],["$","span","Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","Gaussian Splatting"]}],["$","span","Iterative Refinement",{"className":"page__taxonomy-item","children":["#","Iterative Refinement"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Multi-view Learning",{"className":"page__taxonomy-item","children":["#","Multi-view Learning"]}],["$","span","Scalability",{"className":"page__taxonomy-item","children":["#","Scalability"]}],["$","span","Feed-forward Models",{"className":"page__taxonomy-item","children":["#","Feed-forward Models"]}]]}]]}]]}],["$","article","2025-8-3-TARS-MinMax-Token-Adaptive-Preference-Strategy-for-Hallucination-Reduction-in-MLLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-TARS-MinMax-Token-Adaptive-Preference-Strategy-for-Hallucination-Reduction-in-MLLMs/","children":"[논문리뷰] TARS: MinMax Token-Adaptive Preference Strategy for Hallucination Reduction in MLLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiasheng Tang이 [arXiv]에 게시한 'TARS: MinMax Token-Adaptive Preference Strategy for Hallucination Reduction in MLLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-03 07:35:17+0900","children":"2025년 8월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","MLLMs",{"className":"page__taxonomy-item","children":["#","MLLMs"]}],["$","span","Hallucination Reduction",{"className":"page__taxonomy-item","children":["#","Hallucination Reduction"]}],["$","span","Preference Optimization",{"className":"page__taxonomy-item","children":["#","Preference Optimization"]}],["$","span","Min-Max Optimization",{"className":"page__taxonomy-item","children":["#","Min-Max Optimization"]}],["$","span","Token-Adaptive Strategy",{"className":"page__taxonomy-item","children":["#","Token-Adaptive Strategy"]}],["$","span","Spectral Regularization",{"className":"page__taxonomy-item","children":["#","Spectral Regularization"]}],["$","span","Visual Grounding",{"className":"page__taxonomy-item","children":["#","Visual Grounding"]}]]}]]}]]}],["$","article","2025-8-3-Seed-Prover-Deep-and-Broad-Reasoning-for-Automated-Theorem-Proving",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-Seed-Prover-Deep-and-Broad-Reasoning-for-Automated-Theorem-Proving/","children":"[논문리뷰] Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhicheng Jiang이 [arXiv]에 게시한 'Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-03 07:35:17+0900","children":"2025년 8월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Automated Theorem Proving",{"className":"page__taxonomy-item","children":["#","Automated Theorem Proving"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Formal Verification",{"className":"page__taxonomy-item","children":["#","Formal Verification"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Lean",{"className":"page__taxonomy-item","children":["#","Lean"]}],["$","span","Geometry Reasoning",{"className":"page__taxonomy-item","children":["#","Geometry Reasoning"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Lemma-Style Proving",{"className":"page__taxonomy-item","children":["#","Lemma-Style Proving"]}]]}]]}]]}],["$","article","2025-8-3-Scalable-Multi-Task-Reinforcement-Learning-for-Generalizable-Spatial-Intelligence-in-Visuomotor-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-Scalable-Multi-Task-Reinforcement-Learning-for-Generalizable-Spatial-Intelligence-in-Visuomotor-Agents/","children":"[논문리뷰] Scalable Multi-Task Reinforcement Learning for Generalizable Spatial Intelligence in Visuomotor Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Anji Liu이 [arXiv]에 게시한 'Scalable Multi-Task Reinforcement Learning for Generalizable Spatial Intelligence in Visuomotor Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-03 07:35:17+0900","children":"2025년 8월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Multi-Task Learning",{"className":"page__taxonomy-item","children":["#","Multi-Task Learning"]}],["$","span","Visuomotor Agents",{"className":"page__taxonomy-item","children":["#","Visuomotor Agents"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Minecraft",{"className":"page__taxonomy-item","children":["#","Minecraft"]}],["$","span","Cross-View Goal Specification",{"className":"page__taxonomy-item","children":["#","Cross-View Goal Specification"]}],["$","span","Automated Task Synthesis",{"className":"page__taxonomy-item","children":["#","Automated Task Synthesis"]}]]}]]}]]}],["$","article","2025-8-3-RecGPT-Technical-Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-RecGPT-Technical-Report/","children":"[논문리뷰] RecGPT Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jian Wu이 [arXiv]에 게시한 'RecGPT Technical Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-03 07:35:17+0900","children":"2025년 8월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Recommender Systems",{"className":"page__taxonomy-item","children":["#","Recommender Systems"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","User Intent Modeling",{"className":"page__taxonomy-item","children":["#","User Intent Modeling"]}],["$","span","Multi-Stage Training",{"className":"page__taxonomy-item","children":["#","Multi-Stage Training"]}],["$","span","Human-in-the-Loop",{"className":"page__taxonomy-item","children":["#","Human-in-the-Loop"]}],["$","span","E-commerce",{"className":"page__taxonomy-item","children":["#","E-commerce"]}],["$","span","Filter Bubble Mitigation",{"className":"page__taxonomy-item","children":["#","Filter Bubble Mitigation"]}],["$","span","Matthew Effect",{"className":"page__taxonomy-item","children":["#","Matthew Effect"]}]]}]]}]]}],["$","article","2025-8-3-Phi-Ground-Tech-Report-Advancing-Perception-in-GUI-Grounding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-Phi-Ground-Tech-Report-Advancing-Perception-in-GUI-Grounding/","children":"[논문리뷰] Phi-Ground Tech Report: Advancing Perception in GUI Grounding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kai Qiu이 [arXiv]에 게시한 'Phi-Ground Tech Report: Advancing Perception in GUI Grounding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-03 07:35:17+0900","children":"2025년 8월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","GUI grounding",{"className":"page__taxonomy-item","children":["#","GUI grounding"]}],["$","span","AI agent",{"className":"page__taxonomy-item","children":["#","AI agent"]}],["$","span","Large Multi-modal Model",{"className":"page__taxonomy-item","children":["#","Large Multi-modal Model"]}],["$","span","Perception",{"className":"page__taxonomy-item","children":["#","Perception"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}],["$","span","Direct Preference Optimization",{"className":"page__taxonomy-item","children":["#","Direct Preference Optimization"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}]]}]]}]]}],["$","article","2025-8-3-Persona-Vectors-Monitoring-and-Controlling-Character-Traits-in-Language-Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-Persona-Vectors-Monitoring-and-Controlling-Character-Traits-in-Language-Models/","children":"[논문리뷰] Persona Vectors: Monitoring and Controlling Character Traits in Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jack Lindsey이 [arXiv]에 게시한 'Persona Vectors: Monitoring and Controlling Character Traits in Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-03 07:35:17+0900","children":"2025년 8월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Persona Control",{"className":"page__taxonomy-item","children":["#","Persona Control"]}],["$","span","Activation Steering",{"className":"page__taxonomy-item","children":["#","Activation Steering"]}],["$","span","Finetuning",{"className":"page__taxonomy-item","children":["#","Finetuning"]}],["$","span","Behavioral Shift Detection",{"className":"page__taxonomy-item","children":["#","Behavioral Shift Detection"]}],["$","span","Interpretability",{"className":"page__taxonomy-item","children":["#","Interpretability"]}],["$","span","Data Filtering",{"className":"page__taxonomy-item","children":["#","Data Filtering"]}]]}]]}]]}],["$","article","2025-8-3-On-the-Expressiveness-of-Softmax-Attention-A-Recurrent-Neural-Network-Perspective",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-On-the-Expressiveness-of-Softmax-Attention-A-Recurrent-Neural-Network-Perspective/","children":"[논문리뷰] On the Expressiveness of Softmax Attention: A Recurrent Neural Network Perspective"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Eric C. Larson이 [arXiv]에 게시한 'On the Expressiveness of Softmax Attention: A Recurrent Neural Network Perspective' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-03 07:35:17+0900","children":"2025년 8월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Softmax Attention",{"className":"page__taxonomy-item","children":["#","Softmax Attention"]}],["$","span","Linear Attention",{"className":"page__taxonomy-item","children":["#","Linear Attention"]}],["$","span","Recurrent Neural Networks (RNNs)",{"className":"page__taxonomy-item","children":["#","Recurrent Neural Networks (RNNs)"]}],["$","span","Taylor Series Expansion",{"className":"page__taxonomy-item","children":["#","Taylor Series Expansion"]}],["$","span","Attention Mechanisms",{"className":"page__taxonomy-item","children":["#","Attention Mechanisms"]}],["$","span","Expressiveness",{"className":"page__taxonomy-item","children":["#","Expressiveness"]}],["$","span","Transformer Architectures",{"className":"page__taxonomy-item","children":["#","Transformer Architectures"]}]]}]]}]]}],["$","article","2025-8-3-NeRF-Is-a-Valuable-Assistant-for-3D-Gaussian-Splatting",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-NeRF-Is-a-Valuable-Assistant-for-3D-Gaussian-Splatting/","children":"[논문리뷰] NeRF Is a Valuable Assistant for 3D Gaussian Splatting"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"ZeSheng Wang이 [arXiv]에 게시한 'NeRF Is a Valuable Assistant for 3D Gaussian Splatting' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-03 07:35:17+0900","children":"2025년 8월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","NeRF",{"className":"page__taxonomy-item","children":["#","NeRF"]}],["$","span","3D Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","3D Gaussian Splatting"]}],["$","span","Hybrid Model",{"className":"page__taxonomy-item","children":["#","Hybrid Model"]}],["$","span","Joint Optimization",{"className":"page__taxonomy-item","children":["#","Joint Optimization"]}],["$","span","Scene Representation",{"className":"page__taxonomy-item","children":["#","Scene Representation"]}],["$","span","Neural Rendering",{"className":"page__taxonomy-item","children":["#","Neural Rendering"]}],["$","span","Residual Learning",{"className":"page__taxonomy-item","children":["#","Residual Learning"]}],["$","span","Sparse View",{"className":"page__taxonomy-item","children":["#","Sparse View"]}]]}]]}]]}],["$","article","2025-8-3-Flow-Equivariant-Recurrent-Neural-Networks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-Flow-Equivariant-Recurrent-Neural-Networks/","children":"[논문리뷰] Flow Equivariant Recurrent Neural Networks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"T. Anderson Keller이 [arXiv]에 게시한 'Flow Equivariant Recurrent Neural Networks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-03 07:35:17+0900","children":"2025년 8월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Flow Equivariance",{"className":"page__taxonomy-item","children":["#","Flow Equivariance"]}],["$","span","Recurrent Neural Networks",{"className":"page__taxonomy-item","children":["#","Recurrent Neural Networks"]}],["$","span","Sequence Models",{"className":"page__taxonomy-item","children":["#","Sequence Models"]}],["$","span","Group Equivariance",{"className":"page__taxonomy-item","children":["#","Group Equivariance"]}],["$","span","Lie Subgroups",{"className":"page__taxonomy-item","children":["#","Lie Subgroups"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Time-Parameterized Symmetries",{"className":"page__taxonomy-item","children":["#","Time-Parameterized Symmetries"]}]]}]]}]]}],["$","article","2025-8-3-Enhanced-Arabic-Text-Retrieval-with-Attentive-Relevance-Scoring",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-Enhanced-Arabic-Text-Retrieval-with-Attentive-Relevance-Scoring/","children":"[논문리뷰] Enhanced Arabic Text Retrieval with Attentive Relevance Scoring"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Abdenour Hadid이 [arXiv]에 게시한 'Enhanced Arabic Text Retrieval with Attentive Relevance Scoring' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-03 07:35:17+0900","children":"2025년 8월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Arabic NLP",{"className":"page__taxonomy-item","children":["#","Arabic NLP"]}],["$","span","Dense Passage Retrieval",{"className":"page__taxonomy-item","children":["#","Dense Passage Retrieval"]}],["$","span","Attentive Relevance Scoring",{"className":"page__taxonomy-item","children":["#","Attentive Relevance Scoring"]}],["$","span","Information Retrieval",{"className":"page__taxonomy-item","children":["#","Information Retrieval"]}],["$","span","Question Answering",{"className":"page__taxonomy-item","children":["#","Question Answering"]}],["$","span","Transformer Models",{"className":"page__taxonomy-item","children":["#","Transformer Models"]}],["$","span","Semantic Matching",{"className":"page__taxonomy-item","children":["#","Semantic Matching"]}]]}]]}]]}],["$","article","2025-8-3-Efficient-Machine-Unlearning-via-Influence-Approximation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-Efficient-Machine-Unlearning-via-Influence-Approximation/","children":"[논문리뷰] Efficient Machine Unlearning via Influence Approximation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Enhong Chen이 [arXiv]에 게시한 'Efficient Machine Unlearning via Influence Approximation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-03 07:35:17+0900","children":"2025년 8월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Machine Unlearning",{"className":"page__taxonomy-item","children":["#","Machine Unlearning"]}],["$","span","Influence Function",{"className":"page__taxonomy-item","children":["#","Influence Function"]}],["$","span","Incremental Learning",{"className":"page__taxonomy-item","children":["#","Incremental Learning"]}],["$","span","Privacy Protection",{"className":"page__taxonomy-item","children":["#","Privacy Protection"]}],["$","span","Gradient Optimization",{"className":"page__taxonomy-item","children":["#","Gradient Optimization"]}],["$","span","Model Editing",{"className":"page__taxonomy-item","children":["#","Model Editing"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}]]}]]}]]}],["$","article","2025-8-3-C3-A-Bilingual-Benchmark-for-Spoken-Dialogue-Models-Exploring-Challenges-in-Complex-Conversations",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-C3-A-Bilingual-Benchmark-for-Spoken-Dialogue-Models-Exploring-Challenges-in-Complex-Conversations/","children":"[논문리뷰] C3: A Bilingual Benchmark for Spoken Dialogue Models Exploring Challenges in Complex Conversations"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yiwen Guo이 [arXiv]에 게시한 'C3: A Bilingual Benchmark for Spoken Dialogue Models Exploring Challenges in Complex Conversations' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-03 07:35:17+0900","children":"2025년 8월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Spoken Dialogue Models",{"className":"page__taxonomy-item","children":["#","Spoken Dialogue Models"]}],["$","span","Bilingual Benchmark",{"className":"page__taxonomy-item","children":["#","Bilingual Benchmark"]}],["$","span","Complex Conversations",{"className":"page__taxonomy-item","children":["#","Complex Conversations"]}],["$","span","Ambiguity Resolution",{"className":"page__taxonomy-item","children":["#","Ambiguity Resolution"]}],["$","span","Context Understanding",{"className":"page__taxonomy-item","children":["#","Context Understanding"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Human-Computer Interaction",{"className":"page__taxonomy-item","children":["#","Human-Computer Interaction"]}]]}]]}]]}],["$","article","2025-8-3-Beyond-Linear-Bottlenecks-Spline-Based-Knowledge-Distillation-for-Culturally-Diverse-Art-Style-Classification",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-Beyond-Linear-Bottlenecks-Spline-Based-Knowledge-Distillation-for-Culturally-Diverse-Art-Style-Classification/","children":"[논문리뷰] Beyond Linear Bottlenecks: Spline-Based Knowledge Distillation for Culturally Diverse Art Style Classification"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Abdelmalik Taleb-Ahmed이 [arXiv]에 게시한 'Beyond Linear Bottlenecks: Spline-Based Knowledge Distillation for Culturally Diverse Art Style Classification' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-03 07:35:17+0900","children":"2025년 8월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Kolmogorov-Arnold Networks",{"className":"page__taxonomy-item","children":["#","Kolmogorov-Arnold Networks"]}],["$","span","Knowledge Distillation",{"className":"page__taxonomy-item","children":["#","Knowledge Distillation"]}],["$","span","Art Style Classification",{"className":"page__taxonomy-item","children":["#","Art Style Classification"]}],["$","span","Self-Supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-Supervised Learning"]}],["$","span","Spline-Based Activation",{"className":"page__taxonomy-item","children":["#","Spline-Based Activation"]}],["$","span","Dual-Teacher",{"className":"page__taxonomy-item","children":["#","Dual-Teacher"]}],["$","span","Gram Matrix",{"className":"page__taxonomy-item","children":["#","Gram Matrix"]}]]}]]}]]}],["$","article","2025-8-3-AgroBench-Vision-Language-Model-Benchmark-in-Agriculture",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-AgroBench-Vision-Language-Model-Benchmark-in-Agriculture/","children":"[논문리뷰] AgroBench: Vision-Language Model Benchmark in Agriculture"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yoshitaka Ushiku이 [arXiv]에 게시한 'AgroBench: Vision-Language Model Benchmark in Agriculture' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-03 07:35:17+0900","children":"2025년 8월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Agriculture",{"className":"page__taxonomy-item","children":["#","Agriculture"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Disease Identification",{"className":"page__taxonomy-item","children":["#","Disease Identification"]}],["$","span","Pest Management",{"className":"page__taxonomy-item","children":["#","Pest Management"]}],["$","span","Crop Management",{"className":"page__taxonomy-item","children":["#","Crop Management"]}],["$","span","Agronomy",{"className":"page__taxonomy-item","children":["#","Agronomy"]}]]}]]}]]}]]}]]}],["$","aside",null,{"className":"lg:w-80","children":["$","div",null,{"className":"sidebar sticky","children":["$","nav",null,{"className":"space-y-4","children":[["$","div","Backend",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"Backend"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Django",{"children":["$","a",null,{"href":"/backend/django/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Django"," (",6,")"]}]}],["$","li","Logging",{"children":["$","a",null,{"href":"/backend/logging/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Logging"," (",1,")"]}]}]]}]]}],["$","div","Python",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"Python"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","PEP",{"children":["$","a",null,{"href":"/python/pep/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["PEP"," (",650,")"]}]}]]}]]}],["$","div","AI/ML",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"AI/ML"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","LLM",{"children":["$","a",null,{"href":"/ai/llm/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["LLM"," (",1,")"]}]}],["$","li","Review",{"children":["$","a",null,{"href":"/ai/review/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Review"," (",1661,")"]}]}]]}]]}],["$","div","DevOps",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"DevOps"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Nginx",{"children":["$","a",null,{"href":"/devops/nginx/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Nginx"," (",1,")"]}]}],["$","li","Docker",{"children":["$","a",null,{"href":"/devops/docker/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Docker"," (",1,")"]}]}],["$","li","SafeLine",{"children":["$","a",null,{"href":"/devops/safeline/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["SafeLine"," (",1,")"]}]}],["$","li","Jenkins",{"children":["$","a",null,{"href":"/devops/jenkins/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Jenkins"," (",3,")"]}]}],["$","li","GitHub Actions",{"children":["$","a",null,{"href":"/devops/github-actions/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["GitHub Actions"," (",1,")"]}]}],["$","li","AWS",{"children":["$","a",null,{"href":"/devops/aws/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["AWS"," (",1,")"]}]}]]}]]}],["$","div","etc",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"etc"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Me",{"children":["$","a",null,{"href":"/etc/me/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Me"," (",3,")"]}]}],["$","li","Chrome Extension",{"children":["$","a",null,{"href":"/etc/chrome-extension/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Chrome Extension"," (",1,")"]}]}]]}]]}]]}]}]}]]}]}],["$","div",null,{"id":"footer","className":"page__footer","children":["$","footer",null,{"className":"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8","children":["$","div",null,{"className":"text-center text-gray-500 text-sm","children":["$","p",null,{"children":"© 2025 secrett2633. All rights reserved."}]}]}]}]]],null],null]},["$","$L4",null,{"parallelRouterKey":"children","segmentPath":["children","categories","children","$5","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L6",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},["$","$L4",null,{"parallelRouterKey":"children","segmentPath":["children","categories","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L6",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},[["$","html",null,{"lang":"ko","className":"no-js","children":[["$","head",null,{"children":[["$","meta",null,{"name":"msapplication-TileColor","content":"#ffc40d"}],["$","meta",null,{"name":"theme-color","content":"#ffffff"}],["$","script",null,{"async":true,"src":"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY"}],["$","script",null,{"dangerouslySetInnerHTML":{"__html":"\n              window.dataLayer = window.dataLayer || [];\n              function gtag(){dataLayer.push(arguments);}\n              gtag('js', new Date());\n              gtag('config', 'G-NE2W3CFPNY');\n            "}}]]}],["$","body",null,{"className":"__className_f367f3 layout--default","children":["$","div",null,{"className":"min-h-screen bg-gray-50","children":[["$","$L2",null,{}],["$","main",null,{"className":"initial-content","children":["$","$L4",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L6",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","div",null,{"className":"min-h-screen flex items-center justify-center bg-gray-50","children":["$","div",null,{"className":"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center","children":[["$","h1",null,{"className":"text-6xl font-bold text-primary-600 mb-4","children":"404"}],["$","h2",null,{"className":"text-2xl font-semibold text-gray-900 mb-4","children":"페이지를 찾을 수 없습니다"}],["$","p",null,{"className":"text-gray-600 mb-8","children":"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다."}],["$","$L3",null,{"href":"/","className":"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors","children":"홈으로 돌아가기"}]]}]}],"notFoundStyles":[],"styles":null}]}],["$","div",null,{"id":"footer","className":"page__footer","children":["$","footer",null,{"className":"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8","children":["$","div",null,{"className":"text-center text-gray-500 text-sm","children":["$","p",null,{"children":"© 2025 secrett2633. All rights reserved."}]}]}]}]]}]}]]}],null],[["$","div",null,{"className":"flex items-center justify-center min-h-screen","children":["$","div",null,{"className":"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600"}]}],[],[]]],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/edf391eeca43d999.css","precedence":"next","crossOrigin":"$undefined"}]],[null,"$L7"]]]]]
7:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"secrett2633's blog"}],["$","meta","3",{"name":"description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","meta","4",{"name":"author","content":"secrett2633"}],["$","meta","5",{"name":"keywords","content":"Django, Python, DevOps, AI, ML, 블로그, 기술"}],["$","meta","6",{"name":"creator","content":"secrett2633"}],["$","meta","7",{"name":"publisher","content":"secrett2633"}],["$","meta","8",{"name":"robots","content":"index, follow"}],["$","meta","9",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","10",{"rel":"canonical","href":"https://blog.secrett2633.site/"}],["$","meta","11",{"name":"format-detection","content":"telephone=no, address=no, email=no"}],["$","meta","12",{"property":"og:title","content":"secrett2633's blog"}],["$","meta","13",{"property":"og:description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","meta","14",{"property":"og:url","content":"https://blog.secrett2633.site/"}],["$","meta","15",{"property":"og:site_name","content":"secrett2633's blog"}],["$","meta","16",{"property":"og:locale","content":"ko_KR"}],["$","meta","17",{"property":"og:type","content":"website"}],["$","meta","18",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","19",{"name":"twitter:title","content":"secrett2633's blog"}],["$","meta","20",{"name":"twitter:description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","link","21",{"rel":"icon","href":"/icon.ico?6d9f34d4948640b8","type":"image/x-icon","sizes":"16x16"}],["$","meta","22",{"name":"next-size-adjust"}]]
1:null
