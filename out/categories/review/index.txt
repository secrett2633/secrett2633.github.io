2:I[9157,["231","static/chunks/231-c27e618569e042bc.js","157","static/chunks/157-0249a4ed84fdbe73.js","257","static/chunks/app/categories/%5Bcategory%5D/page-ded3c6ffc7adebd2.js"],"default"]
3:I[231,["231","static/chunks/231-c27e618569e042bc.js","157","static/chunks/157-0249a4ed84fdbe73.js","257","static/chunks/app/categories/%5Bcategory%5D/page-ded3c6ffc7adebd2.js"],""]
4:I[9275,[],""]
6:I[1343,[],""]
5:["category","review","d"]
0:["e6YNzZ2BVZ8NBZ6boXfWj",[[["",{"children":["categories",{"children":[["category","review","d"],{"children":["__PAGE__?{\"category\":\"review\"}",{}]}]}]},"$undefined","$undefined",true],["",{"children":["categories",{"children":[["category","review","d"],{"children":["__PAGE__",{},[["$L1",[["$","$L2",null,{}],["$","div",null,{"className":"initial-content","children":["$","div",null,{"className":"flex flex-col lg:flex-row gap-8","children":[["$","main",null,{"className":"flex-1","children":[["$","h1",null,{"className":"page__title","children":["Review"," 카테고리"]}],["$","div",null,{"className":"entries-list","children":[["$","article","2025-10-24-Thought_Communication_in_Multiagent_Collaboration",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-Thought_Communication_in_Multiagent_Collaboration/","children":"[논문리뷰] Thought Communication in Multiagent Collaboration"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Mingze Gao이 [arXiv]에 게시한 'Thought Communication in Multiagent Collaboration' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multiagent Systems",{"className":"page__taxonomy-item","children":["#","Multiagent Systems"]}],["$","span","LLM Communication",{"className":"page__taxonomy-item","children":["#","LLM Communication"]}],["$","span","Latent Variable Models",{"className":"page__taxonomy-item","children":["#","Latent Variable Models"]}],["$","span","Identifiability Theory",{"className":"page__taxonomy-item","children":["#","Identifiability Theory"]}],["$","span","Thought Communication",{"className":"page__taxonomy-item","children":["#","Thought Communication"]}],["$","span","Sparse Autoencoder",{"className":"page__taxonomy-item","children":["#","Sparse Autoencoder"]}],["$","span","Prefix Tuning",{"className":"page__taxonomy-item","children":["#","Prefix Tuning"]}]]}]]}]]}],["$","article","2025-10-24-The_Massive_Legal_Embedding_Benchmark_MLEB",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-The_Massive_Legal_Embedding_Benchmark_MLEB/","children":"[논문리뷰] The Massive Legal Embedding Benchmark (MLEB)"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'The Massive Legal Embedding Benchmark (MLEB)' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Legal Information Retrieval",{"className":"page__taxonomy-item","children":["#","Legal Information Retrieval"]}],["$","span","Embedding Models",{"className":"page__taxonomy-item","children":["#","Embedding Models"]}],["$","span","Benchmark Dataset",{"className":"page__taxonomy-item","children":["#","Benchmark Dataset"]}],["$","span","Natural Language Processing",{"className":"page__taxonomy-item","children":["#","Natural Language Processing"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","Jurisdictional Diversity",{"className":"page__taxonomy-item","children":["#","Jurisdictional Diversity"]}],["$","span","Legal Tech",{"className":"page__taxonomy-item","children":["#","Legal Tech"]}]]}]]}]]}],["$","article","2025-10-24-Seed3D_1.0_From_Images_to_High-Fidelity_Simulation-Ready_3D_Assets",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-Seed3D_1.0_From_Images_to_High-Fidelity_Simulation-Ready_3D_Assets/","children":"[논문리뷰] Seed3D 1.0: From Images to High-Fidelity Simulation-Ready 3D Assets"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Seed3D 1.0: From Images to High-Fidelity Simulation-Ready 3D Assets' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Asset Generation",{"className":"page__taxonomy-item","children":["#","3D Asset Generation"]}],["$","span","Simulation-Ready Assets",{"className":"page__taxonomy-item","children":["#","Simulation-Ready Assets"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Physically Based Rendering (PBR)",{"className":"page__taxonomy-item","children":["#","Physically Based Rendering (PBR)"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Robotic Simulation",{"className":"page__taxonomy-item","children":["#","Robotic Simulation"]}],["$","span","Image-to-3D",{"className":"page__taxonomy-item","children":["#","Image-to-3D"]}],["$","span","Foundation Model",{"className":"page__taxonomy-item","children":["#","Foundation Model"]}]]}]]}]]}],["$","article","2025-10-24-Search_Self-play_Pushing_the_Frontier_of_Agent_Capability_without_Supervision",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-Search_Self-play_Pushing_the_Frontier_of_Agent_Capability_without_Supervision/","children":"[논문리뷰] Search Self-play: Pushing the Frontier of Agent Capability without Supervision"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Search Self-play: Pushing the Frontier of Agent Capability without Supervision' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Self-play",{"className":"page__taxonomy-item","children":["#","Self-play"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Search Agents",{"className":"page__taxonomy-item","children":["#","Search Agents"]}],["$","span","Supervision-Free Training",{"className":"page__taxonomy-item","children":["#","Supervision-Free Training"]}],["$","span","Retrieval-Augmented Generation (RAG)",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation (RAG)"]}],["$","span","Task Generation",{"className":"page__taxonomy-item","children":["#","Task Generation"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}]]}]]}]]}],["$","article","2025-10-24-SAKE_Towards_Editing_Auditory_Attribute_Knowledge_of_Large_Audio-Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-SAKE_Towards_Editing_Auditory_Attribute_Knowledge_of_Large_Audio-Language_Models/","children":"[논문리뷰] SAKE: Towards Editing Auditory Attribute Knowledge of Large Audio-Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'SAKE: Towards Editing Auditory Attribute Knowledge of Large Audio-Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Knowledge Editing",{"className":"page__taxonomy-item","children":["#","Knowledge Editing"]}],["$","span","Audio-Language Models",{"className":"page__taxonomy-item","children":["#","Audio-Language Models"]}],["$","span","Auditory Attributes",{"className":"page__taxonomy-item","children":["#","Auditory Attributes"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Reliability",{"className":"page__taxonomy-item","children":["#","Reliability"]}],["$","span","Generality",{"className":"page__taxonomy-item","children":["#","Generality"]}],["$","span","Locality",{"className":"page__taxonomy-item","children":["#","Locality"]}],["$","span","Portability",{"className":"page__taxonomy-item","children":["#","Portability"]}]]}]]}]]}],["$","article","2025-10-24-Open-o3_Video_Grounded_Video_Reasoning_with_Explicit_Spatio-Temporal_Evidence",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-Open-o3_Video_Grounded_Video_Reasoning_with_Explicit_Spatio-Temporal_Evidence/","children":"[논문리뷰] Open-o3 Video: Grounded Video Reasoning with Explicit Spatio-Temporal Evidence"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Open-o3 Video: Grounded Video Reasoning with Explicit Spatio-Temporal Evidence' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Reasoning",{"className":"page__taxonomy-item","children":["#","Video Reasoning"]}],["$","span","Spatio-Temporal Grounding",{"className":"page__taxonomy-item","children":["#","Spatio-Temporal Grounding"]}],["$","span","Large Multimodal Models",{"className":"page__taxonomy-item","children":["#","Large Multimodal Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Visual Evidence",{"className":"page__taxonomy-item","children":["#","Visual Evidence"]}],["$","span","Dataset Curation",{"className":"page__taxonomy-item","children":["#","Dataset Curation"]}]]}]]}]]}],["$","article","2025-10-24-Loopholing_Discrete_Diffusion_Deterministic_Bypass_of_the_Sampling_Wall",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-Loopholing_Discrete_Diffusion_Deterministic_Bypass_of_the_Sampling_Wall/","children":"[논문리뷰] Loopholing Discrete Diffusion: Deterministic Bypass of the Sampling Wall"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Sungjin Ahn이 [arXiv]에 게시한 'Loopholing Discrete Diffusion: Deterministic Bypass of the Sampling Wall' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Discrete Diffusion Models",{"className":"page__taxonomy-item","children":["#","Discrete Diffusion Models"]}],["$","span","Sampling Wall",{"className":"page__taxonomy-item","children":["#","Sampling Wall"]}],["$","span","Loopholing",{"className":"page__taxonomy-item","children":["#","Loopholing"]}],["$","span","Self-Conditioning",{"className":"page__taxonomy-item","children":["#","Self-Conditioning"]}],["$","span","Non-Autoregressive Generation",{"className":"page__taxonomy-item","children":["#","Non-Autoregressive Generation"]}],["$","span","Text Generation",{"className":"page__taxonomy-item","children":["#","Text Generation"]}],["$","span","Language Modeling",{"className":"page__taxonomy-item","children":["#","Language Modeling"]}],["$","span","Reasoning Tasks",{"className":"page__taxonomy-item","children":["#","Reasoning Tasks"]}]]}]]}]]}],["$","article","2025-10-24-LayerComposer_Interactive_Personalized_T2I_via_Spatially-Aware_Layered_Canvas",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-LayerComposer_Interactive_Personalized_T2I_via_Spatially-Aware_Layered_Canvas/","children":"[논문리뷰] LayerComposer: Interactive Personalized T2I via Spatially-Aware Layered Canvas"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'LayerComposer: Interactive Personalized T2I via Spatially-Aware Layered Canvas' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Personalization",{"className":"page__taxonomy-item","children":["#","Personalization"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Interactive Control",{"className":"page__taxonomy-item","children":["#","Interactive Control"]}],["$","span","Multi-Subject Composition",{"className":"page__taxonomy-item","children":["#","Multi-Subject Composition"]}],["$","span","Layered Canvas",{"className":"page__taxonomy-item","children":["#","Layered Canvas"]}],["$","span","Spatial Control",{"className":"page__taxonomy-item","children":["#","Spatial Control"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}]]}]]}]]}],["$","article","2025-10-24-Investigating_Safety_Vulnerabilities_of_Large_Audio-Language_Models_Under_Speaker_Emotional_Variations",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-Investigating_Safety_Vulnerabilities_of_Large_Audio-Language_Models_Under_Speaker_Emotional_Variations/","children":"[논문리뷰] Investigating Safety Vulnerabilities of Large Audio-Language Models Under Speaker Emotional Variations"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Investigating Safety Vulnerabilities of Large Audio-Language Models Under Speaker Emotional Variations' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LALM Safety",{"className":"page__taxonomy-item","children":["#","LALM Safety"]}],["$","span","Speaker Emotion",{"className":"page__taxonomy-item","children":["#","Speaker Emotion"]}],["$","span","Safety Alignment",{"className":"page__taxonomy-item","children":["#","Safety Alignment"]}],["$","span","Jailbreaking",{"className":"page__taxonomy-item","children":["#","Jailbreaking"]}],["$","span","Audio-Language Models",{"className":"page__taxonomy-item","children":["#","Audio-Language Models"]}],["$","span","Emotional Variation",{"className":"page__taxonomy-item","children":["#","Emotional Variation"]}],["$","span","Unsafe Rate",{"className":"page__taxonomy-item","children":["#","Unsafe Rate"]}],["$","span","Non-refusal Rate",{"className":"page__taxonomy-item","children":["#","Non-refusal Rate"]}]]}]]}]]}],["$","article","2025-10-24-ImpossibleBench_Measuring_LLMs_Propensity_of_Exploiting_Test_Cases",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-ImpossibleBench_Measuring_LLMs_Propensity_of_Exploiting_Test_Cases/","children":"[논문리뷰] ImpossibleBench: Measuring LLMs' Propensity of Exploiting Test Cases"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Nicholas Carlini이 [arXiv]에 게시한 'ImpossibleBench: Measuring LLMs' Propensity of Exploiting Test Cases' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Reward Hacking",{"className":"page__taxonomy-item","children":["#","Reward Hacking"]}],["$","span","Benchmark Reliability",{"className":"page__taxonomy-item","children":["#","Benchmark Reliability"]}],["$","span","Test Exploitation",{"className":"page__taxonomy-item","children":["#","Test Exploitation"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","LLM Safety",{"className":"page__taxonomy-item","children":["#","LLM Safety"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}]]}]]}]]}],["$","article","2025-10-24-Human-Agent_Collaborative_Paper-to-Page_Crafting_for_Under_0.1",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-Human-Agent_Collaborative_Paper-to-Page_Crafting_for_Under_0.1/","children":"[논문리뷰] Human-Agent Collaborative Paper-to-Page Crafting for Under $0.1"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Human-Agent Collaborative Paper-to-Page Crafting for Under $0.1' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Human-Agent Collaboration",{"className":"page__taxonomy-item","children":["#","Human-Agent Collaboration"]}],["$","span","Project Page Generation",{"className":"page__taxonomy-item","children":["#","Project Page Generation"]}],["$","span","Multi-Agent System",{"className":"page__taxonomy-item","children":["#","Multi-Agent System"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","VLM",{"className":"page__taxonomy-item","children":["#","VLM"]}],["$","span","Webpage Automation",{"className":"page__taxonomy-item","children":["#","Webpage Automation"]}],["$","span","PageBench",{"className":"page__taxonomy-item","children":["#","PageBench"]}],["$","span","Scientific Communication",{"className":"page__taxonomy-item","children":["#","Scientific Communication"]}],["$","span","Cost-Effective AI",{"className":"page__taxonomy-item","children":["#","Cost-Effective AI"]}]]}]]}]]}],["$","article","2025-10-24-HoloCine_Holistic_Generation_of_Cinematic_Multi-Shot_Long_Video_Narratives",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-HoloCine_Holistic_Generation_of_Cinematic_Multi-Shot_Long_Video_Narratives/","children":"[논문리뷰] HoloCine: Holistic Generation of Cinematic Multi-Shot Long Video Narratives"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'HoloCine: Holistic Generation of Cinematic Multi-Shot Long Video Narratives' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Video Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Video Generation"]}],["$","span","Multi-Shot Video",{"className":"page__taxonomy-item","children":["#","Multi-Shot Video"]}],["$","span","Narrative Coherence",{"className":"page__taxonomy-item","children":["#","Narrative Coherence"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Self-Attention",{"className":"page__taxonomy-item","children":["#","Self-Attention"]}],["$","span","Cinematic AI",{"className":"page__taxonomy-item","children":["#","Cinematic AI"]}],["$","span","Video Consistency",{"className":"page__taxonomy-item","children":["#","Video Consistency"]}],["$","span","Directorial Control",{"className":"page__taxonomy-item","children":["#","Directorial Control"]}]]}]]}]]}],["$","article","2025-10-24-From_Masks_to_Worlds_A_Hitchhikers_Guide_to_World_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-From_Masks_to_Worlds_A_Hitchhikers_Guide_to_World_Models/","children":"[논문리뷰] From Masks to Worlds: A Hitchhiker's Guide to World Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shufan Li이 [arXiv]에 게시한 'From Masks to Worlds: A Hitchhiker's Guide to World Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","World Models",{"className":"page__taxonomy-item","children":["#","World Models"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Masked Modeling",{"className":"page__taxonomy-item","children":["#","Masked Modeling"]}],["$","span","Interactive AI",{"className":"page__taxonomy-item","children":["#","Interactive AI"]}],["$","span","Memory Systems",{"className":"page__taxonomy-item","children":["#","Memory Systems"]}],["$","span","Autonomous Agents",{"className":"page__taxonomy-item","children":["#","Autonomous Agents"]}],["$","span","AI Roadmap",{"className":"page__taxonomy-item","children":["#","AI Roadmap"]}]]}]]}]]}],["$","article","2025-10-24-Every_Question_Has_Its_Own_Value_Reinforcement_Learning_with_Explicit_Human_Values",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-Every_Question_Has_Its_Own_Value_Reinforcement_Learning_with_Explicit_Human_Values/","children":"[논문리뷰] Every Question Has Its Own Value: Reinforcement Learning with Explicit Human Values"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Every Question Has Its Own Value: Reinforcement Learning with Explicit Human Values' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","LLM Alignment",{"className":"page__taxonomy-item","children":["#","LLM Alignment"]}],["$","span","Human Values",{"className":"page__taxonomy-item","children":["#","Human Values"]}],["$","span","Reward Shaping",{"className":"page__taxonomy-item","children":["#","Reward Shaping"]}],["$","span","Value-Weighted Reward",{"className":"page__taxonomy-item","children":["#","Value-Weighted Reward"]}],["$","span","Termination Policy",{"className":"page__taxonomy-item","children":["#","Termination Policy"]}],["$","span","RLVR",{"className":"page__taxonomy-item","children":["#","RLVR"]}]]}]]}]]}],["$","article","2025-10-24-Emergence_of_Linear_Truth_Encodings_in_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-Emergence_of_Linear_Truth_Encodings_in_Language_Models/","children":"[논문리뷰] Emergence of Linear Truth Encodings in Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Alberto Bietti이 [arXiv]에 게시한 'Emergence of Linear Truth Encodings in Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Language Models",{"className":"page__taxonomy-item","children":["#","Language Models"]}],["$","span","Truth Encoding",{"className":"page__taxonomy-item","children":["#","Truth Encoding"]}],["$","span","Linear Subspaces",{"className":"page__taxonomy-item","children":["#","Linear Subspaces"]}],["$","span","Mechanistic Interpretability",{"className":"page__taxonomy-item","children":["#","Mechanistic Interpretability"]}],["$","span","Transformer Models",{"className":"page__taxonomy-item","children":["#","Transformer Models"]}],["$","span","Learning Dynamics",{"className":"page__taxonomy-item","children":["#","Learning Dynamics"]}],["$","span","Truth Co-occurrence Hypothesis",{"className":"page__taxonomy-item","children":["#","Truth Co-occurrence Hypothesis"]}],["$","span","Hallucinations",{"className":"page__taxonomy-item","children":["#","Hallucinations"]}]]}]]}]]}],["$","article","2025-10-24-DyPE_Dynamic_Position_Extrapolation_for_Ultra_High_Resolution_Diffusion",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-DyPE_Dynamic_Position_Extrapolation_for_Ultra_High_Resolution_Diffusion/","children":"[논문리뷰] DyPE: Dynamic Position Extrapolation for Ultra High Resolution Diffusion"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DyPE: Dynamic Position Extrapolation for Ultra High Resolution Diffusion' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Positional Encoding",{"className":"page__taxonomy-item","children":["#","Positional Encoding"]}],["$","span","High-Resolution Image Generation",{"className":"page__taxonomy-item","children":["#","High-Resolution Image Generation"]}],["$","span","Extrapolation",{"className":"page__taxonomy-item","children":["#","Extrapolation"]}],["$","span","Dynamic Adaptation",{"className":"page__taxonomy-item","children":["#","Dynamic Adaptation"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}]]}]]}]]}],["$","article","2025-10-24-Diff-XYZ_A_Benchmark_for_Evaluating_Diff_Understanding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-Diff-XYZ_A_Benchmark_for_Evaluating_Diff_Understanding/","children":"[논문리뷰] Diff-XYZ: A Benchmark for Evaluating Diff Understanding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Diff-XYZ: A Benchmark for Evaluating Diff Understanding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diff Understanding",{"className":"page__taxonomy-item","children":["#","Diff Understanding"]}],["$","span","Code Diff",{"className":"page__taxonomy-item","children":["#","Code Diff"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Code Editing",{"className":"page__taxonomy-item","children":["#","Code Editing"]}],["$","span","Software Engineering",{"className":"page__taxonomy-item","children":["#","Software Engineering"]}],["$","span","Unified Diff Format",{"className":"page__taxonomy-item","children":["#","Unified Diff Format"]}],["$","span","Search-Replace",{"className":"page__taxonomy-item","children":["#","Search-Replace"]}]]}]]}]]}],["$","article","2025-10-24-Conan_Progressive_Learning_to_Reason_Like_a_Detective_over_Multi-Scale_Visual_Evidence",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-Conan_Progressive_Learning_to_Reason_Like_a_Detective_over_Multi-Scale_Visual_Evidence/","children":"[논문리뷰] Conan: Progressive Learning to Reason Like a Detective over Multi-Scale Visual Evidence"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Conan: Progressive Learning to Reason Like a Detective over Multi-Scale Visual Evidence' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Reasoning",{"className":"page__taxonomy-item","children":["#","Video Reasoning"]}],["$","span","Multimodal Large Language Models (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models (MLLMs)"]}],["$","span","Reinforcement Learning (RLVR)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RLVR)"]}],["$","span","Evidence Grounding",{"className":"page__taxonomy-item","children":["#","Evidence Grounding"]}],["$","span","Multi-step Reasoning",{"className":"page__taxonomy-item","children":["#","Multi-step Reasoning"]}],["$","span","Frame Retrieval",{"className":"page__taxonomy-item","children":["#","Frame Retrieval"]}],["$","span","Dataset Construction",{"className":"page__taxonomy-item","children":["#","Dataset Construction"]}],["$","span","Progressive Learning",{"className":"page__taxonomy-item","children":["#","Progressive Learning"]}]]}]]}]]}],["$","article","2025-10-24-ComProScanner_A_multi-agent_based_framework_for_composition-property_structured_data_extraction_from_scientific_literature",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-ComProScanner_A_multi-agent_based_framework_for_composition-property_structured_data_extraction_from_scientific_literature/","children":"[논문리뷰] ComProScanner: A multi-agent based framework for composition-property structured data extraction from scientific literature"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'ComProScanner: A multi-agent based framework for composition-property structured data extraction from scientific literature' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-agent Systems"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Information Extraction",{"className":"page__taxonomy-item","children":["#","Information Extraction"]}],["$","span","Scientific Literature",{"className":"page__taxonomy-item","children":["#","Scientific Literature"]}],["$","span","Materials Science",{"className":"page__taxonomy-item","children":["#","Materials Science"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Piezoelectric Materials",{"className":"page__taxonomy-item","children":["#","Piezoelectric Materials"]}],["$","span","RAG (Retrieval-Augmented Generation)",{"className":"page__taxonomy-item","children":["#","RAG (Retrieval-Augmented Generation)"]}]]}]]}]]}],["$","article","2025-10-24-ARGenSeg_Image_Segmentation_with_Autoregressive_Image_Generation_Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-ARGenSeg_Image_Segmentation_with_Autoregressive_Image_Generation_Model/","children":"[논문리뷰] ARGenSeg: Image Segmentation with Autoregressive Image Generation Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'ARGenSeg: Image Segmentation with Autoregressive Image Generation Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Segmentation",{"className":"page__taxonomy-item","children":["#","Image Segmentation"]}],["$","span","Autoregressive Generation",{"className":"page__taxonomy-item","children":["#","Autoregressive Generation"]}],["$","span","Multimodal Large Language Models (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models (MLLMs)"]}],["$","span","Visual Understanding",{"className":"page__taxonomy-item","children":["#","Visual Understanding"]}],["$","span","VQ-VAE",{"className":"page__taxonomy-item","children":["#","VQ-VAE"]}],["$","span","Multi-scale Prediction",{"className":"page__taxonomy-item","children":["#","Multi-scale Prediction"]}],["$","span","Referring Expression Segmentation",{"className":"page__taxonomy-item","children":["#","Referring Expression Segmentation"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}]]}]]}]]}],["$","article","2025-10-24-AlphaFlow_Understanding_and_Improving_MeanFlow_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-AlphaFlow_Understanding_and_Improving_MeanFlow_Models/","children":"[논문리뷰] AlphaFlow: Understanding and Improving MeanFlow Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'AlphaFlow: Understanding and Improving MeanFlow Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Consistency Models",{"className":"page__taxonomy-item","children":["#","Consistency Models"]}],["$","span","MeanFlow",{"className":"page__taxonomy-item","children":["#","MeanFlow"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Few-Step Generation",{"className":"page__taxonomy-item","children":["#","Few-Step Generation"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}]]}]]}]]}],["$","article","2025-10-24-AdaSPEC_Selective_Knowledge_Distillation_for_Efficient_Speculative_Decoders",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-24-AdaSPEC_Selective_Knowledge_Distillation_for_Efficient_Speculative_Decoders/","children":"[논문리뷰] AdaSPEC: Selective Knowledge Distillation for Efficient Speculative Decoders"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'AdaSPEC: Selective Knowledge Distillation for Efficient Speculative Decoders' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-24 13:04:16+0900","children":"2025년 10월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Speculative Decoding",{"className":"page__taxonomy-item","children":["#","Speculative Decoding"]}],["$","span","Knowledge Distillation",{"className":"page__taxonomy-item","children":["#","Knowledge Distillation"]}],["$","span","LLM Inference",{"className":"page__taxonomy-item","children":["#","LLM Inference"]}],["$","span","Model Acceleration",{"className":"page__taxonomy-item","children":["#","Model Acceleration"]}],["$","span","Token Filtering",{"className":"page__taxonomy-item","children":["#","Token Filtering"]}],["$","span","Draft Model",{"className":"page__taxonomy-item","children":["#","Draft Model"]}],["$","span","Acceptance Rate",{"className":"page__taxonomy-item","children":["#","Acceptance Rate"]}]]}]]}]]}],["$","article","2025-10-23-VideoAgentTrek_Computer_Use_Pretraining_from_Unlabeled_Videos",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-VideoAgentTrek_Computer_Use_Pretraining_from_Unlabeled_Videos/","children":"[논문리뷰] VideoAgentTrek: Computer Use Pretraining from Unlabeled Videos"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xinyuan Wang이 [arXiv]에 게시한 'VideoAgentTrek: Computer Use Pretraining from Unlabeled Videos' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","GUI Agents",{"className":"page__taxonomy-item","children":["#","GUI Agents"]}],["$","span","Video Pretraining",{"className":"page__taxonomy-item","children":["#","Video Pretraining"]}],["$","span","Inverse Dynamics",{"className":"page__taxonomy-item","children":["#","Inverse Dynamics"]}],["$","span","Action Recognition",{"className":"page__taxonomy-item","children":["#","Action Recognition"]}],["$","span","Computer Use Automation",{"className":"page__taxonomy-item","children":["#","Computer Use Automation"]}],["$","span","Data Synthesis",{"className":"page__taxonomy-item","children":["#","Data Synthesis"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}]]}]]}]]}],["$","article","2025-10-23-Unified_Reinforcement_and_Imitation_Learning_for_Vision-Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-Unified_Reinforcement_and_Imitation_Learning_for_Vision-Language_Models/","children":"[논문리뷰] Unified Reinforcement and Imitation Learning for Vision-Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Unified Reinforcement and Imitation Learning for Vision-Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Imitation Learning",{"className":"page__taxonomy-item","children":["#","Imitation Learning"]}],["$","span","Model Distillation",{"className":"page__taxonomy-item","children":["#","Model Distillation"]}],["$","span","Lightweight VLMs",{"className":"page__taxonomy-item","children":["#","Lightweight VLMs"]}],["$","span","LLM-as-a-Judge",{"className":"page__taxonomy-item","children":["#","LLM-as-a-Judge"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}]]}]]}]]}],["$","article","2025-10-23-RIR-Mega_a_large-scale_simulated_room_impulse_response_dataset_for_machine_learning_and_room_acoustics_modeling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-RIR-Mega_a_large-scale_simulated_room_impulse_response_dataset_for_machine_learning_and_room_acoustics_modeling/","children":"[논문리뷰] RIR-Mega: a large-scale simulated room impulse response dataset for machine learning and room acoustics modeling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Mandip Goswami이 [arXiv]에 게시한 'RIR-Mega: a large-scale simulated room impulse response dataset for machine learning and room acoustics modeling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Room Impulse Response",{"className":"page__taxonomy-item","children":["#","Room Impulse Response"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}],["$","span","Room Acoustics",{"className":"page__taxonomy-item","children":["#","Room Acoustics"]}],["$","span","Machine Learning",{"className":"page__taxonomy-item","children":["#","Machine Learning"]}],["$","span","Dereverberation",{"className":"page__taxonomy-item","children":["#","Dereverberation"]}],["$","span","Speech Recognition",{"className":"page__taxonomy-item","children":["#","Speech Recognition"]}],["$","span","Simulation",{"className":"page__taxonomy-item","children":["#","Simulation"]}],["$","span","Hugging Face",{"className":"page__taxonomy-item","children":["#","Hugging Face"]}]]}]]}]]}],["$","article","2025-10-23-ProfBench_Multi-Domain_Rubrics_requiring_Professional_Knowledge_to_Answer_and_Judge",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-ProfBench_Multi-Domain_Rubrics_requiring_Professional_Knowledge_to_Answer_and_Judge/","children":"[논문리뷰] ProfBench: Multi-Domain Rubrics requiring Professional Knowledge to Answer and Judge"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'ProfBench: Multi-Domain Rubrics requiring Professional Knowledge to Answer and Judge' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Rubric-based Benchmark",{"className":"page__taxonomy-item","children":["#","Rubric-based Benchmark"]}],["$","span","Professional Knowledge",{"className":"page__taxonomy-item","children":["#","Professional Knowledge"]}],["$","span","Multi-domain Tasks",{"className":"page__taxonomy-item","children":["#","Multi-domain Tasks"]}],["$","span","LLM-Judge Bias Mitigation",{"className":"page__taxonomy-item","children":["#","LLM-Judge Bias Mitigation"]}],["$","span","Cost Reduction",{"className":"page__taxonomy-item","children":["#","Cost Reduction"]}],["$","span","Reasoning Assessment",{"className":"page__taxonomy-item","children":["#","Reasoning Assessment"]}],["$","span","Open-weight Models",{"className":"page__taxonomy-item","children":["#","Open-weight Models"]}]]}]]}]]}],["$","article","2025-10-23-Pico-Banana-400K_A_Large-Scale_Dataset_for_Text-Guided_Image_Editing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-Pico-Banana-400K_A_Large-Scale_Dataset_for_Text-Guided_Image_Editing/","children":"[논문리뷰] Pico-Banana-400K: A Large-Scale Dataset for Text-Guided Image Editing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Pico-Banana-400K: A Large-Scale Dataset for Text-Guided Image Editing' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-Guided Image Editing",{"className":"page__taxonomy-item","children":["#","Text-Guided Image Editing"]}],["$","span","Large-Scale Dataset",{"className":"page__taxonomy-item","children":["#","Large-Scale Dataset"]}],["$","span","Multimodal Models",{"className":"page__taxonomy-item","children":["#","Multimodal Models"]}],["$","span","Dataset Curation",{"className":"page__taxonomy-item","children":["#","Dataset Curation"]}],["$","span","Quality Control",{"className":"page__taxonomy-item","children":["#","Quality Control"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","Preference Learning",{"className":"page__taxonomy-item","children":["#","Preference Learning"]}],["$","span","Multi-Turn Editing",{"className":"page__taxonomy-item","children":["#","Multi-Turn Editing"]}]]}]]}]]}],["$","article","2025-10-23-OmniNWM_Omniscient_Driving_Navigation_World_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-OmniNWM_Omniscient_Driving_Navigation_World_Models/","children":"[논문리뷰] OmniNWM: Omniscient Driving Navigation World Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhujin Liang이 [arXiv]에 게시한 'OmniNWM: Omniscient Driving Navigation World Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Autonomous Driving",{"className":"page__taxonomy-item","children":["#","Autonomous Driving"]}],["$","span","World Models",{"className":"page__taxonomy-item","children":["#","World Models"]}],["$","span","Multi-modal Generation",{"className":"page__taxonomy-item","children":["#","Multi-modal Generation"]}],["$","span","3D Occupancy",{"className":"page__taxonomy-item","children":["#","3D Occupancy"]}],["$","span","Plücker Ray-maps",{"className":"page__taxonomy-item","children":["#","Plücker Ray-maps"]}],["$","span","Action Control",{"className":"page__taxonomy-item","children":["#","Action Control"]}],["$","span","Dense Rewards",{"className":"page__taxonomy-item","children":["#","Dense Rewards"]}],["$","span","Long-term Forecasting",{"className":"page__taxonomy-item","children":["#","Long-term Forecasting"]}]]}]]}]]}],["$","article","2025-10-23-olmOCR_2_Unit_Test_Rewards_for_Document_OCR",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-olmOCR_2_Unit_Test_Rewards_for_Document_OCR/","children":"[논문리뷰] olmOCR 2: Unit Test Rewards for Document OCR"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'olmOCR 2: Unit Test Rewards for Document OCR' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Document OCR",{"className":"page__taxonomy-item","children":["#","Document OCR"]}],["$","span","Vision Language Model",{"className":"page__taxonomy-item","children":["#","Vision Language Model"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Unit Tests",{"className":"page__taxonomy-item","children":["#","Unit Tests"]}],["$","span","Synthetic Data Generation",{"className":"page__taxonomy-item","children":["#","Synthetic Data Generation"]}],["$","span","RLVR",{"className":"page__taxonomy-item","children":["#","RLVR"]}],["$","span","Document Parsing",{"className":"page__taxonomy-item","children":["#","Document Parsing"]}],["$","span","State-of-the-Art OCR",{"className":"page__taxonomy-item","children":["#","State-of-the-Art OCR"]}]]}]]}]]}],["$","article","2025-10-23-MINED_Probing_and_Updating_with_Multimodal_Time-Sensitive_Knowledge_for_Large_Multimodal_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-MINED_Probing_and_Updating_with_Multimodal_Time-Sensitive_Knowledge_for_Large_Multimodal_Models/","children":"[논문리뷰] MINED: Probing and Updating with Multimodal Time-Sensitive Knowledge for Large Multimodal Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yifan Gao이 [arXiv]에 게시한 'MINED: Probing and Updating with Multimodal Time-Sensitive Knowledge for Large Multimodal Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Multimodal Models (LMMs)",{"className":"page__taxonomy-item","children":["#","Large Multimodal Models (LMMs)"]}],["$","span","Time-Sensitive Knowledge",{"className":"page__taxonomy-item","children":["#","Time-Sensitive Knowledge"]}],["$","span","Temporal Reasoning",{"className":"page__taxonomy-item","children":["#","Temporal Reasoning"]}],["$","span","Knowledge Editing",{"className":"page__taxonomy-item","children":["#","Knowledge Editing"]}],["$","span","Multimodal Benchmarking",{"className":"page__taxonomy-item","children":["#","Multimodal Benchmarking"]}],["$","span","Temporal Awareness",{"className":"page__taxonomy-item","children":["#","Temporal Awareness"]}],["$","span","Dynamic Knowledge",{"className":"page__taxonomy-item","children":["#","Dynamic Knowledge"]}]]}]]}]]}],["$","article","2025-10-23-Machine_Text_Detectors_are_Membership_Inference_Attacks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-Machine_Text_Detectors_are_Membership_Inference_Attacks/","children":"[논문리뷰] Machine Text Detectors are Membership Inference Attacks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Naoaki Okazaki이 [arXiv]에 게시한 'Machine Text Detectors are Membership Inference Attacks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Membership Inference Attacks",{"className":"page__taxonomy-item","children":["#","Membership Inference Attacks"]}],["$","span","Machine-Generated Text Detection",{"className":"page__taxonomy-item","children":["#","Machine-Generated Text Detection"]}],["$","span","Transferability",{"className":"page__taxonomy-item","children":["#","Transferability"]}],["$","span","Likelihood Ratio Test",{"className":"page__taxonomy-item","children":["#","Likelihood Ratio Test"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Zero-Shot Detection",{"className":"page__taxonomy-item","children":["#","Zero-Shot Detection"]}],["$","span","Model Security",{"className":"page__taxonomy-item","children":["#","Model Security"]}],["$","span","AI Safety",{"className":"page__taxonomy-item","children":["#","AI Safety"]}]]}]]}]]}],["$","article","2025-10-23-LoongRLReinforcement_Learning_for_Advanced_Reasoning_over_Long_Contexts",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-LoongRLReinforcement_Learning_for_Advanced_Reasoning_over_Long_Contexts/","children":"[논문리뷰] LoongRL:Reinforcement Learning for Advanced Reasoning over Long Contexts"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'LoongRL:Reinforcement Learning for Advanced Reasoning over Long Contexts' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Long Context Reasoning",{"className":"page__taxonomy-item","children":["#","Long Context Reasoning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Multi-hop QA",{"className":"page__taxonomy-item","children":["#","Multi-hop QA"]}],["$","span","Data Synthesis",{"className":"page__taxonomy-item","children":["#","Data Synthesis"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}]]}]]}]]}],["$","article","2025-10-23-Learning_from_the_Best_Differently_A_Diversity-Driven_Rethinking_on_Data_Selection",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-Learning_from_the_Best_Differently_A_Diversity-Driven_Rethinking_on_Data_Selection/","children":"[논문리뷰] Learning from the Best, Differently: A Diversity-Driven Rethinking on Data Selection"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yi Cheng이 [arXiv]에 게시한 'Learning from the Best, Differently: A Diversity-Driven Rethinking on Data Selection' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Data Selection",{"className":"page__taxonomy-item","children":["#","Data Selection"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Data Diversity",{"className":"page__taxonomy-item","children":["#","Data Diversity"]}],["$","span","Data Quality",{"className":"page__taxonomy-item","children":["#","Data Quality"]}],["$","span","Principal Component Analysis (PCA)",{"className":"page__taxonomy-item","children":["#","Principal Component Analysis (PCA)"]}],["$","span","Orthogonal Dimensions",{"className":"page__taxonomy-item","children":["#","Orthogonal Dimensions"]}],["$","span","Pre-training",{"className":"page__taxonomy-item","children":["#","Pre-training"]}]]}]]}]]}],["$","article","2025-10-23-Language_Models_are_Injective_and_Hence_Invertible",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-Language_Models_are_Injective_and_Hence_Invertible/","children":"[논문리뷰] Language Models are Injective and Hence Invertible"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Language Models are Injective and Hence Invertible' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Language Models",{"className":"page__taxonomy-item","children":["#","Language Models"]}],["$","span","Injectivity",{"className":"page__taxonomy-item","children":["#","Injectivity"]}],["$","span","Invertibility",{"className":"page__taxonomy-item","children":["#","Invertibility"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Representation Learning",{"className":"page__taxonomy-item","children":["#","Representation Learning"]}],["$","span","Exact Recovery",{"className":"page__taxonomy-item","children":["#","Exact Recovery"]}],["$","span","SIPIT Algorithm",{"className":"page__taxonomy-item","children":["#","SIPIT Algorithm"]}],["$","span","Real Analysis",{"className":"page__taxonomy-item","children":["#","Real Analysis"]}]]}]]}]]}],["$","article","2025-10-23-KORE_Enhancing_Knowledge_Injection_for_Large_Multimodal_Models_via_Knowledge-Oriented_Augmentations_and_Constraints",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-KORE_Enhancing_Knowledge_Injection_for_Large_Multimodal_Models_via_Knowledge-Oriented_Augmentations_and_Constraints/","children":"[논문리뷰] KORE: Enhancing Knowledge Injection for Large Multimodal Models via Knowledge-Oriented Augmentations and Constraints"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jinhe Bi이 [arXiv]에 게시한 'KORE: Enhancing Knowledge Injection for Large Multimodal Models via Knowledge-Oriented Augmentations and Constraints' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Knowledge Injection",{"className":"page__taxonomy-item","children":["#","Knowledge Injection"]}],["$","span","Large Multimodal Models",{"className":"page__taxonomy-item","children":["#","Large Multimodal Models"]}],["$","span","Catastrophic Forgetting",{"className":"page__taxonomy-item","children":["#","Catastrophic Forgetting"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}],["$","span","Parameter-Efficient Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Parameter-Efficient Fine-Tuning"]}],["$","span","Null Space",{"className":"page__taxonomy-item","children":["#","Null Space"]}],["$","span","Continual Learning",{"className":"page__taxonomy-item","children":["#","Continual Learning"]}]]}]]}]]}],["$","article","2025-10-23-GigaBrain-0_A_World_Model-Powered_Vision-Language-Action_Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-GigaBrain-0_A_World_Model-Powered_Vision-Language-Action_Model/","children":"[논문리뷰] GigaBrain-0: A World Model-Powered Vision-Language-Action Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'GigaBrain-0: A World Model-Powered Vision-Language-Action Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action Model",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action Model"]}],["$","span","World Model",{"className":"page__taxonomy-item","children":["#","World Model"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}],["$","span","Robot Generalization",{"className":"page__taxonomy-item","children":["#","Robot Generalization"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","RGBD",{"className":"page__taxonomy-item","children":["#","RGBD"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}]]}]]}]]}],["$","article","2025-10-23-From_Charts_to_Code_A_Hierarchical_Benchmark_for_Multimodal_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-From_Charts_to_Code_A_Hierarchical_Benchmark_for_Multimodal_Models/","children":"[논문리뷰] From Charts to Code: A Hierarchical Benchmark for Multimodal Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Dongxing Mao이 [arXiv]에 게시한 'From Charts to Code: A Hierarchical Benchmark for Multimodal Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Chart-to-Code",{"className":"page__taxonomy-item","children":["#","Chart-to-Code"]}],["$","span","Multimodal Models",{"className":"page__taxonomy-item","children":["#","Multimodal Models"]}],["$","span","Hierarchical Benchmark",{"className":"page__taxonomy-item","children":["#","Hierarchical Benchmark"]}],["$","span","Chart Understanding",{"className":"page__taxonomy-item","children":["#","Chart Understanding"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","Evaluation Metrics",{"className":"page__taxonomy-item","children":["#","Evaluation Metrics"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}]]}]]}]]}],["$","article","2025-10-23-FinSight_Towards_Real-World_Financial_Deep_Research",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-FinSight_Towards_Real-World_Financial_Deep_Research/","children":"[논문리뷰] FinSight: Towards Real-World Financial Deep Research"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yutao Zhu이 [arXiv]에 게시한 'FinSight: Towards Real-World Financial Deep Research' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Financial Research",{"className":"page__taxonomy-item","children":["#","Financial Research"]}],["$","span","Multi-Agent System",{"className":"page__taxonomy-item","children":["#","Multi-Agent System"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","Multimodal Reports",{"className":"page__taxonomy-item","children":["#","Multimodal Reports"]}],["$","span","Iterative Visualization",{"className":"page__taxonomy-item","children":["#","Iterative Visualization"]}],["$","span","Variable Memory",{"className":"page__taxonomy-item","children":["#","Variable Memory"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}]]}]]}]]}],["$","article","2025-10-23-Every_Attention_Matters_An_Efficient_Hybrid_Architecture_for_Long-Context_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-Every_Attention_Matters_An_Efficient_Hybrid_Architecture_for_Long-Context_Reasoning/","children":"[논문리뷰] Every Attention Matters: An Efficient Hybrid Architecture for Long-Context Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Every Attention Matters: An Efficient Hybrid Architecture for Long-Context Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Long-Context LLM",{"className":"page__taxonomy-item","children":["#","Long-Context LLM"]}],["$","span","Hybrid Attention",{"className":"page__taxonomy-item","children":["#","Hybrid Attention"]}],["$","span","Linear Attention",{"className":"page__taxonomy-item","children":["#","Linear Attention"]}],["$","span","Mixture-of-Experts",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts"]}],["$","span","FP8 Training",{"className":"page__taxonomy-item","children":["#","FP8 Training"]}],["$","span","GPU Optimization",{"className":"page__taxonomy-item","children":["#","GPU Optimization"]}],["$","span","Training-Inference Alignment",{"className":"page__taxonomy-item","children":["#","Training-Inference Alignment"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}]]}]]}]]}],["$","article","2025-10-23-Directional_Reasoning_Injection_for_Fine-Tuning_MLLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-Directional_Reasoning_Injection_for_Fine-Tuning_MLLMs/","children":"[논문리뷰] Directional Reasoning Injection for Fine-Tuning MLLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jialian Wu이 [arXiv]에 게시한 'Directional Reasoning Injection for Fine-Tuning MLLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Reasoning Transfer",{"className":"page__taxonomy-item","children":["#","Reasoning Transfer"]}],["$","span","Gradient-based Fine-tuning",{"className":"page__taxonomy-item","children":["#","Gradient-based Fine-tuning"]}],["$","span","Model Merging",{"className":"page__taxonomy-item","children":["#","Model Merging"]}],["$","span","Parameter-Efficient Learning",{"className":"page__taxonomy-item","children":["#","Parameter-Efficient Learning"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Directional Prior",{"className":"page__taxonomy-item","children":["#","Directional Prior"]}]]}]]}]]}],["$","article","2025-10-23-DeLeaker_Dynamic_Inference-Time_Reweighting_For_Semantic_Leakage_Mitigation_in_Text-to-Image_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-DeLeaker_Dynamic_Inference-Time_Reweighting_For_Semantic_Leakage_Mitigation_in_Text-to-Image_Models/","children":"[논문리뷰] DeLeaker: Dynamic Inference-Time Reweighting For Semantic Leakage Mitigation in Text-to-Image Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Roi Reichart이 [arXiv]에 게시한 'DeLeaker: Dynamic Inference-Time Reweighting For Semantic Leakage Mitigation in Text-to-Image Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Semantic Leakage",{"className":"page__taxonomy-item","children":["#","Semantic Leakage"]}],["$","span","Text-to-Image Models",{"className":"page__taxonomy-item","children":["#","Text-to-Image Models"]}],["$","span","Attention Control",{"className":"page__taxonomy-item","children":["#","Attention Control"]}],["$","span","Inference-time Mitigation",{"className":"page__taxonomy-item","children":["#","Inference-time Mitigation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Evaluation Dataset",{"className":"page__taxonomy-item","children":["#","Evaluation Dataset"]}],["$","span","Self-Attention",{"className":"page__taxonomy-item","children":["#","Self-Attention"]}]]}]]}]]}],["$","article","2025-10-23-DaMo_Data_Mixing_Optimizer_in_Fine-tuning_Multimodal_LLMs_for_Mobile_Phone_Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-DaMo_Data_Mixing_Optimizer_in_Fine-tuning_Multimodal_LLMs_for_Mobile_Phone_Agents/","children":"[논문리뷰] DaMo: Data Mixing Optimizer in Fine-tuning Multimodal LLMs for Mobile Phone Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DaMo: Data Mixing Optimizer in Fine-tuning Multimodal LLMs for Mobile Phone Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Data Mixing Optimization",{"className":"page__taxonomy-item","children":["#","Data Mixing Optimization"]}],["$","span","Mobile Phone Agents",{"className":"page__taxonomy-item","children":["#","Mobile Phone Agents"]}],["$","span","Downstream Task Prediction",{"className":"page__taxonomy-item","children":["#","Downstream Task Prediction"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Neural Networks",{"className":"page__taxonomy-item","children":["#","Neural Networks"]}]]}]]}]]}],["$","article","2025-10-23-ColorAgent_Building_A_Robust_Personalized_and_Interactive_OS_Agent",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-ColorAgent_Building_A_Robust_Personalized_and_Interactive_OS_Agent/","children":"[논문리뷰] ColorAgent: Building A Robust, Personalized, and Interactive OS Agent"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Weiming Zhang이 [arXiv]에 게시한 'ColorAgent: Building A Robust, Personalized, and Interactive OS Agent' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","OS Agent",{"className":"page__taxonomy-item","children":["#","OS Agent"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Multi-agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-agent Systems"]}],["$","span","Personalization",{"className":"page__taxonomy-item","children":["#","Personalization"]}],["$","span","Proactive Interaction",{"className":"page__taxonomy-item","children":["#","Proactive Interaction"]}],["$","span","GUI Agents",{"className":"page__taxonomy-item","children":["#","GUI Agents"]}],["$","span","Self-Evolving Training",{"className":"page__taxonomy-item","children":["#","Self-Evolving Training"]}]]}]]}]]}],["$","article","2025-10-23-BAPO_Stabilizing_Off-Policy_Reinforcement_Learning_for_LLMs_via_Balanced_Policy_Optimization_with_Adaptive_Clipping",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-BAPO_Stabilizing_Off-Policy_Reinforcement_Learning_for_LLMs_via_Balanced_Policy_Optimization_with_Adaptive_Clipping/","children":"[논문리뷰] BAPO: Stabilizing Off-Policy Reinforcement Learning for LLMs via Balanced Policy Optimization with Adaptive Clipping"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Junrui Shen이 [arXiv]에 게시한 'BAPO: Stabilizing Off-Policy Reinforcement Learning for LLMs via Balanced Policy Optimization with Adaptive Clipping' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Off-Policy Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Off-Policy Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Adaptive Clipping",{"className":"page__taxonomy-item","children":["#","Adaptive Clipping"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","PPO",{"className":"page__taxonomy-item","children":["#","PPO"]}],["$","span","Entropy Preservation",{"className":"page__taxonomy-item","children":["#","Entropy Preservation"]}],["$","span","RL Stabilization",{"className":"page__taxonomy-item","children":["#","RL Stabilization"]}]]}]]}]]}],["$","article","2025-10-23-Attention_Sinks_in_Diffusion_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-Attention_Sinks_in_Diffusion_Language_Models/","children":"[논문리뷰] Attention Sinks in Diffusion Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Simone Scardapane이 [arXiv]에 게시한 'Attention Sinks in Diffusion Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Language Models",{"className":"page__taxonomy-item","children":["#","Diffusion Language Models"]}],["$","span","Attention Sinks",{"className":"page__taxonomy-item","children":["#","Attention Sinks"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Masked Language Modeling",{"className":"page__taxonomy-item","children":["#","Masked Language Modeling"]}],["$","span","Bidirectional Attention",{"className":"page__taxonomy-item","children":["#","Bidirectional Attention"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Robustness",{"className":"page__taxonomy-item","children":["#","Robustness"]}],["$","span","Dynamic Attention",{"className":"page__taxonomy-item","children":["#","Dynamic Attention"]}]]}]]}]]}],["$","article","2025-10-23-AlphaOPT_Formulating_Optimization_Programs_with_Self-Improving_LLM_Experience_Library",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-23-AlphaOPT_Formulating_Optimization_Programs_with_Self-Improving_LLM_Experience_Library/","children":"[논문리뷰] AlphaOPT: Formulating Optimization Programs with Self-Improving LLM Experience Library"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chonghe Jiang이 [arXiv]에 게시한 'AlphaOPT: Formulating Optimization Programs with Self-Improving LLM Experience Library' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-23 13:08:59+0900","children":"2025년 10월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Optimization Modeling",{"className":"page__taxonomy-item","children":["#","Optimization Modeling"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Experience Library",{"className":"page__taxonomy-item","children":["#","Experience Library"]}],["$","span","Self-Improving Systems",{"className":"page__taxonomy-item","children":["#","Self-Improving Systems"]}],["$","span","Continual Learning",{"className":"page__taxonomy-item","children":["#","Continual Learning"]}],["$","span","Out-of-Distribution Generalization",{"className":"page__taxonomy-item","children":["#","Out-of-Distribution Generalization"]}],["$","span","Operations Research",{"className":"page__taxonomy-item","children":["#","Operations Research"]}],["$","span","Knowledge Representation",{"className":"page__taxonomy-item","children":["#","Knowledge Representation"]}]]}]]}]]}],["$","article","2025-10-22-World-in-World_World_Models_in_a_Closed-Loop_World",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-World-in-World_World_Models_in_a_Closed-Loop_World/","children":"[논문리뷰] World-in-World: World Models in a Closed-Loop World"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Arda Uzunoglu이 [arXiv]에 게시한 'World-in-World: World Models in a Closed-Loop World' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","World Models",{"className":"page__taxonomy-item","children":["#","World Models"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Closed-Loop Evaluation",{"className":"page__taxonomy-item","children":["#","Closed-Loop Evaluation"]}],["$","span","Online Planning",{"className":"page__taxonomy-item","children":["#","Online Planning"]}],["$","span","Data Scaling",{"className":"page__taxonomy-item","children":["#","Data Scaling"]}],["$","span","Controllability",{"className":"page__taxonomy-item","children":["#","Controllability"]}],["$","span","Robotic Manipulation",{"className":"page__taxonomy-item","children":["#","Robotic Manipulation"]}]]}]]}]]}],["$","article","2025-10-22-Video_Reasoning_without_Training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-Video_Reasoning_without_Training/","children":"[논문리뷰] Video Reasoning without Training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Video Reasoning without Training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Reasoning",{"className":"page__taxonomy-item","children":["#","Video Reasoning"]}],["$","span","Large Multimodal Models (LMMs)",{"className":"page__taxonomy-item","children":["#","Large Multimodal Models (LMMs)"]}],["$","span","Inference-Time Optimization",{"className":"page__taxonomy-item","children":["#","Inference-Time Optimization"]}],["$","span","Entropy-Based Objective",{"className":"page__taxonomy-item","children":["#","Entropy-Based Objective"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}],["$","span","KV-Cache Steering",{"className":"page__taxonomy-item","children":["#","KV-Cache Steering"]}],["$","span","Micro-Exploration",{"className":"page__taxonomy-item","children":["#","Micro-Exploration"]}],["$","span","Macro-Exploitation",{"className":"page__taxonomy-item","children":["#","Macro-Exploitation"]}]]}]]}]]}],["$","article","2025-10-22-Unleashing_Scientific_Reasoning_for_Bio-experimental_Protocol_Generation_via_Structured_Component-based_Reward_Mechanism",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-Unleashing_Scientific_Reasoning_for_Bio-experimental_Protocol_Generation_via_Structured_Component-based_Reward_Mechanism/","children":"[논문리뷰] Unleashing Scientific Reasoning for Bio-experimental Protocol Generation via Structured Component-based Reward Mechanism"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shuang Gu이 [arXiv]에 게시한 'Unleashing Scientific Reasoning for Bio-experimental Protocol Generation via Structured Component-based Reward Mechanism' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Scientific Reasoning",{"className":"page__taxonomy-item","children":["#","Scientific Reasoning"]}],["$","span","Bio-experimental Protocol Generation",{"className":"page__taxonomy-item","children":["#","Bio-experimental Protocol Generation"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Structured Reward",{"className":"page__taxonomy-item","children":["#","Structured Reward"]}],["$","span","SciRecipe Dataset",{"className":"page__taxonomy-item","children":["#","SciRecipe Dataset"]}],["$","span","Sketch-and-Fill",{"className":"page__taxonomy-item","children":["#","Sketch-and-Fill"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Thoth",{"className":"page__taxonomy-item","children":["#","Thoth"]}]]}]]}]]}],["$","article","2025-10-22-UniGenBench_A_Unified_Semantic_Evaluation_Benchmark_for_Text-to-Image_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-UniGenBench_A_Unified_Semantic_Evaluation_Benchmark_for_Text-to-Image_Generation/","children":"[논문리뷰] UniGenBench++: A Unified Semantic Evaluation Benchmark for Text-to-Image Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yujie Zhou이 [arXiv]에 게시한 'UniGenBench++: A Unified Semantic Evaluation Benchmark for Text-to-Image Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Semantic Evaluation",{"className":"page__taxonomy-item","children":["#","Semantic Evaluation"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Multilingual Evaluation",{"className":"page__taxonomy-item","children":["#","Multilingual Evaluation"]}],["$","span","Fine-grained Assessment",{"className":"page__taxonomy-item","children":["#","Fine-grained Assessment"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Model Evaluation",{"className":"page__taxonomy-item","children":["#","Model Evaluation"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}]]}]]}]]}],["$","article","2025-10-22-UltraGen_High-Resolution_Video_Generation_with_Hierarchical_Attention",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-UltraGen_High-Resolution_Video_Generation_with_Hierarchical_Attention/","children":"[논문리뷰] UltraGen: High-Resolution Video Generation with Hierarchical Attention"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ran Yi이 [arXiv]에 게시한 'UltraGen: High-Resolution Video Generation with Hierarchical Attention' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","High-Resolution",{"className":"page__taxonomy-item","children":["#","High-Resolution"]}],["$","span","Diffusion Transformer",{"className":"page__taxonomy-item","children":["#","Diffusion Transformer"]}],["$","span","Hierarchical Attention",{"className":"page__taxonomy-item","children":["#","Hierarchical Attention"]}],["$","span","Global-Local Attention",{"className":"page__taxonomy-item","children":["#","Global-Local Attention"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}],["$","span","4K Synthesis",{"className":"page__taxonomy-item","children":["#","4K Synthesis"]}]]}]]}]]}],["$","article","2025-10-22-Towards_Faithful_and_Controllable_Personalization_via_Critique-Post-Edit_Reinforcement_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-Towards_Faithful_and_Controllable_Personalization_via_Critique-Post-Edit_Reinforcement_Learning/","children":"[논문리뷰] Towards Faithful and Controllable Personalization via Critique-Post-Edit Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuchen Eleanor Jiang이 [arXiv]에 게시한 'Towards Faithful and Controllable Personalization via Critique-Post-Edit Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Personalization",{"className":"page__taxonomy-item","children":["#","LLM Personalization"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Generative Reward Model",{"className":"page__taxonomy-item","children":["#","Generative Reward Model"]}],["$","span","Critique-Post-Edit",{"className":"page__taxonomy-item","children":["#","Critique-Post-Edit"]}],["$","span","Reward Hacking",{"className":"page__taxonomy-item","children":["#","Reward Hacking"]}],["$","span","Controllable AI",{"className":"page__taxonomy-item","children":["#","Controllable AI"]}]]}]]}]]}],["$","article","2025-10-22-ProCLIP_Progressive_Vision-Language_Alignment_via_LLM-based_Embedder",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-ProCLIP_Progressive_Vision-Language_Alignment_via_LLM-based_Embedder/","children":"[논문리뷰] ProCLIP: Progressive Vision-Language Alignment via LLM-based Embedder"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zonghao Guo이 [arXiv]에 게시한 'ProCLIP: Progressive Vision-Language Alignment via LLM-based Embedder' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","CLIP",{"className":"page__taxonomy-item","children":["#","CLIP"]}],["$","span","LLM-based Embedder",{"className":"page__taxonomy-item","children":["#","LLM-based Embedder"]}],["$","span","Knowledge Distillation",{"className":"page__taxonomy-item","children":["#","Knowledge Distillation"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Multimodal Alignment",{"className":"page__taxonomy-item","children":["#","Multimodal Alignment"]}],["$","span","Progressive Alignment",{"className":"page__taxonomy-item","children":["#","Progressive Alignment"]}]]}]]}]]}],["$","article","2025-10-22-PRISMM-Bench_A_Benchmark_of_Peer-Review_Grounded_Multimodal_Inconsistencies",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-PRISMM-Bench_A_Benchmark_of_Peer-Review_Grounded_Multimodal_Inconsistencies/","children":"[논문리뷰] PRISMM-Bench: A Benchmark of Peer-Review Grounded Multimodal Inconsistencies"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"James Glass이 [arXiv]에 게시한 'PRISMM-Bench: A Benchmark of Peer-Review Grounded Multimodal Inconsistencies' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Multimodal Models (LMMs)",{"className":"page__taxonomy-item","children":["#","Large Multimodal Models (LMMs)"]}],["$","span","Scientific Document Analysis",{"className":"page__taxonomy-item","children":["#","Scientific Document Analysis"]}],["$","span","Multimodal Inconsistencies",{"className":"page__taxonomy-item","children":["#","Multimodal Inconsistencies"]}],["$","span","Peer Review",{"className":"page__taxonomy-item","children":["#","Peer Review"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Debiasing",{"className":"page__taxonomy-item","children":["#","Debiasing"]}],["$","span","JSON-based Representation",{"className":"page__taxonomy-item","children":["#","JSON-based Representation"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}]]}]]}]]}],["$","article","2025-10-22-PokeeResearch_Effective_Deep_Research_via_Reinforcement_Learning_from_AI_Feedback_and_Robust_Reasoning_Scaffold",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-PokeeResearch_Effective_Deep_Research_via_Reinforcement_Learning_from_AI_Feedback_and_Robust_Reasoning_Scaffold/","children":"[논문리뷰] PokeeResearch: Effective Deep Research via Reinforcement Learning from AI Feedback and Robust Reasoning Scaffold"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'PokeeResearch: Effective Deep Research via Reinforcement Learning from AI Feedback and Robust Reasoning Scaffold' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Deep Research Agent",{"className":"page__taxonomy-item","children":["#","Deep Research Agent"]}],["$","span","Reinforcement Learning from AI Feedback",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning from AI Feedback"]}],["$","span","RLOO Algorithm",{"className":"page__taxonomy-item","children":["#","RLOO Algorithm"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Self-Correction",{"className":"page__taxonomy-item","children":["#","Self-Correction"]}],["$","span","Reasoning Scaffold",{"className":"page__taxonomy-item","children":["#","Reasoning Scaffold"]}],["$","span","Agent Alignment",{"className":"page__taxonomy-item","children":["#","Agent Alignment"]}]]}]]}]]}],["$","article","2025-10-22-MUG-V_10B_High-efficiency_Training_Pipeline_for_Large_Video_Generation_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-MUG-V_10B_High-efficiency_Training_Pipeline_for_Large_Video_Generation_Models/","children":"[논문리뷰] MUG-V 10B: High-efficiency Training Pipeline for Large Video Generation Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'MUG-V 10B: High-efficiency Training Pipeline for Large Video Generation Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Diffusion Transformer",{"className":"page__taxonomy-item","children":["#","Diffusion Transformer"]}],["$","span","Large-scale Training",{"className":"page__taxonomy-item","children":["#","Large-scale Training"]}],["$","span","Megatron-Core",{"className":"page__taxonomy-item","children":["#","Megatron-Core"]}],["$","span","Video VAE",{"className":"page__taxonomy-item","children":["#","Video VAE"]}],["$","span","E-commerce AI",{"className":"page__taxonomy-item","children":["#","E-commerce AI"]}],["$","span","High-efficiency Pipeline",{"className":"page__taxonomy-item","children":["#","High-efficiency Pipeline"]}],["$","span","Preference Optimization",{"className":"page__taxonomy-item","children":["#","Preference Optimization"]}]]}]]}]]}],["$","article","2025-10-22-MT-Video-Bench_A_Holistic_Video_Understanding_Benchmark_for_Evaluating_Multimodal_LLMs_in_Multi-Turn_Dialogues",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-MT-Video-Bench_A_Holistic_Video_Understanding_Benchmark_for_Evaluating_Multimodal_LLMs_in_Multi-Turn_Dialogues/","children":"[논문리뷰] MT-Video-Bench: A Holistic Video Understanding Benchmark for Evaluating Multimodal LLMs in Multi-Turn Dialogues"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'MT-Video-Bench: A Holistic Video Understanding Benchmark for Evaluating Multimodal LLMs in Multi-Turn Dialogues' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Video Understanding",{"className":"page__taxonomy-item","children":["#","Video Understanding"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Multi-Turn Dialogues",{"className":"page__taxonomy-item","children":["#","Multi-Turn Dialogues"]}],["$","span","Perceptivity",{"className":"page__taxonomy-item","children":["#","Perceptivity"]}],["$","span","Interactivity",{"className":"page__taxonomy-item","children":["#","Interactivity"]}],["$","span","Evaluation",{"className":"page__taxonomy-item","children":["#","Evaluation"]}]]}]]}]]}],["$","article","2025-10-22-MoGA_Mixture-of-Groups_Attention_for_End-to-End_Long_Video_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-MoGA_Mixture-of-Groups_Attention_for_End-to-End_Long_Video_Generation/","children":"[논문리뷰] MoGA: Mixture-of-Groups Attention for End-to-End Long Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'MoGA: Mixture-of-Groups Attention for End-to-End Long Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Long Video Generation",{"className":"page__taxonomy-item","children":["#","Long Video Generation"]}],["$","span","Sparse Attention",{"className":"page__taxonomy-item","children":["#","Sparse Attention"]}],["$","span","Diffusion Transformers",{"className":"page__taxonomy-item","children":["#","Diffusion Transformers"]}],["$","span","Mixture-of-Groups Attention",{"className":"page__taxonomy-item","children":["#","Mixture-of-Groups Attention"]}],["$","span","Token Routing",{"className":"page__taxonomy-item","children":["#","Token Routing"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}],["$","span","Context Length",{"className":"page__taxonomy-item","children":["#","Context Length"]}]]}]]}]]}],["$","article","2025-10-22-IF-VidCap_Can_Video_Caption_Models_Follow_Instructions",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-IF-VidCap_Can_Video_Caption_Models_Follow_Instructions/","children":"[논문리뷰] IF-VidCap: Can Video Caption Models Follow Instructions?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'IF-VidCap: Can Video Caption Models Follow Instructions?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Captioning",{"className":"page__taxonomy-item","children":["#","Video Captioning"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}],["$","span","MLLMs",{"className":"page__taxonomy-item","children":["#","MLLMs"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Controllable Generation",{"className":"page__taxonomy-item","children":["#","Controllable Generation"]}],["$","span","Multimodal Evaluation",{"className":"page__taxonomy-item","children":["#","Multimodal Evaluation"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}]]}]]}]]}],["$","article","2025-10-22-Grasp_Any_Region_Towards_Precise_Contextual_Pixel_Understanding_for_Multimodal_LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-Grasp_Any_Region_Towards_Precise_Contextual_Pixel_Understanding_for_Multimodal_LLMs/","children":"[논문리뷰] Grasp Any Region: Towards Precise, Contextual Pixel Understanding for Multimodal LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Grasp Any Region: Towards Precise, Contextual Pixel Understanding for Multimodal LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Region Understanding",{"className":"page__taxonomy-item","children":["#","Region Understanding"]}],["$","span","Contextual Pixel Understanding",{"className":"page__taxonomy-item","children":["#","Contextual Pixel Understanding"]}],["$","span","RoI-aligned Feature Replay",{"className":"page__taxonomy-item","children":["#","RoI-aligned Feature Replay"]}],["$","span","Compositional Reasoning",{"className":"page__taxonomy-item","children":["#","Compositional Reasoning"]}],["$","span","GAR-Bench",{"className":"page__taxonomy-item","children":["#","GAR-Bench"]}],["$","span","Zero-shot Video Understanding",{"className":"page__taxonomy-item","children":["#","Zero-shot Video Understanding"]}]]}]]}]]}],["$","article","2025-10-22-Extracting_alignment_data_in_open_models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-Extracting_alignment_data_in_open_models/","children":"[논문리뷰] Extracting alignment data in open models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Extracting alignment data in open models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Alignment Data Extraction",{"className":"page__taxonomy-item","children":["#","Alignment Data Extraction"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Memorization",{"className":"page__taxonomy-item","children":["#","Memorization"]}],["$","span","Neural Embeddings",{"className":"page__taxonomy-item","children":["#","Neural Embeddings"]}],["$","span","Semantic Similarity",{"className":"page__taxonomy-item","children":["#","Semantic Similarity"]}],["$","span","Chat Templates",{"className":"page__taxonomy-item","children":["#","Chat Templates"]}],["$","span","Model Distillation",{"className":"page__taxonomy-item","children":["#","Model Distillation"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Supervised Finetuning",{"className":"page__taxonomy-item","children":["#","Supervised Finetuning"]}]]}]]}]]}],["$","article","2025-10-22-EvoSyn_Generalizable_Evolutionary_Data_Synthesis_for_Verifiable_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-EvoSyn_Generalizable_Evolutionary_Data_Synthesis_for_Verifiable_Learning/","children":"[논문리뷰] EvoSyn: Generalizable Evolutionary Data Synthesis for Verifiable Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Qipeng Guo이 [arXiv]에 게시한 'EvoSyn: Generalizable Evolutionary Data Synthesis for Verifiable Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Verifiable Learning",{"className":"page__taxonomy-item","children":["#","Verifiable Learning"]}],["$","span","Data Synthesis",{"className":"page__taxonomy-item","children":["#","Data Synthesis"]}],["$","span","Evolutionary Algorithm",{"className":"page__taxonomy-item","children":["#","Evolutionary Algorithm"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Model Distillation",{"className":"page__taxonomy-item","children":["#","Model Distillation"]}],["$","span","Test Generation",{"className":"page__taxonomy-item","children":["#","Test Generation"]}]]}]]}]]}],["$","article","2025-10-22-DSI-Bench_A_Benchmark_for_Dynamic_Spatial_Intelligence",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-DSI-Bench_A_Benchmark_for_Dynamic_Spatial_Intelligence/","children":"[논문리뷰] DSI-Bench: A Benchmark for Dynamic Spatial Intelligence"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DSI-Bench: A Benchmark for Dynamic Spatial Intelligence' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Dynamic Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Dynamic Spatial Reasoning"]}],["$","span","Vision-Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision-Language Models (VLMs)"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Video Understanding",{"className":"page__taxonomy-item","children":["#","Video Understanding"]}],["$","span","Motion Perception",{"className":"page__taxonomy-item","children":["#","Motion Perception"]}],["$","span","3D Spatial Intelligence",{"className":"page__taxonomy-item","children":["#","3D Spatial Intelligence"]}],["$","span","Hallucinations",{"className":"page__taxonomy-item","children":["#","Hallucinations"]}],["$","span","Bias",{"className":"page__taxonomy-item","children":["#","Bias"]}]]}]]}]]}],["$","article","2025-10-22-Chem-R_Learning_to_Reason_as_a_Chemist",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-Chem-R_Learning_to_Reason_as_a_Chemist/","children":"[논문리뷰] Chem-R: Learning to Reason as a Chemist"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Chem-R: Learning to Reason as a Chemist' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Chemical Reasoning",{"className":"page__taxonomy-item","children":["#","Chemical Reasoning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Chem-R",{"className":"page__taxonomy-item","children":["#","Chem-R"]}],["$","span","Structured Reasoning",{"className":"page__taxonomy-item","children":["#","Structured Reasoning"]}],["$","span","Multi-task Optimization",{"className":"page__taxonomy-item","children":["#","Multi-task Optimization"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Chemical Discovery",{"className":"page__taxonomy-item","children":["#","Chemical Discovery"]}]]}]]}]]}],["$","article","2025-10-22-AlphaQuanter_An_End-to-End_Tool-Orchestrated_Agentic_Reinforcement_Learning_Framework_for_Stock_Trading",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-22-AlphaQuanter_An_End-to-End_Tool-Orchestrated_Agentic_Reinforcement_Learning_Framework_for_Stock_Trading/","children":"[논문리뷰] AlphaQuanter: An End-to-End Tool-Orchestrated Agentic Reinforcement Learning Framework for Stock Trading"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiashu Wang이 [arXiv]에 게시한 'AlphaQuanter: An End-to-End Tool-Orchestrated Agentic Reinforcement Learning Framework for Stock Trading' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-22 13:07:20+0900","children":"2025년 10월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Automated Trading",{"className":"page__taxonomy-item","children":["#","Automated Trading"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Tool Orchestration",{"className":"page__taxonomy-item","children":["#","Tool Orchestration"]}],["$","span","Financial Markets",{"className":"page__taxonomy-item","children":["#","Financial Markets"]}],["$","span","Algorithmic Trading",{"className":"page__taxonomy-item","children":["#","Algorithmic Trading"]}],["$","span","Interpretable AI",{"className":"page__taxonomy-item","children":["#","Interpretable AI"]}],["$","span","ReAct",{"className":"page__taxonomy-item","children":["#","ReAct"]}]]}]]}]]}],["$","article","2025-10-21-When_to_Ensemble_Identifying_Token-Level_Points_for_Stable_and_Fast_LLM_Ensembling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-When_to_Ensemble_Identifying_Token-Level_Points_for_Stable_and_Fast_LLM_Ensembling/","children":"[논문리뷰] When to Ensemble: Identifying Token-Level Points for Stable and Fast LLM Ensembling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'When to Ensemble: Identifying Token-Level Points for Stable and Fast LLM Ensembling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Ensembling",{"className":"page__taxonomy-item","children":["#","LLM Ensembling"]}],["$","span","Token-level Ensembling",{"className":"page__taxonomy-item","children":["#","Token-level Ensembling"]}],["$","span","Speculative Decoding",{"className":"page__taxonomy-item","children":["#","Speculative Decoding"]}],["$","span","Tokenization Mismatch",{"className":"page__taxonomy-item","children":["#","Tokenization Mismatch"]}],["$","span","Probability Sharpening",{"className":"page__taxonomy-item","children":["#","Probability Sharpening"]}],["$","span","Long-form Generation",{"className":"page__taxonomy-item","children":["#","Long-form Generation"]}],["$","span","KV Cache Management",{"className":"page__taxonomy-item","children":["#","KV Cache Management"]}]]}]]}]]}],["$","article","2025-10-21-Visual_Autoregressive_Models_Beat_Diffusion_Models_on_Inference_Time_Scaling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-Visual_Autoregressive_Models_Beat_Diffusion_Models_on_Inference_Time_Scaling/","children":"[논문리뷰] Visual Autoregressive Models Beat Diffusion Models on Inference Time Scaling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Dim P. Papadopoulos이 [arXiv]에 게시한 'Visual Autoregressive Models Beat Diffusion Models on Inference Time Scaling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Visual Autoregressive Models",{"className":"page__taxonomy-item","children":["#","Visual Autoregressive Models"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Inference Time Scaling",{"className":"page__taxonomy-item","children":["#","Inference Time Scaling"]}],["$","span","Beam Search",{"className":"page__taxonomy-item","children":["#","Beam Search"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Text-to-Image Synthesis",{"className":"page__taxonomy-item","children":["#","Text-to-Image Synthesis"]}],["$","span","Discrete Latent Space",{"className":"page__taxonomy-item","children":["#","Discrete Latent Space"]}]]}]]}]]}],["$","article","2025-10-21-Uniworld-V2_Reinforce_Image_Editing_with_Diffusion_Negative-aware_Finetuning_and_MLLM_Implicit_Feedback",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-Uniworld-V2_Reinforce_Image_Editing_with_Diffusion_Negative-aware_Finetuning_and_MLLM_Implicit_Feedback/","children":"[논문리뷰] Uniworld-V2: Reinforce Image Editing with Diffusion Negative-aware Finetuning and MLLM Implicit Feedback"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Uniworld-V2: Reinforce Image Editing with Diffusion Negative-aware Finetuning and MLLM Implicit Feedback' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","MLLM",{"className":"page__taxonomy-item","children":["#","MLLM"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Finetuning",{"className":"page__taxonomy-item","children":["#","Finetuning"]}],["$","span","Reward Modeling",{"className":"page__taxonomy-item","children":["#","Reward Modeling"]}],["$","span","Human Alignment",{"className":"page__taxonomy-item","children":["#","Human Alignment"]}]]}]]}]]}],["$","article","2025-10-21-UltraCUA_A_Foundation_Model_for_Computer_Use_Agents_with_Hybrid_Action",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-UltraCUA_A_Foundation_Model_for_Computer_Use_Agents_with_Hybrid_Action/","children":"[논문리뷰] UltraCUA: A Foundation Model for Computer Use Agents with Hybrid Action"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'UltraCUA: A Foundation Model for Computer Use Agents with Hybrid Action' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Computer Use Agents",{"className":"page__taxonomy-item","children":["#","Computer Use Agents"]}],["$","span","Hybrid Action",{"className":"page__taxonomy-item","children":["#","Hybrid Action"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Synthetic Data Generation",{"className":"page__taxonomy-item","children":["#","Synthetic Data Generation"]}],["$","span","Tool Learning",{"className":"page__taxonomy-item","children":["#","Tool Learning"]}],["$","span","GUI Automation",{"className":"page__taxonomy-item","children":["#","GUI Automation"]}]]}]]}]]}],["$","article","2025-10-21-Towards_Mixed-Modal_Retrieval_for_Universal_Retrieval-Augmented_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-Towards_Mixed-Modal_Retrieval_for_Universal_Retrieval-Augmented_Generation/","children":"[논문리뷰] Towards Mixed-Modal Retrieval for Universal Retrieval-Augmented Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Towards Mixed-Modal Retrieval for Universal Retrieval-Augmented Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Universal RAG",{"className":"page__taxonomy-item","children":["#","Universal RAG"]}],["$","span","Multimodal Retrieval",{"className":"page__taxonomy-item","children":["#","Multimodal Retrieval"]}],["$","span","Mixed-Modal Data Generation",{"className":"page__taxonomy-item","children":["#","Mixed-Modal Data Generation"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Matryoshka Representation Learning",{"className":"page__taxonomy-item","children":["#","Matryoshka Representation Learning"]}]]}]]}]]}],["$","article","2025-10-21-RL_makes_MLLMs_see_better_than_SFT",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-RL_makes_MLLMs_see_better_than_SFT/","children":"[논문리뷰] RL makes MLLMs see better than SFT"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'RL makes MLLMs see better than SFT' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Language Models",{"className":"page__taxonomy-item","children":["#","Multimodal Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Supervised Finetuning",{"className":"page__taxonomy-item","children":["#","Supervised Finetuning"]}],["$","span","Vision Encoder",{"className":"page__taxonomy-item","children":["#","Vision Encoder"]}],["$","span","Visual Representations",{"className":"page__taxonomy-item","children":["#","Visual Representations"]}],["$","span","Direct Preference Optimization",{"className":"page__taxonomy-item","children":["#","Direct Preference Optimization"]}],["$","span","Preference Alignment",{"className":"page__taxonomy-item","children":["#","Preference Alignment"]}],["$","span","PIVOT",{"className":"page__taxonomy-item","children":["#","PIVOT"]}]]}]]}]]}],["$","article","2025-10-21-QueST_Incentivizing_LLMs_to_Generate_Difficult_Problems",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-QueST_Incentivizing_LLMs_to_Generate_Difficult_Problems/","children":"[논문리뷰] QueST: Incentivizing LLMs to Generate Difficult Problems"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'QueST: Incentivizing LLMs to Generate Difficult Problems' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Problem Generation",{"className":"page__taxonomy-item","children":["#","Problem Generation"]}],["$","span","Competitive Programming",{"className":"page__taxonomy-item","children":["#","Competitive Programming"]}],["$","span","Synthetic Data",{"className":"page__taxonomy-item","children":["#","Synthetic Data"]}],["$","span","Difficulty Estimation",{"className":"page__taxonomy-item","children":["#","Difficulty Estimation"]}],["$","span","Rejection Fine-tuning",{"className":"page__taxonomy-item","children":["#","Rejection Fine-tuning"]}],["$","span","Graph Sampling",{"className":"page__taxonomy-item","children":["#","Graph Sampling"]}]]}]]}]]}],["$","article","2025-10-21-PICABench_How_Far_Are_We_from_Physically_Realistic_Image_Editing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-PICABench_How_Far_Are_We_from_Physically_Realistic_Image_Editing/","children":"[논문리뷰] PICABench: How Far Are We from Physically Realistic Image Editing?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kaiwen Zhu이 [arXiv]에 게시한 'PICABench: How Far Are We from Physically Realistic Image Editing?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Physical Realism",{"className":"page__taxonomy-item","children":["#","Physical Realism"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","VLM-as-a-Judge",{"className":"page__taxonomy-item","children":["#","VLM-as-a-Judge"]}],["$","span","Synthetic Data",{"className":"page__taxonomy-item","children":["#","Synthetic Data"]}],["$","span","Physics-Aware AI",{"className":"page__taxonomy-item","children":["#","Physics-Aware AI"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Evaluation Metrics",{"className":"page__taxonomy-item","children":["#","Evaluation Metrics"]}]]}]]}]]}],["$","article","2025-10-21-On_Non-interactive_Evaluation_of_Animal_Communication_Translators",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-On_Non-interactive_Evaluation_of_Animal_Communication_Translators/","children":"[논문리뷰] On Non-interactive Evaluation of Animal Communication Translators"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Adam Tauman Kalai이 [arXiv]에 게시한 'On Non-interactive Evaluation of Animal Communication Translators' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Machine Translation Quality Evaluation",{"className":"page__taxonomy-item","children":["#","Machine Translation Quality Evaluation"]}],["$","span","Reference-Free Evaluation",{"className":"page__taxonomy-item","children":["#","Reference-Free Evaluation"]}],["$","span","Animal Communication",{"className":"page__taxonomy-item","children":["#","Animal Communication"]}],["$","span","Language Models",{"className":"page__taxonomy-item","children":["#","Language Models"]}],["$","span","Shuffle Test",{"className":"page__taxonomy-item","children":["#","Shuffle Test"]}],["$","span","Conlangs",{"className":"page__taxonomy-item","children":["#","Conlangs"]}],["$","span","Non-interactive Evaluation",{"className":"page__taxonomy-item","children":["#","Non-interactive Evaluation"]}]]}]]}]]}],["$","article","2025-10-21-MultiVerse_A_Multi-Turn_Conversation_Benchmark_for_Evaluating_Large_Vision_and_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-MultiVerse_A_Multi-Turn_Conversation_Benchmark_for_Evaluating_Large_Vision_and_Language_Models/","children":"[논문리뷰] MultiVerse: A Multi-Turn Conversation Benchmark for Evaluating Large Vision and Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'MultiVerse: A Multi-Turn Conversation Benchmark for Evaluating Large Vision and Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-Turn Conversation",{"className":"page__taxonomy-item","children":["#","Multi-Turn Conversation"]}],["$","span","VLM Evaluation",{"className":"page__taxonomy-item","children":["#","VLM Evaluation"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Vision and Language Models",{"className":"page__taxonomy-item","children":["#","Vision and Language Models"]}],["$","span","Contextual Understanding",{"className":"page__taxonomy-item","children":["#","Contextual Understanding"]}],["$","span","Checklist-based Evaluation",{"className":"page__taxonomy-item","children":["#","Checklist-based Evaluation"]}],["$","span","Interactive AI",{"className":"page__taxonomy-item","children":["#","Interactive AI"]}]]}]]}]]}],["$","article","2025-10-21-Knowledge-based_Visual_Question_Answer_with_Multimodal_Processing_Retrieval_and_Filtering",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-Knowledge-based_Visual_Question_Answer_with_Multimodal_Processing_Retrieval_and_Filtering/","children":"[논문리뷰] Knowledge-based Visual Question Answer with Multimodal Processing, Retrieval and Filtering"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Knowledge-based Visual Question Answer with Multimodal Processing, Retrieval and Filtering' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Visual Question Answering",{"className":"page__taxonomy-item","children":["#","Visual Question Answering"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Knowledge Base",{"className":"page__taxonomy-item","children":["#","Knowledge Base"]}],["$","span","Tool Learning",{"className":"page__taxonomy-item","children":["#","Tool Learning"]}],["$","span","Information Filtering",{"className":"page__taxonomy-item","children":["#","Information Filtering"]}]]}]]}]]}],["$","article","2025-10-21-GuideFlow3D_Optimization-Guided_Rectified_Flow_For_Appearance_Transfer",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-GuideFlow3D_Optimization-Guided_Rectified_Flow_For_Appearance_Transfer/","children":"[논문리뷰] GuideFlow3D: Optimization-Guided Rectified Flow For Appearance Transfer"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'GuideFlow3D: Optimization-Guided Rectified Flow For Appearance Transfer' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Appearance Transfer",{"className":"page__taxonomy-item","children":["#","3D Appearance Transfer"]}],["$","span","Rectified Flow",{"className":"page__taxonomy-item","children":["#","Rectified Flow"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Optimization-Guided Sampling",{"className":"page__taxonomy-item","children":["#","Optimization-Guided Sampling"]}],["$","span","Neural Latent Representations",{"className":"page__taxonomy-item","children":["#","Neural Latent Representations"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}],["$","span","GPT-Based Evaluation",{"className":"page__taxonomy-item","children":["#","GPT-Based Evaluation"]}]]}]]}]]}],["$","article","2025-10-21-Glyph_Scaling_Context_Windows_via_Visual-Text_Compression",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-Glyph_Scaling_Context_Windows_via_Visual-Text_Compression/","children":"[논문리뷰] Glyph: Scaling Context Windows via Visual-Text Compression"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wenyi Hong이 [arXiv]에 게시한 'Glyph: Scaling Context Windows via Visual-Text Compression' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Long-Context Modeling",{"className":"page__taxonomy-item","children":["#","Long-Context Modeling"]}],["$","span","Visual Compression",{"className":"page__taxonomy-item","children":["#","Visual Compression"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Token Efficiency",{"className":"page__taxonomy-item","children":["#","Token Efficiency"]}],["$","span","Genetic Algorithms",{"className":"page__taxonomy-item","children":["#","Genetic Algorithms"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","LLM Scaling",{"className":"page__taxonomy-item","children":["#","LLM Scaling"]}]]}]]}]]}],["$","article","2025-10-21-FineVision_Open_Data_Is_All_You_Need",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-FineVision_Open_Data_Is_All_You_Need/","children":"[논문리뷰] FineVision: Open Data Is All You Need"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'FineVision: Open Data Is All You Need' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Datasets",{"className":"page__taxonomy-item","children":["#","Multimodal Datasets"]}],["$","span","VLM",{"className":"page__taxonomy-item","children":["#","VLM"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Data Hygiene",{"className":"page__taxonomy-item","children":["#","Data Hygiene"]}],["$","span","De-duplication",{"className":"page__taxonomy-item","children":["#","De-duplication"]}],["$","span","Human-in-the-loop",{"className":"page__taxonomy-item","children":["#","Human-in-the-loop"]}],["$","span","GUI Automation",{"className":"page__taxonomy-item","children":["#","GUI Automation"]}],["$","span","Test-set Decontamination",{"className":"page__taxonomy-item","children":["#","Test-set Decontamination"]}]]}]]}]]}],["$","article","2025-10-21-Executable_Knowledge_Graphs_for_Replicating_AI_Research",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-Executable_Knowledge_Graphs_for_Replicating_AI_Research/","children":"[논문리뷰] Executable Knowledge Graphs for Replicating AI Research"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Executable Knowledge Graphs for Replicating AI Research' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Research Replication",{"className":"page__taxonomy-item","children":["#","AI Research Replication"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Knowledge Graphs (KGs)",{"className":"page__taxonomy-item","children":["#","Knowledge Graphs (KGs)"]}],["$","span","Executable Code Generation",{"className":"page__taxonomy-item","children":["#","Executable Code Generation"]}],["$","span","Retrieval-Augmented Generation (RAG)",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation (RAG)"]}],["$","span","PaperBench",{"className":"page__taxonomy-item","children":["#","PaperBench"]}],["$","span","Automated AI Research",{"className":"page__taxonomy-item","children":["#","Automated AI Research"]}]]}]]}]]}],["$","article","2025-10-21-Enterprise_Deep_Research_Steerable_Multi-Agent_Deep_Research_for_Enterprise_Analytics",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-Enterprise_Deep_Research_Steerable_Multi-Agent_Deep_Research_for_Enterprise_Analytics/","children":"[논문리뷰] Enterprise Deep Research: Steerable Multi-Agent Deep Research for Enterprise Analytics"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Enterprise Deep Research: Steerable Multi-Agent Deep Research for Enterprise Analytics' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Deep Research",{"className":"page__taxonomy-item","children":["#","Deep Research"]}],["$","span","Enterprise AI",{"className":"page__taxonomy-item","children":["#","Enterprise AI"]}],["$","span","Human-in-the-Loop",{"className":"page__taxonomy-item","children":["#","Human-in-the-Loop"]}],["$","span","Steerable AI",{"className":"page__taxonomy-item","children":["#","Steerable AI"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Context Engineering",{"className":"page__taxonomy-item","children":["#","Context Engineering"]}],["$","span","Enterprise Analytics",{"className":"page__taxonomy-item","children":["#","Enterprise Analytics"]}]]}]]}]]}],["$","article","2025-10-21-Embody_3D_A_Large-scale_Multimodal_Motion_and_Behavior_Dataset",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-Embody_3D_A_Large-scale_Multimodal_Motion_and_Behavior_Dataset/","children":"[논문리뷰] Embody 3D: A Large-scale Multimodal Motion and Behavior Dataset"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Embody 3D: A Large-scale Multimodal Motion and Behavior Dataset' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Motion Dataset",{"className":"page__taxonomy-item","children":["#","3D Motion Dataset"]}],["$","span","Multimodal Data",{"className":"page__taxonomy-item","children":["#","Multimodal Data"]}],["$","span","Human Behavior",{"className":"page__taxonomy-item","children":["#","Human Behavior"]}],["$","span","Pose Tracking",{"className":"page__taxonomy-item","children":["#","Pose Tracking"]}],["$","span","Hand Tracking",{"className":"page__taxonomy-item","children":["#","Hand Tracking"]}],["$","span","Audio-Visual Data",{"className":"page__taxonomy-item","children":["#","Audio-Visual Data"]}],["$","span","Large-scale Dataset",{"className":"page__taxonomy-item","children":["#","Large-scale Dataset"]}],["$","span","SMPL-X",{"className":"page__taxonomy-item","children":["#","SMPL-X"]}]]}]]}]]}],["$","article","2025-10-21-Distractor_Injection_Attacks_on_Large_Reasoning_Models_Characterization_and_Defense",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-Distractor_Injection_Attacks_on_Large_Reasoning_Models_Characterization_and_Defense/","children":"[논문리뷰] Distractor Injection Attacks on Large Reasoning Models: Characterization and Defense"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Distractor Injection Attacks on Large Reasoning Models: Characterization and Defense' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Reasoning Models (LRMs)",{"className":"page__taxonomy-item","children":["#","Large Reasoning Models (LRMs)"]}],["$","span","Prompt Injection",{"className":"page__taxonomy-item","children":["#","Prompt Injection"]}],["$","span","Adversarial Attack",{"className":"page__taxonomy-item","children":["#","Adversarial Attack"]}],["$","span","Reasoning Distraction",{"className":"page__taxonomy-item","children":["#","Reasoning Distraction"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Robustness",{"className":"page__taxonomy-item","children":["#","Robustness"]}],["$","span","Supervised Fine-Tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning (SFT)"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}]]}]]}]]}],["$","article","2025-10-21-Deep_Self-Evolving_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-Deep_Self-Evolving_Reasoning/","children":"[논문리뷰] Deep Self-Evolving Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Deep Self-Evolving Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Deep Self-Evolving Reasoning",{"className":"page__taxonomy-item","children":["#","Deep Self-Evolving Reasoning"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Iterative Reasoning",{"className":"page__taxonomy-item","children":["#","Iterative Reasoning"]}],["$","span","Markov Chain",{"className":"page__taxonomy-item","children":["#","Markov Chain"]}],["$","span","Self-Verification",{"className":"page__taxonomy-item","children":["#","Self-Verification"]}],["$","span","Self-Refinement",{"className":"page__taxonomy-item","children":["#","Self-Refinement"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","AIME Benchmark",{"className":"page__taxonomy-item","children":["#","AIME Benchmark"]}]]}]]}]]}],["$","article","2025-10-21-DeepAnalyze_Agentic_Large_Language_Models_for_Autonomous_Data_Science",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-DeepAnalyze_Agentic_Large_Language_Models_for_Autonomous_Data_Science/","children":"[논문리뷰] DeepAnalyze: Agentic Large Language Models for Autonomous Data Science"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DeepAnalyze: Agentic Large Language Models for Autonomous Data Science' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Autonomous Data Science",{"className":"page__taxonomy-item","children":["#","Autonomous Data Science"]}],["$","span","Agentic LLM",{"className":"page__taxonomy-item","children":["#","Agentic LLM"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Data Agents",{"className":"page__taxonomy-item","children":["#","Data Agents"]}],["$","span","End-to-end Data Science",{"className":"page__taxonomy-item","children":["#","End-to-end Data Science"]}]]}]]}]]}],["$","article","2025-10-21-ConsistEdit_Highly_Consistent_and_Precise_Training-free_Visual_Editing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-ConsistEdit_Highly_Consistent_and_Precise_Training-free_Visual_Editing/","children":"[논문리뷰] ConsistEdit: Highly Consistent and Precise Training-free Visual Editing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xili Dai이 [arXiv]에 게시한 'ConsistEdit: Highly Consistent and Precise Training-free Visual Editing' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Video Editing",{"className":"page__taxonomy-item","children":["#","Video Editing"]}],["$","span","Diffusion Transformer",{"className":"page__taxonomy-item","children":["#","Diffusion Transformer"]}],["$","span","Attention Control",{"className":"page__taxonomy-item","children":["#","Attention Control"]}],["$","span","Training-free",{"className":"page__taxonomy-item","children":["#","Training-free"]}],["$","span","Multi-modal Diffusion Transformer (MM-DiT)",{"className":"page__taxonomy-item","children":["#","Multi-modal Diffusion Transformer (MM-DiT)"]}],["$","span","Consistency Preservation",{"className":"page__taxonomy-item","children":["#","Consistency Preservation"]}]]}]]}]]}],["$","article","2025-10-21-Chronos-2_From_Univariate_to_Universal_Forecasting",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-Chronos-2_From_Univariate_to_Universal_Forecasting/","children":"[논문리뷰] Chronos-2: From Univariate to Universal Forecasting"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Chronos-2: From Univariate to Universal Forecasting' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Time Series Forecasting",{"className":"page__taxonomy-item","children":["#","Time Series Forecasting"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Pretrained Models",{"className":"page__taxonomy-item","children":["#","Pretrained Models"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","In-Context Learning",{"className":"page__taxonomy-item","children":["#","In-Context Learning"]}],["$","span","Multivariate Forecasting",{"className":"page__taxonomy-item","children":["#","Multivariate Forecasting"]}],["$","span","Covariates",{"className":"page__taxonomy-item","children":["#","Covariates"]}],["$","span","Group Attention",{"className":"page__taxonomy-item","children":["#","Group Attention"]}]]}]]}]]}],["$","article","2025-10-21-Balanced_Multi-Task_Attention_for_Satellite_Image_Classification_A_Systematic_Approach_to_Achieving_97.23_Accuracy_on_EuroSAT_Without_Pre-Training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-Balanced_Multi-Task_Attention_for_Satellite_Image_Classification_A_Systematic_Approach_to_Achieving_97.23_Accuracy_on_EuroSAT_Without_Pre-Training/","children":"[논문리뷰] Balanced Multi-Task Attention for Satellite Image Classification: A Systematic Approach to Achieving 97.23% Accuracy on EuroSAT Without Pre-Training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Aditya Vir이 [arXiv]에 게시한 'Balanced Multi-Task Attention for Satellite Image Classification: A Systematic Approach to Achieving 97.23% Accuracy on EuroSAT Without Pre-Training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Satellite Image Classification",{"className":"page__taxonomy-item","children":["#","Satellite Image Classification"]}],["$","span","Multi-Task Attention",{"className":"page__taxonomy-item","children":["#","Multi-Task Attention"]}],["$","span","From-Scratch Training",{"className":"page__taxonomy-item","children":["#","From-Scratch Training"]}],["$","span","EuroSAT Dataset",{"className":"page__taxonomy-item","children":["#","EuroSAT Dataset"]}],["$","span","Squeeze-Excitation Networks",{"className":"page__taxonomy-item","children":["#","Squeeze-Excitation Networks"]}],["$","span","Coordinate Attention",{"className":"page__taxonomy-item","children":["#","Coordinate Attention"]}],["$","span","CNN",{"className":"page__taxonomy-item","children":["#","CNN"]}],["$","span","Deep Learning Architecture",{"className":"page__taxonomy-item","children":["#","Deep Learning Architecture"]}]]}]]}]]}],["$","article","2025-10-21-AsyncVoice_Agent_Real-Time_Explanation_for_LLM_Planning_and_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-AsyncVoice_Agent_Real-Time_Explanation_for_LLM_Planning_and_Reasoning/","children":"[논문리뷰] AsyncVoice Agent: Real-Time Explanation for LLM Planning and Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Nikos Vlassis이 [arXiv]에 게시한 'AsyncVoice Agent: Real-Time Explanation for LLM Planning and Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Real-Time Interaction",{"className":"page__taxonomy-item","children":["#","Real-Time Interaction"]}],["$","span","Asynchronous Agents",{"className":"page__taxonomy-item","children":["#","Asynchronous Agents"]}],["$","span","LLM Explanation",{"className":"page__taxonomy-item","children":["#","LLM Explanation"]}],["$","span","Human-AI Collaboration",{"className":"page__taxonomy-item","children":["#","Human-AI Collaboration"]}],["$","span","Voice Interface",{"className":"page__taxonomy-item","children":["#","Voice Interface"]}],["$","span","Planning and Reasoning",{"className":"page__taxonomy-item","children":["#","Planning and Reasoning"]}],["$","span","Context Management",{"className":"page__taxonomy-item","children":["#","Context Management"]}],["$","span","Interruption Handling",{"className":"page__taxonomy-item","children":["#","Interruption Handling"]}]]}]]}]]}],["$","article","2025-10-21-Annotation-Efficient_Universal_Honesty_Alignment",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-Annotation-Efficient_Universal_Honesty_Alignment/","children":"[논문리뷰] Annotation-Efficient Universal Honesty Alignment"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jingtong Wu이 [arXiv]에 게시한 'Annotation-Efficient Universal Honesty Alignment' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Honesty Alignment",{"className":"page__taxonomy-item","children":["#","LLM Honesty Alignment"]}],["$","span","Confidence Calibration",{"className":"page__taxonomy-item","children":["#","Confidence Calibration"]}],["$","span","Annotation Efficiency",{"className":"page__taxonomy-item","children":["#","Annotation Efficiency"]}],["$","span","Self-Consistency",{"className":"page__taxonomy-item","children":["#","Self-Consistency"]}],["$","span","Elicitation-Then-Calibration (EliCal)",{"className":"page__taxonomy-item","children":["#","Elicitation-Then-Calibration (EliCal)"]}],["$","span","HonestyBench",{"className":"page__taxonomy-item","children":["#","HonestyBench"]}],["$","span","LoRA",{"className":"page__taxonomy-item","children":["#","LoRA"]}],["$","span","Trustworthy AI",{"className":"page__taxonomy-item","children":["#","Trustworthy AI"]}]]}]]}]]}],["$","article","2025-10-21-Agentic_Reinforcement_Learning_for_Search_is_Unsafe",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-21-Agentic_Reinforcement_Learning_for_Search_is_Unsafe/","children":"[논문리뷰] Agentic Reinforcement Learning for Search is Unsafe"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Agentic Reinforcement Learning for Search is Unsafe' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-21 13:08:30+0900","children":"2025년 10월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Agentic Reinforcement Learning"]}],["$","span","LLM Safety",{"className":"page__taxonomy-item","children":["#","LLM Safety"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Search Models",{"className":"page__taxonomy-item","children":["#","Search Models"]}],["$","span","Jailbreaking",{"className":"page__taxonomy-item","children":["#","Jailbreaking"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}],["$","span","Vulnerability",{"className":"page__taxonomy-item","children":["#","Vulnerability"]}]]}]]}]]}],["$","article","2025-10-20-VISTA_A_Test-Time_Self-Improving_Video_Generation_Agent",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-VISTA_A_Test-Time_Self-Improving_Video_Generation_Agent/","children":"[논문리뷰] VISTA: A Test-Time Self-Improving Video Generation Agent"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Tomas Pfister이 [arXiv]에 게시한 'VISTA: A Test-Time Self-Improving Video Generation Agent' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Video Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Video Generation"]}],["$","span","Prompt Optimization",{"className":"page__taxonomy-item","children":["#","Prompt Optimization"]}],["$","span","Multi-Agent System",{"className":"page__taxonomy-item","children":["#","Multi-Agent System"]}],["$","span","Test-Time Improvement",{"className":"page__taxonomy-item","children":["#","Test-Time Improvement"]}],["$","span","MLLM-as-a-Judge",{"className":"page__taxonomy-item","children":["#","MLLM-as-a-Judge"]}],["$","span","Video Evaluation",{"className":"page__taxonomy-item","children":["#","Video Evaluation"]}],["$","span","Audio-Video Synthesis",{"className":"page__taxonomy-item","children":["#","Audio-Video Synthesis"]}]]}]]}]]}],["$","article","2025-10-20-Train_a_Unified_Multimodal_Data_Quality_Classifier_with_Synthetic_Data",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-Train_a_Unified_Multimodal_Data_Quality_Classifier_with_Synthetic_Data/","children":"[논문리뷰] Train a Unified Multimodal Data Quality Classifier with Synthetic Data"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ritesh Sarkhel이 [arXiv]에 게시한 'Train a Unified Multimodal Data Quality Classifier with Synthetic Data' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Data Quality",{"className":"page__taxonomy-item","children":["#","Multimodal Data Quality"]}],["$","span","MLLM",{"className":"page__taxonomy-item","children":["#","MLLM"]}],["$","span","Synthetic Data",{"className":"page__taxonomy-item","children":["#","Synthetic Data"]}],["$","span","Data Filtering",{"className":"page__taxonomy-item","children":["#","Data Filtering"]}],["$","span","Image-Text Captioning",{"className":"page__taxonomy-item","children":["#","Image-Text Captioning"]}],["$","span","Interleaved Document Analysis",{"className":"page__taxonomy-item","children":["#","Interleaved Document Analysis"]}],["$","span","Pre-training",{"className":"page__taxonomy-item","children":["#","Pre-training"]}]]}]]}]]}],["$","article","2025-10-20-Skyfall-GS_Synthesizing_Immersive_3D_Urban_Scenes_from_Satellite_Imagery",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-Skyfall-GS_Synthesizing_Immersive_3D_Urban_Scenes_from_Satellite_Imagery/","children":"[논문리뷰] Skyfall-GS: Synthesizing Immersive 3D Urban Scenes from Satellite Imagery"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chung-Ho Wu이 [arXiv]에 게시한 'Skyfall-GS: Synthesizing Immersive 3D Urban Scenes from Satellite Imagery' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Scene Synthesis",{"className":"page__taxonomy-item","children":["#","3D Scene Synthesis"]}],["$","span","Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","Gaussian Splatting"]}],["$","span","Satellite Imagery",{"className":"page__taxonomy-item","children":["#","Satellite Imagery"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Urban Modeling",{"className":"page__taxonomy-item","children":["#","Urban Modeling"]}],["$","span","Novel View Synthesis",{"className":"page__taxonomy-item","children":["#","Novel View Synthesis"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Real-time Rendering",{"className":"page__taxonomy-item","children":["#","Real-time Rendering"]}]]}]]}]]}],["$","article","2025-10-20-Scaling_Instruction-Based_Video_Editing_with_a_High-Quality_Synthetic_Dataset",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-Scaling_Instruction-Based_Video_Editing_with_a_High-Quality_Synthetic_Dataset/","children":"[논문리뷰] Scaling Instruction-Based Video Editing with a High-Quality Synthetic Dataset"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hao Ouyang이 [arXiv]에 게시한 'Scaling Instruction-Based Video Editing with a High-Quality Synthetic Dataset' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Editing",{"className":"page__taxonomy-item","children":["#","Video Editing"]}],["$","span","Instruction-Based Editing",{"className":"page__taxonomy-item","children":["#","Instruction-Based Editing"]}],["$","span","Synthetic Data Generation",{"className":"page__taxonomy-item","children":["#","Synthetic Data Generation"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}]]}]]}]]}],["$","article","2025-10-20-Robust_Layerwise_Scaling_Rules_by_Proper_Weight_Decay_Tuning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-Robust_Layerwise_Scaling_Rules_by_Proper_Weight_Decay_Tuning/","children":"[논문리뷰] Robust Layerwise Scaling Rules by Proper Weight Decay Tuning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Robust Layerwise Scaling Rules by Proper Weight Decay Tuning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Weight Decay Scaling",{"className":"page__taxonomy-item","children":["#","Weight Decay Scaling"]}],["$","span","Maximal-Update Parameterization (µP)",{"className":"page__taxonomy-item","children":["#","Maximal-Update Parameterization (µP)"]}],["$","span","AdamW",{"className":"page__taxonomy-item","children":["#","AdamW"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Hyperparameter Transfer",{"className":"page__taxonomy-item","children":["#","Hyperparameter Transfer"]}],["$","span","Scaling Laws",{"className":"page__taxonomy-item","children":["#","Scaling Laws"]}],["$","span","Singular Value Spectrum",{"className":"page__taxonomy-item","children":["#","Singular Value Spectrum"]}],["$","span","Steady State Training",{"className":"page__taxonomy-item","children":["#","Steady State Training"]}]]}]]}]]}],["$","article","2025-10-20-Rewiring_Experts_on_the_FlyContinuous_Rerouting_for_Better_Online_Adaptation_in_Mixture-of-Expert_models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-Rewiring_Experts_on_the_FlyContinuous_Rerouting_for_Better_Online_Adaptation_in_Mixture-of-Expert_models/","children":"[논문리뷰] Rewiring Experts on the Fly:Continuous Rerouting for Better Online Adaptation in Mixture-of-Expert models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shiwei Liu이 [arXiv]에 게시한 'Rewiring Experts on the Fly:Continuous Rerouting for Better Online Adaptation in Mixture-of-Expert models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Mixture-of-Experts (MoE)",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts (MoE)"]}],["$","span","Online Adaptation",{"className":"page__taxonomy-item","children":["#","Online Adaptation"]}],["$","span","Test-Time Adaptation (TTA)",{"className":"page__taxonomy-item","children":["#","Test-Time Adaptation (TTA)"]}],["$","span","Expert Routing",{"className":"page__taxonomy-item","children":["#","Expert Routing"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Self-Supervision",{"className":"page__taxonomy-item","children":["#","Self-Supervision"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}],["$","span","Context Shift Robustness",{"className":"page__taxonomy-item","children":["#","Context Shift Robustness"]}]]}]]}]]}],["$","article","2025-10-20-Paper2Web_Lets_Make_Your_Paper_Alive",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-Paper2Web_Lets_Make_Your_Paper_Alive/","children":"[논문리뷰] Paper2Web: Let's Make Your Paper Alive!"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yao Wan이 [arXiv]에 게시한 'Paper2Web: Let's Make Your Paper Alive!' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Academic Webpage Generation",{"className":"page__taxonomy-item","children":["#","Academic Webpage Generation"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Model Context Protocol",{"className":"page__taxonomy-item","children":["#","Model Context Protocol"]}],["$","span","Interactive Content",{"className":"page__taxonomy-item","children":["#","Interactive Content"]}],["$","span","Multimedia Dissemination",{"className":"page__taxonomy-item","children":["#","Multimedia Dissemination"]}],["$","span","Evaluation Benchmark",{"className":"page__taxonomy-item","children":["#","Evaluation Benchmark"]}],["$","span","Human-Computer Interaction",{"className":"page__taxonomy-item","children":["#","Human-Computer Interaction"]}]]}]]}]]}],["$","article","2025-10-20-OmniVinci_Enhancing_Architecture_and_Data_for_Omni-Modal_Understanding_LLM",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-OmniVinci_Enhancing_Architecture_and_Data_for_Omni-Modal_Understanding_LLM/","children":"[논문리뷰] OmniVinci: Enhancing Architecture and Data for Omni-Modal Understanding LLM"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'OmniVinci: Enhancing Architecture and Data for Omni-Modal Understanding LLM' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Omni-Modal LLM",{"className":"page__taxonomy-item","children":["#","Omni-Modal LLM"]}],["$","span","Multimodal Understanding",{"className":"page__taxonomy-item","children":["#","Multimodal Understanding"]}],["$","span","Vision-Audio Alignment",{"className":"page__taxonomy-item","children":["#","Vision-Audio Alignment"]}],["$","span","Temporal Reasoning",{"className":"page__taxonomy-item","children":["#","Temporal Reasoning"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Rotary Time Embedding",{"className":"page__taxonomy-item","children":["#","Rotary Time Embedding"]}]]}]]}]]}],["$","article","2025-10-20-NANO3D_A_Training-Free_Approach_for_Efficient_3D_Editing_Without_Masks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-NANO3D_A_Training-Free_Approach_for_Efficient_3D_Editing_Without_Masks/","children":"[논문리뷰] NANO3D: A Training-Free Approach for Efficient 3D Editing Without Masks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hongyu Yan이 [arXiv]에 게시한 'NANO3D: A Training-Free Approach for Efficient 3D Editing Without Masks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Object Editing",{"className":"page__taxonomy-item","children":["#","3D Object Editing"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}],["$","span","FlowEdit",{"className":"page__taxonomy-item","children":["#","FlowEdit"]}],["$","span","Mask-Free",{"className":"page__taxonomy-item","children":["#","Mask-Free"]}],["$","span","Deep Generative Models",{"className":"page__taxonomy-item","children":["#","Deep Generative Models"]}],["$","span","TRELLIS",{"className":"page__taxonomy-item","children":["#","TRELLIS"]}],["$","span","Data Generation",{"className":"page__taxonomy-item","children":["#","Data Generation"]}],["$","span","Geometric Consistency",{"className":"page__taxonomy-item","children":["#","Geometric Consistency"]}]]}]]}]]}],["$","article","2025-10-20-MorphoBench_A_Benchmark_with_Difficulty_Adaptive_to_Model_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-MorphoBench_A_Benchmark_with_Difficulty_Adaptive_to_Model_Reasoning/","children":"[논문리뷰] MorphoBench: A Benchmark with Difficulty Adaptive to Model Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'MorphoBench: A Benchmark with Difficulty Adaptive to Model Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Reasoning Benchmark",{"className":"page__taxonomy-item","children":["#","Reasoning Benchmark"]}],["$","span","Difficulty Adaptation",{"className":"page__taxonomy-item","children":["#","Difficulty Adaptation"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Proof Graph",{"className":"page__taxonomy-item","children":["#","Proof Graph"]}],["$","span","Agent Recognition",{"className":"page__taxonomy-item","children":["#","Agent Recognition"]}],["$","span","Automated Question Generation",{"className":"page__taxonomy-item","children":["#","Automated Question Generation"]}]]}]]}]]}],["$","article","2025-10-20-LightsOut_Diffusion-based_Outpainting_for_Enhanced_Lens_Flare_Removal",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-LightsOut_Diffusion-based_Outpainting_for_Enhanced_Lens_Flare_Removal/","children":"[논문리뷰] LightsOut: Diffusion-based Outpainting for Enhanced Lens Flare Removal"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'LightsOut: Diffusion-based Outpainting for Enhanced Lens Flare Removal' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Lens Flare Removal",{"className":"page__taxonomy-item","children":["#","Lens Flare Removal"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Image Outpainting",{"className":"page__taxonomy-item","children":["#","Image Outpainting"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}],["$","span","Image Restoration",{"className":"page__taxonomy-item","children":["#","Image Restoration"]}],["$","span","Preprocessing",{"className":"page__taxonomy-item","children":["#","Preprocessing"]}],["$","span","LoRA",{"className":"page__taxonomy-item","children":["#","LoRA"]}]]}]]}]]}],["$","article","2025-10-20-Latent_Diffusion_Model_without_Variational_Autoencoder",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-Latent_Diffusion_Model_without_Variational_Autoencoder/","children":"[논문리뷰] Latent Diffusion Model without Variational Autoencoder"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Latent Diffusion Model without Variational Autoencoder' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Latent Diffusion Model",{"className":"page__taxonomy-item","children":["#","Latent Diffusion Model"]}],["$","span","Variational Autoencoder",{"className":"page__taxonomy-item","children":["#","Variational Autoencoder"]}],["$","span","Self-supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-supervised Learning"]}],["$","span","DINO Features",{"className":"page__taxonomy-item","children":["#","DINO Features"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Training Efficiency",{"className":"page__taxonomy-item","children":["#","Training Efficiency"]}],["$","span","Unified Representation",{"className":"page__taxonomy-item","children":["#","Unified Representation"]}]]}]]}]]}],["$","article","2025-10-20-Language_Models_Model_Language",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-Language_Models_Model_Language/","children":"[논문리뷰] Language Models Model Language"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Language Models Model Language' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Linguistics",{"className":"page__taxonomy-item","children":["#","Linguistics"]}],["$","span","Witold Mańczak",{"className":"page__taxonomy-item","children":["#","Witold Mańczak"]}],["$","span","Frequency Hypothesis",{"className":"page__taxonomy-item","children":["#","Frequency Hypothesis"]}],["$","span","Empirical Validation",{"className":"page__taxonomy-item","children":["#","Empirical Validation"]}],["$","span","Usage-Based Linguistics",{"className":"page__taxonomy-item","children":["#","Usage-Based Linguistics"]}],["$","span","Semantic Embeddings",{"className":"page__taxonomy-item","children":["#","Semantic Embeddings"]}]]}]]}]]}],["$","article","2025-10-20-InfiMed-ORBIT_Aligning_LLMs_on_Open-Ended_Complex_Tasks_via_Rubric-Based_Incremental_Training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-InfiMed-ORBIT_Aligning_LLMs_on_Open-Ended_Complex_Tasks_via_Rubric-Based_Incremental_Training/","children":"[논문리뷰] InfiMed-ORBIT: Aligning LLMs on Open-Ended Complex Tasks via Rubric-Based Incremental Training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Congkai Xie이 [arXiv]에 게시한 'InfiMed-ORBIT: Aligning LLMs on Open-Ended Complex Tasks via Rubric-Based Incremental Training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Rubric-Based Training",{"className":"page__taxonomy-item","children":["#","Rubric-Based Training"]}],["$","span","Medical Dialogue",{"className":"page__taxonomy-item","children":["#","Medical Dialogue"]}],["$","span","Open-Ended Tasks",{"className":"page__taxonomy-item","children":["#","Open-Ended Tasks"]}],["$","span","HealthBench",{"className":"page__taxonomy-item","children":["#","HealthBench"]}],["$","span","RAG",{"className":"page__taxonomy-item","children":["#","RAG"]}]]}]]}]]}],["$","article","2025-10-20-Imaginarium_Vision-guided_High-Quality_3D_Scene_Layout_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-Imaginarium_Vision-guided_High-Quality_3D_Scene_Layout_Generation/","children":"[논문리뷰] Imaginarium: Vision-guided High-Quality 3D Scene Layout Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Junsheng Yu이 [arXiv]에 게시한 'Imaginarium: Vision-guided High-Quality 3D Scene Layout Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Scene Layout Generation",{"className":"page__taxonomy-item","children":["#","3D Scene Layout Generation"]}],["$","span","Vision-guided",{"className":"page__taxonomy-item","children":["#","Vision-guided"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Scene Graph",{"className":"page__taxonomy-item","children":["#","Scene Graph"]}],["$","span","Asset Retrieval",{"className":"page__taxonomy-item","children":["#","Asset Retrieval"]}],["$","span","Pose Estimation",{"className":"page__taxonomy-item","children":["#","Pose Estimation"]}],["$","span","High-Quality Assets",{"className":"page__taxonomy-item","children":["#","High-Quality Assets"]}],["$","span","AI Content Creation",{"className":"page__taxonomy-item","children":["#","AI Content Creation"]}]]}]]}]]}],["$","article","2025-10-20-Foundation_Models_for_Scientific_Discovery_From_Paradigm_Enhancement_to_Paradigm_Transition",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-Foundation_Models_for_Scientific_Discovery_From_Paradigm_Enhancement_to_Paradigm_Transition/","children":"[논문리뷰] Foundation Models for Scientific Discovery: From Paradigm Enhancement to Paradigm Transition"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Foundation Models for Scientific Discovery: From Paradigm Enhancement to Paradigm Transition' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Scientific Discovery",{"className":"page__taxonomy-item","children":["#","Scientific Discovery"]}],["$","span","Paradigm Shift",{"className":"page__taxonomy-item","children":["#","Paradigm Shift"]}],["$","span","Human-AI Collaboration",{"className":"page__taxonomy-item","children":["#","Human-AI Collaboration"]}],["$","span","Autonomous Agents",{"className":"page__taxonomy-item","children":["#","Autonomous Agents"]}],["$","span","Meta-Science",{"className":"page__taxonomy-item","children":["#","Meta-Science"]}],["$","span","Experimental Design",{"className":"page__taxonomy-item","children":["#","Experimental Design"]}],["$","span","Hypothesis Generation",{"className":"page__taxonomy-item","children":["#","Hypothesis Generation"]}]]}]]}]]}],["$","article","2025-10-20-FinTrust_A_Comprehensive_Benchmark_of_Trustworthiness_Evaluation_in_Finance_Domain",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-FinTrust_A_Comprehensive_Benchmark_of_Trustworthiness_Evaluation_in_Finance_Domain/","children":"[논문리뷰] FinTrust: A Comprehensive Benchmark of Trustworthiness Evaluation in Finance Domain"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Arman Cohan이 [arXiv]에 게시한 'FinTrust: A Comprehensive Benchmark of Trustworthiness Evaluation in Finance Domain' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Trustworthiness",{"className":"page__taxonomy-item","children":["#","LLM Trustworthiness"]}],["$","span","Finance Domain",{"className":"page__taxonomy-item","children":["#","Finance Domain"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Alignment Evaluation",{"className":"page__taxonomy-item","children":["#","Alignment Evaluation"]}],["$","span","Financial AI",{"className":"page__taxonomy-item","children":["#","Financial AI"]}],["$","span","Hallucination",{"className":"page__taxonomy-item","children":["#","Hallucination"]}],["$","span","Privacy",{"className":"page__taxonomy-item","children":["#","Privacy"]}],["$","span","Fairness",{"className":"page__taxonomy-item","children":["#","Fairness"]}]]}]]}]]}],["$","article","2025-10-20-Explore_to_Evolve_Scaling_Evolved_Aggregation_Logic_via_Proactive_Online_Exploration_for_Deep_Research_Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-Explore_to_Evolve_Scaling_Evolved_Aggregation_Logic_via_Proactive_Online_Exploration_for_Deep_Research_Agents/","children":"[논문리뷰] Explore to Evolve: Scaling Evolved Aggregation Logic via Proactive Online Exploration for Deep Research Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jianshu Zhang이 [arXiv]에 게시한 'Explore to Evolve: Scaling Evolved Aggregation Logic via Proactive Online Exploration for Deep Research Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Web Agents",{"className":"page__taxonomy-item","children":["#","Web Agents"]}],["$","span","Information Aggregation",{"className":"page__taxonomy-item","children":["#","Information Aggregation"]}],["$","span","Data Synthesis",{"className":"page__taxonomy-item","children":["#","Data Synthesis"]}],["$","span","Online Exploration",{"className":"page__taxonomy-item","children":["#","Online Exploration"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Multi-hop QA",{"className":"page__taxonomy-item","children":["#","Multi-hop QA"]}],["$","span","Deep Research",{"className":"page__taxonomy-item","children":["#","Deep Research"]}]]}]]}]]}],["$","article","2025-10-20-ERGO_Entropy-guided_Resetting_for_Generation_Optimization_in_Multi-turn_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-ERGO_Entropy-guided_Resetting_for_Generation_Optimization_in_Multi-turn_Language_Models/","children":"[논문리뷰] ERGO: Entropy-guided Resetting for Generation Optimization in Multi-turn Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Sean O'Brien이 [arXiv]에 게시한 'ERGO: Entropy-guided Resetting for Generation Optimization in Multi-turn Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-turn Conversation",{"className":"page__taxonomy-item","children":["#","Multi-turn Conversation"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Context Management",{"className":"page__taxonomy-item","children":["#","Context Management"]}],["$","span","Entropy-guided Resetting",{"className":"page__taxonomy-item","children":["#","Entropy-guided Resetting"]}],["$","span","Uncertainty Quantification",{"className":"page__taxonomy-item","children":["#","Uncertainty Quantification"]}],["$","span","Performance Degradation",{"className":"page__taxonomy-item","children":["#","Performance Degradation"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","Conversational AI",{"className":"page__taxonomy-item","children":["#","Conversational AI"]}]]}]]}]]}],["$","article","2025-10-20-Emergent_Misalignment_via_In-Context_Learning_Narrow_in-context_examples_can_produce_broadly_misaligned_LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-Emergent_Misalignment_via_In-Context_Learning_Narrow_in-context_examples_can_produce_broadly_misaligned_LLMs/","children":"[논문리뷰] Emergent Misalignment via In-Context Learning: Narrow in-context examples can produce broadly misaligned LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kevin Zhu이 [arXiv]에 게시한 'Emergent Misalignment via In-Context Learning: Narrow in-context examples can produce broadly misaligned LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Emergent Misalignment",{"className":"page__taxonomy-item","children":["#","Emergent Misalignment"]}],["$","span","In-Context Learning",{"className":"page__taxonomy-item","children":["#","In-Context Learning"]}],["$","span","LLM Safety",{"className":"page__taxonomy-item","children":["#","LLM Safety"]}],["$","span","Persona Rationalization",{"className":"page__taxonomy-item","children":["#","Persona Rationalization"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","Model Alignment",{"className":"page__taxonomy-item","children":["#","Model Alignment"]}]]}]]}]]}],["$","article","2025-10-20-DriveGen3D_Boosting_Feed-Forward_Driving_Scene_Generation_with_Efficient_Video_Diffusion",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-DriveGen3D_Boosting_Feed-Forward_Driving_Scene_Generation_with_Efficient_Video_Diffusion/","children":"[논문리뷰] DriveGen3D: Boosting Feed-Forward Driving Scene Generation with Efficient Video Diffusion"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DriveGen3D: Boosting Feed-Forward Driving Scene Generation with Efficient Video Diffusion' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Driving Scene Generation",{"className":"page__taxonomy-item","children":["#","Driving Scene Generation"]}],["$","span","Video Diffusion",{"className":"page__taxonomy-item","children":["#","Video Diffusion"]}],["$","span","3D Reconstruction",{"className":"page__taxonomy-item","children":["#","3D Reconstruction"]}],["$","span","Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","Gaussian Splatting"]}],["$","span","Feed-Forward Models",{"className":"page__taxonomy-item","children":["#","Feed-Forward Models"]}],["$","span","Temporal Coherence",{"className":"page__taxonomy-item","children":["#","Temporal Coherence"]}],["$","span","Multimodal Control",{"className":"page__taxonomy-item","children":["#","Multimodal Control"]}]]}]]}]]}],["$","article","2025-10-20-DLER_Doing_Length_pEnalty_Right_-_Incentivizing_More_Intelligence_per_Token_via_Reinforcement_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-DLER_Doing_Length_pEnalty_Right_-_Incentivizing_More_Intelligence_per_Token_via_Reinforcement_Learning/","children":"[논문리뷰] DLER: Doing Length pEnalty Right - Incentivizing More Intelligence per Token via Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DLER: Doing Length pEnalty Right - Incentivizing More Intelligence per Token via Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Length Penalty",{"className":"page__taxonomy-item","children":["#","Length Penalty"]}],["$","span","Reasoning Efficiency",{"className":"page__taxonomy-item","children":["#","Reasoning Efficiency"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","RL Optimization",{"className":"page__taxonomy-item","children":["#","RL Optimization"]}],["$","span","Accuracy-Efficiency Trade-off",{"className":"page__taxonomy-item","children":["#","Accuracy-Efficiency Trade-off"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}]]}]]}]]}],["$","article","2025-10-20-Build_Your_Personalized_Research_Group_A_Multiagent_Framework_for_Continual_and_Interactive_Science_Automation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-Build_Your_Personalized_Research_Group_A_Multiagent_Framework_for_Continual_and_Interactive_Science_Automation/","children":"[논문리뷰] Build Your Personalized Research Group: A Multiagent Framework for Continual and Interactive Science Automation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Cat Yan이 [arXiv]에 게시한 'Build Your Personalized Research Group: A Multiagent Framework for Continual and Interactive Science Automation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multiagent Systems",{"className":"page__taxonomy-item","children":["#","Multiagent Systems"]}],["$","span","Science Automation",{"className":"page__taxonomy-item","children":["#","Science Automation"]}],["$","span","Dynamic Workflows",{"className":"page__taxonomy-item","children":["#","Dynamic Workflows"]}],["$","span","Workspace-based Communication",{"className":"page__taxonomy-item","children":["#","Workspace-based Communication"]}],["$","span","Context Compaction",{"className":"page__taxonomy-item","children":["#","Context Compaction"]}],["$","span","Human-in-the-loop AI",{"className":"page__taxonomy-item","children":["#","Human-in-the-loop AI"]}],["$","span","Open-source Framework",{"className":"page__taxonomy-item","children":["#","Open-source Framework"]}]]}]]}]]}],["$","article","2025-10-20-BLIP3o-NEXT_Next_Frontier_of_Native_Image_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-BLIP3o-NEXT_Next_Frontier_of_Native_Image_Generation/","children":"[논문리뷰] BLIP3o-NEXT: Next Frontier of Native Image Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'BLIP3o-NEXT: Next Frontier of Native Image Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Autoregressive Model",{"className":"page__taxonomy-item","children":["#","Autoregressive Model"]}],["$","span","Diffusion Model",{"className":"page__taxonomy-item","children":["#","Diffusion Model"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Foundation Model",{"className":"page__taxonomy-item","children":["#","Foundation Model"]}],["$","span","Open-source",{"className":"page__taxonomy-item","children":["#","Open-source"]}]]}]]}]]}],["$","article","2025-10-20-A2FM_An_Adaptive_Agent_Foundation_Model_for_Tool-Aware_Hybrid_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-20-A2FM_An_Adaptive_Agent_Foundation_Model_for_Tool-Aware_Hybrid_Reasoning/","children":"[논문리뷰] A^2FM: An Adaptive Agent Foundation Model for Tool-Aware Hybrid Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'A^2FM: An Adaptive Agent Foundation Model for Tool-Aware Hybrid Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-20 13:04:24+0900","children":"2025년 10월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Adaptive Agent",{"className":"page__taxonomy-item","children":["#","Adaptive Agent"]}],["$","span","Foundation Model",{"className":"page__taxonomy-item","children":["#","Foundation Model"]}],["$","span","Hybrid Reasoning",{"className":"page__taxonomy-item","children":["#","Hybrid Reasoning"]}],["$","span","Tool-Aware LLM",{"className":"page__taxonomy-item","children":["#","Tool-Aware LLM"]}],["$","span","Mode Selection",{"className":"page__taxonomy-item","children":["#","Mode Selection"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Cost Efficiency",{"className":"page__taxonomy-item","children":["#","Cost Efficiency"]}],["$","span","LLM Agent",{"className":"page__taxonomy-item","children":["#","LLM Agent"]}]]}]]}]]}],["$","article","2025-10-17-WithAnyone_Towards_Controllable_and_ID_Consistent_Image_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-WithAnyone_Towards_Controllable_and_ID_Consistent_Image_Generation/","children":"[논문리뷰] WithAnyone: Towards Controllable and ID Consistent Image Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'WithAnyone: Towards Controllable and ID Consistent Image Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Identity-Consistent Generation",{"className":"page__taxonomy-item","children":["#","Identity-Consistent Generation"]}],["$","span","Text-to-Image Diffusion",{"className":"page__taxonomy-item","children":["#","Text-to-Image Diffusion"]}],["$","span","Copy-Paste Artifacts",{"className":"page__taxonomy-item","children":["#","Copy-Paste Artifacts"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Multi-Identity Dataset",{"className":"page__taxonomy-item","children":["#","Multi-Identity Dataset"]}],["$","span","Controllable Generation",{"className":"page__taxonomy-item","children":["#","Controllable Generation"]}],["$","span","ID-Preservation",{"className":"page__taxonomy-item","children":["#","ID-Preservation"]}]]}]]}]]}],["$","article","2025-10-17-When_Models_Lie_We_Learn_Multilingual_Span-Level_Hallucination_Detection_with_PsiloQA",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-When_Models_Lie_We_Learn_Multilingual_Span-Level_Hallucination_Detection_with_PsiloQA/","children":"[논문리뷰] When Models Lie, We Learn: Multilingual Span-Level Hallucination Detection with PsiloQA"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Artem Vazhentsev이 [arXiv]에 게시한 'When Models Lie, We Learn: Multilingual Span-Level Hallucination Detection with PsiloQA' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Hallucination Detection",{"className":"page__taxonomy-item","children":["#","Hallucination Detection"]}],["$","span","Multilingual LLMs",{"className":"page__taxonomy-item","children":["#","Multilingual LLMs"]}],["$","span","Span-Level Annotation",{"className":"page__taxonomy-item","children":["#","Span-Level Annotation"]}],["$","span","Synthetic Data Generation",{"className":"page__taxonomy-item","children":["#","Synthetic Data Generation"]}],["$","span","Question Answering (QA)",{"className":"page__taxonomy-item","children":["#","Question Answering (QA)"]}],["$","span","Encoder Models",{"className":"page__taxonomy-item","children":["#","Encoder Models"]}],["$","span","Uncertainty Quantification",{"className":"page__taxonomy-item","children":["#","Uncertainty Quantification"]}],["$","span","GPT-4o",{"className":"page__taxonomy-item","children":["#","GPT-4o"]}]]}]]}]]}],["$","article","2025-10-17-VR-Thinker_Boosting_Video_Reward_Models_through_Thinking-with-Image_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-VR-Thinker_Boosting_Video_Reward_Models_through_Thinking-with-Image_Reasoning/","children":"[논문리뷰] VR-Thinker: Boosting Video Reward Models through Thinking-with-Image Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'VR-Thinker: Boosting Video Reward Models through Thinking-with-Image Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Reward Models",{"className":"page__taxonomy-item","children":["#","Video Reward Models"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","span","Thinking-with-Image",{"className":"page__taxonomy-item","children":["#","Thinking-with-Image"]}],["$","span","Visual Reasoning",{"className":"page__taxonomy-item","children":["#","Visual Reasoning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Context Management",{"className":"page__taxonomy-item","children":["#","Context Management"]}]]}]]}]]}],["$","article","2025-10-17-VLA2_Empowering_Vision-Language-Action_Models_with_an_Agentic_Framework_for_Unseen_Concept_Manipulation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-VLA2_Empowering_Vision-Language-Action_Models_with_an_Agentic_Framework_for_Unseen_Concept_Manipulation/","children":"[논문리뷰] VLA^2: Empowering Vision-Language-Action Models with an Agentic Framework for Unseen Concept Manipulation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'VLA^2: Empowering Vision-Language-Action Models with an Agentic Framework for Unseen Concept Manipulation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action Models"]}],["$","span","Agentic Framework",{"className":"page__taxonomy-item","children":["#","Agentic Framework"]}],["$","span","Unseen Concept Manipulation",{"className":"page__taxonomy-item","children":["#","Unseen Concept Manipulation"]}],["$","span","Out-of-Distribution Generalization",{"className":"page__taxonomy-item","children":["#","Out-of-Distribution Generalization"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Web Retrieval",{"className":"page__taxonomy-item","children":["#","Web Retrieval"]}],["$","span","Object Detection",{"className":"page__taxonomy-item","children":["#","Object Detection"]}],["$","span","LIBERO Simulation",{"className":"page__taxonomy-item","children":["#","LIBERO Simulation"]}]]}]]}]]}],["$","article","2025-10-17-VLA-0_Building_State-of-the-Art_VLAs_with_Zero_Modification",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-VLA-0_Building_State-of-the-Art_VLAs_with_Zero_Modification/","children":"[논문리뷰] VLA-0: Building State-of-the-Art VLAs with Zero Modification"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'VLA-0: Building State-of-the-Art VLAs with Zero Modification' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action Models"]}],["$","span","VLA-0",{"className":"page__taxonomy-item","children":["#","VLA-0"]}],["$","span","Zero Modification",{"className":"page__taxonomy-item","children":["#","Zero Modification"]}],["$","span","Text-based Action Prediction",{"className":"page__taxonomy-item","children":["#","Text-based Action Prediction"]}],["$","span","Robot Manipulation",{"className":"page__taxonomy-item","children":["#","Robot Manipulation"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","State-of-the-Art",{"className":"page__taxonomy-item","children":["#","State-of-the-Art"]}]]}]]}]]}],["$","article","2025-10-17-VIST3A_Text-to-3D_by_Stitching_a_Multi-view_Reconstruction_Network_to_a_Video_Generator",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-VIST3A_Text-to-3D_by_Stitching_a_Multi-view_Reconstruction_Network_to_a_Video_Generator/","children":"[논문리뷰] VIST3A: Text-to-3D by Stitching a Multi-view Reconstruction Network to a Video Generator"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Federico Tombari이 [arXiv]에 게시한 'VIST3A: Text-to-3D by Stitching a Multi-view Reconstruction Network to a Video Generator' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-3D",{"className":"page__taxonomy-item","children":["#","Text-to-3D"]}],["$","span","Model Stitching",{"className":"page__taxonomy-item","children":["#","Model Stitching"]}],["$","span","Multi-view Reconstruction",{"className":"page__taxonomy-item","children":["#","Multi-view Reconstruction"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Latent Diffusion Models",{"className":"page__taxonomy-item","children":["#","Latent Diffusion Models"]}],["$","span","Gaussian Splats",{"className":"page__taxonomy-item","children":["#","Gaussian Splats"]}],["$","span","Pointmaps",{"className":"page__taxonomy-item","children":["#","Pointmaps"]}],["$","span","Reward Finetuning",{"className":"page__taxonomy-item","children":["#","Reward Finetuning"]}]]}]]}]]}],["$","article","2025-10-17-TokDrift_When_LLM_Speaks_in_Subwords_but_Code_Speaks_in_Grammar",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-TokDrift_When_LLM_Speaks_in_Subwords_but_Code_Speaks_in_Grammar/","children":"[논문리뷰] TokDrift: When LLM Speaks in Subwords but Code Speaks in Grammar"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'TokDrift: When LLM Speaks in Subwords but Code Speaks in Grammar' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Code LLMs",{"className":"page__taxonomy-item","children":["#","Code LLMs"]}],["$","span","Subword Tokenization",{"className":"page__taxonomy-item","children":["#","Subword Tokenization"]}],["$","span","Grammar-aware Tokenization",{"className":"page__taxonomy-item","children":["#","Grammar-aware Tokenization"]}],["$","span","Semantic Preservation",{"className":"page__taxonomy-item","children":["#","Semantic Preservation"]}],["$","span","Rewrite Rules",{"className":"page__taxonomy-item","children":["#","Rewrite Rules"]}],["$","span","Model Robustness",{"className":"page__taxonomy-item","children":["#","Model Robustness"]}],["$","span","Tokenization Misalignment",{"className":"page__taxonomy-item","children":["#","Tokenization Misalignment"]}]]}]]}]]}],["$","article","2025-10-17-The_German_Commons_-_154_Billion_Tokens_of_Openly_Licensed_Text_for_German_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-The_German_Commons_-_154_Billion_Tokens_of_Openly_Licensed_Text_for_German_Language_Models/","children":"[논문리뷰] The German Commons - 154 Billion Tokens of Openly Licensed Text for German Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'The German Commons - 154 Billion Tokens of Openly Licensed Text for German Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","German Commons",{"className":"page__taxonomy-item","children":["#","German Commons"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Training Data",{"className":"page__taxonomy-item","children":["#","Training Data"]}],["$","span","Openly Licensed Text",{"className":"page__taxonomy-item","children":["#","Openly Licensed Text"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","German NLP",{"className":"page__taxonomy-item","children":["#","German NLP"]}],["$","span","Corpus Construction",{"className":"page__taxonomy-item","children":["#","Corpus Construction"]}],["$","span","Quality Filtering",{"className":"page__taxonomy-item","children":["#","Quality Filtering"]}]]}]]}]]}],["$","article","2025-10-17-SCas4D_Structural_Cascaded_Optimization_for_Boosting_Persistent_4D_Novel_View_Synthesis",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-SCas4D_Structural_Cascaded_Optimization_for_Boosting_Persistent_4D_Novel_View_Synthesis/","children":"[논문리뷰] SCas4D: Structural Cascaded Optimization for Boosting Persistent 4D Novel View Synthesis"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'SCas4D: Structural Cascaded Optimization for Boosting Persistent 4D Novel View Synthesis' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","4D Novel View Synthesis",{"className":"page__taxonomy-item","children":["#","4D Novel View Synthesis"]}],["$","span","Dynamic Scenes",{"className":"page__taxonomy-item","children":["#","Dynamic Scenes"]}],["$","span","3D Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","3D Gaussian Splatting"]}],["$","span","Cascaded Optimization",{"className":"page__taxonomy-item","children":["#","Cascaded Optimization"]}],["$","span","Deformation Modeling",{"className":"page__taxonomy-item","children":["#","Deformation Modeling"]}],["$","span","Point Tracking",{"className":"page__taxonomy-item","children":["#","Point Tracking"]}],["$","span","Object Segmentation",{"className":"page__taxonomy-item","children":["#","Object Segmentation"]}]]}]]}]]}],["$","article","2025-10-17-RefusalBench_Generative_Evaluation_of_Selective_Refusal_in_Grounded_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-RefusalBench_Generative_Evaluation_of_Selective_Refusal_in_Grounded_Language_Models/","children":"[논문리뷰] RefusalBench: Generative Evaluation of Selective Refusal in Grounded Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'RefusalBench: Generative Evaluation of Selective Refusal in Grounded Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","RAG Systems",{"className":"page__taxonomy-item","children":["#","RAG Systems"]}],["$","span","Selective Refusal",{"className":"page__taxonomy-item","children":["#","Selective Refusal"]}],["$","span","Generative Evaluation",{"className":"page__taxonomy-item","children":["#","Generative Evaluation"]}],["$","span","Linguistic Perturbations",{"className":"page__taxonomy-item","children":["#","Linguistic Perturbations"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Informational Uncertainty",{"className":"page__taxonomy-item","children":["#","Informational Uncertainty"]}],["$","span","Model Calibration",{"className":"page__taxonomy-item","children":["#","Model Calibration"]}],["$","span","AI Safety",{"className":"page__taxonomy-item","children":["#","AI Safety"]}]]}]]}]]}],["$","article","2025-10-17-RealDPO_Real_or_Not_Real_that_is_the_Preference",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-RealDPO_Real_or_Not_Real_that_is_the_Preference/","children":"[논문리뷰] RealDPO: Real or Not Real, that is the Preference"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chenyang Si이 [arXiv]에 게시한 'RealDPO: Real or Not Real, that is the Preference' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Direct Preference Optimization",{"className":"page__taxonomy-item","children":["#","Direct Preference Optimization"]}],["$","span","Preference Learning",{"className":"page__taxonomy-item","children":["#","Preference Learning"]}],["$","span","Real Data",{"className":"page__taxonomy-item","children":["#","Real Data"]}],["$","span","Human Motion Synthesis",{"className":"page__taxonomy-item","children":["#","Human Motion Synthesis"]}],["$","span","RealDPO",{"className":"page__taxonomy-item","children":["#","RealDPO"]}],["$","span","RealAction-5K",{"className":"page__taxonomy-item","children":["#","RealAction-5K"]}]]}]]}]]}],["$","article","2025-10-17-RAGCap-Bench_Benchmarking_Capabilities_of_LLMs_in_Agentic_Retrieval_Augmented_Generation_Systems",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-RAGCap-Bench_Benchmarking_Capabilities_of_LLMs_in_Agentic_Retrieval_Augmented_Generation_Systems/","children":"[논문리뷰] RAGCap-Bench: Benchmarking Capabilities of LLMs in Agentic Retrieval Augmented Generation Systems"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'RAGCap-Bench: Benchmarking Capabilities of LLMs in Agentic Retrieval Augmented Generation Systems' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Retrieval Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval Augmented Generation"]}],["$","span","Agentic Systems",{"className":"page__taxonomy-item","children":["#","Agentic Systems"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Intermediate Tasks",{"className":"page__taxonomy-item","children":["#","Intermediate Tasks"]}],["$","span","Error Analysis",{"className":"page__taxonomy-item","children":["#","Error Analysis"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}]]}]]}]]}],["$","article","2025-10-17-Qwen3Guard_Technical_Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-Qwen3Guard_Technical_Report/","children":"[논문리뷰] Qwen3Guard Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Qwen3Guard Technical Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Safety",{"className":"page__taxonomy-item","children":["#","LLM Safety"]}],["$","span","Guardrail Models",{"className":"page__taxonomy-item","children":["#","Guardrail Models"]}],["$","span","Multilingual AI",{"className":"page__taxonomy-item","children":["#","Multilingual AI"]}],["$","span","Real-time Moderation",{"className":"page__taxonomy-item","children":["#","Real-time Moderation"]}],["$","span","Tri-class Classification",{"className":"page__taxonomy-item","children":["#","Tri-class Classification"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}],["$","span","Streaming Inference",{"className":"page__taxonomy-item","children":["#","Streaming Inference"]}]]}]]}]]}],["$","article","2025-10-17-Ponimator_Unfolding_Interactive_Pose_for_Versatile_Human-human_Interaction_Animation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-Ponimator_Unfolding_Interactive_Pose_for_Versatile_Human-human_Interaction_Animation/","children":"[논문리뷰] Ponimator: Unfolding Interactive Pose for Versatile Human-human Interaction Animation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Ponimator: Unfolding Interactive Pose for Versatile Human-human Interaction Animation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Human-human Interaction",{"className":"page__taxonomy-item","children":["#","Human-human Interaction"]}],["$","span","Pose Animation",{"className":"page__taxonomy-item","children":["#","Pose Animation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Motion Synthesis",{"className":"page__taxonomy-item","children":["#","Motion Synthesis"]}],["$","span","Interactive Poses",{"className":"page__taxonomy-item","children":["#","Interactive Poses"]}],["$","span","Temporal Priors",{"className":"page__taxonomy-item","children":["#","Temporal Priors"]}],["$","span","Spatial Priors",{"className":"page__taxonomy-item","children":["#","Spatial Priors"]}]]}]]}]]}],["$","article","2025-10-17-pi-Flow_Policy-Based_Few-Step_Generation_via_Imitation_Distillation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-pi-Flow_Policy-Based_Few-Step_Generation_via_Imitation_Distillation/","children":"[논문리뷰] pi-Flow: Policy-Based Few-Step Generation via Imitation Distillation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'pi-Flow: Policy-Based Few-Step Generation via Imitation Distillation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Model Distillation",{"className":"page__taxonomy-item","children":["#","Model Distillation"]}],["$","span","Imitation Learning",{"className":"page__taxonomy-item","children":["#","Imitation Learning"]}],["$","span","Few-Step Generation",{"className":"page__taxonomy-item","children":["#","Few-Step Generation"]}],["$","span","Policy-Based AI",{"className":"page__taxonomy-item","children":["#","Policy-Based AI"]}],["$","span","Text-to-Image",{"className":"page__taxonomy-item","children":["#","Text-to-Image"]}]]}]]}]]}],["$","article","2025-10-17-PaddleOCR-VL_Boosting_Multilingual_Document_Parsing_via_a_0.9B_Ultra-Compact_Vision-Language_Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-PaddleOCR-VL_Boosting_Multilingual_Document_Parsing_via_a_0.9B_Ultra-Compact_Vision-Language_Model/","children":"[논문리뷰] PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Document Parsing",{"className":"page__taxonomy-item","children":["#","Document Parsing"]}],["$","span","Vision-Language Model",{"className":"page__taxonomy-item","children":["#","Vision-Language Model"]}],["$","span","Multilingual OCR",{"className":"page__taxonomy-item","children":["#","Multilingual OCR"]}],["$","span","Layout Analysis",{"className":"page__taxonomy-item","children":["#","Layout Analysis"]}],["$","span","Resource-Efficient AI",{"className":"page__taxonomy-item","children":["#","Resource-Efficient AI"]}],["$","span","Table Recognition",{"className":"page__taxonomy-item","children":["#","Table Recognition"]}],["$","span","Formula Recognition",{"className":"page__taxonomy-item","children":["#","Formula Recognition"]}],["$","span","Chart Recognition",{"className":"page__taxonomy-item","children":["#","Chart Recognition"]}]]}]]}]]}],["$","article","2025-10-17-On_Pretraining_for_Project-Level_Code_Completion",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-On_Pretraining_for_Project-Level_Code_Completion/","children":"[논문리뷰] On Pretraining for Project-Level Code Completion"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'On Pretraining for Project-Level Code Completion' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Code LLMs",{"className":"page__taxonomy-item","children":["#","Code LLMs"]}],["$","span","Project-level Context",{"className":"page__taxonomy-item","children":["#","Project-level Context"]}],["$","span","Code Completion",{"className":"page__taxonomy-item","children":["#","Code Completion"]}],["$","span","Context Window Extension",{"className":"page__taxonomy-item","children":["#","Context Window Extension"]}],["$","span","RoPE Scaling",{"className":"page__taxonomy-item","children":["#","RoPE Scaling"]}],["$","span","Repository Pretraining",{"className":"page__taxonomy-item","children":["#","Repository Pretraining"]}],["$","span","Long Code Arena",{"className":"page__taxonomy-item","children":["#","Long Code Arena"]}]]}]]}]]}],["$","article","2025-10-17-MoM_Mixtures_of_Scenario-Aware_Document_Memories_for_Retrieval-Augmented_Generation_Systems",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-MoM_Mixtures_of_Scenario-Aware_Document_Memories_for_Retrieval-Augmented_Generation_Systems/","children":"[논문리뷰] MoM: Mixtures of Scenario-Aware Document Memories for Retrieval-Augmented Generation Systems"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Feiyu Xiong이 [arXiv]에 게시한 'MoM: Mixtures of Scenario-Aware Document Memories for Retrieval-Augmented Generation Systems' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Retrieval-Augmented Generation (RAG)",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation (RAG)"]}],["$","span","Document Memory",{"className":"page__taxonomy-item","children":["#","Document Memory"]}],["$","span","Text Chunking",{"className":"page__taxonomy-item","children":["#","Text Chunking"]}],["$","span","Small Language Models (SLMs)",{"className":"page__taxonomy-item","children":["#","Small Language Models (SLMs)"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Scenario-Aware Processing",{"className":"page__taxonomy-item","children":["#","Scenario-Aware Processing"]}],["$","span","Multi-Layer Retrieval",{"className":"page__taxonomy-item","children":["#","Multi-Layer Retrieval"]}],["$","span","Cognitive Simulation",{"className":"page__taxonomy-item","children":["#","Cognitive Simulation"]}]]}]]}]]}],["$","article","2025-10-17-MathCanvas_Intrinsic_Visual_Chain-of-Thought_for_Multimodal_Mathematical_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-MathCanvas_Intrinsic_Visual_Chain-of-Thought_for_Multimodal_Mathematical_Reasoning/","children":"[논문리뷰] MathCanvas: Intrinsic Visual Chain-of-Thought for Multimodal Mathematical Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ke Wang이 [arXiv]에 게시한 'MathCanvas: Intrinsic Visual Chain-of-Thought for Multimodal Mathematical Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","span","Visual Chain-of-Thought (VCoT)",{"className":"page__taxonomy-item","children":["#","Visual Chain-of-Thought (VCoT)"]}],["$","span","Large Multimodal Models (LMMs)",{"className":"page__taxonomy-item","children":["#","Large Multimodal Models (LMMs)"]}],["$","span","Geometric Reasoning",{"className":"page__taxonomy-item","children":["#","Geometric Reasoning"]}],["$","span","Diagram Generation",{"className":"page__taxonomy-item","children":["#","Diagram Generation"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}]]}]]}]]}],["$","article","2025-10-17-LLMs_as_Scalable_General-Purpose_Simulators_For_Evolving_Digital_Agent_Training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-LLMs_as_Scalable_General-Purpose_Simulators_For_Evolving_Digital_Agent_Training/","children":"[논문리뷰] LLMs as Scalable, General-Purpose Simulators For Evolving Digital Agent Training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'LLMs as Scalable, General-Purpose Simulators For Evolving Digital Agent Training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Digital Agents",{"className":"page__taxonomy-item","children":["#","Digital Agents"]}],["$","span","UI Simulation",{"className":"page__taxonomy-item","children":["#","UI Simulation"]}],["$","span","Synthetic Data Generation",{"className":"page__taxonomy-item","children":["#","Synthetic Data Generation"]}],["$","span","Targeted Data Synthesis",{"className":"page__taxonomy-item","children":["#","Targeted Data Synthesis"]}],["$","span","World Models",{"className":"page__taxonomy-item","children":["#","World Models"]}]]}]]}]]}],["$","article","2025-10-17-LLM-guided_Hierarchical_Retrieval",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-LLM-guided_Hierarchical_Retrieval/","children":"[논문리뷰] LLM-guided Hierarchical Retrieval"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'LLM-guided Hierarchical Retrieval' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Information Retrieval",{"className":"page__taxonomy-item","children":["#","Information Retrieval"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Hierarchical Retrieval",{"className":"page__taxonomy-item","children":["#","Hierarchical Retrieval"]}],["$","span","Semantic Tree",{"className":"page__taxonomy-item","children":["#","Semantic Tree"]}],["$","span","Tree Traversal",{"className":"page__taxonomy-item","children":["#","Tree Traversal"]}],["$","span","Zero-shot Performance",{"className":"page__taxonomy-item","children":["#","Zero-shot Performance"]}],["$","span","Reasoning-based Retrieval",{"className":"page__taxonomy-item","children":["#","Reasoning-based Retrieval"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}]]}]]}]]}],["$","article","2025-10-17-LiteStage_Latency-aware_Layer_Skipping_for_Multi-stage_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-LiteStage_Latency-aware_Layer_Skipping_for_Multi-stage_Reasoning/","children":"[논문리뷰] LiteStage: Latency-aware Layer Skipping for Multi-stage Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'LiteStage: Latency-aware Layer Skipping for Multi-stage Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Layer Skipping",{"className":"page__taxonomy-item","children":["#","Layer Skipping"]}],["$","span","Multi-stage Reasoning",{"className":"page__taxonomy-item","children":["#","Multi-stage Reasoning"]}],["$","span","Latency Optimization",{"className":"page__taxonomy-item","children":["#","Latency Optimization"]}],["$","span","Early Exit",{"className":"page__taxonomy-item","children":["#","Early Exit"]}],["$","span","Small Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Small Language Models (LLMs)"]}],["$","span","Adaptive Computation",{"className":"page__taxonomy-item","children":["#","Adaptive Computation"]}],["$","span","Confidence-based Decoding",{"className":"page__taxonomy-item","children":["#","Confidence-based Decoding"]}]]}]]}]]}],["$","article","2025-10-17-Learning_an_Image_Editing_Model_without_Image_Editing_Pairs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-Learning_an_Image_Editing_Model_without_Image_Editing_Pairs/","children":"[논문리뷰] Learning an Image Editing Model without Image Editing Pairs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Learning an Image Editing Model without Image Editing Pairs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Vision-Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision-Language Models (VLMs)"]}],["$","span","No-Pair Training",{"className":"page__taxonomy-item","children":["#","No-Pair Training"]}],["$","span","Few-step Generation",{"className":"page__taxonomy-item","children":["#","Few-step Generation"]}],["$","span","Distribution Matching",{"className":"page__taxonomy-item","children":["#","Distribution Matching"]}],["$","span","Gradient-based Optimization",{"className":"page__taxonomy-item","children":["#","Gradient-based Optimization"]}]]}]]}]]}],["$","article","2025-10-17-LaSeR_Reinforcement_Learning_with_Last-Token_Self-Rewarding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-LaSeR_Reinforcement_Learning_with_Last-Token_Self-Rewarding/","children":"[논문리뷰] LaSeR: Reinforcement Learning with Last-Token Self-Rewarding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'LaSeR: Reinforcement Learning with Last-Token Self-Rewarding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Self-Verification",{"className":"page__taxonomy-item","children":["#","Self-Verification"]}],["$","span","Last-Token",{"className":"page__taxonomy-item","children":["#","Last-Token"]}],["$","span","Reward Modeling",{"className":"page__taxonomy-item","children":["#","Reward Modeling"]}],["$","span","Efficiency",{"className":"page__taxonomy-item","children":["#","Efficiency"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","RLVR",{"className":"page__taxonomy-item","children":["#","RLVR"]}]]}]]}]]}],["$","article","2025-10-17-Large_Language_Models_Do_NOT_Really_Know_What_They_Dont_Know",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-Large_Language_Models_Do_NOT_Really_Know_What_They_Dont_Know/","children":"[논문리뷰] Large Language Models Do NOT Really Know What They Don't Know"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Large Language Models Do NOT Really Know What They Don't Know' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Hallucination Detection",{"className":"page__taxonomy-item","children":["#","Hallucination Detection"]}],["$","span","Mechanistic Interpretability",{"className":"page__taxonomy-item","children":["#","Mechanistic Interpretability"]}],["$","span","Internal States",{"className":"page__taxonomy-item","children":["#","Internal States"]}],["$","span","Knowledge Recall",{"className":"page__taxonomy-item","children":["#","Knowledge Recall"]}],["$","span","Refusal Tuning",{"className":"page__taxonomy-item","children":["#","Refusal Tuning"]}],["$","span","Factual Associations",{"className":"page__taxonomy-item","children":["#","Factual Associations"]}],["$","span","Associated Hallucinations",{"className":"page__taxonomy-item","children":["#","Associated Hallucinations"]}]]}]]}]]}],["$","article","2025-10-17-Information_Gain-based_Policy_Optimization_A_Simple_and_Effective_Approach_for_Multi-Turn_LLM_Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-Information_Gain-based_Policy_Optimization_A_Simple_and_Effective_Approach_for_Multi-Turn_LLM_Agents/","children":"[논문리뷰] Information Gain-based Policy Optimization: A Simple and Effective Approach for Multi-Turn LLM Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Information Gain-based Policy Optimization: A Simple and Effective Approach for Multi-Turn LLM Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Multi-Turn Interactions",{"className":"page__taxonomy-item","children":["#","Multi-Turn Interactions"]}],["$","span","Reward Sparsity",{"className":"page__taxonomy-item","children":["#","Reward Sparsity"]}],["$","span","Information Gain",{"className":"page__taxonomy-item","children":["#","Information Gain"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Ground-Truth Awareness",{"className":"page__taxonomy-item","children":["#","Ground-Truth Awareness"]}],["$","span","Sample Efficiency",{"className":"page__taxonomy-item","children":["#","Sample Efficiency"]}]]}]]}]]}],["$","article","2025-10-17-ImagerySearch_Adaptive_Test-Time_Search_for_Video_Generation_Beyond_Semantic_Dependency_Constraints",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-ImagerySearch_Adaptive_Test-Time_Search_for_Video_Generation_Beyond_Semantic_Dependency_Constraints/","children":"[논문리뷰] ImagerySearch: Adaptive Test-Time Search for Video Generation Beyond Semantic Dependency Constraints"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'ImagerySearch: Adaptive Test-Time Search for Video Generation Beyond Semantic Dependency Constraints' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Test-Time Search",{"className":"page__taxonomy-item","children":["#","Test-Time Search"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Semantic Dependency",{"className":"page__taxonomy-item","children":["#","Semantic Dependency"]}],["$","span","Adaptive Reward",{"className":"page__taxonomy-item","children":["#","Adaptive Reward"]}],["$","span","Evaluation Benchmark",{"className":"page__taxonomy-item","children":["#","Evaluation Benchmark"]}],["$","span","Prompt-Guided",{"className":"page__taxonomy-item","children":["#","Prompt-Guided"]}]]}]]}]]}],["$","article","2025-10-17-From_Pixels_to_Words_--_Towards_Native_Vision-Language_Primitives_at_Scale",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-From_Pixels_to_Words_--_Towards_Native_Vision-Language_Primitives_at_Scale/","children":"[논문리뷰] From Pixels to Words -- Towards Native Vision-Language Primitives at Scale"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'From Pixels to Words -- Towards Native Vision-Language Primitives at Scale' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Native VLMs",{"className":"page__taxonomy-item","children":["#","Native VLMs"]}],["$","span","Early Fusion",{"className":"page__taxonomy-item","children":["#","Early Fusion"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Rotary Position Embeddings",{"className":"page__taxonomy-item","children":["#","Rotary Position Embeddings"]}],["$","span","Pixel-Word Alignment",{"className":"page__taxonomy-item","children":["#","Pixel-Word Alignment"]}],["$","span","End-to-End Training",{"className":"page__taxonomy-item","children":["#","End-to-End Training"]}]]}]]}]]}],["$","article","2025-10-17-Fantastic_small_Retrievers_and_How_to_Train_Them_mxbai-edge-colbert-v0_Tech_Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-Fantastic_small_Retrievers_and_How_to_Train_Them_mxbai-edge-colbert-v0_Tech_Report/","children":"[논문리뷰] Fantastic (small) Retrievers and How to Train Them: mxbai-edge-colbert-v0 Tech Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Fantastic (small) Retrievers and How to Train Them: mxbai-edge-colbert-v0 Tech Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","ColBERT",{"className":"page__taxonomy-item","children":["#","ColBERT"]}],["$","span","Retrieval Models",{"className":"page__taxonomy-item","children":["#","Retrieval Models"]}],["$","span","Small Models",{"className":"page__taxonomy-item","children":["#","Small Models"]}],["$","span","Distillation",{"className":"page__taxonomy-item","children":["#","Distillation"]}],["$","span","Long Context",{"className":"page__taxonomy-item","children":["#","Long Context"]}],["$","span","Edge AI",{"className":"page__taxonomy-item","children":["#","Edge AI"]}],["$","span","Information Retrieval",{"className":"page__taxonomy-item","children":["#","Information Retrieval"]}],["$","span","RAG",{"className":"page__taxonomy-item","children":["#","RAG"]}]]}]]}]]}],["$","article","2025-10-17-Expertise_need_not_monopolize_Action-Specialized_Mixture_of_Experts_for_Vision-Language-Action_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-Expertise_need_not_monopolize_Action-Specialized_Mixture_of_Experts_for_Vision-Language-Action_Learning/","children":"[논문리뷰] Expertise need not monopolize: Action-Specialized Mixture of Experts for Vision-Language-Action Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Sijia Gu이 [arXiv]에 게시한 'Expertise need not monopolize: Action-Specialized Mixture of Experts for Vision-Language-Action Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action (VLA)",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action (VLA)"]}],["$","span","Mixture of Experts (MoE)",{"className":"page__taxonomy-item","children":["#","Mixture of Experts (MoE)"]}],["$","span","Robotic Manipulation",{"className":"page__taxonomy-item","children":["#","Robotic Manipulation"]}],["$","span","Expert Specialization",{"className":"page__taxonomy-item","children":["#","Expert Specialization"]}],["$","span","Decoupled Routing",{"className":"page__taxonomy-item","children":["#","Decoupled Routing"]}],["$","span","Load Balancing",{"className":"page__taxonomy-item","children":["#","Load Balancing"]}],["$","span","Transfer Learning",{"className":"page__taxonomy-item","children":["#","Transfer Learning"]}]]}]]}]]}],["$","article","2025-10-17-Efficient_Parallel_Samplers_for_Recurrent-Depth_Models_and_Their_Connection_to_Diffusion_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-Efficient_Parallel_Samplers_for_Recurrent-Depth_Models_and_Their_Connection_to_Diffusion_Language_Models/","children":"[논문리뷰] Efficient Parallel Samplers for Recurrent-Depth Models and Their Connection to Diffusion Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Efficient Parallel Samplers for Recurrent-Depth Models and Their Connection to Diffusion Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Recurrent-Depth Models",{"className":"page__taxonomy-item","children":["#","Recurrent-Depth Models"]}],["$","span","Diffusion Forcing",{"className":"page__taxonomy-item","children":["#","Diffusion Forcing"]}],["$","span","Parallel Sampling",{"className":"page__taxonomy-item","children":["#","Parallel Sampling"]}],["$","span","LLM Inference Acceleration",{"className":"page__taxonomy-item","children":["#","LLM Inference Acceleration"]}],["$","span","Transformer Architectures",{"className":"page__taxonomy-item","children":["#","Transformer Architectures"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Latent Space Diffusion",{"className":"page__taxonomy-item","children":["#","Latent Space Diffusion"]}]]}]]}]]}],["$","article","2025-10-17-DialectGen_Benchmarking_and_Improving_Dialect_Robustness_in_Multimodal_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-DialectGen_Benchmarking_and_Improving_Dialect_Robustness_in_Multimodal_Generation/","children":"[논문리뷰] DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Generation",{"className":"page__taxonomy-item","children":["#","Multimodal Generation"]}],["$","span","Dialect Robustness",{"className":"page__taxonomy-item","children":["#","Dialect Robustness"]}],["$","span","Text-to-Image",{"className":"page__taxonomy-item","children":["#","Text-to-Image"]}],["$","span","Text-to-Video",{"className":"page__taxonomy-item","children":["#","Text-to-Video"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Text Encoder Tuning",{"className":"page__taxonomy-item","children":["#","Text Encoder Tuning"]}],["$","span","Low-Resource Dialects",{"className":"page__taxonomy-item","children":["#","Low-Resource Dialects"]}]]}]]}]]}],["$","article","2025-10-17-COIG-Writer_A_High-Quality_Dataset_for_Chinese_Creative_Writing_with_Thought_Processes",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-COIG-Writer_A_High-Quality_Dataset_for_Chinese_Creative_Writing_with_Thought_Processes/","children":"[논문리뷰] COIG-Writer: A High-Quality Dataset for Chinese Creative Writing with Thought Processes"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'COIG-Writer: A High-Quality Dataset for Chinese Creative Writing with Thought Processes' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Chinese Creative Writing",{"className":"page__taxonomy-item","children":["#","Chinese Creative Writing"]}],["$","span","Process Supervision",{"className":"page__taxonomy-item","children":["#","Process Supervision"]}],["$","span","LLM Training",{"className":"page__taxonomy-item","children":["#","LLM Training"]}],["$","span","Dataset Creation",{"className":"page__taxonomy-item","children":["#","Dataset Creation"]}],["$","span","Cross-Lingual Transfer",{"className":"page__taxonomy-item","children":["#","Cross-Lingual Transfer"]}],["$","span","Narrative Logic",{"className":"page__taxonomy-item","children":["#","Narrative Logic"]}],["$","span","Linguistic Expression",{"className":"page__taxonomy-item","children":["#","Linguistic Expression"]}],["$","span","Type-Token Ratio",{"className":"page__taxonomy-item","children":["#","Type-Token Ratio"]}]]}]]}]]}],["$","article","2025-10-17-BitNet_Distillation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-BitNet_Distillation/","children":"[논문리뷰] BitNet Distillation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'BitNet Distillation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Low-bit Quantization",{"className":"page__taxonomy-item","children":["#","Low-bit Quantization"]}],["$","span","LLM Compression",{"className":"page__taxonomy-item","children":["#","LLM Compression"]}],["$","span","Knowledge Distillation",{"className":"page__taxonomy-item","children":["#","Knowledge Distillation"]}],["$","span","Ternary Weights",{"className":"page__taxonomy-item","children":["#","Ternary Weights"]}],["$","span","Inference Optimization",{"className":"page__taxonomy-item","children":["#","Inference Optimization"]}],["$","span","Memory Efficiency",{"className":"page__taxonomy-item","children":["#","Memory Efficiency"]}],["$","span","SubLN",{"className":"page__taxonomy-item","children":["#","SubLN"]}],["$","span","Continual Pre-training",{"className":"page__taxonomy-item","children":["#","Continual Pre-training"]}]]}]]}]]}],["$","article","2025-10-17-Beyond_One_World_Benchmarking_Super_Heros_in_Role-Playing_Across_Multiversal_Contexts",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-Beyond_One_World_Benchmarking_Super_Heros_in_Role-Playing_Across_Multiversal_Contexts/","children":"[논문리뷰] Beyond One World: Benchmarking Super Heros in Role-Playing Across Multiversal Contexts"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Beyond One World: Benchmarking Super Heros in Role-Playing Across Multiversal Contexts' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Role-playing LLMs",{"className":"page__taxonomy-item","children":["#","Role-playing LLMs"]}],["$","span","Multiversal Consistency",{"className":"page__taxonomy-item","children":["#","Multiversal Consistency"]}],["$","span","Character Benchmarking",{"className":"page__taxonomy-item","children":["#","Character Benchmarking"]}],["$","span","Moral Dilemmas",{"className":"page__taxonomy-item","children":["#","Moral Dilemmas"]}],["$","span","Canon Events",{"className":"page__taxonomy-item","children":["#","Canon Events"]}],["$","span","Reasoning-Acting Alignment",{"className":"page__taxonomy-item","children":["#","Reasoning-Acting Alignment"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Superheroes",{"className":"page__taxonomy-item","children":["#","Superheroes"]}]]}]]}]]}],["$","article","2025-10-17-Beyond_Correctness_Evaluating_Subjective_Writing_Preferences_Across_Cultures",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-Beyond_Correctness_Evaluating_Subjective_Writing_Preferences_Across_Cultures/","children":"[논문리뷰] Beyond Correctness: Evaluating Subjective Writing Preferences Across Cultures"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Beyond Correctness: Evaluating Subjective Writing Preferences Across Cultures' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Subjective Preference Learning",{"className":"page__taxonomy-item","children":["#","Subjective Preference Learning"]}],["$","span","Writing Evaluation",{"className":"page__taxonomy-item","children":["#","Writing Evaluation"]}],["$","span","Reward Models",{"className":"page__taxonomy-item","children":["#","Reward Models"]}],["$","span","RLHF",{"className":"page__taxonomy-item","children":["#","RLHF"]}],["$","span","Cross-Cultural AI",{"className":"page__taxonomy-item","children":["#","Cross-Cultural AI"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Language Model Judges",{"className":"page__taxonomy-item","children":["#","Language Model Judges"]}],["$","span","Genre Instability",{"className":"page__taxonomy-item","children":["#","Genre Instability"]}]]}]]}]]}],["$","article","2025-10-17-Attention_Is_All_You_Need_for_KV_Cache_in_Diffusion_LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-Attention_Is_All_You_Need_for_KV_Cache_in_Diffusion_LLMs/","children":"[논문리뷰] Attention Is All You Need for KV Cache in Diffusion LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Attention Is All You Need for KV Cache in Diffusion LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion LLMs",{"className":"page__taxonomy-item","children":["#","Diffusion LLMs"]}],["$","span","KV Cache",{"className":"page__taxonomy-item","children":["#","KV Cache"]}],["$","span","Adaptive Caching",{"className":"page__taxonomy-item","children":["#","Adaptive Caching"]}],["$","span","Inference Optimization",{"className":"page__taxonomy-item","children":["#","Inference Optimization"]}],["$","span","Attention Mechanism",{"className":"page__taxonomy-item","children":["#","Attention Mechanism"]}],["$","span","Latency Reduction",{"className":"page__taxonomy-item","children":["#","Latency Reduction"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}]]}]]}]]}],["$","article","2025-10-17-AI_for_Service_Proactive_Assistance_with_AI_Glasses",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-AI_for_Service_Proactive_Assistance_with_AI_Glasses/","children":"[논문리뷰] AI for Service: Proactive Assistance with AI Glasses"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'AI for Service: Proactive Assistance with AI Glasses' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI for Service",{"className":"page__taxonomy-item","children":["#","AI for Service"]}],["$","span","Proactive AI",{"className":"page__taxonomy-item","children":["#","Proactive AI"]}],["$","span","AI Glasses",{"className":"page__taxonomy-item","children":["#","AI Glasses"]}],["$","span","Multi-agent System",{"className":"page__taxonomy-item","children":["#","Multi-agent System"]}],["$","span","Human-AI Interaction",{"className":"page__taxonomy-item","children":["#","Human-AI Interaction"]}],["$","span","Context-aware AI",{"className":"page__taxonomy-item","children":["#","Context-aware AI"]}],["$","span","Wearable AI",{"className":"page__taxonomy-item","children":["#","Wearable AI"]}]]}]]}]]}],["$","article","2025-10-17-Agentic_Entropy-Balanced_Policy_Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-17-Agentic_Entropy-Balanced_Policy_Optimization/","children":"[논문리뷰] Agentic Entropy-Balanced Policy Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Agentic Entropy-Balanced Policy Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-17 13:09:57+0900","children":"2025년 10월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Agentic Reinforcement Learning"]}],["$","span","Web Agents",{"className":"page__taxonomy-item","children":["#","Web Agents"]}],["$","span","Tool Learning",{"className":"page__taxonomy-item","children":["#","Tool Learning"]}],["$","span","Entropy Balancing",{"className":"page__taxonomy-item","children":["#","Entropy Balancing"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Rollout Strategy",{"className":"page__taxonomy-item","children":["#","Rollout Strategy"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}]]}]]}]]}],["$","article","2025-10-16-X-VLA_Soft-Prompted_Transformer_as_Scalable_Cross-Embodiment_Vision-Language-Action_Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-X-VLA_Soft-Prompted_Transformer_as_Scalable_Cross-Embodiment_Vision-Language-Action_Model/","children":"[논문리뷰] X-VLA: Soft-Prompted Transformer as Scalable Cross-Embodiment Vision-Language-Action Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xirui Kang이 [arXiv]에 게시한 'X-VLA: Soft-Prompted Transformer as Scalable Cross-Embodiment Vision-Language-Action Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action (VLA) Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action (VLA) Models"]}],["$","span","Soft Prompts",{"className":"page__taxonomy-item","children":["#","Soft Prompts"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Cross-Embodiment",{"className":"page__taxonomy-item","children":["#","Cross-Embodiment"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Pretraining",{"className":"page__taxonomy-item","children":["#","Pretraining"]}],["$","span","Domain Adaptation",{"className":"page__taxonomy-item","children":["#","Domain Adaptation"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}]]}]]}]]}],["$","article","2025-10-16-Universal_Image_Restoration_Pre-training_via_Masked_Degradation_Classification",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-Universal_Image_Restoration_Pre-training_via_Masked_Degradation_Classification/","children":"[논문리뷰] Universal Image Restoration Pre-training via Masked Degradation Classification"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Universal Image Restoration Pre-training via Masked Degradation Classification' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Universal Image Restoration",{"className":"page__taxonomy-item","children":["#","Universal Image Restoration"]}],["$","span","Pre-training",{"className":"page__taxonomy-item","children":["#","Pre-training"]}],["$","span","Masked Image Modeling",{"className":"page__taxonomy-item","children":["#","Masked Image Modeling"]}],["$","span","Degradation Classification",{"className":"page__taxonomy-item","children":["#","Degradation Classification"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}],["$","span","Computer Vision",{"className":"page__taxonomy-item","children":["#","Computer Vision"]}],["$","span","Self-supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-supervised Learning"]}],["$","span","Low-level Vision",{"className":"page__taxonomy-item","children":["#","Low-level Vision"]}]]}]]}]]}],["$","article","2025-10-16-UniMoE-Audio_Unified_Speech_and_Music_Generation_with_Dynamic-Capacity_MoE",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-UniMoE-Audio_Unified_Speech_and_Music_Generation_with_Dynamic-Capacity_MoE/","children":"[논문리뷰] UniMoE-Audio: Unified Speech and Music Generation with Dynamic-Capacity MoE"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'UniMoE-Audio: Unified Speech and Music Generation with Dynamic-Capacity MoE' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Mixture of Experts",{"className":"page__taxonomy-item","children":["#","Mixture of Experts"]}],["$","span","Speech Generation",{"className":"page__taxonomy-item","children":["#","Speech Generation"]}],["$","span","Music Generation",{"className":"page__taxonomy-item","children":["#","Music Generation"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Dynamic Routing",{"className":"page__taxonomy-item","children":["#","Dynamic Routing"]}],["$","span","Training Curriculum",{"className":"page__taxonomy-item","children":["#","Training Curriculum"]}],["$","span","Data Imbalance",{"className":"page__taxonomy-item","children":["#","Data Imbalance"]}],["$","span","Audio Synthesis",{"className":"page__taxonomy-item","children":["#","Audio Synthesis"]}]]}]]}]]}],["$","article","2025-10-16-UniME-V2_MLLM-as-a-Judge_for_Universal_Multimodal_Embedding_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-UniME-V2_MLLM-as-a-Judge_for_Universal_Multimodal_Embedding_Learning/","children":"[논문리뷰] UniME-V2: MLLM-as-a-Judge for Universal Multimodal Embedding Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ziyong Feng이 [arXiv]에 게시한 'UniME-V2: MLLM-as-a-Judge for Universal Multimodal Embedding Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Embeddings",{"className":"page__taxonomy-item","children":["#","Multimodal Embeddings"]}],["$","span","MLLM-as-a-Judge",{"className":"page__taxonomy-item","children":["#","MLLM-as-a-Judge"]}],["$","span","Hard Negative Mining",{"className":"page__taxonomy-item","children":["#","Hard Negative Mining"]}],["$","span","Semantic Alignment",{"className":"page__taxonomy-item","children":["#","Semantic Alignment"]}],["$","span","Representation Learning",{"className":"page__taxonomy-item","children":["#","Representation Learning"]}],["$","span","Reranking",{"className":"page__taxonomy-item","children":["#","Reranking"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}]]}]]}]]}],["$","article","2025-10-16-Uni-MMMU_A_Massive_Multi-discipline_Multimodal_Unified_Benchmark",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-Uni-MMMU_A_Massive_Multi-discipline_Multimodal_Unified_Benchmark/","children":"[논문리뷰] Uni-MMMU: A Massive Multi-discipline Multimodal Unified Benchmark"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Uni-MMMU: A Massive Multi-discipline Multimodal Unified Benchmark' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Unified Models",{"className":"page__taxonomy-item","children":["#","Unified Models"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Generation",{"className":"page__taxonomy-item","children":["#","Generation"]}],["$","span","Understanding",{"className":"page__taxonomy-item","children":["#","Understanding"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Evaluation",{"className":"page__taxonomy-item","children":["#","Evaluation"]}],["$","span","Cross-modal Synergy",{"className":"page__taxonomy-item","children":["#","Cross-modal Synergy"]}]]}]]}]]}],["$","article","2025-10-16-Trace_Anything_Representing_Any_Video_in_4D_via_Trajectory_Fields",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-Trace_Anything_Representing_Any_Video_in_4D_via_Trajectory_Fields/","children":"[논문리뷰] Trace Anything: Representing Any Video in 4D via Trajectory Fields"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Trace Anything: Representing Any Video in 4D via Trajectory Fields' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","4D Video Representation",{"className":"page__taxonomy-item","children":["#","4D Video Representation"]}],["$","span","Trajectory Fields",{"className":"page__taxonomy-item","children":["#","Trajectory Fields"]}],["$","span","Neural Networks",{"className":"page__taxonomy-item","children":["#","Neural Networks"]}],["$","span","Spatio-temporal Modeling",{"className":"page__taxonomy-item","children":["#","Spatio-temporal Modeling"]}],["$","span","3D Point Tracking",{"className":"page__taxonomy-item","children":["#","3D Point Tracking"]}],["$","span","Motion Forecasting",{"className":"page__taxonomy-item","children":["#","Motion Forecasting"]}],["$","span","Computer Vision",{"className":"page__taxonomy-item","children":["#","Computer Vision"]}],["$","span","B-splines",{"className":"page__taxonomy-item","children":["#","B-splines"]}]]}]]}]]}],["$","article","2025-10-16-The_Role_of_Computing_Resources_in_Publishing_Foundation_Model_Research",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-The_Role_of_Computing_Resources_in_Publishing_Foundation_Model_Research/","children":"[논문리뷰] The Role of Computing Resources in Publishing Foundation Model Research"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhenwen Liang이 [arXiv]에 게시한 'The Role of Computing Resources in Publishing Foundation Model Research' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Computing Resources",{"className":"page__taxonomy-item","children":["#","Computing Resources"]}],["$","span","GPU Disparity",{"className":"page__taxonomy-item","children":["#","GPU Disparity"]}],["$","span","AI Research",{"className":"page__taxonomy-item","children":["#","AI Research"]}],["$","span","Publication Bias",{"className":"page__taxonomy-item","children":["#","Publication Bias"]}],["$","span","Resource Allocation",{"className":"page__taxonomy-item","children":["#","Resource Allocation"]}],["$","span","Research Transparency",{"className":"page__taxonomy-item","children":["#","Research Transparency"]}]]}]]}]]}],["$","article","2025-10-16-The_Art_of_Scaling_Reinforcement_Learning_Compute_for_LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-The_Art_of_Scaling_Reinforcement_Learning_Compute_for_LLMs/","children":"[논문리뷰] The Art of Scaling Reinforcement Learning Compute for LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'The Art of Scaling Reinforcement Learning Compute for LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Scaling Laws",{"className":"page__taxonomy-item","children":["#","Scaling Laws"]}],["$","span","Compute Efficiency",{"className":"page__taxonomy-item","children":["#","Compute Efficiency"]}],["$","span","Predictability",{"className":"page__taxonomy-item","children":["#","Predictability"]}],["$","span","Sigmoidal Curves",{"className":"page__taxonomy-item","children":["#","Sigmoidal Curves"]}],["$","span","ScaleRL",{"className":"page__taxonomy-item","children":["#","ScaleRL"]}],["$","span","Off-Policy RL",{"className":"page__taxonomy-item","children":["#","Off-Policy RL"]}]]}]]}]]}],["$","article","2025-10-16-Stronger_Together_On-Policy_Reinforcement_Learning_for_Collaborative_LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-Stronger_Together_On-Policy_Reinforcement_Learning_for_Collaborative_LLMs/","children":"[논문리뷰] Stronger Together: On-Policy Reinforcement Learning for Collaborative LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hao Zhang이 [arXiv]에 게시한 'Stronger Together: On-Policy Reinforcement Learning for Collaborative LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Multi-Agent Systems (MAS)",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems (MAS)"]}],["$","span","On-Policy RL",{"className":"page__taxonomy-item","children":["#","On-Policy RL"]}],["$","span","Collaborative AI",{"className":"page__taxonomy-item","children":["#","Collaborative AI"]}],["$","span","Agentic LLMs",{"className":"page__taxonomy-item","children":["#","Agentic LLMs"]}],["$","span","Group-based Optimization",{"className":"page__taxonomy-item","children":["#","Group-based Optimization"]}]]}]]}]]}],["$","article","2025-10-16-Revisiting_Model_Interpolation_for_Efficient_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-Revisiting_Model_Interpolation_for_Efficient_Reasoning/","children":"[논문리뷰] Revisiting Model Interpolation for Efficient Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Revisiting Model Interpolation for Efficient Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Model Interpolation",{"className":"page__taxonomy-item","children":["#","Model Interpolation"]}],["$","span","Efficient Reasoning",{"className":"page__taxonomy-item","children":["#","Efficient Reasoning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Model Merging",{"className":"page__taxonomy-item","children":["#","Model Merging"]}],["$","span","Performance Dynamics",{"className":"page__taxonomy-item","children":["#","Performance Dynamics"]}],["$","span","Ablation Study",{"className":"page__taxonomy-item","children":["#","Ablation Study"]}]]}]]}]]}],["$","article","2025-10-16-Reasoning_in_Space_via_Grounding_in_the_World",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-Reasoning_in_Space_via_Grounding_in_the_World/","children":"[논문리뷰] Reasoning in Space via Grounding in the World"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Li Zhang이 [arXiv]에 게시한 'Reasoning in Space via Grounding in the World' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Visual Grounding",{"className":"page__taxonomy-item","children":["#","3D Visual Grounding"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Chain-of-Thought (CoT)",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought (CoT)"]}],["$","span","Hybrid Representation",{"className":"page__taxonomy-item","children":["#","Hybrid Representation"]}],["$","span","Multi-modal LLMs",{"className":"page__taxonomy-item","children":["#","Multi-modal LLMs"]}],["$","span","Point Clouds",{"className":"page__taxonomy-item","children":["#","Point Clouds"]}]]}]]}]]}],["$","article","2025-10-16-Point_Prompting_Counterfactual_Tracking_with_Video_Diffusion_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-Point_Prompting_Counterfactual_Tracking_with_Video_Diffusion_Models/","children":"[논문리뷰] Point Prompting: Counterfactual Tracking with Video Diffusion Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Andrew Owens이 [arXiv]에 게시한 'Point Prompting: Counterfactual Tracking with Video Diffusion Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Diffusion Models",{"className":"page__taxonomy-item","children":["#","Video Diffusion Models"]}],["$","span","Point Tracking",{"className":"page__taxonomy-item","children":["#","Point Tracking"]}],["$","span","Zero-Shot Learning",{"className":"page__taxonomy-item","children":["#","Zero-Shot Learning"]}],["$","span","Counterfactual Modeling",{"className":"page__taxonomy-item","children":["#","Counterfactual Modeling"]}],["$","span","Visual Prompting",{"className":"page__taxonomy-item","children":["#","Visual Prompting"]}],["$","span","SDEdit",{"className":"page__taxonomy-item","children":["#","SDEdit"]}],["$","span","Negative Prompting",{"className":"page__taxonomy-item","children":["#","Negative Prompting"]}],["$","span","Object Permanence",{"className":"page__taxonomy-item","children":["#","Object Permanence"]}]]}]]}]]}],["$","article","2025-10-16-PhysMaster_Mastering_Physical_Representation_for_Video_Generation_via_Reinforcement_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-PhysMaster_Mastering_Physical_Representation_for_Video_Generation_via_Reinforcement_Learning/","children":"[논문리뷰] PhysMaster: Mastering Physical Representation for Video Generation via Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hengshuang Zhao이 [arXiv]에 게시한 'PhysMaster: Mastering Physical Representation for Video Generation via Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Physical Plausibility",{"className":"page__taxonomy-item","children":["#","Physical Plausibility"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Direct Preference Optimization",{"className":"page__taxonomy-item","children":["#","Direct Preference Optimization"]}],["$","span","Physical Representation",{"className":"page__taxonomy-item","children":["#","Physical Representation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","World Models",{"className":"page__taxonomy-item","children":["#","World Models"]}],["$","span","Image-to-Video",{"className":"page__taxonomy-item","children":["#","Image-to-Video"]}]]}]]}]]}],["$","article","2025-10-16-ParallelBench_Understanding_the_Trade-offs_of_Parallel_Decoding_in_Diffusion_LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-ParallelBench_Understanding_the_Trade-offs_of_Parallel_Decoding_in_Diffusion_LLMs/","children":"[논문리뷰] ParallelBench: Understanding the Trade-offs of Parallel Decoding in Diffusion LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'ParallelBench: Understanding the Trade-offs of Parallel Decoding in Diffusion LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion LLMs",{"className":"page__taxonomy-item","children":["#","Diffusion LLMs"]}],["$","span","Parallel Decoding",{"className":"page__taxonomy-item","children":["#","Parallel Decoding"]}],["$","span","Speed-Quality Trade-off",{"className":"page__taxonomy-item","children":["#","Speed-Quality Trade-off"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Token Dependencies",{"className":"page__taxonomy-item","children":["#","Token Dependencies"]}],["$","span","Unmasking Strategies",{"className":"page__taxonomy-item","children":["#","Unmasking Strategies"]}],["$","span","Information Theory",{"className":"page__taxonomy-item","children":["#","Information Theory"]}]]}]]}]]}],["$","article","2025-10-16-NOSA_Native_and_Offloadable_Sparse_Attention",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-NOSA_Native_and_Offloadable_Sparse_Attention/","children":"[논문리뷰] NOSA: Native and Offloadable Sparse Attention"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhiyuan Liu이 [arXiv]에 게시한 'NOSA: Native and Offloadable Sparse Attention' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Sparse Attention",{"className":"page__taxonomy-item","children":["#","Sparse Attention"]}],["$","span","KV Cache Offloading",{"className":"page__taxonomy-item","children":["#","KV Cache Offloading"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Decoding Throughput",{"className":"page__taxonomy-item","children":["#","Decoding Throughput"]}],["$","span","Locality Constraint",{"className":"page__taxonomy-item","children":["#","Locality Constraint"]}],["$","span","Memory Optimization",{"className":"page__taxonomy-item","children":["#","Memory Optimization"]}],["$","span","Trainable Sparse Attention",{"className":"page__taxonomy-item","children":["#","Trainable Sparse Attention"]}]]}]]}]]}],["$","article","2025-10-16-MTSQL-R1_Towards_Long-Horizon_Multi-Turn_Text-to-SQL_via_Agentic_Training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-MTSQL-R1_Towards_Long-Horizon_Multi-Turn_Text-to-SQL_via_Agentic_Training/","children":"[논문리뷰] MTSQL-R1: Towards Long-Horizon Multi-Turn Text-to-SQL via Agentic Training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'MTSQL-R1: Towards Long-Horizon Multi-Turn Text-to-SQL via Agentic Training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-turn Text-to-SQL",{"className":"page__taxonomy-item","children":["#","Multi-turn Text-to-SQL"]}],["$","span","Agentic Training",{"className":"page__taxonomy-item","children":["#","Agentic Training"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Dialogue Systems",{"className":"page__taxonomy-item","children":["#","Dialogue Systems"]}],["$","span","Semantic Parsing",{"className":"page__taxonomy-item","children":["#","Semantic Parsing"]}],["$","span","Database Interaction",{"className":"page__taxonomy-item","children":["#","Database Interaction"]}],["$","span","Self-correction",{"className":"page__taxonomy-item","children":["#","Self-correction"]}]]}]]}]]}],["$","article","2025-10-16-MATH-Beyond_A_Benchmark_for_RL_to_Expand_Beyond_the_Base_Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-MATH-Beyond_A_Benchmark_for_RL_to_Expand_Beyond_the_Base_Model/","children":"[논문리뷰] MATH-Beyond: A Benchmark for RL to Expand Beyond the Base Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wieland Brendel이 [arXiv]에 게시한 'MATH-Beyond: A Benchmark for RL to Expand Beyond the Base Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Exploration",{"className":"page__taxonomy-item","children":["#","Exploration"]}],["$","span","Boundary Expansion",{"className":"page__taxonomy-item","children":["#","Boundary Expansion"]}],["$","span","MATH-Beyond",{"className":"page__taxonomy-item","children":["#","MATH-Beyond"]}]]}]]}]]}],["$","article","2025-10-16-LIBERO-Plus_In-depth_Robustness_Analysis_of_Vision-Language-Action_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-LIBERO-Plus_In-depth_Robustness_Analysis_of_Vision-Language-Action_Models/","children":"[논문리뷰] LIBERO-Plus: In-depth Robustness Analysis of Vision-Language-Action Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'LIBERO-Plus: In-depth Robustness Analysis of Vision-Language-Action Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action Models"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Robustness Analysis",{"className":"page__taxonomy-item","children":["#","Robustness Analysis"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Perturbations",{"className":"page__taxonomy-item","children":["#","Perturbations"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","LIBERO-Plus",{"className":"page__taxonomy-item","children":["#","LIBERO-Plus"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}]]}]]}]]}],["$","article","2025-10-16-InternVLA-M1_A_Spatially_Guided_Vision-Language-Action_Framework_for_Generalist_Robot_Policy",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-InternVLA-M1_A_Spatially_Guided_Vision-Language-Action_Framework_for_Generalist_Robot_Policy/","children":"[논문리뷰] InternVLA-M1: A Spatially Guided Vision-Language-Action Framework for Generalist Robot Policy"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yilun Chen이 [arXiv]에 게시한 'InternVLA-M1: A Spatially Guided Vision-Language-Action Framework for Generalist Robot Policy' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Vision-Language-Action (VLA)",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action (VLA)"]}],["$","span","Spatial Grounding",{"className":"page__taxonomy-item","children":["#","Spatial Grounding"]}],["$","span","Generalist Policy",{"className":"page__taxonomy-item","children":["#","Generalist Policy"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}],["$","span","Simulation-to-Real",{"className":"page__taxonomy-item","children":["#","Simulation-to-Real"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}]]}]]}]]}],["$","article","2025-10-16-InteractiveOmni_A_Unified_Omni-modal_Model_for_Audio-Visual_Multi-turn_Dialogue",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-InteractiveOmni_A_Unified_Omni-modal_Model_for_Audio-Visual_Multi-turn_Dialogue/","children":"[논문리뷰] InteractiveOmni: A Unified Omni-modal Model for Audio-Visual Multi-turn Dialogue"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Dongchuan Ran이 [arXiv]에 게시한 'InteractiveOmni: A Unified Omni-modal Model for Audio-Visual Multi-turn Dialogue' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Omni-modal LLM",{"className":"page__taxonomy-item","children":["#","Omni-modal LLM"]}],["$","span","Audio-Visual Dialogue",{"className":"page__taxonomy-item","children":["#","Audio-Visual Dialogue"]}],["$","span","Multi-turn Interaction",{"className":"page__taxonomy-item","children":["#","Multi-turn Interaction"]}],["$","span","Speech Generation",{"className":"page__taxonomy-item","children":["#","Speech Generation"]}],["$","span","Long-term Memory",{"className":"page__taxonomy-item","children":["#","Long-term Memory"]}],["$","span","Multimodal Understanding",{"className":"page__taxonomy-item","children":["#","Multimodal Understanding"]}],["$","span","End-to-end Training",{"className":"page__taxonomy-item","children":["#","End-to-end Training"]}]]}]]}]]}],["$","article","2025-10-16-HyperAgent_Leveraging_Hypergraphs_for_Topology_Optimization_in_Multi-Agent_Communication",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-HyperAgent_Leveraging_Hypergraphs_for_Topology_Optimization_in_Multi-Agent_Communication/","children":"[논문리뷰] HyperAgent: Leveraging Hypergraphs for Topology Optimization in Multi-Agent Communication"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Haochen You이 [arXiv]에 게시한 'HyperAgent: Leveraging Hypergraphs for Topology Optimization in Multi-Agent Communication' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Model",{"className":"page__taxonomy-item","children":["#","Large Language Model"]}],["$","span","Multi-agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-agent Systems"]}],["$","span","Multi-agent Communication",{"className":"page__taxonomy-item","children":["#","Multi-agent Communication"]}],["$","span","Graph Neural Networks",{"className":"page__taxonomy-item","children":["#","Graph Neural Networks"]}],["$","span","Hypergraph",{"className":"page__taxonomy-item","children":["#","Hypergraph"]}],["$","span","Topology Optimization",{"className":"page__taxonomy-item","children":["#","Topology Optimization"]}],["$","span","Variational Autoencoder",{"className":"page__taxonomy-item","children":["#","Variational Autoencoder"]}],["$","span","Sparsity Regularization",{"className":"page__taxonomy-item","children":["#","Sparsity Regularization"]}]]}]]}]]}],["$","article","2025-10-16-Hierarchical_Frequency_Tagging_Probe_HFTP_A_Unified_Approach_to_Investigate_Syntactic_Structure_Representations_in_Large_Language_Models_and_the_Human_Brain",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-Hierarchical_Frequency_Tagging_Probe_HFTP_A_Unified_Approach_to_Investigate_Syntactic_Structure_Representations_in_Large_Language_Models_and_the_Human_Brain/","children":"[논문리뷰] Hierarchical Frequency Tagging Probe (HFTP): A Unified Approach to Investigate Syntactic Structure Representations in Large Language Models and the Human Brain"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Lingxi Lu이 [arXiv]에 게시한 'Hierarchical Frequency Tagging Probe (HFTP): A Unified Approach to Investigate Syntactic Structure Representations in Large Language Models and the Human Brain' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Syntactic Structure",{"className":"page__taxonomy-item","children":["#","Syntactic Structure"]}],["$","span","Human Brain",{"className":"page__taxonomy-item","children":["#","Human Brain"]}],["$","span","Frequency Tagging",{"className":"page__taxonomy-item","children":["#","Frequency Tagging"]}],["$","span","Neuroscience",{"className":"page__taxonomy-item","children":["#","Neuroscience"]}],["$","span","Model Interpretability",{"className":"page__taxonomy-item","children":["#","Model Interpretability"]}],["$","span","Representational Similarity Analysis",{"className":"page__taxonomy-item","children":["#","Representational Similarity Analysis"]}],["$","span","Intracranial EEG",{"className":"page__taxonomy-item","children":["#","Intracranial EEG"]}]]}]]}]]}],["$","article","2025-10-16-Hard2Verify_A_Step-Level_Verification_Benchmark_for_Open-Ended_Frontier_Math",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-Hard2Verify_A_Step-Level_Verification_Benchmark_for_Open-Ended_Frontier_Math/","children":"[논문리뷰] Hard2Verify: A Step-Level Verification Benchmark for Open-Ended Frontier Math"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Hard2Verify: A Step-Level Verification Benchmark for Open-Ended Frontier Math' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Verification",{"className":"page__taxonomy-item","children":["#","LLM Verification"]}],["$","span","Math Reasoning",{"className":"page__taxonomy-item","children":["#","Math Reasoning"]}],["$","span","Step-Level Verification",{"className":"page__taxonomy-item","children":["#","Step-Level Verification"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Open-Ended Problems",{"className":"page__taxonomy-item","children":["#","Open-Ended Problems"]}],["$","span","Process Reward Models",{"className":"page__taxonomy-item","children":["#","Process Reward Models"]}],["$","span","Generative Critics",{"className":"page__taxonomy-item","children":["#","Generative Critics"]}]]}]]}]]}],["$","article","2025-10-16-GraphTracer_Graph-Guided_Failure_Tracing_in_LLM_Agents_for_Robust_Multi-Turn_Deep_Search",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-GraphTracer_Graph-Guided_Failure_Tracing_in_LLM_Agents_for_Robust_Multi-Turn_Deep_Search/","children":"[논문리뷰] GraphTracer: Graph-Guided Failure Tracing in LLM Agents for Robust Multi-Turn Deep Search"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zijian Zhang이 [arXiv]에 게시한 'GraphTracer: Graph-Guided Failure Tracing in LLM Agents for Robust Multi-Turn Deep Search' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Failure Tracing",{"className":"page__taxonomy-item","children":["#","Failure Tracing"]}],["$","span","Root Cause Analysis",{"className":"page__taxonomy-item","children":["#","Root Cause Analysis"]}],["$","span","Information Dependency Graph",{"className":"page__taxonomy-item","children":["#","Information Dependency Graph"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Deep Search",{"className":"page__taxonomy-item","children":["#","Deep Search"]}]]}]]}]]}],["$","article","2025-10-16-Generative_Universal_Verifier_as_Multimodal_Meta-Reasoner",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-Generative_Universal_Verifier_as_Multimodal_Meta-Reasoner/","children":"[논문리뷰] Generative Universal Verifier as Multimodal Meta-Reasoner"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Generative Universal Verifier as Multimodal Meta-Reasoner' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Visual Verification",{"className":"page__taxonomy-item","children":["#","Visual Verification"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Self-Refinement",{"className":"page__taxonomy-item","children":["#","Self-Refinement"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Test-Time Scaling",{"className":"page__taxonomy-item","children":["#","Test-Time Scaling"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}]]}]]}]]}],["$","article","2025-10-16-FlashWorld_High-quality_3D_Scene_Generation_within_Seconds",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-FlashWorld_High-quality_3D_Scene_Generation_within_Seconds/","children":"[논문리뷰] FlashWorld: High-quality 3D Scene Generation within Seconds"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chunchao Guo이 [arXiv]에 게시한 'FlashWorld: High-quality 3D Scene Generation within Seconds' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Scene Generation",{"className":"page__taxonomy-item","children":["#","3D Scene Generation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Multi-View Synthesis",{"className":"page__taxonomy-item","children":["#","Multi-View Synthesis"]}],["$","span","3D Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","3D Gaussian Splatting"]}],["$","span","Knowledge Distillation",{"className":"page__taxonomy-item","children":["#","Knowledge Distillation"]}],["$","span","Real-time Generation",{"className":"page__taxonomy-item","children":["#","Real-time Generation"]}],["$","span","High-Quality Rendering",{"className":"page__taxonomy-item","children":["#","High-Quality Rendering"]}],["$","span","Cross-modal Training",{"className":"page__taxonomy-item","children":["#","Cross-modal Training"]}]]}]]}]]}],["$","article","2025-10-16-FG-CLIP_2_A_Bilingual_Fine-grained_Vision-Language_Alignment_Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-FG-CLIP_2_A_Bilingual_Fine-grained_Vision-Language_Alignment_Model/","children":"[논문리뷰] FG-CLIP 2: A Bilingual Fine-grained Vision-Language Alignment Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Dawei Liang이 [arXiv]에 게시한 'FG-CLIP 2: A Bilingual Fine-grained Vision-Language Alignment Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Alignment",{"className":"page__taxonomy-item","children":["#","Vision-Language Alignment"]}],["$","span","Fine-grained Understanding",{"className":"page__taxonomy-item","children":["#","Fine-grained Understanding"]}],["$","span","Bilingual Model",{"className":"page__taxonomy-item","children":["#","Bilingual Model"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Multimodal Retrieval",{"className":"page__taxonomy-item","children":["#","Multimodal Retrieval"]}],["$","span","Open-Vocabulary Detection",{"className":"page__taxonomy-item","children":["#","Open-Vocabulary Detection"]}],["$","span","Region-Text Matching",{"className":"page__taxonomy-item","children":["#","Region-Text Matching"]}]]}]]}]]}],["$","article","2025-10-16-EAGER_Entropy-Aware_GEneRation_for_Adaptive_Inference-Time_Scaling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-EAGER_Entropy-Aware_GEneRation_for_Adaptive_Inference-Time_Scaling/","children":"[논문리뷰] EAGER: Entropy-Aware GEneRation for Adaptive Inference-Time Scaling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ahmet Üstün이 [arXiv]에 게시한 'EAGER: Entropy-Aware GEneRation for Adaptive Inference-Time Scaling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Inference-Time Scaling",{"className":"page__taxonomy-item","children":["#","Inference-Time Scaling"]}],["$","span","Entropy-Aware Generation",{"className":"page__taxonomy-item","children":["#","Entropy-Aware Generation"]}],["$","span","Adaptive Budget Allocation",{"className":"page__taxonomy-item","children":["#","Adaptive Budget Allocation"]}],["$","span","Reasoning Benchmarks",{"className":"page__taxonomy-item","children":["#","Reasoning Benchmarks"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}]]}]]}]]}],["$","article","2025-10-16-Direct_Multi-Token_Decoding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-Direct_Multi-Token_Decoding/","children":"[논문리뷰] Direct Multi-Token Decoding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xifeng Yan이 [arXiv]에 게시한 'Direct Multi-Token Decoding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Inference",{"className":"page__taxonomy-item","children":["#","LLM Inference"]}],["$","span","Multi-token Decoding",{"className":"page__taxonomy-item","children":["#","Multi-token Decoding"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Layer Specialization",{"className":"page__taxonomy-item","children":["#","Layer Specialization"]}],["$","span","Cyclical Refilling",{"className":"page__taxonomy-item","children":["#","Cyclical Refilling"]}],["$","span","Inference Speedup",{"className":"page__taxonomy-item","children":["#","Inference Speedup"]}],["$","span","Model Scaling",{"className":"page__taxonomy-item","children":["#","Model Scaling"]}]]}]]}]]}],["$","article","2025-10-16-Deflanderization_for_Game_Dialogue_Balancing_Character_Authenticity_with_Task_Execution_in_LLM-based_NPCs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-Deflanderization_for_Game_Dialogue_Balancing_Character_Authenticity_with_Task_Execution_in_LLM-based_NPCs/","children":"[논문리뷰] Deflanderization for Game Dialogue: Balancing Character Authenticity with Task Execution in LLM-based NPCs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Deflanderization for Game Dialogue: Balancing Character Authenticity with Task Execution in LLM-based NPCs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","NPC",{"className":"page__taxonomy-item","children":["#","NPC"]}],["$","span","Game Dialogue",{"className":"page__taxonomy-item","children":["#","Game Dialogue"]}],["$","span","Persona-Grounded Dialogue",{"className":"page__taxonomy-item","children":["#","Persona-Grounded Dialogue"]}],["$","span","Task Execution",{"className":"page__taxonomy-item","children":["#","Task Execution"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Deflanderization",{"className":"page__taxonomy-item","children":["#","Deflanderization"]}]]}]]}]]}],["$","article","2025-10-16-CVD-STORM_Cross-View_Video_Diffusion_with_Spatial-Temporal_Reconstruction_Model_for_Autonomous_Driving",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-CVD-STORM_Cross-View_Video_Diffusion_with_Spatial-Temporal_Reconstruction_Model_for_Autonomous_Driving/","children":"[논문리뷰] CVD-STORM: Cross-View Video Diffusion with Spatial-Temporal Reconstruction Model for Autonomous Driving"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jingcheng Ni이 [arXiv]에 게시한 'CVD-STORM: Cross-View Video Diffusion with Spatial-Temporal Reconstruction Model for Autonomous Driving' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Autonomous Driving",{"className":"page__taxonomy-item","children":["#","Autonomous Driving"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Spatial-Temporal Reconstruction",{"className":"page__taxonomy-item","children":["#","Spatial-Temporal Reconstruction"]}],["$","span","3D Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","3D Gaussian Splatting"]}],["$","span","Variational Autoencoder",{"className":"page__taxonomy-item","children":["#","Variational Autoencoder"]}],["$","span","World Modeling",{"className":"page__taxonomy-item","children":["#","World Modeling"]}],["$","span","Multi-View Video",{"className":"page__taxonomy-item","children":["#","Multi-View Video"]}]]}]]}]]}],["$","article","2025-10-16-CoIRL-AD_Collaborative-Competitive_Imitation-Reinforcement_Learning_in_Latent_World_Models_for_Autonomous_Driving",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-CoIRL-AD_Collaborative-Competitive_Imitation-Reinforcement_Learning_in_Latent_World_Models_for_Autonomous_Driving/","children":"[논문리뷰] CoIRL-AD: Collaborative-Competitive Imitation-Reinforcement Learning in Latent World Models for Autonomous Driving"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'CoIRL-AD: Collaborative-Competitive Imitation-Reinforcement Learning in Latent World Models for Autonomous Driving' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Autonomous Driving",{"className":"page__taxonomy-item","children":["#","Autonomous Driving"]}],["$","span","Imitation Learning",{"className":"page__taxonomy-item","children":["#","Imitation Learning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","World Models",{"className":"page__taxonomy-item","children":["#","World Models"]}],["$","span","Latent Space",{"className":"page__taxonomy-item","children":["#","Latent Space"]}],["$","span","Dual-Policy",{"className":"page__taxonomy-item","children":["#","Dual-Policy"]}],["$","span","Competitive Learning",{"className":"page__taxonomy-item","children":["#","Competitive Learning"]}]]}]]}]]}],["$","article","2025-10-16-Bee_A_High-Quality_Corpus_and_Full-Stack_Suite_to_Unlock_Advanced_Fully_Open_MLLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-Bee_A_High-Quality_Corpus_and_Full-Stack_Suite_to_Unlock_Advanced_Fully_Open_MLLMs/","children":"[논문리뷰] Bee: A High-Quality Corpus and Full-Stack Suite to Unlock Advanced Fully Open MLLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Bee: A High-Quality Corpus and Full-Stack Suite to Unlock Advanced Fully Open MLLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Open-source AI",{"className":"page__taxonomy-item","children":["#","Open-source AI"]}],["$","span","Data Quality",{"className":"page__taxonomy-item","children":["#","Data Quality"]}],["$","span","MLLM Training",{"className":"page__taxonomy-item","children":["#","MLLM Training"]}]]}]]}]]}],["$","article","2025-10-16-Attention_Illuminates_LLM_Reasoning_The_Preplan-and-Anchor_Rhythm_Enables_Fine-Grained_Policy_Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-16-Attention_Illuminates_LLM_Reasoning_The_Preplan-and-Anchor_Rhythm_Enables_Fine-Grained_Policy_Optimization/","children":"[논문리뷰] Attention Illuminates LLM Reasoning: The Preplan-and-Anchor Rhythm Enables Fine-Grained Policy Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Attention Illuminates LLM Reasoning: The Preplan-and-Anchor Rhythm Enables Fine-Grained Policy Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-16 13:09:51+0900","children":"2025년 10월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Reasoning",{"className":"page__taxonomy-item","children":["#","LLM Reasoning"]}],["$","span","Attention Mechanisms",{"className":"page__taxonomy-item","children":["#","Attention Mechanisms"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Credit Assignment",{"className":"page__taxonomy-item","children":["#","Credit Assignment"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Interpretability",{"className":"page__taxonomy-item","children":["#","Interpretability"]}],["$","span","Preplan-and-Anchor Rhythm",{"className":"page__taxonomy-item","children":["#","Preplan-and-Anchor Rhythm"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}]]}]]}]]}],["$","article","2025-10-15-What_If_Understanding_Motion_Through_Sparse_Interactions",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-What_If_Understanding_Motion_Through_Sparse_Interactions/","children":"[논문리뷰] What If : Understanding Motion Through Sparse Interactions"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'What If : Understanding Motion Through Sparse Interactions' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Motion Understanding",{"className":"page__taxonomy-item","children":["#","Motion Understanding"]}],["$","span","Sparse Interactions",{"className":"page__taxonomy-item","children":["#","Sparse Interactions"]}],["$","span","Multimodal Prediction",{"className":"page__taxonomy-item","children":["#","Multimodal Prediction"]}],["$","span","Flow Poke Transformer",{"className":"page__taxonomy-item","children":["#","Flow Poke Transformer"]}],["$","span","Physical Scene Dynamics",{"className":"page__taxonomy-item","children":["#","Physical Scene Dynamics"]}],["$","span","Uncertainty Quantification",{"className":"page__taxonomy-item","children":["#","Uncertainty Quantification"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Computer Vision",{"className":"page__taxonomy-item","children":["#","Computer Vision"]}]]}]]}]]}],["$","article","2025-10-15-ViCO_A_Training_Strategy_towards_Semantic_Aware_Dynamic_High-Resolution",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-ViCO_A_Training_Strategy_towards_Semantic_Aware_Dynamic_High-Resolution/","children":"[논문리뷰] ViCO: A Training Strategy towards Semantic Aware Dynamic High-Resolution"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'ViCO: A Training Strategy towards Semantic Aware Dynamic High-Resolution' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models (MLLMs)"]}],["$","span","Dynamic Resolution",{"className":"page__taxonomy-item","children":["#","Dynamic Resolution"]}],["$","span","Token Compression",{"className":"page__taxonomy-item","children":["#","Token Compression"]}],["$","span","Semantic Awareness",{"className":"page__taxonomy-item","children":["#","Semantic Awareness"]}],["$","span","Visual Consistency Learning (ViCO)",{"className":"page__taxonomy-item","children":["#","Visual Consistency Learning (ViCO)"]}],["$","span","Visual Resolution Router (ViR)",{"className":"page__taxonomy-item","children":["#","Visual Resolution Router (ViR)"]}],["$","span","Inference Optimization",{"className":"page__taxonomy-item","children":["#","Inference Optimization"]}]]}]]}]]}],["$","article","2025-10-15-UniFusion_Vision-Language_Model_as_Unified_Encoder_in_Image_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-UniFusion_Vision-Language_Model_as_Unified_Encoder_in_Image_Generation/","children":"[논문리뷰] UniFusion: Vision-Language Model as Unified Encoder in Image Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'UniFusion: Vision-Language Model as Unified Encoder in Image Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Model",{"className":"page__taxonomy-item","children":["#","Vision-Language Model"]}],["$","span","Unified Encoder",{"className":"page__taxonomy-item","children":["#","Unified Encoder"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Text-to-Image",{"className":"page__taxonomy-item","children":["#","Text-to-Image"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Zero-shot Learning",{"className":"page__taxonomy-item","children":["#","Zero-shot Learning"]}]]}]]}]]}],["$","article","2025-10-15-Tensor_Logic_The_Language_of_AI",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-Tensor_Logic_The_Language_of_AI/","children":"[논문리뷰] Tensor Logic: The Language of AI"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Pedro Domingos이 [arXiv]에 게시한 'Tensor Logic: The Language of AI' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Tensor Logic",{"className":"page__taxonomy-item","children":["#","Tensor Logic"]}],["$","span","Neurosymbolic AI",{"className":"page__taxonomy-item","children":["#","Neurosymbolic AI"]}],["$","span","Logic Programming",{"className":"page__taxonomy-item","children":["#","Logic Programming"]}],["$","span","Tensor Algebra",{"className":"page__taxonomy-item","children":["#","Tensor Algebra"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}],["$","span","Automated Reasoning",{"className":"page__taxonomy-item","children":["#","Automated Reasoning"]}],["$","span","Embedding Space",{"className":"page__taxonomy-item","children":["#","Embedding Space"]}]]}]]}]]}],["$","article","2025-10-15-Temporal_Alignment_Guidance_On-Manifold_Sampling_in_Diffusion_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-Temporal_Alignment_Guidance_On-Manifold_Sampling_in_Diffusion_Models/","children":"[논문리뷰] Temporal Alignment Guidance: On-Manifold Sampling in Diffusion Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Temporal Alignment Guidance: On-Manifold Sampling in Diffusion Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Guidance",{"className":"page__taxonomy-item","children":["#","Guidance"]}],["$","span","On-Manifold Sampling",{"className":"page__taxonomy-item","children":["#","On-Manifold Sampling"]}],["$","span","Temporal Alignment",{"className":"page__taxonomy-item","children":["#","Temporal Alignment"]}],["$","span","Score Approximation Error",{"className":"page__taxonomy-item","children":["#","Score Approximation Error"]}],["$","span","Training-Free Guidance",{"className":"page__taxonomy-item","children":["#","Training-Free Guidance"]}]]}]]}]]}],["$","article","2025-10-15-SynthID-Image_Image_watermarking_at_internet_scale",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-SynthID-Image_Image_watermarking_at_internet_scale/","children":"[논문리뷰] SynthID-Image: Image watermarking at internet scale"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'SynthID-Image: Image watermarking at internet scale' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Watermarking",{"className":"page__taxonomy-item","children":["#","Image Watermarking"]}],["$","span","AI-Generated Content",{"className":"page__taxonomy-item","children":["#","AI-Generated Content"]}],["$","span","Provenance",{"className":"page__taxonomy-item","children":["#","Provenance"]}],["$","span","Robustness",{"className":"page__taxonomy-item","children":["#","Robustness"]}],["$","span","Security",{"className":"page__taxonomy-item","children":["#","Security"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}],["$","span","Internet Scale",{"className":"page__taxonomy-item","children":["#","Internet Scale"]}],["$","span","Post-hoc",{"className":"page__taxonomy-item","children":["#","Post-hoc"]}]]}]]}]]}],["$","article","2025-10-15-SRUM_Fine-Grained_Self-Rewarding_for_Unified_Multimodal_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-SRUM_Fine-Grained_Self-Rewarding_for_Unified_Multimodal_Models/","children":"[논문리뷰] SRUM: Fine-Grained Self-Rewarding for Unified Multimodal Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'SRUM: Fine-Grained Self-Rewarding for Unified Multimodal Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Unified Multimodal Models",{"className":"page__taxonomy-item","children":["#","Unified Multimodal Models"]}],["$","span","Self-Rewarding",{"className":"page__taxonomy-item","children":["#","Self-Rewarding"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Image Understanding",{"className":"page__taxonomy-item","children":["#","Image Understanding"]}],["$","span","Post-Training",{"className":"page__taxonomy-item","children":["#","Post-Training"]}],["$","span","Global-Local Reward",{"className":"page__taxonomy-item","children":["#","Global-Local Reward"]}],["$","span","Compositional Reasoning",{"className":"page__taxonomy-item","children":["#","Compositional Reasoning"]}]]}]]}]]}],["$","article","2025-10-15-Spatial_Forcing_Implicit_Spatial_Representation_Alignment_for_Vision-language-action_Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-Spatial_Forcing_Implicit_Spatial_Representation_Alignment_for_Vision-language-action_Model/","children":"[논문리뷰] Spatial Forcing: Implicit Spatial Representation Alignment for Vision-language-action Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Spatial Forcing: Implicit Spatial Representation Alignment for Vision-language-action Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action Models"]}],["$","span","Spatial Perception",{"className":"page__taxonomy-item","children":["#","Spatial Perception"]}],["$","span","Implicit Representation Alignment",{"className":"page__taxonomy-item","children":["#","Implicit Representation Alignment"]}],["$","span","3D Foundation Models",{"className":"page__taxonomy-item","children":["#","3D Foundation Models"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Data Efficiency",{"className":"page__taxonomy-item","children":["#","Data Efficiency"]}],["$","span","Representation Learning",{"className":"page__taxonomy-item","children":["#","Representation Learning"]}]]}]]}]]}],["$","article","2025-10-15-Scaling_Language-Centric_Omnimodal_Representation_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-Scaling_Language-Centric_Omnimodal_Representation_Learning/","children":"[논문리뷰] Scaling Language-Centric Omnimodal Representation Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Scaling Language-Centric Omnimodal Representation Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Embeddings",{"className":"page__taxonomy-item","children":["#","Multimodal Embeddings"]}],["$","span","MLLMs",{"className":"page__taxonomy-item","children":["#","MLLMs"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Cross-modal Alignment",{"className":"page__taxonomy-item","children":["#","Cross-modal Alignment"]}],["$","span","Generative Pretraining",{"className":"page__taxonomy-item","children":["#","Generative Pretraining"]}],["$","span","Representation Learning",{"className":"page__taxonomy-item","children":["#","Representation Learning"]}],["$","span","Scaling Laws",{"className":"page__taxonomy-item","children":["#","Scaling Laws"]}]]}]]}]]}],["$","article","2025-10-15-SAIL-Embedding_Technical_Report_Omni-modal_Embedding_Foundation_Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-SAIL-Embedding_Technical_Report_Omni-modal_Embedding_Foundation_Model/","children":"[논문리뷰] SAIL-Embedding Technical Report: Omni-modal Embedding Foundation Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'SAIL-Embedding Technical Report: Omni-modal Embedding Foundation Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Omni-modal Embedding",{"className":"page__taxonomy-item","children":["#","Omni-modal Embedding"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Recommendation Systems",{"className":"page__taxonomy-item","children":["#","Recommendation Systems"]}],["$","span","Hard Negative Mining",{"className":"page__taxonomy-item","children":["#","Hard Negative Mining"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Data Balancing",{"className":"page__taxonomy-item","children":["#","Data Balancing"]}],["$","span","Multitask Learning",{"className":"page__taxonomy-item","children":["#","Multitask Learning"]}]]}]]}]]}],["$","article","2025-10-15-Robot_Learning_A_Tutorial",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-Robot_Learning_A_Tutorial/","children":"[논문리뷰] Robot Learning: A Tutorial"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Robot Learning: A Tutorial' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Robot Learning",{"className":"page__taxonomy-item","children":["#","Robot Learning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Imitation Learning",{"className":"page__taxonomy-item","children":["#","Imitation Learning"]}],["$","span","Behavioral Cloning",{"className":"page__taxonomy-item","children":["#","Behavioral Cloning"]}],["$","span","Vision-Language-Action Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action Models"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Transformers",{"className":"page__taxonomy-item","children":["#","Transformers"]}],["$","span","LeRobot",{"className":"page__taxonomy-item","children":["#","LeRobot"]}]]}]]}]]}],["$","article","2025-10-15-ReFIne_A_Framework_for_Trustworthy_Large_Reasoning_Models_with_Reliability_Faithfulness_and_Interpretability",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-ReFIne_A_Framework_for_Trustworthy_Large_Reasoning_Models_with_Reliability_Faithfulness_and_Interpretability/","children":"[논문리뷰] ReFIne: A Framework for Trustworthy Large Reasoning Models with Reliability, Faithfulness, and Interpretability"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Tsui-Wei Weng이 [arXiv]에 게시한 'ReFIne: A Framework for Trustworthy Large Reasoning Models with Reliability, Faithfulness, and Interpretability' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Trustworthy AI",{"className":"page__taxonomy-item","children":["#","Trustworthy AI"]}],["$","span","Large Reasoning Models (LRMs)",{"className":"page__taxonomy-item","children":["#","Large Reasoning Models (LRMs)"]}],["$","span","Interpretability",{"className":"page__taxonomy-item","children":["#","Interpretability"]}],["$","span","Faithfulness",{"className":"page__taxonomy-item","children":["#","Faithfulness"]}],["$","span","Reliability",{"className":"page__taxonomy-item","children":["#","Reliability"]}],["$","span","Chain-of-Thought (CoT)",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought (CoT)"]}],["$","span","Supervised Fine-tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning (SFT)"]}],["$","span","GRPO",{"className":"page__taxonomy-item","children":["#","GRPO"]}]]}]]}]]}],["$","article","2025-10-15-One_Life_to_Learn_Inferring_Symbolic_World_Models_for_Stochastic_Environments_from_Unguided_Exploration",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-One_Life_to_Learn_Inferring_Symbolic_World_Models_for_Stochastic_Environments_from_Unguided_Exploration/","children":"[논문리뷰] One Life to Learn: Inferring Symbolic World Models for Stochastic Environments from Unguided Exploration"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Mohit Bansal이 [arXiv]에 게시한 'One Life to Learn: Inferring Symbolic World Models for Stochastic Environments from Unguided Exploration' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Symbolic World Models",{"className":"page__taxonomy-item","children":["#","Symbolic World Models"]}],["$","span","Stochastic Environments",{"className":"page__taxonomy-item","children":["#","Stochastic Environments"]}],["$","span","Unguided Exploration",{"className":"page__taxonomy-item","children":["#","Unguided Exploration"]}],["$","span","Probabilistic Programming",{"className":"page__taxonomy-item","children":["#","Probabilistic Programming"]}],["$","span","Law Synthesis",{"className":"page__taxonomy-item","children":["#","Law Synthesis"]}],["$","span","Crafter-OO",{"className":"page__taxonomy-item","children":["#","Crafter-OO"]}],["$","span","Program Synthesis",{"className":"page__taxonomy-item","children":["#","Program Synthesis"]}]]}]]}]]}],["$","article","2025-10-15-MLLM_as_a_UI_Judge_Benchmarking_Multimodal_LLMs_for_Predicting_Human_Perception_of_User_Interfaces",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-MLLM_as_a_UI_Judge_Benchmarking_Multimodal_LLMs_for_Predicting_Human_Perception_of_User_Interfaces/","children":"[논문리뷰] MLLM as a UI Judge: Benchmarking Multimodal LLMs for Predicting Human Perception of User Interfaces"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Sungchul Kim이 [arXiv]에 게시한 'MLLM as a UI Judge: Benchmarking Multimodal LLMs for Predicting Human Perception of User Interfaces' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","UI Evaluation",{"className":"page__taxonomy-item","children":["#","UI Evaluation"]}],["$","span","Human Perception",{"className":"page__taxonomy-item","children":["#","Human Perception"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","UX Research",{"className":"page__taxonomy-item","children":["#","UX Research"]}],["$","span","MLLM-as-a-Judge",{"className":"page__taxonomy-item","children":["#","MLLM-as-a-Judge"]}],["$","span","Cognitive Factors",{"className":"page__taxonomy-item","children":["#","Cognitive Factors"]}],["$","span","Pairwise Comparison",{"className":"page__taxonomy-item","children":["#","Pairwise Comparison"]}]]}]]}]]}],["$","article","2025-10-15-Memory_as_Action_Autonomous_Context_Curation_for_Long-Horizon_Agentic_Tasks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-Memory_as_Action_Autonomous_Context_Curation_for_Long-Horizon_Agentic_Tasks/","children":"[논문리뷰] Memory as Action: Autonomous Context Curation for Long-Horizon Agentic Tasks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xueyuan Lin이 [arXiv]에 게시한 'Memory as Action: Autonomous Context Curation for Long-Horizon Agentic Tasks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Long-Horizon Tasks",{"className":"page__taxonomy-item","children":["#","Long-Horizon Tasks"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Context Curation",{"className":"page__taxonomy-item","children":["#","Context Curation"]}],["$","span","Working Memory",{"className":"page__taxonomy-item","children":["#","Working Memory"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Memory-as-Action",{"className":"page__taxonomy-item","children":["#","Memory-as-Action"]}]]}]]}]]}],["$","article","2025-10-15-LLM_Reasoning_for_Machine_Translation_Synthetic_Data_Generation_over_Thinking_Tokens",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-LLM_Reasoning_for_Machine_Translation_Synthetic_Data_Generation_over_Thinking_Tokens/","children":"[논문리뷰] LLM Reasoning for Machine Translation: Synthetic Data Generation over Thinking Tokens"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'LLM Reasoning for Machine Translation: Synthetic Data Generation over Thinking Tokens' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Machine Translation (MT)",{"className":"page__taxonomy-item","children":["#","Machine Translation (MT)"]}],["$","span","Chain-of-Thought (CoT)",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought (CoT)"]}],["$","span","Knowledge Distillation",{"className":"page__taxonomy-item","children":["#","Knowledge Distillation"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","Synthetic Data",{"className":"page__taxonomy-item","children":["#","Synthetic Data"]}]]}]]}]]}],["$","article","2025-10-15-Information-Preserving_Reformulation_of_Reasoning_Traces_for_Antidistillation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-Information-Preserving_Reformulation_of_Reasoning_Traces_for_Antidistillation/","children":"[논문리뷰] Information-Preserving Reformulation of Reasoning Traces for Antidistillation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Information-Preserving Reformulation of Reasoning Traces for Antidistillation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Antidistillation",{"className":"page__taxonomy-item","children":["#","Antidistillation"]}],["$","span","Reasoning Traces",{"className":"page__taxonomy-item","children":["#","Reasoning Traces"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Knowledge Distillation",{"className":"page__taxonomy-item","children":["#","Knowledge Distillation"]}],["$","span","Information Preservation",{"className":"page__taxonomy-item","children":["#","Information Preservation"]}],["$","span","Trace Reformulation",{"className":"page__taxonomy-item","children":["#","Trace Reformulation"]}],["$","span","Supervised Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning"]}]]}]]}]]}],["$","article","2025-10-15-HoneyBee_Data_Recipes_for_Vision-Language_Reasoners",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-HoneyBee_Data_Recipes_for_Vision-Language_Reasoners/","children":"[논문리뷰] HoneyBee: Data Recipes for Vision-Language Reasoners"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'HoneyBee: Data Recipes for Vision-Language Reasoners' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","VL Reasoning",{"className":"page__taxonomy-item","children":["#","VL Reasoning"]}],["$","span","Dataset Scaling",{"className":"page__taxonomy-item","children":["#","Dataset Scaling"]}],["$","span","Supervised Finetuning",{"className":"page__taxonomy-item","children":["#","Supervised Finetuning"]}],["$","span","HONEYBEE",{"className":"page__taxonomy-item","children":["#","HONEYBEE"]}],["$","span","Test-Time Scaling",{"className":"page__taxonomy-item","children":["#","Test-Time Scaling"]}]]}]]}]]}],["$","article","2025-10-15-FlashVSR_Towards_Real-Time_Diffusion-Based_Streaming_Video_Super-Resolution",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-FlashVSR_Towards_Real-Time_Diffusion-Based_Streaming_Video_Super-Resolution/","children":"[논문리뷰] FlashVSR: Towards Real-Time Diffusion-Based Streaming Video Super-Resolution"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yihao Liu이 [arXiv]에 게시한 'FlashVSR: Towards Real-Time Diffusion-Based Streaming Video Super-Resolution' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Super-Resolution (VSR)",{"className":"page__taxonomy-item","children":["#","Video Super-Resolution (VSR)"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Real-time VSR",{"className":"page__taxonomy-item","children":["#","Real-time VSR"]}],["$","span","Streaming VSR",{"className":"page__taxonomy-item","children":["#","Streaming VSR"]}],["$","span","Sparse Attention",{"className":"page__taxonomy-item","children":["#","Sparse Attention"]}],["$","span","Distillation",{"className":"page__taxonomy-item","children":["#","Distillation"]}],["$","span","Conditional Decoder",{"className":"page__taxonomy-item","children":["#","Conditional Decoder"]}],["$","span","High-resolution",{"className":"page__taxonomy-item","children":["#","High-resolution"]}]]}]]}]]}],["$","article","2025-10-15-ExpVid_A_Benchmark_for_Experiment_Video_Understanding_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-ExpVid_A_Benchmark_for_Experiment_Video_Understanding_Reasoning/","children":"[논문리뷰] ExpVid: A Benchmark for Experiment Video Understanding & Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'ExpVid: A Benchmark for Experiment Video Understanding & Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Experiment Video Understanding",{"className":"page__taxonomy-item","children":["#","Experiment Video Understanding"]}],["$","span","Multimodal Large Language Models (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models (MLLMs)"]}],["$","span","Scientific Reasoning",{"className":"page__taxonomy-item","children":["#","Scientific Reasoning"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Wet-Lab Experiments",{"className":"page__taxonomy-item","children":["#","Wet-Lab Experiments"]}],["$","span","Procedural Understanding",{"className":"page__taxonomy-item","children":["#","Procedural Understanding"]}],["$","span","Fine-grained Perception",{"className":"page__taxonomy-item","children":["#","Fine-grained Perception"]}],["$","span","Video QA",{"className":"page__taxonomy-item","children":["#","Video QA"]}]]}]]}]]}],["$","article","2025-10-15-ERA_Transforming_VLMs_into_Embodied_Agents_via_Embodied_Prior_Learning_and_Online_Reinforcement_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-ERA_Transforming_VLMs_into_Embodied_Agents_via_Embodied_Prior_Learning_and_Online_Reinforcement_Learning/","children":"[논문리뷰] ERA: Transforming VLMs into Embodied Agents via Embodied Prior Learning and Online Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'ERA: Transforming VLMs into Embodied Agents via Embodied Prior Learning and Online Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Vision Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision Language Models (VLMs)"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Prior Learning",{"className":"page__taxonomy-item","children":["#","Prior Learning"]}],["$","span","Supervised Fine-tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning (SFT)"]}],["$","span","Embodied Agents",{"className":"page__taxonomy-item","children":["#","Embodied Agents"]}]]}]]}]]}],["$","article","2025-10-15-Dr.LLM_Dynamic_Layer_Routing_in_LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-Dr.LLM_Dynamic_Layer_Routing_in_LLMs/","children":"[논문리뷰] Dr.LLM: Dynamic Layer Routing in LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Dr.LLM: Dynamic Layer Routing in LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Dynamic Routing",{"className":"page__taxonomy-item","children":["#","Dynamic Routing"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Adaptive Depth",{"className":"page__taxonomy-item","children":["#","Adaptive Depth"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}],["$","span","Monte Carlo Tree Search (MCTS)",{"className":"page__taxonomy-item","children":["#","Monte Carlo Tree Search (MCTS)"]}],["$","span","Retrofittable Framework",{"className":"page__taxonomy-item","children":["#","Retrofittable Framework"]}],["$","span","Supervised Learning",{"className":"page__taxonomy-item","children":["#","Supervised Learning"]}],["$","span","Accuracy Improvement",{"className":"page__taxonomy-item","children":["#","Accuracy Improvement"]}]]}]]}]]}],["$","article","2025-10-15-DITING_A_Multi-Agent_Evaluation_Framework_for_Benchmarking_Web_Novel_Translation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-DITING_A_Multi-Agent_Evaluation_Framework_for_Benchmarking_Web_Novel_Translation/","children":"[논문리뷰] DITING: A Multi-Agent Evaluation Framework for Benchmarking Web Novel Translation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DITING: A Multi-Agent Evaluation Framework for Benchmarking Web Novel Translation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Machine Translation Evaluation",{"className":"page__taxonomy-item","children":["#","Machine Translation Evaluation"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Web Novel Translation",{"className":"page__taxonomy-item","children":["#","Web Novel Translation"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Cultural Nuance",{"className":"page__taxonomy-item","children":["#","Cultural Nuance"]}],["$","span","Benchmark Dataset",{"className":"page__taxonomy-item","children":["#","Benchmark Dataset"]}],["$","span","Natural Language Generation",{"className":"page__taxonomy-item","children":["#","Natural Language Generation"]}]]}]]}]]}],["$","article","2025-10-15-Detect_Anything_via_Next_Point_Prediction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-Detect_Anything_via_Next_Point_Prediction/","children":"[논문리뷰] Detect Anything via Next Point Prediction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Detect Anything via Next Point Prediction' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models"]}],["$","span","Object Detection",{"className":"page__taxonomy-item","children":["#","Object Detection"]}],["$","span","Coordinate Prediction",{"className":"page__taxonomy-item","children":["#","Coordinate Prediction"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Visual Perception",{"className":"page__taxonomy-item","children":["#","Visual Perception"]}],["$","span","Zero-shot Learning",{"className":"page__taxonomy-item","children":["#","Zero-shot Learning"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}]]}]]}]]}],["$","article","2025-10-15-DeepMMSearch-R1_Empowering_Multimodal_LLMs_in_Multimodal_Web_Search",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-DeepMMSearch-R1_Empowering_Multimodal_LLMs_in_Multimodal_Web_Search/","children":"[논문리뷰] DeepMMSearch-R1: Empowering Multimodal LLMs in Multimodal Web Search"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DeepMMSearch-R1: Empowering Multimodal LLMs in Multimodal Web Search' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLM",{"className":"page__taxonomy-item","children":["#","Multimodal LLM"]}],["$","span","Web Search",{"className":"page__taxonomy-item","children":["#","Web Search"]}],["$","span","Visual Question Answering",{"className":"page__taxonomy-item","children":["#","Visual Question Answering"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Image Cropping",{"className":"page__taxonomy-item","children":["#","Image Cropping"]}],["$","span","Self-Correction",{"className":"page__taxonomy-item","children":["#","Self-Correction"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}]]}]]}]]}],["$","article","2025-10-15-Boundary-Guided_Policy_Optimization_for_Memory-efficient_RL_of_Diffusion_Large_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-Boundary-Guided_Policy_Optimization_for_Memory-efficient_RL_of_Diffusion_Large_Language_Models/","children":"[논문리뷰] Boundary-Guided Policy Optimization for Memory-efficient RL of Diffusion Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Boundary-Guided Policy Optimization for Memory-efficient RL of Diffusion Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Large Language Models",{"className":"page__taxonomy-item","children":["#","Diffusion Large Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Memory Efficiency",{"className":"page__taxonomy-item","children":["#","Memory Efficiency"]}],["$","span","Monte Carlo Sampling",{"className":"page__taxonomy-item","children":["#","Monte Carlo Sampling"]}],["$","span","Log-Likelihood Approximation",{"className":"page__taxonomy-item","children":["#","Log-Likelihood Approximation"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","ELBO",{"className":"page__taxonomy-item","children":["#","ELBO"]}]]}]]}]]}],["$","article","2025-10-15-A_Survey_of_Vibe_Coding_with_Large_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-A_Survey_of_Vibe_Coding_with_Large_Language_Models/","children":"[논문리뷰] A Survey of Vibe Coding with Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'A Survey of Vibe Coding with Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vibe Coding",{"className":"page__taxonomy-item","children":["#","Vibe Coding"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Coding Agents",{"className":"page__taxonomy-item","children":["#","Coding Agents"]}],["$","span","Human-AI Collaboration",{"className":"page__taxonomy-item","children":["#","Human-AI Collaboration"]}],["$","span","Software Engineering",{"className":"page__taxonomy-item","children":["#","Software Engineering"]}],["$","span","Development Models",{"className":"page__taxonomy-item","children":["#","Development Models"]}],["$","span","Context Engineering",{"className":"page__taxonomy-item","children":["#","Context Engineering"]}]]}]]}]]}],["$","article","2025-10-15-Advancing_End-to-End_Pixel_Space_Generative_Modeling_via_Self-supervised_Pre-training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-15-Advancing_End-to-End_Pixel_Space_Generative_Modeling_via_Self-supervised_Pre-training/","children":"[논문리뷰] Advancing End-to-End Pixel Space Generative Modeling via Self-supervised Pre-training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Advancing End-to-End Pixel Space Generative Modeling via Self-supervised Pre-training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-15 13:01:40+0900","children":"2025년 10월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Pixel-space Generative Models",{"className":"page__taxonomy-item","children":["#","Pixel-space Generative Models"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Consistency Models",{"className":"page__taxonomy-item","children":["#","Consistency Models"]}],["$","span","Self-supervised Pre-training",{"className":"page__taxonomy-item","children":["#","Self-supervised Pre-training"]}],["$","span","End-to-end Training",{"className":"page__taxonomy-item","children":["#","End-to-end Training"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","FID",{"className":"page__taxonomy-item","children":["#","FID"]}],["$","span","Representation Learning",{"className":"page__taxonomy-item","children":["#","Representation Learning"]}]]}]]}]]}],["$","article","2025-10-13-Which_Heads_Matter_for_Reasoning_RL-Guided_KV_Cache_Compression",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Which_Heads_Matter_for_Reasoning_RL-Guided_KV_Cache_Compression/","children":"[논문리뷰] Which Heads Matter for Reasoning? RL-Guided KV Cache Compression"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Huan Wang이 [arXiv]에 게시한 'Which Heads Matter for Reasoning? RL-Guided KV Cache Compression' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","KV Cache Compression",{"className":"page__taxonomy-item","children":["#","KV Cache Compression"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Reasoning Models",{"className":"page__taxonomy-item","children":["#","Reasoning Models"]}],["$","span","Attention Heads",{"className":"page__taxonomy-item","children":["#","Attention Heads"]}],["$","span","Chain-of-Thought (CoT)",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought (CoT)"]}],["$","span","Memory Efficiency",{"className":"page__taxonomy-item","children":["#","Memory Efficiency"]}]]}]]}]]}],["$","article","2025-10-13-Webscale-RL_Automated_Data_Pipeline_for_Scaling_RL_Data_to_Pretraining_Levels",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Webscale-RL_Automated_Data_Pipeline_for_Scaling_RL_Data_to_Pretraining_Levels/","children":"[논문리뷰] Webscale-RL: Automated Data Pipeline for Scaling RL Data to Pretraining Levels"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Webscale-RL: Automated Data Pipeline for Scaling RL Data to Pretraining Levels' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Data Pipeline",{"className":"page__taxonomy-item","children":["#","Data Pipeline"]}],["$","span","Web-scale Data",{"className":"page__taxonomy-item","children":["#","Web-scale Data"]}],["$","span","Question-Answering (QA)",{"className":"page__taxonomy-item","children":["#","Question-Answering (QA)"]}],["$","span","Data Generation",{"className":"page__taxonomy-item","children":["#","Data Generation"]}],["$","span","Data Diversity",{"className":"page__taxonomy-item","children":["#","Data Diversity"]}],["$","span","Data Efficiency",{"className":"page__taxonomy-item","children":["#","Data Efficiency"]}]]}]]}]]}],["$","article","2025-10-13-Understanding_DeepResearch_via_Reports",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Understanding_DeepResearch_via_Reports/","children":"[논문리뷰] Understanding DeepResearch via Reports"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chengen Huang이 [arXiv]에 게시한 'Understanding DeepResearch via Reports' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","DeepResearch Agents",{"className":"page__taxonomy-item","children":["#","DeepResearch Agents"]}],["$","span","LLM-as-a-Judge",{"className":"page__taxonomy-item","children":["#","LLM-as-a-Judge"]}],["$","span","Report Evaluation",{"className":"page__taxonomy-item","children":["#","Report Evaluation"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Factuality",{"className":"page__taxonomy-item","children":["#","Factuality"]}],["$","span","Redundancy",{"className":"page__taxonomy-item","children":["#","Redundancy"]}],["$","span","Research Automation",{"className":"page__taxonomy-item","children":["#","Research Automation"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}]]}]]}]]}],["$","article","2025-10-13-Thinking_with_Camera_A_Unified_Multimodal_Model_for_Camera-Centric_Understanding_and_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Thinking_with_Camera_A_Unified_Multimodal_Model_for_Camera-Centric_Understanding_and_Generation/","children":"[논문리뷰] Thinking with Camera: A Unified Multimodal Model for Camera-Centric Understanding and Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Linyi Jin이 [arXiv]에 게시한 'Thinking with Camera: A Unified Multimodal Model for Camera-Centric Understanding and Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Unified Multimodal Model",{"className":"page__taxonomy-item","children":["#","Unified Multimodal Model"]}],["$","span","Camera-Centric",{"className":"page__taxonomy-item","children":["#","Camera-Centric"]}],["$","span","Image Understanding",{"className":"page__taxonomy-item","children":["#","Image Understanding"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}],["$","span","Camera Parameters",{"className":"page__taxonomy-item","children":["#","Camera Parameters"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}],["$","span","Multimodal Spatial Intelligence",{"className":"page__taxonomy-item","children":["#","Multimodal Spatial Intelligence"]}]]}]]}]]}],["$","article","2025-10-13-Temporal_Prompting_Matters_Rethinking_Referring_Video_Object_Segmentation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Temporal_Prompting_Matters_Rethinking_Referring_Video_Object_Segmentation/","children":"[논문리뷰] Temporal Prompting Matters: Rethinking Referring Video Object Segmentation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Sifei Liu이 [arXiv]에 게시한 'Temporal Prompting Matters: Rethinking Referring Video Object Segmentation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Referring Video Object Segmentation",{"className":"page__taxonomy-item","children":["#","Referring Video Object Segmentation"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","Object Tracking",{"className":"page__taxonomy-item","children":["#","Object Tracking"]}],["$","span","SAM",{"className":"page__taxonomy-item","children":["#","SAM"]}],["$","span","Video Analysis",{"className":"page__taxonomy-item","children":["#","Video Analysis"]}],["$","span","Prompt Preference Learning",{"className":"page__taxonomy-item","children":["#","Prompt Preference Learning"]}]]}]]}]]}],["$","article","2025-10-13-TC-LoRA_Temporally_Modulated_Conditional_LoRA_for_Adaptive_Diffusion_Control",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-TC-LoRA_Temporally_Modulated_Conditional_LoRA_for_Adaptive_Diffusion_Control/","children":"[논문리뷰] TC-LoRA: Temporally Modulated Conditional LoRA for Adaptive Diffusion Control"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Adityan Jothi이 [arXiv]에 게시한 'TC-LoRA: Temporally Modulated Conditional LoRA for Adaptive Diffusion Control' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Conditional Generation",{"className":"page__taxonomy-item","children":["#","Conditional Generation"]}],["$","span","LoRA",{"className":"page__taxonomy-item","children":["#","LoRA"]}],["$","span","Hypernetwork",{"className":"page__taxonomy-item","children":["#","Hypernetwork"]}],["$","span","Dynamic Weight Adaptation",{"className":"page__taxonomy-item","children":["#","Dynamic Weight Adaptation"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Controllable Generation",{"className":"page__taxonomy-item","children":["#","Controllable Generation"]}]]}]]}]]}],["$","article","2025-10-13-StreamingVLM_Real-Time_Understanding_for_Infinite_Video_Streams",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-StreamingVLM_Real-Time_Understanding_for_Infinite_Video_Streams/","children":"[논문리뷰] StreamingVLM: Real-Time Understanding for Infinite Video Streams"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kelly Peng이 [arXiv]에 게시한 'StreamingVLM: Real-Time Understanding for Infinite Video Streams' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Stream Understanding",{"className":"page__taxonomy-item","children":["#","Video Stream Understanding"]}],["$","span","Real-Time VLM",{"className":"page__taxonomy-item","children":["#","Real-Time VLM"]}],["$","span","Attention Sink",{"className":"page__taxonomy-item","children":["#","Attention Sink"]}],["$","span","KV Cache Management",{"className":"page__taxonomy-item","children":["#","KV Cache Management"]}],["$","span","Contiguous RoPE",{"className":"page__taxonomy-item","children":["#","Contiguous RoPE"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Long-Context Video",{"className":"page__taxonomy-item","children":["#","Long-Context Video"]}]]}]]}]]}],["$","article","2025-10-13-StatEval_A_Comprehensive_Benchmark_for_Large_Language_Models_in_Statistics",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-StatEval_A_Comprehensive_Benchmark_for_Large_Language_Models_in_Statistics/","children":"[논문리뷰] StatEval: A Comprehensive Benchmark for Large Language Models in Statistics"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'StatEval: A Comprehensive Benchmark for Large Language Models in Statistics' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Statistical Reasoning",{"className":"page__taxonomy-item","children":["#","Statistical Reasoning"]}],["$","span","LLM Benchmark",{"className":"page__taxonomy-item","children":["#","LLM Benchmark"]}],["$","span","Statistics Education",{"className":"page__taxonomy-item","children":["#","Statistics Education"]}],["$","span","Proof Verification",{"className":"page__taxonomy-item","children":["#","Proof Verification"]}],["$","span","Multi-agent Pipeline",{"className":"page__taxonomy-item","children":["#","Multi-agent Pipeline"]}],["$","span","Automated Extraction",{"className":"page__taxonomy-item","children":["#","Automated Extraction"]}],["$","span","Evaluation Framework",{"className":"page__taxonomy-item","children":["#","Evaluation Framework"]}]]}]]}]]}],["$","article","2025-10-13-Speculative_Jacobi-Denoising_Decoding_for_Accelerating_Autoregressive_Text-to-image_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Speculative_Jacobi-Denoising_Decoding_for_Accelerating_Autoregressive_Text-to-image_Generation/","children":"[논문리뷰] Speculative Jacobi-Denoising Decoding for Accelerating Autoregressive Text-to-image Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Han Shi이 [arXiv]에 게시한 'Speculative Jacobi-Denoising Decoding for Accelerating Autoregressive Text-to-image Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Autoregressive Models",{"className":"page__taxonomy-item","children":["#","Autoregressive Models"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Inference Acceleration",{"className":"page__taxonomy-item","children":["#","Inference Acceleration"]}],["$","span","Jacobi Decoding",{"className":"page__taxonomy-item","children":["#","Jacobi Decoding"]}],["$","span","Denoising Diffusion Models",{"className":"page__taxonomy-item","children":["#","Denoising Diffusion Models"]}],["$","span","Speculative Decoding",{"className":"page__taxonomy-item","children":["#","Speculative Decoding"]}],["$","span","Multi-token Prediction",{"className":"page__taxonomy-item","children":["#","Multi-token Prediction"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}]]}]]}]]}],["$","article","2025-10-13-SpaceVista_All-Scale_Visual_Spatial_Reasoning_from_mm_to_km",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-SpaceVista_All-Scale_Visual_Spatial_Reasoning_from_mm_to_km/","children":"[논문리뷰] SpaceVista: All-Scale Visual Spatial Reasoning from mm to km"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kaituo Feng이 [arXiv]에 게시한 'SpaceVista: All-Scale Visual Spatial Reasoning from mm to km' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}],["$","span","Multi-Scale Vision",{"className":"page__taxonomy-item","children":["#","Multi-Scale Vision"]}],["$","span","MLLM",{"className":"page__taxonomy-item","children":["#","MLLM"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}],["$","span","Scale Experts",{"className":"page__taxonomy-item","children":["#","Scale Experts"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Computer Vision",{"className":"page__taxonomy-item","children":["#","Computer Vision"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}]]}]]}]]}],["$","article","2025-10-13-ReviewerToo_Should_AI_Join_The_Program_Committee_A_Look_At_The_Future_of_Peer_Review",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-ReviewerToo_Should_AI_Join_The_Program_Committee_A_Look_At_The_Future_of_Peer_Review/","children":"[논문리뷰] ReviewerToo: Should AI Join The Program Committee? A Look At The Future of Peer Review"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Christopher Pal이 [arXiv]에 게시한 'ReviewerToo: Should AI Join The Program Committee? A Look At The Future of Peer Review' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Peer Review",{"className":"page__taxonomy-item","children":["#","Peer Review"]}],["$","span","AI-Assisted Review",{"className":"page__taxonomy-item","children":["#","AI-Assisted Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Meta-Review",{"className":"page__taxonomy-item","children":["#","Meta-Review"]}],["$","span","Conference Submissions",{"className":"page__taxonomy-item","children":["#","Conference Submissions"]}],["$","span","Reviewer Personas",{"className":"page__taxonomy-item","children":["#","Reviewer Personas"]}],["$","span","Evaluation Metrics",{"className":"page__taxonomy-item","children":["#","Evaluation Metrics"]}]]}]]}]]}],["$","article","2025-10-13-R-Horizon_How_Far_Can_Your_Large_Reasoning_Model_Really_Go_in_Breadth_and_Depth",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-R-Horizon_How_Far_Can_Your_Large_Reasoning_Model_Really_Go_in_Breadth_and_Depth/","children":"[논문리뷰] R-Horizon: How Far Can Your Large Reasoning Model Really Go in Breadth and Depth?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'R-Horizon: How Far Can Your Large Reasoning Model Really Go in Breadth and Depth?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Long-Horizon Reasoning",{"className":"page__taxonomy-item","children":["#","Long-Horizon Reasoning"]}],["$","span","Query Composition",{"className":"page__taxonomy-item","children":["#","Query Composition"]}],["$","span","Large Reasoning Models",{"className":"page__taxonomy-item","children":["#","Large Reasoning Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Benchmark Evaluation",{"className":"page__taxonomy-item","children":["#","Benchmark Evaluation"]}],["$","span","Thinking Budget",{"className":"page__taxonomy-item","children":["#","Thinking Budget"]}],["$","span","Performance Degradation",{"className":"page__taxonomy-item","children":["#","Performance Degradation"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}]]}]]}]]}],["$","article","2025-10-13-Pseudo2Real_Task_Arithmetic_for_Pseudo-Label_Correction_in_Automatic_Speech_Recognition",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Pseudo2Real_Task_Arithmetic_for_Pseudo-Label_Correction_in_Automatic_Speech_Recognition/","children":"[논문리뷰] Pseudo2Real: Task Arithmetic for Pseudo-Label Correction in Automatic Speech Recognition"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shang-Tse Chen이 [arXiv]에 게시한 'Pseudo2Real: Task Arithmetic for Pseudo-Label Correction in Automatic Speech Recognition' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","ASR",{"className":"page__taxonomy-item","children":["#","ASR"]}],["$","span","Pseudo-labeling",{"className":"page__taxonomy-item","children":["#","Pseudo-labeling"]}],["$","span","Domain Adaptation",{"className":"page__taxonomy-item","children":["#","Domain Adaptation"]}],["$","span","Task Arithmetic",{"className":"page__taxonomy-item","children":["#","Task Arithmetic"]}],["$","span","Correction Vector",{"className":"page__taxonomy-item","children":["#","Correction Vector"]}],["$","span","Accent Adaptation",{"className":"page__taxonomy-item","children":["#","Accent Adaptation"]}],["$","span","Speaker Clustering",{"className":"page__taxonomy-item","children":["#","Speaker Clustering"]}],["$","span","Model Editing",{"className":"page__taxonomy-item","children":["#","Model Editing"]}]]}]]}]]}],["$","article","2025-10-13-Progressive_Gaussian_Transformer_with_Anisotropy-aware_Sampling_for_Open_Vocabulary_Occupancy_Prediction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Progressive_Gaussian_Transformer_with_Anisotropy-aware_Sampling_for_Open_Vocabulary_Occupancy_Prediction/","children":"[논문리뷰] Progressive Gaussian Transformer with Anisotropy-aware Sampling for Open Vocabulary Occupancy Prediction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"danxuhk이 [arXiv]에 게시한 'Progressive Gaussian Transformer with Anisotropy-aware Sampling for Open Vocabulary Occupancy Prediction' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Occupancy Prediction",{"className":"page__taxonomy-item","children":["#","3D Occupancy Prediction"]}],["$","span","Open Vocabulary",{"className":"page__taxonomy-item","children":["#","Open Vocabulary"]}],["$","span","Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","Gaussian Splatting"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Progressive Densification",{"className":"page__taxonomy-item","children":["#","Progressive Densification"]}],["$","span","Anisotropy-aware Sampling",{"className":"page__taxonomy-item","children":["#","Anisotropy-aware Sampling"]}],["$","span","Autonomous Driving",{"className":"page__taxonomy-item","children":["#","Autonomous Driving"]}]]}]]}]]}],["$","article","2025-10-13-PhysToolBench_Benchmarking_Physical_Tool_Understanding_for_MLLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-PhysToolBench_Benchmarking_Physical_Tool_Understanding_for_MLLMs/","children":"[논문리뷰] PhysToolBench: Benchmarking Physical Tool Understanding for MLLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xu Zheng이 [arXiv]에 게시한 'PhysToolBench: Benchmarking Physical Tool Understanding for MLLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models (MLLMs)"]}],["$","span","Physical Tool Understanding",{"className":"page__taxonomy-item","children":["#","Physical Tool Understanding"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Visual Question Answering (VQA)",{"className":"page__taxonomy-item","children":["#","Visual Question Answering (VQA)"]}],["$","span","Tool Affordances",{"className":"page__taxonomy-item","children":["#","Tool Affordances"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}]]}]]}]]}],["$","article","2025-10-13-Parallel_Test-Time_Scaling_for_Latent_Reasoning_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Parallel_Test-Time_Scaling_for_Latent_Reasoning_Models/","children":"[논문리뷰] Parallel Test-Time Scaling for Latent Reasoning Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Parallel Test-Time Scaling for Latent Reasoning Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Latent Reasoning",{"className":"page__taxonomy-item","children":["#","Latent Reasoning"]}],["$","span","Test-Time Scaling",{"className":"page__taxonomy-item","children":["#","Test-Time Scaling"]}],["$","span","Parallel Inference",{"className":"page__taxonomy-item","children":["#","Parallel Inference"]}],["$","span","Stochastic Sampling",{"className":"page__taxonomy-item","children":["#","Stochastic Sampling"]}],["$","span","Monte Carlo Dropout",{"className":"page__taxonomy-item","children":["#","Monte Carlo Dropout"]}],["$","span","Additive Gaussian Noise",{"className":"page__taxonomy-item","children":["#","Additive Gaussian Noise"]}],["$","span","Latent Reward Model",{"className":"page__taxonomy-item","children":["#","Latent Reward Model"]}],["$","span","Trajectory Aggregation",{"className":"page__taxonomy-item","children":["#","Trajectory Aggregation"]}]]}]]}]]}],["$","article","2025-10-13-One_Patch_to_Caption_Them_All_A_Unified_Zero-Shot_Captioning_Framework",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-One_Patch_to_Caption_Them_All_A_Unified_Zero-Shot_Captioning_Framework/","children":"[논문리뷰] One Patch to Caption Them All: A Unified Zero-Shot Captioning Framework"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Giuseppe Amato이 [arXiv]에 게시한 'One Patch to Caption Them All: A Unified Zero-Shot Captioning Framework' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Zero-Shot Captioning",{"className":"page__taxonomy-item","children":["#","Zero-Shot Captioning"]}],["$","span","Region-Level Captioning",{"className":"page__taxonomy-item","children":["#","Region-Level Captioning"]}],["$","span","Vision Transformers",{"className":"page__taxonomy-item","children":["#","Vision Transformers"]}],["$","span","DINOv2",{"className":"page__taxonomy-item","children":["#","DINOv2"]}],["$","span","Patch-Centric",{"className":"page__taxonomy-item","children":["#","Patch-Centric"]}],["$","span","Modality Gap Mitigation",{"className":"page__taxonomy-item","children":["#","Modality Gap Mitigation"]}],["$","span","Visual-Language Models",{"className":"page__taxonomy-item","children":["#","Visual-Language Models"]}]]}]]}]]}],["$","article","2025-10-13-Multimodal_Prompt_Optimization_Why_Not_Leverage_Multiple_Modalities_for_MLLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Multimodal_Prompt_Optimization_Why_Not_Leverage_Multiple_Modalities_for_MLLMs/","children":"[논문리뷰] Multimodal Prompt Optimization: Why Not Leverage Multiple Modalities for MLLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Multimodal Prompt Optimization: Why Not Leverage Multiple Modalities for MLLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Prompt Optimization",{"className":"page__taxonomy-item","children":["#","Prompt Optimization"]}],["$","span","MLLMs",{"className":"page__taxonomy-item","children":["#","MLLMs"]}],["$","span","Bayesian Optimization",{"className":"page__taxonomy-item","children":["#","Bayesian Optimization"]}],["$","span","Cross-modal Alignment",{"className":"page__taxonomy-item","children":["#","Cross-modal Alignment"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Exploration-Exploitation",{"className":"page__taxonomy-item","children":["#","Exploration-Exploitation"]}]]}]]}]]}],["$","article","2025-10-13-MRMR_A_Realistic_and_Expert-Level_Multidisciplinary_Benchmark_for_Reasoning-Intensive_Multimodal_Retrieval",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-MRMR_A_Realistic_and_Expert-Level_Multidisciplinary_Benchmark_for_Reasoning-Intensive_Multimodal_Retrieval/","children":"[논문리뷰] MRMR: A Realistic and Expert-Level Multidisciplinary Benchmark for Reasoning-Intensive Multimodal Retrieval"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Tingyu Song이 [arXiv]에 게시한 'MRMR: A Realistic and Expert-Level Multidisciplinary Benchmark for Reasoning-Intensive Multimodal Retrieval' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Retrieval",{"className":"page__taxonomy-item","children":["#","Multimodal Retrieval"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Multidisciplinary",{"className":"page__taxonomy-item","children":["#","Multidisciplinary"]}],["$","span","Expert-Level",{"className":"page__taxonomy-item","children":["#","Expert-Level"]}],["$","span","Image-Text Interleaving",{"className":"page__taxonomy-item","children":["#","Image-Text Interleaving"]}],["$","span","Contradiction Retrieval",{"className":"page__taxonomy-item","children":["#","Contradiction Retrieval"]}]]}]]}]]}],["$","article","2025-10-13-Mitigating_Overthinking_through_Reasoning_Shaping",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Mitigating_Overthinking_through_Reasoning_Shaping/","children":"[논문리뷰] Mitigating Overthinking through Reasoning Shaping"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wen Luo이 [arXiv]에 게시한 'Mitigating Overthinking through Reasoning Shaping' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Reasoning Models (LRMs)",{"className":"page__taxonomy-item","children":["#","Large Reasoning Models (LRMs)"]}],["$","span","RLVR",{"className":"page__taxonomy-item","children":["#","RLVR"]}],["$","span","Overthinking Mitigation",{"className":"page__taxonomy-item","children":["#","Overthinking Mitigation"]}],["$","span","Reasoning Shaping",{"className":"page__taxonomy-item","children":["#","Reasoning Shaping"]}],["$","span","Segment-level Penalization",{"className":"page__taxonomy-item","children":["#","Segment-level Penalization"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}],["$","span","Training Stability",{"className":"page__taxonomy-item","children":["#","Training Stability"]}],["$","span","Length-aware Weighting",{"className":"page__taxonomy-item","children":["#","Length-aware Weighting"]}]]}]]}]]}],["$","article","2025-10-13-KORMo_Korean_Open_Reasoning_Model_for_Everyone",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-KORMo_Korean_Open_Reasoning_Model_for_Everyone/","children":"[논문리뷰] KORMo: Korean Open Reasoning Model for Everyone"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'KORMo: Korean Open Reasoning Model for Everyone' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Model",{"className":"page__taxonomy-item","children":["#","Large Language Model"]}],["$","span","Korean",{"className":"page__taxonomy-item","children":["#","Korean"]}],["$","span","Bilingual",{"className":"page__taxonomy-item","children":["#","Bilingual"]}],["$","span","Synthetic Data",{"className":"page__taxonomy-item","children":["#","Synthetic Data"]}],["$","span","Fully Open Model",{"className":"page__taxonomy-item","children":["#","Fully Open Model"]}],["$","span","Tokenizer",{"className":"page__taxonomy-item","children":["#","Tokenizer"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Pretraining",{"className":"page__taxonomy-item","children":["#","Pretraining"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}]]}]]}]]}],["$","article","2025-10-13-Instant4D_4D_Gaussian_Splatting_in_Minutes",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Instant4D_4D_Gaussian_Splatting_in_Minutes/","children":"[논문리뷰] Instant4D: 4D Gaussian Splatting in Minutes"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Li Lu이 [arXiv]에 게시한 'Instant4D: 4D Gaussian Splatting in Minutes' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","4D Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","4D Gaussian Splatting"]}],["$","span","Dynamic View Synthesis",{"className":"page__taxonomy-item","children":["#","Dynamic View Synthesis"]}],["$","span","Monocular Reconstruction",{"className":"page__taxonomy-item","children":["#","Monocular Reconstruction"]}],["$","span","Visual SLAM",{"className":"page__taxonomy-item","children":["#","Visual SLAM"]}],["$","span","Grid Pruning",{"className":"page__taxonomy-item","children":["#","Grid Pruning"]}],["$","span","Real-time Rendering",{"className":"page__taxonomy-item","children":["#","Real-time Rendering"]}],["$","span","GPU Memory Optimization",{"className":"page__taxonomy-item","children":["#","GPU Memory Optimization"]}]]}]]}]]}],["$","article","2025-10-13-Hybrid-grained_Feature_Aggregation_with_Coarse-to-fine_Language_Guidance_for_Self-supervised_Monocular_Depth_Estimation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Hybrid-grained_Feature_Aggregation_with_Coarse-to-fine_Language_Guidance_for_Self-supervised_Monocular_Depth_Estimation/","children":"[논문리뷰] Hybrid-grained Feature Aggregation with Coarse-to-fine Language Guidance for Self-supervised Monocular Depth Estimation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zekun Qi이 [arXiv]에 게시한 'Hybrid-grained Feature Aggregation with Coarse-to-fine Language Guidance for Self-supervised Monocular Depth Estimation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Self-supervised Monocular Depth Estimation",{"className":"page__taxonomy-item","children":["#","Self-supervised Monocular Depth Estimation"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","CLIP",{"className":"page__taxonomy-item","children":["#","CLIP"]}],["$","span","DINO",{"className":"page__taxonomy-item","children":["#","DINO"]}],["$","span","Language Guidance",{"className":"page__taxonomy-item","children":["#","Language Guidance"]}],["$","span","Coarse-to-fine Learning",{"className":"page__taxonomy-item","children":["#","Coarse-to-fine Learning"]}],["$","span","Feature Aggregation",{"className":"page__taxonomy-item","children":["#","Feature Aggregation"]}],["$","span","3D Perception",{"className":"page__taxonomy-item","children":["#","3D Perception"]}]]}]]}]]}],["$","article","2025-10-13-GTAlign_Game-Theoretic_Alignment_of_LLM_Assistants_for_Mutual_Welfare",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-GTAlign_Game-Theoretic_Alignment_of_LLM_Assistants_for_Mutual_Welfare/","children":"[논문리뷰] GTAlign: Game-Theoretic Alignment of LLM Assistants for Mutual Welfare"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'GTAlign: Game-Theoretic Alignment of LLM Assistants for Mutual Welfare' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","LLM Alignment",{"className":"page__taxonomy-item","children":["#","LLM Alignment"]}],["$","span","Game Theory",{"className":"page__taxonomy-item","children":["#","Game Theory"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Mutual Welfare",{"className":"page__taxonomy-item","children":["#","Mutual Welfare"]}],["$","span","Payoff Matrix",{"className":"page__taxonomy-item","children":["#","Payoff Matrix"]}],["$","span","Strategic Decision Making",{"className":"page__taxonomy-item","children":["#","Strategic Decision Making"]}],["$","span","Human-AI Interaction",{"className":"page__taxonomy-item","children":["#","Human-AI Interaction"]}]]}]]}]]}],["$","article","2025-10-13-Dyna-Mind_Learning_to_Simulate_from_Experience_for_Better_AI_Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Dyna-Mind_Learning_to_Simulate_from_Experience_for_Better_AI_Agents/","children":"[논문리뷰] Dyna-Mind: Learning to Simulate from Experience for Better AI Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Qianhui Wu이 [arXiv]에 게시한 'Dyna-Mind: Learning to Simulate from Experience for Better AI Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Agents",{"className":"page__taxonomy-item","children":["#","AI Agents"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","World Models",{"className":"page__taxonomy-item","children":["#","World Models"]}],["$","span","Simulation",{"className":"page__taxonomy-item","children":["#","Simulation"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Language Models",{"className":"page__taxonomy-item","children":["#","Language Models"]}],["$","span","Planning",{"className":"page__taxonomy-item","children":["#","Planning"]}],["$","span","Interactive AI",{"className":"page__taxonomy-item","children":["#","Interactive AI"]}]]}]]}]]}],["$","article","2025-10-13-Dont_Waste_Mistakes_Leveraging_Negative_RL-Groups_via_Confidence_Reweighting",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Dont_Waste_Mistakes_Leveraging_Negative_RL-Groups_via_Confidence_Reweighting/","children":"[논문리뷰] Don't Waste Mistakes: Leveraging Negative RL-Groups via Confidence Reweighting"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Julia Kempe이 [arXiv]에 게시한 'Don't Waste Mistakes: Leveraging Negative RL-Groups via Confidence Reweighting' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reasoning Tasks",{"className":"page__taxonomy-item","children":["#","Reasoning Tasks"]}],["$","span","GRPO",{"className":"page__taxonomy-item","children":["#","GRPO"]}],["$","span","Negative Samples",{"className":"page__taxonomy-item","children":["#","Negative Samples"]}],["$","span","Reward Modeling",{"className":"page__taxonomy-item","children":["#","Reward Modeling"]}],["$","span","Confidence Reweighting",{"className":"page__taxonomy-item","children":["#","Confidence Reweighting"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}]]}]]}]]}],["$","article","2025-10-13-DISCO_Diversifying_Sample_Condensation_for_Efficient_Model_Evaluation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-DISCO_Diversifying_Sample_Condensation_for_Efficient_Model_Evaluation/","children":"[논문리뷰] DISCO: Diversifying Sample Condensation for Efficient Model Evaluation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DISCO: Diversifying Sample Condensation for Efficient Model Evaluation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Efficient Evaluation",{"className":"page__taxonomy-item","children":["#","Efficient Evaluation"]}],["$","span","Sample Condensation",{"className":"page__taxonomy-item","children":["#","Sample Condensation"]}],["$","span","Model Disagreement",{"className":"page__taxonomy-item","children":["#","Model Disagreement"]}],["$","span","Predictive Diversity",{"className":"page__taxonomy-item","children":["#","Predictive Diversity"]}],["$","span","Performance Prediction",{"className":"page__taxonomy-item","children":["#","Performance Prediction"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Model Signatures",{"className":"page__taxonomy-item","children":["#","Model Signatures"]}],["$","span","Meta-modeling",{"className":"page__taxonomy-item","children":["#","Meta-modeling"]}]]}]]}]]}],["$","article","2025-10-13-D2E_Scaling_Vision-Action_Pretraining_on_Desktop_Data_for_Transfer_to_Embodied_AI",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-D2E_Scaling_Vision-Action_Pretraining_on_Desktop_Data_for_Transfer_to_Embodied_AI/","children":"[논문리뷰] D2E: Scaling Vision-Action Pretraining on Desktop Data for Transfer to Embodied AI"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Haebin Seong이 [arXiv]에 게시한 'D2E: Scaling Vision-Action Pretraining on Desktop Data for Transfer to Embodied AI' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Vision-Action Pretraining",{"className":"page__taxonomy-item","children":["#","Vision-Action Pretraining"]}],["$","span","Desktop Data",{"className":"page__taxonomy-item","children":["#","Desktop Data"]}],["$","span","Inverse Dynamics Model (IDM)",{"className":"page__taxonomy-item","children":["#","Inverse Dynamics Model (IDM)"]}],["$","span","Pseudo-labeling",{"className":"page__taxonomy-item","children":["#","Pseudo-labeling"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Data Compression",{"className":"page__taxonomy-item","children":["#","Data Compression"]}]]}]]}]]}],["$","article","2025-10-13-Bridging_Reasoning_to_Learning_Unmasking_Illusions_using_Complexity_Out_of_Distribution_Generalization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Bridging_Reasoning_to_Learning_Unmasking_Illusions_using_Complexity_Out_of_Distribution_Generalization/","children":"[논문리뷰] Bridging Reasoning to Learning: Unmasking Illusions using Complexity Out of Distribution Generalization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Mahdi Ghaznavai이 [arXiv]에 게시한 'Bridging Reasoning to Learning: Unmasking Illusions using Complexity Out of Distribution Generalization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Complexity OoD Generalization",{"className":"page__taxonomy-item","children":["#","Complexity OoD Generalization"]}],["$","span","System-1 Thinking",{"className":"page__taxonomy-item","children":["#","System-1 Thinking"]}],["$","span","System-2 Reasoning",{"className":"page__taxonomy-item","children":["#","System-2 Reasoning"]}],["$","span","Kolmogorov Complexity",{"className":"page__taxonomy-item","children":["#","Kolmogorov Complexity"]}],["$","span","Inductive Biases",{"className":"page__taxonomy-item","children":["#","Inductive Biases"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Reasoning Evaluation",{"className":"page__taxonomy-item","children":["#","Reasoning Evaluation"]}]]}]]}]]}],["$","article","2025-10-13-BigCodeArena_Unveiling_More_Reliable_Human_Preferences_in_Code_Generation_via_Execution",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-BigCodeArena_Unveiling_More_Reliable_Human_Preferences_in_Code_Generation_via_Execution/","children":"[논문리뷰] BigCodeArena: Unveiling More Reliable Human Preferences in Code Generation via Execution"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hange Liu이 [arXiv]에 게시한 'BigCodeArena: Unveiling More Reliable Human Preferences in Code Generation via Execution' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","Human Preference",{"className":"page__taxonomy-item","children":["#","Human Preference"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Execution Feedback",{"className":"page__taxonomy-item","children":["#","Execution Feedback"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Crowdsourcing",{"className":"page__taxonomy-item","children":["#","Crowdsourcing"]}],["$","span","Software Engineering",{"className":"page__taxonomy-item","children":["#","Software Engineering"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}]]}]]}]]}],["$","article","2025-10-13-Better_Together_Leveraging_Unpaired_Multimodal_Data_for_Stronger_Unimodal_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Better_Together_Leveraging_Unpaired_Multimodal_Data_for_Stronger_Unimodal_Models/","children":"[논문리뷰] Better Together: Leveraging Unpaired Multimodal Data for Stronger Unimodal Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Better Together: Leveraging Unpaired Multimodal Data for Stronger Unimodal Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Unpaired Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Unpaired Multimodal Learning"]}],["$","span","Unimodal Representation",{"className":"page__taxonomy-item","children":["#","Unimodal Representation"]}],["$","span","Weight Sharing",{"className":"page__taxonomy-item","children":["#","Weight Sharing"]}],["$","span","Cross-modal Transfer",{"className":"page__taxonomy-item","children":["#","Cross-modal Transfer"]}],["$","span","Fisher Information",{"className":"page__taxonomy-item","children":["#","Fisher Information"]}],["$","span","Self-supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-supervised Learning"]}],["$","span","Multimodal Neurons",{"className":"page__taxonomy-item","children":["#","Multimodal Neurons"]}],["$","span","Data Efficiency",{"className":"page__taxonomy-item","children":["#","Data Efficiency"]}]]}]]}]]}],["$","article","2025-10-13-A_Goal_Without_a_Plan_Is_Just_a_Wish_Efficient_and_Effective_Global_Planner_Training_for_Long-Horizon_Agent_Tasks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-A_Goal_Without_a_Plan_Is_Just_a_Wish_Efficient_and_Effective_Global_Planner_Training_for_Long-Horizon_Agent_Tasks/","children":"[논문리뷰] A Goal Without a Plan Is Just a Wish: Efficient and Effective Global Planner Training for Long-Horizon Agent Tasks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Fanchao Qi이 [arXiv]에 게시한 'A Goal Without a Plan Is Just a Wish: Efficient and Effective Global Planner Training for Long-Horizon Agent Tasks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Long-Horizon Tasks",{"className":"page__taxonomy-item","children":["#","Long-Horizon Tasks"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Global Planning",{"className":"page__taxonomy-item","children":["#","Global Planning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Homologous Consensus Filtering",{"className":"page__taxonomy-item","children":["#","Homologous Consensus Filtering"]}],["$","span","Executor Capability Gain Reward",{"className":"page__taxonomy-item","children":["#","Executor Capability Gain Reward"]}],["$","span","Plan-and-Execute",{"className":"page__taxonomy-item","children":["#","Plan-and-Execute"]}]]}]]}]]}],["$","article","2025-10-13-AutoPR_Lets_Automate_Your_Academic_Promotion",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-AutoPR_Lets_Automate_Your_Academic_Promotion/","children":"[논문리뷰] AutoPR: Let's Automate Your Academic Promotion!"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yixin Yuan이 [arXiv]에 게시한 'AutoPR: Let's Automate Your Academic Promotion!' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Academic Promotion",{"className":"page__taxonomy-item","children":["#","Academic Promotion"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Scholarly Communication",{"className":"page__taxonomy-item","children":["#","Scholarly Communication"]}],["$","span","Multimodal Processing",{"className":"page__taxonomy-item","children":["#","Multimodal Processing"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Content Generation",{"className":"page__taxonomy-item","children":["#","Content Generation"]}],["$","span","Social Media Marketing",{"className":"page__taxonomy-item","children":["#","Social Media Marketing"]}]]}]]}]]}],["$","article","2025-10-13-ARES_Multimodal_Adaptive_Reasoning_via_Difficulty-Aware_Token-Level_Entropy_Shaping",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-ARES_Multimodal_Adaptive_Reasoning_via_Difficulty-Aware_Token-Level_Entropy_Shaping/","children":"[논문리뷰] ARES: Multimodal Adaptive Reasoning via Difficulty-Aware Token-Level Entropy Shaping"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wenbo Hu이 [arXiv]에 게시한 'ARES: Multimodal Adaptive Reasoning via Difficulty-Aware Token-Level Entropy Shaping' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","span","Adaptive Learning",{"className":"page__taxonomy-item","children":["#","Adaptive Learning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Entropy Shaping",{"className":"page__taxonomy-item","children":["#","Entropy Shaping"]}],["$","span","Difficulty-Aware",{"className":"page__taxonomy-item","children":["#","Difficulty-Aware"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Token-Level Analysis",{"className":"page__taxonomy-item","children":["#","Token-Level Analysis"]}]]}]]}]]}],["$","article","2025-10-13-Adaptive_Attacks_on_Trusted_Monitors_Subvert_AI_Control_Protocols",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-Adaptive_Attacks_on_Trusted_Monitors_Subvert_AI_Control_Protocols/","children":"[논문리뷰] Adaptive Attacks on Trusted Monitors Subvert AI Control Protocols"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Maksym Andriushchenko이 [arXiv]에 게시한 'Adaptive Attacks on Trusted Monitors Subvert AI Control Protocols' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Control Protocols",{"className":"page__taxonomy-item","children":["#","AI Control Protocols"]}],["$","span","LLM Monitors",{"className":"page__taxonomy-item","children":["#","LLM Monitors"]}],["$","span","Adaptive Attacks",{"className":"page__taxonomy-item","children":["#","Adaptive Attacks"]}],["$","span","Prompt Injection",{"className":"page__taxonomy-item","children":["#","Prompt Injection"]}],["$","span","Jailbreaking",{"className":"page__taxonomy-item","children":["#","Jailbreaking"]}],["$","span","Red Teaming",{"className":"page__taxonomy-item","children":["#","Red Teaming"]}],["$","span","Scalable Oversight",{"className":"page__taxonomy-item","children":["#","Scalable Oversight"]}]]}]]}]]}],["$","article","2025-10-13-ACE_Attribution-Controlled_Knowledge_Editing_for_Multi-hop_Factual_Recall",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-13-ACE_Attribution-Controlled_Knowledge_Editing_for_Multi-hop_Factual_Recall/","children":"[논문리뷰] ACE: Attribution-Controlled Knowledge Editing for Multi-hop Factual Recall"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiaqi Tang이 [arXiv]에 게시한 'ACE: Attribution-Controlled Knowledge Editing for Multi-hop Factual Recall' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-13 13:44:18+0900","children":"2025년 10월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Knowledge Editing",{"className":"page__taxonomy-item","children":["#","Knowledge Editing"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Multi-hop Reasoning",{"className":"page__taxonomy-item","children":["#","Multi-hop Reasoning"]}],["$","span","Mechanistic Interpretability",{"className":"page__taxonomy-item","children":["#","Mechanistic Interpretability"]}],["$","span","Neuron-level Attribution",{"className":"page__taxonomy-item","children":["#","Neuron-level Attribution"]}],["$","span","Factual Recall",{"className":"page__taxonomy-item","children":["#","Factual Recall"]}],["$","span","Transformer Networks",{"className":"page__taxonomy-item","children":["#","Transformer Networks"]}]]}]]}]]}],["$","article","2025-10-10-When_Thoughts_Meet_Facts_Reusable_Reasoning_for_Long-Context_LMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-When_Thoughts_Meet_Facts_Reusable_Reasoning_for_Long-Context_LMs/","children":"[논문리뷰] When Thoughts Meet Facts: Reusable Reasoning for Long-Context LMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'When Thoughts Meet Facts: Reusable Reasoning for Long-Context LMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Long-Context LMs",{"className":"page__taxonomy-item","children":["#","Long-Context LMs"]}],["$","span","Multi-hop Reasoning",{"className":"page__taxonomy-item","children":["#","Multi-hop Reasoning"]}],["$","span","Thought Templates",{"className":"page__taxonomy-item","children":["#","Thought Templates"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","Natural Language Feedback",{"className":"page__taxonomy-item","children":["#","Natural Language Feedback"]}],["$","span","Knowledge-intensive QA",{"className":"page__taxonomy-item","children":["#","Knowledge-intensive QA"]}],["$","span","Reasoning Reuse",{"className":"page__taxonomy-item","children":["#","Reasoning Reuse"]}]]}]]}]]}],["$","article","2025-10-10-VideoCanvas_Unified_Video_Completion_from_Arbitrary_Spatiotemporal_Patches_via_In-Context_Conditioning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-VideoCanvas_Unified_Video_Completion_from_Arbitrary_Spatiotemporal_Patches_via_In-Context_Conditioning/","children":"[논문리뷰] VideoCanvas: Unified Video Completion from Arbitrary Spatiotemporal Patches via In-Context Conditioning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Quande Liu이 [arXiv]에 게시한 'VideoCanvas: Unified Video Completion from Arbitrary Spatiotemporal Patches via In-Context Conditioning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Completion",{"className":"page__taxonomy-item","children":["#","Video Completion"]}],["$","span","Spatio-Temporal Control",{"className":"page__taxonomy-item","children":["#","Spatio-Temporal Control"]}],["$","span","In-Context Conditioning",{"className":"page__taxonomy-item","children":["#","In-Context Conditioning"]}],["$","span","Video Diffusion Models",{"className":"page__taxonomy-item","children":["#","Video Diffusion Models"]}],["$","span","RoPE Interpolation",{"className":"page__taxonomy-item","children":["#","RoPE Interpolation"]}],["$","span","VAE",{"className":"page__taxonomy-item","children":["#","VAE"]}],["$","span","Unified Framework",{"className":"page__taxonomy-item","children":["#","Unified Framework"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}]]}]]}]]}],["$","article","2025-10-10-UP2You_Fast_Reconstruction_of_Yourself_from_Unconstrained_Photo_Collections",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-UP2You_Fast_Reconstruction_of_Yourself_from_Unconstrained_Photo_Collections/","children":"[논문리뷰] UP2You: Fast Reconstruction of Yourself from Unconstrained Photo Collections"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Boqian Li이 [arXiv]에 게시한 'UP2You: Fast Reconstruction of Yourself from Unconstrained Photo Collections' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Human Reconstruction",{"className":"page__taxonomy-item","children":["#","3D Human Reconstruction"]}],["$","span","Unconstrained Photos",{"className":"page__taxonomy-item","children":["#","Unconstrained Photos"]}],["$","span","Data Rectifier",{"className":"page__taxonomy-item","children":["#","Data Rectifier"]}],["$","span","Multi-View Generation",{"className":"page__taxonomy-item","children":["#","Multi-View Generation"]}],["$","span","Pose-Correlated Feature Aggregation",{"className":"page__taxonomy-item","children":["#","Pose-Correlated Feature Aggregation"]}],["$","span","SMPL-X",{"className":"page__taxonomy-item","children":["#","SMPL-X"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Virtual Try-On",{"className":"page__taxonomy-item","children":["#","Virtual Try-On"]}]]}]]}]]}],["$","article","2025-10-10-UniVideo_Unified_Understanding_Generation_and_Editing_for_Videos",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-UniVideo_Unified_Understanding_Generation_and_Editing_for_Videos/","children":"[논문리뷰] UniVideo: Unified Understanding, Generation, and Editing for Videos"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xintao Wang이 [arXiv]에 게시한 'UniVideo: Unified Understanding, Generation, and Editing for Videos' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Unified Multimodal Model",{"className":"page__taxonomy-item","children":["#","Unified Multimodal Model"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Video Editing",{"className":"page__taxonomy-item","children":["#","Video Editing"]}],["$","span","MLLM",{"className":"page__taxonomy-item","children":["#","MLLM"]}],["$","span","Diffusion Transformer",{"className":"page__taxonomy-item","children":["#","Diffusion Transformer"]}],["$","span","In-Context Learning",{"className":"page__taxonomy-item","children":["#","In-Context Learning"]}],["$","span","Zero-shot Generalization",{"className":"page__taxonomy-item","children":["#","Zero-shot Generalization"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}]]}]]}]]}],["$","article","2025-10-10-UniMMVSR_A_Unified_Multi-Modal_Framework_for_Cascaded_Video_Super-Resolution",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-UniMMVSR_A_Unified_Multi-Modal_Framework_for_Cascaded_Video_Super-Resolution/","children":"[논문리뷰] UniMMVSR: A Unified Multi-Modal Framework for Cascaded Video Super-Resolution"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'UniMMVSR: A Unified Multi-Modal Framework for Cascaded Video Super-Resolution' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Super-Resolution",{"className":"page__taxonomy-item","children":["#","Video Super-Resolution"]}],["$","span","Multi-Modal Generation",{"className":"page__taxonomy-item","children":["#","Multi-Modal Generation"]}],["$","span","Latent Diffusion Models",{"className":"page__taxonomy-item","children":["#","Latent Diffusion Models"]}],["$","span","Cascaded Framework",{"className":"page__taxonomy-item","children":["#","Cascaded Framework"]}],["$","span","Condition Injection",{"className":"page__taxonomy-item","children":["#","Condition Injection"]}],["$","span","Text-to-Video",{"className":"page__taxonomy-item","children":["#","Text-to-Video"]}],["$","span","Video Editing",{"className":"page__taxonomy-item","children":["#","Video Editing"]}],["$","span","4K Video",{"className":"page__taxonomy-item","children":["#","4K Video"]}]]}]]}]]}],["$","article","2025-10-10-UNIDOC-BENCH_A_Unified_Benchmark_for_Document-Centric_Multimodal_RAG",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-UNIDOC-BENCH_A_Unified_Benchmark_for_Document-Centric_Multimodal_RAG/","children":"[논문리뷰] UNIDOC-BENCH: A Unified Benchmark for Document-Centric Multimodal RAG"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'UNIDOC-BENCH: A Unified Benchmark for Document-Centric Multimodal RAG' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal RAG",{"className":"page__taxonomy-item","children":["#","Multimodal RAG"]}],["$","span","Document AI",{"className":"page__taxonomy-item","children":["#","Document AI"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Information Retrieval",{"className":"page__taxonomy-item","children":["#","Information Retrieval"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Multimodal Embeddings",{"className":"page__taxonomy-item","children":["#","Multimodal Embeddings"]}],["$","span","PDF Processing",{"className":"page__taxonomy-item","children":["#","PDF Processing"]}],["$","span","Question Answering",{"className":"page__taxonomy-item","children":["#","Question Answering"]}]]}]]}]]}],["$","article","2025-10-10-Training-Free_Group_Relative_Policy_Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Training-Free_Group_Relative_Policy_Optimization/","children":"[논문리뷰] Training-Free Group Relative Policy Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Training-Free Group Relative Policy Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Parameter-Free Optimization",{"className":"page__taxonomy-item","children":["#","Parameter-Free Optimization"]}],["$","span","Experiential Knowledge",{"className":"page__taxonomy-item","children":["#","Experiential Knowledge"]}],["$","span","Token Prior",{"className":"page__taxonomy-item","children":["#","Token Prior"]}],["$","span","Group Relative Policy Optimization",{"className":"page__taxonomy-item","children":["#","Group Relative Policy Optimization"]}],["$","span","In-Context Learning",{"className":"page__taxonomy-item","children":["#","In-Context Learning"]}],["$","span","Cost-Effective AI",{"className":"page__taxonomy-item","children":["#","Cost-Effective AI"]}]]}]]}]]}],["$","article","2025-10-10-Towards_Scalable_and_Consistent_3D_Editing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Towards_Scalable_and_Consistent_3D_Editing/","children":"[논문리뷰] Towards Scalable and Consistent 3D Editing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Pan Zhou이 [arXiv]에 게시한 'Towards Scalable and Consistent 3D Editing' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Editing",{"className":"page__taxonomy-item","children":["#","3D Editing"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Dataset Generation",{"className":"page__taxonomy-item","children":["#","Dataset Generation"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Conditional Generation",{"className":"page__taxonomy-item","children":["#","Conditional Generation"]}],["$","span","Image-to-3D",{"className":"page__taxonomy-item","children":["#","Image-to-3D"]}]]}]]}]]}],["$","article","2025-10-10-The_Alignment_Waltz_Jointly_Training_Agents_to_Collaborate_for_Safety",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-The_Alignment_Waltz_Jointly_Training_Agents_to_Collaborate_for_Safety/","children":"[논문리뷰] The Alignment Waltz: Jointly Training Agents to Collaborate for Safety"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'The Alignment Waltz: Jointly Training Agents to Collaborate for Safety' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Safety",{"className":"page__taxonomy-item","children":["#","LLM Safety"]}],["$","span","Multi-agent Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Multi-agent Reinforcement Learning"]}],["$","span","Safety Alignment",{"className":"page__taxonomy-item","children":["#","Safety Alignment"]}],["$","span","Overrefusal",{"className":"page__taxonomy-item","children":["#","Overrefusal"]}],["$","span","Adversarial Attacks",{"className":"page__taxonomy-item","children":["#","Adversarial Attacks"]}],["$","span","Feedback Agent",{"className":"page__taxonomy-item","children":["#","Feedback Agent"]}],["$","span","Conversation Agent",{"className":"page__taxonomy-item","children":["#","Conversation Agent"]}],["$","span","Dynamic Improvement Reward",{"className":"page__taxonomy-item","children":["#","Dynamic Improvement Reward"]}]]}]]}]]}],["$","article","2025-10-10-Taming_Text-to-Sounding_Video_Generation_via_Advanced_Modality_Condition_and_Interaction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Taming_Text-to-Sounding_Video_Generation_via_Advanced_Modality_Condition_and_Interaction/","children":"[논문리뷰] Taming Text-to-Sounding Video Generation via Advanced Modality Condition and Interaction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Taming Text-to-Sounding Video Generation via Advanced Modality Condition and Interaction' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Sounding Video Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Sounding Video Generation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Dual-tower Architecture",{"className":"page__taxonomy-item","children":["#","Dual-tower Architecture"]}],["$","span","Cross-modal Fusion",{"className":"page__taxonomy-item","children":["#","Cross-modal Fusion"]}],["$","span","Visual Grounding",{"className":"page__taxonomy-item","children":["#","Visual Grounding"]}],["$","span","Hierarchical Captioning",{"className":"page__taxonomy-item","children":["#","Hierarchical Captioning"]}],["$","span","Cross-Attention",{"className":"page__taxonomy-item","children":["#","Cross-Attention"]}]]}]]}]]}],["$","article","2025-10-10-SViM3D_Stable_Video_Material_Diffusion_for_Single_Image_3D_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-SViM3D_Stable_Video_Material_Diffusion_for_Single_Image_3D_Generation/","children":"[논문리뷰] SViM3D: Stable Video Material Diffusion for Single Image 3D Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'SViM3D: Stable Video Material Diffusion for Single Image 3D Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Single Image 3D Reconstruction",{"className":"page__taxonomy-item","children":["#","Single Image 3D Reconstruction"]}],["$","span","Material Prediction",{"className":"page__taxonomy-item","children":["#","Material Prediction"]}],["$","span","Video Diffusion Models",{"className":"page__taxonomy-item","children":["#","Video Diffusion Models"]}],["$","span","Physically Based Rendering (PBR)",{"className":"page__taxonomy-item","children":["#","Physically Based Rendering (PBR)"]}],["$","span","Inverse Rendering",{"className":"page__taxonomy-item","children":["#","Inverse Rendering"]}],["$","span","Novel View Synthesis",{"className":"page__taxonomy-item","children":["#","Novel View Synthesis"]}],["$","span","Camera Control",{"className":"page__taxonomy-item","children":["#","Camera Control"]}],["$","span","Latent Diffusion",{"className":"page__taxonomy-item","children":["#","Latent Diffusion"]}]]}]]}]]}],["$","article","2025-10-10-Search-R3_Unifying_Reasoning_and_Embedding_Generation_in_Large_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Search-R3_Unifying_Reasoning_and_Embedding_Generation_in_Large_Language_Models/","children":"[논문리뷰] Search-R3: Unifying Reasoning and Embedding Generation in Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"James Cheng이 [arXiv]에 게시한 'Search-R3: Unifying Reasoning and Embedding Generation in Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Sentence Embedding",{"className":"page__taxonomy-item","children":["#","Sentence Embedding"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Information Retrieval",{"className":"page__taxonomy-item","children":["#","Information Retrieval"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}]]}]]}]]}],["$","article","2025-10-10-SciVideoBench_Benchmarking_Scientific_Video_Reasoning_in_Large_Multimodal_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-SciVideoBench_Benchmarking_Scientific_Video_Reasoning_in_Large_Multimodal_Models/","children":"[논문리뷰] SciVideoBench: Benchmarking Scientific Video Reasoning in Large Multimodal Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Mohit Bansal이 [arXiv]에 게시한 'SciVideoBench: Benchmarking Scientific Video Reasoning in Large Multimodal Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Reasoning",{"className":"page__taxonomy-item","children":["#","Video Reasoning"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Scientific Research",{"className":"page__taxonomy-item","children":["#","Scientific Research"]}],["$","span","Large Multimodal Models",{"className":"page__taxonomy-item","children":["#","Large Multimodal Models"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Quantitative Reasoning",{"className":"page__taxonomy-item","children":["#","Quantitative Reasoning"]}],["$","span","Domain Knowledge",{"className":"page__taxonomy-item","children":["#","Domain Knowledge"]}],["$","span","Visual Grounding",{"className":"page__taxonomy-item","children":["#","Visual Grounding"]}]]}]]}]]}],["$","article","2025-10-10-Reinforcing_Diffusion_Models_by_Direct_Group_Preference_Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Reinforcing_Diffusion_Models_by_Direct_Group_Preference_Optimization/","children":"[논문리뷰] Reinforcing Diffusion Models by Direct Group Preference Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jing Tang이 [arXiv]에 게시한 'Reinforcing Diffusion Models by Direct Group Preference Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Preference Optimization",{"className":"page__taxonomy-item","children":["#","Preference Optimization"]}],["$","span","Group Preference",{"className":"page__taxonomy-item","children":["#","Group Preference"]}],["$","span","Direct Preference Optimization",{"className":"page__taxonomy-item","children":["#","Direct Preference Optimization"]}],["$","span","ODE Samplers",{"className":"page__taxonomy-item","children":["#","ODE Samplers"]}],["$","span","Efficient Training",{"className":"page__taxonomy-item","children":["#","Efficient Training"]}]]}]]}]]}],["$","article","2025-10-10-Recycling_Pretrained_Checkpoints_Orthogonal_Growth_of_Mixture-of-Experts_for_Efficient_Large_Language_Model_Pre-Training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Recycling_Pretrained_Checkpoints_Orthogonal_Growth_of_Mixture-of-Experts_for_Efficient_Large_Language_Model_Pre-Training/","children":"[논문리뷰] Recycling Pretrained Checkpoints: Orthogonal Growth of Mixture-of-Experts for Efficient Large Language Model Pre-Training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Peng Cheng이 [arXiv]에 게시한 'Recycling Pretrained Checkpoints: Orthogonal Growth of Mixture-of-Experts for Efficient Large Language Model Pre-Training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Mixture-of-Experts",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Checkpoint Recycling",{"className":"page__taxonomy-item","children":["#","Checkpoint Recycling"]}],["$","span","Model Growth",{"className":"page__taxonomy-item","children":["#","Model Growth"]}],["$","span","Efficient Pretraining",{"className":"page__taxonomy-item","children":["#","Efficient Pretraining"]}],["$","span","Depth Growth",{"className":"page__taxonomy-item","children":["#","Depth Growth"]}],["$","span","Width Growth",{"className":"page__taxonomy-item","children":["#","Width Growth"]}],["$","span","Sunk Cost",{"className":"page__taxonomy-item","children":["#","Sunk Cost"]}]]}]]}]]}],["$","article","2025-10-10-R2RGEN_Real-to-Real_3D_Data_Generation_for_Spatially_Generalized_Manipulation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-R2RGEN_Real-to-Real_3D_Data_Generation_for_Spatially_Generalized_Manipulation/","children":"[논문리뷰] R2RGEN: Real-to-Real 3D Data Generation for Spatially Generalized Manipulation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zheng Zhu이 [arXiv]에 게시한 'R2RGEN: Real-to-Real 3D Data Generation for Spatially Generalized Manipulation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Robotic Manipulation",{"className":"page__taxonomy-item","children":["#","Robotic Manipulation"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}],["$","span","Spatial Generalization",{"className":"page__taxonomy-item","children":["#","Spatial Generalization"]}],["$","span","3D Data Generation",{"className":"page__taxonomy-item","children":["#","3D Data Generation"]}],["$","span","Imitation Learning",{"className":"page__taxonomy-item","children":["#","Imitation Learning"]}],["$","span","Point Cloud",{"className":"page__taxonomy-item","children":["#","Point Cloud"]}],["$","span","Real-to-Real",{"className":"page__taxonomy-item","children":["#","Real-to-Real"]}],["$","span","Mobile Manipulation",{"className":"page__taxonomy-item","children":["#","Mobile Manipulation"]}]]}]]}]]}],["$","article","2025-10-10-NewtonBench_Benchmarking_Generalizable_Scientific_Law_Discovery_in_LLM_Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-NewtonBench_Benchmarking_Generalizable_Scientific_Law_Discovery_in_LLM_Agents/","children":"[논문리뷰] NewtonBench: Benchmarking Generalizable Scientific Law Discovery in LLM Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Baixuan Xu이 [arXiv]에 게시한 'NewtonBench: Benchmarking Generalizable Scientific Law Discovery in LLM Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Scientific Law Discovery",{"className":"page__taxonomy-item","children":["#","Scientific Law Discovery"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Metaphysical Shifts",{"className":"page__taxonomy-item","children":["#","Metaphysical Shifts"]}],["$","span","Interactive Environments",{"className":"page__taxonomy-item","children":["#","Interactive Environments"]}],["$","span","Exploration-Exploitation",{"className":"page__taxonomy-item","children":["#","Exploration-Exploitation"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}]]}]]}]]}],["$","article","2025-10-10-NaViL_Rethinking_Scaling_Properties_of_Native_Multimodal_Large_Language_Models_under_Data_Constraints",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-NaViL_Rethinking_Scaling_Properties_of_Native_Multimodal_Large_Language_Models_under_Data_Constraints/","children":"[논문리뷰] NaViL: Rethinking Scaling Properties of Native Multimodal Large Language Models under Data Constraints"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'NaViL: Rethinking Scaling Properties of Native Multimodal Large Language Models under Data Constraints' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models"]}],["$","span","Native MLLMs",{"className":"page__taxonomy-item","children":["#","Native MLLMs"]}],["$","span","Scaling Laws",{"className":"page__taxonomy-item","children":["#","Scaling Laws"]}],["$","span","Data Constraints",{"className":"page__taxonomy-item","children":["#","Data Constraints"]}],["$","span","Visual Encoder",{"className":"page__taxonomy-item","children":["#","Visual Encoder"]}],["$","span","LLM Initialization",{"className":"page__taxonomy-item","children":["#","LLM Initialization"]}],["$","span","Mixture-of-Experts",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts"]}],["$","span","End-to-end Training",{"className":"page__taxonomy-item","children":["#","End-to-end Training"]}]]}]]}]]}],["$","article","2025-10-10-MM-HELIX_Boosting_Multimodal_Long-Chain_Reflective_Reasoning_with_Holistic_Platform_and_Adaptive_Hybrid_Policy_Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-MM-HELIX_Boosting_Multimodal_Long-Chain_Reflective_Reasoning_with_Holistic_Platform_and_Adaptive_Hybrid_Policy_Optimization/","children":"[논문리뷰] MM-HELIX: Boosting Multimodal Long-Chain Reflective Reasoning with Holistic Platform and Adaptive Hybrid Policy Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"vanilla1116이 [arXiv]에 게시한 'MM-HELIX: Boosting Multimodal Long-Chain Reflective Reasoning with Holistic Platform and Adaptive Hybrid Policy Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Reflective Reasoning",{"className":"page__taxonomy-item","children":["#","Reflective Reasoning"]}],["$","span","Long-Chain Reasoning",{"className":"page__taxonomy-item","children":["#","Long-Chain Reasoning"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Data Generation",{"className":"page__taxonomy-item","children":["#","Data Generation"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Backtracking",{"className":"page__taxonomy-item","children":["#","Backtracking"]}]]}]]}]]}],["$","article","2025-10-10-Meta-Awareness_Enhances_Reasoning_Models_Self-Alignment_Reinforcement_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Meta-Awareness_Enhances_Reasoning_Models_Self-Alignment_Reinforcement_Learning/","children":"[논문리뷰] Meta-Awareness Enhances Reasoning Models: Self-Alignment Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Meta-Awareness Enhances Reasoning Models: Self-Alignment Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Meta-Awareness",{"className":"page__taxonomy-item","children":["#","Meta-Awareness"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Self-Alignment",{"className":"page__taxonomy-item","children":["#","Self-Alignment"]}],["$","span","LLM Reasoning",{"className":"page__taxonomy-item","children":["#","LLM Reasoning"]}],["$","span","Training Efficiency",{"className":"page__taxonomy-item","children":["#","Training Efficiency"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Predictive Gating",{"className":"page__taxonomy-item","children":["#","Predictive Gating"]}]]}]]}]]}],["$","article","2025-10-10-Memory_Retrieval_and_Consolidation_in_Large_Language_Models_through_Function_Tokens",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Memory_Retrieval_and_Consolidation_in_Large_Language_Models_through_Function_Tokens/","children":"[논문리뷰] Memory Retrieval and Consolidation in Large Language Models through Function Tokens"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Memory Retrieval and Consolidation in Large Language Models through Function Tokens' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","LLM Interpretability",{"className":"page__taxonomy-item","children":["#","LLM Interpretability"]}],["$","span","Function Tokens",{"className":"page__taxonomy-item","children":["#","Function Tokens"]}],["$","span","Memory Retrieval",{"className":"page__taxonomy-item","children":["#","Memory Retrieval"]}],["$","span","Memory Consolidation",{"className":"page__taxonomy-item","children":["#","Memory Consolidation"]}],["$","span","Sparse Autoencoders",{"className":"page__taxonomy-item","children":["#","Sparse Autoencoders"]}],["$","span","Pre-training",{"className":"page__taxonomy-item","children":["#","Pre-training"]}]]}]]}]]}],["$","article","2025-10-10-MemMamba_Rethinking_Memory_Patterns_in_State_Space_Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-MemMamba_Rethinking_Memory_Patterns_in_State_Space_Model/","children":"[논문리뷰] MemMamba: Rethinking Memory Patterns in State Space Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiao Sun이 [arXiv]에 게시한 'MemMamba: Rethinking Memory Patterns in State Space Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","State Space Models",{"className":"page__taxonomy-item","children":["#","State Space Models"]}],["$","span","Mamba",{"className":"page__taxonomy-item","children":["#","Mamba"]}],["$","span","Long-sequence modeling",{"className":"page__taxonomy-item","children":["#","Long-sequence modeling"]}],["$","span","Memory decay",{"className":"page__taxonomy-item","children":["#","Memory decay"]}],["$","span","State summarization",{"className":"page__taxonomy-item","children":["#","State summarization"]}],["$","span","Cross-layer attention",{"className":"page__taxonomy-item","children":["#","Cross-layer attention"]}],["$","span","Perplexity",{"className":"page__taxonomy-item","children":["#","Perplexity"]}],["$","span","Linear complexity",{"className":"page__taxonomy-item","children":["#","Linear complexity"]}]]}]]}]]}],["$","article","2025-10-10-Low-probability_Tokens_Sustain_Exploration_in_Reinforcement_Learning_with_Verifiable_Reward",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Low-probability_Tokens_Sustain_Exploration_in_Reinforcement_Learning_with_Verifiable_Reward/","children":"[논문리뷰] Low-probability Tokens Sustain Exploration in Reinforcement Learning with Verifiable Reward"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Low-probability Tokens Sustain Exploration in Reinforcement Learning with Verifiable Reward' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","LLM Exploration",{"className":"page__taxonomy-item","children":["#","LLM Exploration"]}],["$","span","Verifiable Reward",{"className":"page__taxonomy-item","children":["#","Verifiable Reward"]}],["$","span","Low-Probability Regularization",{"className":"page__taxonomy-item","children":["#","Low-Probability Regularization"]}],["$","span","Reasoning Sparks",{"className":"page__taxonomy-item","children":["#","Reasoning Sparks"]}],["$","span","Policy Entropy",{"className":"page__taxonomy-item","children":["#","Policy Entropy"]}],["$","span","KL Divergence",{"className":"page__taxonomy-item","children":["#","KL Divergence"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}]]}]]}]]}],["$","article","2025-10-10-LongRM_Revealing_and_Unlocking_the_Context_Boundary_of_Reward_Modeling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-LongRM_Revealing_and_Unlocking_the_Context_Boundary_of_Reward_Modeling/","children":"[논문리뷰] LongRM: Revealing and Unlocking the Context Boundary of Reward Modeling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'LongRM: Revealing and Unlocking the Context Boundary of Reward Modeling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reward Model",{"className":"page__taxonomy-item","children":["#","Reward Model"]}],["$","span","Long Context",{"className":"page__taxonomy-item","children":["#","Long Context"]}],["$","span","LLM Alignment",{"className":"page__taxonomy-item","children":["#","LLM Alignment"]}],["$","span","Multi-stage Training",{"className":"page__taxonomy-item","children":["#","Multi-stage Training"]}],["$","span","Context Window Scaling",{"className":"page__taxonomy-item","children":["#","Context Window Scaling"]}],["$","span","Preference Learning",{"className":"page__taxonomy-item","children":["#","Preference Learning"]}],["$","span","Long-RewardBench",{"className":"page__taxonomy-item","children":["#","Long-RewardBench"]}]]}]]}]]}],["$","article","2025-10-10-LLMs_Learn_to_Deceive_Unintentionally_Emergent_Misalignment_in_Dishonesty_from_Misaligned_Samples_to_Biased_Human-AI_Interactions",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-LLMs_Learn_to_Deceive_Unintentionally_Emergent_Misalignment_in_Dishonesty_from_Misaligned_Samples_to_Biased_Human-AI_Interactions/","children":"[논문리뷰] LLMs Learn to Deceive Unintentionally: Emergent Misalignment in Dishonesty from Misaligned Samples to Biased Human-AI Interactions"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'LLMs Learn to Deceive Unintentionally: Emergent Misalignment in Dishonesty from Misaligned Samples to Biased Human-AI Interactions' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Misalignment",{"className":"page__taxonomy-item","children":["#","LLM Misalignment"]}],["$","span","Dishonesty",{"className":"page__taxonomy-item","children":["#","Dishonesty"]}],["$","span","Deception",{"className":"page__taxonomy-item","children":["#","Deception"]}],["$","span","Finetuning",{"className":"page__taxonomy-item","children":["#","Finetuning"]}],["$","span","Human-AI Interaction",{"className":"page__taxonomy-item","children":["#","Human-AI Interaction"]}],["$","span","Biased Feedback",{"className":"page__taxonomy-item","children":["#","Biased Feedback"]}],["$","span","Emergent Behavior",{"className":"page__taxonomy-item","children":["#","Emergent Behavior"]}]]}]]}]]}],["$","article","2025-10-10-Learning_to_Route_LLMs_from_Bandit_Feedback_One_Policy_Many_Trade-offs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Learning_to_Route_LLMs_from_Bandit_Feedback_One_Policy_Many_Trade-offs/","children":"[논문리뷰] Learning to Route LLMs from Bandit Feedback: One Policy, Many Trade-offs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Franck Dernoncourt이 [arXiv]에 게시한 'Learning to Route LLMs from Bandit Feedback: One Policy, Many Trade-offs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Routing",{"className":"page__taxonomy-item","children":["#","LLM Routing"]}],["$","span","Contextual Bandits",{"className":"page__taxonomy-item","children":["#","Contextual Bandits"]}],["$","span","Bandit Feedback",{"className":"page__taxonomy-item","children":["#","Bandit Feedback"]}],["$","span","Multi-objective Optimization",{"className":"page__taxonomy-item","children":["#","Multi-objective Optimization"]}],["$","span","Preference-tuning",{"className":"page__taxonomy-item","children":["#","Preference-tuning"]}],["$","span","Policy Gradient",{"className":"page__taxonomy-item","children":["#","Policy Gradient"]}],["$","span","Cost-efficiency",{"className":"page__taxonomy-item","children":["#","Cost-efficiency"]}]]}]]}]]}],["$","article","2025-10-10-Learning_on_the_Job_An_Experience-Driven_Self-Evolving_Agent_for_Long-Horizon_Tasks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Learning_on_the_Job_An_Experience-Driven_Self-Evolving_Agent_for_Long-Horizon_Tasks/","children":"[논문리뷰] Learning on the Job: An Experience-Driven Self-Evolving Agent for Long-Horizon Tasks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Learning on the Job: An Experience-Driven Self-Evolving Agent for Long-Horizon Tasks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Continuous Learning",{"className":"page__taxonomy-item","children":["#","Continuous Learning"]}],["$","span","Self-Evolving",{"className":"page__taxonomy-item","children":["#","Self-Evolving"]}],["$","span","Memory Module",{"className":"page__taxonomy-item","children":["#","Memory Module"]}],["$","span","Long-Horizon Planning",{"className":"page__taxonomy-item","children":["#","Long-Horizon Planning"]}],["$","span","Productivity Tasks",{"className":"page__taxonomy-item","children":["#","Productivity Tasks"]}],["$","span","Test-Time Learning",{"className":"page__taxonomy-item","children":["#","Test-Time Learning"]}],["$","span","Experience Replay",{"className":"page__taxonomy-item","children":["#","Experience Replay"]}]]}]]}]]}],["$","article","2025-10-10-Large_Scale_Diffusion_Distillation_via_Score-Regularized_Continuous-Time_Consistency",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Large_Scale_Diffusion_Distillation_via_Score-Regularized_Continuous-Time_Consistency/","children":"[논문리뷰] Large Scale Diffusion Distillation via Score-Regularized Continuous-Time Consistency"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jintao Zhang이 [arXiv]에 게시한 'Large Scale Diffusion Distillation via Score-Regularized Continuous-Time Consistency' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Distillation",{"className":"page__taxonomy-item","children":["#","Diffusion Distillation"]}],["$","span","Consistency Models",{"className":"page__taxonomy-item","children":["#","Consistency Models"]}],["$","span","Score Regularization",{"className":"page__taxonomy-item","children":["#","Score Regularization"]}],["$","span","Large-Scale Generative Models",{"className":"page__taxonomy-item","children":["#","Large-Scale Generative Models"]}],["$","span","Text-to-Image",{"className":"page__taxonomy-item","children":["#","Text-to-Image"]}],["$","span","Text-to-Video",{"className":"page__taxonomy-item","children":["#","Text-to-Video"]}],["$","span","Model Acceleration",{"className":"page__taxonomy-item","children":["#","Model Acceleration"]}],["$","span","JVP",{"className":"page__taxonomy-item","children":["#","JVP"]}]]}]]}]]}],["$","article","2025-10-10-InstructX_Towards_Unified_Visual_Editing_with_MLLM_Guidance",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-InstructX_Towards_Unified_Visual_Editing_with_MLLM_Guidance/","children":"[논문리뷰] InstructX: Towards Unified Visual Editing with MLLM Guidance"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xinghui Li이 [arXiv]에 게시한 'InstructX: Towards Unified Visual Editing with MLLM Guidance' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Visual Editing",{"className":"page__taxonomy-item","children":["#","Visual Editing"]}],["$","span","MLLM Guidance",{"className":"page__taxonomy-item","children":["#","MLLM Guidance"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Video Editing",{"className":"page__taxonomy-item","children":["#","Video Editing"]}],["$","span","Unified Framework",{"className":"page__taxonomy-item","children":["#","Unified Framework"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Instruction-based Editing",{"className":"page__taxonomy-item","children":["#","Instruction-based Editing"]}]]}]]}]]}],["$","article","2025-10-10-Hybrid_Reinforcement_When_Reward_Is_Sparse_Its_Better_to_Be_Dense",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Hybrid_Reinforcement_When_Reward_Is_Sparse_Its_Better_to_Be_Dense/","children":"[논문리뷰] Hybrid Reinforcement: When Reward Is Sparse, It's Better to Be Dense"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Hybrid Reinforcement: When Reward Is Sparse, It's Better to Be Dense' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Reward Modeling",{"className":"page__taxonomy-item","children":["#","Reward Modeling"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Sparse Rewards",{"className":"page__taxonomy-item","children":["#","Sparse Rewards"]}],["$","span","Dense Rewards",{"className":"page__taxonomy-item","children":["#","Dense Rewards"]}],["$","span","Hybrid Reinforcement",{"className":"page__taxonomy-item","children":["#","Hybrid Reinforcement"]}],["$","span","Verifier-based Rewards",{"className":"page__taxonomy-item","children":["#","Verifier-based Rewards"]}]]}]]}]]}],["$","article","2025-10-10-GCPO_When_Contrast_Fails_Go_Gold",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-GCPO_When_Contrast_Fails_Go_Gold/","children":"[논문리뷰] GCPO: When Contrast Fails, Go Gold"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'GCPO: When Contrast Fails, Go Gold' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","LLMs Reasoning",{"className":"page__taxonomy-item","children":["#","LLMs Reasoning"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Chain of Thought",{"className":"page__taxonomy-item","children":["#","Chain of Thought"]}],["$","span","Reference Answers",{"className":"page__taxonomy-item","children":["#","Reference Answers"]}],["$","span","Math Reasoning",{"className":"page__taxonomy-item","children":["#","Math Reasoning"]}],["$","span","Gold-Standard Answer",{"className":"page__taxonomy-item","children":["#","Gold-Standard Answer"]}]]}]]}]]}],["$","article","2025-10-10-From_What_to_Why_A_Multi-Agent_System_for_Evidence-based_Chemical_Reaction_Condition_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-From_What_to_Why_A_Multi-Agent_System_for_Evidence-based_Chemical_Reaction_Condition_Reasoning/","children":"[논문리뷰] From What to Why: A Multi-Agent System for Evidence-based Chemical Reaction Condition Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Feiwei Qin이 [arXiv]에 게시한 'From What to Why: A Multi-Agent System for Evidence-based Chemical Reaction Condition Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-Agent System",{"className":"page__taxonomy-item","children":["#","Multi-Agent System"]}],["$","span","Chemical Reaction Prediction",{"className":"page__taxonomy-item","children":["#","Chemical Reaction Prediction"]}],["$","span","Explainable AI",{"className":"page__taxonomy-item","children":["#","Explainable AI"]}],["$","span","Evidence-Based Reasoning",{"className":"page__taxonomy-item","children":["#","Evidence-Based Reasoning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Tool-Augmented LLMs",{"className":"page__taxonomy-item","children":["#","Tool-Augmented LLMs"]}],["$","span","Scientific Discovery",{"className":"page__taxonomy-item","children":["#","Scientific Discovery"]}]]}]]}]]}],["$","article","2025-10-10-First_Try_Matters_Revisiting_the_Role_of_Reflection_in_Reasoning_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-First_Try_Matters_Revisiting_the_Role_of_Reflection_in_Reasoning_Models/","children":"[논문리뷰] First Try Matters: Revisiting the Role of Reflection in Reasoning Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wee Sun Lee이 [arXiv]에 게시한 'First Try Matters: Revisiting the Role of Reflection in Reasoning Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Chain-of-Thought (CoT)",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought (CoT)"]}],["$","span","Reflection",{"className":"page__taxonomy-item","children":["#","Reflection"]}],["$","span","Early Stopping",{"className":"page__taxonomy-item","children":["#","Early Stopping"]}],["$","span","Supervised Fine-tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning (SFT)"]}],["$","span","Token Efficiency",{"className":"page__taxonomy-item","children":["#","Token Efficiency"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}]]}]]}]]}],["$","article","2025-10-10-Fidelity-Aware_Data_Composition_for_Robust_Robot_Generalization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Fidelity-Aware_Data_Composition_for_Robust_Robot_Generalization/","children":"[논문리뷰] Fidelity-Aware Data Composition for Robust Robot Generalization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Liliang Chen이 [arXiv]에 게시한 'Fidelity-Aware Data Composition for Robust Robot Generalization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Robot Generalization",{"className":"page__taxonomy-item","children":["#","Robot Generalization"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}],["$","span","Out-of-Distribution (OOD)",{"className":"page__taxonomy-item","children":["#","Out-of-Distribution (OOD)"]}],["$","span","Shortcut Learning",{"className":"page__taxonomy-item","children":["#","Shortcut Learning"]}],["$","span","Information Fidelity",{"className":"page__taxonomy-item","children":["#","Information Fidelity"]}],["$","span","Data Composition",{"className":"page__taxonomy-item","children":["#","Data Composition"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Multi-View Video Synthesis",{"className":"page__taxonomy-item","children":["#","Multi-View Video Synthesis"]}]]}]]}]]}],["$","article","2025-10-10-Entropy_Regularizing_Activation_Boosting_Continuous_Control_Large_Language_Models_and_Image_Classification_with_Activation_as_Entropy_Constraints",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Entropy_Regularizing_Activation_Boosting_Continuous_Control_Large_Language_Models_and_Image_Classification_with_Activation_as_Entropy_Constraints/","children":"[논문리뷰] Entropy Regularizing Activation: Boosting Continuous Control, Large Language Models, and Image Classification with Activation as Entropy Constraints"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Huazhe Xu이 [arXiv]에 게시한 'Entropy Regularizing Activation: Boosting Continuous Control, Large Language Models, and Image Classification with Activation as Entropy Constraints' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Entropy Regularization",{"className":"page__taxonomy-item","children":["#","Entropy Regularization"]}],["$","span","Activation Functions",{"className":"page__taxonomy-item","children":["#","Activation Functions"]}],["$","span","Continuous Control",{"className":"page__taxonomy-item","children":["#","Continuous Control"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Image Classification",{"className":"page__taxonomy-item","children":["#","Image Classification"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Policy Stochasticity",{"className":"page__taxonomy-item","children":["#","Policy Stochasticity"]}],["$","span","Entropy Constraints",{"className":"page__taxonomy-item","children":["#","Entropy Constraints"]}]]}]]}]]}],["$","article","2025-10-10-DexNDM_Closing_the_Reality_Gap_for_Dexterous_In-Hand_Rotation_via_Joint-Wise_Neural_Dynamics_Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-DexNDM_Closing_the_Reality_Gap_for_Dexterous_In-Hand_Rotation_via_Joint-Wise_Neural_Dynamics_Model/","children":"[논문리뷰] DexNDM: Closing the Reality Gap for Dexterous In-Hand Rotation via Joint-Wise Neural Dynamics Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Li Yi이 [arXiv]에 게시한 'DexNDM: Closing the Reality Gap for Dexterous In-Hand Rotation via Joint-Wise Neural Dynamics Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Dexterous Manipulation",{"className":"page__taxonomy-item","children":["#","Dexterous Manipulation"]}],["$","span","In-Hand Rotation",{"className":"page__taxonomy-item","children":["#","In-Hand Rotation"]}],["$","span","Sim-to-Real Transfer",{"className":"page__taxonomy-item","children":["#","Sim-to-Real Transfer"]}],["$","span","Neural Dynamics Model",{"className":"page__taxonomy-item","children":["#","Neural Dynamics Model"]}],["$","span","Joint-Wise Learning",{"className":"page__taxonomy-item","children":["#","Joint-Wise Learning"]}],["$","span","Autonomous Data Collection",{"className":"page__taxonomy-item","children":["#","Autonomous Data Collection"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}]]}]]}]]}],["$","article","2025-10-10-DeepPrune_Parallel_Scaling_without_Inter-trace_Redundancy",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-DeepPrune_Parallel_Scaling_without_Inter-trace_Redundancy/","children":"[논문리뷰] DeepPrune: Parallel Scaling without Inter-trace Redundancy"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DeepPrune: Parallel Scaling without Inter-trace Redundancy' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Parallel Scaling",{"className":"page__taxonomy-item","children":["#","Parallel Scaling"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","LLM Reasoning",{"className":"page__taxonomy-item","children":["#","LLM Reasoning"]}],["$","span","Dynamic Pruning",{"className":"page__taxonomy-item","children":["#","Dynamic Pruning"]}],["$","span","Inter-trace Redundancy",{"className":"page__taxonomy-item","children":["#","Inter-trace Redundancy"]}],["$","span","Judge Model",{"className":"page__taxonomy-item","children":["#","Judge Model"]}],["$","span","Resource Efficiency",{"className":"page__taxonomy-item","children":["#","Resource Efficiency"]}],["$","span","Answer Diversity",{"className":"page__taxonomy-item","children":["#","Answer Diversity"]}]]}]]}]]}],["$","article","2025-10-10-CoMAS_Co-Evolving_Multi-Agent_Systems_via_Interaction_Rewards",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-CoMAS_Co-Evolving_Multi-Agent_Systems_via_Interaction_Rewards/","children":"[논문리뷰] CoMAS: Co-Evolving Multi-Agent Systems via Interaction Rewards"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yijiang Li이 [arXiv]에 게시한 'CoMAS: Co-Evolving Multi-Agent Systems via Interaction Rewards' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Self-Evolution",{"className":"page__taxonomy-item","children":["#","Self-Evolution"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Interaction Rewards",{"className":"page__taxonomy-item","children":["#","Interaction Rewards"]}],["$","span","LLM-as-a-Judge",{"className":"page__taxonomy-item","children":["#","LLM-as-a-Judge"]}],["$","span","Decentralized Learning",{"className":"page__taxonomy-item","children":["#","Decentralized Learning"]}]]}]]}]]}],["$","article","2025-10-10-Beyond_Turn_Limits_Training_Deep_Search_Agents_with_Dynamic_Context_Window",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Beyond_Turn_Limits_Training_Deep_Search_Agents_with_Dynamic_Context_Window/","children":"[논문리뷰] Beyond Turn Limits: Training Deep Search Agents with Dynamic Context Window"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yaojie Lu이 [arXiv]에 게시한 'Beyond Turn Limits: Training Deep Search Agents with Dynamic Context Window' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Deep Search Agents",{"className":"page__taxonomy-item","children":["#","Deep Search Agents"]}],["$","span","Dynamic Context Window",{"className":"page__taxonomy-item","children":["#","Dynamic Context Window"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Long-horizon Interaction",{"className":"page__taxonomy-item","children":["#","Long-horizon Interaction"]}],["$","span","Context Management",{"className":"page__taxonomy-item","children":["#","Context Management"]}],["$","span","High-difficulty Tasks",{"className":"page__taxonomy-item","children":["#","High-difficulty Tasks"]}],["$","span","Multi-turn Reasoning",{"className":"page__taxonomy-item","children":["#","Multi-turn Reasoning"]}],["$","span","Web Agents",{"className":"page__taxonomy-item","children":["#","Web Agents"]}]]}]]}]]}],["$","article","2025-10-10-Beyond_Outliers_A_Study_of_Optimizers_Under_Quantization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Beyond_Outliers_A_Study_of_Optimizers_Under_Quantization/","children":"[논문리뷰] Beyond Outliers: A Study of Optimizers Under Quantization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Beyond Outliers: A Study of Optimizers Under Quantization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Quantization",{"className":"page__taxonomy-item","children":["#","Quantization"]}],["$","span","Optimizers",{"className":"page__taxonomy-item","children":["#","Optimizers"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Post-Training Quantization (PTQ)",{"className":"page__taxonomy-item","children":["#","Post-Training Quantization (PTQ)"]}],["$","span","Quantization-Aware Training (QAT)",{"className":"page__taxonomy-item","children":["#","Quantization-Aware Training (QAT)"]}],["$","span","Error Propagation",{"className":"page__taxonomy-item","children":["#","Error Propagation"]}],["$","span","Scaling Laws",{"className":"page__taxonomy-item","children":["#","Scaling Laws"]}],["$","span","Shampoo",{"className":"page__taxonomy-item","children":["#","Shampoo"]}]]}]]}]]}],["$","article","2025-10-10-ARTDECO_Towards_Efficient_and_High-Fidelity_On-the-Fly_3D_Reconstruction_with_Structured_Scene_Representation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-ARTDECO_Towards_Efficient_and_High-Fidelity_On-the-Fly_3D_Reconstruction_with_Structured_Scene_Representation/","children":"[논문리뷰] ARTDECO: Towards Efficient and High-Fidelity On-the-Fly 3D Reconstruction with Structured Scene Representation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'ARTDECO: Towards Efficient and High-Fidelity On-the-Fly 3D Reconstruction with Structured Scene Representation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Reconstruction",{"className":"page__taxonomy-item","children":["#","3D Reconstruction"]}],["$","span","Monocular SLAM",{"className":"page__taxonomy-item","children":["#","Monocular SLAM"]}],["$","span","Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","Gaussian Splatting"]}],["$","span","Level of Detail (LoD)",{"className":"page__taxonomy-item","children":["#","Level of Detail (LoD)"]}],["$","span","Feed-Forward Models",{"className":"page__taxonomy-item","children":["#","Feed-Forward Models"]}],["$","span","Structured Scene Representation",{"className":"page__taxonomy-item","children":["#","Structured Scene Representation"]}],["$","span","Real-time",{"className":"page__taxonomy-item","children":["#","Real-time"]}],["$","span","High-Fidelity",{"className":"page__taxonomy-item","children":["#","High-Fidelity"]}]]}]]}]]}],["$","article","2025-10-10-Agent_Learning_via_Early_Experience",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-Agent_Learning_via_Early_Experience/","children":"[논문리뷰] Agent Learning via Early Experience"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Agent Learning via Early Experience' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Language Agents",{"className":"page__taxonomy-item","children":["#","Language Agents"]}],["$","span","Early Experience",{"className":"page__taxonomy-item","children":["#","Early Experience"]}],["$","span","Reward-Free Learning",{"className":"page__taxonomy-item","children":["#","Reward-Free Learning"]}],["$","span","World Modeling",{"className":"page__taxonomy-item","children":["#","World Modeling"]}],["$","span","Self-Reflection",{"className":"page__taxonomy-item","children":["#","Self-Reflection"]}],["$","span","Imitation Learning",{"className":"page__taxonomy-item","children":["#","Imitation Learning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Out-of-Domain Generalization",{"className":"page__taxonomy-item","children":["#","Out-of-Domain Generalization"]}]]}]]}]]}],["$","article","2025-10-10-A2Search_Ambiguity-Aware_Question_Answering_with_Reinforcement_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-10-A2Search_Ambiguity-Aware_Question_Answering_with_Reinforcement_Learning/","children":"[논문리뷰] A^2Search: Ambiguity-Aware Question Answering with Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'A^2Search: Ambiguity-Aware Question Answering with Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-10 13:53:45+0900","children":"2025년 10월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Question Answering",{"className":"page__taxonomy-item","children":["#","Question Answering"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Ambiguity Resolution",{"className":"page__taxonomy-item","children":["#","Ambiguity Resolution"]}],["$","span","Multi-hop QA",{"className":"page__taxonomy-item","children":["#","Multi-hop QA"]}],["$","span","Automated Data Generation",{"className":"page__taxonomy-item","children":["#","Automated Data Generation"]}],["$","span","Tool-Augmented LLMs",{"className":"page__taxonomy-item","children":["#","Tool-Augmented LLMs"]}],["$","span","AnsF1 Reward",{"className":"page__taxonomy-item","children":["#","AnsF1 Reward"]}]]}]]}]]}],["$","article","2025-10-9-WristWorld_Generating_Wrist-Views_via_4D_World_Models_for_Robotic_Manipulation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-WristWorld_Generating_Wrist-Views_via_4D_World_Models_for_Robotic_Manipulation/","children":"[논문리뷰] WristWorld: Generating Wrist-Views via 4D World Models for Robotic Manipulation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'WristWorld: Generating Wrist-Views via 4D World Models for Robotic Manipulation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","4D World Models",{"className":"page__taxonomy-item","children":["#","4D World Models"]}],["$","span","Robotic Manipulation",{"className":"page__taxonomy-item","children":["#","Robotic Manipulation"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Multi-view Synthesis",{"className":"page__taxonomy-item","children":["#","Multi-view Synthesis"]}],["$","span","Visual-Language-Action (VLA)",{"className":"page__taxonomy-item","children":["#","Visual-Language-Action (VLA)"]}],["$","span","Geometric Consistency",{"className":"page__taxonomy-item","children":["#","Geometric Consistency"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Wrist-View",{"className":"page__taxonomy-item","children":["#","Wrist-View"]}]]}]]}]]}],["$","article","2025-10-9-Why_Low-Precision_Transformer_Training_Fails_An_Analysis_on_Flash_Attention",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Why_Low-Precision_Transformer_Training_Fails_An_Analysis_on_Flash_Attention/","children":"[논문리뷰] Why Low-Precision Transformer Training Fails: An Analysis on Flash Attention"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Why Low-Precision Transformer Training Fails: An Analysis on Flash Attention' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Low-Precision Training",{"className":"page__taxonomy-item","children":["#","Low-Precision Training"]}],["$","span","Flash Attention",{"className":"page__taxonomy-item","children":["#","Flash Attention"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Numerical Stability",{"className":"page__taxonomy-item","children":["#","Numerical Stability"]}],["$","span","BF16",{"className":"page__taxonomy-item","children":["#","BF16"]}],["$","span","Rounding Error",{"className":"page__taxonomy-item","children":["#","Rounding Error"]}],["$","span","Gradient Bias",{"className":"page__taxonomy-item","children":["#","Gradient Bias"]}],["$","span","Deep Learning Optimization",{"className":"page__taxonomy-item","children":["#","Deep Learning Optimization"]}]]}]]}]]}],["$","article","2025-10-9-When_Benchmarks_Age_Temporal_Misalignment_through_Large_Language_Model_Factuality_Evaluation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-When_Benchmarks_Age_Temporal_Misalignment_through_Large_Language_Model_Factuality_Evaluation/","children":"[논문리뷰] When Benchmarks Age: Temporal Misalignment through Large Language Model Factuality Evaluation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'When Benchmarks Age: Temporal Misalignment through Large Language Model Factuality Evaluation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Factuality Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Factuality Evaluation"]}],["$","span","Benchmark Aging",{"className":"page__taxonomy-item","children":["#","Benchmark Aging"]}],["$","span","Temporal Misalignment",{"className":"page__taxonomy-item","children":["#","Temporal Misalignment"]}],["$","span","Information Retrieval",{"className":"page__taxonomy-item","children":["#","Information Retrieval"]}],["$","span","Question Answering",{"className":"page__taxonomy-item","children":["#","Question Answering"]}],["$","span","Evaluation Metrics",{"className":"page__taxonomy-item","children":["#","Evaluation Metrics"]}],["$","span","GPT-4o-mini",{"className":"page__taxonomy-item","children":["#","GPT-4o-mini"]}],["$","span","Qwen2.5",{"className":"page__taxonomy-item","children":["#","Qwen2.5"]}]]}]]}]]}],["$","article","2025-10-9-Vibe_Checker_Aligning_Code_Evaluation_with_Human_Preference",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Vibe_Checker_Aligning_Code_Evaluation_with_Human_Preference/","children":"[논문리뷰] Vibe Checker: Aligning Code Evaluation with Human Preference"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Vibe Checker: Aligning Code Evaluation with Human Preference' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Code Evaluation",{"className":"page__taxonomy-item","children":["#","Code Evaluation"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}],["$","span","Human Preference",{"className":"page__taxonomy-item","children":["#","Human Preference"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Vibe Check",{"className":"page__taxonomy-item","children":["#","Vibe Check"]}],["$","span","Non-functional Requirements",{"className":"page__taxonomy-item","children":["#","Non-functional Requirements"]}],["$","span","VeriCode",{"className":"page__taxonomy-item","children":["#","VeriCode"]}]]}]]}]]}],["$","article","2025-10-9-U-Bench_A_Comprehensive_Understanding_of_U-Net_through_100-Variant_Benchmarking",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-U-Bench_A_Comprehensive_Understanding_of_U-Net_through_100-Variant_Benchmarking/","children":"[논문리뷰] U-Bench: A Comprehensive Understanding of U-Net through 100-Variant Benchmarking"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Heqin Zhu이 [arXiv]에 게시한 'U-Bench: A Comprehensive Understanding of U-Net through 100-Variant Benchmarking' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","U-Net",{"className":"page__taxonomy-item","children":["#","U-Net"]}],["$","span","Medical Image Segmentation",{"className":"page__taxonomy-item","children":["#","Medical Image Segmentation"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Performance Evaluation",{"className":"page__taxonomy-item","children":["#","Performance Evaluation"]}],["$","span","Efficiency Metrics",{"className":"page__taxonomy-item","children":["#","Efficiency Metrics"]}],["$","span","Zero-shot Generalization",{"className":"page__taxonomy-item","children":["#","Zero-shot Generalization"]}],["$","span","U-Score",{"className":"page__taxonomy-item","children":["#","U-Score"]}]]}]]}]]}],["$","article","2025-10-9-TTRV_Test-Time_Reinforcement_Learning_for_Vision_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-TTRV_Test-Time_Reinforcement_Learning_for_Vision_Language_Models/","children":"[논문리뷰] TTRV: Test-Time Reinforcement Learning for Vision Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Serena Yeung-Levy이 [arXiv]에 게시한 'TTRV: Test-Time Reinforcement Learning for Vision Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision-Language Models (VLMs)"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Test-Time Adaptation",{"className":"page__taxonomy-item","children":["#","Test-Time Adaptation"]}],["$","span","Unsupervised Learning",{"className":"page__taxonomy-item","children":["#","Unsupervised Learning"]}],["$","span","Image Recognition",{"className":"page__taxonomy-item","children":["#","Image Recognition"]}],["$","span","Visual Question Answering (VQA)",{"className":"page__taxonomy-item","children":["#","Visual Question Answering (VQA)"]}],["$","span","Group Relative Policy Optimization (GRPO)",{"className":"page__taxonomy-item","children":["#","Group Relative Policy Optimization (GRPO)"]}],["$","span","Entropy Regularization",{"className":"page__taxonomy-item","children":["#","Entropy Regularization"]}]]}]]}]]}],["$","article","2025-10-9-The_Markovian_Thinker",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-The_Markovian_Thinker/","children":"[논문리뷰] The Markovian Thinker"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'The Markovian Thinker' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Markovian Thinking",{"className":"page__taxonomy-item","children":["#","Markovian Thinking"]}],["$","span","Context Management",{"className":"page__taxonomy-item","children":["#","Context Management"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}],["$","span","Long-Context LLMs",{"className":"page__taxonomy-item","children":["#","Long-Context LLMs"]}],["$","span","Transformer Optimization",{"className":"page__taxonomy-item","children":["#","Transformer Optimization"]}]]}]]}]]}],["$","article","2025-10-9-The_African_Languages_Lab_A_Collaborative_Approach_to_Advancing_Low-Resource_African_NLP",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-The_African_Languages_Lab_A_Collaborative_Approach_to_Advancing_Low-Resource_African_NLP/","children":"[논문리뷰] The African Languages Lab: A Collaborative Approach to Advancing Low-Resource African NLP"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'The African Languages Lab: A Collaborative Approach to Advancing Low-Resource African NLP' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Low-Resource NLP",{"className":"page__taxonomy-item","children":["#","Low-Resource NLP"]}],["$","span","African Languages",{"className":"page__taxonomy-item","children":["#","African Languages"]}],["$","span","Data Collection",{"className":"page__taxonomy-item","children":["#","Data Collection"]}],["$","span","Multilingual Models",{"className":"page__taxonomy-item","children":["#","Multilingual Models"]}],["$","span","Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Fine-Tuning"]}],["$","span","Speech Data",{"className":"page__taxonomy-item","children":["#","Speech Data"]}],["$","span","Text Data",{"className":"page__taxonomy-item","children":["#","Text Data"]}],["$","span","Capacity Building",{"className":"page__taxonomy-item","children":["#","Capacity Building"]}]]}]]}]]}],["$","article","2025-10-9-StaMo_Unsupervised_Learning_of_Generalizable_Robot_Motion_from_Compact_State_Representation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-StaMo_Unsupervised_Learning_of_Generalizable_Robot_Motion_from_Compact_State_Representation/","children":"[논문리뷰] StaMo: Unsupervised Learning of Generalizable Robot Motion from Compact State Representation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'StaMo: Unsupervised Learning of Generalizable Robot Motion from Compact State Representation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Robot Learning",{"className":"page__taxonomy-item","children":["#","Robot Learning"]}],["$","span","State Representation",{"className":"page__taxonomy-item","children":["#","State Representation"]}],["$","span","Motion Representation",{"className":"page__taxonomy-item","children":["#","Motion Representation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Unsupervised Learning",{"className":"page__taxonomy-item","children":["#","Unsupervised Learning"]}],["$","span","World Modeling",{"className":"page__taxonomy-item","children":["#","World Modeling"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Latent Action",{"className":"page__taxonomy-item","children":["#","Latent Action"]}]]}]]}]]}],["$","article","2025-10-9-SHANKS_Simultaneous_Hearing_and_Thinking_for_Spoken_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-SHANKS_Simultaneous_Hearing_and_Thinking_for_Spoken_Language_Models/","children":"[논문리뷰] SHANKS: Simultaneous Hearing and Thinking for Spoken Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kevin Lin이 [arXiv]에 게시한 'SHANKS: Simultaneous Hearing and Thinking for Spoken Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Spoken Language Models",{"className":"page__taxonomy-item","children":["#","Spoken Language Models"]}],["$","span","Real-time Interaction",{"className":"page__taxonomy-item","children":["#","Real-time Interaction"]}],["$","span","Thinking While Listening",{"className":"page__taxonomy-item","children":["#","Thinking While Listening"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Interruption",{"className":"page__taxonomy-item","children":["#","Interruption"]}],["$","span","Tool Calling",{"className":"page__taxonomy-item","children":["#","Tool Calling"]}],["$","span","Streaming ASR",{"className":"page__taxonomy-item","children":["#","Streaming ASR"]}]]}]]}]]}],["$","article","2025-10-9-RLinf-VLA_A_Unified_and_Efficient_Framework_for_VLARL_Training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-RLinf-VLA_A_Unified_and_Efficient_Framework_for_VLARL_Training/","children":"[논문리뷰] RLinf-VLA: A Unified and Efficient Framework for VLA+RL Training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'RLinf-VLA: A Unified and Efficient Framework for VLA+RL Training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","VLA Models",{"className":"page__taxonomy-item","children":["#","VLA Models"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","GPU Management",{"className":"page__taxonomy-item","children":["#","GPU Management"]}],["$","span","PPO",{"className":"page__taxonomy-item","children":["#","PPO"]}],["$","span","GRPO",{"className":"page__taxonomy-item","children":["#","GRPO"]}],["$","span","Sim-to-Real",{"className":"page__taxonomy-item","children":["#","Sim-to-Real"]}]]}]]}]]}],["$","article","2025-10-9-Revisiting_the_Uniform_Information_Density_Hypothesis_in_LLM_Reasoning_Traces",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Revisiting_the_Uniform_Information_Density_Hypothesis_in_LLM_Reasoning_Traces/","children":"[논문리뷰] Revisiting the Uniform Information Density Hypothesis in LLM Reasoning Traces"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Revisiting the Uniform Information Density Hypothesis in LLM Reasoning Traces' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Reasoning",{"className":"page__taxonomy-item","children":["#","LLM Reasoning"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Uniform Information Density",{"className":"page__taxonomy-item","children":["#","Uniform Information Density"]}],["$","span","Information Theory",{"className":"page__taxonomy-item","children":["#","Information Theory"]}],["$","span","Reasoning Trace Analysis",{"className":"page__taxonomy-item","children":["#","Reasoning Trace Analysis"]}],["$","span","Entropy",{"className":"page__taxonomy-item","children":["#","Entropy"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Model Evaluation",{"className":"page__taxonomy-item","children":["#","Model Evaluation"]}]]}]]}]]}],["$","article","2025-10-9-Revisiting_Long-context_Modeling_from_Context_Denoising_Perspective",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Revisiting_Long-context_Modeling_from_Context_Denoising_Perspective/","children":"[논문리뷰] Revisiting Long-context Modeling from Context Denoising Perspective"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Revisiting Long-context Modeling from Context Denoising Perspective' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Long-context Models",{"className":"page__taxonomy-item","children":["#","Long-context Models"]}],["$","span","Context Denoising",{"className":"page__taxonomy-item","children":["#","Context Denoising"]}],["$","span","Integrated Gradient",{"className":"page__taxonomy-item","children":["#","Integrated Gradient"]}],["$","span","LLM Training",{"className":"page__taxonomy-item","children":["#","LLM Training"]}],["$","span","Context Window Scaling",{"className":"page__taxonomy-item","children":["#","Context Window Scaling"]}],["$","span","Information Flow",{"className":"page__taxonomy-item","children":["#","Information Flow"]}],["$","span","Attention Mechanism",{"className":"page__taxonomy-item","children":["#","Attention Mechanism"]}]]}]]}]]}],["$","article","2025-10-9-Pushing_on_Multilingual_Reasoning_Models_with_Language-Mixed_Chain-of-Thought",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Pushing_on_Multilingual_Reasoning_Models_with_Language-Mixed_Chain-of-Thought/","children":"[논문리뷰] Pushing on Multilingual Reasoning Models with Language-Mixed Chain-of-Thought"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Pushing on Multilingual Reasoning Models with Language-Mixed Chain-of-Thought' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multilingual Reasoning",{"className":"page__taxonomy-item","children":["#","Multilingual Reasoning"]}],["$","span","Chain-of-Thought (CoT)",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought (CoT)"]}],["$","span","Language-Mixed CoT",{"className":"page__taxonomy-item","children":["#","Language-Mixed CoT"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}],["$","span","Korean LLMs",{"className":"page__taxonomy-item","children":["#","Korean LLMs"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Supervised Fine-tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning (SFT)"]}]]}]]}]]}],["$","article","2025-10-9-Patch-as-Decodable-Token_Towards_Unified_Multi-Modal_Vision_Tasks_in_MLLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Patch-as-Decodable-Token_Towards_Unified_Multi-Modal_Vision_Tasks_in_MLLMs/","children":"[논문리뷰] Patch-as-Decodable-Token: Towards Unified Multi-Modal Vision Tasks in MLLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jingyi Liao이 [arXiv]에 게시한 'Patch-as-Decodable-Token: Towards Unified Multi-Modal Vision Tasks in MLLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models (MLLMs)"]}],["$","span","Visual Reference Tokens (VRTs)",{"className":"page__taxonomy-item","children":["#","Visual Reference Tokens (VRTs)"]}],["$","span","Dense Prediction",{"className":"page__taxonomy-item","children":["#","Dense Prediction"]}],["$","span","Referring Expression Comprehension (REC)",{"className":"page__taxonomy-item","children":["#","Referring Expression Comprehension (REC)"]}],["$","span","Open-Vocabulary Detection (OVD)",{"className":"page__taxonomy-item","children":["#","Open-Vocabulary Detection (OVD)"]}],["$","span","Image Captioning",{"className":"page__taxonomy-item","children":["#","Image Captioning"]}],["$","span","Unified Architecture",{"className":"page__taxonomy-item","children":["#","Unified Architecture"]}],["$","span","Autoregressive Generation",{"className":"page__taxonomy-item","children":["#","Autoregressive Generation"]}]]}]]}]]}],["$","article","2025-10-9-Online_Generic_Event_Boundary_Detection",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Online_Generic_Event_Boundary_Detection/","children":"[논문리뷰] Online Generic Event Boundary Detection"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jonghyun Choi이 [arXiv]에 게시한 'Online Generic Event Boundary Detection' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Online Video Analysis",{"className":"page__taxonomy-item","children":["#","Online Video Analysis"]}],["$","span","Event Boundary Detection",{"className":"page__taxonomy-item","children":["#","Event Boundary Detection"]}],["$","span","Event Segmentation Theory",{"className":"page__taxonomy-item","children":["#","Event Segmentation Theory"]}],["$","span","Real-time AI",{"className":"page__taxonomy-item","children":["#","Real-time AI"]}],["$","span","Anomaly Detection",{"className":"page__taxonomy-item","children":["#","Anomaly Detection"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}]]}]]}]]}],["$","article","2025-10-9-OBS-Diff_Accurate_Pruning_For_Diffusion_Models_in_One-Shot",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-OBS-Diff_Accurate_Pruning_For_Diffusion_Models_in_One-Shot/","children":"[논문리뷰] OBS-Diff: Accurate Pruning For Diffusion Models in One-Shot"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'OBS-Diff: Accurate Pruning For Diffusion Models in One-Shot' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Network Pruning",{"className":"page__taxonomy-item","children":["#","Network Pruning"]}],["$","span","One-Shot Pruning",{"className":"page__taxonomy-item","children":["#","One-Shot Pruning"]}],["$","span","Optimal Brain Surgeon (OBS)",{"className":"page__taxonomy-item","children":["#","Optimal Brain Surgeon (OBS)"]}],["$","span","Model Compression",{"className":"page__taxonomy-item","children":["#","Model Compression"]}],["$","span","Timestep-Aware Hessian",{"className":"page__taxonomy-item","children":["#","Timestep-Aware Hessian"]}],["$","span","Structured Pruning",{"className":"page__taxonomy-item","children":["#","Structured Pruning"]}]]}]]}]]}],["$","article","2025-10-9-NorMuon_Making_Muon_more_efficient_and_scalable",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-NorMuon_Making_Muon_more_efficient_and_scalable/","children":"[논문리뷰] NorMuon: Making Muon more efficient and scalable"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Tuo Zhao이 [arXiv]에 게시한 'NorMuon: Making Muon more efficient and scalable' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Training",{"className":"page__taxonomy-item","children":["#","LLM Training"]}],["$","span","Optimizer",{"className":"page__taxonomy-item","children":["#","Optimizer"]}],["$","span","Muon",{"className":"page__taxonomy-item","children":["#","Muon"]}],["$","span","Orthogonalization",{"className":"page__taxonomy-item","children":["#","Orthogonalization"]}],["$","span","Adaptive Learning Rates",{"className":"page__taxonomy-item","children":["#","Adaptive Learning Rates"]}],["$","span","Distributed Training",{"className":"page__taxonomy-item","children":["#","Distributed Training"]}],["$","span","FSDP2",{"className":"page__taxonomy-item","children":["#","FSDP2"]}],["$","span","NorMuon",{"className":"page__taxonomy-item","children":["#","NorMuon"]}]]}]]}]]}],["$","article","2025-10-9-Native_Hybrid_Attention_for_Efficient_Sequence_Modeling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Native_Hybrid_Attention_for_Efficient_Sequence_Modeling/","children":"[논문리뷰] Native Hybrid Attention for Efficient Sequence Modeling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yu Cheng이 [arXiv]에 게시한 'Native Hybrid Attention for Efficient Sequence Modeling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Sequence Modeling",{"className":"page__taxonomy-item","children":["#","Sequence Modeling"]}],["$","span","Hybrid Attention",{"className":"page__taxonomy-item","children":["#","Hybrid Attention"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Linear Attention",{"className":"page__taxonomy-item","children":["#","Linear Attention"]}],["$","span","Sliding Window Attention",{"className":"page__taxonomy-item","children":["#","Sliding Window Attention"]}],["$","span","Long Context",{"className":"page__taxonomy-item","children":["#","Long Context"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Efficiency",{"className":"page__taxonomy-item","children":["#","Efficiency"]}]]}]]}]]}],["$","article","2025-10-9-Multi-Agent_Tool-Integrated_Policy_Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Multi-Agent_Tool-Integrated_Policy_Optimization/","children":"[논문리뷰] Multi-Agent Tool-Integrated Policy Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Lidong Bing이 [arXiv]에 게시한 'Multi-Agent Tool-Integrated Policy Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-Agent RL",{"className":"page__taxonomy-item","children":["#","Multi-Agent RL"]}],["$","span","Tool-Integrated Planning",{"className":"page__taxonomy-item","children":["#","Tool-Integrated Planning"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Credit Assignment",{"className":"page__taxonomy-item","children":["#","Credit Assignment"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","MATPO",{"className":"page__taxonomy-item","children":["#","MATPO"]}]]}]]}]]}],["$","article","2025-10-9-MLE-Smith_Scaling_MLE_Tasks_with_Automated_Multi-Agent_Pipeline",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-MLE-Smith_Scaling_MLE_Tasks_with_Automated_Multi-Agent_Pipeline/","children":"[논문리뷰] MLE-Smith: Scaling MLE Tasks with Automated Multi-Agent Pipeline"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'MLE-Smith: Scaling MLE Tasks with Automated Multi-Agent Pipeline' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","MLE (Machine Learning Engineering)",{"className":"page__taxonomy-item","children":["#","MLE (Machine Learning Engineering)"]}],["$","span","Automated Task Generation",{"className":"page__taxonomy-item","children":["#","Automated Task Generation"]}],["$","span","Multi-Agent System",{"className":"page__taxonomy-item","children":["#","Multi-Agent System"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Hybrid Verification",{"className":"page__taxonomy-item","children":["#","Hybrid Verification"]}],["$","span","Kaggle",{"className":"page__taxonomy-item","children":["#","Kaggle"]}]]}]]}]]}],["$","article","2025-10-9-Ming-UniVision_Joint_Image_Understanding_and_Generation_with_a_Unified_Continuous_Tokenizer",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Ming-UniVision_Joint_Image_Understanding_and_Generation_with_a_Unified_Continuous_Tokenizer/","children":"[논문리뷰] Ming-UniVision: Joint Image Understanding and Generation with a Unified Continuous Tokenizer"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Ming-UniVision: Joint Image Understanding and Generation with a Unified Continuous Tokenizer' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Unified Vision-Language Model",{"className":"page__taxonomy-item","children":["#","Unified Vision-Language Model"]}],["$","span","Continuous Tokenizer",{"className":"page__taxonomy-item","children":["#","Continuous Tokenizer"]}],["$","span","Autoregressive Generation",{"className":"page__taxonomy-item","children":["#","Autoregressive Generation"]}],["$","span","Image Understanding",{"className":"page__taxonomy-item","children":["#","Image Understanding"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","In-context Editing",{"className":"page__taxonomy-item","children":["#","In-context Editing"]}]]}]]}]]}],["$","article","2025-10-9-MATRIX_Mask_Track_Alignment_for_Interaction-aware_Video_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-MATRIX_Mask_Track_Alignment_for_Interaction-aware_Video_Generation/","children":"[논문리뷰] MATRIX: Mask Track Alignment for Interaction-aware Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hyunwook Choi이 [arXiv]에 게시한 'MATRIX: Mask Track Alignment for Interaction-aware Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Diffusion Transformers",{"className":"page__taxonomy-item","children":["#","Diffusion Transformers"]}],["$","span","Human-Object Interaction",{"className":"page__taxonomy-item","children":["#","Human-Object Interaction"]}],["$","span","Attention Alignment",{"className":"page__taxonomy-item","children":["#","Attention Alignment"]}],["$","span","Mask Tracking",{"className":"page__taxonomy-item","children":["#","Mask Tracking"]}],["$","span","Semantic Grounding",{"className":"page__taxonomy-item","children":["#","Semantic Grounding"]}],["$","span","Semantic Propagation",{"className":"page__taxonomy-item","children":["#","Semantic Propagation"]}],["$","span","Text-to-Video",{"className":"page__taxonomy-item","children":["#","Text-to-Video"]}]]}]]}]]}],["$","article","2025-10-9-Lumina-DiMOO_An_Omni_Diffusion_Large_Language_Model_for_Multi-Modal_Generation_and_Understanding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Lumina-DiMOO_An_Omni_Diffusion_Large_Language_Model_for_Multi-Modal_Generation_and_Understanding/","children":"[논문리뷰] Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-modal LLM",{"className":"page__taxonomy-item","children":["#","Multi-modal LLM"]}],["$","span","Discrete Diffusion",{"className":"page__taxonomy-item","children":["#","Discrete Diffusion"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Image Understanding",{"className":"page__taxonomy-item","children":["#","Image Understanding"]}],["$","span","Omni-modal",{"className":"page__taxonomy-item","children":["#","Omni-modal"]}],["$","span","Interactive Retouching",{"className":"page__taxonomy-item","children":["#","Interactive Retouching"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}]]}]]}]]}],["$","article","2025-10-9-Heptapod_Language_Modeling_on_Visual_Signals",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Heptapod_Language_Modeling_on_Visual_Signals/","children":"[논문리뷰] Heptapod: Language Modeling on Visual Signals"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Heptapod: Language Modeling on Visual Signals' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Autoregressive Models",{"className":"page__taxonomy-item","children":["#","Autoregressive Models"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Language Modeling",{"className":"page__taxonomy-item","children":["#","Language Modeling"]}],["$","span","Causal Transformer",{"className":"page__taxonomy-item","children":["#","Causal Transformer"]}],["$","span","2D Distribution Prediction",{"className":"page__taxonomy-item","children":["#","2D Distribution Prediction"]}],["$","span","Visual Tokenization",{"className":"page__taxonomy-item","children":["#","Visual Tokenization"]}],["$","span","Self-Supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-Supervised Learning"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}]]}]]}]]}],["$","article","2025-10-9-G2RPO_Granular_GRPO_for_Precise_Reward_in_Flow_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-G2RPO_Granular_GRPO_for_Precise_Reward_in_Flow_Models/","children":"[논문리뷰] G^2RPO: Granular GRPO for Precise Reward in Flow Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'G^2RPO: Granular GRPO for Precise Reward in Flow Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Flow Models",{"className":"page__taxonomy-item","children":["#","Flow Models"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Human Preference Alignment",{"className":"page__taxonomy-item","children":["#","Human Preference Alignment"]}],["$","span","Stochastic Differential Equations (SDE)",{"className":"page__taxonomy-item","children":["#","Stochastic Differential Equations (SDE)"]}],["$","span","Reward Signal",{"className":"page__taxonomy-item","children":["#","Reward Signal"]}],["$","span","Multi-Granularity",{"className":"page__taxonomy-item","children":["#","Multi-Granularity"]}]]}]]}]]}],["$","article","2025-10-9-DeepTravel_An_End-to-End_Agentic_Reinforcement_Learning_Framework_for_Autonomous_Travel_Planning_Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-DeepTravel_An_End-to-End_Agentic_Reinforcement_Learning_Framework_for_Autonomous_Travel_Planning_Agents/","children":"[논문리뷰] DeepTravel: An End-to-End Agentic Reinforcement Learning Framework for Autonomous Travel Planning Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DeepTravel: An End-to-End Agentic Reinforcement Learning Framework for Autonomous Travel Planning Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Agentic Reinforcement Learning"]}],["$","span","Travel Planning",{"className":"page__taxonomy-item","children":["#","Travel Planning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Sandbox Environment",{"className":"page__taxonomy-item","children":["#","Sandbox Environment"]}],["$","span","Hierarchical Reward Modeling",{"className":"page__taxonomy-item","children":["#","Hierarchical Reward Modeling"]}],["$","span","Experience Replay",{"className":"page__taxonomy-item","children":["#","Experience Replay"]}],["$","span","Autonomous Agents",{"className":"page__taxonomy-item","children":["#","Autonomous Agents"]}]]}]]}]]}],["$","article","2025-10-9-D3QE_Learning_Discrete_Distribution_Discrepancy-aware_Quantization_Error_for_Autoregressive-Generated_Image_Detection",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-D3QE_Learning_Discrete_Distribution_Discrepancy-aware_Quantization_Error_for_Autoregressive-Generated_Image_Detection/","children":"[논문리뷰] D^3QE: Learning Discrete Distribution Discrepancy-aware Quantization Error for Autoregressive-Generated Image Detection"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yueqi Duan이 [arXiv]에 게시한 'D^3QE: Learning Discrete Distribution Discrepancy-aware Quantization Error for Autoregressive-Generated Image Detection' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Autoregressive Models",{"className":"page__taxonomy-item","children":["#","Autoregressive Models"]}],["$","span","Image Detection",{"className":"page__taxonomy-item","children":["#","Image Detection"]}],["$","span","Discrete Distribution Discrepancy",{"className":"page__taxonomy-item","children":["#","Discrete Distribution Discrepancy"]}],["$","span","Quantization Error",{"className":"page__taxonomy-item","children":["#","Quantization Error"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Deepfake Detection",{"className":"page__taxonomy-item","children":["#","Deepfake Detection"]}]]}]]}]]}],["$","article","2025-10-9-CALM_Before_the_STORM_Unlocking_Native_Reasoning_for_Optimization_Modeling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-CALM_Before_the_STORM_Unlocking_Native_Reasoning_for_Optimization_Modeling/","children":"[논문리뷰] CALM Before the STORM: Unlocking Native Reasoning for Optimization Modeling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chengpeng Li이 [arXiv]에 게시한 'CALM Before the STORM: Unlocking Native Reasoning for Optimization Modeling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Reasoning Models",{"className":"page__taxonomy-item","children":["#","Large Reasoning Models"]}],["$","span","Optimization Modeling",{"className":"page__taxonomy-item","children":["#","Optimization Modeling"]}],["$","span","Reflective Generation",{"className":"page__taxonomy-item","children":["#","Reflective Generation"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Human-in-the-Loop",{"className":"page__taxonomy-item","children":["#","Human-in-the-Loop"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","Domain Adaptation",{"className":"page__taxonomy-item","children":["#","Domain Adaptation"]}]]}]]}]]}],["$","article","2025-10-9-Cache-to-Cache_Direct_Semantic_Communication_Between_Large_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Cache-to-Cache_Direct_Semantic_Communication_Between_Large_Language_Models/","children":"[논문리뷰] Cache-to-Cache: Direct Semantic Communication Between Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Cache-to-Cache: Direct Semantic Communication Between Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Inter-model Communication",{"className":"page__taxonomy-item","children":["#","Inter-model Communication"]}],["$","span","KV-Cache",{"className":"page__taxonomy-item","children":["#","KV-Cache"]}],["$","span","Semantic Transfer",{"className":"page__taxonomy-item","children":["#","Semantic Transfer"]}],["$","span","Multi-LLM Systems",{"className":"page__taxonomy-item","children":["#","Multi-LLM Systems"]}],["$","span","Cache Fusion",{"className":"page__taxonomy-item","children":["#","Cache Fusion"]}],["$","span","Latency Reduction",{"className":"page__taxonomy-item","children":["#","Latency Reduction"]}],["$","span","Knowledge Sharing",{"className":"page__taxonomy-item","children":["#","Knowledge Sharing"]}]]}]]}]]}],["$","article","2025-10-9-Bridging_Text_and_Video_Generation_A_Survey",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Bridging_Text_and_Video_Generation_A_Survey/","children":"[논문리뷰] Bridging Text and Video Generation: A Survey"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"G. Maragatham이 [arXiv]에 게시한 'Bridging Text and Video Generation: A Survey' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Video Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Video Generation"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","GANs",{"className":"page__taxonomy-item","children":["#","GANs"]}],["$","span","VAEs",{"className":"page__taxonomy-item","children":["#","VAEs"]}],["$","span","Video Synthesis",{"className":"page__taxonomy-item","children":["#","Video Synthesis"]}],["$","span","Survey",{"className":"page__taxonomy-item","children":["#","Survey"]}],["$","span","Evaluation Metrics",{"className":"page__taxonomy-item","children":["#","Evaluation Metrics"]}]]}]]}]]}],["$","article","2025-10-9-Beyond_Monolingual_Assumptions_A_Survey_of_Code-Switched_NLP_in_the_Era_of_Large_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Beyond_Monolingual_Assumptions_A_Survey_of_Code-Switched_NLP_in_the_Era_of_Large_Language_Models/","children":"[논문리뷰] Beyond Monolingual Assumptions: A Survey of Code-Switched NLP in the Era of Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Beyond Monolingual Assumptions: A Survey of Code-Switched NLP in the Era of Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Code-switching",{"className":"page__taxonomy-item","children":["#","Code-switching"]}],["$","span","Multilingual NLP",{"className":"page__taxonomy-item","children":["#","Multilingual NLP"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","NLP Survey",{"className":"page__taxonomy-item","children":["#","NLP Survey"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}],["$","span","Evaluation Metrics",{"className":"page__taxonomy-item","children":["#","Evaluation Metrics"]}],["$","span","Low-Resource Languages",{"className":"page__taxonomy-item","children":["#","Low-Resource Languages"]}]]}]]}]]}],["$","article","2025-10-9-Artificial_Hippocampus_Networks_for_Efficient_Long-Context_Modeling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Artificial_Hippocampus_Networks_for_Efficient_Long-Context_Modeling/","children":"[논문리뷰] Artificial Hippocampus Networks for Efficient Long-Context Modeling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Artificial Hippocampus Networks for Efficient Long-Context Modeling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Long-Context Modeling",{"className":"page__taxonomy-item","children":["#","Long-Context Modeling"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","RNN",{"className":"page__taxonomy-item","children":["#","RNN"]}],["$","span","Memory Management",{"className":"page__taxonomy-item","children":["#","Memory Management"]}],["$","span","Self-Distillation",{"className":"page__taxonomy-item","children":["#","Self-Distillation"]}],["$","span","Attention Mechanism",{"className":"page__taxonomy-item","children":["#","Attention Mechanism"]}],["$","span","Artificial Hippocampus Networks",{"className":"page__taxonomy-item","children":["#","Artificial Hippocampus Networks"]}],["$","span","Cognitive Science",{"className":"page__taxonomy-item","children":["#","Cognitive Science"]}]]}]]}]]}],["$","article","2025-10-9-Are_We_Using_the_Right_Benchmark_An_Evaluation_Framework_for_Visual_Token_Compression_Methods",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-Are_We_Using_the_Right_Benchmark_An_Evaluation_Framework_for_Visual_Token_Compression_Methods/","children":"[논문리뷰] Are We Using the Right Benchmark: An Evaluation Framework for Visual Token Compression Methods"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yiyu Wang이 [arXiv]에 게시한 'Are We Using the Right Benchmark: An Evaluation Framework for Visual Token Compression Methods' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Visual Token Compression",{"className":"page__taxonomy-item","children":["#","Visual Token Compression"]}],["$","span","MLLMs",{"className":"page__taxonomy-item","children":["#","MLLMs"]}],["$","span","Evaluation Framework",{"className":"page__taxonomy-item","children":["#","Evaluation Framework"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Downsampling",{"className":"page__taxonomy-item","children":["#","Downsampling"]}],["$","span","Data Filtering",{"className":"page__taxonomy-item","children":["#","Data Filtering"]}],["$","span","Model Efficiency",{"className":"page__taxonomy-item","children":["#","Model Efficiency"]}]]}]]}]]}],["$","article","2025-10-9-AlphaApollo_Orchestrating_Foundation_Models_and_Professional_Tools_into_a_Self-Evolving_System_for_Deep_Agentic_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-9-AlphaApollo_Orchestrating_Foundation_Models_and_Professional_Tools_into_a_Self-Evolving_System_for_Deep_Agentic_Reasoning/","children":"[논문리뷰] AlphaApollo: Orchestrating Foundation Models and Professional Tools into a Self-Evolving System for Deep Agentic Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zongze Li이 [arXiv]에 게시한 'AlphaApollo: Orchestrating Foundation Models and Professional Tools into a Self-Evolving System for Deep Agentic Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-09 13:45:06+0900","children":"2025년 10월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Agentic Reasoning",{"className":"page__taxonomy-item","children":["#","Agentic Reasoning"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Self-Evolving System",{"className":"page__taxonomy-item","children":["#","Self-Evolving System"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","Computational Tools",{"className":"page__taxonomy-item","children":["#","Computational Tools"]}],["$","span","Error Correction",{"className":"page__taxonomy-item","children":["#","Error Correction"]}]]}]]}]]}],["$","article","2025-10-8-VeriGuard_Enhancing_LLM_Agent_Safety_via_Verified_Code_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-VeriGuard_Enhancing_LLM_Agent_Safety_via_Verified_Code_Generation/","children":"[논문리뷰] VeriGuard: Enhancing LLM Agent Safety via Verified Code Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'VeriGuard: Enhancing LLM Agent Safety via Verified Code Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Safety",{"className":"page__taxonomy-item","children":["#","Safety"]}],["$","span","Formal Verification",{"className":"page__taxonomy-item","children":["#","Formal Verification"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","Runtime Monitoring",{"className":"page__taxonomy-item","children":["#","Runtime Monitoring"]}],["$","span","Security",{"className":"page__taxonomy-item","children":["#","Security"]}],["$","span","Guardrails",{"className":"page__taxonomy-item","children":["#","Guardrails"]}],["$","span","Policy Enforcement",{"className":"page__taxonomy-item","children":["#","Policy Enforcement"]}]]}]]}]]}],["$","article","2025-10-8-Training_Dynamics_Impact_Post-Training_Quantization_Robustness",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Training_Dynamics_Impact_Post-Training_Quantization_Robustness/","children":"[논문리뷰] Training Dynamics Impact Post-Training Quantization Robustness"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jonas Geiping이 [arXiv]에 게시한 'Training Dynamics Impact Post-Training Quantization Robustness' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Post-Training Quantization",{"className":"page__taxonomy-item","children":["#","Post-Training Quantization"]}],["$","span","Quantization Robustness",{"className":"page__taxonomy-item","children":["#","Quantization Robustness"]}],["$","span","Training Dynamics",{"className":"page__taxonomy-item","children":["#","Training Dynamics"]}],["$","span","Learning Rate Schedules",{"className":"page__taxonomy-item","children":["#","Learning Rate Schedules"]}],["$","span","Weight Averaging",{"className":"page__taxonomy-item","children":["#","Weight Averaging"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Hyperparameter Tuning",{"className":"page__taxonomy-item","children":["#","Hyperparameter Tuning"]}]]}]]}]]}],["$","article","2025-10-8-TensorBLEU_Vectorized_GPU-based_BLEU_Score_Implementation_for_Per-Sentence_In-Training_Evaluation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-TensorBLEU_Vectorized_GPU-based_BLEU_Score_Implementation_for_Per-Sentence_In-Training_Evaluation/","children":"[논문리뷰] TensorBLEU: Vectorized GPU-based BLEU Score Implementation for Per-Sentence In-Training Evaluation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'TensorBLEU: Vectorized GPU-based BLEU Score Implementation for Per-Sentence In-Training Evaluation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","BLEU Score",{"className":"page__taxonomy-item","children":["#","BLEU Score"]}],["$","span","GPU Acceleration",{"className":"page__taxonomy-item","children":["#","GPU Acceleration"]}],["$","span","PyTorch",{"className":"page__taxonomy-item","children":["#","PyTorch"]}],["$","span","Natural Language Processing",{"className":"page__taxonomy-item","children":["#","Natural Language Processing"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Vectorization",{"className":"page__taxonomy-item","children":["#","Vectorization"]}],["$","span","In-Training Evaluation",{"className":"page__taxonomy-item","children":["#","In-Training Evaluation"]}],["$","span","N-gram Counting",{"className":"page__taxonomy-item","children":["#","N-gram Counting"]}]]}]]}]]}],["$","article","2025-10-8-TaTToo_Tool-Grounded_Thinking_PRM_for_Test-Time_Scaling_in_Tabular_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-TaTToo_Tool-Grounded_Thinking_PRM_for_Test-Time_Scaling_in_Tabular_Reasoning/","children":"[논문리뷰] TaTToo: Tool-Grounded Thinking PRM for Test-Time Scaling in Tabular Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'TaTToo: Tool-Grounded Thinking PRM for Test-Time Scaling in Tabular Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Process Reward Models",{"className":"page__taxonomy-item","children":["#","Process Reward Models"]}],["$","span","Tabular Reasoning",{"className":"page__taxonomy-item","children":["#","Tabular Reasoning"]}],["$","span","Test-Time Scaling",{"className":"page__taxonomy-item","children":["#","Test-Time Scaling"]}],["$","span","Tool Integration",{"className":"page__taxonomy-item","children":["#","Tool Integration"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}]]}]]}]]}],["$","article","2025-10-8-ShapeGen4D_Towards_High_Quality_4D_Shape_Generation_from_Videos",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-ShapeGen4D_Towards_High_Quality_4D_Shape_Generation_from_Videos/","children":"[논문리뷰] ShapeGen4D: Towards High Quality 4D Shape Generation from Videos"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Sergey Tulyakov이 [arXiv]에 게시한 'ShapeGen4D: Towards High Quality 4D Shape Generation from Videos' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","4D Shape Generation",{"className":"page__taxonomy-item","children":["#","4D Shape Generation"]}],["$","span","Video-conditioned",{"className":"page__taxonomy-item","children":["#","Video-conditioned"]}],["$","span","Dynamic 3D Meshes",{"className":"page__taxonomy-item","children":["#","Dynamic 3D Meshes"]}],["$","span","Latent Diffusion Model",{"className":"page__taxonomy-item","children":["#","Latent Diffusion Model"]}],["$","span","Spatiotemporal Attention",{"className":"page__taxonomy-item","children":["#","Spatiotemporal Attention"]}],["$","span","Temporal Consistency",{"className":"page__taxonomy-item","children":["#","Temporal Consistency"]}],["$","span","Pre-trained 3D Models",{"className":"page__taxonomy-item","children":["#","Pre-trained 3D Models"]}],["$","span","VAE",{"className":"page__taxonomy-item","children":["#","VAE"]}]]}]]}]]}],["$","article","2025-10-8-Scaling_Code-Assisted_Chain-of-Thoughts_and_Instructions_for_Model_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Scaling_Code-Assisted_Chain-of-Thoughts_and_Instructions_for_Model_Reasoning/","children":"[논문리뷰] Scaling Code-Assisted Chain-of-Thoughts and Instructions for Model Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhuoshi Pan이 [arXiv]에 게시한 'Scaling Code-Assisted Chain-of-Thoughts and Instructions for Model Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Code-Assisted Reasoning",{"className":"page__taxonomy-item","children":["#","Code-Assisted Reasoning"]}],["$","span","Chain-of-Thought (CoT)",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought (CoT)"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Self-Verification",{"className":"page__taxonomy-item","children":["#","Self-Verification"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}]]}]]}]]}],["$","article","2025-10-8-Revisiting_Modeling_and_Evaluation_Approaches_in_Speech_Emotion_Recognition_Considering_Subjectivity_of_Annotators_and_Ambiguity_of_Emotions",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Revisiting_Modeling_and_Evaluation_Approaches_in_Speech_Emotion_Recognition_Considering_Subjectivity_of_Annotators_and_Ambiguity_of_Emotions/","children":"[논문리뷰] Revisiting Modeling and Evaluation Approaches in Speech Emotion Recognition: Considering Subjectivity of Annotators and Ambiguity of Emotions"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Revisiting Modeling and Evaluation Approaches in Speech Emotion Recognition: Considering Subjectivity of Annotators and Ambiguity of Emotions' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Speech Emotion Recognition",{"className":"page__taxonomy-item","children":["#","Speech Emotion Recognition"]}],["$","span","Annotator Subjectivity",{"className":"page__taxonomy-item","children":["#","Annotator Subjectivity"]}],["$","span","Emotion Ambiguity",{"className":"page__taxonomy-item","children":["#","Emotion Ambiguity"]}],["$","span","Soft Labels",{"className":"page__taxonomy-item","children":["#","Soft Labels"]}],["$","span","Multi-label Classification",{"className":"page__taxonomy-item","children":["#","Multi-label Classification"]}],["$","span","Evaluation Metrics",{"className":"page__taxonomy-item","children":["#","Evaluation Metrics"]}],["$","span","Loss Functions",{"className":"page__taxonomy-item","children":["#","Loss Functions"]}]]}]]}]]}],["$","article","2025-10-8-Refusal_Falls_off_a_Cliff_How_Safety_Alignment_Fails_in_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Refusal_Falls_off_a_Cliff_How_Safety_Alignment_Fails_in_Reasoning/","children":"[논문리뷰] Refusal Falls off a Cliff: How Safety Alignment Fails in Reasoning?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Refusal Falls off a Cliff: How Safety Alignment Fails in Reasoning?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Safety Alignment",{"className":"page__taxonomy-item","children":["#","Safety Alignment"]}],["$","span","Large Reasoning Models",{"className":"page__taxonomy-item","children":["#","Large Reasoning Models"]}],["$","span","Mechanistic Interpretability",{"className":"page__taxonomy-item","children":["#","Mechanistic Interpretability"]}],["$","span","Refusal Cliff",{"className":"page__taxonomy-item","children":["#","Refusal Cliff"]}],["$","span","Attention Heads",{"className":"page__taxonomy-item","children":["#","Attention Heads"]}],["$","span","Data Selection",{"className":"page__taxonomy-item","children":["#","Data Selection"]}],["$","span","Linear Probing",{"className":"page__taxonomy-item","children":["#","Linear Probing"]}]]}]]}]]}],["$","article","2025-10-8-Presenting_a_Paper_is_an_Art_Self-Improvement_Aesthetic_Agents_for_Academic_Presentations",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Presenting_a_Paper_is_an_Art_Self-Improvement_Aesthetic_Agents_for_Academic_Presentations/","children":"[논문리뷰] Presenting a Paper is an Art: Self-Improvement Aesthetic Agents for Academic Presentations"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Presenting a Paper is an Art: Self-Improvement Aesthetic Agents for Academic Presentations' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Self-Improvement Agent",{"className":"page__taxonomy-item","children":["#","Self-Improvement Agent"]}],["$","span","Academic Presentation",{"className":"page__taxonomy-item","children":["#","Academic Presentation"]}],["$","span","Aesthetic Evaluation",{"className":"page__taxonomy-item","children":["#","Aesthetic Evaluation"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Multi-task Learning",{"className":"page__taxonomy-item","children":["#","Multi-task Learning"]}],["$","span","Presentation Generation",{"className":"page__taxonomy-item","children":["#","Presentation Generation"]}],["$","span","LLM-based Agents",{"className":"page__taxonomy-item","children":["#","LLM-based Agents"]}],["$","span","Human Feedback",{"className":"page__taxonomy-item","children":["#","Human Feedback"]}]]}]]}]]}],["$","article","2025-10-8-OneFlow_Concurrent_Mixed-Modal_and_Interleaved_Generation_with_Edit_Flows",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-OneFlow_Concurrent_Mixed-Modal_and_Interleaved_Generation_with_Edit_Flows/","children":"[논문리뷰] OneFlow: Concurrent Mixed-Modal and Interleaved Generation with Edit Flows"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'OneFlow: Concurrent Mixed-Modal and Interleaved Generation with Edit Flows' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Non-Autoregressive",{"className":"page__taxonomy-item","children":["#","Non-Autoregressive"]}],["$","span","Multimodal Generation",{"className":"page__taxonomy-item","children":["#","Multimodal Generation"]}],["$","span","Edit Flows",{"className":"page__taxonomy-item","children":["#","Edit Flows"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Interleaved Generation",{"className":"page__taxonomy-item","children":["#","Interleaved Generation"]}],["$","span","Text-to-Image Synthesis",{"className":"page__taxonomy-item","children":["#","Text-to-Image Synthesis"]}],["$","span","Unified Models",{"className":"page__taxonomy-item","children":["#","Unified Models"]}]]}]]}]]}],["$","article","2025-10-8-No_Tokens_Wasted_Leveraging_Long_Context_in_Biomedical_Vision-Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-No_Tokens_Wasted_Leveraging_Long_Context_in_Biomedical_Vision-Language_Models/","children":"[논문리뷰] No Tokens Wasted: Leveraging Long Context in Biomedical Vision-Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiao Xiao Sun이 [arXiv]에 게시한 'No Tokens Wasted: Leveraging Long Context in Biomedical Vision-Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Biomedical Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Biomedical Vision-Language Models"]}],["$","span","Long-context Modeling",{"className":"page__taxonomy-item","children":["#","Long-context Modeling"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Token Efficiency",{"className":"page__taxonomy-item","children":["#","Token Efficiency"]}],["$","span","Zero-shot Classification",{"className":"page__taxonomy-item","children":["#","Zero-shot Classification"]}],["$","span","Medical Image Retrieval",{"className":"page__taxonomy-item","children":["#","Medical Image Retrieval"]}]]}]]}]]}],["$","article","2025-10-8-MixReasoning_Switching_Modes_to_Think",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-MixReasoning_Switching_Modes_to_Think/","children":"[논문리뷰] MixReasoning: Switching Modes to Think"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'MixReasoning: Switching Modes to Think' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Reasoning",{"className":"page__taxonomy-item","children":["#","LLM Reasoning"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Efficiency",{"className":"page__taxonomy-item","children":["#","Efficiency"]}],["$","span","LoRA",{"className":"page__taxonomy-item","children":["#","LoRA"]}],["$","span","Adaptive Reasoning",{"className":"page__taxonomy-item","children":["#","Adaptive Reasoning"]}],["$","span","Token Uncertainty",{"className":"page__taxonomy-item","children":["#","Token Uncertainty"]}],["$","span","Dynamic Switching",{"className":"page__taxonomy-item","children":["#","Dynamic Switching"]}],["$","span","Reasoning Compression",{"className":"page__taxonomy-item","children":["#","Reasoning Compression"]}]]}]]}]]}],["$","article","2025-10-8-Mixing_Mechanisms_How_Language_Models_Retrieve_Bound_Entities_In-Context",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Mixing_Mechanisms_How_Language_Models_Retrieve_Bound_Entities_In-Context/","children":"[논문리뷰] Mixing Mechanisms: How Language Models Retrieve Bound Entities In-Context"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Mixing Mechanisms: How Language Models Retrieve Bound Entities In-Context' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Language Models",{"className":"page__taxonomy-item","children":["#","Language Models"]}],["$","span","In-Context Learning",{"className":"page__taxonomy-item","children":["#","In-Context Learning"]}],["$","span","Entity Binding",{"className":"page__taxonomy-item","children":["#","Entity Binding"]}],["$","span","Mechanistic Interpretability",{"className":"page__taxonomy-item","children":["#","Mechanistic Interpretability"]}],["$","span","Causal Abstraction",{"className":"page__taxonomy-item","children":["#","Causal Abstraction"]}],["$","span","Long-Context Reasoning",{"className":"page__taxonomy-item","children":["#","Long-Context Reasoning"]}],["$","span","Positional Encoding",{"className":"page__taxonomy-item","children":["#","Positional Encoding"]}],["$","span","Information Retrieval",{"className":"page__taxonomy-item","children":["#","Information Retrieval"]}]]}]]}]]}],["$","article","2025-10-8-Margin_Adaptive_DPO_Leveraging_Reward_Model_for_Granular_Control_in_Preference_Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Margin_Adaptive_DPO_Leveraging_Reward_Model_for_Granular_Control_in_Preference_Optimization/","children":"[논문리뷰] Margin Adaptive DPO: Leveraging Reward Model for Granular Control in Preference Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"sirano1004이 [arXiv]에 게시한 'Margin Adaptive DPO: Leveraging Reward Model for Granular Control in Preference Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Direct Preference Optimization",{"className":"page__taxonomy-item","children":["#","Direct Preference Optimization"]}],["$","span","Preference Alignment",{"className":"page__taxonomy-item","children":["#","Preference Alignment"]}],["$","span","Adaptive Regularization",{"className":"page__taxonomy-item","children":["#","Adaptive Regularization"]}],["$","span","Reward Model",{"className":"page__taxonomy-item","children":["#","Reward Model"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Sentiment Generation",{"className":"page__taxonomy-item","children":["#","Sentiment Generation"]}]]}]]}]]}],["$","article","2025-10-8-LightCache_Memory-Efficient_Training-Free_Acceleration_for_Video_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-LightCache_Memory-Efficient_Training-Free_Acceleration_for_Video_Generation/","children":"[논문리뷰] LightCache: Memory-Efficient, Training-Free Acceleration for Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zheng Zhan이 [arXiv]에 게시한 'LightCache: Memory-Efficient, Training-Free Acceleration for Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Memory Efficiency",{"className":"page__taxonomy-item","children":["#","Memory Efficiency"]}],["$","span","Inference Acceleration",{"className":"page__taxonomy-item","children":["#","Inference Acceleration"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}],["$","span","Cache Mechanism",{"className":"page__taxonomy-item","children":["#","Cache Mechanism"]}],["$","span","GPU Optimization",{"className":"page__taxonomy-item","children":["#","GPU Optimization"]}]]}]]}]]}],["$","article","2025-10-8-Less_is_More_Recursive_Reasoning_with_Tiny_Networks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Less_is_More_Recursive_Reasoning_with_Tiny_Networks/","children":"[논문리뷰] Less is More: Recursive Reasoning with Tiny Networks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Less is More: Recursive Reasoning with Tiny Networks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Recursive Reasoning",{"className":"page__taxonomy-item","children":["#","Recursive Reasoning"]}],["$","span","Tiny Networks",{"className":"page__taxonomy-item","children":["#","Tiny Networks"]}],["$","span","Deep Supervision",{"className":"page__taxonomy-item","children":["#","Deep Supervision"]}],["$","span","Hierarchical Reasoning Model (HRM)",{"className":"page__taxonomy-item","children":["#","Hierarchical Reasoning Model (HRM)"]}],["$","span","Sudoku-Extreme",{"className":"page__taxonomy-item","children":["#","Sudoku-Extreme"]}],["$","span","ARC-AGI",{"className":"page__taxonomy-item","children":["#","ARC-AGI"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Parameter Efficiency",{"className":"page__taxonomy-item","children":["#","Parameter Efficiency"]}]]}]]}]]}],["$","article","2025-10-8-In-the-Flow_Agentic_System_Optimization_for_Effective_Planning_and_Tool_Use",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-In-the-Flow_Agentic_System_Optimization_for_Effective_Planning_and_Tool_Use/","children":"[논문리뷰] In-the-Flow Agentic System Optimization for Effective Planning and Tool Use"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'In-the-Flow Agentic System Optimization for Effective Planning and Tool Use' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic Systems",{"className":"page__taxonomy-item","children":["#","Agentic Systems"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","On-policy Optimization",{"className":"page__taxonomy-item","children":["#","On-policy Optimization"]}],["$","span","Flow-based Group Refined Policy Optimization (Flow-GRPO)",{"className":"page__taxonomy-item","children":["#","Flow-based Group Refined Policy Optimization (Flow-GRPO)"]}],["$","span","Multi-turn Reasoning",{"className":"page__taxonomy-item","children":["#","Multi-turn Reasoning"]}]]}]]}]]}],["$","article","2025-10-8-Human3R_Everyone_Everywhere_All_at_Once",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Human3R_Everyone_Everywhere_All_at_Once/","children":"[논문리뷰] Human3R: Everyone Everywhere All at Once"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuliang Xiu이 [arXiv]에 게시한 'Human3R: Everyone Everywhere All at Once' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","4D Human-Scene Reconstruction",{"className":"page__taxonomy-item","children":["#","4D Human-Scene Reconstruction"]}],["$","span","Online Reconstruction",{"className":"page__taxonomy-item","children":["#","Online Reconstruction"]}],["$","span","Multi-person",{"className":"page__taxonomy-item","children":["#","Multi-person"]}],["$","span","SMPL-X",{"className":"page__taxonomy-item","children":["#","SMPL-X"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Visual Prompt Tuning",{"className":"page__taxonomy-item","children":["#","Visual Prompt Tuning"]}],["$","span","Real-time",{"className":"page__taxonomy-item","children":["#","Real-time"]}],["$","span","Foundation Model",{"className":"page__taxonomy-item","children":["#","Foundation Model"]}]]}]]}]]}],["$","article","2025-10-8-HoloScene_Simulation-Ready_Interactive_3D_Worlds_from_a_Single_Video",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-HoloScene_Simulation-Ready_Interactive_3D_Worlds_from_a_Single_Video/","children":"[논문리뷰] HoloScene: Simulation-Ready Interactive 3D Worlds from a Single Video"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Katelyn Gao이 [arXiv]에 게시한 'HoloScene: Simulation-Ready Interactive 3D Worlds from a Single Video' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Reconstruction",{"className":"page__taxonomy-item","children":["#","3D Reconstruction"]}],["$","span","Digital Twin",{"className":"page__taxonomy-item","children":["#","Digital Twin"]}],["$","span","Scene Graph",{"className":"page__taxonomy-item","children":["#","Scene Graph"]}],["$","span","Physical Simulation",{"className":"page__taxonomy-item","children":["#","Physical Simulation"]}],["$","span","Interactive Environments",{"className":"page__taxonomy-item","children":["#","Interactive Environments"]}],["$","span","Single Video Reconstruction",{"className":"page__taxonomy-item","children":["#","Single Video Reconstruction"]}],["$","span","Neural Rendering",{"className":"page__taxonomy-item","children":["#","Neural Rendering"]}]]}]]}]]}],["$","article","2025-10-8-HalluGuard_Evidence-Grounded_Small_Reasoning_Models_to_Mitigate_Hallucinations_in_Retrieval-Augmented_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-HalluGuard_Evidence-Grounded_Small_Reasoning_Models_to_Mitigate_Hallucinations_in_Retrieval-Augmented_Generation/","children":"[논문리뷰] HalluGuard: Evidence-Grounded Small Reasoning Models to Mitigate Hallucinations in Retrieval-Augmented Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Radu State이 [arXiv]에 게시한 'HalluGuard: Evidence-Grounded Small Reasoning Models to Mitigate Hallucinations in Retrieval-Augmented Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Hallucination Detection",{"className":"page__taxonomy-item","children":["#","Hallucination Detection"]}],["$","span","Retrieval-Augmented Generation (RAG)",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation (RAG)"]}],["$","span","Small Reasoning Model (SRM)",{"className":"page__taxonomy-item","children":["#","Small Reasoning Model (SRM)"]}],["$","span","Preference Fine-tuning",{"className":"page__taxonomy-item","children":["#","Preference Fine-tuning"]}],["$","span","ORPO",{"className":"page__taxonomy-item","children":["#","ORPO"]}],["$","span","Evidence Grounding",{"className":"page__taxonomy-item","children":["#","Evidence Grounding"]}],["$","span","Fact-checking",{"className":"page__taxonomy-item","children":["#","Fact-checking"]}]]}]]}]]}],["$","article","2025-10-8-Fathom-DeepResearch_Unlocking_Long_Horizon_Information_Retrieval_and_Synthesis_for_SLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Fathom-DeepResearch_Unlocking_Long_Horizon_Information_Retrieval_and_Synthesis_for_SLMs/","children":"[논문리뷰] Fathom-DeepResearch: Unlocking Long Horizon Information Retrieval and Synthesis for SLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Fathom-DeepResearch: Unlocking Long Horizon Information Retrieval and Synthesis for SLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","DeepResearch Agents",{"className":"page__taxonomy-item","children":["#","DeepResearch Agents"]}],["$","span","Tool-integrated Reasoning",{"className":"page__taxonomy-item","children":["#","Tool-integrated Reasoning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Information Retrieval",{"className":"page__taxonomy-item","children":["#","Information Retrieval"]}],["$","span","Information Synthesis",{"className":"page__taxonomy-item","children":["#","Information Synthesis"]}],["$","span","Multi-agent Self-play",{"className":"page__taxonomy-item","children":["#","Multi-agent Self-play"]}],["$","span","Reward Shaping",{"className":"page__taxonomy-item","children":["#","Reward Shaping"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}]]}]]}]]}],["$","article","2025-10-8-Fast-dLLM_v2_Efficient_Block-Diffusion_LLM",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Fast-dLLM_v2_Efficient_Block-Diffusion_LLM/","children":"[논문리뷰] Fast-dLLM v2: Efficient Block-Diffusion LLM"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Fast-dLLM v2: Efficient Block-Diffusion LLM' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion LLMs",{"className":"page__taxonomy-item","children":["#","Diffusion LLMs"]}],["$","span","Inference Acceleration",{"className":"page__taxonomy-item","children":["#","Inference Acceleration"]}],["$","span","Parallel Decoding",{"className":"page__taxonomy-item","children":["#","Parallel Decoding"]}],["$","span","Autoregressive Models",{"className":"page__taxonomy-item","children":["#","Autoregressive Models"]}],["$","span","Caching",{"className":"page__taxonomy-item","children":["#","Caching"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Block-wise Attention",{"className":"page__taxonomy-item","children":["#","Block-wise Attention"]}]]}]]}]]}],["$","article","2025-10-8-Equilibrium_Matching_Generative_Modeling_with_Implicit_Energy-Based_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Equilibrium_Matching_Generative_Modeling_with_Implicit_Energy-Based_Models/","children":"[논문리뷰] Equilibrium Matching: Generative Modeling with Implicit Energy-Based Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Equilibrium Matching: Generative Modeling with Implicit Energy-Based Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Equilibrium Dynamics",{"className":"page__taxonomy-item","children":["#","Equilibrium Dynamics"]}],["$","span","Energy-Based Models (EBMs)",{"className":"page__taxonomy-item","children":["#","Energy-Based Models (EBMs)"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Optimization-Based Sampling",{"className":"page__taxonomy-item","children":["#","Optimization-Based Sampling"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}]]}]]}]]}],["$","article","2025-10-8-EgoNight_Towards_Egocentric_Vision_Understanding_at_Night_with_a_Challenging_Benchmark",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-EgoNight_Towards_Egocentric_Vision_Understanding_at_Night_with_a_Challenging_Benchmark/","children":"[논문리뷰] EgoNight: Towards Egocentric Vision Understanding at Night with a Challenging Benchmark"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Tianwen Qian이 [arXiv]에 게시한 'EgoNight: Towards Egocentric Vision Understanding at Night with a Challenging Benchmark' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Egocentric Vision",{"className":"page__taxonomy-item","children":["#","Egocentric Vision"]}],["$","span","Nighttime Conditions",{"className":"page__taxonomy-item","children":["#","Nighttime Conditions"]}],["$","span","Visual Question Answering (VQA)",{"className":"page__taxonomy-item","children":["#","Visual Question Answering (VQA)"]}],["$","span","Day-Night Alignment",{"className":"page__taxonomy-item","children":["#","Day-Night Alignment"]}],["$","span","Multimodal Large Language Models (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models (MLLMs)"]}],["$","span","Depth Estimation",{"className":"page__taxonomy-item","children":["#","Depth Estimation"]}],["$","span","Correspondence Retrieval",{"className":"page__taxonomy-item","children":["#","Correspondence Retrieval"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}]]}]]}]]}],["$","article","2025-10-8-DRIFT_Learning_from_Abundant_User_Dissatisfaction_in_Real-World_Preference_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-DRIFT_Learning_from_Abundant_User_Dissatisfaction_in_Real-World_Preference_Learning/","children":"[논문리뷰] DRIFT: Learning from Abundant User Dissatisfaction in Real-World Preference Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zheli Liu이 [arXiv]에 게시한 'DRIFT: Learning from Abundant User Dissatisfaction in Real-World Preference Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Preference Learning",{"className":"page__taxonomy-item","children":["#","Preference Learning"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","User Feedback",{"className":"page__taxonomy-item","children":["#","User Feedback"]}],["$","span","Dissatisfaction Signals",{"className":"page__taxonomy-item","children":["#","Dissatisfaction Signals"]}],["$","span","DPO",{"className":"page__taxonomy-item","children":["#","DPO"]}],["$","span","Iterative Training",{"className":"page__taxonomy-item","children":["#","Iterative Training"]}],["$","span","RLHF",{"className":"page__taxonomy-item","children":["#","RLHF"]}],["$","span","Exploration",{"className":"page__taxonomy-item","children":["#","Exploration"]}]]}]]}]]}],["$","article","2025-10-8-Drax_Speech_Recognition_with_Discrete_Flow_Matching",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Drax_Speech_Recognition_with_Discrete_Flow_Matching/","children":"[논문리뷰] Drax: Speech Recognition with Discrete Flow Matching"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Drax: Speech Recognition with Discrete Flow Matching' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Automatic Speech Recognition (ASR)",{"className":"page__taxonomy-item","children":["#","Automatic Speech Recognition (ASR)"]}],["$","span","Discrete Flow Matching (DFM)",{"className":"page__taxonomy-item","children":["#","Discrete Flow Matching (DFM)"]}],["$","span","Non-Autoregressive (NAR)",{"className":"page__taxonomy-item","children":["#","Non-Autoregressive (NAR)"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Tri-mixture Probability Path",{"className":"page__taxonomy-item","children":["#","Tri-mixture Probability Path"]}],["$","span","Parallel Decoding",{"className":"page__taxonomy-item","children":["#","Parallel Decoding"]}],["$","span","Accuracy-Efficiency Trade-off",{"className":"page__taxonomy-item","children":["#","Accuracy-Efficiency Trade-off"]}],["$","span","Speech Synthesis",{"className":"page__taxonomy-item","children":["#","Speech Synthesis"]}]]}]]}]]}],["$","article","2025-10-8-Distributional_Semantics_Tracing_A_Framework_for_Explaining_Hallucinations_in_Large_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Distributional_Semantics_Tracing_A_Framework_for_Explaining_Hallucinations_in_Large_Language_Models/","children":"[논문리뷰] Distributional Semantics Tracing: A Framework for Explaining Hallucinations in Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jacobo Azcona이 [arXiv]에 게시한 'Distributional Semantics Tracing: A Framework for Explaining Hallucinations in Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Hallucinations",{"className":"page__taxonomy-item","children":["#","LLM Hallucinations"]}],["$","span","Mechanistic Interpretability",{"className":"page__taxonomy-item","children":["#","Mechanistic Interpretability"]}],["$","span","Distributional Semantics Tracing (DST)",{"className":"page__taxonomy-item","children":["#","Distributional Semantics Tracing (DST)"]}],["$","span","Dual-Process Theory",{"className":"page__taxonomy-item","children":["#","Dual-Process Theory"]}],["$","span","Semantic Drift",{"className":"page__taxonomy-item","children":["#","Semantic Drift"]}],["$","span","Commitment Layer",{"className":"page__taxonomy-item","children":["#","Commitment Layer"]}],["$","span","Faithfulness Score",{"className":"page__taxonomy-item","children":["#","Faithfulness Score"]}]]}]]}]]}],["$","article","2025-10-8-Discrete_Diffusion_Models_with_MLLMs_for_Unified_Medical_Multimodal_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Discrete_Diffusion_Models_with_MLLMs_for_Unified_Medical_Multimodal_Generation/","children":"[논문리뷰] Discrete Diffusion Models with MLLMs for Unified Medical Multimodal Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Discrete Diffusion Models with MLLMs for Unified Medical Multimodal Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Discrete Diffusion Models",{"className":"page__taxonomy-item","children":["#","Discrete Diffusion Models"]}],["$","span","Multimodal Large Language Models (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models (MLLMs)"]}],["$","span","Medical Image Generation",{"className":"page__taxonomy-item","children":["#","Medical Image Generation"]}],["$","span","Medical Report Generation",{"className":"page__taxonomy-item","children":["#","Medical Report Generation"]}],["$","span","Multimodal Generation",{"className":"page__taxonomy-item","children":["#","Multimodal Generation"]}],["$","span","Medical AI",{"className":"page__taxonomy-item","children":["#","Medical AI"]}],["$","span","Cross-modal Alignment",{"className":"page__taxonomy-item","children":["#","Cross-modal Alignment"]}]]}]]}]]}],["$","article","2025-10-8-Demystifying_deep_search_a_holistic_evaluation_with_hint-free_multi-hop_questions_and_factorised_metrics",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Demystifying_deep_search_a_holistic_evaluation_with_hint-free_multi-hop_questions_and_factorised_metrics/","children":"[논문리뷰] Demystifying deep search: a holistic evaluation with hint-free multi-hop questions and factorised metrics"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Demystifying deep search: a holistic evaluation with hint-free multi-hop questions and factorised metrics' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Deep Search",{"className":"page__taxonomy-item","children":["#","Deep Search"]}],["$","span","Multi-hop Reasoning",{"className":"page__taxonomy-item","children":["#","Multi-hop Reasoning"]}],["$","span","Evaluation Benchmark",{"className":"page__taxonomy-item","children":["#","Evaluation Benchmark"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","Web Agents",{"className":"page__taxonomy-item","children":["#","Web Agents"]}],["$","span","Diagnostic Metrics",{"className":"page__taxonomy-item","children":["#","Diagnostic Metrics"]}],["$","span","Knowledge Utilization",{"className":"page__taxonomy-item","children":["#","Knowledge Utilization"]}],["$","span","Hint-Free Questions",{"className":"page__taxonomy-item","children":["#","Hint-Free Questions"]}]]}]]}]]}],["$","article","2025-10-8-Deforming_Videos_to_Masks_Flow_Matching_for_Referring_Video_Segmentation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Deforming_Videos_to_Masks_Flow_Matching_for_Referring_Video_Segmentation/","children":"[논문리뷰] Deforming Videos to Masks: Flow Matching for Referring Video Segmentation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chengzu Li이 [arXiv]에 게시한 'Deforming Videos to Masks: Flow Matching for Referring Video Segmentation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Referring Video Object Segmentation",{"className":"page__taxonomy-item","children":["#","Referring Video Object Segmentation"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Video Segmentation",{"className":"page__taxonomy-item","children":["#","Video Segmentation"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Text-to-Video",{"className":"page__taxonomy-item","children":["#","Text-to-Video"]}],["$","span","Continuous Flow",{"className":"page__taxonomy-item","children":["#","Continuous Flow"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}]]}]]}]]}],["$","article","2025-10-8-CoDA_Coding_LM_via_Diffusion_Adaptation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-CoDA_Coding_LM_via_Diffusion_Adaptation/","children":"[논문리뷰] CoDA: Coding LM via Diffusion Adaptation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'CoDA: Coding LM via Diffusion Adaptation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Language Models",{"className":"page__taxonomy-item","children":["#","Diffusion Language Models"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","Bidirectional Decoding",{"className":"page__taxonomy-item","children":["#","Bidirectional Decoding"]}],["$","span","Text Infilling",{"className":"page__taxonomy-item","children":["#","Text Infilling"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}],["$","span","Lightweight Models",{"className":"page__taxonomy-item","children":["#","Lightweight Models"]}],["$","span","TPU Training",{"className":"page__taxonomy-item","children":["#","TPU Training"]}]]}]]}]]}],["$","article","2025-10-8-CCD_Mitigating_Hallucinations_in_Radiology_MLLMs_via_Clinical_Contrastive_Decoding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-CCD_Mitigating_Hallucinations_in_Radiology_MLLMs_via_Clinical_Contrastive_Decoding/","children":"[논문리뷰] CCD: Mitigating Hallucinations in Radiology MLLMs via Clinical Contrastive Decoding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'CCD: Mitigating Hallucinations in Radiology MLLMs via Clinical Contrastive Decoding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models (MLLMs)"]}],["$","span","Radiology Report Generation (RRG)",{"className":"page__taxonomy-item","children":["#","Radiology Report Generation (RRG)"]}],["$","span","Medical Hallucinations",{"className":"page__taxonomy-item","children":["#","Medical Hallucinations"]}],["$","span","Contrastive Decoding",{"className":"page__taxonomy-item","children":["#","Contrastive Decoding"]}],["$","span","Training-free Inference",{"className":"page__taxonomy-item","children":["#","Training-free Inference"]}],["$","span","Clinical AI",{"className":"page__taxonomy-item","children":["#","Clinical AI"]}],["$","span","Visual Question Answering (VQA)",{"className":"page__taxonomy-item","children":["#","Visual Question Answering (VQA)"]}]]}]]}]]}],["$","article","2025-10-8-CARE_Cognitive-reasoning_Augmented_Reinforcement_for_Emotional_Support_Conversation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-CARE_Cognitive-reasoning_Augmented_Reinforcement_for_Emotional_Support_Conversation/","children":"[논문리뷰] CARE: Cognitive-reasoning Augmented Reinforcement for Emotional Support Conversation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'CARE: Cognitive-reasoning Augmented Reinforcement for Emotional Support Conversation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Emotional Support Conversation",{"className":"page__taxonomy-item","children":["#","Emotional Support Conversation"]}],["$","span","Cognitive Reasoning",{"className":"page__taxonomy-item","children":["#","Cognitive Reasoning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Dialogue Generation",{"className":"page__taxonomy-item","children":["#","Dialogue Generation"]}],["$","span","Natural Language Processing",{"className":"page__taxonomy-item","children":["#","Natural Language Processing"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Psychological Support",{"className":"page__taxonomy-item","children":["#","Psychological Support"]}]]}]]}]]}],["$","article","2025-10-8-BIRD-INTERACT_Re-imagining_Text-to-SQL_Evaluation_for_Large_Language_Models_via_Lens_of_Dynamic_Interactions",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-BIRD-INTERACT_Re-imagining_Text-to-SQL_Evaluation_for_Large_Language_Models_via_Lens_of_Dynamic_Interactions/","children":"[논문리뷰] BIRD-INTERACT: Re-imagining Text-to-SQL Evaluation for Large Language Models via Lens of Dynamic Interactions"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shipei Lin이 [arXiv]에 게시한 'BIRD-INTERACT: Re-imagining Text-to-SQL Evaluation for Large Language Models via Lens of Dynamic Interactions' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-SQL",{"className":"page__taxonomy-item","children":["#","Text-to-SQL"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Multi-turn Interaction",{"className":"page__taxonomy-item","children":["#","Multi-turn Interaction"]}],["$","span","Dynamic Environment",{"className":"page__taxonomy-item","children":["#","Dynamic Environment"]}],["$","span","User Simulator",{"className":"page__taxonomy-item","children":["#","User Simulator"]}],["$","span","Ambiguity Resolution",{"className":"page__taxonomy-item","children":["#","Ambiguity Resolution"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}]]}]]}]]}],["$","article","2025-10-8-Benchmark_It_Yourself_BIY_Preparing_a_Dataset_and_Benchmarking_AI_Models_for_Scatterplot-Related_Tasks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-Benchmark_It_Yourself_BIY_Preparing_a_Dataset_and_Benchmarking_AI_Models_for_Scatterplot-Related_Tasks/","children":"[논문리뷰] Benchmark It Yourself (BIY): Preparing a Dataset and Benchmarking AI Models for Scatterplot-Related Tasks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Pedro Bizarro이 [arXiv]에 게시한 'Benchmark It Yourself (BIY): Preparing a Dataset and Benchmarking AI Models for Scatterplot-Related Tasks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Scatterplot Analysis",{"className":"page__taxonomy-item","children":["#","Scatterplot Analysis"]}],["$","span","AI Benchmarking",{"className":"page__taxonomy-item","children":["#","AI Benchmarking"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Synthetic Data Generation",{"className":"page__taxonomy-item","children":["#","Synthetic Data Generation"]}],["$","span","Cluster Detection",{"className":"page__taxonomy-item","children":["#","Cluster Detection"]}],["$","span","Outlier Detection",{"className":"page__taxonomy-item","children":["#","Outlier Detection"]}],["$","span","Data Visualization",{"className":"page__taxonomy-item","children":["#","Data Visualization"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}]]}]]}]]}],["$","article","2025-10-8-A_Contextual_Quality_Reward_Model_for_Reliable_and_Efficient_Best-of-N_Sampling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-A_Contextual_Quality_Reward_Model_for_Reliable_and_Efficient_Best-of-N_Sampling/","children":"[논문리뷰] A Contextual Quality Reward Model for Reliable and Efficient Best-of-N Sampling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"sirano1004이 [arXiv]에 게시한 'A Contextual Quality Reward Model for Reliable and Efficient Best-of-N Sampling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reward Model",{"className":"page__taxonomy-item","children":["#","Reward Model"]}],["$","span","Best-of-N Sampling",{"className":"page__taxonomy-item","children":["#","Best-of-N Sampling"]}],["$","span","Preference Alignment",{"className":"page__taxonomy-item","children":["#","Preference Alignment"]}],["$","span","Contextual Acceptability",{"className":"page__taxonomy-item","children":["#","Contextual Acceptability"]}],["$","span","Discrete Choice Model",{"className":"page__taxonomy-item","children":["#","Discrete Choice Model"]}],["$","span","Alignment Guardrail",{"className":"page__taxonomy-item","children":["#","Alignment Guardrail"]}],["$","span","Inference Accelerator",{"className":"page__taxonomy-item","children":["#","Inference Accelerator"]}]]}]]}]]}],["$","article","2025-10-8-ASPO_Asymmetric_Importance_Sampling_Policy_Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-ASPO_Asymmetric_Importance_Sampling_Policy_Optimization/","children":"[논문리뷰] ASPO: Asymmetric Importance Sampling Policy Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiu Li이 [arXiv]에 게시한 'ASPO: Asymmetric Importance Sampling Policy Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Importance Sampling",{"className":"page__taxonomy-item","children":["#","Importance Sampling"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","PPO-Clip",{"className":"page__taxonomy-item","children":["#","PPO-Clip"]}],["$","span","Outcome-Supervised RL",{"className":"page__taxonomy-item","children":["#","Outcome-Supervised RL"]}],["$","span","Token Weighting",{"className":"page__taxonomy-item","children":["#","Token Weighting"]}],["$","span","GRPO",{"className":"page__taxonomy-item","children":["#","GRPO"]}]]}]]}]]}],["$","article","2025-10-8-AInstein_Assessing_the_Feasibility_of_AI-Generated_Approaches_to_Research_Problems",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-8-AInstein_Assessing_the_Feasibility_of_AI-Generated_Approaches_to_Research_Problems/","children":"[논문리뷰] AInstein: Assessing the Feasibility of AI-Generated Approaches to Research Problems"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jose Dolz이 [arXiv]에 게시한 'AInstein: Assessing the Feasibility of AI-Generated Approaches to Research Problems' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-08 13:48:12+0900","children":"2025년 10월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Scientific Problem Solving",{"className":"page__taxonomy-item","children":["#","Scientific Problem Solving"]}],["$","span","AI Research",{"className":"page__taxonomy-item","children":["#","AI Research"]}],["$","span","Iterative Refinement",{"className":"page__taxonomy-item","children":["#","Iterative Refinement"]}],["$","span","Autonomous Agents",{"className":"page__taxonomy-item","children":["#","Autonomous Agents"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Evaluation Framework",{"className":"page__taxonomy-item","children":["#","Evaluation Framework"]}],["$","span","Problem Extraction",{"className":"page__taxonomy-item","children":["#","Problem Extraction"]}]]}]]}]]}],["$","article","2025-10-7-Watch_and_Learn_Learning_to_Use_Computers_from_Online_Videos",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Watch_and_Learn_Learning_to_Use_Computers_from_Online_Videos/","children":"[논문리뷰] Watch and Learn: Learning to Use Computers from Online Videos"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Oriana Riva이 [arXiv]에 게시한 'Watch and Learn: Learning to Use Computers from Online Videos' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Computer Use Agents",{"className":"page__taxonomy-item","children":["#","Computer Use Agents"]}],["$","span","Inverse Dynamics Model",{"className":"page__taxonomy-item","children":["#","Inverse Dynamics Model"]}],["$","span","UI Trajectories",{"className":"page__taxonomy-item","children":["#","UI Trajectories"]}],["$","span","Web Videos",{"className":"page__taxonomy-item","children":["#","Web Videos"]}],["$","span","In-Context Learning",{"className":"page__taxonomy-item","children":["#","In-Context Learning"]}],["$","span","Supervised Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","OSWorld Benchmark",{"className":"page__taxonomy-item","children":["#","OSWorld Benchmark"]}]]}]]}]]}],["$","article","2025-10-7-Video-LMM_Post-Training_A_Deep_Dive_into_Video_Reasoning_with_Large_Multimodal_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Video-LMM_Post-Training_A_Deep_Dive_into_Video_Reasoning_with_Large_Multimodal_Models/","children":"[논문리뷰] Video-LMM Post-Training: A Deep Dive into Video Reasoning with Large Multimodal Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"zeliang0426이 [arXiv]에 게시한 'Video-LMM Post-Training: A Deep Dive into Video Reasoning with Large Multimodal Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Reasoning",{"className":"page__taxonomy-item","children":["#","Video Reasoning"]}],["$","span","Large Multimodal Models (LMMs)",{"className":"page__taxonomy-item","children":["#","Large Multimodal Models (LMMs)"]}],["$","span","Post-training",{"className":"page__taxonomy-item","children":["#","Post-training"]}],["$","span","Supervised Fine-tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning (SFT)"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Test-Time Scaling (TTS)",{"className":"page__taxonomy-item","children":["#","Test-Time Scaling (TTS)"]}],["$","span","Chain-of-Thought (CoT)",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought (CoT)"]}]]}]]}]]}],["$","article","2025-10-7-VChain_Chain-of-Visual-Thought_for_Reasoning_in_Video_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-VChain_Chain-of-Visual-Thought_for_Reasoning_in_Video_Generation/","children":"[논문리뷰] VChain: Chain-of-Visual-Thought for Reasoning in Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Paul Debevec이 [arXiv]에 게시한 'VChain: Chain-of-Visual-Thought for Reasoning in Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Multimodal Models",{"className":"page__taxonomy-item","children":["#","Multimodal Models"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Inference-Time Tuning",{"className":"page__taxonomy-item","children":["#","Inference-Time Tuning"]}],["$","span","Sparse Supervision",{"className":"page__taxonomy-item","children":["#","Sparse Supervision"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Keyframe Generation",{"className":"page__taxonomy-item","children":["#","Keyframe Generation"]}]]}]]}]]}],["$","article","2025-10-7-Utility-Learning_Tension_in_Self-Modifying_Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Utility-Learning_Tension_in_Self-Modifying_Agents/","children":"[논문리뷰] Utility-Learning Tension in Self-Modifying Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Peter Jin이 [arXiv]에 게시한 'Utility-Learning Tension in Self-Modifying Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Self-Modifying Agents",{"className":"page__taxonomy-item","children":["#","Self-Modifying Agents"]}],["$","span","PAC Learnability",{"className":"page__taxonomy-item","children":["#","PAC Learnability"]}],["$","span","VC Dimension",{"className":"page__taxonomy-item","children":["#","VC Dimension"]}],["$","span","Capacity Bounds",{"className":"page__taxonomy-item","children":["#","Capacity Bounds"]}],["$","span","Metacognition",{"className":"page__taxonomy-item","children":["#","Metacognition"]}],["$","span","Architectural Search",{"className":"page__taxonomy-item","children":["#","Architectural Search"]}],["$","span","Algorithmic Stability",{"className":"page__taxonomy-item","children":["#","Algorithmic Stability"]}],["$","span","Generalization Theory",{"className":"page__taxonomy-item","children":["#","Generalization Theory"]}]]}]]}]]}],["$","article","2025-10-7-Thai_Semantic_End-of-Turn_Detection_for_Real-Time_Voice_Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Thai_Semantic_End-of-Turn_Detection_for_Real-Time_Voice_Agents/","children":"[논문리뷰] Thai Semantic End-of-Turn Detection for Real-Time Voice Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Monthol Charattrakool이 [arXiv]에 게시한 'Thai Semantic End-of-Turn Detection for Real-Time Voice Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","End-of-Turn Detection",{"className":"page__taxonomy-item","children":["#","End-of-Turn Detection"]}],["$","span","Thai NLP",{"className":"page__taxonomy-item","children":["#","Thai NLP"]}],["$","span","Voice Agents",{"className":"page__taxonomy-item","children":["#","Voice Agents"]}],["$","span","Real-time Inference",{"className":"page__taxonomy-item","children":["#","Real-time Inference"]}],["$","span","Transformer Models",{"className":"page__taxonomy-item","children":["#","Transformer Models"]}],["$","span","Few-shot Learning",{"className":"page__taxonomy-item","children":["#","Few-shot Learning"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Latency Optimization",{"className":"page__taxonomy-item","children":["#","Latency Optimization"]}]]}]]}]]}],["$","article","2025-10-7-SwiReasoning_Switch-Thinking_in_Latent_and_Explicit_for_Pareto-Superior_Reasoning_LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-SwiReasoning_Switch-Thinking_in_Latent_and_Explicit_for_Pareto-Superior_Reasoning_LLMs/","children":"[논문리뷰] SwiReasoning: Switch-Thinking in Latent and Explicit for Pareto-Superior Reasoning LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'SwiReasoning: Switch-Thinking in Latent and Explicit for Pareto-Superior Reasoning LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Reasoning",{"className":"page__taxonomy-item","children":["#","LLM Reasoning"]}],["$","span","Latent Thinking",{"className":"page__taxonomy-item","children":["#","Latent Thinking"]}],["$","span","Explicit Thinking",{"className":"page__taxonomy-item","children":["#","Explicit Thinking"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}],["$","span","Token Efficiency",{"className":"page__taxonomy-item","children":["#","Token Efficiency"]}],["$","span","Accuracy Improvement",{"className":"page__taxonomy-item","children":["#","Accuracy Improvement"]}],["$","span","Dynamic Switching",{"className":"page__taxonomy-item","children":["#","Dynamic Switching"]}],["$","span","Entropy-based Control",{"className":"page__taxonomy-item","children":["#","Entropy-based Control"]}]]}]]}]]}],["$","article","2025-10-7-Self-Reflective_Generation_at_Test_Time",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Self-Reflective_Generation_at_Test_Time/","children":"[논문리뷰] Self-Reflective Generation at Test Time"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shuang Qiu이 [arXiv]에 게시한 'Self-Reflective Generation at Test Time' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Self-Reflection",{"className":"page__taxonomy-item","children":["#","Self-Reflection"]}],["$","span","Test-Time Optimization",{"className":"page__taxonomy-item","children":["#","Test-Time Optimization"]}],["$","span","Uncertainty Monitoring",{"className":"page__taxonomy-item","children":["#","Uncertainty Monitoring"]}],["$","span","Proactive Error Prevention",{"className":"page__taxonomy-item","children":["#","Proactive Error Prevention"]}],["$","span","Reasoning Tasks",{"className":"page__taxonomy-item","children":["#","Reasoning Tasks"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}]]}]]}]]}],["$","article","2025-10-7-SAEdit_Token-level_control_for_continuous_image_editing_via_Sparse_AutoEncoder",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-SAEdit_Token-level_control_for_continuous_image_editing_via_Sparse_AutoEncoder/","children":"[논문리뷰] SAEdit: Token-level control for continuous image editing via Sparse AutoEncoder"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Or Patashnik이 [arXiv]에 게시한 'SAEdit: Token-level control for continuous image editing via Sparse AutoEncoder' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Sparse Autoencoder (SAE)",{"className":"page__taxonomy-item","children":["#","Sparse Autoencoder (SAE)"]}],["$","span","Text-to-Image",{"className":"page__taxonomy-item","children":["#","Text-to-Image"]}],["$","span","Disentangled Control",{"className":"page__taxonomy-item","children":["#","Disentangled Control"]}],["$","span","Continuous Control",{"className":"page__taxonomy-item","children":["#","Continuous Control"]}],["$","span","Token-level Manipulation",{"className":"page__taxonomy-item","children":["#","Token-level Manipulation"]}],["$","span","Text Embeddings",{"className":"page__taxonomy-item","children":["#","Text Embeddings"]}]]}]]}]]}],["$","article","2025-10-7-Reinforce-Ada_An_Adaptive_Sampling_Framework_for_Reinforce-Style_LLM_Training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Reinforce-Ada_An_Adaptive_Sampling_Framework_for_Reinforce-Style_LLM_Training/","children":"[논문리뷰] Reinforce-Ada: An Adaptive Sampling Framework for Reinforce-Style LLM Training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Reinforce-Ada: An Adaptive Sampling Framework for Reinforce-Style LLM Training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Adaptive Sampling",{"className":"page__taxonomy-item","children":["#","Adaptive Sampling"]}],["$","span","Policy Gradient",{"className":"page__taxonomy-item","children":["#","Policy Gradient"]}],["$","span","Reward Optimization",{"className":"page__taxonomy-item","children":["#","Reward Optimization"]}],["$","span","Signal Collapse",{"className":"page__taxonomy-item","children":["#","Signal Collapse"]}],["$","span","Variance Reduction",{"className":"page__taxonomy-item","children":["#","Variance Reduction"]}]]}]]}]]}],["$","article","2025-10-7-Reactive_Transformer_RxT_--_Stateful_Real-Time_Processing_for_Event-Driven_Reactive_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Reactive_Transformer_RxT_--_Stateful_Real-Time_Processing_for_Event-Driven_Reactive_Language_Models/","children":"[논문리뷰] Reactive Transformer (RxT) -- Stateful Real-Time Processing for Event-Driven Reactive Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Reactive Transformer (RxT) -- Stateful Real-Time Processing for Event-Driven Reactive Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reactive Transformer",{"className":"page__taxonomy-item","children":["#","Reactive Transformer"]}],["$","span","Stateful LLM",{"className":"page__taxonomy-item","children":["#","Stateful LLM"]}],["$","span","Event-Driven AI",{"className":"page__taxonomy-item","children":["#","Event-Driven AI"]}],["$","span","Asynchronous Memory",{"className":"page__taxonomy-item","children":["#","Asynchronous Memory"]}],["$","span","Conversational AI",{"className":"page__taxonomy-item","children":["#","Conversational AI"]}],["$","span","Linear Scaling",{"className":"page__taxonomy-item","children":["#","Linear Scaling"]}],["$","span","Short-Term Memory (STM)",{"className":"page__taxonomy-item","children":["#","Short-Term Memory (STM)"]}],["$","span","Memory Attention",{"className":"page__taxonomy-item","children":["#","Memory Attention"]}]]}]]}]]}],["$","article","2025-10-7-Optimal_Scaling_Needs_Optimal_Norm",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Optimal_Scaling_Needs_Optimal_Norm/","children":"[논문리뷰] Optimal Scaling Needs Optimal Norm"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Stefan Kesselheim이 [arXiv]에 게시한 'Optimal Scaling Needs Optimal Norm' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Optimal Scaling",{"className":"page__taxonomy-item","children":["#","Optimal Scaling"]}],["$","span","Norm-Based Optimizers",{"className":"page__taxonomy-item","children":["#","Norm-Based Optimizers"]}],["$","span","Hyperparameter Transfer",{"className":"page__taxonomy-item","children":["#","Hyperparameter Transfer"]}],["$","span","Learning Rate Scaling",{"className":"page__taxonomy-item","children":["#","Learning Rate Scaling"]}],["$","span","Batch Size Scaling",{"className":"page__taxonomy-item","children":["#","Batch Size Scaling"]}],["$","span","Transformer Models",{"className":"page__taxonomy-item","children":["#","Transformer Models"]}],["$","span","Scion Optimizer",{"className":"page__taxonomy-item","children":["#","Scion Optimizer"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}]]}]]}]]}],["$","article","2025-10-7-MoME_Mixture_of_Matryoshka_Experts_for_Audio-Visual_Speech_Recognition",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-MoME_Mixture_of_Matryoshka_Experts_for_Audio-Visual_Speech_Recognition/","children":"[논문리뷰] MoME: Mixture of Matryoshka Experts for Audio-Visual Speech Recognition"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'MoME: Mixture of Matryoshka Experts for Audio-Visual Speech Recognition' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Audio-Visual Speech Recognition",{"className":"page__taxonomy-item","children":["#","Audio-Visual Speech Recognition"]}],["$","span","Mixture of Experts",{"className":"page__taxonomy-item","children":["#","Mixture of Experts"]}],["$","span","Matryoshka Representation Learning",{"className":"page__taxonomy-item","children":["#","Matryoshka Representation Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Elastic Inference",{"className":"page__taxonomy-item","children":["#","Elastic Inference"]}],["$","span","Token Compression",{"className":"page__taxonomy-item","children":["#","Token Compression"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}]]}]]}]]}],["$","article","2025-10-7-MITS_Enhanced_Tree_Search_Reasoning_for_LLMs_via_Pointwise_Mutual_Information",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-MITS_Enhanced_Tree_Search_Reasoning_for_LLMs_via_Pointwise_Mutual_Information/","children":"[논문리뷰] MITS: Enhanced Tree Search Reasoning for LLMs via Pointwise Mutual Information"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'MITS: Enhanced Tree Search Reasoning for LLMs via Pointwise Mutual Information' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Reasoning",{"className":"page__taxonomy-item","children":["#","LLM Reasoning"]}],["$","span","Tree Search",{"className":"page__taxonomy-item","children":["#","Tree Search"]}],["$","span","Pointwise Mutual Information (PMI)",{"className":"page__taxonomy-item","children":["#","Pointwise Mutual Information (PMI)"]}],["$","span","Dynamic Sampling",{"className":"page__taxonomy-item","children":["#","Dynamic Sampling"]}],["$","span","Beam Search",{"className":"page__taxonomy-item","children":["#","Beam Search"]}],["$","span","Weighted Voting",{"className":"page__taxonomy-item","children":["#","Weighted Voting"]}],["$","span","Information Theory",{"className":"page__taxonomy-item","children":["#","Information Theory"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}]]}]]}]]}],["$","article","2025-10-7-LLMSQL_Upgrading_WikiSQL_for_the_LLM_Era_of_Text-to-SQL",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-LLMSQL_Upgrading_WikiSQL_for_the_LLM_Era_of_Text-to-SQL/","children":"[논문리뷰] LLMSQL: Upgrading WikiSQL for the LLM Era of Text-to-SQL"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'LLMSQL: Upgrading WikiSQL for the LLM Era of Text-to-SQL' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-SQL",{"className":"page__taxonomy-item","children":["#","Text-to-SQL"]}],["$","span","WikiSQL",{"className":"page__taxonomy-item","children":["#","WikiSQL"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Dataset Curation",{"className":"page__taxonomy-item","children":["#","Dataset Curation"]}],["$","span","Natural Language Processing",{"className":"page__taxonomy-item","children":["#","Natural Language Processing"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","SQL Generation",{"className":"page__taxonomy-item","children":["#","SQL Generation"]}],["$","span","Data Cleaning",{"className":"page__taxonomy-item","children":["#","Data Cleaning"]}]]}]]}]]}],["$","article","2025-10-7-Learning_on_the_Job_Test-Time_Curricula_for_Targeted_Reinforcement_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Learning_on_the_Job_Test-Time_Curricula_for_Targeted_Reinforcement_Learning/","children":"[논문리뷰] Learning on the Job: Test-Time Curricula for Targeted Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Learning on the Job: Test-Time Curricula for Targeted Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Test-Time Curriculum",{"className":"page__taxonomy-item","children":["#","Test-Time Curriculum"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Self-Curated Learning",{"className":"page__taxonomy-item","children":["#","Self-Curated Learning"]}],["$","span","Continual Learning",{"className":"page__taxonomy-item","children":["#","Continual Learning"]}],["$","span","Reasoning Benchmarks",{"className":"page__taxonomy-item","children":["#","Reasoning Benchmarks"]}],["$","span","Adaptive Training",{"className":"page__taxonomy-item","children":["#","Adaptive Training"]}]]}]]}]]}],["$","article","2025-10-7-Judging_with_Confidence_Calibrating_Autoraters_to_Preference_Distributions",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Judging_with_Confidence_Calibrating_Autoraters_to_Preference_Distributions/","children":"[논문리뷰] Judging with Confidence: Calibrating Autoraters to Preference Distributions"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Judging with Confidence: Calibrating Autoraters to Preference Distributions' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Autoraters",{"className":"page__taxonomy-item","children":["#","Autoraters"]}],["$","span","Calibration",{"className":"page__taxonomy-item","children":["#","Calibration"]}],["$","span","Preference Distributions",{"className":"page__taxonomy-item","children":["#","Preference Distributions"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Positional Bias",{"className":"page__taxonomy-item","children":["#","Positional Bias"]}]]}]]}]]}],["$","article","2025-10-7-Imperceptible_Jailbreaking_against_Large_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Imperceptible_Jailbreaking_against_Large_Language_Models/","children":"[논문리뷰] Imperceptible Jailbreaking against Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Imperceptible Jailbreaking against Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Jailbreaking",{"className":"page__taxonomy-item","children":["#","Jailbreaking"]}],["$","span","Imperceptible Attacks",{"className":"page__taxonomy-item","children":["#","Imperceptible Attacks"]}],["$","span","Unicode Variation Selectors",{"className":"page__taxonomy-item","children":["#","Unicode Variation Selectors"]}],["$","span","Adversarial Suffixes",{"className":"page__taxonomy-item","children":["#","Adversarial Suffixes"]}],["$","span","Safety Alignment",{"className":"page__taxonomy-item","children":["#","Safety Alignment"]}],["$","span","Prompt Injection",{"className":"page__taxonomy-item","children":["#","Prompt Injection"]}]]}]]}]]}],["$","article","2025-10-7-Hybrid_Architectures_for_Language_Models_Systematic_Analysis_and_Design_Insights",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Hybrid_Architectures_for_Language_Models_Systematic_Analysis_and_Design_Insights/","children":"[논문리뷰] Hybrid Architectures for Language Models: Systematic Analysis and Design Insights"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Hybrid Architectures for Language Models: Systematic Analysis and Design Insights' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Hybrid LLM",{"className":"page__taxonomy-item","children":["#","Hybrid LLM"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Mamba",{"className":"page__taxonomy-item","children":["#","Mamba"]}],["$","span","State Space Models (SSM)",{"className":"page__taxonomy-item","children":["#","State Space Models (SSM)"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}],["$","span","Long-Context",{"className":"page__taxonomy-item","children":["#","Long-Context"]}],["$","span","Language Model Architectures",{"className":"page__taxonomy-item","children":["#","Language Model Architectures"]}],["$","span","Scaling Laws",{"className":"page__taxonomy-item","children":["#","Scaling Laws"]}]]}]]}]]}],["$","article","2025-10-7-HiKE_Hierarchical_Evaluation_Framework_for_Korean-English_Code-Switching_Speech_Recognition",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-HiKE_Hierarchical_Evaluation_Framework_for_Korean-English_Code-Switching_Speech_Recognition/","children":"[논문리뷰] HiKE: Hierarchical Evaluation Framework for Korean-English Code-Switching Speech Recognition"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'HiKE: Hierarchical Evaluation Framework for Korean-English Code-Switching Speech Recognition' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Code-Switching",{"className":"page__taxonomy-item","children":["#","Code-Switching"]}],["$","span","Speech Recognition",{"className":"page__taxonomy-item","children":["#","Speech Recognition"]}],["$","span","Korean-English ASR",{"className":"page__taxonomy-item","children":["#","Korean-English ASR"]}],["$","span","Evaluation Framework",{"className":"page__taxonomy-item","children":["#","Evaluation Framework"]}],["$","span","Multilingual ASR",{"className":"page__taxonomy-item","children":["#","Multilingual ASR"]}],["$","span","Loanword Processing",{"className":"page__taxonomy-item","children":["#","Loanword Processing"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Hierarchical Labeling",{"className":"page__taxonomy-item","children":["#","Hierarchical Labeling"]}]]}]]}]]}],["$","article","2025-10-7-Graph2Eval_Automatic_Multimodal_Task_Generation_for_Agents_via_Knowledge_Graphs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Graph2Eval_Automatic_Multimodal_Task_Generation_for_Agents_via_Knowledge_Graphs/","children":"[논문리뷰] Graph2Eval: Automatic Multimodal Task Generation for Agents via Knowledge Graphs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zeyi Liao이 [arXiv]에 게시한 'Graph2Eval: Automatic Multimodal Task Generation for Agents via Knowledge Graphs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agent Evaluation",{"className":"page__taxonomy-item","children":["#","Agent Evaluation"]}],["$","span","Task Generation",{"className":"page__taxonomy-item","children":["#","Task Generation"]}],["$","span","Knowledge Graphs",{"className":"page__taxonomy-item","children":["#","Knowledge Graphs"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Web Interaction",{"className":"page__taxonomy-item","children":["#","Web Interaction"]}],["$","span","Document Comprehension",{"className":"page__taxonomy-item","children":["#","Document Comprehension"]}],["$","span","LLM-driven Agents",{"className":"page__taxonomy-item","children":["#","LLM-driven Agents"]}]]}]]}]]}],["$","article","2025-10-7-Good_Intentions_Beyond_ACL_Who_Does_NLP_for_Social_Good_and_Where",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Good_Intentions_Beyond_ACL_Who_Does_NLP_for_Social_Good_and_Where/","children":"[논문리뷰] Good Intentions Beyond ACL: Who Does NLP for Social Good, and Where?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Denis Peskoff이 [arXiv]에 게시한 'Good Intentions Beyond ACL: Who Does NLP for Social Good, and Where?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","NLP for Social Good",{"className":"page__taxonomy-item","children":["#","NLP for Social Good"]}],["$","span","ACL Community",{"className":"page__taxonomy-item","children":["#","ACL Community"]}],["$","span","Scientometrics",{"className":"page__taxonomy-item","children":["#","Scientometrics"]}],["$","span","Venue Analysis",{"className":"page__taxonomy-item","children":["#","Venue Analysis"]}],["$","span","Author Classification",{"className":"page__taxonomy-item","children":["#","Author Classification"]}],["$","span","Sustainable Development Goals",{"className":"page__taxonomy-item","children":["#","Sustainable Development Goals"]}],["$","span","Neural Methods",{"className":"page__taxonomy-item","children":["#","Neural Methods"]}],["$","span","Research Landscape",{"className":"page__taxonomy-item","children":["#","Research Landscape"]}]]}]]}]]}],["$","article","2025-10-7-Front-Loading_Reasoning_The_Synergy_between_Pretraining_and_Post-Training_Data",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Front-Loading_Reasoning_The_Synergy_between_Pretraining_and_Post-Training_Data/","children":"[논문리뷰] Front-Loading Reasoning: The Synergy between Pretraining and Post-Training Data"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Front-Loading Reasoning: The Synergy between Pretraining and Post-Training Data' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Pretraining",{"className":"page__taxonomy-item","children":["#","Pretraining"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Reasoning Data",{"className":"page__taxonomy-item","children":["#","Reasoning Data"]}],["$","span","Data Allocation",{"className":"page__taxonomy-item","children":["#","Data Allocation"]}],["$","span","Diversity",{"className":"page__taxonomy-item","children":["#","Diversity"]}],["$","span","Quality",{"className":"page__taxonomy-item","children":["#","Quality"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}]]}]]}]]}],["$","article","2025-10-7-Factuality_Matters_When_Image_Generation_and_Editing_Meet_Structured_Visuals",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Factuality_Matters_When_Image_Generation_and_Editing_Meet_Structured_Visuals/","children":"[논문리뷰] Factuality Matters: When Image Generation and Editing Meet Structured Visuals"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Boxiang Qiu이 [arXiv]에 게시한 'Factuality Matters: When Image Generation and Editing Meet Structured Visuals' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Structured Visuals",{"className":"page__taxonomy-item","children":["#","Structured Visuals"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","span","Factual Fidelity",{"className":"page__taxonomy-item","children":["#","Factual Fidelity"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Evaluation Benchmark",{"className":"page__taxonomy-item","children":["#","Evaluation Benchmark"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}]]}]]}]]}],["$","article","2025-10-7-EvolProver_Advancing_Automated_Theorem_Proving_by_Evolving_Formalized_Problems_via_Symmetry_and_Difficulty",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-EvolProver_Advancing_Automated_Theorem_Proving_by_Evolving_Formalized_Problems_via_Symmetry_and_Difficulty/","children":"[논문리뷰] EvolProver: Advancing Automated Theorem Proving by Evolving Formalized Problems via Symmetry and Difficulty"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xuanwu Wang이 [arXiv]에 게시한 'EvolProver: Advancing Automated Theorem Proving by Evolving Formalized Problems via Symmetry and Difficulty' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Automated Theorem Proving",{"className":"page__taxonomy-item","children":["#","Automated Theorem Proving"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Formal Mathematics",{"className":"page__taxonomy-item","children":["#","Formal Mathematics"]}],["$","span","Symmetry",{"className":"page__taxonomy-item","children":["#","Symmetry"]}],["$","span","Difficulty Evolution",{"className":"page__taxonomy-item","children":["#","Difficulty Evolution"]}],["$","span","Abstract Syntax Tree",{"className":"page__taxonomy-item","children":["#","Abstract Syntax Tree"]}],["$","span","Generalizability",{"className":"page__taxonomy-item","children":["#","Generalizability"]}]]}]]}]]}],["$","article","2025-10-7-Epistemic_Diversity_and_Knowledge_Collapse_in_Large_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Epistemic_Diversity_and_Knowledge_Collapse_in_Large_Language_Models/","children":"[논문리뷰] Epistemic Diversity and Knowledge Collapse in Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Epistemic Diversity and Knowledge Collapse in Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Epistemic Diversity",{"className":"page__taxonomy-item","children":["#","Epistemic Diversity"]}],["$","span","Knowledge Collapse",{"className":"page__taxonomy-item","children":["#","Knowledge Collapse"]}],["$","span","Homogenization",{"className":"page__taxonomy-item","children":["#","Homogenization"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Information Diversity",{"className":"page__taxonomy-item","children":["#","Information Diversity"]}],["$","span","Cultural Bias",{"className":"page__taxonomy-item","children":["#","Cultural Bias"]}]]}]]}]]}],["$","article","2025-10-7-Code4MeV2_a_Research-oriented_Code-completion_Platform",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Code4MeV2_a_Research-oriented_Code-completion_Platform/","children":"[논문리뷰] Code4MeV2: a Research-oriented Code-completion Platform"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Code4MeV2: a Research-oriented Code-completion Platform' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Code Completion",{"className":"page__taxonomy-item","children":["#","Code Completion"]}],["$","span","Research Platform",{"className":"page__taxonomy-item","children":["#","Research Platform"]}],["$","span","Human-AI Interaction",{"className":"page__taxonomy-item","children":["#","Human-AI Interaction"]}],["$","span","Software Engineering",{"className":"page__taxonomy-item","children":["#","Software Engineering"]}],["$","span","Open Science",{"className":"page__taxonomy-item","children":["#","Open Science"]}],["$","span","JetBrains IDE Plugin",{"className":"page__taxonomy-item","children":["#","JetBrains IDE Plugin"]}],["$","span","Telemetry",{"className":"page__taxonomy-item","children":["#","Telemetry"]}],["$","span","AI4SE",{"className":"page__taxonomy-item","children":["#","AI4SE"]}]]}]]}]]}],["$","article","2025-10-7-ChronoEdit_Towards_Temporal_Reasoning_for_Image_Editing_and_World_Simulation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-ChronoEdit_Towards_Temporal_Reasoning_for_Image_Editing_and_World_Simulation/","children":"[논문리뷰] ChronoEdit: Towards Temporal Reasoning for Image Editing and World Simulation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'ChronoEdit: Towards Temporal Reasoning for Image Editing and World Simulation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Temporal Reasoning",{"className":"page__taxonomy-item","children":["#","Temporal Reasoning"]}],["$","span","World Simulation",{"className":"page__taxonomy-item","children":["#","World Simulation"]}],["$","span","Physical Consistency",{"className":"page__taxonomy-item","children":["#","Physical Consistency"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}]]}]]}]]}],["$","article","2025-10-7-Character_Mixing_for_Video_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Character_Mixing_for_Video_Generation/","children":"[논문리뷰] Character Mixing for Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Character Mixing for Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Character Mixing",{"className":"page__taxonomy-item","children":["#","Character Mixing"]}],["$","span","Style Preservation",{"className":"page__taxonomy-item","children":["#","Style Preservation"]}],["$","span","Multi-character Interaction",{"className":"page__taxonomy-item","children":["#","Multi-character Interaction"]}],["$","span","Text-to-Video",{"className":"page__taxonomy-item","children":["#","Text-to-Video"]}],["$","span","Cross-Domain Synthesis",{"className":"page__taxonomy-item","children":["#","Cross-Domain Synthesis"]}],["$","span","Identity Preservation",{"className":"page__taxonomy-item","children":["#","Identity Preservation"]}]]}]]}]]}],["$","article","2025-10-7-Alignment_Tipping_Process_How_Self-Evolution_Pushes_LLM_Agents_Off_the_Rails",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Alignment_Tipping_Process_How_Self-Evolution_Pushes_LLM_Agents_Off_the_Rails/","children":"[논문리뷰] Alignment Tipping Process: How Self-Evolution Pushes LLM Agents Off the Rails"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xinyuan Liu이 [arXiv]에 게시한 'Alignment Tipping Process: How Self-Evolution Pushes LLM Agents Off the Rails' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Alignment",{"className":"page__taxonomy-item","children":["#","Alignment"]}],["$","span","Self-Evolution",{"className":"page__taxonomy-item","children":["#","Self-Evolution"]}],["$","span","Behavioral Drift",{"className":"page__taxonomy-item","children":["#","Behavioral Drift"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Alignment Tipping Process",{"className":"page__taxonomy-item","children":["#","Alignment Tipping Process"]}]]}]]}]]}],["$","article","2025-10-7-Agentic_Context_Engineering_Evolving_Contexts_for_Self-Improving_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-Agentic_Context_Engineering_Evolving_Contexts_for_Self-Improving_Language_Models/","children":"[논문리뷰] Agentic Context Engineering: Evolving Contexts for Self-Improving Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Fenglu Hong이 [arXiv]에 게시한 'Agentic Context Engineering: Evolving Contexts for Self-Improving Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Context Adaptation",{"className":"page__taxonomy-item","children":["#","LLM Context Adaptation"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Self-Improving Systems",{"className":"page__taxonomy-item","children":["#","Self-Improving Systems"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","Context Management",{"className":"page__taxonomy-item","children":["#","Context Management"]}],["$","span","Dynamic Playbooks",{"className":"page__taxonomy-item","children":["#","Dynamic Playbooks"]}],["$","span","Incremental Learning",{"className":"page__taxonomy-item","children":["#","Incremental Learning"]}]]}]]}]]}],["$","article","2025-10-7-AdvEvo-MARL_Shaping_Internalized_Safety_through_Adversarial_Co-Evolution_in_Multi-Agent_Reinforcement_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-7-AdvEvo-MARL_Shaping_Internalized_Safety_through_Adversarial_Co-Evolution_in_Multi-Agent_Reinforcement_Learning/","children":"[논문리뷰] AdvEvo-MARL: Shaping Internalized Safety through Adversarial Co-Evolution in Multi-Agent Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zeliang Zhang이 [arXiv]에 게시한 'AdvEvo-MARL: Shaping Internalized Safety through Adversarial Co-Evolution in Multi-Agent Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-07 13:36:57+0900","children":"2025년 10월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-Agent Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Multi-Agent Reinforcement Learning"]}],["$","span","Adversarial Co-evolution",{"className":"page__taxonomy-item","children":["#","Adversarial Co-evolution"]}],["$","span","LLM Safety",{"className":"page__taxonomy-item","children":["#","LLM Safety"]}],["$","span","Jailbreak Attacks",{"className":"page__taxonomy-item","children":["#","Jailbreak Attacks"]}],["$","span","Internalized Safety",{"className":"page__taxonomy-item","children":["#","Internalized Safety"]}],["$","span","Public Baseline",{"className":"page__taxonomy-item","children":["#","Public Baseline"]}],["$","span","System Robustness",{"className":"page__taxonomy-item","children":["#","System Robustness"]}]]}]]}]]}],["$","article","2025-10-6-Your_Agent_May_Misevolve_Emergent_Risks_in_Self-evolving_LLM_Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-Your_Agent_May_Misevolve_Emergent_Risks_in_Self-evolving_LLM_Agents/","children":"[논문리뷰] Your Agent May Misevolve: Emergent Risks in Self-evolving LLM Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Boyi Wei이 [arXiv]에 게시한 'Your Agent May Misevolve: Emergent Risks in Self-evolving LLM Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Self-evolving Agents",{"className":"page__taxonomy-item","children":["#","Self-evolving Agents"]}],["$","span","LLM Safety",{"className":"page__taxonomy-item","children":["#","LLM Safety"]}],["$","span","Misevolution",{"className":"page__taxonomy-item","children":["#","Misevolution"]}],["$","span","Emergent Risks",{"className":"page__taxonomy-item","children":["#","Emergent Risks"]}],["$","span","Model Evolution",{"className":"page__taxonomy-item","children":["#","Model Evolution"]}],["$","span","Memory Evolution",{"className":"page__taxonomy-item","children":["#","Memory Evolution"]}],["$","span","Tool Evolution",{"className":"page__taxonomy-item","children":["#","Tool Evolution"]}],["$","span","Workflow Evolution",{"className":"page__taxonomy-item","children":["#","Workflow Evolution"]}]]}]]}]]}],["$","article","2025-10-6-WAInjectBench_Benchmarking_Prompt_Injection_Detections_for_Web_Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-WAInjectBench_Benchmarking_Prompt_Injection_Detections_for_Web_Agents/","children":"[논문리뷰] WAInjectBench: Benchmarking Prompt Injection Detections for Web Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Neil Zhenqiang Gong이 [arXiv]에 게시한 'WAInjectBench: Benchmarking Prompt Injection Detections for Web Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Prompt Injection",{"className":"page__taxonomy-item","children":["#","Prompt Injection"]}],["$","span","Web Agents",{"className":"page__taxonomy-item","children":["#","Web Agents"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Adversarial Attacks",{"className":"page__taxonomy-item","children":["#","Adversarial Attacks"]}],["$","span","Detection Benchmarking",{"className":"page__taxonomy-item","children":["#","Detection Benchmarking"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Image-based Detection",{"className":"page__taxonomy-item","children":["#","Image-based Detection"]}],["$","span","Text-based Detection",{"className":"page__taxonomy-item","children":["#","Text-based Detection"]}]]}]]}]]}],["$","article","2025-10-6-Triangle_Splatting_Differentiable_Rendering_with_Opaque_Triangles",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-Triangle_Splatting_Differentiable_Rendering_with_Opaque_Triangles/","children":"[논문리뷰] Triangle Splatting+: Differentiable Rendering with Opaque Triangles"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Matheus Gadelha이 [arXiv]에 게시한 'Triangle Splatting+: Differentiable Rendering with Opaque Triangles' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Differentiable Rendering",{"className":"page__taxonomy-item","children":["#","Differentiable Rendering"]}],["$","span","3D Reconstruction",{"className":"page__taxonomy-item","children":["#","3D Reconstruction"]}],["$","span","Novel View Synthesis",{"className":"page__taxonomy-item","children":["#","Novel View Synthesis"]}],["$","span","Triangles",{"className":"page__taxonomy-item","children":["#","Triangles"]}],["$","span","Opaque Primitives",{"className":"page__taxonomy-item","children":["#","Opaque Primitives"]}],["$","span","Game Engines",{"className":"page__taxonomy-item","children":["#","Game Engines"]}],["$","span","Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","Gaussian Splatting"]}],["$","span","Mesh-based Rendering",{"className":"page__taxonomy-item","children":["#","Mesh-based Rendering"]}]]}]]}]]}],["$","article","2025-10-6-TalkPlay-Tools_Conversational_Music_Recommendation_with_LLM_Tool_Calling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-TalkPlay-Tools_Conversational_Music_Recommendation_with_LLM_Tool_Calling/","children":"[논문리뷰] TalkPlay-Tools: Conversational Music Recommendation with LLM Tool Calling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Juhan Nam이 [arXiv]에 게시한 'TalkPlay-Tools: Conversational Music Recommendation with LLM Tool Calling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Conversational Recommendation",{"className":"page__taxonomy-item","children":["#","Conversational Recommendation"]}],["$","span","LLM Tool Calling",{"className":"page__taxonomy-item","children":["#","LLM Tool Calling"]}],["$","span","Music Recommendation",{"className":"page__taxonomy-item","children":["#","Music Recommendation"]}],["$","span","Multimodal Retrieval",{"className":"page__taxonomy-item","children":["#","Multimodal Retrieval"]}],["$","span","Information Retrieval",{"className":"page__taxonomy-item","children":["#","Information Retrieval"]}],["$","span","Retrieval-Reranking",{"className":"page__taxonomy-item","children":["#","Retrieval-Reranking"]}],["$","span","Semantic IDs",{"className":"page__taxonomy-item","children":["#","Semantic IDs"]}]]}]]}]]}],["$","article","2025-10-6-SurveyBench_How_Well_Can_LLM-Agents_Write_Academic_Surveys",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-SurveyBench_How_Well_Can_LLM-Agents_Write_Academic_Surveys/","children":"[논문리뷰] SurveyBench: How Well Can LLM(-Agents) Write Academic Surveys?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shuo Wang이 [arXiv]에 게시한 'SurveyBench: How Well Can LLM(-Agents) Write Academic Surveys?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Academic Survey Generation",{"className":"page__taxonomy-item","children":["#","Academic Survey Generation"]}],["$","span","Evaluation Framework",{"className":"page__taxonomy-item","children":["#","Evaluation Framework"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Quiz-driven Evaluation",{"className":"page__taxonomy-item","children":["#","Quiz-driven Evaluation"]}],["$","span","Content Quality Metrics",{"className":"page__taxonomy-item","children":["#","Content Quality Metrics"]}]]}]]}]]}],["$","article","2025-10-6-SpineBench_A_Clinically_Salient_Level-Aware_Benchmark_Powered_by_the_SpineMed-450k_Corpus",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-SpineBench_A_Clinically_Salient_Level-Aware_Benchmark_Powered_by_the_SpineMed-450k_Corpus/","children":"[논문리뷰] SpineBench: A Clinically Salient, Level-Aware Benchmark Powered by the SpineMed-450k Corpus"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhonghao Zhang이 [arXiv]에 게시한 'SpineBench: A Clinically Salient, Level-Aware Benchmark Powered by the SpineMed-450k Corpus' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Medical AI",{"className":"page__taxonomy-item","children":["#","Medical AI"]}],["$","span","Spine Diagnosis",{"className":"page__taxonomy-item","children":["#","Spine Diagnosis"]}],["$","span","Multimodal LLM",{"className":"page__taxonomy-item","children":["#","Multimodal LLM"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}],["$","span","Clinical Reasoning",{"className":"page__taxonomy-item","children":["#","Clinical Reasoning"]}],["$","span","Spine Surgery",{"className":"page__taxonomy-item","children":["#","Spine Surgery"]}],["$","span","Vision-Language Model",{"className":"page__taxonomy-item","children":["#","Vision-Language Model"]}]]}]]}]]}],["$","article","2025-10-6-Self-Improvement_in_Multimodal_Large_Language_Models_A_Survey",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-Self-Improvement_in_Multimodal_Large_Language_Models_A_Survey/","children":"[논문리뷰] Self-Improvement in Multimodal Large Language Models: A Survey"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yapeng Tian이 [arXiv]에 게시한 'Self-Improvement in Multimodal Large Language Models: A Survey' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models (MLLMs)"]}],["$","span","Self-Improvement",{"className":"page__taxonomy-item","children":["#","Self-Improvement"]}],["$","span","Data Collection",{"className":"page__taxonomy-item","children":["#","Data Collection"]}],["$","span","Data Organization",{"className":"page__taxonomy-item","children":["#","Data Organization"]}],["$","span","Model Optimization",{"className":"page__taxonomy-item","children":["#","Model Optimization"]}],["$","span","Survey",{"className":"page__taxonomy-item","children":["#","Survey"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Direct Preference Optimization",{"className":"page__taxonomy-item","children":["#","Direct Preference Optimization"]}]]}]]}]]}],["$","article","2025-10-6-Scaling_Policy_Compliance_Assessment_in_Language_Models_with_Policy_Reasoning_Traces",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-Scaling_Policy_Compliance_Assessment_in_Language_Models_with_Policy_Reasoning_Traces/","children":"[논문리뷰] Scaling Policy Compliance Assessment in Language Models with Policy Reasoning Traces"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Scaling Policy Compliance Assessment in Language Models with Policy Reasoning Traces' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Policy Compliance",{"className":"page__taxonomy-item","children":["#","Policy Compliance"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Reasoning Traces",{"className":"page__taxonomy-item","children":["#","Reasoning Traces"]}],["$","span","In-Context Learning (ICL)",{"className":"page__taxonomy-item","children":["#","In-Context Learning (ICL)"]}],["$","span","Supervised Finetuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Finetuning (SFT)"]}],["$","span","HIPAA",{"className":"page__taxonomy-item","children":["#","HIPAA"]}],["$","span","GDPR",{"className":"page__taxonomy-item","children":["#","GDPR"]}],["$","span","ModelSpec",{"className":"page__taxonomy-item","children":["#","ModelSpec"]}]]}]]}]]}],["$","article","2025-10-6-REPAIR_Robust_Editing_via_Progressive_Adaptive_Intervention_and_Reintegration",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-REPAIR_Robust_Editing_via_Progressive_Adaptive_Intervention_and_Reintegration/","children":"[논문리뷰] REPAIR: Robust Editing via Progressive Adaptive Intervention and Reintegration"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'REPAIR: Robust Editing via Progressive Adaptive Intervention and Reintegration' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Model Editing",{"className":"page__taxonomy-item","children":["#","Model Editing"]}],["$","span","Lifelong Learning",{"className":"page__taxonomy-item","children":["#","Lifelong Learning"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Continual Learning",{"className":"page__taxonomy-item","children":["#","Continual Learning"]}],["$","span","Knowledge Distillation",{"className":"page__taxonomy-item","children":["#","Knowledge Distillation"]}],["$","span","Error Feedback",{"className":"page__taxonomy-item","children":["#","Error Feedback"]}],["$","span","Memory Management",{"className":"page__taxonomy-item","children":["#","Memory Management"]}],["$","span","Parameter Merging",{"className":"page__taxonomy-item","children":["#","Parameter Merging"]}]]}]]}]]}],["$","article","2025-10-6-OrtSAE_Orthogonal_Sparse_Autoencoders_Uncover_Atomic_Features",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-OrtSAE_Orthogonal_Sparse_Autoencoders_Uncover_Atomic_Features/","children":"[논문리뷰] OrtSAE: Orthogonal Sparse Autoencoders Uncover Atomic Features"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Elena Tutubalina이 [arXiv]에 게시한 'OrtSAE: Orthogonal Sparse Autoencoders Uncover Atomic Features' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Sparse Autoencoders",{"className":"page__taxonomy-item","children":["#","Sparse Autoencoders"]}],["$","span","Mechanistic Interpretability",{"className":"page__taxonomy-item","children":["#","Mechanistic Interpretability"]}],["$","span","Feature Disentanglement",{"className":"page__taxonomy-item","children":["#","Feature Disentanglement"]}],["$","span","Orthogonality",{"className":"page__taxonomy-item","children":["#","Orthogonality"]}],["$","span","LLM Features",{"className":"page__taxonomy-item","children":["#","LLM Features"]}],["$","span","Feature Absorption",{"className":"page__taxonomy-item","children":["#","Feature Absorption"]}],["$","span","Feature Composition",{"className":"page__taxonomy-item","children":["#","Feature Composition"]}]]}]]}]]}],["$","article","2025-10-6-NuRisk_A_Visual_Question_Answering_Dataset_for_Agent-Level_Risk_Assessment_in_Autonomous_Driving",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-NuRisk_A_Visual_Question_Answering_Dataset_for_Agent-Level_Risk_Assessment_in_Autonomous_Driving/","children":"[논문리뷰] NuRisk: A Visual Question Answering Dataset for Agent-Level Risk Assessment in Autonomous Driving"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'NuRisk: A Visual Question Answering Dataset for Agent-Level Risk Assessment in Autonomous Driving' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Visual Question Answering (VQA)",{"className":"page__taxonomy-item","children":["#","Visual Question Answering (VQA)"]}],["$","span","Autonomous Driving",{"className":"page__taxonomy-item","children":["#","Autonomous Driving"]}],["$","span","Risk Assessment",{"className":"page__taxonomy-item","children":["#","Risk Assessment"]}],["$","span","Spatio-Temporal Reasoning",{"className":"page__taxonomy-item","children":["#","Spatio-Temporal Reasoning"]}],["$","span","Large Vision Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Large Vision Models (VLMs)"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}],["$","span","Bird-Eye-View (BEV)",{"className":"page__taxonomy-item","children":["#","Bird-Eye-View (BEV)"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}]]}]]}]]}],["$","article","2025-10-6-LSPO_Length-aware_Dynamic_Sampling_for_Policy_Optimization_in_LLM_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-LSPO_Length-aware_Dynamic_Sampling_for_Policy_Optimization_in_LLM_Reasoning/","children":"[논문리뷰] LSPO: Length-aware Dynamic Sampling for Policy Optimization in LLM Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'LSPO: Length-aware Dynamic Sampling for Policy Optimization in LLM Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Reasoning",{"className":"page__taxonomy-item","children":["#","LLM Reasoning"]}],["$","span","RLVR",{"className":"page__taxonomy-item","children":["#","RLVR"]}],["$","span","Dynamic Sampling",{"className":"page__taxonomy-item","children":["#","Dynamic Sampling"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Response Length",{"className":"page__taxonomy-item","children":["#","Response Length"]}],["$","span","Meta-RL",{"className":"page__taxonomy-item","children":["#","Meta-RL"]}],["$","span","Overthinking",{"className":"page__taxonomy-item","children":["#","Overthinking"]}]]}]]}]]}],["$","article","2025-10-6-LEAML_Label-Efficient_Adaptation_to_Out-of-Distribution_Visual_Tasks_for_Multimodal_Large_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-LEAML_Label-Efficient_Adaptation_to_Out-of-Distribution_Visual_Tasks_for_Multimodal_Large_Language_Models/","children":"[논문리뷰] LEAML: Label-Efficient Adaptation to Out-of-Distribution Visual Tasks for Multimodal Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yu-Chiang Frank Wang이 [arXiv]에 게시한 'LEAML: Label-Efficient Adaptation to Out-of-Distribution Visual Tasks for Multimodal Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLM",{"className":"page__taxonomy-item","children":["#","Multimodal LLM"]}],["$","span","OOD Adaptation",{"className":"page__taxonomy-item","children":["#","OOD Adaptation"]}],["$","span","Label Efficiency",{"className":"page__taxonomy-item","children":["#","Label Efficiency"]}],["$","span","VQA",{"className":"page__taxonomy-item","children":["#","VQA"]}],["$","span","Semi-Supervised Learning",{"className":"page__taxonomy-item","children":["#","Semi-Supervised Learning"]}],["$","span","Neuron Distillation",{"className":"page__taxonomy-item","children":["#","Neuron Distillation"]}],["$","span","Pseudo Labeling",{"className":"page__taxonomy-item","children":["#","Pseudo Labeling"]}],["$","span","Medical Imaging",{"className":"page__taxonomy-item","children":["#","Medical Imaging"]}]]}]]}]]}],["$","article","2025-10-6-Improving_GUI_Grounding_with_Explicit_Position-to-Coordinate_Mapping",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-Improving_GUI_Grounding_with_Explicit_Position-to-Coordinate_Mapping/","children":"[논문리뷰] Improving GUI Grounding with Explicit Position-to-Coordinate Mapping"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Spandana Gella이 [arXiv]에 게시한 'Improving GUI Grounding with Explicit Position-to-Coordinate Mapping' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","GUI Grounding",{"className":"page__taxonomy-item","children":["#","GUI Grounding"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Positional Embedding",{"className":"page__taxonomy-item","children":["#","Positional Embedding"]}],["$","span","UI Automation",{"className":"page__taxonomy-item","children":["#","UI Automation"]}],["$","span","Coordinate Prediction",{"className":"page__taxonomy-item","children":["#","Coordinate Prediction"]}],["$","span","Resolution Generalization",{"className":"page__taxonomy-item","children":["#","Resolution Generalization"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}]]}]]}]]}],["$","article","2025-10-6-How_Confident_are_Video_Models_Empowering_Video_Models_to_Express_their_Uncertainty",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-How_Confident_are_Video_Models_Empowering_Video_Models_to_Express_their_Uncertainty/","children":"[논문리뷰] How Confident are Video Models? Empowering Video Models to Express their Uncertainty"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Anirudha Majumdar이 [arXiv]에 게시한 'How Confident are Video Models? Empowering Video Models to Express their Uncertainty' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Uncertainty Quantification",{"className":"page__taxonomy-item","children":["#","Uncertainty Quantification"]}],["$","span","Aleatoric Uncertainty",{"className":"page__taxonomy-item","children":["#","Aleatoric Uncertainty"]}],["$","span","Epistemic Uncertainty",{"className":"page__taxonomy-item","children":["#","Epistemic Uncertainty"]}],["$","span","Model Calibration",{"className":"page__taxonomy-item","children":["#","Model Calibration"]}],["$","span","Text-to-Video",{"className":"page__taxonomy-item","children":["#","Text-to-Video"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","VMF Distribution",{"className":"page__taxonomy-item","children":["#","VMF Distribution"]}]]}]]}]]}],["$","article","2025-10-6-Free_Lunch_Alignment_of_Text-to-Image_Diffusion_Models_without_Preference_Image_Pairs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-Free_Lunch_Alignment_of_Text-to-Image_Diffusion_Models_without_Preference_Image_Pairs/","children":"[논문리뷰] Free Lunch Alignment of Text-to-Image Diffusion Models without Preference Image Pairs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Free Lunch Alignment of Text-to-Image Diffusion Models without Preference Image Pairs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Image Models",{"className":"page__taxonomy-item","children":["#","Text-to-Image Models"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Preference Optimization",{"className":"page__taxonomy-item","children":["#","Preference Optimization"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","RLHF",{"className":"page__taxonomy-item","children":["#","RLHF"]}],["$","span","Prompt Editing",{"className":"page__taxonomy-item","children":["#","Prompt Editing"]}],["$","span","Free Lunch Alignment",{"className":"page__taxonomy-item","children":["#","Free Lunch Alignment"]}],["$","span","TDPO",{"className":"page__taxonomy-item","children":["#","TDPO"]}],["$","span","TKTO",{"className":"page__taxonomy-item","children":["#","TKTO"]}]]}]]}]]}],["$","article","2025-10-6-FocusAgent_Simple_Yet_Effective_Ways_of_Trimming_the_Large_Context_of_Web_Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-FocusAgent_Simple_Yet_Effective_Ways_of_Trimming_the_Large_Context_of_Web_Agents/","children":"[논문리뷰] FocusAgent: Simple Yet Effective Ways of Trimming the Large Context of Web Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Léo Boisvert이 [arXiv]에 게시한 'FocusAgent: Simple Yet Effective Ways of Trimming the Large Context of Web Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Web Agents",{"className":"page__taxonomy-item","children":["#","Web Agents"]}],["$","span","LLM Context Pruning",{"className":"page__taxonomy-item","children":["#","LLM Context Pruning"]}],["$","span","Accessibility Tree",{"className":"page__taxonomy-item","children":["#","Accessibility Tree"]}],["$","span","Prompt Injection",{"className":"page__taxonomy-item","children":["#","Prompt Injection"]}],["$","span","Retrieval Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval Augmented Generation"]}],["$","span","Web Navigation",{"className":"page__taxonomy-item","children":["#","Web Navigation"]}],["$","span","Agent Security",{"className":"page__taxonomy-item","children":["#","Agent Security"]}],["$","span","Efficient LLM",{"className":"page__taxonomy-item","children":["#","Efficient LLM"]}]]}]]}]]}],["$","article","2025-10-6-Efficient_Multi-modal_Large_Language_Models_via_Progressive_Consistency_Distillation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-Efficient_Multi-modal_Large_Language_Models_via_Progressive_Consistency_Distillation/","children":"[논문리뷰] Efficient Multi-modal Large Language Models via Progressive Consistency Distillation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Efficient Multi-modal Large Language Models via Progressive Consistency Distillation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-modal LLMs",{"className":"page__taxonomy-item","children":["#","Multi-modal LLMs"]}],["$","span","Token Compression",{"className":"page__taxonomy-item","children":["#","Token Compression"]}],["$","span","Efficiency",{"className":"page__taxonomy-item","children":["#","Efficiency"]}],["$","span","Knowledge Distillation",{"className":"page__taxonomy-item","children":["#","Knowledge Distillation"]}],["$","span","Progressive Learning",{"className":"page__taxonomy-item","children":["#","Progressive Learning"]}],["$","span","Consistency Distillation",{"className":"page__taxonomy-item","children":["#","Consistency Distillation"]}],["$","span","MLLM Training",{"className":"page__taxonomy-item","children":["#","MLLM Training"]}]]}]]}]]}],["$","article","2025-10-6-DiffTester_Accelerating_Unit_Test_Generation_for_Diffusion_LLMs_via_Repetitive_Pattern",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-DiffTester_Accelerating_Unit_Test_Generation_for_Diffusion_LLMs_via_Repetitive_Pattern/","children":"[논문리뷰] DiffTester: Accelerating Unit Test Generation for Diffusion LLMs via Repetitive Pattern"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jia Li이 [arXiv]에 게시한 'DiffTester: Accelerating Unit Test Generation for Diffusion LLMs via Repetitive Pattern' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion LLMs",{"className":"page__taxonomy-item","children":["#","Diffusion LLMs"]}],["$","span","Unit Test Generation",{"className":"page__taxonomy-item","children":["#","Unit Test Generation"]}],["$","span","Acceleration",{"className":"page__taxonomy-item","children":["#","Acceleration"]}],["$","span","Repetitive Patterns",{"className":"page__taxonomy-item","children":["#","Repetitive Patterns"]}],["$","span","Abstract Syntax Tree",{"className":"page__taxonomy-item","children":["#","Abstract Syntax Tree"]}],["$","span","Software Testing",{"className":"page__taxonomy-item","children":["#","Software Testing"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}]]}]]}]]}],["$","article","2025-10-6-Compose_Your_Policies_Improving_Diffusion-based_or_Flow-based_Robot_Policies_via_Test-time_Distribution-level_Composition",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-Compose_Your_Policies_Improving_Diffusion-based_or_Flow-based_Robot_Policies_via_Test-time_Distribution-level_Composition/","children":"[논문리뷰] Compose Your Policies! Improving Diffusion-based or Flow-based Robot Policies via Test-time Distribution-level Composition"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Compose Your Policies! Improving Diffusion-based or Flow-based Robot Policies via Test-time Distribution-level Composition' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Flow-based Models",{"className":"page__taxonomy-item","children":["#","Flow-based Models"]}],["$","span","Robotics Control",{"className":"page__taxonomy-item","children":["#","Robotics Control"]}],["$","span","Policy Composition",{"className":"page__taxonomy-item","children":["#","Policy Composition"]}],["$","span","Test-time Optimization",{"className":"page__taxonomy-item","children":["#","Test-time Optimization"]}],["$","span","Score-based Models",{"className":"page__taxonomy-item","children":["#","Score-based Models"]}],["$","span","Training-free",{"className":"page__taxonomy-item","children":["#","Training-free"]}]]}]]}]]}],["$","article","2025-10-6-CoDA_Agentic_Systems_for_Collaborative_Data_Visualization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-CoDA_Agentic_Systems_for_Collaborative_Data_Visualization/","children":"[논문리뷰] CoDA: Agentic Systems for Collaborative Data Visualization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'CoDA: Agentic Systems for Collaborative Data Visualization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-agent Systems"]}],["$","span","Data Visualization",{"className":"page__taxonomy-item","children":["#","Data Visualization"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Automation",{"className":"page__taxonomy-item","children":["#","Automation"]}],["$","span","Self-reflection",{"className":"page__taxonomy-item","children":["#","Self-reflection"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","Natural Language to Visualization",{"className":"page__taxonomy-item","children":["#","Natural Language to Visualization"]}]]}]]}]]}],["$","article","2025-10-6-A_Practitioners_Guide_to_Multi-turn_Agentic_Reinforcement_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-A_Practitioners_Guide_to_Multi-turn_Agentic_Reinforcement_Learning/","children":"[논문리뷰] A Practitioner's Guide to Multi-turn Agentic Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'A Practitioner's Guide to Multi-turn Agentic Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-turn Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Multi-turn Reinforcement Learning"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Text-based Environments",{"className":"page__taxonomy-item","children":["#","Text-based Environments"]}],["$","span","Reward Shaping",{"className":"page__taxonomy-item","children":["#","Reward Shaping"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Supervised Fine-tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning (SFT)"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Environment Complexity",{"className":"page__taxonomy-item","children":["#","Environment Complexity"]}]]}]]}]]}],["$","article","2025-10-6-Apriel-1.5-15b-Thinker",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-Apriel-1.5-15b-Thinker/","children":"[논문리뷰] Apriel-1.5-15b-Thinker"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Apriel-1.5-15b-Thinker' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Reasoning Model",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning Model"]}],["$","span","Open-Weights Model",{"className":"page__taxonomy-item","children":["#","Open-Weights Model"]}],["$","span","Continual Pretraining (CPT)",{"className":"page__taxonomy-item","children":["#","Continual Pretraining (CPT)"]}],["$","span","Supervised Fine-Tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning (SFT)"]}],["$","span","Training Design",{"className":"page__taxonomy-item","children":["#","Training Design"]}],["$","span","Efficiency",{"className":"page__taxonomy-item","children":["#","Efficiency"]}],["$","span","Frontier Performance",{"className":"page__taxonomy-item","children":["#","Frontier Performance"]}]]}]]}]]}],["$","article","2025-10-6-Align_Your_Tangent_Training_Better_Consistency_Models_via_Manifold-Aligned_Tangents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-6-Align_Your_Tangent_Training_Better_Consistency_Models_via_Manifold-Aligned_Tangents/","children":"[논문리뷰] Align Your Tangent: Training Better Consistency Models via Manifold-Aligned Tangents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jong Chul Ye이 [arXiv]에 게시한 'Align Your Tangent: Training Better Consistency Models via Manifold-Aligned Tangents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-06 13:29:11+0900","children":"2025년 10월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Consistency Models",{"className":"page__taxonomy-item","children":["#","Consistency Models"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Manifold Learning",{"className":"page__taxonomy-item","children":["#","Manifold Learning"]}],["$","span","Tangent Alignment",{"className":"page__taxonomy-item","children":["#","Tangent Alignment"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Training Dynamics",{"className":"page__taxonomy-item","children":["#","Training Dynamics"]}],["$","span","Manifold Feature Distance",{"className":"page__taxonomy-item","children":["#","Manifold Feature Distance"]}]]}]]}]]}],["$","article","2025-10-2-Why_Cant_Transformers_Learn_Multiplication_Reverse-Engineering_Reveals_Long-Range_Dependency_Pitfalls",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-Why_Cant_Transformers_Learn_Multiplication_Reverse-Engineering_Reveals_Long-Range_Dependency_Pitfalls/","children":"[논문리뷰] Why Can't Transformers Learn Multiplication? Reverse-Engineering Reveals Long-Range Dependency Pitfalls"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Stuart Shieber이 [arXiv]에 게시한 'Why Can't Transformers Learn Multiplication? Reverse-Engineering Reveals Long-Range Dependency Pitfalls' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Transformers",{"className":"page__taxonomy-item","children":["#","Transformers"]}],["$","span","Multiplication",{"className":"page__taxonomy-item","children":["#","Multiplication"]}],["$","span","Long-Range Dependencies",{"className":"page__taxonomy-item","children":["#","Long-Range Dependencies"]}],["$","span","Implicit Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Implicit Chain-of-Thought"]}],["$","span","Attention Mechanisms",{"className":"page__taxonomy-item","children":["#","Attention Mechanisms"]}],["$","span","Inductive Bias",{"className":"page__taxonomy-item","children":["#","Inductive Bias"]}],["$","span","Reverse Engineering",{"className":"page__taxonomy-item","children":["#","Reverse Engineering"]}]]}]]}]]}],["$","article","2025-10-2-VLM-FO1_Bridging_the_Gap_Between_High-Level_Reasoning_and_Fine-Grained_Perception_in_VLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-VLM-FO1_Bridging_the_Gap_Between_High-Level_Reasoning_and_Fine-Grained_Perception_in_VLMs/","children":"[논문리뷰] VLM-FO1: Bridging the Gap Between High-Level Reasoning and Fine-Grained Perception in VLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'VLM-FO1: Bridging the Gap Between High-Level Reasoning and Fine-Grained Perception in VLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Object Grounding",{"className":"page__taxonomy-item","children":["#","Object Grounding"]}],["$","span","Fine-grained Perception",{"className":"page__taxonomy-item","children":["#","Fine-grained Perception"]}],["$","span","Hybrid Region Encoder",{"className":"page__taxonomy-item","children":["#","Hybrid Region Encoder"]}],["$","span","Plug-and-play",{"className":"page__taxonomy-item","children":["#","Plug-and-play"]}],["$","span","Two-stage Training",{"className":"page__taxonomy-item","children":["#","Two-stage Training"]}],["$","span","Visual Reasoning",{"className":"page__taxonomy-item","children":["#","Visual Reasoning"]}]]}]]}]]}],["$","article","2025-10-2-VLA-RFT_Vision-Language-Action_Reinforcement_Fine-tuning_with_Verified_Rewards_in_World_Simulators",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-VLA-RFT_Vision-Language-Action_Reinforcement_Fine-tuning_with_Verified_Rewards_in_World_Simulators/","children":"[논문리뷰] VLA-RFT: Vision-Language-Action Reinforcement Fine-tuning with Verified Rewards in World Simulators"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zirui Ge이 [arXiv]에 게시한 'VLA-RFT: Vision-Language-Action Reinforcement Fine-tuning with Verified Rewards in World Simulators' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","World Models",{"className":"page__taxonomy-item","children":["#","World Models"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Reward Design",{"className":"page__taxonomy-item","children":["#","Reward Design"]}],["$","span","Distribution Shift",{"className":"page__taxonomy-item","children":["#","Distribution Shift"]}]]}]]}]]}],["$","article","2025-10-2-Training_Vision-Language_Process_Reward_Models_for_Test-Time_Scaling_in_Multimodal_Reasoning_Key_Insights_and_Lessons_Learned",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-Training_Vision-Language_Process_Reward_Models_for_Test-Time_Scaling_in_Multimodal_Reasoning_Key_Insights_and_Lessons_Learned/","children":"[논문리뷰] Training Vision-Language Process Reward Models for Test-Time Scaling in Multimodal Reasoning: Key Insights and Lessons Learned"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Training Vision-Language Process Reward Models for Test-Time Scaling in Multimodal Reasoning: Key Insights and Lessons Learned' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision-Language Models (VLMs)"]}],["$","span","Process Reward Models (PRMs)",{"className":"page__taxonomy-item","children":["#","Process Reward Models (PRMs)"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","span","Test-Time Scaling (TTS)",{"className":"page__taxonomy-item","children":["#","Test-Time Scaling (TTS)"]}],["$","span","Process Supervision",{"className":"page__taxonomy-item","children":["#","Process Supervision"]}],["$","span","Dataset Construction",{"className":"page__taxonomy-item","children":["#","Dataset Construction"]}],["$","span","Perception Errors",{"className":"page__taxonomy-item","children":["#","Perception Errors"]}],["$","span","MCTS",{"className":"page__taxonomy-item","children":["#","MCTS"]}]]}]]}]]}],["$","article","2025-10-2-ReSWD_ReSTIRd_not_shaken._Combining_Reservoir_Sampling_and_Sliced_Wasserstein_Distance_for_Variance_Reduction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-ReSWD_ReSTIRd_not_shaken._Combining_Reservoir_Sampling_and_Sliced_Wasserstein_Distance_for_Variance_Reduction/","children":"[논문리뷰] ReSWD: ReSTIR'd, not shaken. Combining Reservoir Sampling and Sliced Wasserstein Distance for Variance Reduction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'ReSWD: ReSTIR'd, not shaken. Combining Reservoir Sampling and Sliced Wasserstein Distance for Variance Reduction' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Sliced Wasserstein Distance",{"className":"page__taxonomy-item","children":["#","Sliced Wasserstein Distance"]}],["$","span","Reservoir Sampling",{"className":"page__taxonomy-item","children":["#","Reservoir Sampling"]}],["$","span","Variance Reduction",{"className":"page__taxonomy-item","children":["#","Variance Reduction"]}],["$","span","Distribution Matching",{"className":"page__taxonomy-item","children":["#","Distribution Matching"]}],["$","span","Diffusion Guidance",{"className":"page__taxonomy-item","children":["#","Diffusion Guidance"]}],["$","span","Color Correction",{"className":"page__taxonomy-item","children":["#","Color Correction"]}],["$","span","Monte Carlo Estimation",{"className":"page__taxonomy-item","children":["#","Monte Carlo Estimation"]}]]}]]}]]}],["$","article","2025-10-2-PIPer_On-Device_Environment_Setup_via_Online_Reinforcement_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-PIPer_On-Device_Environment_Setup_via_Online_Reinforcement_Learning/","children":"[논문리뷰] PIPer: On-Device Environment Setup via Online Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'PIPer: On-Device Environment Setup via Online Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Environment Setup",{"className":"page__taxonomy-item","children":["#","Environment Setup"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","On-device AI",{"className":"page__taxonomy-item","children":["#","On-device AI"]}],["$","span","Software Engineering",{"className":"page__taxonomy-item","children":["#","Software Engineering"]}],["$","span","Verifiable Rewards",{"className":"page__taxonomy-item","children":["#","Verifiable Rewards"]}]]}]]}]]}],["$","article","2025-10-2-On_Predictability_of_Reinforcement_Learning_Dynamics_for_Large_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-On_Predictability_of_Reinforcement_Learning_Dynamics_for_Large_Language_Models/","children":"[논문리뷰] On Predictability of Reinforcement Learning Dynamics for Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuqing Huang이 [arXiv]에 게시한 'On Predictability of Reinforcement Learning Dynamics for Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Parameter Dynamics",{"className":"page__taxonomy-item","children":["#","Parameter Dynamics"]}],["$","span","Rank-1 Dominance",{"className":"page__taxonomy-item","children":["#","Rank-1 Dominance"]}],["$","span","Linear Dynamics",{"className":"page__taxonomy-item","children":["#","Linear Dynamics"]}],["$","span","SVD",{"className":"page__taxonomy-item","children":["#","SVD"]}],["$","span","Model Acceleration",{"className":"page__taxonomy-item","children":["#","Model Acceleration"]}],["$","span","Predictability",{"className":"page__taxonomy-item","children":["#","Predictability"]}]]}]]}]]}],["$","article","2025-10-2-Making_not_Taking_the_Best_of_N",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-Making_not_Taking_the_Best_of_N/","children":"[논문리뷰] Making, not Taking, the Best of N"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Making, not Taking, the Best of N' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Aggregation",{"className":"page__taxonomy-item","children":["#","LLM Aggregation"]}],["$","span","Generative Fusion",{"className":"page__taxonomy-item","children":["#","Generative Fusion"]}],["$","span","Best-of-N",{"className":"page__taxonomy-item","children":["#","Best-of-N"]}],["$","span","Synthetic Data Generation",{"className":"page__taxonomy-item","children":["#","Synthetic Data Generation"]}],["$","span","Test-Time Scaling",{"className":"page__taxonomy-item","children":["#","Test-Time Scaling"]}],["$","span","Multilingual Models",{"className":"page__taxonomy-item","children":["#","Multilingual Models"]}],["$","span","Ensemble Learning",{"className":"page__taxonomy-item","children":["#","Ensemble Learning"]}]]}]]}]]}],["$","article","2025-10-2-Knapsack_RL_Unlocking_Exploration_of_LLMs_via_Optimizing_Budget_Allocation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-Knapsack_RL_Unlocking_Exploration_of_LLMs_via_Optimizing_Budget_Allocation/","children":"[논문리뷰] Knapsack RL: Unlocking Exploration of LLMs via Optimizing Budget Allocation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Knapsack RL: Unlocking Exploration of LLMs via Optimizing Budget Allocation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Exploration Budget Allocation",{"className":"page__taxonomy-item","children":["#","Exploration Budget Allocation"]}],["$","span","Knapsack Problem",{"className":"page__taxonomy-item","children":["#","Knapsack Problem"]}],["$","span","Group Relative Policy Optimization (GRPO)",{"className":"page__taxonomy-item","children":["#","Group Relative Policy Optimization (GRPO)"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Resource Optimization",{"className":"page__taxonomy-item","children":["#","Resource Optimization"]}]]}]]}]]}],["$","article","2025-10-2-JoyAgent-JDGenie_Technical_Report_on_the_GAIA",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-JoyAgent-JDGenie_Technical_Report_on_the_GAIA/","children":"[논문리뷰] JoyAgent-JDGenie: Technical Report on the GAIA"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'JoyAgent-JDGenie: Technical Report on the GAIA' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Generalist Agent",{"className":"page__taxonomy-item","children":["#","Generalist Agent"]}],["$","span","Multi-Agent System",{"className":"page__taxonomy-item","children":["#","Multi-Agent System"]}],["$","span","Plan-Execute",{"className":"page__taxonomy-item","children":["#","Plan-Execute"]}],["$","span","ReAct",{"className":"page__taxonomy-item","children":["#","ReAct"]}],["$","span","Hierarchical Memory",{"className":"page__taxonomy-item","children":["#","Hierarchical Memory"]}],["$","span","Tool Integration",{"className":"page__taxonomy-item","children":["#","Tool Integration"]}],["$","span","GAIA Benchmark",{"className":"page__taxonomy-item","children":["#","GAIA Benchmark"]}],["$","span","LLM Agent",{"className":"page__taxonomy-item","children":["#","LLM Agent"]}]]}]]}]]}],["$","article","2025-10-2-Infusing_Theory_of_Mind_into_Socially_Intelligent_LLM_Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-Infusing_Theory_of_Mind_into_Socially_Intelligent_LLM_Agents/","children":"[논문리뷰] Infusing Theory of Mind into Socially Intelligent LLM Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Infusing Theory of Mind into Socially Intelligent LLM Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Theory of Mind",{"className":"page__taxonomy-item","children":["#","Theory of Mind"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Social Agents",{"className":"page__taxonomy-item","children":["#","Social Agents"]}],["$","span","Dialogue Systems",{"className":"page__taxonomy-item","children":["#","Dialogue Systems"]}],["$","span","Mental State Modeling",{"className":"page__taxonomy-item","children":["#","Mental State Modeling"]}],["$","span","Look-ahead Planning",{"className":"page__taxonomy-item","children":["#","Look-ahead Planning"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Sotopia Benchmark",{"className":"page__taxonomy-item","children":["#","Sotopia Benchmark"]}]]}]]}]]}],["$","article","2025-10-2-In-Place_Feedback_A_New_Paradigm_for_Guiding_LLMs_in_Multi-Turn_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-In-Place_Feedback_A_New_Paradigm_for_Guiding_LLMs_in_Multi-Turn_Reasoning/","children":"[논문리뷰] In-Place Feedback: A New Paradigm for Guiding LLMs in Multi-Turn Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chaehyeon Chung이 [arXiv]에 게시한 'In-Place Feedback: A New Paradigm for Guiding LLMs in Multi-Turn Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Feedback",{"className":"page__taxonomy-item","children":["#","LLM Feedback"]}],["$","span","Multi-turn Reasoning",{"className":"page__taxonomy-item","children":["#","Multi-turn Reasoning"]}],["$","span","In-place Editing",{"className":"page__taxonomy-item","children":["#","In-place Editing"]}],["$","span","Token Efficiency",{"className":"page__taxonomy-item","children":["#","Token Efficiency"]}],["$","span","Error Correction",{"className":"page__taxonomy-item","children":["#","Error Correction"]}],["$","span","Human-AI Interaction",{"className":"page__taxonomy-item","children":["#","Human-AI Interaction"]}],["$","span","Reasoning Tasks",{"className":"page__taxonomy-item","children":["#","Reasoning Tasks"]}]]}]]}]]}],["$","article","2025-10-2-Hyperdimensional_Probe_Decoding_LLM_Representations_via_Vector_Symbolic_Architectures",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-Hyperdimensional_Probe_Decoding_LLM_Representations_via_Vector_Symbolic_Architectures/","children":"[논문리뷰] Hyperdimensional Probe: Decoding LLM Representations via Vector Symbolic Architectures"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Andrea Passerini이 [arXiv]에 게시한 'Hyperdimensional Probe: Decoding LLM Representations via Vector Symbolic Architectures' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Interpretability",{"className":"page__taxonomy-item","children":["#","LLM Interpretability"]}],["$","span","Vector Symbolic Architectures",{"className":"page__taxonomy-item","children":["#","Vector Symbolic Architectures"]}],["$","span","Neural Probing",{"className":"page__taxonomy-item","children":["#","Neural Probing"]}],["$","span","Information Decoding",{"className":"page__taxonomy-item","children":["#","Information Decoding"]}],["$","span","Hyperdimensional Computing",{"className":"page__taxonomy-item","children":["#","Hyperdimensional Computing"]}],["$","span","Latent Representations",{"className":"page__taxonomy-item","children":["#","Latent Representations"]}]]}]]}]]}],["$","article","2025-10-2-GUI-KV_Efficient_GUI_Agents_via_KV_Cache_with_Spatio-Temporal_Awareness",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-GUI-KV_Efficient_GUI_Agents_via_KV_Cache_with_Spatio-Temporal_Awareness/","children":"[논문리뷰] GUI-KV: Efficient GUI Agents via KV Cache with Spatio-Temporal Awareness"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chien-Sheng Wu이 [arXiv]에 게시한 'GUI-KV: Efficient GUI Agents via KV Cache with Spatio-Temporal Awareness' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","GUI Agents",{"className":"page__taxonomy-item","children":["#","GUI Agents"]}],["$","span","KV Cache Compression",{"className":"page__taxonomy-item","children":["#","KV Cache Compression"]}],["$","span","Spatio-Temporal Awareness",{"className":"page__taxonomy-item","children":["#","Spatio-Temporal Awareness"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Efficiency",{"className":"page__taxonomy-item","children":["#","Efficiency"]}],["$","span","Attention Sparsity",{"className":"page__taxonomy-item","children":["#","Attention Sparsity"]}],["$","span","QR Decomposition",{"className":"page__taxonomy-item","children":["#","QR Decomposition"]}]]}]]}]]}],["$","article","2025-10-2-GEM_A_Gym_for_Agentic_LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-GEM_A_Gym_for_Agentic_LLMs/","children":"[논문리뷰] GEM: A Gym for Agentic LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'GEM: A Gym for Agentic LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic LLMs",{"className":"page__taxonomy-item","children":["#","Agentic LLMs"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Environment Simulator",{"className":"page__taxonomy-item","children":["#","Environment Simulator"]}],["$","span","Multi-turn Interactions",{"className":"page__taxonomy-item","children":["#","Multi-turn Interactions"]}],["$","span","Return Batch Normalization",{"className":"page__taxonomy-item","children":["#","Return Batch Normalization"]}],["$","span","Tool Integration",{"className":"page__taxonomy-item","children":["#","Tool Integration"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}]]}]]}]]}],["$","article","2025-10-2-Flash-Searcher_Fast_and_Effective_Web_Agents_via_DAG-Based_Parallel_Execution",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-Flash-Searcher_Fast_and_Effective_Web_Agents_via_DAG-Based_Parallel_Execution/","children":"[논문리뷰] Flash-Searcher: Fast and Effective Web Agents via DAG-Based Parallel Execution"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Flash-Searcher: Fast and Effective Web Agents via DAG-Based Parallel Execution' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Parallel Execution",{"className":"page__taxonomy-item","children":["#","Parallel Execution"]}],["$","span","DAG-based Planning",{"className":"page__taxonomy-item","children":["#","DAG-based Planning"]}],["$","span","Tool Orchestration",{"className":"page__taxonomy-item","children":["#","Tool Orchestration"]}],["$","span","Web Agents",{"className":"page__taxonomy-item","children":["#","Web Agents"]}],["$","span","Reasoning Framework",{"className":"page__taxonomy-item","children":["#","Reasoning Framework"]}],["$","span","Efficiency",{"className":"page__taxonomy-item","children":["#","Efficiency"]}]]}]]}]]}],["$","article","2025-10-2-Eliciting_Secret_Knowledge_from_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-Eliciting_Secret_Knowledge_from_Language_Models/","children":"[논문리뷰] Eliciting Secret Knowledge from Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Neel Nanda이 [arXiv]에 게시한 'Eliciting Secret Knowledge from Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Language Models",{"className":"page__taxonomy-item","children":["#","Language Models"]}],["$","span","Secret Elicitation",{"className":"page__taxonomy-item","children":["#","Secret Elicitation"]}],["$","span","Mechanistic Interpretability",{"className":"page__taxonomy-item","children":["#","Mechanistic Interpretability"]}],["$","span","Black-box Methods",{"className":"page__taxonomy-item","children":["#","Black-box Methods"]}],["$","span","White-box Methods",{"className":"page__taxonomy-item","children":["#","White-box Methods"]}],["$","span","AI Auditing",{"className":"page__taxonomy-item","children":["#","AI Auditing"]}],["$","span","Model Organisms",{"className":"page__taxonomy-item","children":["#","Model Organisms"]}],["$","span","Prefill Attacks",{"className":"page__taxonomy-item","children":["#","Prefill Attacks"]}]]}]]}]]}],["$","article","2025-10-2-DeepSearch_Overcome_the_Bottleneck_of_Reinforcement_Learning_with_Verifiable_Rewards_via_Monte_Carlo_Tree_Search",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-DeepSearch_Overcome_the_Bottleneck_of_Reinforcement_Learning_with_Verifiable_Rewards_via_Monte_Carlo_Tree_Search/","children":"[논문리뷰] DeepSearch: Overcome the Bottleneck of Reinforcement Learning with Verifiable Rewards via Monte Carlo Tree Search"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DeepSearch: Overcome the Bottleneck of Reinforcement Learning with Verifiable Rewards via Monte Carlo Tree Search' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning with Verifiable Rewards (RLVR)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning with Verifiable Rewards (RLVR)"]}],["$","span","Monte Carlo Tree Search (MCTS)",{"className":"page__taxonomy-item","children":["#","Monte Carlo Tree Search (MCTS)"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Systematic Exploration",{"className":"page__taxonomy-item","children":["#","Systematic Exploration"]}],["$","span","Adaptive Training",{"className":"page__taxonomy-item","children":["#","Adaptive Training"]}],["$","span","Tree-GRPO",{"className":"page__taxonomy-item","children":["#","Tree-GRPO"]}]]}]]}]]}],["$","article","2025-10-2-CurES_From_Gradient_Analysis_to_Efficient_Curriculum_Learning_for_Reasoning_LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-CurES_From_Gradient_Analysis_to_Efficient_Curriculum_Learning_for_Reasoning_LLMs/","children":"[논문리뷰] CurES: From Gradient Analysis to Efficient Curriculum Learning for Reasoning LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hengyi Cai이 [arXiv]에 게시한 'CurES: From Gradient Analysis to Efficient Curriculum Learning for Reasoning LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Gradient Optimization",{"className":"page__taxonomy-item","children":["#","Gradient Optimization"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Bayesian Inference",{"className":"page__taxonomy-item","children":["#","Bayesian Inference"]}],["$","span","Sample Efficiency",{"className":"page__taxonomy-item","children":["#","Sample Efficiency"]}]]}]]}]]}],["$","article","2025-10-2-Code2Video_A_Code-centric_Paradigm_for_Educational_Video_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-Code2Video_A_Code-centric_Paradigm_for_Educational_Video_Generation/","children":"[논문리뷰] Code2Video: A Code-centric Paradigm for Educational Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Code2Video: A Code-centric Paradigm for Educational Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Educational Video Generation",{"className":"page__taxonomy-item","children":["#","Educational Video Generation"]}],["$","span","Code-centric AI",{"className":"page__taxonomy-item","children":["#","Code-centric AI"]}],["$","span","Multi-agent Framework",{"className":"page__taxonomy-item","children":["#","Multi-agent Framework"]}],["$","span","Manim",{"className":"page__taxonomy-item","children":["#","Manim"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Knowledge Transfer",{"className":"page__taxonomy-item","children":["#","Knowledge Transfer"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","MMMC Benchmark",{"className":"page__taxonomy-item","children":["#","MMMC Benchmark"]}]]}]]}]]}],["$","article","2025-10-2-BroRL_Scaling_Reinforcement_Learning_via_Broadened_Exploration",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-BroRL_Scaling_Reinforcement_Learning_via_Broadened_Exploration/","children":"[논문리뷰] BroRL: Scaling Reinforcement Learning via Broadened Exploration"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'BroRL: Scaling Reinforcement Learning via Broadened Exploration' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Scaling Laws",{"className":"page__taxonomy-item","children":["#","Scaling Laws"]}],["$","span","Exploration",{"className":"page__taxonomy-item","children":["#","Exploration"]}],["$","span","Rollout Size",{"className":"page__taxonomy-item","children":["#","Rollout Size"]}],["$","span","Verifiable Rewards",{"className":"page__taxonomy-item","children":["#","Verifiable Rewards"]}],["$","span","PPO",{"className":"page__taxonomy-item","children":["#","PPO"]}],["$","span","Mass Balance Equation",{"className":"page__taxonomy-item","children":["#","Mass Balance Equation"]}]]}]]}]]}],["$","article","2025-10-2-Boolean_Satisfiability_via_Imitation_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-Boolean_Satisfiability_via_Imitation_Learning/","children":"[논문리뷰] Boolean Satisfiability via Imitation Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiangyu Xu이 [arXiv]에 게시한 'Boolean Satisfiability via Imitation Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Boolean Satisfiability",{"className":"page__taxonomy-item","children":["#","Boolean Satisfiability"]}],["$","span","Imitation Learning",{"className":"page__taxonomy-item","children":["#","Imitation Learning"]}],["$","span","CDCL Solvers",{"className":"page__taxonomy-item","children":["#","CDCL Solvers"]}],["$","span","Branching Policy",{"className":"page__taxonomy-item","children":["#","Branching Policy"]}],["$","span","KeyTrace",{"className":"page__taxonomy-item","children":["#","KeyTrace"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Perceiver AR",{"className":"page__taxonomy-item","children":["#","Perceiver AR"]}]]}]]}]]}],["$","article","2025-10-2-BindWeave_Subject-Consistent_Video_Generation_via_Cross-Modal_Integration",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-BindWeave_Subject-Consistent_Video_Generation_via_Cross-Modal_Integration/","children":"[논문리뷰] BindWeave: Subject-Consistent Video Generation via Cross-Modal Integration"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiangyang Xia이 [arXiv]에 게시한 'BindWeave: Subject-Consistent Video Generation via Cross-Modal Integration' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Subject Consistency",{"className":"page__taxonomy-item","children":["#","Subject Consistency"]}],["$","span","Cross-Modal Integration",{"className":"page__taxonomy-item","children":["#","Cross-Modal Integration"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Multimodal LLM",{"className":"page__taxonomy-item","children":["#","Multimodal LLM"]}],["$","span","Diffusion Transformer",{"className":"page__taxonomy-item","children":["#","Diffusion Transformer"]}],["$","span","Text-to-Video",{"className":"page__taxonomy-item","children":["#","Text-to-Video"]}]]}]]}]]}],["$","article","2025-10-2-BiasFreeBench_a_Benchmark_for_Mitigating_Bias_in_Large_Language_Model_Responses",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-BiasFreeBench_a_Benchmark_for_Mitigating_Bias_in_Large_Language_Model_Responses/","children":"[논문리뷰] BiasFreeBench: a Benchmark for Mitigating Bias in Large Language Model Responses"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Julian McAuley이 [arXiv]에 게시한 'BiasFreeBench: a Benchmark for Mitigating Bias in Large Language Model Responses' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Bias Mitigation",{"className":"page__taxonomy-item","children":["#","LLM Bias Mitigation"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Evaluation Metrics",{"className":"page__taxonomy-item","children":["#","Evaluation Metrics"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Bias-Free Score",{"className":"page__taxonomy-item","children":["#","Bias-Free Score"]}],["$","span","Fairness",{"className":"page__taxonomy-item","children":["#","Fairness"]}]]}]]}]]}],["$","article","2025-10-2-Beyond_Log_Likelihood_Probability-Based_Objectives_for_Supervised_Fine-Tuning_across_the_Model_Capability_Continuum",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-Beyond_Log_Likelihood_Probability-Based_Objectives_for_Supervised_Fine-Tuning_across_the_Model_Capability_Continuum/","children":"[논문리뷰] Beyond Log Likelihood: Probability-Based Objectives for Supervised Fine-Tuning across the Model Capability Continuum"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hanghang Tong이 [arXiv]에 게시한 'Beyond Log Likelihood: Probability-Based Objectives for Supervised Fine-Tuning across the Model Capability Continuum' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Supervised Fine-tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning (SFT)"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Training Objectives",{"className":"page__taxonomy-item","children":["#","Training Objectives"]}],["$","span","Negative Log Likelihood (NLL)",{"className":"page__taxonomy-item","children":["#","Negative Log Likelihood (NLL)"]}],["$","span","Model Capability Continuum",{"className":"page__taxonomy-item","children":["#","Model Capability Continuum"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Probability-based Loss Functions",{"className":"page__taxonomy-item","children":["#","Probability-based Loss Functions"]}]]}]]}]]}],["$","article","2025-10-2-An_Empirical_Study_of_Testing_Practices_in_Open_Source_AI_Agent_Frameworks_and_Agentic_Applications",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-An_Empirical_Study_of_Testing_Practices_in_Open_Source_AI_Agent_Frameworks_and_Agentic_Applications/","children":"[논문리뷰] An Empirical Study of Testing Practices in Open Source AI Agent Frameworks and Agentic Applications"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Bram Adams이 [arXiv]에 게시한 'An Empirical Study of Testing Practices in Open Source AI Agent Frameworks and Agentic Applications' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Agent",{"className":"page__taxonomy-item","children":["#","AI Agent"]}],["$","span","LLM Agent",{"className":"page__taxonomy-item","children":["#","LLM Agent"]}],["$","span","Testing",{"className":"page__taxonomy-item","children":["#","Testing"]}],["$","span","Empirical Study",{"className":"page__taxonomy-item","children":["#","Empirical Study"]}],["$","span","Software Quality",{"className":"page__taxonomy-item","children":["#","Software Quality"]}],["$","span","Agent Frameworks",{"className":"page__taxonomy-item","children":["#","Agent Frameworks"]}],["$","span","Agentic Applications",{"className":"page__taxonomy-item","children":["#","Agentic Applications"]}],["$","span","Non-Determinism",{"className":"page__taxonomy-item","children":["#","Non-Determinism"]}]]}]]}]]}],["$","article","2025-10-2-ACON_Optimizing_Context_Compression_for_Long-horizon_LLM_Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-2-ACON_Optimizing_Context_Compression_for_Long-horizon_LLM_Agents/","children":"[논문리뷰] ACON: Optimizing Context Compression for Long-horizon LLM Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'ACON: Optimizing Context Compression for Long-horizon LLM Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-02 13:30:22+0900","children":"2025년 10월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Context Compression",{"className":"page__taxonomy-item","children":["#","Context Compression"]}],["$","span","Long-horizon Tasks",{"className":"page__taxonomy-item","children":["#","Long-horizon Tasks"]}],["$","span","Prompt Optimization",{"className":"page__taxonomy-item","children":["#","Prompt Optimization"]}],["$","span","Knowledge Distillation",{"className":"page__taxonomy-item","children":["#","Knowledge Distillation"]}],["$","span","Memory Efficiency",{"className":"page__taxonomy-item","children":["#","Memory Efficiency"]}],["$","span","Task Performance",{"className":"page__taxonomy-item","children":["#","Task Performance"]}],["$","span","Failure Analysis",{"className":"page__taxonomy-item","children":["#","Failure Analysis"]}]]}]]}]]}],["$","article","2025-10-1-Winning_the_Pruning_Gamble_A_Unified_Approach_to_Joint_Sample_and_Token_Pruning_for_Efficient_Supervised_Fine-Tuning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Winning_the_Pruning_Gamble_A_Unified_Approach_to_Joint_Sample_and_Token_Pruning_for_Efficient_Supervised_Fine-Tuning/","children":"[논문리뷰] Winning the Pruning Gamble: A Unified Approach to Joint Sample and Token Pruning for Efficient Supervised Fine-Tuning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yue Min이 [arXiv]에 게시한 'Winning the Pruning Gamble: A Unified Approach to Joint Sample and Token Pruning for Efficient Supervised Fine-Tuning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM SFT",{"className":"page__taxonomy-item","children":["#","LLM SFT"]}],["$","span","Data Pruning",{"className":"page__taxonomy-item","children":["#","Data Pruning"]}],["$","span","Sample Pruning",{"className":"page__taxonomy-item","children":["#","Sample Pruning"]}],["$","span","Token Pruning",{"className":"page__taxonomy-item","children":["#","Token Pruning"]}],["$","span","Error-Uncertainty Plane",{"className":"page__taxonomy-item","children":["#","Error-Uncertainty Plane"]}],["$","span","Q-Tuning",{"className":"page__taxonomy-item","children":["#","Q-Tuning"]}],["$","span","Data Efficiency",{"className":"page__taxonomy-item","children":["#","Data Efficiency"]}],["$","span","Dynamic Pruning",{"className":"page__taxonomy-item","children":["#","Dynamic Pruning"]}]]}]]}]]}],["$","article","2025-10-1-Who_invented_deep_residual_learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Who_invented_deep_residual_learning/","children":"[논문리뷰] Who invented deep residual learning?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Juergen Schmidhuber이 [arXiv]에 게시한 'Who invented deep residual learning?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Deep Learning History",{"className":"page__taxonomy-item","children":["#","Deep Learning History"]}],["$","span","Residual Connections",{"className":"page__taxonomy-item","children":["#","Residual Connections"]}],["$","span","Recurrent Neural Networks (RNN)",{"className":"page__taxonomy-item","children":["#","Recurrent Neural Networks (RNN)"]}],["$","span","Long Short-Term Memory (LSTM)",{"className":"page__taxonomy-item","children":["#","Long Short-Term Memory (LSTM)"]}],["$","span","Feedforward Neural Networks (FNN)",{"className":"page__taxonomy-item","children":["#","Feedforward Neural Networks (FNN)"]}],["$","span","Highway Networks",{"className":"page__taxonomy-item","children":["#","Highway Networks"]}],["$","span","ResNet",{"className":"page__taxonomy-item","children":["#","ResNet"]}],["$","span","Vanishing Gradient",{"className":"page__taxonomy-item","children":["#","Vanishing Gradient"]}]]}]]}]]}],["$","article","2025-10-1-Whos_Your_Judge_On_the_Detectability_of_LLM-Generated_Judgments",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Whos_Your_Judge_On_the_Detectability_of_LLM-Generated_Judgments/","children":"[논문리뷰] Who's Your Judge? On the Detectability of LLM-Generated Judgments"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Who's Your Judge? On the Detectability of LLM-Generated Judgments' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM-as-a-judge",{"className":"page__taxonomy-item","children":["#","LLM-as-a-judge"]}],["$","span","Judgment Detection",{"className":"page__taxonomy-item","children":["#","Judgment Detection"]}],["$","span","Bias Quantification",{"className":"page__taxonomy-item","children":["#","Bias Quantification"]}],["$","span","Feature Engineering",{"className":"page__taxonomy-item","children":["#","Feature Engineering"]}],["$","span","Interpretability",{"className":"page__taxonomy-item","children":["#","Interpretability"]}],["$","span","Peer Review",{"className":"page__taxonomy-item","children":["#","Peer Review"]}],["$","span","AI Ethics",{"className":"page__taxonomy-item","children":["#","AI Ethics"]}],["$","span","Evaluation",{"className":"page__taxonomy-item","children":["#","Evaluation"]}]]}]]}]]}],["$","article","2025-10-1-Voice_Evaluation_of_Reasoning_Ability_Diagnosing_the_Modality-Induced_Performance_Gap",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Voice_Evaluation_of_Reasoning_Ability_Diagnosing_the_Modality-Induced_Performance_Gap/","children":"[논문리뷰] Voice Evaluation of Reasoning Ability: Diagnosing the Modality-Induced Performance Gap"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hengfan Zhang이 [arXiv]에 게시한 'Voice Evaluation of Reasoning Ability: Diagnosing the Modality-Induced Performance Gap' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Voice AI",{"className":"page__taxonomy-item","children":["#","Voice AI"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Modality Gap",{"className":"page__taxonomy-item","children":["#","Modality Gap"]}],["$","span","Latency",{"className":"page__taxonomy-item","children":["#","Latency"]}],["$","span","Speech Recognition",{"className":"page__taxonomy-item","children":["#","Speech Recognition"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Real-time Systems",{"className":"page__taxonomy-item","children":["#","Real-time Systems"]}],["$","span","Conversational AI",{"className":"page__taxonomy-item","children":["#","Conversational AI"]}]]}]]}]]}],["$","article","2025-10-1-VitaBench_Benchmarking_LLM_Agents_with_Versatile_Interactive_Tasks_in_Real-world_Applications",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-VitaBench_Benchmarking_LLM_Agents_with_Versatile_Interactive_Tasks_in_Real-world_Applications/","children":"[논문리뷰] VitaBench: Benchmarking LLM Agents with Versatile Interactive Tasks in Real-world Applications"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'VitaBench: Benchmarking LLM Agents with Versatile Interactive Tasks in Real-world Applications' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Interactive Tasks",{"className":"page__taxonomy-item","children":["#","Interactive Tasks"]}],["$","span","Real-world Applications",{"className":"page__taxonomy-item","children":["#","Real-world Applications"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Multi-turn Conversation",{"className":"page__taxonomy-item","children":["#","Multi-turn Conversation"]}],["$","span","Task Complexity",{"className":"page__taxonomy-item","children":["#","Task Complexity"]}]]}]]}]]}],["$","article","2025-10-1-VisualOverload_Probing_Visual_Understanding_of_VLMs_in_Really_Dense_Scenes",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-VisualOverload_Probing_Visual_Understanding_of_VLMs_in_Really_Dense_Scenes/","children":"[논문리뷰] VisualOverload: Probing Visual Understanding of VLMs in Really Dense Scenes"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Muhammad Huzaifa이 [arXiv]에 게시한 'VisualOverload: Probing Visual Understanding of VLMs in Really Dense Scenes' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Visual Question Answering",{"className":"page__taxonomy-item","children":["#","Visual Question Answering"]}],["$","span","Multimodal Models",{"className":"page__taxonomy-item","children":["#","Multimodal Models"]}],["$","span","Dense Scenes",{"className":"page__taxonomy-item","children":["#","Dense Scenes"]}],["$","span","Fine-Grained Perception",{"className":"page__taxonomy-item","children":["#","Fine-Grained Perception"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Error Analysis",{"className":"page__taxonomy-item","children":["#","Error Analysis"]}],["$","span","Counting",{"className":"page__taxonomy-item","children":["#","Counting"]}],["$","span","OCR",{"className":"page__taxonomy-item","children":["#","OCR"]}]]}]]}]]}],["$","article","2025-10-1-Vision-Zero_Scalable_VLM_Self-Improvement_via_Strategic_Gamified_Self-Play",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Vision-Zero_Scalable_VLM_Self-Improvement_via_Strategic_Gamified_Self-Play/","children":"[논문리뷰] Vision-Zero: Scalable VLM Self-Improvement via Strategic Gamified Self-Play"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jing Shi이 [arXiv]에 게시한 'Vision-Zero: Scalable VLM Self-Improvement via Strategic Gamified Self-Play' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision-Language Models (VLMs)"]}],["$","span","Self-Play",{"className":"page__taxonomy-item","children":["#","Self-Play"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Gamification",{"className":"page__taxonomy-item","children":["#","Gamification"]}],["$","span","Data Efficiency",{"className":"page__taxonomy-item","children":["#","Data Efficiency"]}],["$","span","Strategic Reasoning",{"className":"page__taxonomy-item","children":["#","Strategic Reasoning"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Self-Improvement",{"className":"page__taxonomy-item","children":["#","Self-Improvement"]}]]}]]}]]}],["$","article","2025-10-1-TTT3R_3D_Reconstruction_as_Test-Time_Training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-TTT3R_3D_Reconstruction_as_Test-Time_Training/","children":"[논문리뷰] TTT3R: 3D Reconstruction as Test-Time Training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Anpei Chen이 [arXiv]에 게시한 'TTT3R: 3D Reconstruction as Test-Time Training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Reconstruction",{"className":"page__taxonomy-item","children":["#","3D Reconstruction"]}],["$","span","Test-Time Training (TTT)",{"className":"page__taxonomy-item","children":["#","Test-Time Training (TTT)"]}],["$","span","Recurrent Neural Networks (RNN)",{"className":"page__taxonomy-item","children":["#","Recurrent Neural Networks (RNN)"]}],["$","span","Online Learning",{"className":"page__taxonomy-item","children":["#","Online Learning"]}],["$","span","Length Generalization",{"className":"page__taxonomy-item","children":["#","Length Generalization"]}],["$","span","Associative Memory",{"className":"page__taxonomy-item","children":["#","Associative Memory"]}],["$","span","State Update Rule",{"className":"page__taxonomy-item","children":["#","State Update Rule"]}]]}]]}]]}],["$","article","2025-10-1-TruthRL_Incentivizing_Truthful_LLMs_via_Reinforcement_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-TruthRL_Incentivizing_Truthful_LLMs_via_Reinforcement_Learning/","children":"[논문리뷰] TruthRL: Incentivizing Truthful LLMs via Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'TruthRL: Incentivizing Truthful LLMs via Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Hallucination",{"className":"page__taxonomy-item","children":["#","LLM Hallucination"]}],["$","span","Truthfulness",{"className":"page__taxonomy-item","children":["#","Truthfulness"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Ternary Reward",{"className":"page__taxonomy-item","children":["#","Ternary Reward"]}],["$","span","Abstention",{"className":"page__taxonomy-item","children":["#","Abstention"]}],["$","span","Knowledge Boundary",{"className":"page__taxonomy-item","children":["#","Knowledge Boundary"]}],["$","span","GRPO",{"className":"page__taxonomy-item","children":["#","GRPO"]}],["$","span","RLHF",{"className":"page__taxonomy-item","children":["#","RLHF"]}]]}]]}]]}],["$","article","2025-10-1-Thinking_Sparks_Emergent_Attention_Heads_in_Reasoning_Models_During_Post_Training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Thinking_Sparks_Emergent_Attention_Heads_in_Reasoning_Models_During_Post_Training/","children":"[논문리뷰] Thinking Sparks!: Emergent Attention Heads in Reasoning Models During Post Training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Thinking Sparks!: Emergent Attention Heads in Reasoning Models During Post Training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Mechanistic Interpretability",{"className":"page__taxonomy-item","children":["#","Mechanistic Interpretability"]}],["$","span","Attention Heads",{"className":"page__taxonomy-item","children":["#","Attention Heads"]}],["$","span","Post-Training",{"className":"page__taxonomy-item","children":["#","Post-Training"]}],["$","span","Supervised Fine-Tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning (SFT)"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Circuit Analysis",{"className":"page__taxonomy-item","children":["#","Circuit Analysis"]}],["$","span","Reasoning Models",{"className":"page__taxonomy-item","children":["#","Reasoning Models"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}]]}]]}]]}],["$","article","2025-10-1-The_Dragon_Hatchling_The_Missing_Link_between_the_Transformer_and_Models_of_the_Brain",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-The_Dragon_Hatchling_The_Missing_Link_between_the_Transformer_and_Models_of_the_Brain/","children":"[논문리뷰] The Dragon Hatchling: The Missing Link between the Transformer and Models of the Brain"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'The Dragon Hatchling: The Missing Link between the Transformer and Models of the Brain' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Brain-Inspired AI",{"className":"page__taxonomy-item","children":["#","Brain-Inspired AI"]}],["$","span","Graph Neural Networks",{"className":"page__taxonomy-item","children":["#","Graph Neural Networks"]}],["$","span","Hebbian Learning",{"className":"page__taxonomy-item","children":["#","Hebbian Learning"]}],["$","span","Scale-Free Networks",{"className":"page__taxonomy-item","children":["#","Scale-Free Networks"]}],["$","span","Model Interpretability",{"className":"page__taxonomy-item","children":["#","Model Interpretability"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}]]}]]}]]}],["$","article","2025-10-1-Test-Time_Policy_Adaptation_for_Enhanced_Multi-Turn_Interactions_with_LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Test-Time_Policy_Adaptation_for_Enhanced_Multi-Turn_Interactions_with_LLMs/","children":"[논문리뷰] Test-Time Policy Adaptation for Enhanced Multi-Turn Interactions with LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yao Shu이 [arXiv]에 게시한 'Test-Time Policy Adaptation for Enhanced Multi-Turn Interactions with LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Multi-turn Interaction",{"className":"page__taxonomy-item","children":["#","Multi-turn Interaction"]}],["$","span","Test-Time Adaptation",{"className":"page__taxonomy-item","children":["#","Test-Time Adaptation"]}],["$","span","Reinforcement Learning from Human Feedback",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning from Human Feedback"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Online Learning",{"className":"page__taxonomy-item","children":["#","Online Learning"]}],["$","span","Self-Correction",{"className":"page__taxonomy-item","children":["#","Self-Correction"]}]]}]]}]]}],["$","article","2025-10-1-TAU_A_Benchmark_for_Cultural_Sound_Understanding_Beyond_Semantics",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-TAU_A_Benchmark_for_Cultural_Sound_Understanding_Beyond_Semantics/","children":"[논문리뷰] TAU: A Benchmark for Cultural Sound Understanding Beyond Semantics"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Szu-Chi Chen이 [arXiv]에 게시한 'TAU: A Benchmark for Cultural Sound Understanding Beyond Semantics' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Audio Language Models",{"className":"page__taxonomy-item","children":["#","Audio Language Models"]}],["$","span","Cultural Sound Understanding",{"className":"page__taxonomy-item","children":["#","Cultural Sound Understanding"]}],["$","span","Localized Benchmark",{"className":"page__taxonomy-item","children":["#","Localized Benchmark"]}],["$","span","Non-semantic Audio",{"className":"page__taxonomy-item","children":["#","Non-semantic Audio"]}],["$","span","Human-in-the-loop",{"className":"page__taxonomy-item","children":["#","Human-in-the-loop"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Taipei Soundscape",{"className":"page__taxonomy-item","children":["#","Taipei Soundscape"]}]]}]]}]]}],["$","article","2025-10-1-Stable_Cinemetrics_Structured_Taxonomy_and_Evaluation_for_Professional_Video_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Stable_Cinemetrics_Structured_Taxonomy_and_Evaluation_for_Professional_Video_Generation/","children":"[논문리뷰] Stable Cinemetrics : Structured Taxonomy and Evaluation for Professional Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Stable Cinemetrics : Structured Taxonomy and Evaluation for Professional Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Evaluation Framework",{"className":"page__taxonomy-item","children":["#","Evaluation Framework"]}],["$","span","Cinematic Control",{"className":"page__taxonomy-item","children":["#","Cinematic Control"]}],["$","span","Taxonomy",{"className":"page__taxonomy-item","children":["#","Taxonomy"]}],["$","span","Human Annotation",{"className":"page__taxonomy-item","children":["#","Human Annotation"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Text-to-Video",{"className":"page__taxonomy-item","children":["#","Text-to-Video"]}]]}]]}]]}],["$","article","2025-10-1-Specialization_after_Generalization_Towards_Understanding_Test-Time_Training_in_Foundation_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Specialization_after_Generalization_Towards_Understanding_Test-Time_Training_in_Foundation_Models/","children":"[논문리뷰] Specialization after Generalization: Towards Understanding Test-Time Training in Foundation Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Specialization after Generalization: Towards Understanding Test-Time Training in Foundation Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Test-Time Training (TTT)",{"className":"page__taxonomy-item","children":["#","Test-Time Training (TTT)"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Underparameterization",{"className":"page__taxonomy-item","children":["#","Underparameterization"]}],["$","span","Sparse Autoencoders (SAE)",{"className":"page__taxonomy-item","children":["#","Sparse Autoencoders (SAE)"]}],["$","span","Linear Representation Hypothesis (LRH)",{"className":"page__taxonomy-item","children":["#","Linear Representation Hypothesis (LRH)"]}],["$","span","Specialization",{"className":"page__taxonomy-item","children":["#","Specialization"]}],["$","span","Scaling Laws",{"className":"page__taxonomy-item","children":["#","Scaling Laws"]}],["$","span","In-Distribution Data",{"className":"page__taxonomy-item","children":["#","In-Distribution Data"]}]]}]]}]]}],["$","article","2025-10-1-Regression_Language_Models_for_Code",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Regression_Language_Models_for_Code/","children":"[논문리뷰] Regression Language Models for Code"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Regression Language Models for Code' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Regression Language Model",{"className":"page__taxonomy-item","children":["#","Regression Language Model"]}],["$","span","Code Performance Prediction",{"className":"page__taxonomy-item","children":["#","Code Performance Prediction"]}],["$","span","Static Analysis",{"className":"page__taxonomy-item","children":["#","Static Analysis"]}],["$","span","Neural Architecture Search",{"className":"page__taxonomy-item","children":["#","Neural Architecture Search"]}],["$","span","Text-to-Text Regression",{"className":"page__taxonomy-item","children":["#","Text-to-Text Regression"]}],["$","span","Multi-task Learning",{"className":"page__taxonomy-item","children":["#","Multi-task Learning"]}],["$","span","T5Gemma",{"className":"page__taxonomy-item","children":["#","T5Gemma"]}],["$","span","ONNX",{"className":"page__taxonomy-item","children":["#","ONNX"]}]]}]]}]]}],["$","article","2025-10-1-ProfVLM_A_Lightweight_Video-Language_Model_for_Multi-View_Proficiency_Estimation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-ProfVLM_A_Lightweight_Video-Language_Model_for_Multi-View_Proficiency_Estimation/","children":"[논문리뷰] ProfVLM: A Lightweight Video-Language Model for Multi-View Proficiency Estimation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Antonio Liotta이 [arXiv]에 게시한 'ProfVLM: A Lightweight Video-Language Model for Multi-View Proficiency Estimation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video-Language Model",{"className":"page__taxonomy-item","children":["#","Video-Language Model"]}],["$","span","Proficiency Estimation",{"className":"page__taxonomy-item","children":["#","Proficiency Estimation"]}],["$","span","Multi-View Video",{"className":"page__taxonomy-item","children":["#","Multi-View Video"]}],["$","span","Action Quality Assessment",{"className":"page__taxonomy-item","children":["#","Action Quality Assessment"]}],["$","span","Lightweight Model",{"className":"page__taxonomy-item","children":["#","Lightweight Model"]}],["$","span","Generative Feedback",{"className":"page__taxonomy-item","children":["#","Generative Feedback"]}]]}]]}]]}],["$","article","2025-10-1-Probing_the_Critical_Point_CritPt_of_AI_Reasoning_a_Frontier_Physics_Research_Benchmark",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Probing_the_Critical_Point_CritPt_of_AI_Reasoning_a_Frontier_Physics_Research_Benchmark/","children":"[논문리뷰] Probing the Critical Point (CritPt) of AI Reasoning: a Frontier Physics Research Benchmark"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Penghao Zhu이 [arXiv]에 게시한 'Probing the Critical Point (CritPt) of AI Reasoning: a Frontier Physics Research Benchmark' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Reasoning",{"className":"page__taxonomy-item","children":["#","AI Reasoning"]}],["$","span","Physics Research",{"className":"page__taxonomy-item","children":["#","Physics Research"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Scientific Benchmark",{"className":"page__taxonomy-item","children":["#","Scientific Benchmark"]}],["$","span","Frontier Physics",{"className":"page__taxonomy-item","children":["#","Frontier Physics"]}],["$","span","Problem Solving",{"className":"page__taxonomy-item","children":["#","Problem Solving"]}],["$","span","Model Reliability",{"className":"page__taxonomy-item","children":["#","Model Reliability"]}],["$","span","Auto-grading",{"className":"page__taxonomy-item","children":["#","Auto-grading"]}]]}]]}]]}],["$","article","2025-10-1-OffTopicEval_When_Large_Language_Models_Enter_the_Wrong_Chat_Almost_Always",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-OffTopicEval_When_Large_Language_Models_Enter_the_Wrong_Chat_Almost_Always/","children":"[논문리뷰] OffTopicEval: When Large Language Models Enter the Wrong Chat, Almost Always!"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'OffTopicEval: When Large Language Models Enter the Wrong Chat, Almost Always!' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Operational Safety",{"className":"page__taxonomy-item","children":["#","Operational Safety"]}],["$","span","Out-of-Domain (OOD)",{"className":"page__taxonomy-item","children":["#","Out-of-Domain (OOD)"]}],["$","span","Prompt Steering",{"className":"page__taxonomy-item","children":["#","Prompt Steering"]}],["$","span","Jailbreak Attacks",{"className":"page__taxonomy-item","children":["#","Jailbreak Attacks"]}],["$","span","Evaluation Benchmark",{"className":"page__taxonomy-item","children":["#","Evaluation Benchmark"]}],["$","span","Refusal Rate",{"className":"page__taxonomy-item","children":["#","Refusal Rate"]}]]}]]}]]}],["$","article","2025-10-1-OceanGym_A_Benchmark_Environment_for_Underwater_Embodied_Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-OceanGym_A_Benchmark_Environment_for_Underwater_Embodied_Agents/","children":"[논문리뷰] OceanGym: A Benchmark Environment for Underwater Embodied Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'OceanGym: A Benchmark Environment for Underwater Embodied Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Underwater Robotics",{"className":"page__taxonomy-item","children":["#","Underwater Robotics"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Benchmark Environment",{"className":"page__taxonomy-item","children":["#","Benchmark Environment"]}],["$","span","Multi-modal Large Language Models",{"className":"page__taxonomy-item","children":["#","Multi-modal Large Language Models"]}],["$","span","Autonomous Underwater Vehicles",{"className":"page__taxonomy-item","children":["#","Autonomous Underwater Vehicles"]}],["$","span","Perception",{"className":"page__taxonomy-item","children":["#","Perception"]}],["$","span","Decision-Making",{"className":"page__taxonomy-item","children":["#","Decision-Making"]}],["$","span","Simulation",{"className":"page__taxonomy-item","children":["#","Simulation"]}]]}]]}]]}],["$","article","2025-10-1-MotionRAG_Motion_Retrieval-Augmented_Image-to-Video_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-MotionRAG_Motion_Retrieval-Augmented_Image-to-Video_Generation/","children":"[논문리뷰] MotionRAG: Motion Retrieval-Augmented Image-to-Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Limin Wang이 [arXiv]에 게시한 'MotionRAG: Motion Retrieval-Augmented Image-to-Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image-to-Video Generation",{"className":"page__taxonomy-item","children":["#","Image-to-Video Generation"]}],["$","span","Motion Transfer",{"className":"page__taxonomy-item","children":["#","Motion Transfer"]}],["$","span","Retrieval-Augmented Generation (RAG)",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation (RAG)"]}],["$","span","In-Context Learning",{"className":"page__taxonomy-item","children":["#","In-Context Learning"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Video Diffusion",{"className":"page__taxonomy-item","children":["#","Video Diffusion"]}],["$","span","Motion Realism",{"className":"page__taxonomy-item","children":["#","Motion Realism"]}]]}]]}]]}],["$","article","2025-10-1-More_Thought_Less_Accuracy_On_the_Dual_Nature_of_Reasoning_in_Vision-Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-More_Thought_Less_Accuracy_On_the_Dual_Nature_of_Reasoning_in_Vision-Language_Models/","children":"[논문리뷰] More Thought, Less Accuracy? On the Dual Nature of Reasoning in Vision-Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Fabian Waschkowski이 [arXiv]에 게시한 'More Thought, Less Accuracy? On the Dual Nature of Reasoning in Vision-Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Visual Forgetting",{"className":"page__taxonomy-item","children":["#","Visual Forgetting"]}],["$","span","Perceptual Grounding",{"className":"page__taxonomy-item","children":["#","Perceptual Grounding"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Visual Anchors",{"className":"page__taxonomy-item","children":["#","Visual Anchors"]}]]}]]}]]}],["$","article","2025-10-1-Mem-α_Learning_Memory_Construction_via_Reinforcement_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Mem-α_Learning_Memory_Construction_via_Reinforcement_Learning/","children":"[논문리뷰] Mem-α: Learning Memory Construction via Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuzhen Mao이 [arXiv]에 게시한 'Mem-α: Learning Memory Construction via Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","External Memory",{"className":"page__taxonomy-item","children":["#","External Memory"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Memory Management",{"className":"page__taxonomy-item","children":["#","Memory Management"]}],["$","span","Long-Context Understanding",{"className":"page__taxonomy-item","children":["#","Long-Context Understanding"]}],["$","span","Tool Learning",{"className":"page__taxonomy-item","children":["#","Tool Learning"]}],["$","span","RAG",{"className":"page__taxonomy-item","children":["#","RAG"]}],["$","span","Memory Architecture",{"className":"page__taxonomy-item","children":["#","Memory Architecture"]}]]}]]}]]}],["$","article","2025-10-1-MCPMark_A_Benchmark_for_Stress-Testing_Realistic_and_Comprehensive_MCP_Use",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-MCPMark_A_Benchmark_for_Stress-Testing_Realistic_and_Comprehensive_MCP_Use/","children":"[논문리뷰] MCPMark: A Benchmark for Stress-Testing Realistic and Comprehensive MCP Use"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'MCPMark: A Benchmark for Stress-Testing Realistic and Comprehensive MCP Use' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Model Context Protocol",{"className":"page__taxonomy-item","children":["#","Model Context Protocol"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","CRUD Operations",{"className":"page__taxonomy-item","children":["#","CRUD Operations"]}],["$","span","Workflow Automation",{"className":"page__taxonomy-item","children":["#","Workflow Automation"]}],["$","span","Stress Testing",{"className":"page__taxonomy-item","children":["#","Stress Testing"]}],["$","span","Evaluation",{"className":"page__taxonomy-item","children":["#","Evaluation"]}]]}]]}]]}],["$","article","2025-10-1-MANI-Pure_Magnitude-Adaptive_Noise_Injection_for_Adversarial_Purification",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-MANI-Pure_Magnitude-Adaptive_Noise_Injection_for_Adversarial_Purification/","children":"[논문리뷰] MANI-Pure: Magnitude-Adaptive Noise Injection for Adversarial Purification"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhiming Luo이 [arXiv]에 게시한 'MANI-Pure: Magnitude-Adaptive Noise Injection for Adversarial Purification' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Adversarial Purification",{"className":"page__taxonomy-item","children":["#","Adversarial Purification"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Frequency Domain",{"className":"page__taxonomy-item","children":["#","Frequency Domain"]}],["$","span","Adaptive Noise Injection",{"className":"page__taxonomy-item","children":["#","Adaptive Noise Injection"]}],["$","span","Robustness",{"className":"page__taxonomy-item","children":["#","Robustness"]}],["$","span","Image Security",{"className":"page__taxonomy-item","children":["#","Image Security"]}],["$","span","Magnitude Spectrum",{"className":"page__taxonomy-item","children":["#","Magnitude Spectrum"]}]]}]]}]]}],["$","article","2025-10-1-Learning_to_See_Before_Seeing_Demystifying_LLM_Visual_Priors_from_Language_Pre-training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Learning_to_See_Before_Seeing_Demystifying_LLM_Visual_Priors_from_Language_Pre-training/","children":"[논문리뷰] Learning to See Before Seeing: Demystifying LLM Visual Priors from Language Pre-training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Koustuv Sinha이 [arXiv]에 게시한 'Learning to See Before Seeing: Demystifying LLM Visual Priors from Language Pre-training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Visual Priors",{"className":"page__taxonomy-item","children":["#","LLM Visual Priors"]}],["$","span","Language Pre-training",{"className":"page__taxonomy-item","children":["#","Language Pre-training"]}],["$","span","Multimodal LLM",{"className":"page__taxonomy-item","children":["#","Multimodal LLM"]}],["$","span","Data Mixture Optimization",{"className":"page__taxonomy-item","children":["#","Data Mixture Optimization"]}],["$","span","Reasoning Prior",{"className":"page__taxonomy-item","children":["#","Reasoning Prior"]}],["$","span","Perception Prior",{"className":"page__taxonomy-item","children":["#","Perception Prior"]}],["$","span","VQA",{"className":"page__taxonomy-item","children":["#","VQA"]}],["$","span","MLE-Bench",{"className":"page__taxonomy-item","children":["#","MLE-Bench"]}]]}]]}]]}],["$","article","2025-10-1-Learning_Human-Perceived_Fakeness_in_AI-Generated_Videos_via_Multimodal_LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Learning_Human-Perceived_Fakeness_in_AI-Generated_Videos_via_Multimodal_LLMs/","children":"[논문리뷰] Learning Human-Perceived Fakeness in AI-Generated Videos via Multimodal LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Learning Human-Perceived Fakeness in AI-Generated Videos via Multimodal LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI-Generated Videos",{"className":"page__taxonomy-item","children":["#","AI-Generated Videos"]}],["$","span","Deepfake Detection",{"className":"page__taxonomy-item","children":["#","Deepfake Detection"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Human Perception",{"className":"page__taxonomy-item","children":["#","Human Perception"]}],["$","span","Video Generation Evaluation",{"className":"page__taxonomy-item","children":["#","Video Generation Evaluation"]}],["$","span","Spatiotemporal Annotation",{"className":"page__taxonomy-item","children":["#","Spatiotemporal Annotation"]}],["$","span","Reward Modeling",{"className":"page__taxonomy-item","children":["#","Reward Modeling"]}]]}]]}]]}],["$","article","2025-10-1-LayerD_Decomposing_Raster_Graphic_Designs_into_Layers",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-LayerD_Decomposing_Raster_Graphic_Designs_into_Layers/","children":"[논문리뷰] LayerD: Decomposing Raster Graphic Designs into Layers"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kota Yamaguchi이 [arXiv]에 게시한 'LayerD: Decomposing Raster Graphic Designs into Layers' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Graphic Design",{"className":"page__taxonomy-item","children":["#","Graphic Design"]}],["$","span","Image Decomposition",{"className":"page__taxonomy-item","children":["#","Image Decomposition"]}],["$","span","Layer Extraction",{"className":"page__taxonomy-item","children":["#","Layer Extraction"]}],["$","span","Image Matting",{"className":"page__taxonomy-item","children":["#","Image Matting"]}],["$","span","Background Completion",{"className":"page__taxonomy-item","children":["#","Background Completion"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}],["$","span","Creative AI",{"className":"page__taxonomy-item","children":["#","Creative AI"]}],["$","span","Dynamic Time Warping",{"className":"page__taxonomy-item","children":["#","Dynamic Time Warping"]}]]}]]}]]}],["$","article","2025-10-1-Knowledge_Homophily_in_Large_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Knowledge_Homophily_in_Large_Language_Models/","children":"[논문리뷰] Knowledge Homophily in Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Nedim Lipka이 [arXiv]에 게시한 'Knowledge Homophily in Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Knowledge Homophily",{"className":"page__taxonomy-item","children":["#","Knowledge Homophily"]}],["$","span","Graph Neural Networks",{"className":"page__taxonomy-item","children":["#","Graph Neural Networks"]}],["$","span","Knowledge Graph",{"className":"page__taxonomy-item","children":["#","Knowledge Graph"]}],["$","span","Knowledge Injection",{"className":"page__taxonomy-item","children":["#","Knowledge Injection"]}],["$","span","Question Answering",{"className":"page__taxonomy-item","children":["#","Question Answering"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Knowledge Retrieval",{"className":"page__taxonomy-item","children":["#","Knowledge Retrieval"]}]]}]]}]]}],["$","article","2025-10-1-jina-reranker-v3_Last_but_Not_Late_Interaction_for_Document_Reranking",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-jina-reranker-v3_Last_but_Not_Late_Interaction_for_Document_Reranking/","children":"[논문리뷰] jina-reranker-v3: Last but Not Late Interaction for Document Reranking"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'jina-reranker-v3: Last but Not Late Interaction for Document Reranking' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Document Reranking",{"className":"page__taxonomy-item","children":["#","Document Reranking"]}],["$","span","Last but Not Late Interaction",{"className":"page__taxonomy-item","children":["#","Last but Not Late Interaction"]}],["$","span","Multilingual",{"className":"page__taxonomy-item","children":["#","Multilingual"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Cross-Encoder",{"className":"page__taxonomy-item","children":["#","Cross-Encoder"]}],["$","span","InfoNCE Loss",{"className":"page__taxonomy-item","children":["#","InfoNCE Loss"]}],["$","span","Contextual Embedding",{"className":"page__taxonomy-item","children":["#","Contextual Embedding"]}],["$","span","Qwen3",{"className":"page__taxonomy-item","children":["#","Qwen3"]}]]}]]}]]}],["$","article","2025-10-1-InfoAgent_Advancing_Autonomous_Information-Seeking_Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-InfoAgent_Advancing_Autonomous_Information-Seeking_Agents/","children":"[논문리뷰] InfoAgent: Advancing Autonomous Information-Seeking Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'InfoAgent: Advancing Autonomous Information-Seeking Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Information Seeking",{"className":"page__taxonomy-item","children":["#","Information Seeking"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Data Synthesis",{"className":"page__taxonomy-item","children":["#","Data Synthesis"]}],["$","span","Web Search Tools",{"className":"page__taxonomy-item","children":["#","Web Search Tools"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Deep Research Agents",{"className":"page__taxonomy-item","children":["#","Deep Research Agents"]}]]}]]}]]}],["$","article","2025-10-1-IMG_Calibrating_Diffusion_Models_via_Implicit_Multimodal_Guidance",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-IMG_Calibrating_Diffusion_Models_via_Implicit_Multimodal_Guidance/","children":"[논문리뷰] IMG: Calibrating Diffusion Models via Implicit Multimodal Guidance"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'IMG: Calibrating Diffusion Models via Implicit Multimodal Guidance' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Multimodal Alignment",{"className":"page__taxonomy-item","children":["#","Multimodal Alignment"]}],["$","span","MLLM",{"className":"page__taxonomy-item","children":["#","MLLM"]}],["$","span","Image Re-generation",{"className":"page__taxonomy-item","children":["#","Image Re-generation"]}],["$","span","Preference Learning",{"className":"page__taxonomy-item","children":["#","Preference Learning"]}],["$","span","Implicit Guidance",{"className":"page__taxonomy-item","children":["#","Implicit Guidance"]}],["$","span","Text-to-Image",{"className":"page__taxonomy-item","children":["#","Text-to-Image"]}]]}]]}]]}],["$","article","2025-10-1-Humanline_Online_Alignment_as_Perceptual_Loss",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Humanline_Online_Alignment_as_Perceptual_Loss/","children":"[논문리뷰] Humanline: Online Alignment as Perceptual Loss"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Humanline: Online Alignment as Perceptual Loss' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Alignment",{"className":"page__taxonomy-item","children":["#","LLM Alignment"]}],["$","span","Online RLHF",{"className":"page__taxonomy-item","children":["#","Online RLHF"]}],["$","span","Offline RLHF",{"className":"page__taxonomy-item","children":["#","Offline RLHF"]}],["$","span","Prospect Theory",{"className":"page__taxonomy-item","children":["#","Prospect Theory"]}],["$","span","Perceptual Loss",{"className":"page__taxonomy-item","children":["#","Perceptual Loss"]}],["$","span","Human-Centric AI",{"className":"page__taxonomy-item","children":["#","Human-Centric AI"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}]]}]]}]]}],["$","article","2025-10-1-Ferret-UI_Lite_Lessons_from_Building_Small_On-Device_GUI_Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Ferret-UI_Lite_Lessons_from_Building_Small_On-Device_GUI_Agents/","children":"[논문리뷰] Ferret-UI Lite: Lessons from Building Small On-Device GUI Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Ferret-UI Lite: Lessons from Building Small On-Device GUI Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","GUI Agents",{"className":"page__taxonomy-item","children":["#","GUI Agents"]}],["$","span","On-Device AI",{"className":"page__taxonomy-item","children":["#","On-Device AI"]}],["$","span","Multimodal LLM",{"className":"page__taxonomy-item","children":["#","Multimodal LLM"]}],["$","span","GUI Grounding",{"className":"page__taxonomy-item","children":["#","GUI Grounding"]}],["$","span","GUI Navigation",{"className":"page__taxonomy-item","children":["#","GUI Navigation"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Synthetic Data",{"className":"page__taxonomy-item","children":["#","Synthetic Data"]}]]}]]}]]}],["$","article","2025-10-1-Estimating_Time_Series_Foundation_Model_Transferability_via_In-Context_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Estimating_Time_Series_Foundation_Model_Transferability_via_In-Context_Learning/","children":"[논문리뷰] Estimating Time Series Foundation Model Transferability via In-Context Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jun Qi이 [arXiv]에 게시한 'Estimating Time Series Foundation Model Transferability via In-Context Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Time Series Foundation Models",{"className":"page__taxonomy-item","children":["#","Time Series Foundation Models"]}],["$","span","Transferability Estimation",{"className":"page__taxonomy-item","children":["#","Transferability Estimation"]}],["$","span","In-Context Learning",{"className":"page__taxonomy-item","children":["#","In-Context Learning"]}],["$","span","Tabular Foundation Models",{"className":"page__taxonomy-item","children":["#","Tabular Foundation Models"]}],["$","span","Model Selection",{"className":"page__taxonomy-item","children":["#","Model Selection"]}],["$","span","Entropy Profile",{"className":"page__taxonomy-item","children":["#","Entropy Profile"]}],["$","span","Meta-learning",{"className":"page__taxonomy-item","children":["#","Meta-learning"]}],["$","span","Forecasting",{"className":"page__taxonomy-item","children":["#","Forecasting"]}]]}]]}]]}],["$","article","2025-10-1-EntroPE_Entropy-Guided_Dynamic_Patch_Encoder_for_Time_Series_Forecasting",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-EntroPE_Entropy-Guided_Dynamic_Patch_Encoder_for_Time_Series_Forecasting/","children":"[논문리뷰] EntroPE: Entropy-Guided Dynamic Patch Encoder for Time Series Forecasting"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'EntroPE: Entropy-Guided Dynamic Patch Encoder for Time Series Forecasting' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Time Series Forecasting",{"className":"page__taxonomy-item","children":["#","Time Series Forecasting"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Dynamic Patching",{"className":"page__taxonomy-item","children":["#","Dynamic Patching"]}],["$","span","Entropy",{"className":"page__taxonomy-item","children":["#","Entropy"]}],["$","span","Predictive Uncertainty",{"className":"page__taxonomy-item","children":["#","Predictive Uncertainty"]}],["$","span","Adaptive Encoding",{"className":"page__taxonomy-item","children":["#","Adaptive Encoding"]}],["$","span","Attention Mechanisms",{"className":"page__taxonomy-item","children":["#","Attention Mechanisms"]}],["$","span","Causal Transformer",{"className":"page__taxonomy-item","children":["#","Causal Transformer"]}]]}]]}]]}],["$","article","2025-10-1-Efficient_Audio-Visual_Speech_Separation_with_Discrete_Lip_Semantics_and_Multi-Scale_Global-Local_Attention",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Efficient_Audio-Visual_Speech_Separation_with_Discrete_Lip_Semantics_and_Multi-Scale_Global-Local_Attention/","children":"[논문리뷰] Efficient Audio-Visual Speech Separation with Discrete Lip Semantics and Multi-Scale Global-Local Attention"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Efficient Audio-Visual Speech Separation with Discrete Lip Semantics and Multi-Scale Global-Local Attention' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Audio-Visual Speech Separation",{"className":"page__taxonomy-item","children":["#","Audio-Visual Speech Separation"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}],["$","span","Efficiency",{"className":"page__taxonomy-item","children":["#","Efficiency"]}],["$","span","Discrete Lip Semantics",{"className":"page__taxonomy-item","children":["#","Discrete Lip Semantics"]}],["$","span","Global-Local Attention",{"className":"page__taxonomy-item","children":["#","Global-Local Attention"]}],["$","span","Lightweight Models",{"className":"page__taxonomy-item","children":["#","Lightweight Models"]}],["$","span","VQ-VAE",{"className":"page__taxonomy-item","children":["#","VQ-VAE"]}]]}]]}]]}],["$","article","2025-10-1-dParallel_Learnable_Parallel_Decoding_for_dLLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-dParallel_Learnable_Parallel_Decoding_for_dLLMs/","children":"[논문리뷰] dParallel: Learnable Parallel Decoding for dLLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'dParallel: Learnable Parallel Decoding for dLLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Language Models",{"className":"page__taxonomy-item","children":["#","Diffusion Language Models"]}],["$","span","Parallel Decoding",{"className":"page__taxonomy-item","children":["#","Parallel Decoding"]}],["$","span","Inference Acceleration",{"className":"page__taxonomy-item","children":["#","Inference Acceleration"]}],["$","span","Certainty Distillation",{"className":"page__taxonomy-item","children":["#","Certainty Distillation"]}],["$","span","Self-Distillation",{"className":"page__taxonomy-item","children":["#","Self-Distillation"]}],["$","span","Masked Language Models",{"className":"page__taxonomy-item","children":["#","Masked Language Models"]}],["$","span","LLaDA",{"className":"page__taxonomy-item","children":["#","LLaDA"]}]]}]]}]]}],["$","article","2025-10-1-DeepScientist_Advancing_Frontier-Pushing_Scientific_Findings_Progressively",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-DeepScientist_Advancing_Frontier-Pushing_Scientific_Findings_Progressively/","children":"[논문리뷰] DeepScientist: Advancing Frontier-Pushing Scientific Findings Progressively"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DeepScientist: Advancing Frontier-Pushing Scientific Findings Progressively' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Scientist",{"className":"page__taxonomy-item","children":["#","AI Scientist"]}],["$","span","Autonomous Scientific Discovery",{"className":"page__taxonomy-item","children":["#","Autonomous Scientific Discovery"]}],["$","span","Bayesian Optimization",{"className":"page__taxonomy-item","children":["#","Bayesian Optimization"]}],["$","span","LLM-based Agents",{"className":"page__taxonomy-item","children":["#","LLM-based Agents"]}],["$","span","SOTA-Surpassing",{"className":"page__taxonomy-item","children":["#","SOTA-Surpassing"]}],["$","span","Findings Memory",{"className":"page__taxonomy-item","children":["#","Findings Memory"]}],["$","span","Exploration-Exploitation",{"className":"page__taxonomy-item","children":["#","Exploration-Exploitation"]}]]}]]}]]}],["$","article","2025-10-1-DC-VideoGen_Efficient_Video_Generation_with_Deep_Compression_Video_Autoencoder",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-DC-VideoGen_Efficient_Video_Generation_with_Deep_Compression_Video_Autoencoder/","children":"[논문리뷰] DC-VideoGen: Efficient Video Generation with Deep Compression Video Autoencoder"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DC-VideoGen: Efficient Video Generation with Deep Compression Video Autoencoder' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Video Autoencoder",{"className":"page__taxonomy-item","children":["#","Video Autoencoder"]}],["$","span","Deep Compression",{"className":"page__taxonomy-item","children":["#","Deep Compression"]}],["$","span","Model Acceleration",{"className":"page__taxonomy-item","children":["#","Model Acceleration"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Latent Space",{"className":"page__taxonomy-item","children":["#","Latent Space"]}],["$","span","Temporal Modeling",{"className":"page__taxonomy-item","children":["#","Temporal Modeling"]}]]}]]}]]}],["$","article","2025-10-1-DA2_Depth_Anything_in_Any_Direction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-DA2_Depth_Anything_in_Any_Direction/","children":"[논문리뷰] DA^2: Depth Anything in Any Direction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'DA^2: Depth Anything in Any Direction' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Panoramic Depth Estimation",{"className":"page__taxonomy-item","children":["#","Panoramic Depth Estimation"]}],["$","span","Zero-shot Generalization",{"className":"page__taxonomy-item","children":["#","Zero-shot Generalization"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","SphereViT",{"className":"page__taxonomy-item","children":["#","SphereViT"]}],["$","span","Spherical Geometry",{"className":"page__taxonomy-item","children":["#","Spherical Geometry"]}],["$","span","360-degree Imaging",{"className":"page__taxonomy-item","children":["#","360-degree Imaging"]}],["$","span","Vision Transformer",{"className":"page__taxonomy-item","children":["#","Vision Transformer"]}]]}]]}]]}],["$","article","2025-10-1-d2Cache_Accelerating_Diffusion-Based_LLMs_via_Dual_Adaptive_Caching",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-d2Cache_Accelerating_Diffusion-Based_LLMs_via_Dual_Adaptive_Caching/","children":"[논문리뷰] d^2Cache: Accelerating Diffusion-Based LLMs via Dual Adaptive Caching"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiarui Wang이 [arXiv]에 게시한 'd^2Cache: Accelerating Diffusion-Based LLMs via Dual Adaptive Caching' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Inference Acceleration",{"className":"page__taxonomy-item","children":["#","Inference Acceleration"]}],["$","span","KV Cache",{"className":"page__taxonomy-item","children":["#","KV Cache"]}],["$","span","Bidirectional Attention",{"className":"page__taxonomy-item","children":["#","Bidirectional Attention"]}],["$","span","Adaptive Caching",{"className":"page__taxonomy-item","children":["#","Adaptive Caching"]}],["$","span","Token Selection",{"className":"page__taxonomy-item","children":["#","Token Selection"]}]]}]]}]]}],["$","article","2025-10-1-Context_Is_What_You_Need_The_Maximum_Effective_Context_Window_for_Real_World_Limits_of_LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Context_Is_What_You_Need_The_Maximum_Effective_Context_Window_for_Real_World_Limits_of_LLMs/","children":"[논문리뷰] Context Is What You Need: The Maximum Effective Context Window for Real World Limits of LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"normanpaulsen이 [arXiv]에 게시한 'Context Is What You Need: The Maximum Effective Context Window for Real World Limits of LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Context Window",{"className":"page__taxonomy-item","children":["#","Context Window"]}],["$","span","Effective Context Window",{"className":"page__taxonomy-item","children":["#","Effective Context Window"]}],["$","span","Model Performance",{"className":"page__taxonomy-item","children":["#","Model Performance"]}],["$","span","Hallucination Rates",{"className":"page__taxonomy-item","children":["#","Hallucination Rates"]}],["$","span","RAG Systems",{"className":"page__taxonomy-item","children":["#","RAG Systems"]}],["$","span","Token Limits",{"className":"page__taxonomy-item","children":["#","Token Limits"]}]]}]]}]]}],["$","article","2025-10-1-BuildBench_Benchmarking_LLM_Agents_on_Compiling_Real-World_Open-Source_Software",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-BuildBench_Benchmarking_LLM_Agents_on_Compiling_Real-World_Open-Source_Software/","children":"[논문리뷰] BuildBench: Benchmarking LLM Agents on Compiling Real-World Open-Source Software"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'BuildBench: Benchmarking LLM Agents on Compiling Real-World Open-Source Software' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Open-Source Software",{"className":"page__taxonomy-item","children":["#","Open-Source Software"]}],["$","span","Compilation",{"className":"page__taxonomy-item","children":["#","Compilation"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Software Engineering",{"className":"page__taxonomy-item","children":["#","Software Engineering"]}],["$","span","Error Resolution",{"className":"page__taxonomy-item","children":["#","Error Resolution"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}]]}]]}]]}],["$","article","2025-10-1-Benefits_and_Pitfalls_of_Reinforcement_Learning_for_Language_Model_Planning_A_Theoretical_Perspective",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Benefits_and_Pitfalls_of_Reinforcement_Learning_for_Language_Model_Planning_A_Theoretical_Perspective/","children":"[논문리뷰] Benefits and Pitfalls of Reinforcement Learning for Language Model Planning: A Theoretical Perspective"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Benefits and Pitfalls of Reinforcement Learning for Language Model Planning: A Theoretical Perspective' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Planning",{"className":"page__taxonomy-item","children":["#","Planning"]}],["$","span","Policy Gradient",{"className":"page__taxonomy-item","children":["#","Policy Gradient"]}],["$","span","Q-learning",{"className":"page__taxonomy-item","children":["#","Q-learning"]}],["$","span","Supervised Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning"]}],["$","span","Diversity Collapse",{"className":"page__taxonomy-item","children":["#","Diversity Collapse"]}],["$","span","Reward Hacking",{"className":"page__taxonomy-item","children":["#","Reward Hacking"]}]]}]]}]]}],["$","article","2025-10-1-A_Cartography_of_Open_Collaboration_in_Open_Source_AI_Mapping_Practices_Motivations_and_Governance_in_14_Open_Large_Language_Model_Projects",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-A_Cartography_of_Open_Collaboration_in_Open_Source_AI_Mapping_Practices_Motivations_and_Governance_in_14_Open_Large_Language_Model_Projects/","children":"[논문리뷰] A Cartography of Open Collaboration in Open Source AI: Mapping Practices, Motivations, and Governance in 14 Open Large Language Model Projects"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jennifer Ding이 [arXiv]에 게시한 'A Cartography of Open Collaboration in Open Source AI: Mapping Practices, Motivations, and Governance in 14 Open Large Language Model Projects' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Open Source AI",{"className":"page__taxonomy-item","children":["#","Open Source AI"]}],["$","span","LLM Development",{"className":"page__taxonomy-item","children":["#","LLM Development"]}],["$","span","Open Collaboration",{"className":"page__taxonomy-item","children":["#","Open Collaboration"]}],["$","span","Governance Models",{"className":"page__taxonomy-item","children":["#","Governance Models"]}],["$","span","Developer Motivations",{"className":"page__taxonomy-item","children":["#","Developer Motivations"]}],["$","span","Community Engagement",{"className":"page__taxonomy-item","children":["#","Community Engagement"]}],["$","span","AI Ecosystem",{"className":"page__taxonomy-item","children":["#","AI Ecosystem"]}]]}]]}]]}],["$","article","2025-10-1-Attention_as_a_Compass_Efficient_Exploration_for_Process-Supervised_RL_in_Reasoning_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-10-1-Attention_as_a_Compass_Efficient_Exploration_for_Process-Supervised_RL_in_Reasoning_Models/","children":"[논문리뷰] Attention as a Compass: Efficient Exploration for Process-Supervised RL in Reasoning Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Attention as a Compass: Efficient Exploration for Process-Supervised RL in Reasoning Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-10-01 14:04:08+0900","children":"2025년 10월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Process-Supervised RL",{"className":"page__taxonomy-item","children":["#","Process-Supervised RL"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reasoning Models",{"className":"page__taxonomy-item","children":["#","Reasoning Models"]}],["$","span","Attention Mechanism",{"className":"page__taxonomy-item","children":["#","Attention Mechanism"]}],["$","span","Efficient Exploration",{"className":"page__taxonomy-item","children":["#","Efficient Exploration"]}],["$","span","Adaptive Sampling",{"className":"page__taxonomy-item","children":["#","Adaptive Sampling"]}],["$","span","Off-Policy Training",{"className":"page__taxonomy-item","children":["#","Off-Policy Training"]}]]}]]}]]}],["$","article","2025-9-30-Visual_Jigsaw_Post-Training_Improves_MLLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-30-Visual_Jigsaw_Post-Training_Improves_MLLMs/","children":"[논문리뷰] Visual Jigsaw Post-Training Improves MLLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Lewei Lu이 [arXiv]에 게시한 'Visual Jigsaw Post-Training Improves MLLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-30 13:52:24+0900","children":"2025년 9월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","MLLMs",{"className":"page__taxonomy-item","children":["#","MLLMs"]}],["$","span","Post-training",{"className":"page__taxonomy-item","children":["#","Post-training"]}],["$","span","Self-supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-supervised Learning"]}],["$","span","Visual Understanding",{"className":"page__taxonomy-item","children":["#","Visual Understanding"]}],["$","span","Jigsaw Puzzles",{"className":"page__taxonomy-item","children":["#","Jigsaw Puzzles"]}],["$","span","RLVR",{"className":"page__taxonomy-item","children":["#","RLVR"]}],["$","span","Multimodal Perception",{"className":"page__taxonomy-item","children":["#","Multimodal Perception"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}]]}]]}]]}],["$","article","2025-9-30-StableToken_A_Noise-Robust_Semantic_Speech_Tokenizer_for_Resilient_SpeechLLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-30-StableToken_A_Noise-Robust_Semantic_Speech_Tokenizer_for_Resilient_SpeechLLMs/","children":"[논문리뷰] StableToken: A Noise-Robust Semantic Speech Tokenizer for Resilient SpeechLLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wei Jia이 [arXiv]에 게시한 'StableToken: A Noise-Robust Semantic Speech Tokenizer for Resilient SpeechLLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-30 13:52:24+0900","children":"2025년 9월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Speech Tokenizer",{"className":"page__taxonomy-item","children":["#","Speech Tokenizer"]}],["$","span","Noise Robustness",{"className":"page__taxonomy-item","children":["#","Noise Robustness"]}],["$","span","Semantic Tokens",{"className":"page__taxonomy-item","children":["#","Semantic Tokens"]}],["$","span","SpeechLLMs",{"className":"page__taxonomy-item","children":["#","SpeechLLMs"]}],["$","span","Voting-LFQ",{"className":"page__taxonomy-item","children":["#","Voting-LFQ"]}],["$","span","Consensus Training",{"className":"page__taxonomy-item","children":["#","Consensus Training"]}],["$","span","Automatic Speech Recognition",{"className":"page__taxonomy-item","children":["#","Automatic Speech Recognition"]}],["$","span","Speech Synthesis",{"className":"page__taxonomy-item","children":["#","Speech Synthesis"]}]]}]]}]]}],["$","article","2025-9-30-SLA_Beyond_Sparsity_in_Diffusion_Transformers_via_Fine-Tunable_Sparse-Linear_Attention",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-30-SLA_Beyond_Sparsity_in_Diffusion_Transformers_via_Fine-Tunable_Sparse-Linear_Attention/","children":"[논문리뷰] SLA: Beyond Sparsity in Diffusion Transformers via Fine-Tunable Sparse-Linear Attention"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'SLA: Beyond Sparsity in Diffusion Transformers via Fine-Tunable Sparse-Linear Attention' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-30 13:52:24+0900","children":"2025년 9월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Transformers",{"className":"page__taxonomy-item","children":["#","Diffusion Transformers"]}],["$","span","Sparse Attention",{"className":"page__taxonomy-item","children":["#","Sparse Attention"]}],["$","span","Linear Attention",{"className":"page__taxonomy-item","children":["#","Linear Attention"]}],["$","span","Model Acceleration",{"className":"page__taxonomy-item","children":["#","Model Acceleration"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Attention Mechanisms",{"className":"page__taxonomy-item","children":["#","Attention Mechanisms"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}]]}]]}]]}],["$","article","2025-9-30-SANA-Video_Efficient_Video_Generation_with_Block_Linear_Diffusion_Transformer",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-30-SANA-Video_Efficient_Video_Generation_with_Block_Linear_Diffusion_Transformer/","children":"[논문리뷰] SANA-Video: Efficient Video Generation with Block Linear Diffusion Transformer"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'SANA-Video: Efficient Video Generation with Block Linear Diffusion Transformer' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-30 13:52:24+0900","children":"2025년 9월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Diffusion Model",{"className":"page__taxonomy-item","children":["#","Diffusion Model"]}],["$","span","Linear Attention",{"className":"page__taxonomy-item","children":["#","Linear Attention"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Long Video",{"className":"page__taxonomy-item","children":["#","Long Video"]}],["$","span","Efficient Inference",{"className":"page__taxonomy-item","children":["#","Efficient Inference"]}],["$","span","Constant Memory",{"className":"page__taxonomy-item","children":["#","Constant Memory"]}],["$","span","Low-Cost Training",{"className":"page__taxonomy-item","children":["#","Low-Cost Training"]}],["$","span","RTX Deployment",{"className":"page__taxonomy-item","children":["#","RTX Deployment"]}]]}]]}]]}],["$","article","2025-9-30-RealUnify_Do_Unified_Models_Truly_Benefit_from_Unification_A_Comprehensive_Benchmark",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-30-RealUnify_Do_Unified_Models_Truly_Benefit_from_Unification_A_Comprehensive_Benchmark/","children":"[논문리뷰] RealUnify: Do Unified Models Truly Benefit from Unification? A Comprehensive Benchmark"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuran Wang이 [arXiv]에 게시한 'RealUnify: Do Unified Models Truly Benefit from Unification? A Comprehensive Benchmark' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-30 13:52:24+0900","children":"2025년 9월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Unified Models",{"className":"page__taxonomy-item","children":["#","Unified Models"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Capability Synergy",{"className":"page__taxonomy-item","children":["#","Capability Synergy"]}],["$","span","Visual Understanding",{"className":"page__taxonomy-item","children":["#","Visual Understanding"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Dual-Evaluation Protocol",{"className":"page__taxonomy-item","children":["#","Dual-Evaluation Protocol"]}]]}]]}]]}],["$","article","2025-9-30-Random_Policy_Valuation_is_Enough_for_LLM_Reasoning_with_Verifiable_Rewards",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-30-Random_Policy_Valuation_is_Enough_for_LLM_Reasoning_with_Verifiable_Rewards/","children":"[논문리뷰] Random Policy Valuation is Enough for LLM Reasoning with Verifiable Rewards"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Binxing Jiao이 [arXiv]에 게시한 'Random Policy Valuation is Enough for LLM Reasoning with Verifiable Rewards' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-30 13:52:24+0900","children":"2025년 9월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","LLM Reasoning",{"className":"page__taxonomy-item","children":["#","LLM Reasoning"]}],["$","span","Policy Valuation",{"className":"page__taxonomy-item","children":["#","Policy Valuation"]}],["$","span","Markov Decision Process",{"className":"page__taxonomy-item","children":["#","Markov Decision Process"]}],["$","span","Diversity",{"className":"page__taxonomy-item","children":["#","Diversity"]}],["$","span","Math Reasoning",{"className":"page__taxonomy-item","children":["#","Math Reasoning"]}],["$","span","Verifiable Rewards",{"className":"page__taxonomy-item","children":["#","Verifiable Rewards"]}]]}]]}]]}],["$","article","2025-9-30-OpenGPT-4o-Image_A_Comprehensive_Dataset_for_Advanced_Image_Generation_and_Editing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-30-OpenGPT-4o-Image_A_Comprehensive_Dataset_for_Advanced_Image_Generation_and_Editing/","children":"[논문리뷰] OpenGPT-4o-Image: A Comprehensive Dataset for Advanced Image Generation and Editing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Huanyu Zhang이 [arXiv]에 게시한 'OpenGPT-4o-Image: A Comprehensive Dataset for Advanced Image Generation and Editing' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-30 13:52:24+0900","children":"2025년 9월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}],["$","span","Taxonomy",{"className":"page__taxonomy-item","children":["#","Taxonomy"]}],["$","span","GPT-40",{"className":"page__taxonomy-item","children":["#","GPT-40"]}]]}]]}]]}],["$","article","2025-9-30-Multiplayer_Nash_Preference_Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-30-Multiplayer_Nash_Preference_Optimization/","children":"[논문리뷰] Multiplayer Nash Preference Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Multiplayer Nash Preference Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-30 13:52:24+0900","children":"2025년 9월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","RLHF",{"className":"page__taxonomy-item","children":["#","RLHF"]}],["$","span","LLM Alignment",{"className":"page__taxonomy-item","children":["#","LLM Alignment"]}],["$","span","Nash Equilibrium",{"className":"page__taxonomy-item","children":["#","Nash Equilibrium"]}],["$","span","Multiplayer Games",{"className":"page__taxonomy-item","children":["#","Multiplayer Games"]}],["$","span","Preference Optimization",{"className":"page__taxonomy-item","children":["#","Preference Optimization"]}],["$","span","Non-transitive Preferences",{"className":"page__taxonomy-item","children":["#","Non-transitive Preferences"]}],["$","span","Game Theory",{"className":"page__taxonomy-item","children":["#","Game Theory"]}]]}]]}]]}],["$","article","2025-9-30-EditScore_Unlocking_Online_RL_for_Image_Editing_via_High-Fidelity_Reward_Modeling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-30-EditScore_Unlocking_Online_RL_for_Image_Editing_via_High-Fidelity_Reward_Modeling/","children":"[논문리뷰] EditScore: Unlocking Online RL for Image Editing via High-Fidelity Reward Modeling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'EditScore: Unlocking Online RL for Image Editing via High-Fidelity Reward Modeling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-30 13:52:24+0900","children":"2025년 9월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Reward Modeling",{"className":"page__taxonomy-item","children":["#","Reward Modeling"]}],["$","span","Instruction-Guided Editing",{"className":"page__taxonomy-item","children":["#","Instruction-Guided Editing"]}],["$","span","Online RL",{"className":"page__taxonomy-item","children":["#","Online RL"]}],["$","span","Visual Language Models",{"className":"page__taxonomy-item","children":["#","Visual Language Models"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Self-Ensembling",{"className":"page__taxonomy-item","children":["#","Self-Ensembling"]}]]}]]}]]}],["$","article","2025-9-30-EasySteer_A_Unified_Framework_for_High-Performance_and_Extensible_LLM_Steering",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-30-EasySteer_A_Unified_Framework_for_High-Performance_and_Extensible_LLM_Steering/","children":"[논문리뷰] EasySteer: A Unified Framework for High-Performance and Extensible LLM Steering"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'EasySteer: A Unified Framework for High-Performance and Extensible LLM Steering' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-30 13:52:24+0900","children":"2025년 9월 30일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Steering Framework",{"className":"page__taxonomy-item","children":["#","LLM Steering Framework"]}],["$","span","vLLM Integration",{"className":"page__taxonomy-item","children":["#","vLLM Integration"]}],["$","span","Hidden State Manipulation",{"className":"page__taxonomy-item","children":["#","Hidden State Manipulation"]}],["$","span","Inference Optimization",{"className":"page__taxonomy-item","children":["#","Inference Optimization"]}],["$","span","Extensibility",{"className":"page__taxonomy-item","children":["#","Extensibility"]}],["$","span","Modular Architecture",{"className":"page__taxonomy-item","children":["#","Modular Architecture"]}],["$","span","Reasoning Mitigation",{"className":"page__taxonomy-item","children":["#","Reasoning Mitigation"]}],["$","span","Hallucination Reduction",{"className":"page__taxonomy-item","children":["#","Hallucination Reduction"]}]]}]]}]]}],["$","article","2025-9-29-X-Streamer_Unified_Human_World_Modeling_with_Audiovisual_Interaction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-X-Streamer_Unified_Human_World_Modeling_with_Audiovisual_Interaction/","children":"[논문리뷰] X-Streamer: Unified Human World Modeling with Audiovisual Interaction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Guoxian Song이 [arXiv]에 게시한 'X-Streamer: Unified Human World Modeling with Audiovisual Interaction' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Digital Human",{"className":"page__taxonomy-item","children":["#","Digital Human"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Real-time Streaming",{"className":"page__taxonomy-item","children":["#","Real-time Streaming"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Audiovisual Synchronization",{"className":"page__taxonomy-item","children":["#","Audiovisual Synchronization"]}],["$","span","World Modeling",{"className":"page__taxonomy-item","children":["#","World Modeling"]}]]}]]}]]}],["$","article","2025-9-29-X-CoT_Explainable_Text-to-Video_Retrieval_via_LLM-based_Chain-of-Thought_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-X-CoT_Explainable_Text-to-Video_Retrieval_via_LLM-based_Chain-of-Thought_Reasoning/","children":"[논문리뷰] X-CoT: Explainable Text-to-Video Retrieval via LLM-based Chain-of-Thought Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Raghuveer Rao이 [arXiv]에 게시한 'X-CoT: Explainable Text-to-Video Retrieval via LLM-based Chain-of-Thought Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Video Retrieval",{"className":"page__taxonomy-item","children":["#","Text-to-Video Retrieval"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Explainable AI",{"className":"page__taxonomy-item","children":["#","Explainable AI"]}],["$","span","Multimodal Retrieval",{"className":"page__taxonomy-item","children":["#","Multimodal Retrieval"]}],["$","span","Bradley-Terry Model",{"className":"page__taxonomy-item","children":["#","Bradley-Terry Model"]}],["$","span","Video Annotation",{"className":"page__taxonomy-item","children":["#","Video Annotation"]}]]}]]}]]}],["$","article","2025-9-29-WoW_Towards_a_World_omniscient_World_model_Through_Embodied_Interaction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-WoW_Towards_a_World_omniscient_World_model_Through_Embodied_Interaction/","children":"[논문리뷰] WoW: Towards a World omniscient World model Through Embodied Interaction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Weishi Mi이 [arXiv]에 게시한 'WoW: Towards a World omniscient World model Through Embodied Interaction' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","World Model",{"className":"page__taxonomy-item","children":["#","World Model"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Physical Reasoning",{"className":"page__taxonomy-item","children":["#","Physical Reasoning"]}],["$","span","Vision Language Models",{"className":"page__taxonomy-item","children":["#","Vision Language Models"]}],["$","span","Interaction Data",{"className":"page__taxonomy-item","children":["#","Interaction Data"]}],["$","span","Self-Optimization",{"className":"page__taxonomy-item","children":["#","Self-Optimization"]}]]}]]}]]}],["$","article","2025-9-29-Where_MLLMs_Attend_and_What_They_Rely_On_Explaining_Autoregressive_Token_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-Where_MLLMs_Attend_and_What_They_Rely_On_Explaining_Autoregressive_Token_Generation/","children":"[논문리뷰] Where MLLMs Attend and What They Rely On: Explaining Autoregressive Token Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shiming Liu이 [arXiv]에 게시한 'Where MLLMs Attend and What They Rely On: Explaining Autoregressive Token Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","MLLM",{"className":"page__taxonomy-item","children":["#","MLLM"]}],["$","span","Interpretability",{"className":"page__taxonomy-item","children":["#","Interpretability"]}],["$","span","Attribution",{"className":"page__taxonomy-item","children":["#","Attribution"]}],["$","span","Token Generation",{"className":"page__taxonomy-item","children":["#","Token Generation"]}],["$","span","Black-box Explanation",{"className":"page__taxonomy-item","children":["#","Black-box Explanation"]}],["$","span","Hallucination Diagnosis",{"className":"page__taxonomy-item","children":["#","Hallucination Diagnosis"]}],["$","span","Multimodality",{"className":"page__taxonomy-item","children":["#","Multimodality"]}],["$","span","VQA",{"className":"page__taxonomy-item","children":["#","VQA"]}]]}]]}]]}],["$","article","2025-9-29-WebGen-Agent_Enhancing_Interactive_Website_Generation_with_Multi-Level_Feedback_and_Step-Level_Reinforcement_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-WebGen-Agent_Enhancing_Interactive_Website_Generation_with_Multi-Level_Feedback_and_Step-Level_Reinforcement_Learning/","children":"[논문리뷰] WebGen-Agent: Enhancing Interactive Website Generation with Multi-Level Feedback and Step-Level Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhuofan Zong이 [arXiv]에 게시한 'WebGen-Agent: Enhancing Interactive Website Generation with Multi-Level Feedback and Step-Level Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Website Generation",{"className":"page__taxonomy-item","children":["#","Website Generation"]}],["$","span","Code Agent",{"className":"page__taxonomy-item","children":["#","Code Agent"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","VLM",{"className":"page__taxonomy-item","children":["#","VLM"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Multi-Level Feedback",{"className":"page__taxonomy-item","children":["#","Multi-Level Feedback"]}],["$","span","GUI Agent",{"className":"page__taxonomy-item","children":["#","GUI Agent"]}],["$","span","Step-GRPO",{"className":"page__taxonomy-item","children":["#","Step-GRPO"]}]]}]]}]]}],["$","article","2025-9-29-VoiceAssistant-Eval_Benchmarking_AI_Assistants_across_Listening_Speaking_and_Viewing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-VoiceAssistant-Eval_Benchmarking_AI_Assistants_across_Listening_Speaking_and_Viewing/","children":"[논문리뷰] VoiceAssistant-Eval: Benchmarking AI Assistants across Listening, Speaking, and Viewing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'VoiceAssistant-Eval: Benchmarking AI Assistants across Listening, Speaking, and Viewing' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Assistants",{"className":"page__taxonomy-item","children":["#","AI Assistants"]}],["$","span","Multimodal Benchmarking",{"className":"page__taxonomy-item","children":["#","Multimodal Benchmarking"]}],["$","span","Audio Understanding",{"className":"page__taxonomy-item","children":["#","Audio Understanding"]}],["$","span","Speech Synthesis",{"className":"page__taxonomy-item","children":["#","Speech Synthesis"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Role-play",{"className":"page__taxonomy-item","children":["#","Role-play"]}],["$","span","Safety",{"className":"page__taxonomy-item","children":["#","Safety"]}],["$","span","Robustness",{"className":"page__taxonomy-item","children":["#","Robustness"]}]]}]]}]]}],["$","article","2025-9-29-Variational_Reasoning_for_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-Variational_Reasoning_for_Language_Models/","children":"[논문리뷰] Variational Reasoning for Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Variational Reasoning for Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Variational Inference",{"className":"page__taxonomy-item","children":["#","Variational Inference"]}],["$","span","Language Models",{"className":"page__taxonomy-item","children":["#","Language Models"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","ELBO",{"className":"page__taxonomy-item","children":["#","ELBO"]}],["$","span","IWAE",{"className":"page__taxonomy-item","children":["#","IWAE"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Latent Variables",{"className":"page__taxonomy-item","children":["#","Latent Variables"]}],["$","span","Forward-KL",{"className":"page__taxonomy-item","children":["#","Forward-KL"]}]]}]]}]]}],["$","article","2025-9-29-UniVid_Unifying_Vision_Tasks_with_Pre-trained_Video_Generation_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-UniVid_Unifying_Vision_Tasks_with_Pre-trained_Video_Generation_Models/","children":"[논문리뷰] UniVid: Unifying Vision Tasks with Pre-trained Video Generation Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuchao Gu이 [arXiv]에 게시한 'UniVid: Unifying Vision Tasks with Pre-trained Video Generation Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Unified Vision Modeling",{"className":"page__taxonomy-item","children":["#","Unified Vision Modeling"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Diffusion Transformer",{"className":"page__taxonomy-item","children":["#","Diffusion Transformer"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Cross-modal",{"className":"page__taxonomy-item","children":["#","Cross-modal"]}],["$","span","Cross-source Tasks",{"className":"page__taxonomy-item","children":["#","Cross-source Tasks"]}],["$","span","Visual Sentences",{"className":"page__taxonomy-item","children":["#","Visual Sentences"]}],["$","span","LoRA",{"className":"page__taxonomy-item","children":["#","LoRA"]}]]}]]}]]}],["$","article","2025-9-29-UltraHorizon_Benchmarking_Agent_Capabilities_in_Ultra_Long-Horizon_Scenarios",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-UltraHorizon_Benchmarking_Agent_Capabilities_in_Ultra_Long-Horizon_Scenarios/","children":"[논문리뷰] UltraHorizon: Benchmarking Agent Capabilities in Ultra Long-Horizon Scenarios"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zeyu Qin이 [arXiv]에 게시한 'UltraHorizon: Benchmarking Agent Capabilities in Ultra Long-Horizon Scenarios' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Long-Horizon Reasoning",{"className":"page__taxonomy-item","children":["#","Long-Horizon Reasoning"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Partially Observable",{"className":"page__taxonomy-item","children":["#","Partially Observable"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Memory Management",{"className":"page__taxonomy-item","children":["#","Memory Management"]}],["$","span","Exploration",{"className":"page__taxonomy-item","children":["#","Exploration"]}]]}]]}]]}],["$","article","2025-9-29-TUN3D_Towards_Real-World_Scene_Understanding_from_Unposed_Images",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-TUN3D_Towards_Real-World_Scene_Understanding_from_Unposed_Images/","children":"[논문리뷰] TUN3D: Towards Real-World Scene Understanding from Unposed Images"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Anna Vorontsova이 [arXiv]에 게시한 'TUN3D: Towards Real-World Scene Understanding from Unposed Images' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Scene Understanding",{"className":"page__taxonomy-item","children":["#","3D Scene Understanding"]}],["$","span","Layout Estimation",{"className":"page__taxonomy-item","children":["#","Layout Estimation"]}],["$","span","3D Object Detection",{"className":"page__taxonomy-item","children":["#","3D Object Detection"]}],["$","span","Unposed Images",{"className":"page__taxonomy-item","children":["#","Unposed Images"]}],["$","span","Sparse Convolutional Networks",{"className":"page__taxonomy-item","children":["#","Sparse Convolutional Networks"]}],["$","span","Multi-view Stereo",{"className":"page__taxonomy-item","children":["#","Multi-view Stereo"]}],["$","span","Real-time AI",{"className":"page__taxonomy-item","children":["#","Real-time AI"]}]]}]]}]]}],["$","article","2025-9-29-Think-on-Graph_3.0_Efficient_and_Adaptive_LLM_Reasoning_on_Heterogeneous_Graphs_via_Multi-Agent_Dual-Evolving_Context_Retrieval",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-Think-on-Graph_3.0_Efficient_and_Adaptive_LLM_Reasoning_on_Heterogeneous_Graphs_via_Multi-Agent_Dual-Evolving_Context_Retrieval/","children":"[논문리뷰] Think-on-Graph 3.0: Efficient and Adaptive LLM Reasoning on Heterogeneous Graphs via Multi-Agent Dual-Evolving Context Retrieval"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Think-on-Graph 3.0: Efficient and Adaptive LLM Reasoning on Heterogeneous Graphs via Multi-Agent Dual-Evolving Context Retrieval' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","RAG",{"className":"page__taxonomy-item","children":["#","RAG"]}],["$","span","LLM Reasoning",{"className":"page__taxonomy-item","children":["#","LLM Reasoning"]}],["$","span","Knowledge Graphs",{"className":"page__taxonomy-item","children":["#","Knowledge Graphs"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Context Retrieval",{"className":"page__taxonomy-item","children":["#","Context Retrieval"]}],["$","span","Heterogeneous Graphs",{"className":"page__taxonomy-item","children":["#","Heterogeneous Graphs"]}],["$","span","Adaptive Learning",{"className":"page__taxonomy-item","children":["#","Adaptive Learning"]}],["$","span","Dual-Evolution",{"className":"page__taxonomy-item","children":["#","Dual-Evolution"]}]]}]]}]]}],["$","article","2025-9-29-StateX_Enhancing_RNN_Recall_via_Post-training_State_Expansion",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-StateX_Enhancing_RNN_Recall_via_Post-training_State_Expansion/","children":"[논문리뷰] StateX: Enhancing RNN Recall via Post-training State Expansion"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhiyuan Liu이 [arXiv]에 게시한 'StateX: Enhancing RNN Recall via Post-training State Expansion' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","RNN",{"className":"page__taxonomy-item","children":["#","RNN"]}],["$","span","State Expansion",{"className":"page__taxonomy-item","children":["#","State Expansion"]}],["$","span","Post-training",{"className":"page__taxonomy-item","children":["#","Post-training"]}],["$","span","Long-context Recall",{"className":"page__taxonomy-item","children":["#","Long-context Recall"]}],["$","span","Linear Attention",{"className":"page__taxonomy-item","children":["#","Linear Attention"]}],["$","span","State Space Models",{"className":"page__taxonomy-item","children":["#","State Space Models"]}],["$","span","GLA",{"className":"page__taxonomy-item","children":["#","GLA"]}],["$","span","Mamba2",{"className":"page__taxonomy-item","children":["#","Mamba2"]}]]}]]}]]}],["$","article","2025-9-29-SPARK_Synergistic_Policy_And_Reward_Co-Evolving_Framework",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-SPARK_Synergistic_Policy_And_Reward_Co-Evolving_Framework/","children":"[논문리뷰] SPARK: Synergistic Policy And Reward Co-Evolving Framework"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'SPARK: Synergistic Policy And Reward Co-Evolving Framework' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","LVLMs",{"className":"page__taxonomy-item","children":["#","LVLMs"]}],["$","span","Reward Modeling",{"className":"page__taxonomy-item","children":["#","Reward Modeling"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Self-Reflection",{"className":"page__taxonomy-item","children":["#","Self-Reflection"]}],["$","span","Verifiable Rewards",{"className":"page__taxonomy-item","children":["#","Verifiable Rewards"]}],["$","span","Co-evolution",{"className":"page__taxonomy-item","children":["#","Co-evolution"]}]]}]]}]]}],["$","article","2025-9-29-See_Point_Fly_A_Learning-Free_VLM_Framework_for_Universal_Unmanned_Aerial_Navigation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-See_Point_Fly_A_Learning-Free_VLM_Framework_for_Universal_Unmanned_Aerial_Navigation/","children":"[논문리뷰] See, Point, Fly: A Learning-Free VLM Framework for Universal Unmanned Aerial Navigation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chih-Hai Su이 [arXiv]에 게시한 'See, Point, Fly: A Learning-Free VLM Framework for Universal Unmanned Aerial Navigation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","UAV Navigation",{"className":"page__taxonomy-item","children":["#","UAV Navigation"]}],["$","span","Zero-shot",{"className":"page__taxonomy-item","children":["#","Zero-shot"]}],["$","span","Spatial Grounding",{"className":"page__taxonomy-item","children":["#","Spatial Grounding"]}],["$","span","Waypoint Prompting",{"className":"page__taxonomy-item","children":["#","Waypoint Prompting"]}],["$","span","Autonomous Navigation",{"className":"page__taxonomy-item","children":["#","Autonomous Navigation"]}],["$","span","Adaptive Control",{"className":"page__taxonomy-item","children":["#","Adaptive Control"]}]]}]]}]]}],["$","article","2025-9-29-ReviewScore_Misinformed_Peer_Review_Detection_with_Large_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-ReviewScore_Misinformed_Peer_Review_Detection_with_Large_Language_Models/","children":"[논문리뷰] ReviewScore: Misinformed Peer Review Detection with Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'ReviewScore: Misinformed Peer Review Detection with Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Peer Review",{"className":"page__taxonomy-item","children":["#","Peer Review"]}],["$","span","Review Quality",{"className":"page__taxonomy-item","children":["#","Review Quality"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Misinformed Review",{"className":"page__taxonomy-item","children":["#","Misinformed Review"]}],["$","span","Argument Reconstruction",{"className":"page__taxonomy-item","children":["#","Argument Reconstruction"]}],["$","span","Factuality Evaluation",{"className":"page__taxonomy-item","children":["#","Factuality Evaluation"]}],["$","span","Natural Language Processing",{"className":"page__taxonomy-item","children":["#","Natural Language Processing"]}],["$","span","Automated Evaluation",{"className":"page__taxonomy-item","children":["#","Automated Evaluation"]}]]}]]}]]}],["$","article","2025-9-29-RefAM_Attention_Magnets_for_Zero-Shot_Referral_Segmentation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-RefAM_Attention_Magnets_for_Zero-Shot_Referral_Segmentation/","children":"[논문리뷰] RefAM: Attention Magnets for Zero-Shot Referral Segmentation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Federico Tombari이 [arXiv]에 게시한 'RefAM: Attention Magnets for Zero-Shot Referral Segmentation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Zero-Shot Segmentation",{"className":"page__taxonomy-item","children":["#","Zero-Shot Segmentation"]}],["$","span","Referring Segmentation",{"className":"page__taxonomy-item","children":["#","Referring Segmentation"]}],["$","span","Diffusion Transformers (DiTs)",{"className":"page__taxonomy-item","children":["#","Diffusion Transformers (DiTs)"]}],["$","span","Attention Mechanisms",{"className":"page__taxonomy-item","children":["#","Attention Mechanisms"]}],["$","span","Attention Sinks",{"className":"page__taxonomy-item","children":["#","Attention Sinks"]}],["$","span","Stop Words",{"className":"page__taxonomy-item","children":["#","Stop Words"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Training-Free Methods",{"className":"page__taxonomy-item","children":["#","Training-Free Methods"]}]]}]]}]]}],["$","article","2025-9-29-Real-Time_Object_Detection_Meets_DINOv3",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-Real-Time_Object_Detection_Meets_DINOv3/","children":"[논문리뷰] Real-Time Object Detection Meets DINOv3"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xi Shen이 [arXiv]에 게시한 'Real-Time Object Detection Meets DINOv3' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Real-time Object Detection",{"className":"page__taxonomy-item","children":["#","Real-time Object Detection"]}],["$","span","DINOv3",{"className":"page__taxonomy-item","children":["#","DINOv3"]}],["$","span","DEIMv2",{"className":"page__taxonomy-item","children":["#","DEIMv2"]}],["$","span","Vision Transformer",{"className":"page__taxonomy-item","children":["#","Vision Transformer"]}],["$","span","Multi-scale Features",{"className":"page__taxonomy-item","children":["#","Multi-scale Features"]}],["$","span","Spatial Tuning Adapter",{"className":"page__taxonomy-item","children":["#","Spatial Tuning Adapter"]}],["$","span","Lightweight Models",{"className":"page__taxonomy-item","children":["#","Lightweight Models"]}],["$","span","Object Detection Framework",{"className":"page__taxonomy-item","children":["#","Object Detection Framework"]}]]}]]}]]}],["$","article","2025-9-29-Quantile_Advantage_Estimation_for_Entropy-Safe_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-Quantile_Advantage_Estimation_for_Entropy-Safe_Reasoning/","children":"[논문리뷰] Quantile Advantage Estimation for Entropy-Safe Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"An Zhang이 [arXiv]에 게시한 'Quantile Advantage Estimation for Entropy-Safe Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","LLM Reasoning",{"className":"page__taxonomy-item","children":["#","LLM Reasoning"]}],["$","span","Entropy Control",{"className":"page__taxonomy-item","children":["#","Entropy Control"]}],["$","span","Advantage Estimation",{"className":"page__taxonomy-item","children":["#","Advantage Estimation"]}],["$","span","Quantile Baseline",{"className":"page__taxonomy-item","children":["#","Quantile Baseline"]}],["$","span","Exploration-Exploitation",{"className":"page__taxonomy-item","children":["#","Exploration-Exploitation"]}],["$","span","RLVR",{"className":"page__taxonomy-item","children":["#","RLVR"]}]]}]]}]]}],["$","article","2025-9-29-PromptCoT_2.0_Scaling_Prompt_Synthesis_for_Large_Language_Model_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-PromptCoT_2.0_Scaling_Prompt_Synthesis_for_Large_Language_Model_Reasoning/","children":"[논문리뷰] PromptCoT 2.0: Scaling Prompt Synthesis for Large Language Model Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Lingpeng Kong이 [arXiv]에 게시한 'PromptCoT 2.0: Scaling Prompt Synthesis for Large Language Model Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Prompt Synthesis",{"className":"page__taxonomy-item","children":["#","Prompt Synthesis"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Expectation-Maximization",{"className":"page__taxonomy-item","children":["#","Expectation-Maximization"]}],["$","span","Self-Play",{"className":"page__taxonomy-item","children":["#","Self-Play"]}],["$","span","Supervised Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning"]}],["$","span","Task Generation",{"className":"page__taxonomy-item","children":["#","Task Generation"]}],["$","span","Rationale Generation",{"className":"page__taxonomy-item","children":["#","Rationale Generation"]}]]}]]}]]}],["$","article","2025-9-29-No_Prompt_Left_Behind_Exploiting_Zero-Variance_Prompts_in_LLM_Reinforcement_Learning_via_Entropy-Guided_Advantage_Shaping",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-No_Prompt_Left_Behind_Exploiting_Zero-Variance_Prompts_in_LLM_Reinforcement_Learning_via_Entropy-Guided_Advantage_Shaping/","children":"[논문리뷰] No Prompt Left Behind: Exploiting Zero-Variance Prompts in LLM Reinforcement Learning via Entropy-Guided Advantage Shaping"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'No Prompt Left Behind: Exploiting Zero-Variance Prompts in LLM Reinforcement Learning via Entropy-Guided Advantage Shaping' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","LLM Reinforcement Learning"]}],["$","span","Zero-Variance Prompts",{"className":"page__taxonomy-item","children":["#","Zero-Variance Prompts"]}],["$","span","Advantage Shaping",{"className":"page__taxonomy-item","children":["#","Advantage Shaping"]}],["$","span","Entropy-Guided",{"className":"page__taxonomy-item","children":["#","Entropy-Guided"]}],["$","span","Math Reasoning",{"className":"page__taxonomy-item","children":["#","Math Reasoning"]}],["$","span","RLVR",{"className":"page__taxonomy-item","children":["#","RLVR"]}],["$","span","Group Relative Policy Optimization",{"className":"page__taxonomy-item","children":["#","Group Relative Policy Optimization"]}]]}]]}]]}],["$","article","2025-9-29-MinerU2.5_A_Decoupled_Vision-Language_Model_for_Efficient_High-Resolution_Document_Parsing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-MinerU2.5_A_Decoupled_Vision-Language_Model_for_Efficient_High-Resolution_Document_Parsing/","children":"[논문리뷰] MinerU2.5: A Decoupled Vision-Language Model for Efficient High-Resolution Document Parsing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"SunYuefeng이 [arXiv]에 게시한 'MinerU2.5: A Decoupled Vision-Language Model for Efficient High-Resolution Document Parsing' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Document Parsing",{"className":"page__taxonomy-item","children":["#","Document Parsing"]}],["$","span","Vision-Language Model",{"className":"page__taxonomy-item","children":["#","Vision-Language Model"]}],["$","span","High-Resolution",{"className":"page__taxonomy-item","children":["#","High-Resolution"]}],["$","span","Two-Stage Inference",{"className":"page__taxonomy-item","children":["#","Two-Stage Inference"]}],["$","span","Layout Analysis",{"className":"page__taxonomy-item","children":["#","Layout Analysis"]}],["$","span","Content Recognition",{"className":"page__taxonomy-item","children":["#","Content Recognition"]}],["$","span","Data Engine",{"className":"page__taxonomy-item","children":["#","Data Engine"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}]]}]]}]]}],["$","article","2025-9-29-Mind-the-Glitch_Visual_Correspondence_for_Detecting_Inconsistencies_in_Subject-Driven_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-Mind-the-Glitch_Visual_Correspondence_for_Detecting_Inconsistencies_in_Subject-Driven_Generation/","children":"[논문리뷰] Mind-the-Glitch: Visual Correspondence for Detecting Inconsistencies in Subject-Driven Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Peter Wonka이 [arXiv]에 게시한 'Mind-the-Glitch: Visual Correspondence for Detecting Inconsistencies in Subject-Driven Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Subject-Driven Generation",{"className":"page__taxonomy-item","children":["#","Subject-Driven Generation"]}],["$","span","Visual Inconsistency Detection",{"className":"page__taxonomy-item","children":["#","Visual Inconsistency Detection"]}],["$","span","Feature Disentanglement",{"className":"page__taxonomy-item","children":["#","Feature Disentanglement"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Semantic Correspondence",{"className":"page__taxonomy-item","children":["#","Semantic Correspondence"]}],["$","span","Evaluation Metric",{"className":"page__taxonomy-item","children":["#","Evaluation Metric"]}],["$","span","Spatial Localization",{"className":"page__taxonomy-item","children":["#","Spatial Localization"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}]]}]]}]]}],["$","article","2025-9-29-MesaTask_Towards_Task-Driven_Tabletop_Scene_Generation_via_3D_Spatial_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-MesaTask_Towards_Task-Driven_Tabletop_Scene_Generation_via_3D_Spatial_Reasoning/","children":"[논문리뷰] MesaTask: Towards Task-Driven Tabletop Scene Generation via 3D Spatial Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Weipeng Zhong이 [arXiv]에 게시한 'MesaTask: Towards Task-Driven Tabletop Scene Generation via 3D Spatial Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Scene Generation",{"className":"page__taxonomy-item","children":["#","3D Scene Generation"]}],["$","span","Robotic Manipulation",{"className":"page__taxonomy-item","children":["#","Robotic Manipulation"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}],["$","span","Direct Preference Optimization",{"className":"page__taxonomy-item","children":["#","Direct Preference Optimization"]}],["$","span","Tabletop Scene",{"className":"page__taxonomy-item","children":["#","Tabletop Scene"]}]]}]]}]]}],["$","article","2025-9-29-LucidFlux_Caption-Free_Universal_Image_Restoration_via_a_Large-Scale_Diffusion_Transformer",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-LucidFlux_Caption-Free_Universal_Image_Restoration_via_a_Large-Scale_Diffusion_Transformer/","children":"[논문리뷰] LucidFlux: Caption-Free Universal Image Restoration via a Large-Scale Diffusion Transformer"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'LucidFlux: Caption-Free Universal Image Restoration via a Large-Scale Diffusion Transformer' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Universal Image Restoration",{"className":"page__taxonomy-item","children":["#","Universal Image Restoration"]}],["$","span","Diffusion Transformer",{"className":"page__taxonomy-item","children":["#","Diffusion Transformer"]}],["$","span","Caption-Free",{"className":"page__taxonomy-item","children":["#","Caption-Free"]}],["$","span","Semantic Alignment",{"className":"page__taxonomy-item","children":["#","Semantic Alignment"]}],["$","span","Image Quality Assessment",{"className":"page__taxonomy-item","children":["#","Image Quality Assessment"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Real-World Degradations",{"className":"page__taxonomy-item","children":["#","Real-World Degradations"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}]]}]]}]]}],["$","article","2025-9-29-LongLive_Real-time_Interactive_Long_Video_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-LongLive_Real-time_Interactive_Long_Video_Generation/","children":"[논문리뷰] LongLive: Real-time Interactive Long Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'LongLive: Real-time Interactive Long Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Long Video Generation",{"className":"page__taxonomy-item","children":["#","Long Video Generation"]}],["$","span","Real-time",{"className":"page__taxonomy-item","children":["#","Real-time"]}],["$","span","Interactive AI",{"className":"page__taxonomy-item","children":["#","Interactive AI"]}],["$","span","Autoregressive Models",{"className":"page__taxonomy-item","children":["#","Autoregressive Models"]}],["$","span","KV Cache",{"className":"page__taxonomy-item","children":["#","KV Cache"]}],["$","span","Streaming Tuning",{"className":"page__taxonomy-item","children":["#","Streaming Tuning"]}],["$","span","Attention Sink",{"className":"page__taxonomy-item","children":["#","Attention Sink"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}]]}]]}]]}],["$","article","2025-9-29-Learn_the_Ropes_Then_Trust_the_Wins_Self-imitation_with_Progressive_Exploration_for_Agentic_Reinforcement_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-Learn_the_Ropes_Then_Trust_the_Wins_Self-imitation_with_Progressive_Exploration_for_Agentic_Reinforcement_Learning/","children":"[논문리뷰] Learn the Ropes, Then Trust the Wins: Self-imitation with Progressive Exploration for Agentic Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Gang Li이 [arXiv]에 게시한 'Learn the Ropes, Then Trust the Wins: Self-imitation with Progressive Exploration for Agentic Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Exploration-Exploitation",{"className":"page__taxonomy-item","children":["#","Exploration-Exploitation"]}],["$","span","Self-Imitation Learning",{"className":"page__taxonomy-item","children":["#","Self-Imitation Learning"]}],["$","span","Intrinsic Rewards",{"className":"page__taxonomy-item","children":["#","Intrinsic Rewards"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Policy Entropy",{"className":"page__taxonomy-item","children":["#","Policy Entropy"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}]]}]]}]]}],["$","article","2025-9-29-Language_Models_Can_Learn_from_Verbal_Feedback_Without_Scalar_Rewards",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-Language_Models_Can_Learn_from_Verbal_Feedback_Without_Scalar_Rewards/","children":"[논문리뷰] Language Models Can Learn from Verbal Feedback Without Scalar Rewards"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Language Models Can Learn from Verbal Feedback Without Scalar Rewards' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Verbal Feedback",{"className":"page__taxonomy-item","children":["#","Verbal Feedback"]}],["$","span","Conditional Generation",{"className":"page__taxonomy-item","children":["#","Conditional Generation"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Feedback-Conditional Policy",{"className":"page__taxonomy-item","children":["#","Feedback-Conditional Policy"]}],["$","span","Offline-Online Learning",{"className":"page__taxonomy-item","children":["#","Offline-Online Learning"]}],["$","span","Reward Hypothesis Bypass",{"className":"page__taxonomy-item","children":["#","Reward Hypothesis Bypass"]}]]}]]}]]}],["$","article","2025-9-29-Instruction-Following_Evaluation_in_Function_Calling_for_Large_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-Instruction-Following_Evaluation_in_Function_Calling_for_Large_Language_Models/","children":"[논문리뷰] Instruction-Following Evaluation in Function Calling for Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"NikolaiSkripko이 [arXiv]에 게시한 'Instruction-Following Evaluation in Function Calling for Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Function Calling",{"className":"page__taxonomy-item","children":["#","Function Calling"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","JSON Schema",{"className":"page__taxonomy-item","children":["#","JSON Schema"]}],["$","span","AI Agents",{"className":"page__taxonomy-item","children":["#","AI Agents"]}],["$","span","Evaluation Metrics",{"className":"page__taxonomy-item","children":["#","Evaluation Metrics"]}]]}]]}]]}],["$","article","2025-9-29-HiGS_History-Guided_Sampling_for_Plug-and-Play_Enhancement_of_Diffusion_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-HiGS_History-Guided_Sampling_for_Plug-and-Play_Enhancement_of_Diffusion_Models/","children":"[논문리뷰] HiGS: History-Guided Sampling for Plug-and-Play Enhancement of Diffusion Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Romann M. Weber이 [arXiv]에 게시한 'HiGS: History-Guided Sampling for Plug-and-Play Enhancement of Diffusion Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Sampling",{"className":"page__taxonomy-item","children":["#","Sampling"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Plug-and-Play",{"className":"page__taxonomy-item","children":["#","Plug-and-Play"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}],["$","span","Guidance",{"className":"page__taxonomy-item","children":["#","Guidance"]}],["$","span","Momentum-Based Methods",{"className":"page__taxonomy-item","children":["#","Momentum-Based Methods"]}]]}]]}]]}],["$","article","2025-9-29-FlashEdit_Decoupling_Speed_Structure_and_Semantics_for_Precise_Image_Editing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-FlashEdit_Decoupling_Speed_Structure_and_Semantics_for_Precise_Image_Editing/","children":"[논문리뷰] FlashEdit: Decoupling Speed, Structure, and Semantics for Precise Image Editing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Linghe Kong이 [arXiv]에 게시한 'FlashEdit: Decoupling Speed, Structure, and Semantics for Precise Image Editing' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-Guided Image Editing",{"className":"page__taxonomy-item","children":["#","Text-Guided Image Editing"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Real-Time Editing",{"className":"page__taxonomy-item","children":["#","Real-Time Editing"]}],["$","span","One-Step Inversion",{"className":"page__taxonomy-item","children":["#","One-Step Inversion"]}],["$","span","Attention Control",{"className":"page__taxonomy-item","children":["#","Attention Control"]}],["$","span","Background Preservation",{"className":"page__taxonomy-item","children":["#","Background Preservation"]}],["$","span","Semantic Disentanglement",{"className":"page__taxonomy-item","children":["#","Semantic Disentanglement"]}]]}]]}]]}],["$","article","2025-9-29-Fine-tuning_Done_Right_in_Model_Editing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-Fine-tuning_Done_Right_in_Model_Editing/","children":"[논문리뷰] Fine-tuning Done Right in Model Editing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Du Su이 [arXiv]에 게시한 'Fine-tuning Done Right in Model Editing' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Model Editing",{"className":"page__taxonomy-item","children":["#","Model Editing"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Catastrophic Forgetting",{"className":"page__taxonomy-item","children":["#","Catastrophic Forgetting"]}],["$","span","Breadth-First Pipeline",{"className":"page__taxonomy-item","children":["#","Breadth-First Pipeline"]}],["$","span","Depth-First Pipeline",{"className":"page__taxonomy-item","children":["#","Depth-First Pipeline"]}],["$","span","Localized Tuning",{"className":"page__taxonomy-item","children":["#","Localized Tuning"]}],["$","span","Lifelong Learning",{"className":"page__taxonomy-item","children":["#","Lifelong Learning"]}]]}]]}]]}],["$","article","2025-9-29-Finding_3D_Positions_of_Distant_Objects_from_Noisy_Camera_Movement_and_Semantic_Segmentation_Sequences",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-Finding_3D_Positions_of_Distant_Objects_from_Noisy_Camera_Movement_and_Semantic_Segmentation_Sequences/","children":"[논문리뷰] Finding 3D Positions of Distant Objects from Noisy Camera Movement and Semantic Segmentation Sequences"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Eija Honkavaara이 [arXiv]에 게시한 'Finding 3D Positions of Distant Objects from Noisy Camera Movement and Semantic Segmentation Sequences' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Object Localization",{"className":"page__taxonomy-item","children":["#","3D Object Localization"]}],["$","span","Particle Filter",{"className":"page__taxonomy-item","children":["#","Particle Filter"]}],["$","span","Multi-target Tracking",{"className":"page__taxonomy-item","children":["#","Multi-target Tracking"]}],["$","span","Drone Surveillance",{"className":"page__taxonomy-item","children":["#","Drone Surveillance"]}],["$","span","Wildfire Monitoring",{"className":"page__taxonomy-item","children":["#","Wildfire Monitoring"]}],["$","span","Semantic Segmentation",{"className":"page__taxonomy-item","children":["#","Semantic Segmentation"]}],["$","span","Camera Pose Estimation",{"className":"page__taxonomy-item","children":["#","Camera Pose Estimation"]}]]}]]}]]}],["$","article","2025-9-29-ERGO_Efficient_High-Resolution_Visual_Understanding_for_Vision-Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-ERGO_Efficient_High-Resolution_Visual_Understanding_for_Vision-Language_Models/","children":"[논문리뷰] ERGO: Efficient High-Resolution Visual Understanding for Vision-Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ki-Ung Song이 [arXiv]에 게시한 'ERGO: Efficient High-Resolution Visual Understanding for Vision-Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","High-Resolution Vision",{"className":"page__taxonomy-item","children":["#","High-Resolution Vision"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Efficient Reasoning",{"className":"page__taxonomy-item","children":["#","Efficient Reasoning"]}],["$","span","Coarse-to-Fine",{"className":"page__taxonomy-item","children":["#","Coarse-to-Fine"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Visual Understanding",{"className":"page__taxonomy-item","children":["#","Visual Understanding"]}],["$","span","Attention Mechanism",{"className":"page__taxonomy-item","children":["#","Attention Mechanism"]}]]}]]}]]}],["$","article","2025-9-29-EPO_Entropy-regularized_Policy_Optimization_for_LLM_Agents_Reinforcement_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-EPO_Entropy-regularized_Policy_Optimization_for_LLM_Agents_Reinforcement_Learning/","children":"[논문리뷰] EPO: Entropy-regularized Policy Optimization for LLM Agents Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Li Yu-Jhe이 [arXiv]에 게시한 'EPO: Entropy-regularized Policy Optimization for LLM Agents Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Entropy Regularization",{"className":"page__taxonomy-item","children":["#","Entropy Regularization"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Sparse Rewards",{"className":"page__taxonomy-item","children":["#","Sparse Rewards"]}],["$","span","Multi-turn Environments",{"className":"page__taxonomy-item","children":["#","Multi-turn Environments"]}],["$","span","Exploration-Exploitation",{"className":"page__taxonomy-item","children":["#","Exploration-Exploitation"]}]]}]]}]]}],["$","article","2025-9-29-D-Artemis_A_Deliberative_Cognitive_Framework_for_Mobile_GUI_Multi-Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-D-Artemis_A_Deliberative_Cognitive_Framework_for_Mobile_GUI_Multi-Agents/","children":"[논문리뷰] D-Artemis: A Deliberative Cognitive Framework for Mobile GUI Multi-Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jinyuan Li이 [arXiv]에 게시한 'D-Artemis: A Deliberative Cognitive Framework for Mobile GUI Multi-Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Mobile GUI Automation",{"className":"page__taxonomy-item","children":["#","Mobile GUI Automation"]}],["$","span","Multi-Agent System",{"className":"page__taxonomy-item","children":["#","Multi-Agent System"]}],["$","span","Cognitive Architecture",{"className":"page__taxonomy-item","children":["#","Cognitive Architecture"]}],["$","span","Pre-execution Alignment",{"className":"page__taxonomy-item","children":["#","Pre-execution Alignment"]}],["$","span","Post-execution Reflection",{"className":"page__taxonomy-item","children":["#","Post-execution Reflection"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","Multimodal LLM",{"className":"page__taxonomy-item","children":["#","Multimodal LLM"]}],["$","span","Deliberative AI",{"className":"page__taxonomy-item","children":["#","Deliberative AI"]}]]}]]}]]}],["$","article","2025-9-29-CHURRO_Making_History_Readable_with_an_Open-Weight_Large_Vision-Language_Model_for_High-Accuracy_Low-Cost_Historical_Text_Recognition",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-CHURRO_Making_History_Readable_with_an_Open-Weight_Large_Vision-Language_Model_for_High-Accuracy_Low-Cost_Historical_Text_Recognition/","children":"[논문리뷰] CHURRO: Making History Readable with an Open-Weight Large Vision-Language Model for High-Accuracy, Low-Cost Historical Text Recognition"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'CHURRO: Making History Readable with an Open-Weight Large Vision-Language Model for High-Accuracy, Low-Cost Historical Text Recognition' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Historical Text Recognition",{"className":"page__taxonomy-item","children":["#","Historical Text Recognition"]}],["$","span","Vision-Language Model",{"className":"page__taxonomy-item","children":["#","Vision-Language Model"]}],["$","span","Open-Weight Model",{"className":"page__taxonomy-item","children":["#","Open-Weight Model"]}],["$","span","OCR",{"className":"page__taxonomy-item","children":["#","OCR"]}],["$","span","Cultural Heritage",{"className":"page__taxonomy-item","children":["#","Cultural Heritage"]}],["$","span","Low-Cost AI",{"className":"page__taxonomy-item","children":["#","Low-Cost AI"]}],["$","span","Dataset Curation",{"className":"page__taxonomy-item","children":["#","Dataset Curation"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}]]}]]}]]}],["$","article","2025-9-29-Chasing_the_Tail_Effective_Rubric-based_Reward_Modeling_for_Large_Language_Model_Post-Training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-Chasing_the_Tail_Effective_Rubric-based_Reward_Modeling_for_Large_Language_Model_Post-Training/","children":"[논문리뷰] Chasing the Tail: Effective Rubric-based Reward Modeling for Large Language Model Post-Training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'Chasing the Tail: Effective Rubric-based Reward Modeling for Large Language Model Post-Training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Reinforcement Fine-tuning",{"className":"page__taxonomy-item","children":["#","Reinforcement Fine-tuning"]}],["$","span","Reward Modeling",{"className":"page__taxonomy-item","children":["#","Reward Modeling"]}],["$","span","Reward Over-optimization",{"className":"page__taxonomy-item","children":["#","Reward Over-optimization"]}],["$","span","Rubric-based Rewards",{"className":"page__taxonomy-item","children":["#","Rubric-based Rewards"]}],["$","span","High-reward Tail",{"className":"page__taxonomy-item","children":["#","High-reward Tail"]}],["$","span","Off-policy Data",{"className":"page__taxonomy-item","children":["#","Off-policy Data"]}],["$","span","LLM Alignment",{"className":"page__taxonomy-item","children":["#","LLM Alignment"]}]]}]]}]]}],["$","article","2025-9-29-CapRL_Stimulating_Dense_Image_Caption_Capabilities_via_Reinforcement_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-29-CapRL_Stimulating_Dense_Image_Caption_Capabilities_via_Reinforcement_Learning/","children":"[논문리뷰] CapRL: Stimulating Dense Image Caption Capabilities via Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"이 [arXiv]에 게시한 'CapRL: Stimulating Dense Image Caption Capabilities via Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-29 13:47:46+0900","children":"2025년 9월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Captioning",{"className":"page__taxonomy-item","children":["#","Image Captioning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Verifiable Rewards",{"className":"page__taxonomy-item","children":["#","Verifiable Rewards"]}],["$","span","LVLMs",{"className":"page__taxonomy-item","children":["#","LVLMs"]}],["$","span","VQA",{"className":"page__taxonomy-item","children":["#","VQA"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Caption Quality",{"className":"page__taxonomy-item","children":["#","Caption Quality"]}]]}]]}]]}],["$","article","2025-9-26-When_Judgment_Becomes_Noise_How_Design_Failures_in_LLM_Judge_Benchmarks_Silently_Undermine_Validity",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-When_Judgment_Becomes_Noise_How_Design_Failures_in_LLM_Judge_Benchmarks_Silently_Undermine_Validity/","children":"[논문리뷰] When Judgment Becomes Noise: How Design Failures in LLM Judge Benchmarks Silently Undermine Validity"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"John P Dickerson이 [arXiv]에 게시한 'When Judgment Becomes Noise: How Design Failures in LLM Judge Benchmarks Silently Undermine Validity' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Judge",{"className":"page__taxonomy-item","children":["#","LLM Judge"]}],["$","span","Benchmark Evaluation",{"className":"page__taxonomy-item","children":["#","Benchmark Evaluation"]}],["$","span","Validity",{"className":"page__taxonomy-item","children":["#","Validity"]}],["$","span","Reliability",{"className":"page__taxonomy-item","children":["#","Reliability"]}],["$","span","Psychometrics",{"className":"page__taxonomy-item","children":["#","Psychometrics"]}],["$","span","Factor Analysis",{"className":"page__taxonomy-item","children":["#","Factor Analysis"]}],["$","span","Schema Adherence",{"className":"page__taxonomy-item","children":["#","Schema Adherence"]}],["$","span","ELO Ranking",{"className":"page__taxonomy-item","children":["#","ELO Ranking"]}]]}]]}]]}],["$","article","2025-9-26-VCRL_Variance-based_Curriculum_Reinforcement_Learning_for_Large_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-VCRL_Variance-based_Curriculum_Reinforcement_Learning_for_Large_Language_Models/","children":"[논문리뷰] VCRL: Variance-based Curriculum Reinforcement Learning for Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuewei Zhang이 [arXiv]에 게시한 'VCRL: Variance-based Curriculum Reinforcement Learning for Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Variance-based Sampling",{"className":"page__taxonomy-item","children":["#","Variance-based Sampling"]}],["$","span","Replay Learning",{"className":"page__taxonomy-item","children":["#","Replay Learning"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}]]}]]}]]}],["$","article","2025-9-26-V-GameGym_Visual_Game_Generation_for_Code_Large_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-V-GameGym_Visual_Game_Generation_for_Code_Large_Language_Models/","children":"[논문리뷰] V-GameGym: Visual Game Generation for Code Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shawn Guo이 [arXiv]에 게시한 'V-GameGym: Visual Game Generation for Code Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Code Large Language Models",{"className":"page__taxonomy-item","children":["#","Code Large Language Models"]}],["$","span","Visual Game Generation",{"className":"page__taxonomy-item","children":["#","Visual Game Generation"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Pygame",{"className":"page__taxonomy-item","children":["#","Pygame"]}],["$","span","Multimodal Evaluation",{"className":"page__taxonomy-item","children":["#","Multimodal Evaluation"]}],["$","span","Software Engineering",{"className":"page__taxonomy-item","children":["#","Software Engineering"]}],["$","span","AI-assisted Game Development",{"className":"page__taxonomy-item","children":["#","AI-assisted Game Development"]}]]}]]}]]}],["$","article","2025-9-26-Understanding_the_Thinking_Process_of_Reasoning_Models_A_Perspective_from_Schoenfelds_Episode_Theory",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-Understanding_the_Thinking_Process_of_Reasoning_Models_A_Perspective_from_Schoenfelds_Episode_Theory/","children":"[논문리뷰] Understanding the Thinking Process of Reasoning Models: A Perspective from Schoenfeld's Episode Theory"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yanbin Fu이 [arXiv]에 게시한 'Understanding the Thinking Process of Reasoning Models: A Perspective from Schoenfeld's Episode Theory' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Reasoning Models",{"className":"page__taxonomy-item","children":["#","Large Reasoning Models"]}],["$","span","Cognitive Science",{"className":"page__taxonomy-item","children":["#","Cognitive Science"]}],["$","span","Schoenfeld's Episode Theory",{"className":"page__taxonomy-item","children":["#","Schoenfeld's Episode Theory"]}],["$","span","Math Problem Solving",{"className":"page__taxonomy-item","children":["#","Math Problem Solving"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Behavioral Analysis",{"className":"page__taxonomy-item","children":["#","Behavioral Analysis"]}],["$","span","Dataset Annotation",{"className":"page__taxonomy-item","children":["#","Dataset Annotation"]}]]}]]}]]}],["$","article","2025-9-26-TrustJudge_Inconsistencies_of_LLM-as-a-Judge_and_How_to_Alleviate_Them",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-TrustJudge_Inconsistencies_of_LLM-as-a-Judge_and_How_to_Alleviate_Them/","children":"[논문리뷰] TrustJudge: Inconsistencies of LLM-as-a-Judge and How to Alleviate Them"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhuohao Yu이 [arXiv]에 게시한 'TrustJudge: Inconsistencies of LLM-as-a-Judge and How to Alleviate Them' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM-as-a-Judge",{"className":"page__taxonomy-item","children":["#","LLM-as-a-Judge"]}],["$","span","Evaluation Frameworks",{"className":"page__taxonomy-item","children":["#","Evaluation Frameworks"]}],["$","span","Inconsistency Reduction",{"className":"page__taxonomy-item","children":["#","Inconsistency Reduction"]}],["$","span","Probabilistic Scoring",{"className":"page__taxonomy-item","children":["#","Probabilistic Scoring"]}],["$","span","Transitivity",{"className":"page__taxonomy-item","children":["#","Transitivity"]}],["$","span","Information Loss",{"className":"page__taxonomy-item","children":["#","Information Loss"]}],["$","span","Perplexity",{"className":"page__taxonomy-item","children":["#","Perplexity"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}]]}]]}]]}],["$","article","2025-9-26-Tree_Search_for_LLM_Agent_Reinforcement_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-Tree_Search_for_LLM_Agent_Reinforcement_Learning/","children":"[논문리뷰] Tree Search for LLM Agent Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiangxiang Chu이 [arXiv]에 게시한 'Tree Search for LLM Agent Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Tree Search",{"className":"page__taxonomy-item","children":["#","Tree Search"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Preference Learning",{"className":"page__taxonomy-item","children":["#","Preference Learning"]}],["$","span","Sparse Rewards",{"className":"page__taxonomy-item","children":["#","Sparse Rewards"]}],["$","span","Multi-turn Tasks",{"className":"page__taxonomy-item","children":["#","Multi-turn Tasks"]}]]}]]}]]}],["$","article","2025-9-26-Thinking_While_Listening_Simple_Test_Time_Scaling_For_Audio_Classification",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-Thinking_While_Listening_Simple_Test_Time_Scaling_For_Audio_Classification/","children":"[논문리뷰] Thinking While Listening: Simple Test Time Scaling For Audio Classification"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Mert Pilanci이 [arXiv]에 게시한 'Thinking While Listening: Simple Test Time Scaling For Audio Classification' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Audio Classification",{"className":"page__taxonomy-item","children":["#","Audio Classification"]}],["$","span","Test-Time Scaling",{"className":"page__taxonomy-item","children":["#","Test-Time Scaling"]}],["$","span","Reasoning Traces",{"className":"page__taxonomy-item","children":["#","Reasoning Traces"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Transformer Architectures",{"className":"page__taxonomy-item","children":["#","Transformer Architectures"]}],["$","span","Zero-shot Reasoning",{"className":"page__taxonomy-item","children":["#","Zero-shot Reasoning"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}]]}]]}]]}],["$","article","2025-9-26-Thinking_Augmented_Pre-training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-Thinking_Augmented_Pre-training/","children":"[논문리뷰] Thinking Augmented Pre-training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Furu Wei이 [arXiv]에 게시한 'Thinking Augmented Pre-training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Pre-training",{"className":"page__taxonomy-item","children":["#","Pre-training"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Data Efficiency",{"className":"page__taxonomy-item","children":["#","Data Efficiency"]}],["$","span","Thinking Trajectories",{"className":"page__taxonomy-item","children":["#","Thinking Trajectories"]}]]}]]}]]}],["$","article","2025-9-26-The_Unanticipated_Asymmetry_Between_Perceptual_Optimization_and_Assessment",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-The_Unanticipated_Asymmetry_Between_Perceptual_Optimization_and_Assessment/","children":"[논문리뷰] The Unanticipated Asymmetry Between Perceptual Optimization and Assessment"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Du Chen이 [arXiv]에 게시한 'The Unanticipated Asymmetry Between Perceptual Optimization and Assessment' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Perceptual Optimization",{"className":"page__taxonomy-item","children":["#","Perceptual Optimization"]}],["$","span","Image Quality Assessment (IQA)",{"className":"page__taxonomy-item","children":["#","Image Quality Assessment (IQA)"]}],["$","span","Adversarial Training",{"className":"page__taxonomy-item","children":["#","Adversarial Training"]}],["$","span","Discriminators",{"className":"page__taxonomy-item","children":["#","Discriminators"]}],["$","span","Super-Resolution",{"className":"page__taxonomy-item","children":["#","Super-Resolution"]}],["$","span","Fidelity Metrics",{"className":"page__taxonomy-item","children":["#","Fidelity Metrics"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}]]}]]}]]}],["$","article","2025-9-26-StyleBench_Evaluating_thinking_styles_in_Large_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-StyleBench_Evaluating_thinking_styles_in_Large_Language_Models/","children":"[논문리뷰] StyleBench: Evaluating thinking styles in Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Javad Lavaei이 [arXiv]에 게시한 'StyleBench: Evaluating thinking styles in Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reasoning Strategies",{"className":"page__taxonomy-item","children":["#","Reasoning Strategies"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Thinking Styles",{"className":"page__taxonomy-item","children":["#","Thinking Styles"]}],["$","span","Scaling Laws",{"className":"page__taxonomy-item","children":["#","Scaling Laws"]}],["$","span","Meta-Reasoning",{"className":"page__taxonomy-item","children":["#","Meta-Reasoning"]}]]}]]}]]}],["$","article","2025-9-26-Seedream_4.0_Toward_Next-generation_Multimodal_Image_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-Seedream_4.0_Toward_Next-generation_Multimodal_Image_Generation/","children":"[논문리뷰] Seedream 4.0: Toward Next-generation Multimodal Image Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yunpeng Chen이 [arXiv]에 게시한 'Seedream 4.0: Toward Next-generation Multimodal Image Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Image Generation",{"className":"page__taxonomy-item","children":["#","Multimodal Image Generation"]}],["$","span","Diffusion Transformer",{"className":"page__taxonomy-item","children":["#","Diffusion Transformer"]}],["$","span","VAE",{"className":"page__taxonomy-item","children":["#","VAE"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Text-to-Image",{"className":"page__taxonomy-item","children":["#","Text-to-Image"]}],["$","span","Model Acceleration",{"className":"page__taxonomy-item","children":["#","Model Acceleration"]}],["$","span","Human Evaluation",{"className":"page__taxonomy-item","children":["#","Human Evaluation"]}]]}]]}]]}],["$","article","2025-9-26-SD3.5-Flash_Distribution-Guided_Distillation_of_Generative_Flows",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-SD3.5-Flash_Distribution-Guided_Distillation_of_Generative_Flows/","children":"[논문리뷰] SD3.5-Flash: Distribution-Guided Distillation of Generative Flows"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yi-Zhe Song이 [arXiv]에 게시한 'SD3.5-Flash: Distribution-Guided Distillation of Generative Flows' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Rectified Flow",{"className":"page__taxonomy-item","children":["#","Rectified Flow"]}],["$","span","Model Distillation",{"className":"page__taxonomy-item","children":["#","Model Distillation"]}],["$","span","Few-Step Generation",{"className":"page__taxonomy-item","children":["#","Few-Step Generation"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}],["$","span","Prompt Alignment",{"className":"page__taxonomy-item","children":["#","Prompt Alignment"]}]]}]]}]]}],["$","article","2025-9-26-SciReasoner_Laying_the_Scientific_Reasoning_Ground_Across_Disciplines",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-SciReasoner_Laying_the_Scientific_Reasoning_Ground_Across_Disciplines/","children":"[논문리뷰] SciReasoner: Laying the Scientific Reasoning Ground Across Disciplines"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiabei Xiao이 [arXiv]에 게시한 'SciReasoner: Laying the Scientific Reasoning Ground Across Disciplines' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Scientific Reasoning",{"className":"page__taxonomy-item","children":["#","Scientific Reasoning"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Multi-modal Learning",{"className":"page__taxonomy-item","children":["#","Multi-modal Learning"]}],["$","span","Cross-domain Generalization",{"className":"page__taxonomy-item","children":["#","Cross-domain Generalization"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Scientific Discovery",{"className":"page__taxonomy-item","children":["#","Scientific Discovery"]}],["$","span","Molecular Design",{"className":"page__taxonomy-item","children":["#","Molecular Design"]}]]}]]}]]}],["$","article","2025-9-26-SceneWeaver_All-in-One_3D_Scene_Synthesis_with_an_Extensible_and_Self-Reflective_Agent",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-SceneWeaver_All-in-One_3D_Scene_Synthesis_with_an_Extensible_and_Self-Reflective_Agent/","children":"[논문리뷰] SceneWeaver: All-in-One 3D Scene Synthesis with an Extensible and Self-Reflective Agent"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Siyuan Huang이 [arXiv]에 게시한 'SceneWeaver: All-in-One 3D Scene Synthesis with an Extensible and Self-Reflective Agent' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Scene Synthesis",{"className":"page__taxonomy-item","children":["#","3D Scene Synthesis"]}],["$","span","Agentic Framework",{"className":"page__taxonomy-item","children":["#","Agentic Framework"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Self-Reflection",{"className":"page__taxonomy-item","children":["#","Self-Reflection"]}],["$","span","Tool-Use",{"className":"page__taxonomy-item","children":["#","Tool-Use"]}],["$","span","Physical Plausibility",{"className":"page__taxonomy-item","children":["#","Physical Plausibility"]}],["$","span","Iterative Refinement",{"className":"page__taxonomy-item","children":["#","Iterative Refinement"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}]]}]]}]]}],["$","article","2025-9-26-ScaleDiff_Scaling_Difficult_Problems_for_Advanced_Mathematical_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-ScaleDiff_Scaling_Difficult_Problems_for_Advanced_Mathematical_Reasoning/","children":"[논문리뷰] ScaleDiff: Scaling Difficult Problems for Advanced Mathematical Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yu Li이 [arXiv]에 게시한 'ScaleDiff: Scaling Difficult Problems for Advanced Mathematical Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Large Reasoning Models (LRMs)",{"className":"page__taxonomy-item","children":["#","Large Reasoning Models (LRMs)"]}],["$","span","Difficulty Scaling",{"className":"page__taxonomy-item","children":["#","Difficulty Scaling"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}],["$","span","Supervised Fine-Tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning (SFT)"]}],["$","span","Problem Generation",{"className":"page__taxonomy-item","children":["#","Problem Generation"]}],["$","span","Solution Distillation",{"className":"page__taxonomy-item","children":["#","Solution Distillation"]}]]}]]}]]}],["$","article","2025-9-26-Residual_Off-Policy_RL_for_Finetuning_Behavior_Cloning_Policies",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-Residual_Off-Policy_RL_for_Finetuning_Behavior_Cloning_Policies/","children":"[논문리뷰] Residual Off-Policy RL for Finetuning Behavior Cloning Policies"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Pieter Abbeel이 [arXiv]에 게시한 'Residual Off-Policy RL for Finetuning Behavior Cloning Policies' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Behavior Cloning (BC)",{"className":"page__taxonomy-item","children":["#","Behavior Cloning (BC)"]}],["$","span","Residual Learning",{"className":"page__taxonomy-item","children":["#","Residual Learning"]}],["$","span","Off-Policy RL",{"className":"page__taxonomy-item","children":["#","Off-Policy RL"]}],["$","span","Robot Manipulation",{"className":"page__taxonomy-item","children":["#","Robot Manipulation"]}],["$","span","Real-World Robotics",{"className":"page__taxonomy-item","children":["#","Real-World Robotics"]}],["$","span","High-DoF Systems",{"className":"page__taxonomy-item","children":["#","High-DoF Systems"]}],["$","span","Sample Efficiency",{"className":"page__taxonomy-item","children":["#","Sample Efficiency"]}]]}]]}]]}],["$","article","2025-9-26-Recon-Act_A_Self-Evolving_Multi-Agent_Browser-Use_System_via_Web_Reconnaissance_Tool_Generation_and_Task_Execution",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-Recon-Act_A_Self-Evolving_Multi-Agent_Browser-Use_System_via_Web_Reconnaissance_Tool_Generation_and_Task_Execution/","children":"[논문리뷰] Recon-Act: A Self-Evolving Multi-Agent Browser-Use System via Web Reconnaissance, Tool Generation, and Task Execution"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jinjie Gu이 [arXiv]에 게시한 'Recon-Act: A Self-Evolving Multi-Agent Browser-Use System via Web Reconnaissance, Tool Generation, and Task Execution' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-Agent System",{"className":"page__taxonomy-item","children":["#","Multi-Agent System"]}],["$","span","Browser Automation",{"className":"page__taxonomy-item","children":["#","Browser Automation"]}],["$","span","Web Reconnaissance",{"className":"page__taxonomy-item","children":["#","Web Reconnaissance"]}],["$","span","Tool Generation",{"className":"page__taxonomy-item","children":["#","Tool Generation"]}],["$","span","Task Execution",{"className":"page__taxonomy-item","children":["#","Task Execution"]}],["$","span","Self-Evolving AI",{"className":"page__taxonomy-item","children":["#","Self-Evolving AI"]}],["$","span","LLM/VLM",{"className":"page__taxonomy-item","children":["#","LLM/VLM"]}],["$","span","VisualWebArena",{"className":"page__taxonomy-item","children":["#","VisualWebArena"]}]]}]]}]]}],["$","article","2025-9-26-Quantized_Visual_Geometry_Grounded_Transformer",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-Quantized_Visual_Geometry_Grounded_Transformer/","children":"[논문리뷰] Quantized Visual Geometry Grounded Transformer"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuqi Li이 [arXiv]에 게시한 'Quantized Visual Geometry Grounded Transformer' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Quantization",{"className":"page__taxonomy-item","children":["#","Quantization"]}],["$","span","Post-Training Quantization",{"className":"page__taxonomy-item","children":["#","Post-Training Quantization"]}],["$","span","3D Reconstruction",{"className":"page__taxonomy-item","children":["#","3D Reconstruction"]}],["$","span","Visual Transformer",{"className":"page__taxonomy-item","children":["#","Visual Transformer"]}],["$","span","Model Compression",{"className":"page__taxonomy-item","children":["#","Model Compression"]}],["$","span","Efficient Inference",{"className":"page__taxonomy-item","children":["#","Efficient Inference"]}],["$","span","Hadamard Rotation",{"className":"page__taxonomy-item","children":["#","Hadamard Rotation"]}],["$","span","Calibration Sampling",{"className":"page__taxonomy-item","children":["#","Calibration Sampling"]}]]}]]}]]}],["$","article","2025-9-26-MOSS-ChatV_Reinforcement_Learning_with_Process_Reasoning_Reward_for_Video_Temporal_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-MOSS-ChatV_Reinforcement_Learning_with_Process_Reasoning_Reward_for_Video_Temporal_Reasoning/","children":"[논문리뷰] MOSS-ChatV: Reinforcement Learning with Process Reasoning Reward for Video Temporal Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Junyan Zhang이 [arXiv]에 게시한 'MOSS-ChatV: Reinforcement Learning with Process Reasoning Reward for Video Temporal Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Temporal Reasoning",{"className":"page__taxonomy-item","children":["#","Video Temporal Reasoning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Process Supervision",{"className":"page__taxonomy-item","children":["#","Process Supervision"]}],["$","span","Dynamic Time Warping",{"className":"page__taxonomy-item","children":["#","Dynamic Time Warping"]}],["$","span","Multimodal Large Language Models",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models"]}],["$","span","Video State Prediction",{"className":"page__taxonomy-item","children":["#","Video State Prediction"]}],["$","span","Reward Hacking",{"className":"page__taxonomy-item","children":["#","Reward Hacking"]}]]}]]}]]}],["$","article","2025-9-26-MMR1_Enhancing_Multimodal_Reasoning_with_Variance-Aware_Sampling_and_Open_Resources",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-MMR1_Enhancing_Multimodal_Reasoning_with_Variance-Aware_Sampling_and_Open_Resources/","children":"[논문리뷰] MMR1: Enhancing Multimodal Reasoning with Variance-Aware Sampling and Open Resources"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jing Wang이 [arXiv]에 게시한 'MMR1: Enhancing Multimodal Reasoning with Variance-Aware Sampling and Open Resources' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Variance-Aware Sampling",{"className":"page__taxonomy-item","children":["#","Variance-Aware Sampling"]}],["$","span","Gradient Vanishing",{"className":"page__taxonomy-item","children":["#","Gradient Vanishing"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","GRPO",{"className":"page__taxonomy-item","children":["#","GRPO"]}]]}]]}]]}],["$","article","2025-9-26-MI-Fuse_Label_Fusion_for_Unsupervised_Domain_Adaptation_with_Closed-Source_Large-Audio_Language_Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-MI-Fuse_Label_Fusion_for_Unsupervised_Domain_Adaptation_with_Closed-Source_Large-Audio_Language_Model/","children":"[논문리뷰] MI-Fuse: Label Fusion for Unsupervised Domain Adaptation with Closed-Source Large-Audio Language Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hung-yi Lee이 [arXiv]에 게시한 'MI-Fuse: Label Fusion for Unsupervised Domain Adaptation with Closed-Source Large-Audio Language Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Speech Emotion Recognition",{"className":"page__taxonomy-item","children":["#","Speech Emotion Recognition"]}],["$","span","Source-Free Unsupervised Domain Adaptation",{"className":"page__taxonomy-item","children":["#","Source-Free Unsupervised Domain Adaptation"]}],["$","span","Large Audio-Language Models",{"className":"page__taxonomy-item","children":["#","Large Audio-Language Models"]}],["$","span","Label Fusion",{"className":"page__taxonomy-item","children":["#","Label Fusion"]}],["$","span","Mutual Information",{"className":"page__taxonomy-item","children":["#","Mutual Information"]}],["$","span","API-Only Models",{"className":"page__taxonomy-item","children":["#","API-Only Models"]}],["$","span","Domain Mismatch",{"className":"page__taxonomy-item","children":["#","Domain Mismatch"]}]]}]]}]]}],["$","article","2025-9-26-Interactive_Recommendation_Agent_with_Active_User_Commands",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-Interactive_Recommendation_Agent_with_Active_User_Commands/","children":"[논문리뷰] Interactive Recommendation Agent with Active User Commands"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xueyang Feng이 [arXiv]에 게시한 'Interactive Recommendation Agent with Active User Commands' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Interactive Recommendation",{"className":"page__taxonomy-item","children":["#","Interactive Recommendation"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Multi-Agent System",{"className":"page__taxonomy-item","children":["#","Multi-Agent System"]}],["$","span","Natural Language Processing",{"className":"page__taxonomy-item","children":["#","Natural Language Processing"]}],["$","span","Knowledge Distillation",{"className":"page__taxonomy-item","children":["#","Knowledge Distillation"]}],["$","span","User Control",{"className":"page__taxonomy-item","children":["#","User Control"]}]]}]]}]]}],["$","article","2025-9-26-Hunyuan3D-Omni_A_Unified_Framework_for_Controllable_Generation_of_3D_Assets",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-Hunyuan3D-Omni_A_Unified_Framework_for_Controllable_Generation_of_3D_Assets/","children":"[논문리뷰] Hunyuan3D-Omni: A Unified Framework for Controllable Generation of 3D Assets"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Bowen Zhang이 [arXiv]에 게시한 'Hunyuan3D-Omni: A Unified Framework for Controllable Generation of 3D Assets' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Generation",{"className":"page__taxonomy-item","children":["#","3D Generation"]}],["$","span","Controllable Generation",{"className":"page__taxonomy-item","children":["#","Controllable Generation"]}],["$","span","Multi-modal Conditioning",{"className":"page__taxonomy-item","children":["#","Multi-modal Conditioning"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Point Clouds",{"className":"page__taxonomy-item","children":["#","Point Clouds"]}],["$","span","Voxels",{"className":"page__taxonomy-item","children":["#","Voxels"]}],["$","span","Bounding Boxes",{"className":"page__taxonomy-item","children":["#","Bounding Boxes"]}],["$","span","Skeletons",{"className":"page__taxonomy-item","children":["#","Skeletons"]}],["$","span","Hunyuan3D",{"className":"page__taxonomy-item","children":["#","Hunyuan3D"]}]]}]]}]]}],["$","article","2025-9-26-Does_FLUX_Already_Know_How_to_Perform_Physically_Plausible_Image_Composition",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-Does_FLUX_Already_Know_How_to_Perform_Physically_Plausible_Image_Composition/","children":"[논문리뷰] Does FLUX Already Know How to Perform Physically Plausible Image Composition?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chen Zhao이 [arXiv]에 게시한 'Does FLUX Already Know How to Perform Physically Plausible Image Composition?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Composition",{"className":"page__taxonomy-item","children":["#","Image Composition"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}],["$","span","Physically Plausible",{"className":"page__taxonomy-item","children":["#","Physically Plausible"]}],["$","span","FLUX",{"className":"page__taxonomy-item","children":["#","FLUX"]}],["$","span","Adapter",{"className":"page__taxonomy-item","children":["#","Adapter"]}],["$","span","Guidance",{"className":"page__taxonomy-item","children":["#","Guidance"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}]]}]]}]]}],["$","article","2025-9-26-Discrete_Diffusion_for_Reflective_Vision-Language-Action_Models_in_Autonomous_Driving",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-Discrete_Diffusion_for_Reflective_Vision-Language-Action_Models_in_Autonomous_Driving/","children":"[논문리뷰] Discrete Diffusion for Reflective Vision-Language-Action Models in Autonomous Driving"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hang Zhao이 [arXiv]에 게시한 'Discrete Diffusion for Reflective Vision-Language-Action Models in Autonomous Driving' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Autonomous Driving",{"className":"page__taxonomy-item","children":["#","Autonomous Driving"]}],["$","span","Vision-Language-Action Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action Models"]}],["$","span","Discrete Diffusion",{"className":"page__taxonomy-item","children":["#","Discrete Diffusion"]}],["$","span","Reflection Mechanism",{"className":"page__taxonomy-item","children":["#","Reflection Mechanism"]}],["$","span","Trajectory Generation",{"className":"page__taxonomy-item","children":["#","Trajectory Generation"]}],["$","span","Safety Constraints",{"className":"page__taxonomy-item","children":["#","Safety Constraints"]}],["$","span","Imitation Learning",{"className":"page__taxonomy-item","children":["#","Imitation Learning"]}]]}]]}]]}],["$","article","2025-9-26-CHARM_Control-point-based_3D_Anime_Hairstyle_Auto-Regressive_Modeling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-CHARM_Control-point-based_3D_Anime_Hairstyle_Auto-Regressive_Modeling/","children":"[논문리뷰] CHARM: Control-point-based 3D Anime Hairstyle Auto-Regressive Modeling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yushi Bai이 [arXiv]에 게시한 'CHARM: Control-point-based 3D Anime Hairstyle Auto-Regressive Modeling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Anime Hairstyle",{"className":"page__taxonomy-item","children":["#","3D Anime Hairstyle"]}],["$","span","Autoregressive Modeling",{"className":"page__taxonomy-item","children":["#","Autoregressive Modeling"]}],["$","span","Control Points",{"className":"page__taxonomy-item","children":["#","Control Points"]}],["$","span","Parametric Representation",{"className":"page__taxonomy-item","children":["#","Parametric Representation"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Dataset (AnimeHair)",{"className":"page__taxonomy-item","children":["#","Dataset (AnimeHair)"]}],["$","span","Computer Graphics",{"className":"page__taxonomy-item","children":["#","Computer Graphics"]}]]}]]}]]}],["$","article","2025-9-26-CE-GPPO_Controlling_Entropy_via_Gradient-Preserving_Clipping_Policy_Optimization_in_Reinforcement_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-CE-GPPO_Controlling_Entropy_via_Gradient-Preserving_Clipping_Policy_Optimization_in_Reinforcement_Learning/","children":"[논문리뷰] CE-GPPO: Controlling Entropy via Gradient-Preserving Clipping Policy Optimization in Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wenping Hu이 [arXiv]에 게시한 'CE-GPPO: Controlling Entropy via Gradient-Preserving Clipping Policy Optimization in Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","PPO",{"className":"page__taxonomy-item","children":["#","PPO"]}],["$","span","Entropy Control",{"className":"page__taxonomy-item","children":["#","Entropy Control"]}],["$","span","Gradient Clipping",{"className":"page__taxonomy-item","children":["#","Gradient Clipping"]}],["$","span","Exploration-Exploitation",{"className":"page__taxonomy-item","children":["#","Exploration-Exploitation"]}]]}]]}]]}],["$","article","2025-9-26-Blueprints_of_Trust_AI_System_Cards_for_End_to_End_Transparency_and_Governance",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-Blueprints_of_Trust_AI_System_Cards_for_End_to_End_Transparency_and_Governance/","children":"[논문리뷰] Blueprints of Trust: AI System Cards for End to End Transparency and Governance"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Roman Zhukov이 [arXiv]에 게시한 'Blueprints of Trust: AI System Cards for End to End Transparency and Governance' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Governance",{"className":"page__taxonomy-item","children":["#","AI Governance"]}],["$","span","Transparency",{"className":"page__taxonomy-item","children":["#","Transparency"]}],["$","span","AI System Card",{"className":"page__taxonomy-item","children":["#","AI System Card"]}],["$","span","Hazard-Aware System Card",{"className":"page__taxonomy-item","children":["#","Hazard-Aware System Card"]}],["$","span","Data Provenance",{"className":"page__taxonomy-item","children":["#","Data Provenance"]}],["$","span","AI Safety",{"className":"page__taxonomy-item","children":["#","AI Safety"]}],["$","span","AI Risk Management",{"className":"page__taxonomy-item","children":["#","AI Risk Management"]}],["$","span","ISO/IEC 42001",{"className":"page__taxonomy-item","children":["#","ISO/IEC 42001"]}]]}]]}]]}],["$","article","2025-9-26-BESPOKE_Benchmark_for_Search-Augmented_Large_Language_Model_Personalization_via_Diagnostic_Feedback",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-BESPOKE_Benchmark_for_Search-Augmented_Large_Language_Model_Personalization_via_Diagnostic_Feedback/","children":"[논문리뷰] BESPOKE: Benchmark for Search-Augmented Large Language Model Personalization via Diagnostic Feedback"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Dongha Lee이 [arXiv]에 게시한 'BESPOKE: Benchmark for Search-Augmented Large Language Model Personalization via Diagnostic Feedback' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Search-Augmented LLMs",{"className":"page__taxonomy-item","children":["#","Search-Augmented LLMs"]}],["$","span","Personalization",{"className":"page__taxonomy-item","children":["#","Personalization"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Diagnostic Feedback",{"className":"page__taxonomy-item","children":["#","Diagnostic Feedback"]}],["$","span","User History",{"className":"page__taxonomy-item","children":["#","User History"]}],["$","span","Evaluation Framework",{"className":"page__taxonomy-item","children":["#","Evaluation Framework"]}],["$","span","RAG",{"className":"page__taxonomy-item","children":["#","RAG"]}]]}]]}]]}],["$","article","2025-9-26-Behind_RoPE_How_Does_Causal_Mask_Encode_Positional_Information",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-Behind_RoPE_How_Does_Causal_Mask_Encode_Positional_Information/","children":"[논문리뷰] Behind RoPE: How Does Causal Mask Encode Positional Information?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yeyun Gong이 [arXiv]에 게시한 'Behind RoPE: How Does Causal Mask Encode Positional Information?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Transformer Decoder",{"className":"page__taxonomy-item","children":["#","Transformer Decoder"]}],["$","span","Causal Mask",{"className":"page__taxonomy-item","children":["#","Causal Mask"]}],["$","span","Positional Encoding",{"className":"page__taxonomy-item","children":["#","Positional Encoding"]}],["$","span","RoPE",{"className":"page__taxonomy-item","children":["#","RoPE"]}],["$","span","Attention Mechanism",{"className":"page__taxonomy-item","children":["#","Attention Mechanism"]}],["$","span","Length Generalization",{"className":"page__taxonomy-item","children":["#","Length Generalization"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}]]}]]}]]}],["$","article","2025-9-26-AutoIntent_AutoML_for_Text_Classification",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-26-AutoIntent_AutoML_for_Text_Classification/","children":"[논문리뷰] AutoIntent: AutoML for Text Classification"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Denis Kuznetsov이 [arXiv]에 게시한 'AutoIntent: AutoML for Text Classification' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-26 13:35:32+0900","children":"2025년 9월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AutoML",{"className":"page__taxonomy-item","children":["#","AutoML"]}],["$","span","Text Classification",{"className":"page__taxonomy-item","children":["#","Text Classification"]}],["$","span","Intent Classification",{"className":"page__taxonomy-item","children":["#","Intent Classification"]}],["$","span","Transformer Embeddings",{"className":"page__taxonomy-item","children":["#","Transformer Embeddings"]}],["$","span","Out-of-Scope Detection",{"className":"page__taxonomy-item","children":["#","Out-of-Scope Detection"]}],["$","span","Multi-label Classification",{"className":"page__taxonomy-item","children":["#","Multi-label Classification"]}],["$","span","Few-shot Learning",{"className":"page__taxonomy-item","children":["#","Few-shot Learning"]}],["$","span","Sklearn-like Interface",{"className":"page__taxonomy-item","children":["#","Sklearn-like Interface"]}]]}]]}]]}],["$","article","2025-9-25-Video_models_are_zero-shot_learners_and_reasoners",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-25-Video_models_are_zero-shot_learners_and_reasoners/","children":"[논문리뷰] Video models are zero-shot learners and reasoners"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"rgeirhos이 [arXiv]에 게시한 'Video models are zero-shot learners and reasoners' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-25 13:08:16+0900","children":"2025년 9월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Models",{"className":"page__taxonomy-item","children":["#","Video Models"]}],["$","span","Zero-shot Learning",{"className":"page__taxonomy-item","children":["#","Zero-shot Learning"]}],["$","span","Visual Reasoning",{"className":"page__taxonomy-item","children":["#","Visual Reasoning"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Perception",{"className":"page__taxonomy-item","children":["#","Perception"]}],["$","span","Manipulation",{"className":"page__taxonomy-item","children":["#","Manipulation"]}],["$","span","Modeling",{"className":"page__taxonomy-item","children":["#","Modeling"]}]]}]]}]]}],["$","article","2025-9-25-SIM-CoT_Supervised_Implicit_Chain-of-Thought",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-25-SIM-CoT_Supervised_Implicit_Chain-of-Thought/","children":"[논문리뷰] SIM-CoT: Supervised Implicit Chain-of-Thought"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuhang Cao이 [arXiv]에 게시한 'SIM-CoT: Supervised Implicit Chain-of-Thought' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-25 13:08:16+0900","children":"2025년 9월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Implicit Reasoning",{"className":"page__taxonomy-item","children":["#","Implicit Reasoning"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Latent Space",{"className":"page__taxonomy-item","children":["#","Latent Space"]}],["$","span","Supervised Learning",{"className":"page__taxonomy-item","children":["#","Supervised Learning"]}],["$","span","Model Stability",{"className":"page__taxonomy-item","children":["#","Model Stability"]}],["$","span","Interpretability",{"className":"page__taxonomy-item","children":["#","Interpretability"]}]]}]]}]]}],["$","article","2025-9-25-PhysCtrl_Generative_Physics_for_Controllable_and_Physics-Grounded_Video_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-25-PhysCtrl_Generative_Physics_for_Controllable_and_Physics-Grounded_Video_Generation/","children":"[논문리뷰] PhysCtrl: Generative Physics for Controllable and Physics-Grounded Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yiming Huang이 [arXiv]에 게시한 'PhysCtrl: Generative Physics for Controllable and Physics-Grounded Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-25 13:08:16+0900","children":"2025년 9월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Physics-Grounded",{"className":"page__taxonomy-item","children":["#","Physics-Grounded"]}],["$","span","Controllable Generation",{"className":"page__taxonomy-item","children":["#","Controllable Generation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Point Cloud Trajectories",{"className":"page__taxonomy-item","children":["#","Point Cloud Trajectories"]}],["$","span","Material Simulation",{"className":"page__taxonomy-item","children":["#","Material Simulation"]}],["$","span","Generative Physics",{"className":"page__taxonomy-item","children":["#","Generative Physics"]}]]}]]}]]}],["$","article","2025-9-25-On_the_Use_of_Agentic_Coding_An_Empirical_Study_of_Pull_Requests_on_GitHub",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-25-On_the_Use_of_Agentic_Coding_An_Empirical_Study_of_Pull_Requests_on_GitHub/","children":"[논문리뷰] On the Use of Agentic Coding: An Empirical Study of Pull Requests on GitHub"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hajimu Iida이 [arXiv]에 게시한 'On the Use of Agentic Coding: An Empirical Study of Pull Requests on GitHub' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-25 13:08:16+0900","children":"2025년 9월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic Coding",{"className":"page__taxonomy-item","children":["#","Agentic Coding"]}],["$","span","AI Agents",{"className":"page__taxonomy-item","children":["#","AI Agents"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","GitHub Pull Requests",{"className":"page__taxonomy-item","children":["#","GitHub Pull Requests"]}],["$","span","Software Engineering",{"className":"page__taxonomy-item","children":["#","Software Engineering"]}],["$","span","Empirical Study",{"className":"page__taxonomy-item","children":["#","Empirical Study"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","Software Development",{"className":"page__taxonomy-item","children":["#","Software Development"]}]]}]]}]]}],["$","article","2025-9-25-Logics-Parsing_Technical_Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-25-Logics-Parsing_Technical_Report/","children":"[논문리뷰] Logics-Parsing Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Fan Yang이 [arXiv]에 게시한 'Logics-Parsing Technical Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-25 13:08:16+0900","children":"2025년 9월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Document Parsing",{"className":"page__taxonomy-item","children":["#","Document Parsing"]}],["$","span","Large Vision-Language Models (LVLM)",{"className":"page__taxonomy-item","children":["#","Large Vision-Language Models (LVLM)"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Layout Analysis",{"className":"page__taxonomy-item","children":["#","Layout Analysis"]}],["$","span","Reading Order",{"className":"page__taxonomy-item","children":["#","Reading Order"]}],["$","span","Supervised Fine-Tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning (SFT)"]}],["$","span","HTML Annotation",{"className":"page__taxonomy-item","children":["#","HTML Annotation"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}]]}]]}]]}],["$","article","2025-9-25-LLMs4All_A_Review_on_Large_Language_Models_for_Research_and_Applications_in_Academic_Disciplines",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-25-LLMs4All_A_Review_on_Large_Language_Models_for_Research_and_Applications_in_Academic_Disciplines/","children":"[논문리뷰] LLMs4All: A Review on Large Language Models for Research and Applications in Academic Disciplines"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yanfang이 [arXiv]에 게시한 'LLMs4All: A Review on Large Language Models for Research and Applications in Academic Disciplines' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-25 13:08:16+0900","children":"2025년 9월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Academic Disciplines",{"className":"page__taxonomy-item","children":["#","Academic Disciplines"]}],["$","span","LLM Applications",{"className":"page__taxonomy-item","children":["#","LLM Applications"]}],["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Cross-disciplinary Research",{"className":"page__taxonomy-item","children":["#","Cross-disciplinary Research"]}],["$","span","Benchmarks",{"className":"page__taxonomy-item","children":["#","Benchmarks"]}]]}]]}]]}],["$","article","2025-9-25-Lavida-O_Elastic_Large_Masked_Diffusion_Models_for_Unified_Multimodal_Understanding_and_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-25-Lavida-O_Elastic_Large_Masked_Diffusion_Models_for_Unified_Multimodal_Understanding_and_Generation/","children":"[논문리뷰] Lavida-O: Elastic Large Masked Diffusion Models for Unified Multimodal Understanding and Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhe Lin이 [arXiv]에 게시한 'Lavida-O: Elastic Large Masked Diffusion Models for Unified Multimodal Understanding and Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-25 13:08:16+0900","children":"2025년 9월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Masked Diffusion Models",{"className":"page__taxonomy-item","children":["#","Masked Diffusion Models"]}],["$","span","Image Understanding",{"className":"page__taxonomy-item","children":["#","Image Understanding"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Object Grounding",{"className":"page__taxonomy-item","children":["#","Object Grounding"]}],["$","span","ElasticMoT",{"className":"page__taxonomy-item","children":["#","ElasticMoT"]}],["$","span","Self-reflection",{"className":"page__taxonomy-item","children":["#","Self-reflection"]}]]}]]}]]}],["$","article","2025-9-25-EmbeddingGemma_Powerful_and_Lightweight_Text_Representations",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-25-EmbeddingGemma_Powerful_and_Lightweight_Text_Representations/","children":"[논문리뷰] EmbeddingGemma: Powerful and Lightweight Text Representations"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Marksherwood이 [arXiv]에 게시한 'EmbeddingGemma: Powerful and Lightweight Text Representations' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-25 13:08:16+0900","children":"2025년 9월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text Embeddings",{"className":"page__taxonomy-item","children":["#","Text Embeddings"]}],["$","span","Lightweight Models",{"className":"page__taxonomy-item","children":["#","Lightweight Models"]}],["$","span","Encoder-Decoder",{"className":"page__taxonomy-item","children":["#","Encoder-Decoder"]}],["$","span","Knowledge Distillation",{"className":"page__taxonomy-item","children":["#","Knowledge Distillation"]}],["$","span","Model Souping",{"className":"page__taxonomy-item","children":["#","Model Souping"]}],["$","span","Quantization",{"className":"page__taxonomy-item","children":["#","Quantization"]}],["$","span","Multilingual",{"className":"page__taxonomy-item","children":["#","Multilingual"]}],["$","span","Gemma",{"className":"page__taxonomy-item","children":["#","Gemma"]}]]}]]}]]}],["$","article","2025-9-25-EditVerse_Unifying_Image_and_Video_Editing_and_Generation_with_In-Context_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-25-EditVerse_Unifying_Image_and_Video_Editing_and_Generation_with_In-Context_Learning/","children":"[논문리뷰] EditVerse: Unifying Image and Video Editing and Generation with In-Context Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Tianyu Wang이 [arXiv]에 게시한 'EditVerse: Unifying Image and Video Editing and Generation with In-Context Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-25 13:08:16+0900","children":"2025년 9월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Unified Multimodal Model",{"className":"page__taxonomy-item","children":["#","Unified Multimodal Model"]}],["$","span","In-Context Learning",{"className":"page__taxonomy-item","children":["#","In-Context Learning"]}],["$","span","Image and Video Editing",{"className":"page__taxonomy-item","children":["#","Image and Video Editing"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Full Self-Attention",{"className":"page__taxonomy-item","children":["#","Full Self-Attention"]}],["$","span","Rotary Positional Embedding",{"className":"page__taxonomy-item","children":["#","Rotary Positional Embedding"]}],["$","span","Cross-Modal Knowledge Transfer",{"className":"page__taxonomy-item","children":["#","Cross-Modal Knowledge Transfer"]}]]}]]}]]}],["$","article","2025-9-25-Advancing_Speech_Understanding_in_Speech-Aware_Language_Models_with_GRPO",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-25-Advancing_Speech_Understanding_in_Speech-Aware_Language_Models_with_GRPO/","children":"[논문리뷰] Advancing Speech Understanding in Speech-Aware Language Models with GRPO"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Avihu이 [arXiv]에 게시한 'Advancing Speech Understanding in Speech-Aware Language Models with GRPO' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-25 13:08:16+0900","children":"2025년 9월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Speech-Aware Language Models",{"className":"page__taxonomy-item","children":["#","Speech-Aware Language Models"]}],["$","span","SALLMs",{"className":"page__taxonomy-item","children":["#","SALLMs"]}],["$","span","GRPO",{"className":"page__taxonomy-item","children":["#","GRPO"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Speech Understanding",{"className":"page__taxonomy-item","children":["#","Speech Understanding"]}],["$","span","Spoken Question Answering",{"className":"page__taxonomy-item","children":["#","Spoken Question Answering"]}],["$","span","Automatic Speech Translation",{"className":"page__taxonomy-item","children":["#","Automatic Speech Translation"]}],["$","span","BLEU Metric",{"className":"page__taxonomy-item","children":["#","BLEU Metric"]}]]}]]}]]}],["$","article","2025-9-24-Zero-Shot_Multi-Spectral_Learning_Reimagining_a_Generalist_Multimodal_Gemini_2.5_Model_for_Remote_Sensing_Applications",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-24-Zero-Shot_Multi-Spectral_Learning_Reimagining_a_Generalist_Multimodal_Gemini_2.5_Model_for_Remote_Sensing_Applications/","children":"[논문리뷰] Zero-Shot Multi-Spectral Learning: Reimagining a Generalist Multimodal Gemini 2.5 Model for Remote Sensing Applications"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Genady Beryozkin이 [arXiv]에 게시한 'Zero-Shot Multi-Spectral Learning: Reimagining a Generalist Multimodal Gemini 2.5 Model for Remote Sensing Applications' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-24 13:14:19+0900","children":"2025년 9월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Remote Sensing",{"className":"page__taxonomy-item","children":["#","Remote Sensing"]}],["$","span","Zero-Shot Learning",{"className":"page__taxonomy-item","children":["#","Zero-Shot Learning"]}],["$","span","Multimodal Models",{"className":"page__taxonomy-item","children":["#","Multimodal Models"]}],["$","span","Multi-spectral Imagery",{"className":"page__taxonomy-item","children":["#","Multi-spectral Imagery"]}],["$","span","Gemini 2.5",{"className":"page__taxonomy-item","children":["#","Gemini 2.5"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","Land Cover Classification",{"className":"page__taxonomy-item","children":["#","Land Cover Classification"]}],["$","span","Pseudo-Image",{"className":"page__taxonomy-item","children":["#","Pseudo-Image"]}]]}]]}]]}],["$","article","2025-9-24-What_Characterizes_Effective_Reasoning_Revisiting_Length_Review_and_Structure_of_CoT",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-24-What_Characterizes_Effective_Reasoning_Revisiting_Length_Review_and_Structure_of_CoT/","children":"[논문리뷰] What Characterizes Effective Reasoning? Revisiting Length, Review, and Structure of CoT"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Anthony Hartshorn이 [arXiv]에 게시한 'What Characterizes Effective Reasoning? Revisiting Length, Review, and Structure of CoT' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-24 13:14:19+0900","children":"2025년 9월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Reasoning Effectiveness",{"className":"page__taxonomy-item","children":["#","Reasoning Effectiveness"]}],["$","span","Large Reasoning Models",{"className":"page__taxonomy-item","children":["#","Large Reasoning Models"]}],["$","span","Failed-Step Fraction",{"className":"page__taxonomy-item","children":["#","Failed-Step Fraction"]}],["$","span","Test-time Scaling",{"className":"page__taxonomy-item","children":["#","Test-time Scaling"]}],["$","span","Reasoning Graph",{"className":"page__taxonomy-item","children":["#","Reasoning Graph"]}],["$","span","Model Evaluation",{"className":"page__taxonomy-item","children":["#","Model Evaluation"]}]]}]]}]]}],["$","article","2025-9-24-VolSplat_Rethinking_Feed-Forward_3D_Gaussian_Splatting_with_Voxel-Aligned_Prediction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-24-VolSplat_Rethinking_Feed-Forward_3D_Gaussian_Splatting_with_Voxel-Aligned_Prediction/","children":"[논문리뷰] VolSplat: Rethinking Feed-Forward 3D Gaussian Splatting with Voxel-Aligned Prediction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Haoxiao Wang이 [arXiv]에 게시한 'VolSplat: Rethinking Feed-Forward 3D Gaussian Splatting with Voxel-Aligned Prediction' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-24 13:14:19+0900","children":"2025년 9월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","3D Gaussian Splatting"]}],["$","span","Novel View Synthesis",{"className":"page__taxonomy-item","children":["#","Novel View Synthesis"]}],["$","span","Voxel-Aligned Prediction",{"className":"page__taxonomy-item","children":["#","Voxel-Aligned Prediction"]}],["$","span","Feed-Forward Reconstruction",{"className":"page__taxonomy-item","children":["#","Feed-Forward Reconstruction"]}],["$","span","Multi-View Consistency",{"className":"page__taxonomy-item","children":["#","Multi-View Consistency"]}],["$","span","Scene Representation",{"className":"page__taxonomy-item","children":["#","Scene Representation"]}],["$","span","Computer Vision",{"className":"page__taxonomy-item","children":["#","Computer Vision"]}]]}]]}]]}],["$","article","2025-9-24-VIR-Bench_Evaluating_Geospatial_and_Temporal_Understanding_of_MLLMs_via_Travel_Video_Itinerary_Reconstruction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-24-VIR-Bench_Evaluating_Geospatial_and_Temporal_Understanding_of_MLLMs_via_Travel_Video_Itinerary_Reconstruction/","children":"[논문리뷰] VIR-Bench: Evaluating Geospatial and Temporal Understanding of MLLMs via Travel Video Itinerary Reconstruction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"So Fukuda이 [arXiv]에 게시한 'VIR-Bench: Evaluating Geospatial and Temporal Understanding of MLLMs via Travel Video Itinerary Reconstruction' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-24 13:14:19+0900","children":"2025년 9월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Video Understanding",{"className":"page__taxonomy-item","children":["#","Video Understanding"]}],["$","span","Geospatial Reasoning",{"className":"page__taxonomy-item","children":["#","Geospatial Reasoning"]}],["$","span","Temporal Reasoning",{"className":"page__taxonomy-item","children":["#","Temporal Reasoning"]}],["$","span","Travel Itinerary Reconstruction",{"className":"page__taxonomy-item","children":["#","Travel Itinerary Reconstruction"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Agent System",{"className":"page__taxonomy-item","children":["#","Agent System"]}],["$","span","VLOG",{"className":"page__taxonomy-item","children":["#","VLOG"]}]]}]]}]]}],["$","article","2025-9-24-Reinforcement_Learning_on_Pre-Training_Data",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-24-Reinforcement_Learning_on_Pre-Training_Data/","children":"[논문리뷰] Reinforcement Learning on Pre-Training Data"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Evander Yang이 [arXiv]에 게시한 'Reinforcement Learning on Pre-Training Data' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-24 13:14:19+0900","children":"2025년 9월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Pre-training",{"className":"page__taxonomy-item","children":["#","Pre-training"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Self-supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-supervised Learning"]}],["$","span","Scaling Laws",{"className":"page__taxonomy-item","children":["#","Scaling Laws"]}],["$","span","Next-segment Reasoning",{"className":"page__taxonomy-item","children":["#","Next-segment Reasoning"]}],["$","span","Reward Modeling",{"className":"page__taxonomy-item","children":["#","Reward Modeling"]}]]}]]}]]}],["$","article","2025-9-24-OpenGVL_-_Benchmarking_Visual_Temporal_Progress_for_Data_Curation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-24-OpenGVL_-_Benchmarking_Visual_Temporal_Progress_for_Data_Curation/","children":"[논문리뷰] OpenGVL - Benchmarking Visual Temporal Progress for Data Curation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Viktor Petrenko이 [arXiv]에 게시한 'OpenGVL - Benchmarking Visual Temporal Progress for Data Curation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-24 13:14:19+0900","children":"2025년 9월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Robotics Data Curation",{"className":"page__taxonomy-item","children":["#","Robotics Data Curation"]}],["$","span","Visual Temporal Progress",{"className":"page__taxonomy-item","children":["#","Visual Temporal Progress"]}],["$","span","Generative Value Learning (GVL)",{"className":"page__taxonomy-item","children":["#","Generative Value Learning (GVL)"]}],["$","span","Vision-Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision-Language Models (VLMs)"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Task Progress Prediction",{"className":"page__taxonomy-item","children":["#","Task Progress Prediction"]}],["$","span","Value-Order Correlation (VOC)",{"className":"page__taxonomy-item","children":["#","Value-Order Correlation (VOC)"]}]]}]]}]]}],["$","article","2025-9-24-MiniCPM-V_4.5_Cooking_Efficient_MLLMs_via_Architecture_Data_and_Training_Recipe",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-24-MiniCPM-V_4.5_Cooking_Efficient_MLLMs_via_Architecture_Data_and_Training_Recipe/","children":"[논문리뷰] MiniCPM-V 4.5: Cooking Efficient MLLMs via Architecture, Data, and Training Recipe"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wenshuo Ma이 [arXiv]에 게시한 'MiniCPM-V 4.5: Cooking Efficient MLLMs via Architecture, Data, and Training Recipe' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-24 13:14:19+0900","children":"2025년 9월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","MLLM Efficiency",{"className":"page__taxonomy-item","children":["#","MLLM Efficiency"]}],["$","span","Multimodal Transformer",{"className":"page__taxonomy-item","children":["#","Multimodal Transformer"]}],["$","span","3D-Resampler",{"className":"page__taxonomy-item","children":["#","3D-Resampler"]}],["$","span","Document AI",{"className":"page__taxonomy-item","children":["#","Document AI"]}],["$","span","Hybrid Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Hybrid Reinforcement Learning"]}],["$","span","Video Understanding",{"className":"page__taxonomy-item","children":["#","Video Understanding"]}],["$","span","Efficient Inference",{"className":"page__taxonomy-item","children":["#","Efficient Inference"]}]]}]]}]]}],["$","article","2025-9-24-MAPO_Mixed_Advantage_Policy_Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-24-MAPO_Mixed_Advantage_Policy_Optimization/","children":"[논문리뷰] MAPO: Mixed Advantage Policy Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xuankun Rong이 [arXiv]에 게시한 'MAPO: Mixed Advantage Policy Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-24 13:14:19+0900","children":"2025년 9월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Advantage Function",{"className":"page__taxonomy-item","children":["#","Advantage Function"]}],["$","span","Trajectory Certainty",{"className":"page__taxonomy-item","children":["#","Trajectory Certainty"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","span","GRPO",{"className":"page__taxonomy-item","children":["#","GRPO"]}]]}]]}]]}],["$","article","2025-9-24-Lyra_Generative_3D_Scene_Reconstruction_via_Video_Diffusion_Model_Self-Distillation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-24-Lyra_Generative_3D_Scene_Reconstruction_via_Video_Diffusion_Model_Self-Distillation/","children":"[논문리뷰] Lyra: Generative 3D Scene Reconstruction via Video Diffusion Model Self-Distillation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yifeng Jiang이 [arXiv]에 게시한 'Lyra: Generative 3D Scene Reconstruction via Video Diffusion Model Self-Distillation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-24 13:14:19+0900","children":"2025년 9월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","3D Scene Reconstruction",{"className":"page__taxonomy-item","children":["#","3D Scene Reconstruction"]}],["$","span","Video Diffusion Models",{"className":"page__taxonomy-item","children":["#","Video Diffusion Models"]}],["$","span","Self-Distillation",{"className":"page__taxonomy-item","children":["#","Self-Distillation"]}],["$","span","3D Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","3D Gaussian Splatting"]}],["$","span","Dynamic 4D Generation",{"className":"page__taxonomy-item","children":["#","Dynamic 4D Generation"]}],["$","span","Monocular Input",{"className":"page__taxonomy-item","children":["#","Monocular Input"]}]]}]]}]]}],["$","article","2025-9-24-Large_Language_Models_Discriminate_Against_Speakers_of_German_Dialects",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-24-Large_Language_Models_Discriminate_Against_Speakers_of_German_Dialects/","children":"[논문리뷰] Large Language Models Discriminate Against Speakers of German Dialects"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Katharina von der Wense이 [arXiv]에 게시한 'Large Language Models Discriminate Against Speakers of German Dialects' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-24 13:14:19+0900","children":"2025년 9월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Bias",{"className":"page__taxonomy-item","children":["#","Bias"]}],["$","span","German Dialects",{"className":"page__taxonomy-item","children":["#","German Dialects"]}],["$","span","Sociolinguistics",{"className":"page__taxonomy-item","children":["#","Sociolinguistics"]}],["$","span","Stereotypes",{"className":"page__taxonomy-item","children":["#","Stereotypes"]}],["$","span","Implicit Association Test",{"className":"page__taxonomy-item","children":["#","Implicit Association Test"]}],["$","span","Decision Making",{"className":"page__taxonomy-item","children":["#","Decision Making"]}]]}]]}]]}],["$","article","2025-9-24-HyRF_Hybrid_Radiance_Fields_for_Memory-efficient_and_High-quality_Novel_View_Synthesis",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-24-HyRF_Hybrid_Radiance_Fields_for_Memory-efficient_and_High-quality_Novel_View_Synthesis/","children":"[논문리뷰] HyRF: Hybrid Radiance Fields for Memory-efficient and High-quality Novel View Synthesis"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Dan Xu이 [arXiv]에 게시한 'HyRF: Hybrid Radiance Fields for Memory-efficient and High-quality Novel View Synthesis' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-24 13:14:19+0900","children":"2025년 9월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Novel View Synthesis",{"className":"page__taxonomy-item","children":["#","Novel View Synthesis"]}],["$","span","3D Gaussian Splatting (3DGS)",{"className":"page__taxonomy-item","children":["#","3D Gaussian Splatting (3DGS)"]}],["$","span","Neural Radiance Fields (NeRF)",{"className":"page__taxonomy-item","children":["#","Neural Radiance Fields (NeRF)"]}],["$","span","Memory Efficiency",{"className":"page__taxonomy-item","children":["#","Memory Efficiency"]}],["$","span","High-Quality Rendering",{"className":"page__taxonomy-item","children":["#","High-Quality Rendering"]}],["$","span","Hybrid Representation",{"className":"page__taxonomy-item","children":["#","Hybrid Representation"]}],["$","span","Real-time Rendering",{"className":"page__taxonomy-item","children":["#","Real-time Rendering"]}]]}]]}]]}],["$","article","2025-9-24-Hyper-Bagel_A_Unified_Acceleration_Framework_for_Multimodal_Understanding_and_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-24-Hyper-Bagel_A_Unified_Acceleration_Framework_for_Multimodal_Understanding_and_Generation/","children":"[논문리뷰] Hyper-Bagel: A Unified Acceleration Framework for Multimodal Understanding and Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jianbin Zheng이 [arXiv]에 게시한 'Hyper-Bagel: A Unified Acceleration Framework for Multimodal Understanding and Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-24 13:14:19+0900","children":"2025년 9월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Acceleration Framework",{"className":"page__taxonomy-item","children":["#","Acceleration Framework"]}],["$","span","Speculative Decoding",{"className":"page__taxonomy-item","children":["#","Speculative Decoding"]}],["$","span","Diffusion Distillation",{"className":"page__taxonomy-item","children":["#","Diffusion Distillation"]}],["$","span","Unified Models",{"className":"page__taxonomy-item","children":["#","Unified Models"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}]]}]]}]]}],["$","article","2025-9-24-GeoSVR_Taming_Sparse_Voxels_for_Geometrically_Accurate_Surface_Reconstruction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-24-GeoSVR_Taming_Sparse_Voxels_for_Geometrically_Accurate_Surface_Reconstruction/","children":"[논문리뷰] GeoSVR: Taming Sparse Voxels for Geometrically Accurate Surface Reconstruction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jin Zheng이 [arXiv]에 게시한 'GeoSVR: Taming Sparse Voxels for Geometrically Accurate Surface Reconstruction' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-24 13:14:19+0900","children":"2025년 9월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Surface Reconstruction",{"className":"page__taxonomy-item","children":["#","Surface Reconstruction"]}],["$","span","Sparse Voxels",{"className":"page__taxonomy-item","children":["#","Sparse Voxels"]}],["$","span","Geometric Accuracy",{"className":"page__taxonomy-item","children":["#","Geometric Accuracy"]}],["$","span","Neural Radiance Fields",{"className":"page__taxonomy-item","children":["#","Neural Radiance Fields"]}],["$","span","3D Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","3D Gaussian Splatting"]}],["$","span","Monocular Depth",{"className":"page__taxonomy-item","children":["#","Monocular Depth"]}],["$","span","Voxel Uncertainty",{"className":"page__taxonomy-item","children":["#","Voxel Uncertainty"]}]]}]]}]]}],["$","article","2025-9-24-Do_You_Need_Proprioceptive_States_in_Visuomotor_Policies",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-24-Do_You_Need_Proprioceptive_States_in_Visuomotor_Policies/","children":"[논문리뷰] Do You Need Proprioceptive States in Visuomotor Policies?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yushen Liang이 [arXiv]에 게시한 'Do You Need Proprioceptive States in Visuomotor Policies?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-24 13:14:19+0900","children":"2025년 9월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Visuomotor Policies",{"className":"page__taxonomy-item","children":["#","Visuomotor Policies"]}],["$","span","Spatial Generalization",{"className":"page__taxonomy-item","children":["#","Spatial Generalization"]}],["$","span","Imitation Learning",{"className":"page__taxonomy-item","children":["#","Imitation Learning"]}],["$","span","Proprioception",{"className":"page__taxonomy-item","children":["#","Proprioception"]}],["$","span","State-free Policies",{"className":"page__taxonomy-item","children":["#","State-free Policies"]}],["$","span","Robot Manipulation",{"className":"page__taxonomy-item","children":["#","Robot Manipulation"]}],["$","span","End-Effector Control",{"className":"page__taxonomy-item","children":["#","End-Effector Control"]}],["$","span","Data Efficiency",{"className":"page__taxonomy-item","children":["#","Data Efficiency"]}]]}]]}]]}],["$","article","2025-9-24-CAR-Flow_Condition-Aware_Reparameterization_Aligns_Source_and_Target_for_Better_Flow_Matching",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-24-CAR-Flow_Condition-Aware_Reparameterization_Aligns_Source_and_Target_for_Better_Flow_Matching/","children":"[논문리뷰] CAR-Flow: Condition-Aware Reparameterization Aligns Source and Target for Better Flow Matching"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Rui Qian이 [arXiv]에 게시한 'CAR-Flow: Condition-Aware Reparameterization Aligns Source and Target for Better Flow Matching' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-24 13:14:19+0900","children":"2025년 9월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Conditional Generative Models",{"className":"page__taxonomy-item","children":["#","Conditional Generative Models"]}],["$","span","Reparameterization",{"className":"page__taxonomy-item","children":["#","Reparameterization"]}],["$","span","Mode Collapse",{"className":"page__taxonomy-item","children":["#","Mode Collapse"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Latent Space Alignment",{"className":"page__taxonomy-item","children":["#","Latent Space Alignment"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}]]}]]}]]}],["$","article","2025-9-24-Baseer_A_Vision-Language_Model_for_Arabic_Document-to-Markdown_OCR",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-24-Baseer_A_Vision-Language_Model_for_Arabic_Document-to-Markdown_OCR/","children":"[논문리뷰] Baseer: A Vision-Language Model for Arabic Document-to-Markdown OCR"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zeina Aldallal이 [arXiv]에 게시한 'Baseer: A Vision-Language Model for Arabic Document-to-Markdown OCR' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-24 13:14:19+0900","children":"2025년 9월 24일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Arabic OCR",{"className":"page__taxonomy-item","children":["#","Arabic OCR"]}],["$","span","Vision-Language Model",{"className":"page__taxonomy-item","children":["#","Vision-Language Model"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Document Understanding",{"className":"page__taxonomy-item","children":["#","Document Understanding"]}],["$","span","Markdown Conversion",{"className":"page__taxonomy-item","children":["#","Markdown Conversion"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}]]}]]}]]}],["$","article","2025-9-23-When_Big_Models_Train_Small_Ones_Label-Free_Model_Parity_Alignment_for_Efficient_Visual_Question_Answering_using_Small_VLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-When_Big_Models_Train_Small_Ones_Label-Free_Model_Parity_Alignment_for_Efficient_Visual_Question_Answering_using_Small_VLMs/","children":"[논문리뷰] When Big Models Train Small Ones: Label-Free Model Parity Alignment for Efficient Visual Question Answering using Small VLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Anand Mishra이 [arXiv]에 게시한 'When Big Models Train Small Ones: Label-Free Model Parity Alignment for Efficient Visual Question Answering using Small VLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","VQA",{"className":"page__taxonomy-item","children":["#","VQA"]}],["$","span","Small VLMs",{"className":"page__taxonomy-item","children":["#","Small VLMs"]}],["$","span","Large VLMs",{"className":"page__taxonomy-item","children":["#","Large VLMs"]}],["$","span","Knowledge Transfer",{"className":"page__taxonomy-item","children":["#","Knowledge Transfer"]}],["$","span","Pseudo-labeling",{"className":"page__taxonomy-item","children":["#","Pseudo-labeling"]}],["$","span","Label-Free Learning",{"className":"page__taxonomy-item","children":["#","Label-Free Learning"]}],["$","span","Model Parity Alignment",{"className":"page__taxonomy-item","children":["#","Model Parity Alignment"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}]]}]]}]]}],["$","article","2025-9-23-VideoFrom3D_3D_Scene_Video_Generation_via_Complementary_Image_and_Video_Diffusion_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-VideoFrom3D_3D_Scene_Video_Generation_via_Complementary_Image_and_Video_Diffusion_Models/","children":"[논문리뷰] VideoFrom3D: 3D Scene Video Generation via Complementary Image and Video Diffusion Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Sunghyun Cho이 [arXiv]에 게시한 'VideoFrom3D: 3D Scene Video Generation via Complementary Image and Video Diffusion Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Scene Generation",{"className":"page__taxonomy-item","children":["#","3D Scene Generation"]}],["$","span","Video Diffusion",{"className":"page__taxonomy-item","children":["#","Video Diffusion"]}],["$","span","Image Diffusion",{"className":"page__taxonomy-item","children":["#","Image Diffusion"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Computer Graphics",{"className":"page__taxonomy-item","children":["#","Computer Graphics"]}],["$","span","Temporal Consistency",{"className":"page__taxonomy-item","children":["#","Temporal Consistency"]}],["$","span","Sparse Anchor Views",{"className":"page__taxonomy-item","children":["#","Sparse Anchor Views"]}]]}]]}]]}],["$","article","2025-9-23-VaseVQA_Multimodal_Agent_and_Benchmark_for_Ancient_Greek_Pottery",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-VaseVQA_Multimodal_Agent_and_Benchmark_for_Ancient_Greek_Pottery/","children":"[논문리뷰] VaseVQA: Multimodal Agent and Benchmark for Ancient Greek Pottery"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shiya Huang이 [arXiv]에 게시한 'VaseVQA: Multimodal Agent and Benchmark for Ancient Greek Pottery' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models"]}],["$","span","Visual Question Answering",{"className":"page__taxonomy-item","children":["#","Visual Question Answering"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Cultural Heritage",{"className":"page__taxonomy-item","children":["#","Cultural Heritage"]}],["$","span","Ancient Greek Pottery",{"className":"page__taxonomy-item","children":["#","Ancient Greek Pottery"]}],["$","span","Supervised Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}]]}]]}]]}],["$","article","2025-9-23-Understanding_Embedding_Scaling_in_Collaborative_Filtering",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-Understanding_Embedding_Scaling_in_Collaborative_Filtering/","children":"[논문리뷰] Understanding Embedding Scaling in Collaborative Filtering"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yonghui Yang이 [arXiv]에 게시한 'Understanding Embedding Scaling in Collaborative Filtering' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Collaborative Filtering",{"className":"page__taxonomy-item","children":["#","Collaborative Filtering"]}],["$","span","Embedding Scaling",{"className":"page__taxonomy-item","children":["#","Embedding Scaling"]}],["$","span","Noise Robustness",{"className":"page__taxonomy-item","children":["#","Noise Robustness"]}],["$","span","Recommender Systems",{"className":"page__taxonomy-item","children":["#","Recommender Systems"]}],["$","span","Graph Neural Networks",{"className":"page__taxonomy-item","children":["#","Graph Neural Networks"]}],["$","span","Self-supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-supervised Learning"]}],["$","span","Performance Degradation",{"className":"page__taxonomy-item","children":["#","Performance Degradation"]}]]}]]}]]}],["$","article","2025-9-23-Turk-LettuceDetect_A_Hallucination_Detection_Models_for_Turkish_RAG_Applications",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-Turk-LettuceDetect_A_Hallucination_Detection_Models_for_Turkish_RAG_Applications/","children":"[논문리뷰] Turk-LettuceDetect: A Hallucination Detection Models for Turkish RAG Applications"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Fatma Betül Terzioğlu이 [arXiv]에 게시한 'Turk-LettuceDetect: A Hallucination Detection Models for Turkish RAG Applications' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Hallucination Detection",{"className":"page__taxonomy-item","children":["#","Hallucination Detection"]}],["$","span","Retrieval Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval Augmented Generation"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Turkish NLP",{"className":"page__taxonomy-item","children":["#","Turkish NLP"]}],["$","span","Token Classification",{"className":"page__taxonomy-item","children":["#","Token Classification"]}],["$","span","ModernBERT",{"className":"page__taxonomy-item","children":["#","ModernBERT"]}],["$","span","Low-Resource Languages",{"className":"page__taxonomy-item","children":["#","Low-Resource Languages"]}]]}]]}]]}],["$","article","2025-9-23-TempSamp-R1_Effective_Temporal_Sampling_with_Reinforcement_Fine-Tuning_for_Video_LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-TempSamp-R1_Effective_Temporal_Sampling_with_Reinforcement_Fine-Tuning_for_Video_LLMs/","children":"[논문리뷰] TempSamp-R1: Effective Temporal Sampling with Reinforcement Fine-Tuning for Video LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shaohui Jiao이 [arXiv]에 게시한 'TempSamp-R1: Effective Temporal Sampling with Reinforcement Fine-Tuning for Video LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video LLMs",{"className":"page__taxonomy-item","children":["#","Video LLMs"]}],["$","span","Temporal Grounding",{"className":"page__taxonomy-item","children":["#","Temporal Grounding"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Off-policy Learning",{"className":"page__taxonomy-item","children":["#","Off-policy Learning"]}],["$","span","Reward Shaping",{"className":"page__taxonomy-item","children":["#","Reward Shaping"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}]]}]]}]]}],["$","article","2025-9-23-Synthetic_bootstrapped_pretraining",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-Synthetic_bootstrapped_pretraining/","children":"[논문리뷰] Synthetic bootstrapped pretraining"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Emmanuel Candès이 [arXiv]에 게시한 'Synthetic bootstrapped pretraining' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Language Model Pretraining",{"className":"page__taxonomy-item","children":["#","Language Model Pretraining"]}],["$","span","Synthetic Data",{"className":"page__taxonomy-item","children":["#","Synthetic Data"]}],["$","span","Inter-document Correlation",{"className":"page__taxonomy-item","children":["#","Inter-document Correlation"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Bootstrapping",{"className":"page__taxonomy-item","children":["#","Bootstrapping"]}],["$","span","Concept Learning",{"className":"page__taxonomy-item","children":["#","Concept Learning"]}]]}]]}]]}],["$","article","2025-9-23-SWE-Bench_Pro_Can_AI_Agents_Solve_Long-Horizon_Software_Engineering_Tasks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-SWE-Bench_Pro_Can_AI_Agents_Solve_Long-Horizon_Software_Engineering_Tasks/","children":"[논문리뷰] SWE-Bench Pro: Can AI Agents Solve Long-Horizon Software Engineering Tasks?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yannis Yiming He이 [arXiv]에 게시한 'SWE-Bench Pro: Can AI Agents Solve Long-Horizon Software Engineering Tasks?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Agents",{"className":"page__taxonomy-item","children":["#","AI Agents"]}],["$","span","Software Engineering",{"className":"page__taxonomy-item","children":["#","Software Engineering"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Contamination Resistance",{"className":"page__taxonomy-item","children":["#","Contamination Resistance"]}],["$","span","Long-Horizon Tasks",{"className":"page__taxonomy-item","children":["#","Long-Horizon Tasks"]}],["$","span","Enterprise Software",{"className":"page__taxonomy-item","children":["#","Enterprise Software"]}]]}]]}]]}],["$","article","2025-9-23-SCAN_Self-Denoising_Monte_Carlo_Annotation_for_Robust_Process_Reward_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-SCAN_Self-Denoising_Monte_Carlo_Annotation_for_Robust_Process_Reward_Learning/","children":"[논문리뷰] SCAN: Self-Denoising Monte Carlo Annotation for Robust Process Reward Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhaopeng Tu이 [arXiv]에 게시한 'SCAN: Self-Denoising Monte Carlo Annotation for Robust Process Reward Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Process Reward Models",{"className":"page__taxonomy-item","children":["#","Process Reward Models"]}],["$","span","Monte Carlo Annotation",{"className":"page__taxonomy-item","children":["#","Monte Carlo Annotation"]}],["$","span","Noise Denoising",{"className":"page__taxonomy-item","children":["#","Noise Denoising"]}],["$","span","Robust Learning",{"className":"page__taxonomy-item","children":["#","Robust Learning"]}],["$","span","Self-Supervision",{"className":"page__taxonomy-item","children":["#","Self-Supervision"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}]]}]]}]]}],["$","article","2025-9-23-Reasoning_Core_A_Scalable_RL_Environment_for_LLM_Symbolic_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-Reasoning_Core_A_Scalable_RL_Environment_for_LLM_Symbolic_Reasoning/","children":"[논문리뷰] Reasoning Core: A Scalable RL Environment for LLM Symbolic Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Damien Sileo이 [arXiv]에 게시한 'Reasoning Core: A Scalable RL Environment for LLM Symbolic Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Reasoning",{"className":"page__taxonomy-item","children":["#","LLM Reasoning"]}],["$","span","Symbolic AI",{"className":"page__taxonomy-item","children":["#","Symbolic AI"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Procedural Content Generation",{"className":"page__taxonomy-item","children":["#","Procedural Content Generation"]}],["$","span","Verifiable Rewards",{"className":"page__taxonomy-item","children":["#","Verifiable Rewards"]}],["$","span","Adaptive Curricula",{"className":"page__taxonomy-item","children":["#","Adaptive Curricula"]}],["$","span","First-Order Logic",{"className":"page__taxonomy-item","children":["#","First-Order Logic"]}],["$","span","PDDL Planning",{"className":"page__taxonomy-item","children":["#","PDDL Planning"]}]]}]]}]]}],["$","article","2025-9-23-QWHA_Quantization-Aware_Walsh-Hadamard_Adaptation_for_Parameter-Efficient_Fine-Tuning_on_Large_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-QWHA_Quantization-Aware_Walsh-Hadamard_Adaptation_for_Parameter-Efficient_Fine-Tuning_on_Large_Language_Models/","children":"[논문리뷰] QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jae-Joon Kim이 [arXiv]에 게시한 'QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Fine-tuning",{"className":"page__taxonomy-item","children":["#","LLM Fine-tuning"]}],["$","span","Quantization-Aware PEFT",{"className":"page__taxonomy-item","children":["#","Quantization-Aware PEFT"]}],["$","span","Walsh-Hadamard Transform",{"className":"page__taxonomy-item","children":["#","Walsh-Hadamard Transform"]}],["$","span","Sparse Adaptation",{"className":"page__taxonomy-item","children":["#","Sparse Adaptation"]}],["$","span","Low-bit Quantization",{"className":"page__taxonomy-item","children":["#","Low-bit Quantization"]}],["$","span","Parameter-Efficient Learning",{"className":"page__taxonomy-item","children":["#","Parameter-Efficient Learning"]}]]}]]}]]}],["$","article","2025-9-23-Qwen3-Omni_Technical_Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-Qwen3-Omni_Technical_Report/","children":"[논문리뷰] Qwen3-Omni Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Lhma-aslp이 [arXiv]에 게시한 'Qwen3-Omni Technical Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Model",{"className":"page__taxonomy-item","children":["#","Multimodal Model"]}],["$","span","Thinker-Talker Architecture",{"className":"page__taxonomy-item","children":["#","Thinker-Talker Architecture"]}],["$","span","Mixture-of-Experts",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts"]}],["$","span","Low-latency",{"className":"page__taxonomy-item","children":["#","Low-latency"]}],["$","span","Audio Understanding",{"className":"page__taxonomy-item","children":["#","Audio Understanding"]}],["$","span","Cross-modal Reasoning",{"className":"page__taxonomy-item","children":["#","Cross-modal Reasoning"]}],["$","span","State-of-the-Art",{"className":"page__taxonomy-item","children":["#","State-of-the-Art"]}],["$","span","Real-time Interaction",{"className":"page__taxonomy-item","children":["#","Real-time Interaction"]}]]}]]}]]}],["$","article","2025-9-23-OmniInsert_Mask-Free_Video_Insertion_of_Any_Reference_via_Diffusion_Transformer_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-OmniInsert_Mask-Free_Video_Insertion_of_Any_Reference_via_Diffusion_Transformer_Models/","children":"[논문리뷰] OmniInsert: Mask-Free Video Insertion of Any Reference via Diffusion Transformer Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Pengze Zhang이 [arXiv]에 게시한 'OmniInsert: Mask-Free Video Insertion of Any Reference via Diffusion Transformer Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Insertion",{"className":"page__taxonomy-item","children":["#","Video Insertion"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Diffusion Transformers",{"className":"page__taxonomy-item","children":["#","Diffusion Transformers"]}],["$","span","Mask-Free",{"className":"page__taxonomy-item","children":["#","Mask-Free"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}],["$","span","Progressive Training",{"className":"page__taxonomy-item","children":["#","Progressive Training"]}],["$","span","Preference Optimization",{"className":"page__taxonomy-item","children":["#","Preference Optimization"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}]]}]]}]]}],["$","article","2025-9-23-MetaEmbed_Scaling_Multimodal_Retrieval_at_Test-Time_with_Flexible_Late_Interaction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-MetaEmbed_Scaling_Multimodal_Retrieval_at_Test-Time_with_Flexible_Late_Interaction/","children":"[논문리뷰] MetaEmbed: Scaling Multimodal Retrieval at Test-Time with Flexible Late Interaction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xintao Chen이 [arXiv]에 게시한 'MetaEmbed: Scaling Multimodal Retrieval at Test-Time with Flexible Late Interaction' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Retrieval",{"className":"page__taxonomy-item","children":["#","Multimodal Retrieval"]}],["$","span","Late Interaction",{"className":"page__taxonomy-item","children":["#","Late Interaction"]}],["$","span","Meta Tokens",{"className":"page__taxonomy-item","children":["#","Meta Tokens"]}],["$","span","Matryoshka Representation Learning",{"className":"page__taxonomy-item","children":["#","Matryoshka Representation Learning"]}],["$","span","Test-Time Scaling",{"className":"page__taxonomy-item","children":["#","Test-Time Scaling"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Dense Retrieval",{"className":"page__taxonomy-item","children":["#","Dense Retrieval"]}],["$","span","Efficiency",{"className":"page__taxonomy-item","children":["#","Efficiency"]}]]}]]}]]}],["$","article","2025-9-23-Mano_Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-Mano_Report/","children":"[논문리뷰] Mano Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Minghui Wu이 [arXiv]에 게시한 'Mano Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","GUI Agent",{"className":"page__taxonomy-item","children":["#","GUI Agent"]}],["$","span","Multi-modal Foundation Model",{"className":"page__taxonomy-item","children":["#","Multi-modal Foundation Model"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Simulated Environment",{"className":"page__taxonomy-item","children":["#","Simulated Environment"]}],["$","span","Data Generation",{"className":"page__taxonomy-item","children":["#","Data Generation"]}],["$","span","Error Recovery",{"className":"page__taxonomy-item","children":["#","Error Recovery"]}],["$","span","Web Automation",{"className":"page__taxonomy-item","children":["#","Web Automation"]}]]}]]}]]}],["$","article","2025-9-23-LIMI_Less_is_More_for_Agency",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-LIMI_Less_is_More_for_Agency/","children":"[논문리뷰] LIMI: Less is More for Agency"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"happyZYM이 [arXiv]에 게시한 'LIMI: Less is More for Agency' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Agency",{"className":"page__taxonomy-item","children":["#","AI Agency"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Less Is More",{"className":"page__taxonomy-item","children":["#","Less Is More"]}],["$","span","Agentic Intelligence",{"className":"page__taxonomy-item","children":["#","Agentic Intelligence"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Evaluation Benchmark",{"className":"page__taxonomy-item","children":["#","Evaluation Benchmark"]}],["$","span","Efficiency Principle",{"className":"page__taxonomy-item","children":["#","Efficiency Principle"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}]]}]]}]]}],["$","article","2025-9-23-GeoPQA_Bridging_the_Visual_Perception_Gap_in_MLLMs_for_Geometric_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-GeoPQA_Bridging_the_Visual_Perception_Gap_in_MLLMs_for_Geometric_Reasoning/","children":"[논문리뷰] GeoPQA: Bridging the Visual Perception Gap in MLLMs for Geometric Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hou Pong Chan이 [arXiv]에 게시한 'GeoPQA: Bridging the Visual Perception Gap in MLLMs for Geometric Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models (MLLMs)"]}],["$","span","Geometric Reasoning",{"className":"page__taxonomy-item","children":["#","Geometric Reasoning"]}],["$","span","Visual Perception",{"className":"page__taxonomy-item","children":["#","Visual Perception"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Two-stage Training",{"className":"page__taxonomy-item","children":["#","Two-stage Training"]}],["$","span","GeoPQA Benchmark",{"className":"page__taxonomy-item","children":["#","GeoPQA Benchmark"]}],["$","span","Perceptual Bottleneck",{"className":"page__taxonomy-item","children":["#","Perceptual Bottleneck"]}]]}]]}]]}],["$","article","2025-9-23-From_Uniform_to_Heterogeneous_Tailoring_Policy_Optimization_to_Every_Tokens_Nature",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-From_Uniform_to_Heterogeneous_Tailoring_Policy_Optimization_to_Every_Tokens_Nature/","children":"[논문리뷰] From Uniform to Heterogeneous: Tailoring Policy Optimization to Every Token's Nature"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Bin Cui이 [arXiv]에 게시한 'From Uniform to Heterogeneous: Tailoring Policy Optimization to Every Token's Nature' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Token Heterogeneity",{"className":"page__taxonomy-item","children":["#","Token Heterogeneity"]}],["$","span","Adaptive Sampling",{"className":"page__taxonomy-item","children":["#","Adaptive Sampling"]}],["$","span","Advantage Redistribution",{"className":"page__taxonomy-item","children":["#","Advantage Redistribution"]}],["$","span","Asymmetric Clipping",{"className":"page__taxonomy-item","children":["#","Asymmetric Clipping"]}],["$","span","Entropy-based RL",{"className":"page__taxonomy-item","children":["#","Entropy-based RL"]}]]}]]}]]}],["$","article","2025-9-23-From_Hugging_Face_to_GitHub_Tracing_License_Drift_in_the_Open-Source_AI_Ecosystem",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-From_Hugging_Face_to_GitHub_Tracing_License_Drift_in_the_Open-Source_AI_Ecosystem/","children":"[논문리뷰] From Hugging Face to GitHub: Tracing License Drift in the Open-Source AI Ecosystem"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ahmed E. Hassan이 [arXiv]에 게시한 'From Hugging Face to GitHub: Tracing License Drift in the Open-Source AI Ecosystem' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Open-Source AI",{"className":"page__taxonomy-item","children":["#","Open-Source AI"]}],["$","span","License Compliance",{"className":"page__taxonomy-item","children":["#","License Compliance"]}],["$","span","License Drift",{"className":"page__taxonomy-item","children":["#","License Drift"]}],["$","span","AI Supply Chain",{"className":"page__taxonomy-item","children":["#","AI Supply Chain"]}],["$","span","Hugging Face",{"className":"page__taxonomy-item","children":["#","Hugging Face"]}],["$","span","GitHub",{"className":"page__taxonomy-item","children":["#","GitHub"]}],["$","span","LicenseRec",{"className":"page__taxonomy-item","children":["#","LicenseRec"]}],["$","span","Legal Risk",{"className":"page__taxonomy-item","children":["#","Legal Risk"]}]]}]]}]]}],["$","article","2025-9-23-FlagEval_Findings_Report_A_Preliminary_Evaluation_of_Large_Reasoning_Models_on_Automatically_Verifiable_Textual_and_Visual_Questions",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-FlagEval_Findings_Report_A_Preliminary_Evaluation_of_Large_Reasoning_Models_on_Automatically_Verifiable_Textual_and_Visual_Questions/","children":"[논문리뷰] FlagEval Findings Report: A Preliminary Evaluation of Large Reasoning Models on Automatically Verifiable Textual and Visual Questions"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"tengdai722이 [arXiv]에 게시한 'FlagEval Findings Report: A Preliminary Evaluation of Large Reasoning Models on Automatically Verifiable Textual and Visual Questions' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Reasoning Models",{"className":"page__taxonomy-item","children":["#","Large Reasoning Models"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Reasoning Behaviors",{"className":"page__taxonomy-item","children":["#","Reasoning Behaviors"]}],["$","span","Hallucination",{"className":"page__taxonomy-item","children":["#","Hallucination"]}],["$","span","Contamination-Free",{"className":"page__taxonomy-item","children":["#","Contamination-Free"]}],["$","span","AI Safety",{"className":"page__taxonomy-item","children":["#","AI Safety"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}]]}]]}]]}],["$","article","2025-9-23-EpiCache_Episodic_KV_Cache_Management_for_Long_Conversational_Question_Answering",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-EpiCache_Episodic_KV_Cache_Management_for_Long_Conversational_Question_Answering/","children":"[논문리뷰] EpiCache: Episodic KV Cache Management for Long Conversational Question Answering"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Minsik Cho이 [arXiv]에 게시한 'EpiCache: Episodic KV Cache Management for Long Conversational Question Answering' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","KV Cache Management",{"className":"page__taxonomy-item","children":["#","KV Cache Management"]}],["$","span","Long Conversational QA",{"className":"page__taxonomy-item","children":["#","Long Conversational QA"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Memory Efficiency",{"className":"page__taxonomy-item","children":["#","Memory Efficiency"]}],["$","span","Episodic Clustering",{"className":"page__taxonomy-item","children":["#","Episodic Clustering"]}],["$","span","Block Prefill Eviction",{"className":"page__taxonomy-item","children":["#","Block Prefill Eviction"]}],["$","span","Sensitivity-aware Allocation",{"className":"page__taxonomy-item","children":["#","Sensitivity-aware Allocation"]}]]}]]}]]}],["$","article","2025-9-23-DIWALI_-_Diversity_and_Inclusivity_aWare_cuLture_specific_Items_for_India_Dataset_and_Assessment_of_LLMs_for_Cultural_Text_Adaptation_in_Indian_Context",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-DIWALI_-_Diversity_and_Inclusivity_aWare_cuLture_specific_Items_for_India_Dataset_and_Assessment_of_LLMs_for_Cultural_Text_Adaptation_in_Indian_Context/","children":"[논문리뷰] DIWALI - Diversity and Inclusivity aWare cuLture specific Items for India: Dataset and Assessment of LLMs for Cultural Text Adaptation in Indian Context"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Maunendra Sankar Desarkar이 [arXiv]에 게시한 'DIWALI - Diversity and Inclusivity aWare cuLture specific Items for India: Dataset and Assessment of LLMs for Cultural Text Adaptation in Indian Context' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Cultural Adaptation",{"className":"page__taxonomy-item","children":["#","Cultural Adaptation"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Indian Culture",{"className":"page__taxonomy-item","children":["#","Indian Culture"]}],["$","span","Dataset Creation",{"className":"page__taxonomy-item","children":["#","Dataset Creation"]}],["$","span","CSI",{"className":"page__taxonomy-item","children":["#","CSI"]}],["$","span","Human Evaluation",{"className":"page__taxonomy-item","children":["#","Human Evaluation"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Cultural Bias",{"className":"page__taxonomy-item","children":["#","Cultural Bias"]}]]}]]}]]}],["$","article","2025-9-23-DiffusionNFT_Online_Diffusion_Reinforcement_with_Forward_Process",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-DiffusionNFT_Online_Diffusion_Reinforcement_with_Forward_Process/","children":"[논문리뷰] DiffusionNFT: Online Diffusion Reinforcement with Forward Process"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Qinsheng Zhang이 [arXiv]에 게시한 'DiffusionNFT: Online Diffusion Reinforcement with Forward Process' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Online RL",{"className":"page__taxonomy-item","children":["#","Online RL"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Forward Process",{"className":"page__taxonomy-item","children":["#","Forward Process"]}],["$","span","CFG-free",{"className":"page__taxonomy-item","children":["#","CFG-free"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Negative-Aware FineTuning",{"className":"page__taxonomy-item","children":["#","Negative-Aware FineTuning"]}]]}]]}]]}],["$","article","2025-9-23-Cross-Attention_is_Half_Explanation_in_Speech-to-Text_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-Cross-Attention_is_Half_Explanation_in_Speech-to-Text_Models/","children":"[논문리뷰] Cross-Attention is Half Explanation in Speech-to-Text Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Luisa Bentivogli이 [arXiv]에 게시한 'Cross-Attention is Half Explanation in Speech-to-Text Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Cross-attention",{"className":"page__taxonomy-item","children":["#","Cross-attention"]}],["$","span","Speech-to-Text (S2T)",{"className":"page__taxonomy-item","children":["#","Speech-to-Text (S2T)"]}],["$","span","Explainable AI (XAI)",{"className":"page__taxonomy-item","children":["#","Explainable AI (XAI)"]}],["$","span","Saliency Maps",{"className":"page__taxonomy-item","children":["#","Saliency Maps"]}],["$","span","Feature Attribution",{"className":"page__taxonomy-item","children":["#","Feature Attribution"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Context Mixing",{"className":"page__taxonomy-item","children":["#","Context Mixing"]}],["$","span","Correlation",{"className":"page__taxonomy-item","children":["#","Correlation"]}]]}]]}]]}],["$","article","2025-9-23-ContextFlow_Training-Free_Video_Object_Editing_via_Adaptive_Context_Enrichment",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-ContextFlow_Training-Free_Video_Object_Editing_via_Adaptive_Context_Enrichment/","children":"[논문리뷰] ContextFlow: Training-Free Video Object Editing via Adaptive Context Enrichment"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yue Ma이 [arXiv]에 게시한 'ContextFlow: Training-Free Video Object Editing via Adaptive Context Enrichment' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Object Editing",{"className":"page__taxonomy-item","children":["#","Video Object Editing"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}],["$","span","Diffusion Transformers",{"className":"page__taxonomy-item","children":["#","Diffusion Transformers"]}],["$","span","Rectified Flow",{"className":"page__taxonomy-item","children":["#","Rectified Flow"]}],["$","span","Adaptive Context Enrichment",{"className":"page__taxonomy-item","children":["#","Adaptive Context Enrichment"]}],["$","span","Guidance Responsiveness",{"className":"page__taxonomy-item","children":["#","Guidance Responsiveness"]}],["$","span","Temporal Consistency",{"className":"page__taxonomy-item","children":["#","Temporal Consistency"]}],["$","span","Image-to-Video",{"className":"page__taxonomy-item","children":["#","Image-to-Video"]}]]}]]}]]}],["$","article","2025-9-23-CodeFuse-CR-Bench_A_Comprehensiveness-aware_Benchmark_for_End-to-End_Code_Review_Evaluation_in_Python_Projects",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-CodeFuse-CR-Bench_A_Comprehensiveness-aware_Benchmark_for_End-to-End_Code_Review_Evaluation_in_Python_Projects/","children":"[논문리뷰] CodeFuse-CR-Bench: A Comprehensiveness-aware Benchmark for End-to-End Code Review Evaluation in Python Projects"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hang Yu이 [arXiv]에 게시한 'CodeFuse-CR-Bench: A Comprehensiveness-aware Benchmark for End-to-End Code Review Evaluation in Python Projects' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Code Review",{"className":"page__taxonomy-item","children":["#","Code Review"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Python Projects",{"className":"page__taxonomy-item","children":["#","Python Projects"]}],["$","span","End-to-End Evaluation",{"className":"page__taxonomy-item","children":["#","End-to-End Evaluation"]}],["$","span","Context-Awareness",{"className":"page__taxonomy-item","children":["#","Context-Awareness"]}],["$","span","Software Engineering",{"className":"page__taxonomy-item","children":["#","Software Engineering"]}],["$","span","LLM-as-a-Judge",{"className":"page__taxonomy-item","children":["#","LLM-as-a-Judge"]}]]}]]}]]}],["$","article","2025-9-23-ByteWrist_A_Parallel_Robotic_Wrist_Enabling_Flexible_and_Anthropomorphic_Motion_for_Confined_Spaces",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-ByteWrist_A_Parallel_Robotic_Wrist_Enabling_Flexible_and_Anthropomorphic_Motion_for_Confined_Spaces/","children":"[논문리뷰] ByteWrist: A Parallel Robotic Wrist Enabling Flexible and Anthropomorphic Motion for Confined Spaces"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiafeng Xu이 [arXiv]에 게시한 'ByteWrist: A Parallel Robotic Wrist Enabling Flexible and Anthropomorphic Motion for Confined Spaces' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Parallel Manipulator",{"className":"page__taxonomy-item","children":["#","Parallel Manipulator"]}],["$","span","Robotic Wrist",{"className":"page__taxonomy-item","children":["#","Robotic Wrist"]}],["$","span","Confined Space Manipulation",{"className":"page__taxonomy-item","children":["#","Confined Space Manipulation"]}],["$","span","Kinematics",{"className":"page__taxonomy-item","children":["#","Kinematics"]}],["$","span","Anthropomorphic Robot",{"className":"page__taxonomy-item","children":["#","Anthropomorphic Robot"]}],["$","span","Robot Design",{"className":"page__taxonomy-item","children":["#","Robot Design"]}]]}]]}]]}],["$","article","2025-9-23-AuditoryBench_Can_Language_Models_Understand_Auditory_Knowledge_without_Hearing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-AuditoryBench_Can_Language_Models_Understand_Auditory_Knowledge_without_Hearing/","children":"[논문리뷰] AuditoryBench++: Can Language Models Understand Auditory Knowledge without Hearing?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jaeho Lee이 [arXiv]에 게시한 'AuditoryBench++: Can Language Models Understand Auditory Knowledge without Hearing?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Auditory Knowledge",{"className":"page__taxonomy-item","children":["#","Auditory Knowledge"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Auditory Imagination",{"className":"page__taxonomy-item","children":["#","Auditory Imagination"]}],["$","span","Text-only Reasoning",{"className":"page__taxonomy-item","children":["#","Text-only Reasoning"]}]]}]]}]]}],["$","article","2025-9-23-ARE_Scaling_Up_Agent_Environments_and_Evaluations",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-ARE_Scaling_Up_Agent_Environments_and_Evaluations/","children":"[논문리뷰] ARE: Scaling Up Agent Environments and Evaluations"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Matteo Bettini이 [arXiv]에 게시한 'ARE: Scaling Up Agent Environments and Evaluations' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agent Environments",{"className":"page__taxonomy-item","children":["#","Agent Environments"]}],["$","span","Agent Evaluation",{"className":"page__taxonomy-item","children":["#","Agent Evaluation"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Asynchronous Systems",{"className":"page__taxonomy-item","children":["#","Asynchronous Systems"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Multi-agent Collaboration",{"className":"page__taxonomy-item","children":["#","Multi-agent Collaboration"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}]]}]]}]]}],["$","article","2025-9-23-Analyzing_the_Effects_of_Supervised_Fine-Tuning_on_Model_Knowledge_from_Token_and_Parameter_Levels",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-23-Analyzing_the_Effects_of_Supervised_Fine-Tuning_on_Model_Knowledge_from_Token_and_Parameter_Levels/","children":"[논문리뷰] Analyzing the Effects of Supervised Fine-Tuning on Model Knowledge from Token and Parameter Levels"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Qi Zhang이 [arXiv]에 게시한 'Analyzing the Effects of Supervised Fine-Tuning on Model Knowledge from Token and Parameter Levels' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-23 13:36:03+0900","children":"2025년 9월 23일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Supervised Fine-Tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning (SFT)"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Model Knowledge",{"className":"page__taxonomy-item","children":["#","Model Knowledge"]}],["$","span","Closed-Book Question Answering (CBQA)",{"className":"page__taxonomy-item","children":["#","Closed-Book Question Answering (CBQA)"]}],["$","span","Parameter Restoration",{"className":"page__taxonomy-item","children":["#","Parameter Restoration"]}],["$","span","Kullback-Leibler Divergence",{"className":"page__taxonomy-item","children":["#","Kullback-Leibler Divergence"]}],["$","span","Knowledge Forgetting",{"className":"page__taxonomy-item","children":["#","Knowledge Forgetting"]}]]}]]}]]}],["$","article","2025-9-22-WhisTLE_Deeply_Supervised_Text-Only_Domain_Adaptation_for_Pretrained_Speech_Recognition_Transformers",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-22-WhisTLE_Deeply_Supervised_Text-Only_Domain_Adaptation_for_Pretrained_Speech_Recognition_Transformers/","children":"[논문리뷰] WhisTLE: Deeply Supervised, Text-Only Domain Adaptation for Pretrained Speech Recognition Transformers"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Karun Kumar이 [arXiv]에 게시한 'WhisTLE: Deeply Supervised, Text-Only Domain Adaptation for Pretrained Speech Recognition Transformers' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-22 13:11:29+0900","children":"2025년 9월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","ASR",{"className":"page__taxonomy-item","children":["#","ASR"]}],["$","span","Domain Adaptation",{"className":"page__taxonomy-item","children":["#","Domain Adaptation"]}],["$","span","Text-Only Training",{"className":"page__taxonomy-item","children":["#","Text-Only Training"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Variational Autoencoder",{"className":"page__taxonomy-item","children":["#","Variational Autoencoder"]}],["$","span","Deep Supervision",{"className":"page__taxonomy-item","children":["#","Deep Supervision"]}],["$","span","Whisper",{"className":"page__taxonomy-item","children":["#","Whisper"]}],["$","span","Encoder-Decoder Models",{"className":"page__taxonomy-item","children":["#","Encoder-Decoder Models"]}]]}]]}]]}],["$","article","2025-9-22-Video2Roleplay_A_Multimodal_Dataset_and_Framework_for_Video-Guided_Role-playing_Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-22-Video2Roleplay_A_Multimodal_Dataset_and_Framework_for_Video-Guided_Role-playing_Agents/","children":"[논문리뷰] Video2Roleplay: A Multimodal Dataset and Framework for Video-Guided Role-playing Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chao Zhang이 [arXiv]에 게시한 'Video2Roleplay: A Multimodal Dataset and Framework for Video-Guided Role-playing Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-22 13:11:29+0900","children":"2025년 9월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Role-playing Agents (RPAs)",{"className":"page__taxonomy-item","children":["#","Role-playing Agents (RPAs)"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Video Understanding",{"className":"page__taxonomy-item","children":["#","Video Understanding"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Dataset Creation",{"className":"page__taxonomy-item","children":["#","Dataset Creation"]}],["$","span","Dynamic Role Profiles",{"className":"page__taxonomy-item","children":["#","Dynamic Role Profiles"]}],["$","span","Adaptive Temporal Sampling",{"className":"page__taxonomy-item","children":["#","Adaptive Temporal Sampling"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}]]}]]}]]}],["$","article","2025-9-22-SPATIALGEN_Layout-guided_3D_Indoor_Scene_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-22-SPATIALGEN_Layout-guided_3D_Indoor_Scene_Generation/","children":"[논문리뷰] SPATIALGEN: Layout-guided 3D Indoor Scene Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yongsen Mao이 [arXiv]에 게시한 'SPATIALGEN: Layout-guided 3D Indoor Scene Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-22 13:11:29+0900","children":"2025년 9월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Scene Generation",{"className":"page__taxonomy-item","children":["#","3D Scene Generation"]}],["$","span","Layout Guidance",{"className":"page__taxonomy-item","children":["#","Layout Guidance"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Multi-view Synthesis",{"className":"page__taxonomy-item","children":["#","Multi-view Synthesis"]}],["$","span","Synthetic Dataset",{"className":"page__taxonomy-item","children":["#","Synthetic Dataset"]}],["$","span","Indoor Environments",{"className":"page__taxonomy-item","children":["#","Indoor Environments"]}],["$","span","Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","Gaussian Splatting"]}],["$","span","Semantic Consistency",{"className":"page__taxonomy-item","children":["#","Semantic Consistency"]}]]}]]}]]}],["$","article","2025-9-22-RPG_A_Repository_Planning_Graph_for_Unified_and_Scalable_Codebase_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-22-RPG_A_Repository_Planning_Graph_for_Unified_and_Scalable_Codebase_Generation/","children":"[논문리뷰] RPG: A Repository Planning Graph for Unified and Scalable Codebase Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Steven Liu이 [arXiv]에 게시한 'RPG: A Repository Planning Graph for Unified and Scalable Codebase Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-22 13:11:29+0900","children":"2025년 9월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Repository Planning",{"className":"page__taxonomy-item","children":["#","Repository Planning"]}],["$","span","Graph-based Representation",{"className":"page__taxonomy-item","children":["#","Graph-based Representation"]}],["$","span","Software Engineering",{"className":"page__taxonomy-item","children":["#","Software Engineering"]}],["$","span","Agent Frameworks",{"className":"page__taxonomy-item","children":["#","Agent Frameworks"]}],["$","span","Scalable Codebase",{"className":"page__taxonomy-item","children":["#","Scalable Codebase"]}]]}]]}]]}],["$","article","2025-9-22-RGB-Only_Supervised_Camera_Parameter_Optimization_in_Dynamic_Scenes",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-22-RGB-Only_Supervised_Camera_Parameter_Optimization_in_Dynamic_Scenes/","children":"[논문리뷰] RGB-Only Supervised Camera Parameter Optimization in Dynamic Scenes"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Narendra Ahuja이 [arXiv]에 게시한 'RGB-Only Supervised Camera Parameter Optimization in Dynamic Scenes' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-22 13:11:29+0900","children":"2025년 9월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Camera Parameter Optimization",{"className":"page__taxonomy-item","children":["#","Camera Parameter Optimization"]}],["$","span","Dynamic Scenes",{"className":"page__taxonomy-item","children":["#","Dynamic Scenes"]}],["$","span","RGB-Only Supervision",{"className":"page__taxonomy-item","children":["#","RGB-Only Supervision"]}],["$","span","Structure from Motion",{"className":"page__taxonomy-item","children":["#","Structure from Motion"]}],["$","span","Outlier Robustness",{"className":"page__taxonomy-item","children":["#","Outlier Robustness"]}],["$","span","3D Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","3D Gaussian Splatting"]}],["$","span","Two-stage Optimization",{"className":"page__taxonomy-item","children":["#","Two-stage Optimization"]}],["$","span","Point Tracking",{"className":"page__taxonomy-item","children":["#","Point Tracking"]}]]}]]}]]}],["$","article","2025-9-22-MANZANO_A_Simple_and_Scalable_Unified_Multimodal_Model_with_a_Hybrid_Vision_Tokenizer",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-22-MANZANO_A_Simple_and_Scalable_Unified_Multimodal_Model_with_a_Hybrid_Vision_Tokenizer/","children":"[논문리뷰] MANZANO: A Simple and Scalable Unified Multimodal Model with a Hybrid Vision Tokenizer"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"jialingt이 [arXiv]에 게시한 'MANZANO: A Simple and Scalable Unified Multimodal Model with a Hybrid Vision Tokenizer' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-22 13:11:29+0900","children":"2025년 9월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLM",{"className":"page__taxonomy-item","children":["#","Multimodal LLM"]}],["$","span","Hybrid Tokenizer",{"className":"page__taxonomy-item","children":["#","Hybrid Tokenizer"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Visual Question Answering",{"className":"page__taxonomy-item","children":["#","Visual Question Answering"]}],["$","span","Autoregressive Model",{"className":"page__taxonomy-item","children":["#","Autoregressive Model"]}],["$","span","Diffusion Decoder",{"className":"page__taxonomy-item","children":["#","Diffusion Decoder"]}],["$","span","Unified Architecture",{"className":"page__taxonomy-item","children":["#","Unified Architecture"]}],["$","span","Model Scaling",{"className":"page__taxonomy-item","children":["#","Model Scaling"]}]]}]]}]]}],["$","article","2025-9-22-Lynx_Towards_High-Fidelity_Personalized_Video_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-22-Lynx_Towards_High-Fidelity_Personalized_Video_Generation/","children":"[논문리뷰] Lynx: Towards High-Fidelity Personalized Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Linjie Luo이 [arXiv]에 게시한 'Lynx: Towards High-Fidelity Personalized Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-22 13:11:29+0900","children":"2025년 9월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Personalized Video Generation",{"className":"page__taxonomy-item","children":["#","Personalized Video Generation"]}],["$","span","Diffusion Transformer",{"className":"page__taxonomy-item","children":["#","Diffusion Transformer"]}],["$","span","Identity Preservation",{"className":"page__taxonomy-item","children":["#","Identity Preservation"]}],["$","span","Video Synthesis",{"className":"page__taxonomy-item","children":["#","Video Synthesis"]}],["$","span","Adapter Networks",{"className":"page__taxonomy-item","children":["#","Adapter Networks"]}],["$","span","Facial Recognition",{"className":"page__taxonomy-item","children":["#","Facial Recognition"]}],["$","span","Cross-Attention",{"className":"page__taxonomy-item","children":["#","Cross-Attention"]}]]}]]}]]}],["$","article","2025-9-22-Latent_Zoning_Network_A_Unified_Principle_for_Generative_Modeling_Representation_Learning_and_Classification",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-22-Latent_Zoning_Network_A_Unified_Principle_for_Generative_Modeling_Representation_Learning_and_Classification/","children":"[논문리뷰] Latent Zoning Network: A Unified Principle for Generative Modeling, Representation Learning, and Classification"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wenyu Wang이 [arXiv]에 게시한 'Latent Zoning Network: A Unified Principle for Generative Modeling, Representation Learning, and Classification' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-22 13:11:29+0900","children":"2025년 9월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Generative Modeling",{"className":"page__taxonomy-item","children":["#","Generative Modeling"]}],["$","span","Representation Learning",{"className":"page__taxonomy-item","children":["#","Representation Learning"]}],["$","span","Classification",{"className":"page__taxonomy-item","children":["#","Classification"]}],["$","span","Unified Framework",{"className":"page__taxonomy-item","children":["#","Unified Framework"]}],["$","span","Latent Space",{"className":"page__taxonomy-item","children":["#","Latent Space"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}]]}]]}]]}],["$","article","2025-9-22-Do_You_Hear_What_I_Mean_Quantifying_the_Instruction-Perception_Gap_in_Instruction-Guided_Expressive_Text-To-Speech_Systems",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-22-Do_You_Hear_What_I_Mean_Quantifying_the_Instruction-Perception_Gap_in_Instruction-Guided_Expressive_Text-To-Speech_Systems/","children":"[논문리뷰] Do You Hear What I Mean? Quantifying the Instruction-Perception Gap in Instruction-Guided Expressive Text-To-Speech Systems"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hung-yi Lee이 [arXiv]에 게시한 'Do You Hear What I Mean? Quantifying the Instruction-Perception Gap in Instruction-Guided Expressive Text-To-Speech Systems' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-22 13:11:29+0900","children":"2025년 9월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Instruction-Guided TTS",{"className":"page__taxonomy-item","children":["#","Instruction-Guided TTS"]}],["$","span","Expressive Speech Synthesis",{"className":"page__taxonomy-item","children":["#","Expressive Speech Synthesis"]}],["$","span","Human Perception",{"className":"page__taxonomy-item","children":["#","Human Perception"]}],["$","span","Subjective Evaluation",{"className":"page__taxonomy-item","children":["#","Subjective Evaluation"]}],["$","span","Controllability",{"className":"page__taxonomy-item","children":["#","Controllability"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}],["$","span","Evaluation Metrics",{"className":"page__taxonomy-item","children":["#","Evaluation Metrics"]}]]}]]}]]}],["$","article","2025-9-22-BTL-UI_Blink-Think-Link_Reasoning_Model_for_GUI_Agent",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-22-BTL-UI_Blink-Think-Link_Reasoning_Model_for_GUI_Agent/","children":"[논문리뷰] BTL-UI: Blink-Think-Link Reasoning Model for GUI Agent"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiahui Yang이 [arXiv]에 게시한 'BTL-UI: Blink-Think-Link Reasoning Model for GUI Agent' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-22 13:11:29+0900","children":"2025년 9월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","GUI Agent",{"className":"page__taxonomy-item","children":["#","GUI Agent"]}],["$","span","Human-GUI Interaction",{"className":"page__taxonomy-item","children":["#","Human-GUI Interaction"]}],["$","span","Cognitive Modeling",{"className":"page__taxonomy-item","children":["#","Cognitive Modeling"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Multimodal Large Language Models",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models"]}],["$","span","Attention Mechanisms",{"className":"page__taxonomy-item","children":["#","Attention Mechanisms"]}],["$","span","Action Planning",{"className":"page__taxonomy-item","children":["#","Action Planning"]}]]}]]}]]}],["$","article","2025-9-22-BaseReward_A_Strong_Baseline_for_Multimodal_Reward_Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-22-BaseReward_A_Strong_Baseline_for_Multimodal_Reward_Model/","children":"[논문리뷰] BaseReward: A Strong Baseline for Multimodal Reward Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"jianfeipan이 [arXiv]에 게시한 'BaseReward: A Strong Baseline for Multimodal Reward Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-22 13:11:29+0900","children":"2025년 9월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Reward Model",{"className":"page__taxonomy-item","children":["#","Multimodal Reward Model"]}],["$","span","MLLM Alignment",{"className":"page__taxonomy-item","children":["#","MLLM Alignment"]}],["$","span","RLHF",{"className":"page__taxonomy-item","children":["#","RLHF"]}],["$","span","Reward Head Architecture",{"className":"page__taxonomy-item","children":["#","Reward Head Architecture"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Ensemble Methods",{"className":"page__taxonomy-item","children":["#","Ensemble Methods"]}],["$","span","BaseReward",{"className":"page__taxonomy-item","children":["#","BaseReward"]}]]}]]}]]}],["$","article","2025-9-22-A_Vision-Language-Action-Critic_Model_for_Robotic_Real-World_Reinforcement_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-22-A_Vision-Language-Action-Critic_Model_for_Robotic_Real-World_Reinforcement_Learning/","children":"[논문리뷰] A Vision-Language-Action-Critic Model for Robotic Real-World Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiangmiao이 [arXiv]에 게시한 'A Vision-Language-Action-Critic Model for Robotic Real-World Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-22 13:11:29+0900","children":"2025년 9월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Vision-Language-Action (VLA) Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action (VLA) Models"]}],["$","span","Reward Modeling",{"className":"page__taxonomy-item","children":["#","Reward Modeling"]}],["$","span","Human-in-the-Loop",{"className":"page__taxonomy-item","children":["#","Human-in-the-Loop"]}],["$","span","Dense Rewards",{"className":"page__taxonomy-item","children":["#","Dense Rewards"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Autoregressive Models",{"className":"page__taxonomy-item","children":["#","Autoregressive Models"]}]]}]]}]]}],["$","article","2025-9-22-Ask-to-Clarify_Resolving_Instruction_Ambiguity_through_Multi-turn_Dialogue",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-22-Ask-to-Clarify_Resolving_Instruction_Ambiguity_through_Multi-turn_Dialogue/","children":"[논문리뷰] Ask-to-Clarify: Resolving Instruction Ambiguity through Multi-turn Dialogue"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hui Zhang이 [arXiv]에 게시한 'Ask-to-Clarify: Resolving Instruction Ambiguity through Multi-turn Dialogue' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-22 13:11:29+0900","children":"2025년 9월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Human-Robot Interaction",{"className":"page__taxonomy-item","children":["#","Human-Robot Interaction"]}],["$","span","Multi-turn Dialogue",{"className":"page__taxonomy-item","children":["#","Multi-turn Dialogue"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Ambiguity Resolution",{"className":"page__taxonomy-item","children":["#","Ambiguity Resolution"]}],["$","span","Low-level Actions",{"className":"page__taxonomy-item","children":["#","Low-level Actions"]}]]}]]}]]}],["$","article","2025-9-19-WorldForge_Unlocking_Emergent_3D4D_Generation_in_Video_Diffusion_Model_via_Training-Free_Guidance",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-19-WorldForge_Unlocking_Emergent_3D4D_Generation_in_Video_Diffusion_Model_via_Training-Free_Guidance/","children":"[논문리뷰] WorldForge: Unlocking Emergent 3D/4D Generation in Video Diffusion Model via Training-Free Guidance"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ruibo Li이 [arXiv]에 게시한 'WorldForge: Unlocking Emergent 3D/4D Generation in Video Diffusion Model via Training-Free Guidance' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-19 13:12:21+0900","children":"2025년 9월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Diffusion Models",{"className":"page__taxonomy-item","children":["#","Video Diffusion Models"]}],["$","span","3D/4D Generation",{"className":"page__taxonomy-item","children":["#","3D/4D Generation"]}],["$","span","Training-Free Guidance",{"className":"page__taxonomy-item","children":["#","Training-Free Guidance"]}],["$","span","Camera Trajectory Control",{"className":"page__taxonomy-item","children":["#","Camera Trajectory Control"]}],["$","span","Novel View Synthesis",{"className":"page__taxonomy-item","children":["#","Novel View Synthesis"]}],["$","span","Geometric Consistency",{"className":"page__taxonomy-item","children":["#","Geometric Consistency"]}],["$","span","Inference-Time Optimization",{"className":"page__taxonomy-item","children":["#","Inference-Time Optimization"]}]]}]]}]]}],["$","article","2025-9-19-Unleashing_the_Potential_of_Multimodal_LLMs_for_Zero-Shot_Spatio-Temporal_Video_Grounding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-19-Unleashing_the_Potential_of_Multimodal_LLMs_for_Zero-Shot_Spatio-Temporal_Video_Grounding/","children":"[논문리뷰] Unleashing the Potential of Multimodal LLMs for Zero-Shot Spatio-Temporal Video Grounding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Rynson W. H. Lau이 [arXiv]에 게시한 'Unleashing the Potential of Multimodal LLMs for Zero-Shot Spatio-Temporal Video Grounding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-19 13:12:21+0900","children":"2025년 9월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Spatio-Temporal Video Grounding",{"className":"page__taxonomy-item","children":["#","Spatio-Temporal Video Grounding"]}],["$","span","Multimodal Large Language Models",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models"]}],["$","span","Zero-Shot Learning",{"className":"page__taxonomy-item","children":["#","Zero-Shot Learning"]}],["$","span","Visual Grounding",{"className":"page__taxonomy-item","children":["#","Visual Grounding"]}],["$","span","Decomposed Spatio-Temporal Highlighting",{"className":"page__taxonomy-item","children":["#","Decomposed Spatio-Temporal Highlighting"]}],["$","span","Logit-Guided Re-attention",{"className":"page__taxonomy-item","children":["#","Logit-Guided Re-attention"]}],["$","span","Temporal-Augmented Assembling",{"className":"page__taxonomy-item","children":["#","Temporal-Augmented Assembling"]}]]}]]}]]}],["$","article","2025-9-19-Understand_Before_You_Generate_Self-Guided_Training_for_Autoregressive_Image_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-19-Understand_Before_You_Generate_Self-Guided_Training_for_Autoregressive_Image_Generation/","children":"[논문리뷰] Understand Before You Generate: Self-Guided Training for Autoregressive Image Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xihui Liu이 [arXiv]에 게시한 'Understand Before You Generate: Self-Guided Training for Autoregressive Image Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-19 13:12:21+0900","children":"2025년 9월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Autoregressive Models",{"className":"page__taxonomy-item","children":["#","Autoregressive Models"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Self-Supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-Supervised Learning"]}],["$","span","Visual Understanding",{"className":"page__taxonomy-item","children":["#","Visual Understanding"]}],["$","span","Masked Image Modeling",{"className":"page__taxonomy-item","children":["#","Masked Image Modeling"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Next-Token Prediction",{"className":"page__taxonomy-item","children":["#","Next-Token Prediction"]}],["$","span","LlamaGen",{"className":"page__taxonomy-item","children":["#","LlamaGen"]}]]}]]}]]}],["$","article","2025-9-19-ScaleCUA_Scaling_Open-Source_Computer_Use_Agents_with_Cross-Platform_Data",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-19-ScaleCUA_Scaling_Open-Source_Computer_Use_Agents_with_Cross-Platform_Data/","children":"[논문리뷰] ScaleCUA: Scaling Open-Source Computer Use Agents with Cross-Platform Data"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zehao Li이 [arXiv]에 게시한 'ScaleCUA: Scaling Open-Source Computer Use Agents with Cross-Platform Data' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-19 13:12:21+0900","children":"2025년 9월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Computer Use Agents",{"className":"page__taxonomy-item","children":["#","Computer Use Agents"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Cross-Platform Data",{"className":"page__taxonomy-item","children":["#","Cross-Platform Data"]}],["$","span","GUI Automation",{"className":"page__taxonomy-item","children":["#","GUI Automation"]}],["$","span","Data Scaling",{"className":"page__taxonomy-item","children":["#","Data Scaling"]}],["$","span","Open-Source",{"className":"page__taxonomy-item","children":["#","Open-Source"]}],["$","span","Task Completion",{"className":"page__taxonomy-item","children":["#","Task Completion"]}],["$","span","GUI Grounding",{"className":"page__taxonomy-item","children":["#","GUI Grounding"]}]]}]]}]]}],["$","article","2025-9-19-RynnVLA-001_Using_Human_Demonstrations_to_Improve_Robot_Manipulation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-19-RynnVLA-001_Using_Human_Demonstrations_to_Improve_Robot_Manipulation/","children":"[논문리뷰] RynnVLA-001: Using Human Demonstrations to Improve Robot Manipulation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"SpaceProduct이 [arXiv]에 게시한 'RynnVLA-001: Using Human Demonstrations to Improve Robot Manipulation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-19 13:12:21+0900","children":"2025년 9월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action (VLA) Model",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action (VLA) Model"]}],["$","span","Robot Manipulation",{"className":"page__taxonomy-item","children":["#","Robot Manipulation"]}],["$","span","Human Demonstrations",{"className":"page__taxonomy-item","children":["#","Human Demonstrations"]}],["$","span","Video Generative Pretraining",{"className":"page__taxonomy-item","children":["#","Video Generative Pretraining"]}],["$","span","Ego-Centric Video",{"className":"page__taxonomy-item","children":["#","Ego-Centric Video"]}],["$","span","Trajectory Prediction",{"className":"page__taxonomy-item","children":["#","Trajectory Prediction"]}],["$","span","ActionVAE",{"className":"page__taxonomy-item","children":["#","ActionVAE"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}]]}]]}]]}],["$","article","2025-9-19-RecoWorld_Building_Simulated_Environments_for_Agentic_Recommender_Systems",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-19-RecoWorld_Building_Simulated_Environments_for_Agentic_Recommender_Systems/","children":"[논문리뷰] RecoWorld: Building Simulated Environments for Agentic Recommender Systems"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Mingyuan Wu이 [arXiv]에 게시한 'RecoWorld: Building Simulated Environments for Agentic Recommender Systems' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-19 13:12:21+0900","children":"2025년 9월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic Recommender Systems",{"className":"page__taxonomy-item","children":["#","Agentic Recommender Systems"]}],["$","span","Simulated Environments",{"className":"page__taxonomy-item","children":["#","Simulated Environments"]}],["$","span","LLM-driven Simulation",{"className":"page__taxonomy-item","children":["#","LLM-driven Simulation"]}],["$","span","Multi-turn Interaction",{"className":"page__taxonomy-item","children":["#","Multi-turn Interaction"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","User Retention",{"className":"page__taxonomy-item","children":["#","User Retention"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}],["$","span","Multi-agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-agent Systems"]}]]}]]}]]}],["$","article","2025-9-19-Reasoning_over_Boundaries_Enhancing_Specification_Alignment_via_Test-time_Delibration",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-19-Reasoning_over_Boundaries_Enhancing_Specification_Alignment_via_Test-time_Delibration/","children":"[논문리뷰] Reasoning over Boundaries: Enhancing Specification Alignment via Test-time Delibration"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhilin Wang이 [arXiv]에 게시한 'Reasoning over Boundaries: Enhancing Specification Alignment via Test-time Delibration' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-19 13:12:21+0900","children":"2025년 9월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Specification Alignment",{"className":"page__taxonomy-item","children":["#","Specification Alignment"]}],["$","span","Test-Time Deliberation",{"className":"page__taxonomy-item","children":["#","Test-Time Deliberation"]}],["$","span","Safety-Behavior Trade-off",{"className":"page__taxonomy-item","children":["#","Safety-Behavior Trade-off"]}],["$","span","ALIGN3",{"className":"page__taxonomy-item","children":["#","ALIGN3"]}],["$","span","SPECBENCH",{"className":"page__taxonomy-item","children":["#","SPECBENCH"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}]]}]]}]]}],["$","article","2025-9-19-MultiEdit_Advancing_Instruction-based_Image_Editing_on_Diverse_and_Challenging_Tasks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-19-MultiEdit_Advancing_Instruction-based_Image_Editing_on_Diverse_and_Challenging_Tasks/","children":"[논문리뷰] MultiEdit: Advancing Instruction-based Image Editing on Diverse and Challenging Tasks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xijun Gu이 [arXiv]에 게시한 'MultiEdit: Advancing Instruction-based Image Editing on Diverse and Challenging Tasks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-19 13:12:21+0900","children":"2025년 9월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Instruction-based Image Editing",{"className":"page__taxonomy-item","children":["#","Instruction-based Image Editing"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}],["$","span","Multi-modal LLM",{"className":"page__taxonomy-item","children":["#","Multi-modal LLM"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Style Transfer",{"className":"page__taxonomy-item","children":["#","Style Transfer"]}],["$","span","Multi-task Learning",{"className":"page__taxonomy-item","children":["#","Multi-task Learning"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}]]}]]}]]}],["$","article","2025-9-19-Mind_the_Gap_A_Closer_Look_at_Tokenization_for_Multiple-Choice_Question_Answering_with_LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-19-Mind_the_Gap_A_Closer_Look_at_Tokenization_for_Multiple-Choice_Question_Answering_with_LLMs/","children":"[논문리뷰] Mind the Gap: A Closer Look at Tokenization for Multiple-Choice Question Answering with LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Katharina von der Wense이 [arXiv]에 게시한 'Mind the Gap: A Closer Look at Tokenization for Multiple-Choice Question Answering with LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-19 13:12:21+0900","children":"2025년 9월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Multiple-Choice QA",{"className":"page__taxonomy-item","children":["#","Multiple-Choice QA"]}],["$","span","Tokenization",{"className":"page__taxonomy-item","children":["#","Tokenization"]}],["$","span","Prompt Sensitivity",{"className":"page__taxonomy-item","children":["#","Prompt Sensitivity"]}],["$","span","Accuracy",{"className":"page__taxonomy-item","children":["#","Accuracy"]}],["$","span","Calibration",{"className":"page__taxonomy-item","children":["#","Calibration"]}],["$","span","Model Ranking",{"className":"page__taxonomy-item","children":["#","Model Ranking"]}]]}]]}]]}],["$","article","2025-9-19-FSG-Net_Frequency-Spatial_Synergistic_Gated_Network_for_High-Resolution_Remote_Sensing_Change_Detection",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-19-FSG-Net_Frequency-Spatial_Synergistic_Gated_Network_for_High-Resolution_Remote_Sensing_Change_Detection/","children":"[논문리뷰] FSG-Net: Frequency-Spatial Synergistic Gated Network for High-Resolution Remote Sensing Change Detection"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhewei Zhang이 [arXiv]에 게시한 'FSG-Net: Frequency-Spatial Synergistic Gated Network for High-Resolution Remote Sensing Change Detection' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-19 13:12:21+0900","children":"2025년 9월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Change Detection",{"className":"page__taxonomy-item","children":["#","Change Detection"]}],["$","span","Remote Sensing",{"className":"page__taxonomy-item","children":["#","Remote Sensing"]}],["$","span","Frequency-Spatial Analysis",{"className":"page__taxonomy-item","children":["#","Frequency-Spatial Analysis"]}],["$","span","Wavelet Transform",{"className":"page__taxonomy-item","children":["#","Wavelet Transform"]}],["$","span","Attention Mechanism",{"className":"page__taxonomy-item","children":["#","Attention Mechanism"]}],["$","span","Gated Fusion",{"className":"page__taxonomy-item","children":["#","Gated Fusion"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}]]}]]}]]}],["$","article","2025-9-19-FlowRL_Matching_Reward_Distributions_for_LLM_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-19-FlowRL_Matching_Reward_Distributions_for_LLM_Reasoning/","children":"[논문리뷰] FlowRL: Matching Reward Distributions for LLM Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hengli Li이 [arXiv]에 게시한 'FlowRL: Matching Reward Distributions for LLM Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-19 13:12:21+0900","children":"2025년 9월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reward Distribution Matching",{"className":"page__taxonomy-item","children":["#","Reward Distribution Matching"]}],["$","span","GFlowNets",{"className":"page__taxonomy-item","children":["#","GFlowNets"]}],["$","span","Mode Collapse",{"className":"page__taxonomy-item","children":["#","Mode Collapse"]}],["$","span","Diverse Reasoning",{"className":"page__taxonomy-item","children":["#","Diverse Reasoning"]}],["$","span","Flow-Balanced Optimization",{"className":"page__taxonomy-item","children":["#","Flow-Balanced Optimization"]}]]}]]}]]}],["$","article","2025-9-19-FinSearchComp_Towards_a_Realistic_Expert-Level_Evaluation_of_Financial_Search_and_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-19-FinSearchComp_Towards_a_Realistic_Expert-Level_Evaluation_of_Financial_Search_and_Reasoning/","children":"[논문리뷰] FinSearchComp: Towards a Realistic, Expert-Level Evaluation of Financial Search and Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiashuo Liu이 [arXiv]에 게시한 'FinSearchComp: Towards a Realistic, Expert-Level Evaluation of Financial Search and Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-19 13:12:21+0900","children":"2025년 9월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Financial LLMs",{"className":"page__taxonomy-item","children":["#","Financial LLMs"]}],["$","span","Agent Benchmarking",{"className":"page__taxonomy-item","children":["#","Agent Benchmarking"]}],["$","span","Open-domain Search",{"className":"page__taxonomy-item","children":["#","Open-domain Search"]}],["$","span","Financial Reasoning",{"className":"page__taxonomy-item","children":["#","Financial Reasoning"]}],["$","span","Time-Sensitive Data",{"className":"page__taxonomy-item","children":["#","Time-Sensitive Data"]}],["$","span","Multi-hop QA",{"className":"page__taxonomy-item","children":["#","Multi-hop QA"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}]]}]]}]]}],["$","article","2025-9-19-Evolving_Language_Models_without_Labels_Majority_Drives_Selection_Novelty_Promotes_Variation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-19-Evolving_Language_Models_without_Labels_Majority_Drives_Selection_Novelty_Promotes_Variation/","children":"[논문리뷰] Evolving Language Models without Labels: Majority Drives Selection, Novelty Promotes Variation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kishan Panaganti이 [arXiv]에 게시한 'Evolving Language Models without Labels: Majority Drives Selection, Novelty Promotes Variation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-19 13:12:21+0900","children":"2025년 9월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Label-free Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Label-free Reinforcement Learning"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Self-improvement",{"className":"page__taxonomy-item","children":["#","Self-improvement"]}],["$","span","Entropy Collapse",{"className":"page__taxonomy-item","children":["#","Entropy Collapse"]}],["$","span","Novelty Reward",{"className":"page__taxonomy-item","children":["#","Novelty Reward"]}],["$","span","Test-Time RL",{"className":"page__taxonomy-item","children":["#","Test-Time RL"]}],["$","span","GRPO",{"className":"page__taxonomy-item","children":["#","GRPO"]}],["$","span","Evolutionary Computing Principles",{"className":"page__taxonomy-item","children":["#","Evolutionary Computing Principles"]}]]}]]}]]}],["$","article","2025-9-19-EchoVLM_Dynamic_Mixture-of-Experts_Vision-Language_Model_for_Universal_Ultrasound_Intelligence",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-19-EchoVLM_Dynamic_Mixture-of-Experts_Vision-Language_Model_for_Universal_Ultrasound_Intelligence/","children":"[논문리뷰] EchoVLM: Dynamic Mixture-of-Experts Vision-Language Model for Universal Ultrasound Intelligence"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Qinghua Huang이 [arXiv]에 게시한 'EchoVLM: Dynamic Mixture-of-Experts Vision-Language Model for Universal Ultrasound Intelligence' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-19 13:12:21+0900","children":"2025년 9월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Ultrasound Imaging",{"className":"page__taxonomy-item","children":["#","Ultrasound Imaging"]}],["$","span","Medical Diagnosis",{"className":"page__taxonomy-item","children":["#","Medical Diagnosis"]}],["$","span","Mixture-of-Experts (MoE)",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts (MoE)"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Report Generation",{"className":"page__taxonomy-item","children":["#","Report Generation"]}],["$","span","VQA",{"className":"page__taxonomy-item","children":["#","VQA"]}]]}]]}]]}],["$","article","2025-9-19-AToken_A_Unified_Tokenizer_for_Vision",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-19-AToken_A_Unified_Tokenizer_for_Vision/","children":"[논문리뷰] AToken: A Unified Tokenizer for Vision"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Mingze Xu이 [arXiv]에 게시한 'AToken: A Unified Tokenizer for Vision' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-19 13:12:21+0900","children":"2025년 9월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Unified Visual Tokenizer",{"className":"page__taxonomy-item","children":["#","Unified Visual Tokenizer"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","4D Representation",{"className":"page__taxonomy-item","children":["#","4D Representation"]}],["$","span","Adversarial-free Training",{"className":"page__taxonomy-item","children":["#","Adversarial-free Training"]}],["$","span","Reconstruction",{"className":"page__taxonomy-item","children":["#","Reconstruction"]}],["$","span","Semantic Understanding",{"className":"page__taxonomy-item","children":["#","Semantic Understanding"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}]]}]]}]]}],["$","article","2025-9-18-Wan-Animate_Unified_Character_Animation_and_Replacement_with_Holistic_Replication",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-18-Wan-Animate_Unified_Character_Animation_and_Replacement_with_Holistic_Replication/","children":"[논문리뷰] Wan-Animate: Unified Character Animation and Replacement with Holistic Replication"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Mingyang Huang이 [arXiv]에 게시한 'Wan-Animate: Unified Character Animation and Replacement with Holistic Replication' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-18 13:07:00+0900","children":"2025년 9월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Character Animation",{"className":"page__taxonomy-item","children":["#","Character Animation"]}],["$","span","Video Replacement",{"className":"page__taxonomy-item","children":["#","Video Replacement"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","DiT",{"className":"page__taxonomy-item","children":["#","DiT"]}],["$","span","Relighting LoRA",{"className":"page__taxonomy-item","children":["#","Relighting LoRA"]}],["$","span","Holistic Replication",{"className":"page__taxonomy-item","children":["#","Holistic Replication"]}],["$","span","Open-Source",{"className":"page__taxonomy-item","children":["#","Open-Source"]}]]}]]}]]}],["$","article","2025-9-18-THOR_Tool-Integrated_Hierarchical_Optimization_via_RL_for_Mathematical_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-18-THOR_Tool-Integrated_Hierarchical_Optimization_via_RL_for_Mathematical_Reasoning/","children":"[논문리뷰] THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yicheng Pan이 [arXiv]에 게시한 'THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-18 13:07:00+0900","children":"2025년 9월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Tool-Integrated Reasoning",{"className":"page__taxonomy-item","children":["#","Tool-Integrated Reasoning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Hierarchical Optimization",{"className":"page__taxonomy-item","children":["#","Hierarchical Optimization"]}],["$","span","Self-Correction",{"className":"page__taxonomy-item","children":["#","Self-Correction"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}]]}]]}]]}],["$","article","2025-9-18-SteeringControl_Holistic_Evaluation_of_Alignment_Steering_in_LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-18-SteeringControl_Holistic_Evaluation_of_Alignment_Steering_in_LLMs/","children":"[논문리뷰] SteeringControl: Holistic Evaluation of Alignment Steering in LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhun Wang이 [arXiv]에 게시한 'SteeringControl: Holistic Evaluation of Alignment Steering in LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-18 13:07:00+0900","children":"2025년 9월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Alignment",{"className":"page__taxonomy-item","children":["#","LLM Alignment"]}],["$","span","Representation Steering",{"className":"page__taxonomy-item","children":["#","Representation Steering"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Behavioral Entanglement",{"className":"page__taxonomy-item","children":["#","Behavioral Entanglement"]}],["$","span","Bias Mitigation",{"className":"page__taxonomy-item","children":["#","Bias Mitigation"]}],["$","span","Harmful Generation",{"className":"page__taxonomy-item","children":["#","Harmful Generation"]}],["$","span","Hallucination Control",{"className":"page__taxonomy-item","children":["#","Hallucination Control"]}],["$","span","Modular Framework",{"className":"page__taxonomy-item","children":["#","Modular Framework"]}]]}]]}]]}],["$","article","2025-9-18-Scrub_It_Out_Erasing_Sensitive_Memorization_in_Code_Language_Models_via_Machine_Unlearning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-18-Scrub_It_Out_Erasing_Sensitive_Memorization_in_Code_Language_Models_via_Machine_Unlearning/","children":"[논문리뷰] Scrub It Out! Erasing Sensitive Memorization in Code Language Models via Machine Unlearning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhou Yang이 [arXiv]에 게시한 'Scrub It Out! Erasing Sensitive Memorization in Code Language Models via Machine Unlearning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-18 13:07:00+0900","children":"2025년 9월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Code Language Models",{"className":"page__taxonomy-item","children":["#","Code Language Models"]}],["$","span","Machine Unlearning",{"className":"page__taxonomy-item","children":["#","Machine Unlearning"]}],["$","span","Sensitive Memorization",{"className":"page__taxonomy-item","children":["#","Sensitive Memorization"]}],["$","span","Privacy",{"className":"page__taxonomy-item","children":["#","Privacy"]}],["$","span","Gradient Ascent",{"className":"page__taxonomy-item","children":["#","Gradient Ascent"]}],["$","span","Model Utility",{"className":"page__taxonomy-item","children":["#","Model Utility"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}]]}]]}]]}],["$","article","2025-9-18-SAIL-VL2_Technical_Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-18-SAIL-VL2_Technical_Report/","children":"[논문리뷰] SAIL-VL2 Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zijian Kang이 [arXiv]에 게시한 'SAIL-VL2 Technical Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-18 13:07:00+0900","children":"2025년 9월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Model",{"className":"page__taxonomy-item","children":["#","Vision-Language Model"]}],["$","span","Multimodal Understanding",{"className":"page__taxonomy-item","children":["#","Multimodal Understanding"]}],["$","span","Mixture-of-Experts",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts"]}],["$","span","Progressive Training",{"className":"page__taxonomy-item","children":["#","Progressive Training"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","SAIL-ViT",{"className":"page__taxonomy-item","children":["#","SAIL-ViT"]}]]}]]}]]}],["$","article","2025-9-18-PANORAMA_The_Rise_of_Omnidirectional_Vision_in_the_Embodied_AI_Era",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-18-PANORAMA_The_Rise_of_Omnidirectional_Vision_in_the_Embodied_AI_Era/","children":"[논문리뷰] PANORAMA: The Rise of Omnidirectional Vision in the Embodied AI Era"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zihao Dongfang이 [arXiv]에 게시한 'PANORAMA: The Rise of Omnidirectional Vision in the Embodied AI Era' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-18 13:07:00+0900","children":"2025년 9월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Omnidirectional Vision",{"className":"page__taxonomy-item","children":["#","Omnidirectional Vision"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Panoramic Perception",{"className":"page__taxonomy-item","children":["#","Panoramic Perception"]}],["$","span","Multi-modal Learning",{"className":"page__taxonomy-item","children":["#","Multi-modal Learning"]}],["$","span","Dataset Development",{"className":"page__taxonomy-item","children":["#","Dataset Development"]}],["$","span","Robot Navigation",{"className":"page__taxonomy-item","children":["#","Robot Navigation"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}],["$","span","System Architecture",{"className":"page__taxonomy-item","children":["#","System Architecture"]}]]}]]}]]}],["$","article","2025-9-18-MARS2_2025_Challenge_on_Multimodal_Reasoning_Datasets_Methods_Results_Discussion_and_Outlook",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-18-MARS2_2025_Challenge_on_Multimodal_Reasoning_Datasets_Methods_Results_Discussion_and_Outlook/","children":"[논문리뷰] MARS2 2025 Challenge on Multimodal Reasoning: Datasets, Methods, Results, Discussion, and Outlook"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Bowen Zhou이 [arXiv]에 게시한 'MARS2 2025 Challenge on Multimodal Reasoning: Datasets, Methods, Results, Discussion, and Outlook' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-18 13:07:00+0900","children":"2025년 9월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Multimodal Large Language Models (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models (MLLMs)"]}],["$","span","Visual Grounding",{"className":"page__taxonomy-item","children":["#","Visual Grounding"]}],["$","span","Visual Question Answering",{"className":"page__taxonomy-item","children":["#","Visual Question Answering"]}],["$","span","Advertisement Video Analysis",{"className":"page__taxonomy-item","children":["#","Advertisement Video Analysis"]}],["$","span","Real-world Scenarios",{"className":"page__taxonomy-item","children":["#","Real-world Scenarios"]}],["$","span","Challenge Benchmark",{"className":"page__taxonomy-item","children":["#","Challenge Benchmark"]}]]}]]}]]}],["$","article","2025-9-18-Improving_Context_Fidelity_via_Native_Retrieval-Augmented_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-18-Improving_Context_Fidelity_via_Native_Retrieval-Augmented_Reasoning/","children":"[논문리뷰] Improving Context Fidelity via Native Retrieval-Augmented Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiangru Tang이 [arXiv]에 게시한 'Improving Context Fidelity via Native Retrieval-Augmented Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-18 13:07:00+0900","children":"2025년 9월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Context Fidelity",{"className":"page__taxonomy-item","children":["#","Context Fidelity"]}],["$","span","Retrieval-Augmented Generation (RAG)",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation (RAG)"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Supervised Fine-Tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning (SFT)"]}],["$","span","Hallucination",{"className":"page__taxonomy-item","children":["#","Hallucination"]}],["$","span","Question Answering",{"className":"page__taxonomy-item","children":["#","Question Answering"]}],["$","span","In-context Retrieval",{"className":"page__taxonomy-item","children":["#","In-context Retrieval"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}]]}]]}]]}],["$","article","2025-9-18-Hala_Technical_Report_Building_Arabic-Centric_Instruction_Translation_Models_at_Scale",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-18-Hala_Technical_Report_Building_Arabic-Centric_Instruction_Translation_Models_at_Scale/","children":"[논문리뷰] Hala Technical Report: Building Arabic-Centric Instruction & Translation Models at Scale"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Bernard Ghanem이 [arXiv]에 게시한 'Hala Technical Report: Building Arabic-Centric Instruction & Translation Models at Scale' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-18 13:07:00+0900","children":"2025년 9월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Arabic NLP",{"className":"page__taxonomy-item","children":["#","Arabic NLP"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}],["$","span","Machine Translation",{"className":"page__taxonomy-item","children":["#","Machine Translation"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","FP8 Quantization",{"className":"page__taxonomy-item","children":["#","FP8 Quantization"]}],["$","span","Data Bootstrapping",{"className":"page__taxonomy-item","children":["#","Data Bootstrapping"]}],["$","span","Model Merging",{"className":"page__taxonomy-item","children":["#","Model Merging"]}],["$","span","Language-Centric AI",{"className":"page__taxonomy-item","children":["#","Language-Centric AI"]}]]}]]}]]}],["$","article","2025-9-18-GenExam_A_Multidisciplinary_Text-to-Image_Exam",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-18-GenExam_A_Multidisciplinary_Text-to-Image_Exam/","children":"[논문리뷰] GenExam: A Multidisciplinary Text-to-Image Exam"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yu Qiao이 [arXiv]에 게시한 'GenExam: A Multidisciplinary Text-to-Image Exam' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-18 13:07:00+0900","children":"2025년 9월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Multidisciplinary",{"className":"page__taxonomy-item","children":["#","Multidisciplinary"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Evaluation",{"className":"page__taxonomy-item","children":["#","Evaluation"]}],["$","span","AGI",{"className":"page__taxonomy-item","children":["#","AGI"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Scoring System",{"className":"page__taxonomy-item","children":["#","Scoring System"]}],["$","span","Visual Question Answering",{"className":"page__taxonomy-item","children":["#","Visual Question Answering"]}]]}]]}]]}],["$","article","2025-9-17-WebWeaver_Structuring_Web-Scale_Evidence_with_Dynamic_Outlines_for_Open-Ended_Deep_Research",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-17-WebWeaver_Structuring_Web-Scale_Evidence_with_Dynamic_Outlines_for_Open-Ended_Deep_Research/","children":"[논문리뷰] WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for Open-Ended Deep Research"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Houquan Zhou이 [arXiv]에 게시한 'WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for Open-Ended Deep Research' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-17 13:16:01+0900","children":"2025년 9월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Open-Ended Deep Research",{"className":"page__taxonomy-item","children":["#","Open-Ended Deep Research"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Dynamic Outline",{"className":"page__taxonomy-item","children":["#","Dynamic Outline"]}],["$","span","Evidence Acquisition",{"className":"page__taxonomy-item","children":["#","Evidence Acquisition"]}],["$","span","Hierarchical Writing",{"className":"page__taxonomy-item","children":["#","Hierarchical Writing"]}],["$","span","Memory Bank",{"className":"page__taxonomy-item","children":["#","Memory Bank"]}],["$","span","State-of-the-Art",{"className":"page__taxonomy-item","children":["#","State-of-the-Art"]}],["$","span","Supervised Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning"]}]]}]]}]]}],["$","article","2025-9-17-WebSailor-V2_Bridging_the_Chasm_to_Proprietary_Agents_via_Synthetic_Data_and_Scalable_Reinforcement_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-17-WebSailor-V2_Bridging_the_Chasm_to_Proprietary_Agents_via_Synthetic_Data_and_Scalable_Reinforcement_Learning/","children":"[논문리뷰] WebSailor-V2: Bridging the Chasm to Proprietary Agents via Synthetic Data and Scalable Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Huifeng Yin이 [arXiv]에 게시한 'WebSailor-V2: Bridging the Chasm to Proprietary Agents via Synthetic Data and Scalable Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-17 13:16:01+0900","children":"2025년 9월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Web Agents",{"className":"page__taxonomy-item","children":["#","Web Agents"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Synthetic Data",{"className":"page__taxonomy-item","children":["#","Synthetic Data"]}],["$","span","Knowledge Graphs",{"className":"page__taxonomy-item","children":["#","Knowledge Graphs"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Supervised Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning"]}],["$","span","Sim-to-Real Transfer",{"className":"page__taxonomy-item","children":["#","Sim-to-Real Transfer"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}]]}]]}]]}],["$","article","2025-9-17-WebResearcher_Unleashing_unbounded_reasoning_capability_in_Long-Horizon_Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-17-WebResearcher_Unleashing_unbounded_reasoning_capability_in_Long-Horizon_Agents/","children":"[논문리뷰] WebResearcher: Unleashing unbounded reasoning capability in Long-Horizon Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wenbiao Yin이 [arXiv]에 게시한 'WebResearcher: Unleashing unbounded reasoning capability in Long-Horizon Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-17 13:16:01+0900","children":"2025년 9월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Deep Research",{"className":"page__taxonomy-item","children":["#","Deep Research"]}],["$","span","Iterative Reasoning",{"className":"page__taxonomy-item","children":["#","Iterative Reasoning"]}],["$","span","Long-Horizon Tasks",{"className":"page__taxonomy-item","children":["#","Long-Horizon Tasks"]}],["$","span","Context Management",{"className":"page__taxonomy-item","children":["#","Context Management"]}],["$","span","Data Synthesis",{"className":"page__taxonomy-item","children":["#","Data Synthesis"]}],["$","span","Tool-Augmented LLMs",{"className":"page__taxonomy-item","children":["#","Tool-Augmented LLMs"]}],["$","span","Markov Decision Process",{"className":"page__taxonomy-item","children":["#","Markov Decision Process"]}]]}]]}]]}],["$","article","2025-9-17-Towards_General_Agentic_Intelligence_via_Environment_Scaling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-17-Towards_General_Agentic_Intelligence_via_Environment_Scaling/","children":"[논문리뷰] Towards General Agentic Intelligence via Environment Scaling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Guangyu Li이 [arXiv]에 게시한 'Towards General Agentic Intelligence via Environment Scaling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-17 13:16:01+0900","children":"2025년 9월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Environment Scaling",{"className":"page__taxonomy-item","children":["#","Environment Scaling"]}],["$","span","Function Calling",{"className":"page__taxonomy-item","children":["#","Function Calling"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Synthetic Data Generation",{"className":"page__taxonomy-item","children":["#","Synthetic Data Generation"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}]]}]]}]]}],["$","article","2025-9-17-Single-stream_Policy_Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-17-Single-stream_Policy_Optimization/","children":"[논문리뷰] Single-stream Policy Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zihan Ding이 [arXiv]에 게시한 'Single-stream Policy Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-17 13:16:01+0900","children":"2025년 9월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","LLM Optimization",{"className":"page__taxonomy-item","children":["#","LLM Optimization"]}],["$","span","Policy Gradient",{"className":"page__taxonomy-item","children":["#","Policy Gradient"]}],["$","span","Variance Reduction",{"className":"page__taxonomy-item","children":["#","Variance Reduction"]}],["$","span","Adaptive Sampling",{"className":"page__taxonomy-item","children":["#","Adaptive Sampling"]}],["$","span","Scalability",{"className":"page__taxonomy-item","children":["#","Scalability"]}],["$","span","Agentic Systems",{"className":"page__taxonomy-item","children":["#","Agentic Systems"]}],["$","span","RLVR",{"className":"page__taxonomy-item","children":["#","RLVR"]}]]}]]}]]}],["$","article","2025-9-17-Scaling_Agents_via_Continual_Pre-training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-17-Scaling_Agents_via_Continual_Pre-training/","children":"[논문리뷰] Scaling Agents via Continual Pre-training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Guangyu Li이 [arXiv]에 게시한 'Scaling Agents via Continual Pre-training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-17 13:16:01+0900","children":"2025년 9월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic LLMs",{"className":"page__taxonomy-item","children":["#","Agentic LLMs"]}],["$","span","Continual Pre-training",{"className":"page__taxonomy-item","children":["#","Continual Pre-training"]}],["$","span","Deep Research Agents",{"className":"page__taxonomy-item","children":["#","Deep Research Agents"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Multi-step Reasoning",{"className":"page__taxonomy-item","children":["#","Multi-step Reasoning"]}],["$","span","Data Synthesis",{"className":"page__taxonomy-item","children":["#","Data Synthesis"]}],["$","span","Scaling Laws",{"className":"page__taxonomy-item","children":["#","Scaling Laws"]}]]}]]}]]}],["$","article","2025-9-17-ReSum_Unlocking_Long-Horizon_Search_Intelligence_via_Context_Summarization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-17-ReSum_Unlocking_Long-Horizon_Search_Intelligence_via_Context_Summarization/","children":"[논문리뷰] ReSum: Unlocking Long-Horizon Search Intelligence via Context Summarization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Litu Ou이 [arXiv]에 게시한 'ReSum: Unlocking Long-Horizon Search Intelligence via Context Summarization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-17 13:16:01+0900","children":"2025년 9월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Context Management",{"className":"page__taxonomy-item","children":["#","Context Management"]}],["$","span","Summarization",{"className":"page__taxonomy-item","children":["#","Summarization"]}],["$","span","ReAct",{"className":"page__taxonomy-item","children":["#","ReAct"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Web Search",{"className":"page__taxonomy-item","children":["#","Web Search"]}],["$","span","Long-Horizon Reasoning",{"className":"page__taxonomy-item","children":["#","Long-Horizon Reasoning"]}]]}]]}]]}],["$","article","2025-9-17-Optimal_Brain_Restoration_for_Joint_Quantization_and_Sparsification_of_LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-17-Optimal_Brain_Restoration_for_Joint_Quantization_and_Sparsification_of_LLMs/","children":"[논문리뷰] Optimal Brain Restoration for Joint Quantization and Sparsification of LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Luca Benini이 [arXiv]에 게시한 'Optimal Brain Restoration for Joint Quantization and Sparsification of LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-17 13:16:01+0900","children":"2025년 9월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Compression",{"className":"page__taxonomy-item","children":["#","LLM Compression"]}],["$","span","Quantization",{"className":"page__taxonomy-item","children":["#","Quantization"]}],["$","span","Sparsification",{"className":"page__taxonomy-item","children":["#","Sparsification"]}],["$","span","Post-training Quantization",{"className":"page__taxonomy-item","children":["#","Post-training Quantization"]}],["$","span","Hessian-based Optimization",{"className":"page__taxonomy-item","children":["#","Hessian-based Optimization"]}],["$","span","Error Compensation",{"className":"page__taxonomy-item","children":["#","Error Compensation"]}],["$","span","Low-bit LLMs",{"className":"page__taxonomy-item","children":["#","Low-bit LLMs"]}]]}]]}]]}],["$","article","2025-9-17-Multiple_Instance_Learning_Framework_with_Masked_Hard_Instance_Mining_for_Gigapixel_Histopathology_Image_Analysis",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-17-Multiple_Instance_Learning_Framework_with_Masked_Hard_Instance_Mining_for_Gigapixel_Histopathology_Image_Analysis/","children":"[논문리뷰] Multiple Instance Learning Framework with Masked Hard Instance Mining for Gigapixel Histopathology Image Analysis"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Bo Liu이 [arXiv]에 게시한 'Multiple Instance Learning Framework with Masked Hard Instance Mining for Gigapixel Histopathology Image Analysis' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-17 13:16:01+0900","children":"2025년 9월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multiple Instance Learning",{"className":"page__taxonomy-item","children":["#","Multiple Instance Learning"]}],["$","span","Hard Instance Mining",{"className":"page__taxonomy-item","children":["#","Hard Instance Mining"]}],["$","span","Computational Pathology",{"className":"page__taxonomy-item","children":["#","Computational Pathology"]}],["$","span","Whole Slide Images",{"className":"page__taxonomy-item","children":["#","Whole Slide Images"]}],["$","span","Masked Learning",{"className":"page__taxonomy-item","children":["#","Masked Learning"]}],["$","span","Siamese Network",{"className":"page__taxonomy-item","children":["#","Siamese Network"]}],["$","span","Medical Image Analysis",{"className":"page__taxonomy-item","children":["#","Medical Image Analysis"]}]]}]]}]]}],["$","article","2025-9-17-Multimodal_Reasoning_for_Science_Technical_Report_and_1st_Place_Solution_to_the_ICML_2025_SeePhys_Challenge",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-17-Multimodal_Reasoning_for_Science_Technical_Report_and_1st_Place_Solution_to_the_ICML_2025_SeePhys_Challenge/","children":"[논문리뷰] Multimodal Reasoning for Science: Technical Report and 1st Place Solution to the ICML 2025 SeePhys Challenge"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wentao Zhang이 [arXiv]에 게시한 'Multimodal Reasoning for Science: Technical Report and 1st Place Solution to the ICML 2025 SeePhys Challenge' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-17 13:16:01+0900","children":"2025년 9월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","span","Science AI",{"className":"page__taxonomy-item","children":["#","Science AI"]}],["$","span","Caption-assisted Reasoning",{"className":"page__taxonomy-item","children":["#","Caption-assisted Reasoning"]}],["$","span","SeePhys Challenge",{"className":"page__taxonomy-item","children":["#","SeePhys Challenge"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Visual Question Answering",{"className":"page__taxonomy-item","children":["#","Visual Question Answering"]}],["$","span","Physics Problems",{"className":"page__taxonomy-item","children":["#","Physics Problems"]}],["$","span","Cross-modal Alignment",{"className":"page__taxonomy-item","children":["#","Cross-modal Alignment"]}]]}]]}]]}],["$","article","2025-9-17-Hunyuan3D_Studio_End-to-End_AI_Pipeline_for_Game-Ready_3D_Asset_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-17-Hunyuan3D_Studio_End-to-End_AI_Pipeline_for_Game-Ready_3D_Asset_Generation/","children":"[논문리뷰] Hunyuan3D Studio: End-to-End AI Pipeline for Game-Ready 3D Asset Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Lixin Xu이 [arXiv]에 게시한 'Hunyuan3D Studio: End-to-End AI Pipeline for Game-Ready 3D Asset Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-17 13:16:01+0900","children":"2025년 9월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Asset Generation",{"className":"page__taxonomy-item","children":["#","3D Asset Generation"]}],["$","span","AI Pipeline",{"className":"page__taxonomy-item","children":["#","AI Pipeline"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Game Development",{"className":"page__taxonomy-item","children":["#","Game Development"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Neural Modules",{"className":"page__taxonomy-item","children":["#","Neural Modules"]}],["$","span","Retopology",{"className":"page__taxonomy-item","children":["#","Retopology"]}],["$","span","UV Unwrapping",{"className":"page__taxonomy-item","children":["#","UV Unwrapping"]}]]}]]}]]}],["$","article","2025-9-17-Exact_Coset_Sampling_for_Quantum_Lattice_Algorithms",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-17-Exact_Coset_Sampling_for_Quantum_Lattice_Algorithms/","children":"[논문리뷰] Exact Coset Sampling for Quantum Lattice Algorithms"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yifan Zhang이 [arXiv]에 게시한 'Exact Coset Sampling for Quantum Lattice Algorithms' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-17 13:16:01+0900","children":"2025년 9월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Quantum Algorithms",{"className":"page__taxonomy-item","children":["#","Quantum Algorithms"]}],["$","span","Lattice Problems",{"className":"page__taxonomy-item","children":["#","Lattice Problems"]}],["$","span","Coset Sampling",{"className":"page__taxonomy-item","children":["#","Coset Sampling"]}],["$","span","Quantum Fourier Transform (QFT)",{"className":"page__taxonomy-item","children":["#","Quantum Fourier Transform (QFT)"]}],["$","span","Modular Arithmetic",{"className":"page__taxonomy-item","children":["#","Modular Arithmetic"]}],["$","span","Quantum Cryptography",{"className":"page__taxonomy-item","children":["#","Quantum Cryptography"]}],["$","span","Exact Sampling",{"className":"page__taxonomy-item","children":["#","Exact Sampling"]}]]}]]}]]}],["$","article","2025-9-17-EconProver_Towards_More_Economical_Test-Time_Scaling_for_Automated_Theorem_Proving",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-17-EconProver_Towards_More_Economical_Test-Time_Scaling_for_Automated_Theorem_Proving/","children":"[논문리뷰] EconProver: Towards More Economical Test-Time Scaling for Automated Theorem Proving"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shansan Gong이 [arXiv]에 게시한 'EconProver: Towards More Economical Test-Time Scaling for Automated Theorem Proving' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-17 13:16:01+0900","children":"2025년 9월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Automated Theorem Proving",{"className":"page__taxonomy-item","children":["#","Automated Theorem Proving"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Test-Time Scaling",{"className":"page__taxonomy-item","children":["#","Test-Time Scaling"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Efficiency Optimization",{"className":"page__taxonomy-item","children":["#","Efficiency Optimization"]}],["$","span","Token Cost",{"className":"page__taxonomy-item","children":["#","Token Cost"]}],["$","span","Sampling Cost",{"className":"page__taxonomy-item","children":["#","Sampling Cost"]}],["$","span","Dynamic CoT Switching",{"className":"page__taxonomy-item","children":["#","Dynamic CoT Switching"]}]]}]]}]]}],["$","article","2025-9-17-3D_Aware_Region_Prompted_Vision_Language_Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-17-3D_Aware_Region_Prompted_Vision_Language_Model/","children":"[논문리뷰] 3D Aware Region Prompted Vision Language Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiaolong Li이 [arXiv]에 게시한 '3D Aware Region Prompted Vision Language Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-17 13:16:01+0900","children":"2025년 9월 17일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Vision",{"className":"page__taxonomy-item","children":["#","3D Vision"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}],["$","span","Region Prompting",{"className":"page__taxonomy-item","children":["#","Region Prompting"]}],["$","span","Multi-view Learning",{"className":"page__taxonomy-item","children":["#","Multi-view Learning"]}],["$","span","Depth Estimation",{"className":"page__taxonomy-item","children":["#","Depth Estimation"]}],["$","span","Unified Representation",{"className":"page__taxonomy-item","children":["#","Unified Representation"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}]]}]]}]]}],["$","article","2025-9-16-UI-S1_Advancing_GUI_Automation_via_Semi-online_Reinforcement_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-16-UI-S1_Advancing_GUI_Automation_via_Semi-online_Reinforcement_Learning/","children":"[논문리뷰] UI-S1: Advancing GUI Automation via Semi-online Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yongliang Shen이 [arXiv]에 게시한 'UI-S1: Advancing GUI Automation via Semi-online Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-16 13:16:41+0900","children":"2025년 9월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","GUI Automation",{"className":"page__taxonomy-item","children":["#","GUI Automation"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Semi-online RL",{"className":"page__taxonomy-item","children":["#","Semi-online RL"]}],["$","span","Offline RL",{"className":"page__taxonomy-item","children":["#","Offline RL"]}],["$","span","Online RL",{"className":"page__taxonomy-item","children":["#","Online RL"]}],["$","span","Patch Module",{"className":"page__taxonomy-item","children":["#","Patch Module"]}],["$","span","Multi-turn Interaction",{"className":"page__taxonomy-item","children":["#","Multi-turn Interaction"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}]]}]]}]]}],["$","article","2025-9-16-SearchInstruct_Enhancing_Domain_Adaptation_via_Retrieval-Based_Instruction_Dataset_Creation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-16-SearchInstruct_Enhancing_Domain_Adaptation_via_Retrieval-Based_Instruction_Dataset_Creation/","children":"[논문리뷰] SearchInstruct: Enhancing Domain Adaptation via Retrieval-Based Instruction Dataset Creation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Heshaam Faili이 [arXiv]에 게시한 'SearchInstruct: Enhancing Domain Adaptation via Retrieval-Based Instruction Dataset Creation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-16 13:16:41+0900","children":"2025년 9월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}],["$","span","Domain Adaptation",{"className":"page__taxonomy-item","children":["#","Domain Adaptation"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","Dataset Creation",{"className":"page__taxonomy-item","children":["#","Dataset Creation"]}],["$","span","Model Editing",{"className":"page__taxonomy-item","children":["#","Model Editing"]}],["$","span","Supervised Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning"]}]]}]]}]]}],["$","article","2025-9-16-PersonaX_Multimodal_Datasets_with_LLM-Inferred_Behavior_Traits",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-16-PersonaX_Multimodal_Datasets_with_LLM-Inferred_Behavior_Traits/","children":"[논문리뷰] PersonaX: Multimodal Datasets with LLM-Inferred Behavior Traits"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhenhao Chen이 [arXiv]에 게시한 'PersonaX: Multimodal Datasets with LLM-Inferred Behavior Traits' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-16 13:16:41+0900","children":"2025년 9월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Dataset",{"className":"page__taxonomy-item","children":["#","Multimodal Dataset"]}],["$","span","LLM Inference",{"className":"page__taxonomy-item","children":["#","LLM Inference"]}],["$","span","Behavioral Traits",{"className":"page__taxonomy-item","children":["#","Behavioral Traits"]}],["$","span","Causal Representation Learning",{"className":"page__taxonomy-item","children":["#","Causal Representation Learning"]}],["$","span","Big Five",{"className":"page__taxonomy-item","children":["#","Big Five"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Causal Discovery",{"className":"page__taxonomy-item","children":["#","Causal Discovery"]}],["$","span","Human-Computer Interaction",{"className":"page__taxonomy-item","children":["#","Human-Computer Interaction"]}]]}]]}]]}],["$","article","2025-9-16-OmniWorld_A_Multi-Domain_and_Multi-Modal_Dataset_for_4D_World_Modeling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-16-OmniWorld_A_Multi-Domain_and_Multi-Modal_Dataset_for_4D_World_Modeling/","children":"[논문리뷰] OmniWorld: A Multi-Domain and Multi-Modal Dataset for 4D World Modeling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yang Zhou이 [arXiv]에 게시한 'OmniWorld: A Multi-Domain and Multi-Modal Dataset for 4D World Modeling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-16 13:16:41+0900","children":"2025년 9월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","4D World Modeling",{"className":"page__taxonomy-item","children":["#","4D World Modeling"]}],["$","span","Multi-Modal Dataset",{"className":"page__taxonomy-item","children":["#","Multi-Modal Dataset"]}],["$","span","Multi-Domain Data",{"className":"page__taxonomy-item","children":["#","Multi-Domain Data"]}],["$","span","Geometric Foundation Models",{"className":"page__taxonomy-item","children":["#","Geometric Foundation Models"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Spatio-Temporal Data",{"className":"page__taxonomy-item","children":["#","Spatio-Temporal Data"]}],["$","span","Dataset Benchmark",{"className":"page__taxonomy-item","children":["#","Dataset Benchmark"]}]]}]]}]]}],["$","article","2025-9-16-Measuring_Epistemic_Humility_in_Multimodal_Large_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-16-Measuring_Epistemic_Humility_in_Multimodal_Large_Language_Models/","children":"[논문리뷰] Measuring Epistemic Humility in Multimodal Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kaiyang Zhou이 [arXiv]에 게시한 'Measuring Epistemic Humility in Multimodal Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-16 13:16:41+0900","children":"2025년 9월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models"]}],["$","span","Hallucination",{"className":"page__taxonomy-item","children":["#","Hallucination"]}],["$","span","Epistemic Humility",{"className":"page__taxonomy-item","children":["#","Epistemic Humility"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","False-Option Rejection",{"className":"page__taxonomy-item","children":["#","False-Option Rejection"]}],["$","span","Visual Question Answering",{"className":"page__taxonomy-item","children":["#","Visual Question Answering"]}],["$","span","Scene Graph",{"className":"page__taxonomy-item","children":["#","Scene Graph"]}]]}]]}]]}],["$","article","2025-9-16-Lost_in_Embeddings_Information_Loss_in_Vision-Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-16-Lost_in_Embeddings_Information_Loss_in_Vision-Language_Models/","children":"[논문리뷰] Lost in Embeddings: Information Loss in Vision-Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ivan Vulić이 [arXiv]에 게시한 'Lost in Embeddings: Information Loss in Vision-Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-16 13:16:41+0900","children":"2025년 9월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Information Loss",{"className":"page__taxonomy-item","children":["#","Information Loss"]}],["$","span","Embeddings",{"className":"page__taxonomy-item","children":["#","Embeddings"]}],["$","span","Connectors",{"className":"page__taxonomy-item","children":["#","Connectors"]}],["$","span","k-NN Overlap Ratio",{"className":"page__taxonomy-item","children":["#","k-NN Overlap Ratio"]}],["$","span","Embedding Reconstruction",{"className":"page__taxonomy-item","children":["#","Embedding Reconstruction"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}]]}]]}]]}],["$","article","2025-9-16-Look_Again_Think_Slowly_Enhancing_Visual_Reflection_in_Vision-Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-16-Look_Again_Think_Slowly_Enhancing_Visual_Reflection_in_Vision-Language_Models/","children":"[논문리뷰] Look Again, Think Slowly: Enhancing Visual Reflection in Vision-Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shuo Ren이 [arXiv]에 게시한 'Look Again, Think Slowly: Enhancing Visual Reflection in Vision-Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-16 13:16:41+0900","children":"2025년 9월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Visual Reasoning",{"className":"page__taxonomy-item","children":["#","Visual Reasoning"]}],["$","span","Reflection",{"className":"page__taxonomy-item","children":["#","Reflection"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Visual Attention",{"className":"page__taxonomy-item","children":["#","Visual Attention"]}],["$","span","Slow Thinking",{"className":"page__taxonomy-item","children":["#","Slow Thinking"]}],["$","span","Multimodal Agents",{"className":"page__taxonomy-item","children":["#","Multimodal Agents"]}]]}]]}]]}],["$","article","2025-9-16-Locality_in_Image_Diffusion_Models_Emerges_from_Data_Statistics",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-16-Locality_in_Image_Diffusion_Models_Emerges_from_Data_Statistics/","children":"[논문리뷰] Locality in Image Diffusion Models Emerges from Data Statistics"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Vincent Sitzmann이 [arXiv]에 게시한 'Locality in Image Diffusion Models Emerges from Data Statistics' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-16 13:16:41+0900","children":"2025년 9월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Locality",{"className":"page__taxonomy-item","children":["#","Locality"]}],["$","span","Data Statistics",{"className":"page__taxonomy-item","children":["#","Data Statistics"]}],["$","span","Optimal Denoiser",{"className":"page__taxonomy-item","children":["#","Optimal Denoiser"]}],["$","span","Wiener Filter",{"className":"page__taxonomy-item","children":["#","Wiener Filter"]}],["$","span","Sensitivity Fields",{"className":"page__taxonomy-item","children":["#","Sensitivity Fields"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Inductive Bias",{"className":"page__taxonomy-item","children":["#","Inductive Bias"]}]]}]]}]]}],["$","article","2025-9-16-Learning_to_Optimize_Multi-Objective_Alignment_Through_Dynamic_Reward_Weighting",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-16-Learning_to_Optimize_Multi-Objective_Alignment_Through_Dynamic_Reward_Weighting/","children":"[논문리뷰] Learning to Optimize Multi-Objective Alignment Through Dynamic Reward Weighting"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Changlong Yu이 [arXiv]에 게시한 'Learning to Optimize Multi-Objective Alignment Through Dynamic Reward Weighting' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-16 13:16:41+0900","children":"2025년 9월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-objective Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Multi-objective Reinforcement Learning"]}],["$","span","LLM Alignment",{"className":"page__taxonomy-item","children":["#","LLM Alignment"]}],["$","span","Dynamic Reward Weighting",{"className":"page__taxonomy-item","children":["#","Dynamic Reward Weighting"]}],["$","span","Pareto Front Optimization",{"className":"page__taxonomy-item","children":["#","Pareto Front Optimization"]}],["$","span","Hypervolume Indicator",{"className":"page__taxonomy-item","children":["#","Hypervolume Indicator"]}],["$","span","Gradient-based Optimization",{"className":"page__taxonomy-item","children":["#","Gradient-based Optimization"]}],["$","span","Online RL",{"className":"page__taxonomy-item","children":["#","Online RL"]}]]}]]}]]}],["$","article","2025-9-16-LazyDrag_Enabling_Stable_Drag-Based_Editing_on_Multi-Modal_Diffusion_Transformers_via_Explicit_Correspondence",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-16-LazyDrag_Enabling_Stable_Drag-Based_Editing_on_Multi-Modal_Diffusion_Transformers_via_Explicit_Correspondence/","children":"[논문리뷰] LazyDrag: Enabling Stable Drag-Based Editing on Multi-Modal Diffusion Transformers via Explicit Correspondence"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Lionel M. Ni이 [arXiv]에 게시한 'LazyDrag: Enabling Stable Drag-Based Editing on Multi-Modal Diffusion Transformers via Explicit Correspondence' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-16 13:16:41+0900","children":"2025년 9월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Multi-Modal Transformers",{"className":"page__taxonomy-item","children":["#","Multi-Modal Transformers"]}],["$","span","Drag-based Editing",{"className":"page__taxonomy-item","children":["#","Drag-based Editing"]}],["$","span","Explicit Correspondence",{"className":"page__taxonomy-item","children":["#","Explicit Correspondence"]}],["$","span","Attention Control",{"className":"page__taxonomy-item","children":["#","Attention Control"]}],["$","span","Identity Preservation",{"className":"page__taxonomy-item","children":["#","Identity Preservation"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}]]}]]}]]}],["$","article","2025-9-16-InternScenes_A_Large-scale_Simulatable_Indoor_Scene_Dataset_with_Realistic_Layouts",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-16-InternScenes_A_Large-scale_Simulatable_Indoor_Scene_Dataset_with_Realistic_Layouts/","children":"[논문리뷰] InternScenes: A Large-scale Simulatable Indoor Scene Dataset with Realistic Layouts"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wenzhe Cai이 [arXiv]에 게시한 'InternScenes: A Large-scale Simulatable Indoor Scene Dataset with Realistic Layouts' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-16 13:16:41+0900","children":"2025년 9월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","3D Scene Dataset",{"className":"page__taxonomy-item","children":["#","3D Scene Dataset"]}],["$","span","Simulation Environment",{"className":"page__taxonomy-item","children":["#","Simulation Environment"]}],["$","span","Scene Generation",{"className":"page__taxonomy-item","children":["#","Scene Generation"]}],["$","span","Point-Goal Navigation",{"className":"page__taxonomy-item","children":["#","Point-Goal Navigation"]}],["$","span","Realistic Layouts",{"className":"page__taxonomy-item","children":["#","Realistic Layouts"]}],["$","span","Object Interaction",{"className":"page__taxonomy-item","children":["#","Object Interaction"]}],["$","span","Real-to-Sim",{"className":"page__taxonomy-item","children":["#","Real-to-Sim"]}]]}]]}]]}],["$","article","2025-9-16-GAPrune_Gradient-Alignment_Pruning_for_Domain-Aware_Embeddings",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-16-GAPrune_Gradient-Alignment_Pruning_for_Domain-Aware_Embeddings/","children":"[논문리뷰] GAPrune: Gradient-Alignment Pruning for Domain-Aware Embeddings"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yixuan Tang이 [arXiv]에 게시한 'GAPrune: Gradient-Alignment Pruning for Domain-Aware Embeddings' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-16 13:16:41+0900","children":"2025년 9월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Model Pruning",{"className":"page__taxonomy-item","children":["#","Model Pruning"]}],["$","span","Domain Adaptation",{"className":"page__taxonomy-item","children":["#","Domain Adaptation"]}],["$","span","Embedding Models",{"className":"page__taxonomy-item","children":["#","Embedding Models"]}],["$","span","Gradient Alignment",{"className":"page__taxonomy-item","children":["#","Gradient Alignment"]}],["$","span","Fisher Information",{"className":"page__taxonomy-item","children":["#","Fisher Information"]}],["$","span","Model Compression",{"className":"page__taxonomy-item","children":["#","Model Compression"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}]]}]]}]]}],["$","article","2025-9-16-EthicsMH_A_Pilot_Benchmark_for_Ethical_Reasoning_in_Mental_Health_AI",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-16-EthicsMH_A_Pilot_Benchmark_for_Ethical_Reasoning_in_Mental_Health_AI/","children":"[논문리뷰] EthicsMH: A Pilot Benchmark for Ethical Reasoning in Mental Health AI"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"UVSKKR이 [arXiv]에 게시한 'EthicsMH: A Pilot Benchmark for Ethical Reasoning in Mental Health AI' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-16 13:16:41+0900","children":"2025년 9월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Ethical Reasoning",{"className":"page__taxonomy-item","children":["#","Ethical Reasoning"]}],["$","span","Mental Health AI",{"className":"page__taxonomy-item","children":["#","Mental Health AI"]}],["$","span","Benchmark Dataset",{"className":"page__taxonomy-item","children":["#","Benchmark Dataset"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","AI Ethics",{"className":"page__taxonomy-item","children":["#","AI Ethics"]}],["$","span","Clinical Decision Support",{"className":"page__taxonomy-item","children":["#","Clinical Decision Support"]}],["$","span","Human-in-the-loop",{"className":"page__taxonomy-item","children":["#","Human-in-the-loop"]}]]}]]}]]}],["$","article","2025-9-16-Dr.V_A_Hierarchical_Perception-Temporal-Cognition_Framework_to_Diagnose_Video_Hallucination_by_Fine-grained_Spatial-Temporal_Grounding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-16-Dr.V_A_Hierarchical_Perception-Temporal-Cognition_Framework_to_Diagnose_Video_Hallucination_by_Fine-grained_Spatial-Temporal_Grounding/","children":"[논문리뷰] Dr.V: A Hierarchical Perception-Temporal-Cognition Framework to Diagnose Video Hallucination by Fine-grained Spatial-Temporal Grounding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Li Zheng이 [arXiv]에 게시한 'Dr.V: A Hierarchical Perception-Temporal-Cognition Framework to Diagnose Video Hallucination by Fine-grained Spatial-Temporal Grounding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-16 13:16:41+0900","children":"2025년 9월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Hallucination",{"className":"page__taxonomy-item","children":["#","Video Hallucination"]}],["$","span","Large Video Models (LVMs)",{"className":"page__taxonomy-item","children":["#","Large Video Models (LVMs)"]}],["$","span","Hierarchical Reasoning",{"className":"page__taxonomy-item","children":["#","Hierarchical Reasoning"]}],["$","span","Spatial-Temporal Grounding",{"className":"page__taxonomy-item","children":["#","Spatial-Temporal Grounding"]}],["$","span","Diagnostic Framework",{"className":"page__taxonomy-item","children":["#","Diagnostic Framework"]}],["$","span","Benchmark Dataset",{"className":"page__taxonomy-item","children":["#","Benchmark Dataset"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}]]}]]}]]}],["$","article","2025-9-16-CognitiveSky_Scalable_Sentiment_and_Narrative_Analysis_for_Decentralized_Social_Media",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-16-CognitiveSky_Scalable_Sentiment_and_Narrative_Analysis_for_Decentralized_Social_Media/","children":"[논문리뷰] CognitiveSky: Scalable Sentiment and Narrative Analysis for Decentralized Social Media"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Subasish Das이 [arXiv]에 게시한 'CognitiveSky: Scalable Sentiment and Narrative Analysis for Decentralized Social Media' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-16 13:16:41+0900","children":"2025년 9월 16일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Sentiment Analysis",{"className":"page__taxonomy-item","children":["#","Sentiment Analysis"]}],["$","span","Narrative Analysis",{"className":"page__taxonomy-item","children":["#","Narrative Analysis"]}],["$","span","Decentralized Social Media",{"className":"page__taxonomy-item","children":["#","Decentralized Social Media"]}],["$","span","Bluesky",{"className":"page__taxonomy-item","children":["#","Bluesky"]}],["$","span","Transformer Models",{"className":"page__taxonomy-item","children":["#","Transformer Models"]}],["$","span","Topic Modeling",{"className":"page__taxonomy-item","children":["#","Topic Modeling"]}],["$","span","Real-time Processing",{"className":"page__taxonomy-item","children":["#","Real-time Processing"]}],["$","span","Data Visualization",{"className":"page__taxonomy-item","children":["#","Data Visualization"]}]]}]]}]]}],["$","article","2025-9-15-X-Part_high_fidelity_and_structure_coherent_shape_decomposition",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-15-X-Part_high_fidelity_and_structure_coherent_shape_decomposition/","children":"[논문리뷰] X-Part: high fidelity and structure coherent shape decomposition"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yunhan Yang이 [arXiv]에 게시한 'X-Part: high fidelity and structure coherent shape decomposition' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-15 13:12:08+0900","children":"2025년 9월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Shape Decomposition",{"className":"page__taxonomy-item","children":["#","3D Shape Decomposition"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Part-level Generation",{"className":"page__taxonomy-item","children":["#","Part-level Generation"]}],["$","span","Controllable Generation",{"className":"page__taxonomy-item","children":["#","Controllable Generation"]}],["$","span","Bounding Box Prompts",{"className":"page__taxonomy-item","children":["#","Bounding Box Prompts"]}],["$","span","Semantic Features",{"className":"page__taxonomy-item","children":["#","Semantic Features"]}],["$","span","Interactive Editing",{"className":"page__taxonomy-item","children":["#","Interactive Editing"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}]]}]]}]]}],["$","article","2025-9-15-VStyle_A_Benchmark_for_Voice_Style_Adaptation_with_Spoken_Instructions",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-15-VStyle_A_Benchmark_for_Voice_Style_Adaptation_with_Spoken_Instructions/","children":"[논문리뷰] VStyle: A Benchmark for Voice Style Adaptation with Spoken Instructions"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Dong Zhang이 [arXiv]에 게시한 'VStyle: A Benchmark for Voice Style Adaptation with Spoken Instructions' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-15 13:12:08+0900","children":"2025년 9월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Voice Style Adaptation",{"className":"page__taxonomy-item","children":["#","Voice Style Adaptation"]}],["$","span","Spoken Language Models",{"className":"page__taxonomy-item","children":["#","Spoken Language Models"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","LALM-as-a-Judge",{"className":"page__taxonomy-item","children":["#","LALM-as-a-Judge"]}],["$","span","Speech Generation",{"className":"page__taxonomy-item","children":["#","Speech Generation"]}],["$","span","Multilingual",{"className":"page__taxonomy-item","children":["#","Multilingual"]}],["$","span","Evaluation Framework",{"className":"page__taxonomy-item","children":["#","Evaluation Framework"]}]]}]]}]]}],["$","article","2025-9-15-Virtual_Agent_Economies",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-15-Virtual_Agent_Economies/","children":"[논문리뷰] Virtual Agent Economies"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"William A. Cunningham이 [arXiv]에 게시한 'Virtual Agent Economies' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-15 13:12:08+0900","children":"2025년 9월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Agents",{"className":"page__taxonomy-item","children":["#","AI Agents"]}],["$","span","Virtual Economy",{"className":"page__taxonomy-item","children":["#","Virtual Economy"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Economic Mechanisms",{"className":"page__taxonomy-item","children":["#","Economic Mechanisms"]}],["$","span","Governance",{"className":"page__taxonomy-item","children":["#","Governance"]}],["$","span","Blockchain",{"className":"page__taxonomy-item","children":["#","Blockchain"]}],["$","span","Resource Allocation",{"className":"page__taxonomy-item","children":["#","Resource Allocation"]}],["$","span","Agent Alignment",{"className":"page__taxonomy-item","children":["#","Agent Alignment"]}]]}]]}]]}],["$","article","2025-9-15-The_Illusion_of_Diminishing_Returns_Measuring_Long_Horizon_Execution_in_LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-15-The_Illusion_of_Diminishing_Returns_Measuring_Long_Horizon_Execution_in_LLMs/","children":"[논문리뷰] The Illusion of Diminishing Returns: Measuring Long Horizon Execution in LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jonas Geiping이 [arXiv]에 게시한 'The Illusion of Diminishing Returns: Measuring Long Horizon Execution in LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-15 13:12:08+0900","children":"2025년 9월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Long-Horizon Tasks",{"className":"page__taxonomy-item","children":["#","Long-Horizon Tasks"]}],["$","span","Execution Capability",{"className":"page__taxonomy-item","children":["#","Execution Capability"]}],["$","span","Scaling Laws",{"className":"page__taxonomy-item","children":["#","Scaling Laws"]}],["$","span","Self-Conditioning",{"className":"page__taxonomy-item","children":["#","Self-Conditioning"]}],["$","span","Thinking Models",{"className":"page__taxonomy-item","children":["#","Thinking Models"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}]]}]]}]]}],["$","article","2025-9-15-QuantAgent_Price-Driven_Multi-Agent_LLMs_for_High-Frequency_Trading",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-15-QuantAgent_Price-Driven_Multi-Agent_LLMs_for_High-Frequency_Trading/","children":"[논문리뷰] QuantAgent: Price-Driven Multi-Agent LLMs for High-Frequency Trading"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chenyu You이 [arXiv]에 게시한 'QuantAgent: Price-Driven Multi-Agent LLMs for High-Frequency Trading' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-15 13:12:08+0900","children":"2025년 9월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","High-Frequency Trading",{"className":"page__taxonomy-item","children":["#","High-Frequency Trading"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Technical Analysis",{"className":"page__taxonomy-item","children":["#","Technical Analysis"]}],["$","span","Algorithmic Trading",{"className":"page__taxonomy-item","children":["#","Algorithmic Trading"]}],["$","span","Financial Reasoning",{"className":"page__taxonomy-item","children":["#","Financial Reasoning"]}],["$","span","Price-Driven Signals",{"className":"page__taxonomy-item","children":["#","Price-Driven Signals"]}]]}]]}]]}],["$","article","2025-9-15-MCP-AgentBench_Evaluating_Real-World_Language_Agent_Performance_with_MCP-Mediated_Tools",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-15-MCP-AgentBench_Evaluating_Real-World_Language_Agent_Performance_with_MCP-Mediated_Tools/","children":"[논문리뷰] MCP-AgentBench: Evaluating Real-World Language Agent Performance with MCP-Mediated Tools"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiaorui Wang이 [arXiv]에 게시한 'MCP-AgentBench: Evaluating Real-World Language Agent Performance with MCP-Mediated Tools' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-15 13:12:08+0900","children":"2025년 9월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Language Agents",{"className":"page__taxonomy-item","children":["#","Language Agents"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Benchmarks",{"className":"page__taxonomy-item","children":["#","Benchmarks"]}],["$","span","Model Context Protocol (MCP)",{"className":"page__taxonomy-item","children":["#","Model Context Protocol (MCP)"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Real-World Performance",{"className":"page__taxonomy-item","children":["#","Real-World Performance"]}]]}]]}]]}],["$","article","2025-9-15-LoFT_Parameter-Efficient_Fine-Tuning_for_Long-tailed_Semi-Supervised_Learning_in_Open-World_Scenarios",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-15-LoFT_Parameter-Efficient_Fine-Tuning_for_Long-tailed_Semi-Supervised_Learning_in_Open-World_Scenarios/","children":"[논문리뷰] LoFT: Parameter-Efficient Fine-Tuning for Long-tailed Semi-Supervised Learning in Open-World Scenarios"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Bing Su이 [arXiv]에 게시한 'LoFT: Parameter-Efficient Fine-Tuning for Long-tailed Semi-Supervised Learning in Open-World Scenarios' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-15 13:12:08+0900","children":"2025년 9월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Long-tailed Learning",{"className":"page__taxonomy-item","children":["#","Long-tailed Learning"]}],["$","span","Semi-Supervised Learning",{"className":"page__taxonomy-item","children":["#","Semi-Supervised Learning"]}],["$","span","Parameter-Efficient Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Parameter-Efficient Fine-Tuning"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Open-World Scenarios",{"className":"page__taxonomy-item","children":["#","Open-World Scenarios"]}],["$","span","OOD Detection",{"className":"page__taxonomy-item","children":["#","OOD Detection"]}],["$","span","Confidence Calibration",{"className":"page__taxonomy-item","children":["#","Confidence Calibration"]}]]}]]}]]}],["$","article","2025-9-15-IntrEx_A_Dataset_for_Modeling_Engagement_in_Educational_Conversations",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-15-IntrEx_A_Dataset_for_Modeling_Engagement_in_Educational_Conversations/","children":"[논문리뷰] IntrEx: A Dataset for Modeling Engagement in Educational Conversations"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Gabriele Pergola이 [arXiv]에 게시한 'IntrEx: A Dataset for Modeling Engagement in Educational Conversations' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-15 13:12:08+0900","children":"2025년 9월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Educational Dialogue",{"className":"page__taxonomy-item","children":["#","Educational Dialogue"]}],["$","span","Engagement Modeling",{"className":"page__taxonomy-item","children":["#","Engagement Modeling"]}],["$","span","Dataset Annotation",{"className":"page__taxonomy-item","children":["#","Dataset Annotation"]}],["$","span","Second Language Learning",{"className":"page__taxonomy-item","children":["#","Second Language Learning"]}],["$","span","Human Feedback",{"className":"page__taxonomy-item","children":["#","Human Feedback"]}],["$","span","LLM Alignment",{"className":"page__taxonomy-item","children":["#","LLM Alignment"]}],["$","span","Readability Metrics",{"className":"page__taxonomy-item","children":["#","Readability Metrics"]}]]}]]}]]}],["$","article","2025-9-15-Inpainting-Guided_Policy_Optimization_for_Diffusion_Large_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-15-Inpainting-Guided_Policy_Optimization_for_Diffusion_Large_Language_Models/","children":"[논문리뷰] Inpainting-Guided Policy Optimization for Diffusion Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chenyu Wang이 [arXiv]에 게시한 'Inpainting-Guided Policy Optimization for Diffusion Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-15 13:12:08+0900","children":"2025년 9월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion LLMs",{"className":"page__taxonomy-item","children":["#","Diffusion LLMs"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Inpainting",{"className":"page__taxonomy-item","children":["#","Inpainting"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Exploration",{"className":"page__taxonomy-item","children":["#","Exploration"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","GRPO",{"className":"page__taxonomy-item","children":["#","GRPO"]}]]}]]}]]}],["$","article","2025-9-15-InfGen_A_Resolution-Agnostic_Paradigm_for_Scalable_Image_Synthesis",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-15-InfGen_A_Resolution-Agnostic_Paradigm_for_Scalable_Image_Synthesis/","children":"[논문리뷰] InfGen: A Resolution-Agnostic Paradigm for Scalable Image Synthesis"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Song Guo이 [arXiv]에 게시한 'InfGen: A Resolution-Agnostic Paradigm for Scalable Image Synthesis' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-15 13:12:08+0900","children":"2025년 9월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Synthesis",{"className":"page__taxonomy-item","children":["#","Image Synthesis"]}],["$","span","Resolution-Agnostic",{"className":"page__taxonomy-item","children":["#","Resolution-Agnostic"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Latent Space",{"className":"page__taxonomy-item","children":["#","Latent Space"]}],["$","span","VAE Decoder",{"className":"page__taxonomy-item","children":["#","VAE Decoder"]}],["$","span","High-Resolution Image Generation",{"className":"page__taxonomy-item","children":["#","High-Resolution Image Generation"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}]]}]]}]]}],["$","article","2025-9-15-HANRAG_Heuristic_Accurate_Noise-resistant_Retrieval-Augmented_Generation_for_Multi-hop_Question_Answering",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-15-HANRAG_Heuristic_Accurate_Noise-resistant_Retrieval-Augmented_Generation_for_Multi-hop_Question_Answering/","children":"[논문리뷰] HANRAG: Heuristic Accurate Noise-resistant Retrieval-Augmented Generation for Multi-hop Question Answering"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhehao Tan이 [arXiv]에 게시한 'HANRAG: Heuristic Accurate Noise-resistant Retrieval-Augmented Generation for Multi-hop Question Answering' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-15 13:12:08+0900","children":"2025년 9월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","Multi-hop QA",{"className":"page__taxonomy-item","children":["#","Multi-hop QA"]}],["$","span","Noise Resistance",{"className":"page__taxonomy-item","children":["#","Noise Resistance"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Query Decomposition",{"className":"page__taxonomy-item","children":["#","Query Decomposition"]}],["$","span","Adaptive Retrieval",{"className":"page__taxonomy-item","children":["#","Adaptive Retrieval"]}],["$","span","Heuristic Framework",{"className":"page__taxonomy-item","children":["#","Heuristic Framework"]}],["$","span","Revelator",{"className":"page__taxonomy-item","children":["#","Revelator"]}]]}]]}]]}],["$","article","2025-9-15-FLOWER_Democratizing_Generalist_Robot_Policies_with_Efficient_Vision-Language-Action_Flow_Policies",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-15-FLOWER_Democratizing_Generalist_Robot_Policies_with_Efficient_Vision-Language-Action_Flow_Policies/","children":"[논문리뷰] FLOWER: Democratizing Generalist Robot Policies with Efficient Vision-Language-Action Flow Policies"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Fabian Otto이 [arXiv]에 게시한 'FLOWER: Democratizing Generalist Robot Policies with Efficient Vision-Language-Action Flow Policies' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-15 13:12:08+0900","children":"2025년 9월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Generalist Robot Policies",{"className":"page__taxonomy-item","children":["#","Generalist Robot Policies"]}],["$","span","Vision-Language-Action Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action Models"]}],["$","span","Efficient AI",{"className":"page__taxonomy-item","children":["#","Efficient AI"]}],["$","span","Imitation Learning",{"className":"page__taxonomy-item","children":["#","Imitation Learning"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Intermediate Fusion",{"className":"page__taxonomy-item","children":["#","Intermediate Fusion"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}]]}]]}]]}],["$","article","2025-9-15-CMHG_A_Dataset_and_Benchmark_for_Headline_Generation_of_Minority_Languages_in_China",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-15-CMHG_A_Dataset_and_Benchmark_for_Headline_Generation_of_Minority_Languages_in_China/","children":"[논문리뷰] CMHG: A Dataset and Benchmark for Headline Generation of Minority Languages in China"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"XU Han이 [arXiv]에 게시한 'CMHG: A Dataset and Benchmark for Headline Generation of Minority Languages in China' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-15 13:12:08+0900","children":"2025년 9월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Headline Generation",{"className":"page__taxonomy-item","children":["#","Headline Generation"]}],["$","span","Minority Languages",{"className":"page__taxonomy-item","children":["#","Minority Languages"]}],["$","span","Low-Resource NLP",{"className":"page__taxonomy-item","children":["#","Low-Resource NLP"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Natural Language Generation",{"className":"page__taxonomy-item","children":["#","Natural Language Generation"]}],["$","span","Chinese Minority Languages",{"className":"page__taxonomy-item","children":["#","Chinese Minority Languages"]}]]}]]}]]}],["$","article","2025-9-12-VLA-Adapter_An_Effective_Paradigm_for_Tiny-Scale_Vision-Language-Action_Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-12-VLA-Adapter_An_Effective_Paradigm_for_Tiny-Scale_Vision-Language-Action_Model/","children":"[논문리뷰] VLA-Adapter: An Effective Paradigm for Tiny-Scale Vision-Language-Action Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zirui Ge이 [arXiv]에 게시한 'VLA-Adapter: An Effective Paradigm for Tiny-Scale Vision-Language-Action Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-12 13:12:46+0900","children":"2025년 9월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action Models"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Efficient AI",{"className":"page__taxonomy-item","children":["#","Efficient AI"]}],["$","span","Model Adaptation",{"className":"page__taxonomy-item","children":["#","Model Adaptation"]}],["$","span","Bridge Attention",{"className":"page__taxonomy-item","children":["#","Bridge Attention"]}],["$","span","Low-resource Training",{"className":"page__taxonomy-item","children":["#","Low-resource Training"]}]]}]]}]]}],["$","article","2025-9-12-Visual_Programmability_A_Guide_for_Code-as-Thought_in_Chart_Understanding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-12-Visual_Programmability_A_Guide_for_Code-as-Thought_in_Chart_Understanding/","children":"[논문리뷰] Visual Programmability: A Guide for Code-as-Thought in Chart Understanding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ethan Chern이 [arXiv]에 게시한 'Visual Programmability: A Guide for Code-as-Thought in Chart Understanding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-12 13:12:46+0900","children":"2025년 9월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Visual Programmability",{"className":"page__taxonomy-item","children":["#","Visual Programmability"]}],["$","span","Code-as-Thought (CaT)",{"className":"page__taxonomy-item","children":["#","Code-as-Thought (CaT)"]}],["$","span","Chart Understanding",{"className":"page__taxonomy-item","children":["#","Chart Understanding"]}],["$","span","Vision-Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision-Language Models (VLMs)"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Adaptive Reasoning",{"className":"page__taxonomy-item","children":["#","Adaptive Reasoning"]}],["$","span","Dual-Reward System",{"className":"page__taxonomy-item","children":["#","Dual-Reward System"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}]]}]]}]]}],["$","article","2025-9-12-The_Choice_of_Divergence_A_Neglected_Key_to_Mitigating_Diversity_Collapse_in_Reinforcement_Learning_with_Verifiable_Reward",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-12-The_Choice_of_Divergence_A_Neglected_Key_to_Mitigating_Diversity_Collapse_in_Reinforcement_Learning_with_Verifiable_Reward/","children":"[논문리뷰] The Choice of Divergence: A Neglected Key to Mitigating Diversity Collapse in Reinforcement Learning with Verifiable Reward"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiaoyu Tan이 [arXiv]에 게시한 'The Choice of Divergence: A Neglected Key to Mitigating Diversity Collapse in Reinforcement Learning with Verifiable Reward' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-12 13:12:46+0900","children":"2025년 9월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Diversity Collapse",{"className":"page__taxonomy-item","children":["#","Diversity Collapse"]}],["$","span","f-divergence",{"className":"page__taxonomy-item","children":["#","f-divergence"]}],["$","span","Forward-KL",{"className":"page__taxonomy-item","children":["#","Forward-KL"]}],["$","span","JS-divergence",{"className":"page__taxonomy-item","children":["#","JS-divergence"]}],["$","span","Pass@k",{"className":"page__taxonomy-item","children":["#","Pass@k"]}],["$","span","Catastrophic Forgetting",{"className":"page__taxonomy-item","children":["#","Catastrophic Forgetting"]}]]}]]}]]}],["$","article","2025-9-12-SpatialVID_A_Large-Scale_Video_Dataset_with_Spatial_Annotations",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-12-SpatialVID_A_Large-Scale_Video_Dataset_with_Spatial_Annotations/","children":"[논문리뷰] SpatialVID: A Large-Scale Video Dataset with Spatial Annotations"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jian Gao이 [arXiv]에 게시한 'SpatialVID: A Large-Scale Video Dataset with Spatial Annotations' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-12 13:12:46+0900","children":"2025년 9월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Dataset",{"className":"page__taxonomy-item","children":["#","Video Dataset"]}],["$","span","Spatial Annotation",{"className":"page__taxonomy-item","children":["#","Spatial Annotation"]}],["$","span","Camera Pose Estimation",{"className":"page__taxonomy-item","children":["#","Camera Pose Estimation"]}],["$","span","Depth Map",{"className":"page__taxonomy-item","children":["#","Depth Map"]}],["$","span","Structured Caption",{"className":"page__taxonomy-item","children":["#","Structured Caption"]}],["$","span","Motion Instruction",{"className":"page__taxonomy-item","children":["#","Motion Instruction"]}],["$","span","3D Vision",{"className":"page__taxonomy-item","children":["#","3D Vision"]}],["$","span","World Modeling",{"className":"page__taxonomy-item","children":["#","World Modeling"]}]]}]]}]]}],["$","article","2025-9-12-SimpleVLA-RL_Scaling_VLA_Training_via_Reinforcement_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-12-SimpleVLA-RL_Scaling_VLA_Training_via_Reinforcement_Learning/","children":"[논문리뷰] SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhaohui Yang이 [arXiv]에 게시한 'SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-12 13:12:46+0900","children":"2025년 9월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Vision-Language-Action (VLA) Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action (VLA) Models"]}],["$","span","Robotic Manipulation",{"className":"page__taxonomy-item","children":["#","Robotic Manipulation"]}],["$","span","Data Scarcity",{"className":"page__taxonomy-item","children":["#","Data Scarcity"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Sim-to-Real Transfer",{"className":"page__taxonomy-item","children":["#","Sim-to-Real Transfer"]}],["$","span","Online RL",{"className":"page__taxonomy-item","children":["#","Online RL"]}],["$","span","Long-Horizon Planning",{"className":"page__taxonomy-item","children":["#","Long-Horizon Planning"]}]]}]]}]]}],["$","article","2025-9-12-Reasoning_Introduces_New_Poisoning_Attacks_Yet_Makes_Them_More_Complicated",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-12-Reasoning_Introduces_New_Poisoning_Attacks_Yet_Makes_Them_More_Complicated/","children":"[논문리뷰] Reasoning Introduces New Poisoning Attacks Yet Makes Them More Complicated"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jamie Hayes이 [arXiv]에 게시한 'Reasoning Introduces New Poisoning Attacks Yet Makes Them More Complicated' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-12 13:12:46+0900","children":"2025년 9월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Security",{"className":"page__taxonomy-item","children":["#","LLM Security"]}],["$","span","Data Poisoning",{"className":"page__taxonomy-item","children":["#","Data Poisoning"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Reasoning Models",{"className":"page__taxonomy-item","children":["#","Reasoning Models"]}],["$","span","Backdoor Attacks",{"className":"page__taxonomy-item","children":["#","Backdoor Attacks"]}],["$","span","CoT Unfaithfulness",{"className":"page__taxonomy-item","children":["#","CoT Unfaithfulness"]}],["$","span","Emergent Robustness",{"className":"page__taxonomy-item","children":["#","Emergent Robustness"]}]]}]]}]]}],["$","article","2025-9-12-OmniEVA_Embodied_Versatile_Planner_via_Task-Adaptive_3D-Grounded_and_Embodiment-aware_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-12-OmniEVA_Embodied_Versatile_Planner_via_Task-Adaptive_3D-Grounded_and_Embodiment-aware_Reasoning/","children":"[논문리뷰] OmniEVA: Embodied Versatile Planner via Task-Adaptive 3D-Grounded and Embodiment-aware Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuzheng Zhuang이 [arXiv]에 게시한 'OmniEVA: Embodied Versatile Planner via Task-Adaptive 3D-Grounded and Embodiment-aware Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-12 13:12:46+0900","children":"2025년 9월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","3D Grounding",{"className":"page__taxonomy-item","children":["#","3D Grounding"]}],["$","span","Task-Adaptive Reasoning",{"className":"page__taxonomy-item","children":["#","Task-Adaptive Reasoning"]}],["$","span","Embodiment-Aware Planning",{"className":"page__taxonomy-item","children":["#","Embodiment-Aware Planning"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}]]}]]}]]}],["$","article","2025-9-12-Modality_Alignment_with_Multi-scale_Bilateral_Attention_for_Multimodal_Recommendation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-12-Modality_Alignment_with_Multi-scale_Bilateral_Attention_for_Multimodal_Recommendation/","children":"[논문리뷰] Modality Alignment with Multi-scale Bilateral Attention for Multimodal Recommendation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Dong-Ho Lee이 [arXiv]에 게시한 'Modality Alignment with Multi-scale Bilateral Attention for Multimodal Recommendation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-12 13:12:46+0900","children":"2025년 9월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Recommendation",{"className":"page__taxonomy-item","children":["#","Multimodal Recommendation"]}],["$","span","Modality Alignment",{"className":"page__taxonomy-item","children":["#","Modality Alignment"]}],["$","span","Attention Mechanism",{"className":"page__taxonomy-item","children":["#","Attention Mechanism"]}],["$","span","Dilated Convolution",{"className":"page__taxonomy-item","children":["#","Dilated Convolution"]}],["$","span","Maximum Mean Discrepancy",{"className":"page__taxonomy-item","children":["#","Maximum Mean Discrepancy"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Dimensionality Reduction",{"className":"page__taxonomy-item","children":["#","Dimensionality Reduction"]}]]}]]}]]}],["$","article","2025-9-12-LoCoBench_A_Benchmark_for_Long-Context_Large_Language_Models_in_Complex_Software_Engineering",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-12-LoCoBench_A_Benchmark_for_Long-Context_Large_Language_Models_in_Complex_Software_Engineering/","children":"[논문리뷰] LoCoBench: A Benchmark for Long-Context Large Language Models in Complex Software Engineering"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jianguo Zhang이 [arXiv]에 게시한 'LoCoBench: A Benchmark for Long-Context Large Language Models in Complex Software Engineering' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-12 13:12:46+0900","children":"2025년 9월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Long-Context LLMs",{"className":"page__taxonomy-item","children":["#","Long-Context LLMs"]}],["$","span","Software Engineering",{"className":"page__taxonomy-item","children":["#","Software Engineering"]}],["$","span","Code Evaluation",{"className":"page__taxonomy-item","children":["#","Code Evaluation"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Multi-file Reasoning",{"className":"page__taxonomy-item","children":["#","Multi-file Reasoning"]}],["$","span","Architectural Understanding",{"className":"page__taxonomy-item","children":["#","Architectural Understanding"]}],["$","span","Context Length",{"className":"page__taxonomy-item","children":["#","Context Length"]}],["$","span","Software Development Lifecycle",{"className":"page__taxonomy-item","children":["#","Software Development Lifecycle"]}],["$","span","Metrics",{"className":"page__taxonomy-item","children":["#","Metrics"]}]]}]]}]]}],["$","article","2025-9-12-Kling-Avatar_Grounding_Multimodal_Instructions_for_Cascaded_Long-Duration_Avatar_Animation_Synthesis",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-12-Kling-Avatar_Grounding_Multimodal_Instructions_for_Cascaded_Long-Duration_Avatar_Animation_Synthesis/","children":"[논문리뷰] Kling-Avatar: Grounding Multimodal Instructions for Cascaded Long-Duration Avatar Animation Synthesis"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wentao Hu이 [arXiv]에 게시한 'Kling-Avatar: Grounding Multimodal Instructions for Cascaded Long-Duration Avatar Animation Synthesis' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-12 13:12:46+0900","children":"2025년 9월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Avatar Animation",{"className":"page__taxonomy-item","children":["#","Avatar Animation"]}],["$","span","Multimodal Instructions",{"className":"page__taxonomy-item","children":["#","Multimodal Instructions"]}],["$","span","Long-Duration Video Generation",{"className":"page__taxonomy-item","children":["#","Long-Duration Video Generation"]}],["$","span","MLLM Director",{"className":"page__taxonomy-item","children":["#","MLLM Director"]}],["$","span","Cascaded Framework",{"className":"page__taxonomy-item","children":["#","Cascaded Framework"]}],["$","span","Lip Synchronization",{"className":"page__taxonomy-item","children":["#","Lip Synchronization"]}],["$","span","Instruction Grounding",{"className":"page__taxonomy-item","children":["#","Instruction Grounding"]}],["$","span","Video Diffusion Transformers",{"className":"page__taxonomy-item","children":["#","Video Diffusion Transformers"]}]]}]]}]]}],["$","article","2025-9-12-HuMo_Human-Centric_Video_Generation_via_Collaborative_Multi-Modal_Conditioning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-12-HuMo_Human-Centric_Video_Generation_via_Collaborative_Multi-Modal_Conditioning/","children":"[논문리뷰] HuMo: Human-Centric Video Generation via Collaborative Multi-Modal Conditioning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhuowei Chen이 [arXiv]에 게시한 'HuMo: Human-Centric Video Generation via Collaborative Multi-Modal Conditioning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-12 13:12:46+0900","children":"2025년 9월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Human-Centric Video Generation",{"className":"page__taxonomy-item","children":["#","Human-Centric Video Generation"]}],["$","span","Multimodal Conditioning",{"className":"page__taxonomy-item","children":["#","Multimodal Conditioning"]}],["$","span","Text-to-Video",{"className":"page__taxonomy-item","children":["#","Text-to-Video"]}],["$","span","Image-to-Video",{"className":"page__taxonomy-item","children":["#","Image-to-Video"]}],["$","span","Audio-to-Video",{"className":"page__taxonomy-item","children":["#","Audio-to-Video"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Subject Preservation",{"className":"page__taxonomy-item","children":["#","Subject Preservation"]}],["$","span","Audio-Visual Synchronization",{"className":"page__taxonomy-item","children":["#","Audio-Visual Synchronization"]}],["$","span","Progressive Training",{"className":"page__taxonomy-item","children":["#","Progressive Training"]}]]}]]}]]}],["$","article","2025-9-12-Harnessing_Uncertainty_Entropy-Modulated_Policy_Gradients_for_Long-Horizon_LLM_Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-12-Harnessing_Uncertainty_Entropy-Modulated_Policy_Gradients_for_Long-Horizon_LLM_Agents/","children":"[논문리뷰] Harnessing Uncertainty: Entropy-Modulated Policy Gradients for Long-Horizon LLM Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xintao Wang이 [arXiv]에 게시한 'Harnessing Uncertainty: Entropy-Modulated Policy Gradients for Long-Horizon LLM Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-12 13:12:46+0900","children":"2025년 9월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Policy Gradients",{"className":"page__taxonomy-item","children":["#","Policy Gradients"]}],["$","span","Entropy Modulation",{"className":"page__taxonomy-item","children":["#","Entropy Modulation"]}],["$","span","Credit Assignment",{"className":"page__taxonomy-item","children":["#","Credit Assignment"]}],["$","span","Uncertainty",{"className":"page__taxonomy-item","children":["#","Uncertainty"]}],["$","span","Long-Horizon Tasks",{"className":"page__taxonomy-item","children":["#","Long-Horizon Tasks"]}],["$","span","Self-Calibrating Gradient Scaling",{"className":"page__taxonomy-item","children":["#","Self-Calibrating Gradient Scaling"]}]]}]]}]]}],["$","article","2025-9-12-Gradient-Attention_Guided_Dual-Masking_Synergetic_Framework_for_Robust_Text-based_Person_Retrieval",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-12-Gradient-Attention_Guided_Dual-Masking_Synergetic_Framework_for_Robust_Text-based_Person_Retrieval/","children":"[논문리뷰] Gradient-Attention Guided Dual-Masking Synergetic Framework for Robust Text-based Person Retrieval"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kaicheng Yang이 [arXiv]에 게시한 'Gradient-Attention Guided Dual-Masking Synergetic Framework for Robust Text-based Person Retrieval' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-12 13:12:46+0900","children":"2025년 9월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-based Person Retrieval",{"className":"page__taxonomy-item","children":["#","Text-based Person Retrieval"]}],["$","span","CLIP",{"className":"page__taxonomy-item","children":["#","CLIP"]}],["$","span","MLLM",{"className":"page__taxonomy-item","children":["#","MLLM"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Dual-Masking",{"className":"page__taxonomy-item","children":["#","Dual-Masking"]}],["$","span","Gradient-Attention",{"className":"page__taxonomy-item","children":["#","Gradient-Attention"]}],["$","span","WebPerson Dataset",{"className":"page__taxonomy-item","children":["#","WebPerson Dataset"]}]]}]]}]]}],["$","article","2025-9-12-FLUX-Reason-6M_PRISM-Bench_A_Million-Scale_Text-to-Image_Reasoning_Dataset_and_Comprehensive_Benchmark",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-12-FLUX-Reason-6M_PRISM-Bench_A_Million-Scale_Text-to-Image_Reasoning_Dataset_and_Comprehensive_Benchmark/","children":"[논문리뷰] FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shuai Bai이 [arXiv]에 게시한 'FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-12 13:12:46+0900","children":"2025년 9월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Reasoning Dataset",{"className":"page__taxonomy-item","children":["#","Reasoning Dataset"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Generation Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Generation Chain-of-Thought"]}],["$","span","Vision-Language Model",{"className":"page__taxonomy-item","children":["#","Vision-Language Model"]}],["$","span","Image Aesthetics",{"className":"page__taxonomy-item","children":["#","Image Aesthetics"]}],["$","span","Prompt Alignment",{"className":"page__taxonomy-item","children":["#","Prompt Alignment"]}]]}]]}]]}],["$","article","2025-9-12-EchoX_Towards_Mitigating_Acoustic-Semantic_Gap_via_Echo_Training_for_Speech-to-Speech_LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-12-EchoX_Towards_Mitigating_Acoustic-Semantic_Gap_via_Echo_Training_for_Speech-to-Speech_LLMs/","children":"[논문리뷰] EchoX: Towards Mitigating Acoustic-Semantic Gap via Echo Training for Speech-to-Speech LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kaiqi Kou이 [arXiv]에 게시한 'EchoX: Towards Mitigating Acoustic-Semantic Gap via Echo Training for Speech-to-Speech LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-12 13:12:46+0900","children":"2025년 9월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Speech-to-Speech LLMs",{"className":"page__taxonomy-item","children":["#","Speech-to-Speech LLMs"]}],["$","span","Acoustic-Semantic Gap",{"className":"page__taxonomy-item","children":["#","Acoustic-Semantic Gap"]}],["$","span","Echo Training",{"className":"page__taxonomy-item","children":["#","Echo Training"]}],["$","span","Unit Language",{"className":"page__taxonomy-item","children":["#","Unit Language"]}],["$","span","Streaming Inference",{"className":"page__taxonomy-item","children":["#","Streaming Inference"]}],["$","span","Knowledge-based QA",{"className":"page__taxonomy-item","children":["#","Knowledge-based QA"]}]]}]]}]]}],["$","article","2025-9-12-Can_Understanding_and_Generation_Truly_Benefit_Together_--_or_Just_Coexist",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-12-Can_Understanding_and_Generation_Truly_Benefit_Together_--_or_Just_Coexist/","children":"[논문리뷰] Can Understanding and Generation Truly Benefit Together -- or Just Coexist?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hui Han이 [arXiv]에 게시한 'Can Understanding and Generation Truly Benefit Together -- or Just Coexist?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-12 13:12:46+0900","children":"2025년 9월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Understanding",{"className":"page__taxonomy-item","children":["#","Multimodal Understanding"]}],["$","span","Multimodal Generation",{"className":"page__taxonomy-item","children":["#","Multimodal Generation"]}],["$","span","Unified Models",{"className":"page__taxonomy-item","children":["#","Unified Models"]}],["$","span","Auto-Encoder",{"className":"page__taxonomy-item","children":["#","Auto-Encoder"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Image-to-Text",{"className":"page__taxonomy-item","children":["#","Image-to-Text"]}],["$","span","Text-to-Image",{"className":"page__taxonomy-item","children":["#","Text-to-Image"]}],["$","span","Reconstruction Fidelity",{"className":"page__taxonomy-item","children":["#","Reconstruction Fidelity"]}]]}]]}]]}],["$","article","2025-9-12-2D_Gaussian_Splatting_with_Semantic_Alignment_for_Image_Inpainting",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-12-2D_Gaussian_Splatting_with_Semantic_Alignment_for_Image_Inpainting/","children":"[논문리뷰] 2D Gaussian Splatting with Semantic Alignment for Image Inpainting"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Guangming Lu이 [arXiv]에 게시한 '2D Gaussian Splatting with Semantic Alignment for Image Inpainting' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-12 13:12:46+0900","children":"2025년 9월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Inpainting",{"className":"page__taxonomy-item","children":["#","Image Inpainting"]}],["$","span","2D Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","2D Gaussian Splatting"]}],["$","span","Semantic Alignment",{"className":"page__taxonomy-item","children":["#","Semantic Alignment"]}],["$","span","DINO Features",{"className":"page__taxonomy-item","children":["#","DINO Features"]}],["$","span","Patch-level Rasterization",{"className":"page__taxonomy-item","children":["#","Patch-level Rasterization"]}],["$","span","Continuous Representation",{"className":"page__taxonomy-item","children":["#","Continuous Representation"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}]]}]]}]]}],["$","article","2025-9-11-think_So_lets_replace_this_phrase_with_insult..._think_Lessons_learned_from_generation_of_toxic_texts_with_LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-11-think_So_lets_replace_this_phrase_with_insult..._think_Lessons_learned_from_generation_of_toxic_texts_with_LLMs/","children":"[논문리뷰] <think> So let's replace this phrase with insult... </think> Lessons learned from generation of toxic texts with LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Alexander Panchenko이 [arXiv]에 게시한 '<think> So let's replace this phrase with insult... </think> Lessons learned from generation of toxic texts with LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-11 13:02:36+0900","children":"2025년 9월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Toxic Text Generation",{"className":"page__taxonomy-item","children":["#","Toxic Text Generation"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Text Detoxification",{"className":"page__taxonomy-item","children":["#","Text Detoxification"]}],["$","span","Lexical Diversity",{"className":"page__taxonomy-item","children":["#","Lexical Diversity"]}],["$","span","Synthetic Data",{"className":"page__taxonomy-item","children":["#","Synthetic Data"]}],["$","span","Human Annotation",{"className":"page__taxonomy-item","children":["#","Human Annotation"]}],["$","span","Style Transfer",{"className":"page__taxonomy-item","children":["#","Style Transfer"]}]]}]]}]]}],["$","article","2025-9-11-RewardDance_Reward_Scaling_in_Visual_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-11-RewardDance_Reward_Scaling_in_Visual_Generation/","children":"[논문리뷰] RewardDance: Reward Scaling in Visual Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Liang Li이 [arXiv]에 게시한 'RewardDance: Reward Scaling in Visual Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-11 13:02:36+0900","children":"2025년 9월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reward Model",{"className":"page__taxonomy-item","children":["#","Reward Model"]}],["$","span","Visual Generation",{"className":"page__taxonomy-item","children":["#","Visual Generation"]}],["$","span","RLHF",{"className":"page__taxonomy-item","children":["#","RLHF"]}],["$","span","VLM",{"className":"page__taxonomy-item","children":["#","VLM"]}],["$","span","Reward Scaling",{"className":"page__taxonomy-item","children":["#","Reward Scaling"]}],["$","span","Reward Hacking",{"className":"page__taxonomy-item","children":["#","Reward Hacking"]}],["$","span","Generative Paradigm",{"className":"page__taxonomy-item","children":["#","Generative Paradigm"]}],["$","span","Context Scaling",{"className":"page__taxonomy-item","children":["#","Context Scaling"]}],["$","span","Text-to-Image",{"className":"page__taxonomy-item","children":["#","Text-to-Image"]}],["$","span","Text-to-Video",{"className":"page__taxonomy-item","children":["#","Text-to-Video"]}]]}]]}]]}],["$","article","2025-9-11-P3-SAM_Native_3D_Part_Segmentation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-11-P3-SAM_Native_3D_Part_Segmentation/","children":"[논문리뷰] P3-SAM: Native 3D Part Segmentation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yunhan Yang이 [arXiv]에 게시한 'P3-SAM: Native 3D Part Segmentation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-11 13:02:36+0900","children":"2025년 9월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Part Segmentation",{"className":"page__taxonomy-item","children":["#","3D Part Segmentation"]}],["$","span","Point Cloud Segmentation",{"className":"page__taxonomy-item","children":["#","Point Cloud Segmentation"]}],["$","span","Prompt-based Segmentation",{"className":"page__taxonomy-item","children":["#","Prompt-based Segmentation"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Interactive Segmentation",{"className":"page__taxonomy-item","children":["#","Interactive Segmentation"]}],["$","span","Automatic Segmentation",{"className":"page__taxonomy-item","children":["#","Automatic Segmentation"]}],["$","span","Native 3D",{"className":"page__taxonomy-item","children":["#","Native 3D"]}]]}]]}]]}],["$","article","2025-9-11-Hunyuan-MT_Technical_Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-11-Hunyuan-MT_Technical_Report/","children":"[논문리뷰] Hunyuan-MT Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yang Du이 [arXiv]에 게시한 'Hunyuan-MT Technical Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-11 13:02:36+0900","children":"2025년 9월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Machine Translation",{"className":"page__taxonomy-item","children":["#","Machine Translation"]}],["$","span","Large Language Model",{"className":"page__taxonomy-item","children":["#","Large Language Model"]}],["$","span","Multilingual",{"className":"page__taxonomy-item","children":["#","Multilingual"]}],["$","span","Low-Resource Languages",{"className":"page__taxonomy-item","children":["#","Low-Resource Languages"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Weak-to-Strong Learning",{"className":"page__taxonomy-item","children":["#","Weak-to-Strong Learning"]}],["$","span","Slow Thinking",{"className":"page__taxonomy-item","children":["#","Slow Thinking"]}]]}]]}]]}],["$","article","2025-9-11-HumanAgencyBench_Scalable_Evaluation_of_Human_Agency_Support_in_AI_Assistants",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-11-HumanAgencyBench_Scalable_Evaluation_of_Human_Agency_Support_in_AI_Assistants/","children":"[논문리뷰] HumanAgencyBench: Scalable Evaluation of Human Agency Support in AI Assistants"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jacy Reese Anthis이 [arXiv]에 게시한 'HumanAgencyBench: Scalable Evaluation of Human Agency Support in AI Assistants' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-11 13:02:36+0900","children":"2025년 9월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Human Agency",{"className":"page__taxonomy-item","children":["#","Human Agency"]}],["$","span","AI Assistants",{"className":"page__taxonomy-item","children":["#","AI Assistants"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Sociotechnical AI",{"className":"page__taxonomy-item","children":["#","Sociotechnical AI"]}],["$","span","AI Alignment",{"className":"page__taxonomy-item","children":["#","AI Alignment"]}],["$","span","Scalable Evaluation",{"className":"page__taxonomy-item","children":["#","Scalable Evaluation"]}]]}]]}]]}],["$","article","2025-9-11-EnvX_Agentize_Everything_with_Agentic_AI",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-11-EnvX_Agentize_Everything_with_Agentic_AI/","children":"[논문리뷰] EnvX: Agentize Everything with Agentic AI"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wenzheng Tom Tang이 [arXiv]에 게시한 'EnvX: Agentize Everything with Agentic AI' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-11 13:02:36+0900","children":"2025년 9월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Code Repository",{"className":"page__taxonomy-item","children":["#","Code Repository"]}],["$","span","Agentization",{"className":"page__taxonomy-item","children":["#","Agentization"]}],["$","span","Natural Language Interaction",{"className":"page__taxonomy-item","children":["#","Natural Language Interaction"]}],["$","span","Agent-to-Agent Protocol",{"className":"page__taxonomy-item","children":["#","Agent-to-Agent Protocol"]}],["$","span","LLM-based Agents",{"className":"page__taxonomy-item","children":["#","LLM-based Agents"]}]]}]]}]]}],["$","article","2025-9-11-A_Survey_of_Reinforcement_Learning_for_Large_Reasoning_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-11-A_Survey_of_Reinforcement_Learning_for_Large_Reasoning_Models/","children":"[논문리뷰] A Survey of Reinforcement Learning for Large Reasoning Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Runze Liu이 [arXiv]에 게시한 'A Survey of Reinforcement Learning for Large Reasoning Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-11 13:02:36+0900","children":"2025년 9월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Reasoning Models",{"className":"page__taxonomy-item","children":["#","Large Reasoning Models"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Reward Design",{"className":"page__taxonomy-item","children":["#","Reward Design"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Verifiable Rewards",{"className":"page__taxonomy-item","children":["#","Verifiable Rewards"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}]]}]]}]]}],["$","article","2025-9-11-AgentGym-RL_Training_LLM_Agents_for_Long-Horizon_Decision_Making_through_Multi-Turn_Reinforcement_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-11-AgentGym-RL_Training_LLM_Agents_for_Long-Horizon_Decision_Making_through_Multi-Turn_Reinforcement_Learning/","children":"[논문리뷰] AgentGym-RL: Training LLM Agents for Long-Horizon Decision Making through Multi-Turn Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Honglin Guo이 [arXiv]에 게시한 'AgentGym-RL: Training LLM Agents for Long-Horizon Decision Making through Multi-Turn Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-11 13:02:36+0900","children":"2025년 9월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Multi-Turn Interaction",{"className":"page__taxonomy-item","children":["#","Multi-Turn Interaction"]}],["$","span","Long-Horizon Decision Making",{"className":"page__taxonomy-item","children":["#","Long-Horizon Decision Making"]}],["$","span","Agent Framework",{"className":"page__taxonomy-item","children":["#","Agent Framework"]}],["$","span","Exploration-Exploitation",{"className":"page__taxonomy-item","children":["#","Exploration-Exploitation"]}],["$","span","Progressive Scaling",{"className":"page__taxonomy-item","children":["#","Progressive Scaling"]}]]}]]}]]}],["$","article","2025-9-11-3D_and_4D_World_Modeling_A_Survey",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-11-3D_and_4D_World_Modeling_A_Survey/","children":"[논문리뷰] 3D and 4D World Modeling: A Survey"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ao Liang이 [arXiv]에 게시한 '3D and 4D World Modeling: A Survey' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-11 13:02:36+0900","children":"2025년 9월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D World Modeling",{"className":"page__taxonomy-item","children":["#","3D World Modeling"]}],["$","span","4D World Modeling",{"className":"page__taxonomy-item","children":["#","4D World Modeling"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Predictive Models",{"className":"page__taxonomy-item","children":["#","Predictive Models"]}],["$","span","LiDAR",{"className":"page__taxonomy-item","children":["#","LiDAR"]}],["$","span","Occupancy Grids",{"className":"page__taxonomy-item","children":["#","Occupancy Grids"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Autonomous Driving",{"className":"page__taxonomy-item","children":["#","Autonomous Driving"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}]]}]]}]]}],["$","article","2025-9-10-ΔL_Normalization_Rethink_Loss_Aggregation_in_RLVR",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-10-ΔL_Normalization_Rethink_Loss_Aggregation_in_RLVR/","children":"[논문리뷰] ΔL Normalization: Rethink Loss Aggregation in RLVR"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Lili Qiu이 [arXiv]에 게시한 'ΔL Normalization: Rethink Loss Aggregation in RLVR' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-10 13:11:01+0900","children":"2025년 9월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Gradient Variance",{"className":"page__taxonomy-item","children":["#","Gradient Variance"]}],["$","span","Loss Aggregation",{"className":"page__taxonomy-item","children":["#","Loss Aggregation"]}],["$","span","Unbiased Estimator",{"className":"page__taxonomy-item","children":["#","Unbiased Estimator"]}],["$","span","RLVR",{"className":"page__taxonomy-item","children":["#","RLVR"]}],["$","span","Policy Gradient",{"className":"page__taxonomy-item","children":["#","Policy Gradient"]}],["$","span","Normalization",{"className":"page__taxonomy-item","children":["#","Normalization"]}]]}]]}]]}],["$","article","2025-9-10-Visual_Representation_Alignment_for_Multimodal_Large_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-10-Visual_Representation_Alignment_for_Multimodal_Large_Language_Models/","children":"[논문리뷰] Visual Representation Alignment for Multimodal Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Heeseong Shin이 [arXiv]에 게시한 'Visual Representation Alignment for Multimodal Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-10 13:11:01+0900","children":"2025년 9월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Visual Representation Alignment",{"className":"page__taxonomy-item","children":["#","Visual Representation Alignment"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Regularization",{"className":"page__taxonomy-item","children":["#","Regularization"]}],["$","span","Fine-grained Visual Understanding",{"className":"page__taxonomy-item","children":["#","Fine-grained Visual Understanding"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}],["$","span","Object Counting",{"className":"page__taxonomy-item","children":["#","Object Counting"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}]]}]]}]]}],["$","article","2025-9-10-UMO_Scaling_Multi-Identity_Consistency_for_Image_Customization_via_Matching_Reward",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-10-UMO_Scaling_Multi-Identity_Consistency_for_Image_Customization_via_Matching_Reward/","children":"[논문리뷰] UMO: Scaling Multi-Identity Consistency for Image Customization via Matching Reward"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Fei Ding이 [arXiv]에 게시한 'UMO: Scaling Multi-Identity Consistency for Image Customization via Matching Reward' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-10 13:11:01+0900","children":"2025년 9월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Customization",{"className":"page__taxonomy-item","children":["#","Image Customization"]}],["$","span","Multi-Identity Generation",{"className":"page__taxonomy-item","children":["#","Multi-Identity Generation"]}],["$","span","Identity Consistency",{"className":"page__taxonomy-item","children":["#","Identity Consistency"]}],["$","span","Identity Confusion",{"className":"page__taxonomy-item","children":["#","Identity Confusion"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Matching Reward",{"className":"page__taxonomy-item","children":["#","Matching Reward"]}],["$","span","Global Assignment",{"className":"page__taxonomy-item","children":["#","Global Assignment"]}]]}]]}]]}],["$","article","2025-9-10-Staying_in_the_Sweet_Spot_Responsive_Reasoning_Evolution_via_Capability-Adaptive_Hint_Scaffolding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-10-Staying_in_the_Sweet_Spot_Responsive_Reasoning_Evolution_via_Capability-Adaptive_Hint_Scaffolding/","children":"[논문리뷰] Staying in the Sweet Spot: Responsive Reasoning Evolution via Capability-Adaptive Hint Scaffolding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yongcheng Zeng이 [arXiv]에 게시한 'Staying in the Sweet Spot: Responsive Reasoning Evolution via Capability-Adaptive Hint Scaffolding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-10 13:11:01+0900","children":"2025년 9월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","RLVR",{"className":"page__taxonomy-item","children":["#","RLVR"]}],["$","span","LLM Reasoning",{"className":"page__taxonomy-item","children":["#","LLM Reasoning"]}],["$","span","Adaptive Learning",{"className":"page__taxonomy-item","children":["#","Adaptive Learning"]}],["$","span","Hint Scaffolding",{"className":"page__taxonomy-item","children":["#","Hint Scaffolding"]}],["$","span","Item Response Theory",{"className":"page__taxonomy-item","children":["#","Item Response Theory"]}],["$","span","Exploration Efficiency",{"className":"page__taxonomy-item","children":["#","Exploration Efficiency"]}],["$","span","Problem Difficulty",{"className":"page__taxonomy-item","children":["#","Problem Difficulty"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}]]}]]}]]}],["$","article","2025-9-10-SimpleQA_Verified_A_Reliable_Factuality_Benchmark_to_Measure_Parametric_Knowledge",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-10-SimpleQA_Verified_A_Reliable_Factuality_Benchmark_to_Measure_Parametric_Knowledge/","children":"[논문리뷰] SimpleQA Verified: A Reliable Factuality Benchmark to Measure Parametric Knowledge"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Dipanjan Das이 [arXiv]에 게시한 'SimpleQA Verified: A Reliable Factuality Benchmark to Measure Parametric Knowledge' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-10 13:11:01+0900","children":"2025년 9월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Factuality",{"className":"page__taxonomy-item","children":["#","LLM Factuality"]}],["$","span","Parametric Knowledge",{"className":"page__taxonomy-item","children":["#","Parametric Knowledge"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Question Answering",{"className":"page__taxonomy-item","children":["#","Question Answering"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Evaluation Metrics",{"className":"page__taxonomy-item","children":["#","Evaluation Metrics"]}],["$","span","Hallucination Mitigation",{"className":"page__taxonomy-item","children":["#","Hallucination Mitigation"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}]]}]]}]]}],["$","article","2025-9-10-Reconstruction_Alignment_Improves_Unified_Multimodal_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-10-Reconstruction_Alignment_Improves_Unified_Multimodal_Models/","children":"[논문리뷰] Reconstruction Alignment Improves Unified Multimodal Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"XuDong Wang이 [arXiv]에 게시한 'Reconstruction Alignment Improves Unified Multimodal Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-10 13:11:01+0900","children":"2025년 9월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Unified Multimodal Models",{"className":"page__taxonomy-item","children":["#","Unified Multimodal Models"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Post-training",{"className":"page__taxonomy-item","children":["#","Post-training"]}],["$","span","Self-supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-supervised Learning"]}],["$","span","Reconstruction Alignment",{"className":"page__taxonomy-item","children":["#","Reconstruction Alignment"]}],["$","span","Visual Embeddings",{"className":"page__taxonomy-item","children":["#","Visual Embeddings"]}]]}]]}]]}],["$","article","2025-9-10-Q-Sched_Pushing_the_Boundaries_of_Few-Step_Diffusion_Models_with_Quantization-Aware_Scheduling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-10-Q-Sched_Pushing_the_Boundaries_of_Few-Step_Diffusion_Models_with_Quantization-Aware_Scheduling/","children":"[논문리뷰] Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Diana Marculescu이 [arXiv]에 게시한 'Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-10 13:11:01+0900","children":"2025년 9월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Quantization",{"className":"page__taxonomy-item","children":["#","Quantization"]}],["$","span","Few-Step Generation",{"className":"page__taxonomy-item","children":["#","Few-Step Generation"]}],["$","span","Model Compression",{"className":"page__taxonomy-item","children":["#","Model Compression"]}],["$","span","Noise Scheduling",{"className":"page__taxonomy-item","children":["#","Noise Scheduling"]}],["$","span","Post-Training Quantization",{"className":"page__taxonomy-item","children":["#","Post-Training Quantization"]}],["$","span","Image Quality Metrics",{"className":"page__taxonomy-item","children":["#","Image Quality Metrics"]}],["$","span","Latent Consistency Models",{"className":"page__taxonomy-item","children":["#","Latent Consistency Models"]}]]}]]}]]}],["$","article","2025-9-10-Parallel-R1_Towards_Parallel_Thinking_via_Reinforcement_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-10-Parallel-R1_Towards_Parallel_Thinking_via_Reinforcement_Learning/","children":"[논문리뷰] Parallel-R1: Towards Parallel Thinking via Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xinyu Yang이 [arXiv]에 게시한 'Parallel-R1: Towards Parallel Thinking via Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-10 13:11:01+0900","children":"2025년 9월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Parallel Thinking",{"className":"page__taxonomy-item","children":["#","Parallel Thinking"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Progressive Curriculum",{"className":"page__taxonomy-item","children":["#","Progressive Curriculum"]}],["$","span","Reward Design",{"className":"page__taxonomy-item","children":["#","Reward Design"]}],["$","span","Exploration Scaffold",{"className":"page__taxonomy-item","children":["#","Exploration Scaffold"]}]]}]]}]]}],["$","article","2025-9-10-Mini-o3_Scaling_Up_Reasoning_Patterns_and_Interaction_Turns_for_Visual_Search",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-10-Mini-o3_Scaling_Up_Reasoning_Patterns_and_Interaction_Turns_for_Visual_Search/","children":"[논문리뷰] Mini-o3: Scaling Up Reasoning Patterns and Interaction Turns for Visual Search"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Tianjian Li이 [arXiv]에 게시한 'Mini-o3: Scaling Up Reasoning Patterns and Interaction Turns for Visual Search' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-10 13:11:01+0900","children":"2025년 9월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Visual Search",{"className":"page__taxonomy-item","children":["#","Visual Search"]}],["$","span","Multi-Turn Reasoning",{"className":"page__taxonomy-item","children":["#","Multi-Turn Reasoning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Tool-Integrated Agents",{"className":"page__taxonomy-item","children":["#","Tool-Integrated Agents"]}],["$","span","Exploratory Reasoning",{"className":"page__taxonomy-item","children":["#","Exploratory Reasoning"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}],["$","span","Over-turn Masking",{"className":"page__taxonomy-item","children":["#","Over-turn Masking"]}],["$","span","Visual Language Models",{"className":"page__taxonomy-item","children":["#","Visual Language Models"]}]]}]]}]]}],["$","article","2025-9-10-Language_Self-Play_For_Data-Free_Training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-10-Language_Self-Play_For_Data-Free_Training/","children":"[논문리뷰] Language Self-Play For Data-Free Training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Vijai Mohan이 [arXiv]에 게시한 'Language Self-Play For Data-Free Training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-10 13:11:01+0900","children":"2025년 9월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Self-Play",{"className":"page__taxonomy-item","children":["#","Self-Play"]}],["$","span","Data-Free Training",{"className":"page__taxonomy-item","children":["#","Data-Free Training"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}],["$","span","Adversarial Training",{"className":"page__taxonomy-item","children":["#","Adversarial Training"]}],["$","span","Reward Modeling",{"className":"page__taxonomy-item","children":["#","Reward Modeling"]}]]}]]}]]}],["$","article","2025-9-10-F1_A_Vision-Language-Action_Model_Bridging_Understanding_and_Generation_to_Actions",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-10-F1_A_Vision-Language-Action_Model_Bridging_Understanding_and_Generation_to_Actions/","children":"[논문리뷰] F1: A Vision-Language-Action Model Bridging Understanding and Generation to Actions"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zherui Qiu이 [arXiv]에 게시한 'F1: A Vision-Language-Action Model Bridging Understanding and Generation to Actions' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-10 13:11:01+0900","children":"2025년 9월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Visual Foresight",{"className":"page__taxonomy-item","children":["#","Visual Foresight"]}],["$","span","Predictive Inverse Dynamics",{"className":"page__taxonomy-item","children":["#","Predictive Inverse Dynamics"]}],["$","span","Mixture-of-Transformer",{"className":"page__taxonomy-item","children":["#","Mixture-of-Transformer"]}],["$","span","Robot Manipulation",{"className":"page__taxonomy-item","children":["#","Robot Manipulation"]}],["$","span","Multi-stage Training",{"className":"page__taxonomy-item","children":["#","Multi-stage Training"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}]]}]]}]]}],["$","article","2025-9-10-Directly_Aligning_the_Full_Diffusion_Trajectory_with_Fine-Grained_Human_Preference",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-10-Directly_Aligning_the_Full_Diffusion_Trajectory_with_Fine-Grained_Human_Preference/","children":"[논문리뷰] Directly Aligning the Full Diffusion Trajectory with Fine-Grained Human Preference"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yingfang Zhang이 [arXiv]에 게시한 'Directly Aligning the Full Diffusion Trajectory with Fine-Grained Human Preference' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-10 13:11:01+0900","children":"2025년 9월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Human Preference",{"className":"page__taxonomy-item","children":["#","Human Preference"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Reward Hacking",{"className":"page__taxonomy-item","children":["#","Reward Hacking"]}],["$","span","Direct-Align",{"className":"page__taxonomy-item","children":["#","Direct-Align"]}],["$","span","SRPO",{"className":"page__taxonomy-item","children":["#","SRPO"]}],["$","span","Fine-Grained Control",{"className":"page__taxonomy-item","children":["#","Fine-Grained Control"]}],["$","span","Flow Matching Models",{"className":"page__taxonomy-item","children":["#","Flow Matching Models"]}]]}]]}]]}],["$","article","2025-9-10-Curia_A_Multi-Modal_Foundation_Model_for_Radiology",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-10-Curia_A_Multi-Modal_Foundation_Model_for_Radiology/","children":"[논문리뷰] Curia: A Multi-Modal Foundation Model for Radiology"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Elodie Ferreres이 [arXiv]에 게시한 'Curia: A Multi-Modal Foundation Model for Radiology' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-10 13:11:01+0900","children":"2025년 9월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Foundation Model",{"className":"page__taxonomy-item","children":["#","Foundation Model"]}],["$","span","Radiology",{"className":"page__taxonomy-item","children":["#","Radiology"]}],["$","span","Computed Tomography (CT)",{"className":"page__taxonomy-item","children":["#","Computed Tomography (CT)"]}],["$","span","Magnetic Resonance Imaging (MRI)",{"className":"page__taxonomy-item","children":["#","Magnetic Resonance Imaging (MRI)"]}],["$","span","Self-supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-supervised Learning"]}],["$","span","Vision Transformer",{"className":"page__taxonomy-item","children":["#","Vision Transformer"]}],["$","span","Cross-Modality Generalization",{"className":"page__taxonomy-item","children":["#","Cross-Modality Generalization"]}]]}]]}]]}],["$","article","2025-9-10-Causal_Attention_with_Lookahead_Keys",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-10-Causal_Attention_with_Lookahead_Keys/","children":"[논문리뷰] Causal Attention with Lookahead Keys"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Quanquan Gu이 [arXiv]에 게시한 'Causal Attention with Lookahead Keys' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-10 13:11:01+0900","children":"2025년 9월 10일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Causal Attention",{"className":"page__taxonomy-item","children":["#","Causal Attention"]}],["$","span","Lookahead Keys",{"className":"page__taxonomy-item","children":["#","Lookahead Keys"]}],["$","span","Autoregressive Modeling",{"className":"page__taxonomy-item","children":["#","Autoregressive Modeling"]}],["$","span","Language Models",{"className":"page__taxonomy-item","children":["#","Language Models"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Perplexity Reduction",{"className":"page__taxonomy-item","children":["#","Perplexity Reduction"]}],["$","span","Parallel Training",{"className":"page__taxonomy-item","children":["#","Parallel Training"]}],["$","span","Efficient Inference",{"className":"page__taxonomy-item","children":["#","Efficient Inference"]}]]}]]}]]}],["$","article","2025-9-9-WebExplorer_Explore_and_Evolve_for_Training_Long-Horizon_Web_Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-WebExplorer_Explore_and_Evolve_for_Training_Long-Horizon_Web_Agents/","children":"[논문리뷰] WebExplorer: Explore and Evolve for Training Long-Horizon Web Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Aili Chen이 [arXiv]에 게시한 'WebExplorer: Explore and Evolve for Training Long-Horizon Web Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Web Agents",{"className":"page__taxonomy-item","children":["#","Web Agents"]}],["$","span","Long-Horizon Reasoning",{"className":"page__taxonomy-item","children":["#","Long-Horizon Reasoning"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Data Generation",{"className":"page__taxonomy-item","children":["#","Data Generation"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Supervised Fine-tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning (SFT)"]}],["$","span","Web Navigation",{"className":"page__taxonomy-item","children":["#","Web Navigation"]}],["$","span","Information Retrieval",{"className":"page__taxonomy-item","children":["#","Information Retrieval"]}]]}]]}]]}],["$","article","2025-9-9-UniVerse-1_Unified_Audio-Video_Generation_via_Stitching_of_Experts",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-UniVerse-1_Unified_Audio-Video_Generation_via_Stitching_of_Experts/","children":"[논문리뷰] UniVerse-1: Unified Audio-Video Generation via Stitching of Experts"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xinyao Liao이 [arXiv]에 게시한 'UniVerse-1: Unified Audio-Video Generation via Stitching of Experts' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Unified Audio-Video Generation",{"className":"page__taxonomy-item","children":["#","Unified Audio-Video Generation"]}],["$","span","Stitching of Experts (SoE)",{"className":"page__taxonomy-item","children":["#","Stitching of Experts (SoE)"]}],["$","span","Multimodal Diffusion",{"className":"page__taxonomy-item","children":["#","Multimodal Diffusion"]}],["$","span","Online Annotation",{"className":"page__taxonomy-item","children":["#","Online Annotation"]}],["$","span","Cross-modal Noise Correlation",{"className":"page__taxonomy-item","children":["#","Cross-modal Noise Correlation"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Verse-Bench",{"className":"page__taxonomy-item","children":["#","Verse-Bench"]}]]}]]}]]}],["$","article","2025-9-9-Test-Time_Scaling_in_Reasoning_Models_Is_Not_Effective_for_Knowledge-Intensive_Tasks_Yet",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-Test-Time_Scaling_in_Reasoning_Models_Is_Not_Effective_for_Knowledge-Intensive_Tasks_Yet/","children":"[논문리뷰] Test-Time Scaling in Reasoning Models Is Not Effective for Knowledge-Intensive Tasks Yet"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"See-Kiong Ng이 [arXiv]에 게시한 'Test-Time Scaling in Reasoning Models Is Not Effective for Knowledge-Intensive Tasks Yet' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Test-Time Scaling",{"className":"page__taxonomy-item","children":["#","Test-Time Scaling"]}],["$","span","Reasoning Models",{"className":"page__taxonomy-item","children":["#","Reasoning Models"]}],["$","span","Knowledge-Intensive Tasks",{"className":"page__taxonomy-item","children":["#","Knowledge-Intensive Tasks"]}],["$","span","Hallucinations",{"className":"page__taxonomy-item","children":["#","Hallucinations"]}],["$","span","Factual Accuracy",{"className":"page__taxonomy-item","children":["#","Factual Accuracy"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}]]}]]}]]}],["$","article","2025-9-9-Scaling_up_Multi-Turn_Off-Policy_RL_and_Multi-Agent_Tree_Search_for_LLM_Step-Provers",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-Scaling_up_Multi-Turn_Off-Policy_RL_and_Multi-Agent_Tree_Search_for_LLM_Step-Provers/","children":"[논문리뷰] Scaling up Multi-Turn Off-Policy RL and Multi-Agent Tree Search for LLM Step-Provers"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xia Xiao이 [arXiv]에 게시한 'Scaling up Multi-Turn Off-Policy RL and Multi-Agent Tree Search for LLM Step-Provers' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Step-Provers",{"className":"page__taxonomy-item","children":["#","LLM Step-Provers"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Off-Policy RL",{"className":"page__taxonomy-item","children":["#","Off-Policy RL"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Tree Search",{"className":"page__taxonomy-item","children":["#","Tree Search"]}],["$","span","Automated Theorem Proving (ATP)",{"className":"page__taxonomy-item","children":["#","Automated Theorem Proving (ATP)"]}],["$","span","Formal Mathematics",{"className":"page__taxonomy-item","children":["#","Formal Mathematics"]}],["$","span","AlphaZero",{"className":"page__taxonomy-item","children":["#","AlphaZero"]}]]}]]}]]}],["$","article","2025-9-9-Saturation-Driven_Dataset_Generation_for_LLM_Mathematical_Reasoning_in_the_TPTP_Ecosystem",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-Saturation-Driven_Dataset_Generation_for_LLM_Mathematical_Reasoning_in_the_TPTP_Ecosystem/","children":"[논문리뷰] Saturation-Driven Dataset Generation for LLM Mathematical Reasoning in the TPTP Ecosystem"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Damien Sileo이 [arXiv]에 게시한 'Saturation-Driven Dataset Generation for LLM Mathematical Reasoning in the TPTP Ecosystem' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Automated Theorem Proving",{"className":"page__taxonomy-item","children":["#","Automated Theorem Proving"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Synthetic Data Generation",{"className":"page__taxonomy-item","children":["#","Synthetic Data Generation"]}],["$","span","TPTP Ecosystem",{"className":"page__taxonomy-item","children":["#","TPTP Ecosystem"]}],["$","span","Saturation Proving",{"className":"page__taxonomy-item","children":["#","Saturation Proving"]}],["$","span","Proof Graph Reconstruction",{"className":"page__taxonomy-item","children":["#","Proof Graph Reconstruction"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}]]}]]}]]}],["$","article","2025-9-9-Rtextbf2AI_Towards_Resistant_and_Resilient_AI_in_an_Evolving_World",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-Rtextbf2AI_Towards_Resistant_and_Resilient_AI_in_an_Evolving_World/","children":"[논문리뷰] R^textbf{2AI}: Towards Resistant and Resilient AI in an Evolving World"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Bowen Zhou이 [arXiv]에 게시한 'R^textbf{2AI}: Towards Resistant and Resilient AI in an Evolving World' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Safety",{"className":"page__taxonomy-item","children":["#","AI Safety"]}],["$","span","Resistant AI",{"className":"page__taxonomy-item","children":["#","Resistant AI"]}],["$","span","Resilient AI",{"className":"page__taxonomy-item","children":["#","Resilient AI"]}],["$","span","Coevolution",{"className":"page__taxonomy-item","children":["#","Coevolution"]}],["$","span","Fast-Slow Models",{"className":"page__taxonomy-item","children":["#","Fast-Slow Models"]}],["$","span","Adversarial Training",{"className":"page__taxonomy-item","children":["#","Adversarial Training"]}],["$","span","Continual Learning",{"className":"page__taxonomy-item","children":["#","Continual Learning"]}],["$","span","AGI Alignment",{"className":"page__taxonomy-item","children":["#","AGI Alignment"]}]]}]]}]]}],["$","article","2025-9-9-Revolutionizing_Reinforcement_Learning_Framework_for_Diffusion_Large_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-Revolutionizing_Reinforcement_Learning_Framework_for_Diffusion_Large_Language_Models/","children":"[논문리뷰] Revolutionizing Reinforcement Learning Framework for Diffusion Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ke Shen이 [arXiv]에 게시한 'Revolutionizing Reinforcement Learning Framework for Diffusion Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Language Models",{"className":"page__taxonomy-item","children":["#","Diffusion Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Trajectory-aware RL",{"className":"page__taxonomy-item","children":["#","Trajectory-aware RL"]}],["$","span","Value Model",{"className":"page__taxonomy-item","children":["#","Value Model"]}],["$","span","Masked Diffusion Models",{"className":"page__taxonomy-item","children":["#","Masked Diffusion Models"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reasoning Tasks",{"className":"page__taxonomy-item","children":["#","Reasoning Tasks"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}]]}]]}]]}],["$","article","2025-9-9-Reverse-Engineered_Reasoning_for_Open-Ended_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-Reverse-Engineered_Reasoning_for_Open-Ended_Generation/","children":"[논문리뷰] Reverse-Engineered Reasoning for Open-Ended Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wangchunshu Zhou이 [arXiv]에 게시한 'Reverse-Engineered Reasoning for Open-Ended Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Deep Reasoning",{"className":"page__taxonomy-item","children":["#","Deep Reasoning"]}],["$","span","Open-Ended Generation",{"className":"page__taxonomy-item","children":["#","Open-Ended Generation"]}],["$","span","Reverse-Engineered Reasoning (REER)",{"className":"page__taxonomy-item","children":["#","Reverse-Engineered Reasoning (REER)"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Synthetic Data",{"className":"page__taxonomy-item","children":["#","Synthetic Data"]}],["$","span","Iterative Refinement",{"className":"page__taxonomy-item","children":["#","Iterative Refinement"]}],["$","span","Perplexity Minimization",{"className":"page__taxonomy-item","children":["#","Perplexity Minimization"]}],["$","span","DeepWriting-20K",{"className":"page__taxonomy-item","children":["#","DeepWriting-20K"]}]]}]]}]]}],["$","article","2025-9-9-Reinforcement_Learning_Foundations_for_Deep_Research_Systems_A_Survey",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-Reinforcement_Learning_Foundations_for_Deep_Research_Systems_A_Survey/","children":"[논문리뷰] Reinforcement Learning Foundations for Deep Research Systems: A Survey"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wei Han이 [arXiv]에 게시한 'Reinforcement Learning Foundations for Deep Research Systems: A Survey' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Deep Research Systems",{"className":"page__taxonomy-item","children":["#","Deep Research Systems"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Hierarchical Agents",{"className":"page__taxonomy-item","children":["#","Hierarchical Agents"]}],["$","span","Reward Design",{"className":"page__taxonomy-item","children":["#","Reward Design"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","RL Frameworks",{"className":"page__taxonomy-item","children":["#","RL Frameworks"]}]]}]]}]]}],["$","article","2025-9-9-Reinforced_Visual_Perception_with_Tools",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-Reinforced_Visual_Perception_with_Tools/","children":"[논문리뷰] Reinforced Visual Perception with Tools"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Mingyang Fu이 [arXiv]에 게시한 'Reinforced Visual Perception with Tools' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Visual Reasoning",{"className":"page__taxonomy-item","children":["#","Visual Reasoning"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Tool Usage",{"className":"page__taxonomy-item","children":["#","Tool Usage"]}],["$","span","Perception-heavy Benchmarks",{"className":"page__taxonomy-item","children":["#","Perception-heavy Benchmarks"]}],["$","span","GRPO",{"className":"page__taxonomy-item","children":["#","GRPO"]}],["$","span","Vision Tools",{"className":"page__taxonomy-item","children":["#","Vision Tools"]}]]}]]}]]}],["$","article","2025-9-9-Paper2Agent_Reimagining_Research_Papers_As_Interactive_and_Reliable_AI_Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-Paper2Agent_Reimagining_Research_Papers_As_Interactive_and_Reliable_AI_Agents/","children":"[논문리뷰] Paper2Agent: Reimagining Research Papers As Interactive and Reliable AI Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"James Zou이 [arXiv]에 게시한 'Paper2Agent: Reimagining Research Papers As Interactive and Reliable AI Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Agents",{"className":"page__taxonomy-item","children":["#","AI Agents"]}],["$","span","Research Reproducibility",{"className":"page__taxonomy-item","children":["#","Research Reproducibility"]}],["$","span","Scientific Communication",{"className":"page__taxonomy-item","children":["#","Scientific Communication"]}],["$","span","Model Context Protocol (MCP)",{"className":"page__taxonomy-item","children":["#","Model Context Protocol (MCP)"]}],["$","span","Natural Language Interaction",{"className":"page__taxonomy-item","children":["#","Natural Language Interaction"]}],["$","span","Genomics",{"className":"page__taxonomy-item","children":["#","Genomics"]}],["$","span","Single-Cell Analysis",{"className":"page__taxonomy-item","children":["#","Single-Cell Analysis"]}],["$","span","Spatial Transcriptomics",{"className":"page__taxonomy-item","children":["#","Spatial Transcriptomics"]}]]}]]}]]}],["$","article","2025-9-9-MAS-Bench_A_Unified_Benchmark_for_Shortcut-Augmented_Hybrid_Mobile_GUI_Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-MAS-Bench_A_Unified_Benchmark_for_Shortcut-Augmented_Hybrid_Mobile_GUI_Agents/","children":"[논문리뷰] MAS-Bench: A Unified Benchmark for Shortcut-Augmented Hybrid Mobile GUI Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhengxi Lu이 [arXiv]에 게시한 'MAS-Bench: A Unified Benchmark for Shortcut-Augmented Hybrid Mobile GUI Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Mobile GUI Agents",{"className":"page__taxonomy-item","children":["#","Mobile GUI Agents"]}],["$","span","Hybrid Automation",{"className":"page__taxonomy-item","children":["#","Hybrid Automation"]}],["$","span","Shortcut Generation",{"className":"page__taxonomy-item","children":["#","Shortcut Generation"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Task Efficiency",{"className":"page__taxonomy-item","children":["#","Task Efficiency"]}],["$","span","LLM-based Agents",{"className":"page__taxonomy-item","children":["#","LLM-based Agents"]}],["$","span","Mobile Robotics",{"className":"page__taxonomy-item","children":["#","Mobile Robotics"]}]]}]]}]]}],["$","article","2025-9-9-Llama-GENBA-10B_A_Trilingual_Large_Language_Model_for_German_English_and_Bavarian",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-Llama-GENBA-10B_A_Trilingual_Large_Language_Model_for_German_English_and_Bavarian/","children":"[논문리뷰] Llama-GENBA-10B: A Trilingual Large Language Model for German, English and Bavarian"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hoi-Fong Mak이 [arXiv]에 게시한 'Llama-GENBA-10B: A Trilingual Large Language Model for German, English and Bavarian' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multilingual LLM",{"className":"page__taxonomy-item","children":["#","Multilingual LLM"]}],["$","span","Low-Resource Language",{"className":"page__taxonomy-item","children":["#","Low-Resource Language"]}],["$","span","German",{"className":"page__taxonomy-item","children":["#","German"]}],["$","span","Bavarian Dialect",{"className":"page__taxonomy-item","children":["#","Bavarian Dialect"]}],["$","span","Cross-Lingual Transfer",{"className":"page__taxonomy-item","children":["#","Cross-Lingual Transfer"]}],["$","span","Continuous Pretraining",{"className":"page__taxonomy-item","children":["#","Continuous Pretraining"]}],["$","span","Llama-3.1",{"className":"page__taxonomy-item","children":["#","Llama-3.1"]}],["$","span","Model Expansion",{"className":"page__taxonomy-item","children":["#","Model Expansion"]}]]}]]}]]}],["$","article","2025-9-9-Interleaving_Reasoning_for_Better_Text-to-Image_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-Interleaving_Reasoning_for_Better_Text-to-Image_Generation/","children":"[논문리뷰] Interleaving Reasoning for Better Text-to-Image Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shixiang Tang이 [arXiv]에 게시한 'Interleaving Reasoning for Better Text-to-Image Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Interleaving Reasoning",{"className":"page__taxonomy-item","children":["#","Interleaving Reasoning"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Visual Quality",{"className":"page__taxonomy-item","children":["#","Visual Quality"]}],["$","span","Fine-grained Detail",{"className":"page__taxonomy-item","children":["#","Fine-grained Detail"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Self-Correction",{"className":"page__taxonomy-item","children":["#","Self-Correction"]}]]}]]}]]}],["$","article","2025-9-9-Focusing_by_Contrastive_Attention_Enhancing_VLMs_Visual_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-Focusing_by_Contrastive_Attention_Enhancing_VLMs_Visual_Reasoning/","children":"[논문리뷰] Focusing by Contrastive Attention: Enhancing VLMs' Visual Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Baolong Bi이 [arXiv]에 게시한 'Focusing by Contrastive Attention: Enhancing VLMs' Visual Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision-Language Models (VLMs)"]}],["$","span","Visual Reasoning",{"className":"page__taxonomy-item","children":["#","Visual Reasoning"]}],["$","span","Attention Mechanisms",{"className":"page__taxonomy-item","children":["#","Attention Mechanisms"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Noise Suppression",{"className":"page__taxonomy-item","children":["#","Noise Suppression"]}],["$","span","Visual Complexity",{"className":"page__taxonomy-item","children":["#","Visual Complexity"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}]]}]]}]]}],["$","article","2025-9-9-Easier_Painting_Than_Thinking_Can_Text-to-Image_Models_Set_the_Stage_but_Not_Direct_the_Play",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-Easier_Painting_Than_Thinking_Can_Text-to-Image_Models_Set_the_Stage_but_Not_Direct_the_Play/","children":"[논문리뷰] Easier Painting Than Thinking: Can Text-to-Image Models Set the Stage, but Not Direct the Play?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Rui Chen이 [arXiv]에 게시한 'Easier Painting Than Thinking: Can Text-to-Image Models Set the Stage, but Not Direct the Play?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","T2I Benchmarking",{"className":"page__taxonomy-item","children":["#","T2I Benchmarking"]}],["$","span","Compositional Reasoning",{"className":"page__taxonomy-item","children":["#","Compositional Reasoning"]}],["$","span","Deductive Inference",{"className":"page__taxonomy-item","children":["#","Deductive Inference"]}],["$","span","Inductive Inference",{"className":"page__taxonomy-item","children":["#","Inductive Inference"]}],["$","span","Abductive Inference",{"className":"page__taxonomy-item","children":["#","Abductive Inference"]}],["$","span","MLLM Evaluation",{"className":"page__taxonomy-item","children":["#","MLLM Evaluation"]}]]}]]}]]}],["$","article","2025-9-9-Does_DINOv3_Set_a_New_Medical_Vision_Standard",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-Does_DINOv3_Set_a_New_Medical_Vision_Standard/","children":"[논문리뷰] Does DINOv3 Set a New Medical Vision Standard?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Bailiang Jian이 [arXiv]에 게시한 'Does DINOv3 Set a New Medical Vision Standard?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Medical Imaging",{"className":"page__taxonomy-item","children":["#","Medical Imaging"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","DINOv3",{"className":"page__taxonomy-item","children":["#","DINOv3"]}],["$","span","Self-Supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-Supervised Learning"]}],["$","span","Vision Transformer",{"className":"page__taxonomy-item","children":["#","Vision Transformer"]}],["$","span","2D/3D Classification",{"className":"page__taxonomy-item","children":["#","2D/3D Classification"]}],["$","span","Segmentation",{"className":"page__taxonomy-item","children":["#","Segmentation"]}],["$","span","Domain Adaptation",{"className":"page__taxonomy-item","children":["#","Domain Adaptation"]}],["$","span","Scaling Laws",{"className":"page__taxonomy-item","children":["#","Scaling Laws"]}]]}]]}]]}],["$","article","2025-9-9-D-HUMOR_Dark_Humor_Understanding_via_Multimodal_Open-ended_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-9-D-HUMOR_Dark_Humor_Understanding_via_Multimodal_Open-ended_Reasoning/","children":"[논문리뷰] D-HUMOR: Dark Humor Understanding via Multimodal Open-ended Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Dhanvin Sanjay Namboodiri이 [arXiv]에 게시한 'D-HUMOR: Dark Humor Understanding via Multimodal Open-ended Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-09 13:19:09+0900","children":"2025년 9월 9일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Dark Humor Detection",{"className":"page__taxonomy-item","children":["#","Dark Humor Detection"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","span","Vision-Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision-Language Models (VLMs)"]}],["$","span","Iterative Reasoning Refinement",{"className":"page__taxonomy-item","children":["#","Iterative Reasoning Refinement"]}],["$","span","Meme Analysis",{"className":"page__taxonomy-item","children":["#","Meme Analysis"]}],["$","span","Content Moderation",{"className":"page__taxonomy-item","children":["#","Content Moderation"]}],["$","span","Cross-Modal Attention",{"className":"page__taxonomy-item","children":["#","Cross-Modal Attention"]}],["$","span","Dataset Annotation",{"className":"page__taxonomy-item","children":["#","Dataset Annotation"]}]]}]]}]]}],["$","article","2025-9-8-WinT3R_Window-Based_Streaming_Reconstruction_with_Camera_Token_Pool",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-8-WinT3R_Window-Based_Streaming_Reconstruction_with_Camera_Token_Pool/","children":"[논문리뷰] WinT3R: Window-Based Streaming Reconstruction with Camera Token Pool"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wenzheng Chang이 [arXiv]에 게시한 'WinT3R: Window-Based Streaming Reconstruction with Camera Token Pool' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-08 13:10:18+0900","children":"2025년 9월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Online 3D Reconstruction",{"className":"page__taxonomy-item","children":["#","Online 3D Reconstruction"]}],["$","span","Camera Pose Estimation",{"className":"page__taxonomy-item","children":["#","Camera Pose Estimation"]}],["$","span","Streaming Reconstruction",{"className":"page__taxonomy-item","children":["#","Streaming Reconstruction"]}],["$","span","Sliding Window",{"className":"page__taxonomy-item","children":["#","Sliding Window"]}],["$","span","Camera Token Pool",{"className":"page__taxonomy-item","children":["#","Camera Token Pool"]}],["$","span","Real-time Performance",{"className":"page__taxonomy-item","children":["#","Real-time Performance"]}],["$","span","Computer Vision",{"className":"page__taxonomy-item","children":["#","Computer Vision"]}]]}]]}]]}],["$","article","2025-9-8-WildScore_Benchmarking_MLLMs_in-the-Wild_Symbolic_Music_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-8-WildScore_Benchmarking_MLLMs_in-the-Wild_Symbolic_Music_Reasoning/","children":"[논문리뷰] WildScore: Benchmarking MLLMs in-the-Wild Symbolic Music Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Amit Namburi이 [arXiv]에 게시한 'WildScore: Benchmarking MLLMs in-the-Wild Symbolic Music Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-08 13:10:18+0900","children":"2025년 9월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models"]}],["$","span","Symbolic Music Reasoning",{"className":"page__taxonomy-item","children":["#","Symbolic Music Reasoning"]}],["$","span","Music Score Analysis",{"className":"page__taxonomy-item","children":["#","Music Score Analysis"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Visual Question Answering",{"className":"page__taxonomy-item","children":["#","Visual Question Answering"]}],["$","span","In-the-Wild Data",{"className":"page__taxonomy-item","children":["#","In-the-Wild Data"]}],["$","span","Music Theory",{"className":"page__taxonomy-item","children":["#","Music Theory"]}]]}]]}]]}],["$","article","2025-9-8-Why_Language_Models_Hallucinate",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-8-Why_Language_Models_Hallucinate/","children":"[논문리뷰] Why Language Models Hallucinate"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Edwin Zhang이 [arXiv]에 게시한 'Why Language Models Hallucinate' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-08 13:10:18+0900","children":"2025년 9월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Language Models",{"className":"page__taxonomy-item","children":["#","Language Models"]}],["$","span","Hallucination",{"className":"page__taxonomy-item","children":["#","Hallucination"]}],["$","span","Pretraining",{"className":"page__taxonomy-item","children":["#","Pretraining"]}],["$","span","Post-training",{"className":"page__taxonomy-item","children":["#","Post-training"]}],["$","span","Evaluation Metrics",{"className":"page__taxonomy-item","children":["#","Evaluation Metrics"]}],["$","span","Binary Classification",{"className":"page__taxonomy-item","children":["#","Binary Classification"]}],["$","span","Uncertainty Quantification",{"className":"page__taxonomy-item","children":["#","Uncertainty Quantification"]}],["$","span","Calibration",{"className":"page__taxonomy-item","children":["#","Calibration"]}]]}]]}]]}],["$","article","2025-9-8-U-ARM_Ultra_low-cost_general_teleoperation_interface_for_robot_manipulation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-8-U-ARM_Ultra_low-cost_general_teleoperation_interface_for_robot_manipulation/","children":"[논문리뷰] U-ARM : Ultra low-cost general teleoperation interface for robot manipulation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Junda Huang이 [arXiv]에 게시한 'U-ARM : Ultra low-cost general teleoperation interface for robot manipulation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-08 13:10:18+0900","children":"2025년 9월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Teleoperation",{"className":"page__taxonomy-item","children":["#","Teleoperation"]}],["$","span","Robot Manipulation",{"className":"page__taxonomy-item","children":["#","Robot Manipulation"]}],["$","span","Low-Cost Hardware",{"className":"page__taxonomy-item","children":["#","Low-Cost Hardware"]}],["$","span","3D Printing",{"className":"page__taxonomy-item","children":["#","3D Printing"]}],["$","span","Leader-Follower System",{"className":"page__taxonomy-item","children":["#","Leader-Follower System"]}],["$","span","Data Collection",{"className":"page__taxonomy-item","children":["#","Data Collection"]}],["$","span","Robotics Interface",{"className":"page__taxonomy-item","children":["#","Robotics Interface"]}],["$","span","Open Source",{"className":"page__taxonomy-item","children":["#","Open Source"]}]]}]]}]]}],["$","article","2025-9-8-Symbolic_Graphics_Programming_with_Large_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-8-Symbolic_Graphics_Programming_with_Large_Language_Models/","children":"[논문리뷰] Symbolic Graphics Programming with Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kaipeng Zhang이 [arXiv]에 게시한 'Symbolic Graphics Programming with Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-08 13:10:18+0900","children":"2025년 9월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Symbolic Graphics Programming",{"className":"page__taxonomy-item","children":["#","Symbolic Graphics Programming"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","SVG Generation",{"className":"page__taxonomy-item","children":["#","SVG Generation"]}],["$","span","Text-to-Image Synthesis",{"className":"page__taxonomy-item","children":["#","Text-to-Image Synthesis"]}],["$","span","Cross-Modal Alignment",{"className":"page__taxonomy-item","children":["#","Cross-Modal Alignment"]}],["$","span","Program Synthesis",{"className":"page__taxonomy-item","children":["#","Program Synthesis"]}]]}]]}]]}],["$","article","2025-9-8-Set_Block_Decoding_is_a_Language_Model_Inference_Accelerator",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-8-Set_Block_Decoding_is_a_Language_Model_Inference_Accelerator/","children":"[논문리뷰] Set Block Decoding is a Language Model Inference Accelerator"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jeremy Reizenstein이 [arXiv]에 게시한 'Set Block Decoding is a Language Model Inference Accelerator' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-08 13:10:18+0900","children":"2025년 9월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Language Model Inference",{"className":"page__taxonomy-item","children":["#","Language Model Inference"]}],["$","span","Acceleration",{"className":"page__taxonomy-item","children":["#","Acceleration"]}],["$","span","Set Block Decoding",{"className":"page__taxonomy-item","children":["#","Set Block Decoding"]}],["$","span","Next Token Prediction",{"className":"page__taxonomy-item","children":["#","Next Token Prediction"]}],["$","span","Masked Token Prediction",{"className":"page__taxonomy-item","children":["#","Masked Token Prediction"]}],["$","span","Parallel Decoding",{"className":"page__taxonomy-item","children":["#","Parallel Decoding"]}],["$","span","KV-caching",{"className":"page__taxonomy-item","children":["#","KV-caching"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}]]}]]}]]}],["$","article","2025-9-8-On_Robustness_and_Reliability_of_Benchmark-Based_Evaluation_of_LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-8-On_Robustness_and_Reliability_of_Benchmark-Based_Evaluation_of_LLMs/","children":"[논문리뷰] On Robustness and Reliability of Benchmark-Based Evaluation of LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kevin Roitero이 [arXiv]에 게시한 'On Robustness and Reliability of Benchmark-Based Evaluation of LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-08 13:10:18+0900","children":"2025년 9월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Model Robustness",{"className":"page__taxonomy-item","children":["#","Model Robustness"]}],["$","span","Benchmark Reliability",{"className":"page__taxonomy-item","children":["#","Benchmark Reliability"]}],["$","span","Paraphrasing",{"className":"page__taxonomy-item","children":["#","Paraphrasing"]}],["$","span","Linguistic Variability",{"className":"page__taxonomy-item","children":["#","Linguistic Variability"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Question Answering",{"className":"page__taxonomy-item","children":["#","Question Answering"]}]]}]]}]]}],["$","article","2025-9-8-MedVista3D_Vision-Language_Modeling_for_Reducing_Diagnostic_Errors_in_3D_CT_Disease_Detection_Understanding_and_Reporting",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-8-MedVista3D_Vision-Language_Modeling_for_Reducing_Diagnostic_Errors_in_3D_CT_Disease_Detection_Understanding_and_Reporting/","children":"[논문리뷰] MedVista3D: Vision-Language Modeling for Reducing Diagnostic Errors in 3D CT Disease Detection, Understanding and Reporting"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Vanessa Wildman이 [arXiv]에 게시한 'MedVista3D: Vision-Language Modeling for Reducing Diagnostic Errors in 3D CT Disease Detection, Understanding and Reporting' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-08 13:10:18+0900","children":"2025년 9월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D CT",{"className":"page__taxonomy-item","children":["#","3D CT"]}],["$","span","Vision-Language Model",{"className":"page__taxonomy-item","children":["#","Vision-Language Model"]}],["$","span","Medical Imaging",{"className":"page__taxonomy-item","children":["#","Medical Imaging"]}],["$","span","Diagnostic Error Reduction",{"className":"page__taxonomy-item","children":["#","Diagnostic Error Reduction"]}],["$","span","Multi-scale Alignment",{"className":"page__taxonomy-item","children":["#","Multi-scale Alignment"]}],["$","span","Semantic Enrichment",{"className":"page__taxonomy-item","children":["#","Semantic Enrichment"]}],["$","span","Radiology Reporting",{"className":"page__taxonomy-item","children":["#","Radiology Reporting"]}],["$","span","Zero-shot Learning",{"className":"page__taxonomy-item","children":["#","Zero-shot Learning"]}]]}]]}]]}],["$","article","2025-9-8-LuxDiT_Lighting_Estimation_with_Video_Diffusion_Transformer",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-8-LuxDiT_Lighting_Estimation_with_Video_Diffusion_Transformer/","children":"[논문리뷰] LuxDiT: Lighting Estimation with Video Diffusion Transformer"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Sanja Fidler이 [arXiv]에 게시한 'LuxDiT: Lighting Estimation with Video Diffusion Transformer' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-08 13:10:18+0900","children":"2025년 9월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Lighting Estimation",{"className":"page__taxonomy-item","children":["#","Lighting Estimation"]}],["$","span","HDR Environment Map",{"className":"page__taxonomy-item","children":["#","HDR Environment Map"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Video Transformer",{"className":"page__taxonomy-item","children":["#","Video Transformer"]}],["$","span","Low-Rank Adaptation",{"className":"page__taxonomy-item","children":["#","Low-Rank Adaptation"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Synthetic Data",{"className":"page__taxonomy-item","children":["#","Synthetic Data"]}]]}]]}]]}],["$","article","2025-9-8-LatticeWorld_A_Multimodal_Large_Language_Model-Empowered_Framework_for_Interactive_Complex_World_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-8-LatticeWorld_A_Multimodal_Large_Language_Model-Empowered_Framework_for_Interactive_Complex_World_Generation/","children":"[논문리뷰] LatticeWorld: A Multimodal Large Language Model-Empowered Framework for Interactive Complex World Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhan Zhao이 [arXiv]에 게시한 'LatticeWorld: A Multimodal Large Language Model-Empowered Framework for Interactive Complex World Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-08 13:10:18+0900","children":"2025년 9월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLM",{"className":"page__taxonomy-item","children":["#","Multimodal LLM"]}],["$","span","3D World Generation",{"className":"page__taxonomy-item","children":["#","3D World Generation"]}],["$","span","Unreal Engine 5",{"className":"page__taxonomy-item","children":["#","Unreal Engine 5"]}],["$","span","Procedural Content Generation",{"className":"page__taxonomy-item","children":["#","Procedural Content Generation"]}],["$","span","Interactive Environments",{"className":"page__taxonomy-item","children":["#","Interactive Environments"]}],["$","span","Sim-to-Real",{"className":"page__taxonomy-item","children":["#","Sim-to-Real"]}],["$","span","Spatial Understanding",{"className":"page__taxonomy-item","children":["#","Spatial Understanding"]}],["$","span","Multimodal Input",{"className":"page__taxonomy-item","children":["#","Multimodal Input"]}]]}]]}]]}],["$","article","2025-9-8-Bootstrapping_Task_Spaces_for_Self-Improvement",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-8-Bootstrapping_Task_Spaces_for_Self-Improvement/","children":"[논문리뷰] Bootstrapping Task Spaces for Self-Improvement"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yoram Bachrach이 [arXiv]에 게시한 'Bootstrapping Task Spaces for Self-Improvement' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-08 13:10:18+0900","children":"2025년 9월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Self-Improvement",{"className":"page__taxonomy-item","children":["#","Self-Improvement"]}],["$","span","Autocurriculum",{"className":"page__taxonomy-item","children":["#","Autocurriculum"]}],["$","span","Task-Space Exploration",{"className":"page__taxonomy-item","children":["#","Task-Space Exploration"]}],["$","span","Inference-Time Iteration",{"className":"page__taxonomy-item","children":["#","Inference-Time Iteration"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}]]}]]}]]}],["$","article","2025-9-8-Behavioral_Fingerprinting_of_Large_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-8-Behavioral_Fingerprinting_of_Large_Language_Models/","children":"[논문리뷰] Behavioral Fingerprinting of Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xing Li이 [arXiv]에 게시한 'Behavioral Fingerprinting of Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-08 13:10:18+0900","children":"2025년 9월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Behavioral Evaluation",{"className":"page__taxonomy-item","children":["#","Behavioral Evaluation"]}],["$","span","Model Alignment",{"className":"page__taxonomy-item","children":["#","Model Alignment"]}],["$","span","Sycophancy",{"className":"page__taxonomy-item","children":["#","Sycophancy"]}],["$","span","World Model Brittleness",{"className":"page__taxonomy-item","children":["#","World Model Brittleness"]}],["$","span","Metacognition",{"className":"page__taxonomy-item","children":["#","Metacognition"]}],["$","span","Personality Profiling",{"className":"page__taxonomy-item","children":["#","Personality Profiling"]}]]}]]}]]}],["$","article","2025-9-5-Video-MTR_Reinforced_Multi-Turn_Reasoning_for_Long_Video_Understanding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-5-Video-MTR_Reinforced_Multi-Turn_Reasoning_for_Long_Video_Understanding/","children":"[논문리뷰] Video-MTR: Reinforced Multi-Turn Reasoning for Long Video Understanding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Lionel Ni이 [arXiv]에 게시한 'Video-MTR: Reinforced Multi-Turn Reasoning for Long Video Understanding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-05 13:07:20+0900","children":"2025년 9월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Long Video Understanding",{"className":"page__taxonomy-item","children":["#","Long Video Understanding"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Multi-Turn Reasoning",{"className":"page__taxonomy-item","children":["#","Multi-Turn Reasoning"]}],["$","span","MLLMs",{"className":"page__taxonomy-item","children":["#","MLLMs"]}],["$","span","Video Segment Selection",{"className":"page__taxonomy-item","children":["#","Video Segment Selection"]}],["$","span","Bi-level Reward",{"className":"page__taxonomy-item","children":["#","Bi-level Reward"]}],["$","span","Question Answering",{"className":"page__taxonomy-item","children":["#","Question Answering"]}]]}]]}]]}],["$","article","2025-9-5-Transition_Models_Rethinking_the_Generative_Learning_Objective",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-5-Transition_Models_Rethinking_the_Generative_Learning_Objective/","children":"[논문리뷰] Transition Models: Rethinking the Generative Learning Objective"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yangguang Li이 [arXiv]에 게시한 'Transition Models: Rethinking the Generative Learning Objective' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-05 13:07:20+0900","children":"2025년 9월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Training Objective",{"className":"page__taxonomy-item","children":["#","Training Objective"]}],["$","span","Continuous-Time Dynamics",{"className":"page__taxonomy-item","children":["#","Continuous-Time Dynamics"]}],["$","span","State Transition",{"className":"page__taxonomy-item","children":["#","State Transition"]}],["$","span","Few-Step Generation",{"className":"page__taxonomy-item","children":["#","Few-Step Generation"]}],["$","span","Scalable Training",{"className":"page__taxonomy-item","children":["#","Scalable Training"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}]]}]]}]]}],["$","article","2025-9-5-Towards_a_Unified_View_of_Large_Language_Model_Post-Training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-5-Towards_a_Unified_View_of_Large_Language_Model_Post-Training/","children":"[논문리뷰] Towards a Unified View of Large Language Model Post-Training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hongyi Liu이 [arXiv]에 게시한 'Towards a Unified View of Large Language Model Post-Training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-05 13:07:20+0900","children":"2025년 9월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Post-Training",{"className":"page__taxonomy-item","children":["#","Post-Training"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Supervised Fine-Tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning (SFT)"]}],["$","span","Policy Gradient",{"className":"page__taxonomy-item","children":["#","Policy Gradient"]}],["$","span","Unified Framework",{"className":"page__taxonomy-item","children":["#","Unified Framework"]}],["$","span","Hybrid Algorithms",{"className":"page__taxonomy-item","children":["#","Hybrid Algorithms"]}],["$","span","Bias-Variance Tradeoff",{"className":"page__taxonomy-item","children":["#","Bias-Variance Tradeoff"]}]]}]]}]]}],["$","article","2025-9-5-NER_Retriever_Zero-Shot_Named_Entity_Retrieval_with_Type-Aware_Embeddings",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-5-NER_Retriever_Zero-Shot_Named_Entity_Retrieval_with_Type-Aware_Embeddings/","children":"[논문리뷰] NER Retriever: Zero-Shot Named Entity Retrieval with Type-Aware Embeddings"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Oren Glickman이 [arXiv]에 게시한 'NER Retriever: Zero-Shot Named Entity Retrieval with Type-Aware Embeddings' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-05 13:07:20+0900","children":"2025년 9월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Named Entity Retrieval",{"className":"page__taxonomy-item","children":["#","Named Entity Retrieval"]}],["$","span","Zero-Shot Learning",{"className":"page__taxonomy-item","children":["#","Zero-Shot Learning"]}],["$","span","Type-Aware Embeddings",{"className":"page__taxonomy-item","children":["#","Type-Aware Embeddings"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Internal Representations",{"className":"page__taxonomy-item","children":["#","Internal Representations"]}],["$","span","Information Retrieval",{"className":"page__taxonomy-item","children":["#","Information Retrieval"]}]]}]]}]]}],["$","article","2025-9-5-Inverse_IFEval_Can_LLMs_Unlearn_Stubborn_Training_Conventions_to_Follow_Real_Instructions",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-5-Inverse_IFEval_Can_LLMs_Unlearn_Stubborn_Training_Conventions_to_Follow_Real_Instructions/","children":"[논문리뷰] Inverse IFEval: Can LLMs Unlearn Stubborn Training Conventions to Follow Real Instructions?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yu Fu이 [arXiv]에 게시한 'Inverse IFEval: Can LLMs Unlearn Stubborn Training Conventions to Follow Real Instructions?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-05 13:07:20+0900","children":"2025년 9월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Cognitive Inertia",{"className":"page__taxonomy-item","children":["#","Cognitive Inertia"]}],["$","span","Out-of-Distribution",{"className":"page__taxonomy-item","children":["#","Out-of-Distribution"]}],["$","span","Supervised Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning"]}],["$","span","Evaluation",{"className":"page__taxonomy-item","children":["#","Evaluation"]}],["$","span","Robustness",{"className":"page__taxonomy-item","children":["#","Robustness"]}]]}]]}]]}],["$","article","2025-9-5-From_Editor_to_Dense_Geometry_Estimator",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-5-From_Editor_to_Dense_Geometry_Estimator/","children":"[논문리뷰] From Editor to Dense Geometry Estimator"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Lang Nie이 [arXiv]에 게시한 'From Editor to Dense Geometry Estimator' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-05 13:07:20+0900","children":"2025년 9월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Dense Geometry Estimation",{"className":"page__taxonomy-item","children":["#","Dense Geometry Estimation"]}],["$","span","Diffusion Transformer",{"className":"page__taxonomy-item","children":["#","Diffusion Transformer"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Zero-shot Learning",{"className":"page__taxonomy-item","children":["#","Zero-shot Learning"]}],["$","span","Depth Estimation",{"className":"page__taxonomy-item","children":["#","Depth Estimation"]}],["$","span","Normal Estimation",{"className":"page__taxonomy-item","children":["#","Normal Estimation"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Logarithmic Quantization",{"className":"page__taxonomy-item","children":["#","Logarithmic Quantization"]}]]}]]}]]}],["$","article","2025-9-5-Few-step_Flow_for_3D_Generation_via_Marginal-Data_Transport_Distillation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-5-Few-step_Flow_for_3D_Generation_via_Marginal-Data_Transport_Distillation/","children":"[논문리뷰] Few-step Flow for 3D Generation via Marginal-Data Transport Distillation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Lingxi Xie이 [arXiv]에 게시한 'Few-step Flow for 3D Generation via Marginal-Data Transport Distillation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-05 13:07:20+0900","children":"2025년 9월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Generation",{"className":"page__taxonomy-item","children":["#","3D Generation"]}],["$","span","Flow-based Models",{"className":"page__taxonomy-item","children":["#","Flow-based Models"]}],["$","span","Model Distillation",{"className":"page__taxonomy-item","children":["#","Model Distillation"]}],["$","span","Few-step Sampling",{"className":"page__taxonomy-item","children":["#","Few-step Sampling"]}],["$","span","Marginal-Data Transport",{"className":"page__taxonomy-item","children":["#","Marginal-Data Transport"]}],["$","span","Velocity Matching",{"className":"page__taxonomy-item","children":["#","Velocity Matching"]}],["$","span","Velocity Distillation",{"className":"page__taxonomy-item","children":["#","Velocity Distillation"]}]]}]]}]]}],["$","article","2025-9-5-False_Sense_of_Security_Why_Probing-based_Malicious_Input_Detection_Fails_to_Generalize",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-5-False_Sense_of_Security_Why_Probing-based_Malicious_Input_Detection_Fails_to_Generalize/","children":"[논문리뷰] False Sense of Security: Why Probing-based Malicious Input Detection Fails to Generalize"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Muhao Chen이 [arXiv]에 게시한 'False Sense of Security: Why Probing-based Malicious Input Detection Fails to Generalize' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-05 13:07:20+0900","children":"2025년 9월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Safety",{"className":"page__taxonomy-item","children":["#","LLM Safety"]}],["$","span","Malicious Input Detection",{"className":"page__taxonomy-item","children":["#","Malicious Input Detection"]}],["$","span","Probing Classifiers",{"className":"page__taxonomy-item","children":["#","Probing Classifiers"]}],["$","span","Out-of-Distribution Generalization",{"className":"page__taxonomy-item","children":["#","Out-of-Distribution Generalization"]}],["$","span","Superficial Patterns",{"className":"page__taxonomy-item","children":["#","Superficial Patterns"]}],["$","span","Instructional Patterns",{"className":"page__taxonomy-item","children":["#","Instructional Patterns"]}],["$","span","Trigger Words",{"className":"page__taxonomy-item","children":["#","Trigger Words"]}],["$","span","AI Safety",{"className":"page__taxonomy-item","children":["#","AI Safety"]}]]}]]}]]}],["$","article","2025-9-5-Durian_Dual_Reference-guided_Portrait_Animation_with_Attribute_Transfer",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-5-Durian_Dual_Reference-guided_Portrait_Animation_with_Attribute_Transfer/","children":"[논문리뷰] Durian: Dual Reference-guided Portrait Animation with Attribute Transfer"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hanbyul Joo이 [arXiv]에 게시한 'Durian: Dual Reference-guided Portrait Animation with Attribute Transfer' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-05 13:07:20+0900","children":"2025년 9월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Portrait Animation",{"className":"page__taxonomy-item","children":["#","Portrait Animation"]}],["$","span","Attribute Transfer",{"className":"page__taxonomy-item","children":["#","Attribute Transfer"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Dual Reference Networks",{"className":"page__taxonomy-item","children":["#","Dual Reference Networks"]}],["$","span","Zero-shot Learning",{"className":"page__taxonomy-item","children":["#","Zero-shot Learning"]}],["$","span","Self-Reconstruction",{"className":"page__taxonomy-item","children":["#","Self-Reconstruction"]}],["$","span","Facial Editing",{"className":"page__taxonomy-item","children":["#","Facial Editing"]}]]}]]}]]}],["$","article","2025-9-5-Drivel-ology_Challenging_LLMs_with_Interpreting_Nonsense_with_Depth",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-5-Drivel-ology_Challenging_LLMs_with_Interpreting_Nonsense_with_Depth/","children":"[논문리뷰] Drivel-ology: Challenging LLMs with Interpreting Nonsense with Depth"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chi-Li Chen이 [arXiv]에 게시한 'Drivel-ology: Challenging LLMs with Interpreting Nonsense with Depth' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-05 13:07:20+0900","children":"2025년 9월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Pragmatic Understanding",{"className":"page__taxonomy-item","children":["#","Pragmatic Understanding"]}],["$","span","Drivelology",{"className":"page__taxonomy-item","children":["#","Drivelology"]}],["$","span","Benchmark Dataset",{"className":"page__taxonomy-item","children":["#","Benchmark Dataset"]}],["$","span","Multilingual NLP",{"className":"page__taxonomy-item","children":["#","Multilingual NLP"]}],["$","span","Semantic Reasoning",{"className":"page__taxonomy-item","children":["#","Semantic Reasoning"]}],["$","span","Contextual Inference",{"className":"page__taxonomy-item","children":["#","Contextual Inference"]}]]}]]}]]}],["$","article","2025-9-5-Drawing2CAD_Sequence-to-Sequence_Learning_for_CAD_Generation_from_Vector_Drawings",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-5-Drawing2CAD_Sequence-to-Sequence_Learning_for_CAD_Generation_from_Vector_Drawings/","children":"[논문리뷰] Drawing2CAD: Sequence-to-Sequence Learning for CAD Generation from Vector Drawings"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Meie Fang이 [arXiv]에 게시한 'Drawing2CAD: Sequence-to-Sequence Learning for CAD Generation from Vector Drawings' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-05 13:07:20+0900","children":"2025년 9월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","CAD Generation",{"className":"page__taxonomy-item","children":["#","CAD Generation"]}],["$","span","Vector Graphics",{"className":"page__taxonomy-item","children":["#","Vector Graphics"]}],["$","span","Sequence-to-Sequence Learning",{"className":"page__taxonomy-item","children":["#","Sequence-to-Sequence Learning"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Engineering Drawings",{"className":"page__taxonomy-item","children":["#","Engineering Drawings"]}],["$","span","Multi-modal Learning",{"className":"page__taxonomy-item","children":["#","Multi-modal Learning"]}],["$","span","Soft Target Loss",{"className":"page__taxonomy-item","children":["#","Soft Target Loss"]}],["$","span","Dual Decoder",{"className":"page__taxonomy-item","children":["#","Dual Decoder"]}]]}]]}]]}],["$","article","2025-9-5-Delta_Activations_A_Representation_for_Finetuned_Large_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-5-Delta_Activations_A_Representation_for_Finetuned_Large_Language_Models/","children":"[논문리뷰] Delta Activations: A Representation for Finetuned Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ser-Nam Lim이 [arXiv]에 게시한 'Delta Activations: A Representation for Finetuned Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-05 13:07:20+0900","children":"2025년 9월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Embedding",{"className":"page__taxonomy-item","children":["#","LLM Embedding"]}],["$","span","Delta Activations",{"className":"page__taxonomy-item","children":["#","Delta Activations"]}],["$","span","Finetuned Models",{"className":"page__taxonomy-item","children":["#","Finetuned Models"]}],["$","span","Model Representation",{"className":"page__taxonomy-item","children":["#","Model Representation"]}],["$","span","Model Clustering",{"className":"page__taxonomy-item","children":["#","Model Clustering"]}],["$","span","Additive Property",{"className":"page__taxonomy-item","children":["#","Additive Property"]}],["$","span","Task Embedding",{"className":"page__taxonomy-item","children":["#","Task Embedding"]}],["$","span","Model Merging",{"className":"page__taxonomy-item","children":["#","Model Merging"]}]]}]]}]]}],["$","article","2025-9-5-DeepResearch_Arena_The_First_Exam_of_LLMs_Research_Abilities_via_Seminar-Grounded_Tasks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-5-DeepResearch_Arena_The_First_Exam_of_LLMs_Research_Abilities_via_Seminar-Grounded_Tasks/","children":"[논문리뷰] DeepResearch Arena: The First Exam of LLMs' Research Abilities via Seminar-Grounded Tasks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiaxuan Lu이 [arXiv]에 게시한 'DeepResearch Arena: The First Exam of LLMs' Research Abilities via Seminar-Grounded Tasks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-05 13:07:20+0900","children":"2025년 9월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Research Agents",{"className":"page__taxonomy-item","children":["#","Research Agents"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Multi-Agent System",{"className":"page__taxonomy-item","children":["#","Multi-Agent System"]}],["$","span","Seminar-Grounded Tasks",{"className":"page__taxonomy-item","children":["#","Seminar-Grounded Tasks"]}],["$","span","Data Leakage Prevention",{"className":"page__taxonomy-item","children":["#","Data Leakage Prevention"]}],["$","span","Ill-Structured Problems",{"className":"page__taxonomy-item","children":["#","Ill-Structured Problems"]}]]}]]}]]}],["$","article","2025-9-4-Robix_A_Unified_Model_for_Robot_Interaction_Reasoning_and_Planning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-4-Robix_A_Unified_Model_for_Robot_Interaction_Reasoning_and_Planning/","children":"[논문리뷰] Robix: A Unified Model for Robot Interaction, Reasoning and Planning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zixuan Wang이 [arXiv]에 게시한 'Robix: A Unified Model for Robot Interaction, Reasoning and Planning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-04 12:56:15+0900","children":"2025년 9월 4일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Robot Learning",{"className":"page__taxonomy-item","children":["#","Robot Learning"]}],["$","span","Vision-Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision-Language Models (VLMs)"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Human-Robot Interaction (HRI)",{"className":"page__taxonomy-item","children":["#","Human-Robot Interaction (HRI)"]}],["$","span","Task Planning",{"className":"page__taxonomy-item","children":["#","Task Planning"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Chain-of-Thought (CoT) Reasoning",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought (CoT) Reasoning"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}]]}]]}]]}],["$","article","2025-9-4-Open_Data_Synthesis_For_Deep_Research",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-4-Open_Data_Synthesis_For_Deep_Research/","children":"[논문리뷰] Open Data Synthesis For Deep Research"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zheng Liu이 [arXiv]에 게시한 'Open Data Synthesis For Deep Research' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-04 12:56:15+0900","children":"2025년 9월 4일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Data Synthesis",{"className":"page__taxonomy-item","children":["#","Data Synthesis"]}],["$","span","Deep Research",{"className":"page__taxonomy-item","children":["#","Deep Research"]}],["$","span","Hierarchical Constraint Satisfaction Problems",{"className":"page__taxonomy-item","children":["#","Hierarchical Constraint Satisfaction Problems"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Question Answering",{"className":"page__taxonomy-item","children":["#","Question Answering"]}]]}]]}]]}],["$","article","2025-9-4-MOSAIC_Multi-Subject_Personalized_Generation_via_Correspondence-Aware_Alignment_and_Disentanglement",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-4-MOSAIC_Multi-Subject_Personalized_Generation_via_Correspondence-Aware_Alignment_and_Disentanglement/","children":"[논문리뷰] MOSAIC: Multi-Subject Personalized Generation via Correspondence-Aware Alignment and Disentanglement"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hualiang Wang이 [arXiv]에 게시한 'MOSAIC: Multi-Subject Personalized Generation via Correspondence-Aware Alignment and Disentanglement' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-04 12:56:15+0900","children":"2025년 9월 4일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-Subject Generation",{"className":"page__taxonomy-item","children":["#","Multi-Subject Generation"]}],["$","span","Personalized Image Synthesis",{"className":"page__taxonomy-item","children":["#","Personalized Image Synthesis"]}],["$","span","Semantic Correspondence",{"className":"page__taxonomy-item","children":["#","Semantic Correspondence"]}],["$","span","Attention Disentanglement",{"className":"page__taxonomy-item","children":["#","Attention Disentanglement"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Identity Preservation",{"className":"page__taxonomy-item","children":["#","Identity Preservation"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}]]}]]}]]}],["$","article","2025-9-4-Mixture_of_Global_and_Local_Experts_with_Diffusion_Transformer_for_Controllable_Face_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-4-Mixture_of_Global_and_Local_Experts_with_Diffusion_Transformer_for_Controllable_Face_Generation/","children":"[논문리뷰] Mixture of Global and Local Experts with Diffusion Transformer for Controllable Face Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kai Li이 [arXiv]에 게시한 'Mixture of Global and Local Experts with Diffusion Transformer for Controllable Face Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-04 12:56:15+0900","children":"2025년 9월 4일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Transformer",{"className":"page__taxonomy-item","children":["#","Diffusion Transformer"]}],["$","span","Mixture of Experts",{"className":"page__taxonomy-item","children":["#","Mixture of Experts"]}],["$","span","Controllable Generation",{"className":"page__taxonomy-item","children":["#","Controllable Generation"]}],["$","span","Face Generation",{"className":"page__taxonomy-item","children":["#","Face Generation"]}],["$","span","Multimodal Synthesis",{"className":"page__taxonomy-item","children":["#","Multimodal Synthesis"]}],["$","span","Semantic Control",{"className":"page__taxonomy-item","children":["#","Semantic Control"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}]]}]]}]]}],["$","article","2025-9-4-LMEnt_A_Suite_for_Analyzing_Knowledge_in_Language_Models_from_Pretraining_Data_to_Representations",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-4-LMEnt_A_Suite_for_Analyzing_Knowledge_in_Language_Models_from_Pretraining_Data_to_Representations/","children":"[논문리뷰] LMEnt: A Suite for Analyzing Knowledge in Language Models from Pretraining Data to Representations"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yoav Gur-Arieh이 [arXiv]에 게시한 'LMEnt: A Suite for Analyzing Knowledge in Language Models from Pretraining Data to Representations' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-04 12:56:15+0900","children":"2025년 9월 4일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Language Models",{"className":"page__taxonomy-item","children":["#","Language Models"]}],["$","span","Knowledge Acquisition",{"className":"page__taxonomy-item","children":["#","Knowledge Acquisition"]}],["$","span","Pretraining Data",{"className":"page__taxonomy-item","children":["#","Pretraining Data"]}],["$","span","Entity Linking",{"className":"page__taxonomy-item","children":["#","Entity Linking"]}],["$","span","Coreference Resolution",{"className":"page__taxonomy-item","children":["#","Coreference Resolution"]}],["$","span","Information Retrieval",{"className":"page__taxonomy-item","children":["#","Information Retrieval"]}],["$","span","Model Analysis",{"className":"page__taxonomy-item","children":["#","Model Analysis"]}],["$","span","Checkpoints",{"className":"page__taxonomy-item","children":["#","Checkpoints"]}]]}]]}]]}],["$","article","2025-9-3-ViSTA-SLAM_Visual_SLAM_with_Symmetric_Two-view_Association",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-ViSTA-SLAM_Visual_SLAM_with_Symmetric_Two-view_Association/","children":"[논문리뷰] ViSTA-SLAM: Visual SLAM with Symmetric Two-view Association"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Daniel Cremers이 [arXiv]에 게시한 'ViSTA-SLAM: Visual SLAM with Symmetric Two-view Association' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Monocular SLAM",{"className":"page__taxonomy-item","children":["#","Monocular SLAM"]}],["$","span","Dense Reconstruction",{"className":"page__taxonomy-item","children":["#","Dense Reconstruction"]}],["$","span","Neural Networks",{"className":"page__taxonomy-item","children":["#","Neural Networks"]}],["$","span","Pose Graph Optimization",{"className":"page__taxonomy-item","children":["#","Pose Graph Optimization"]}],["$","span","Intrinsics-free",{"className":"page__taxonomy-item","children":["#","Intrinsics-free"]}],["$","span","Real-time",{"className":"page__taxonomy-item","children":["#","Real-time"]}],["$","span","Two-view Association",{"className":"page__taxonomy-item","children":["#","Two-view Association"]}]]}]]}]]}],["$","article","2025-9-3-VerlTool_Towards_Holistic_Agentic_Reinforcement_Learning_with_Tool_Use",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-VerlTool_Towards_Holistic_Agentic_Reinforcement_Learning_with_Tool_Use/","children":"[논문리뷰] VerlTool: Towards Holistic Agentic Reinforcement Learning with Tool Use"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhiheng Lyu이 [arXiv]에 게시한 'VerlTool: Towards Holistic Agentic Reinforcement Learning with Tool Use' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Agentic Reinforcement Learning"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reinforcement Learning from Verifiable Rewards (RLVR)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning from Verifiable Rewards (RLVR)"]}],["$","span","Asynchronous Execution",{"className":"page__taxonomy-item","children":["#","Asynchronous Execution"]}],["$","span","Multi-modal AI",{"className":"page__taxonomy-item","children":["#","Multi-modal AI"]}],["$","span","Framework",{"className":"page__taxonomy-item","children":["#","Framework"]}]]}]]}]]}],["$","article","2025-9-3-Universal_Deep_Research_Bring_Your_Own_Model_and_Strategy",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-Universal_Deep_Research_Bring_Your_Own_Model_and_Strategy/","children":"[논문리뷰] Universal Deep Research: Bring Your Own Model and Strategy"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Pavlo Molchanov이 [arXiv]에 게시한 'Universal Deep Research: Bring Your Own Model and Strategy' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic Systems",{"className":"page__taxonomy-item","children":["#","Agentic Systems"]}],["$","span","Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Language Models (LLMs)"]}],["$","span","Research Automation",{"className":"page__taxonomy-item","children":["#","Research Automation"]}],["$","span","Customizable Strategies",{"className":"page__taxonomy-item","children":["#","Customizable Strategies"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","Deep Research",{"className":"page__taxonomy-item","children":["#","Deep Research"]}],["$","span","User-Defined Agents",{"className":"page__taxonomy-item","children":["#","User-Defined Agents"]}],["$","span","Sandboxed Execution",{"className":"page__taxonomy-item","children":["#","Sandboxed Execution"]}]]}]]}]]}],["$","article","2025-9-3-UI-TARS-2_Technical_Report_Advancing_GUI_Agent_with_Multi-Turn_Reinforcement_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-UI-TARS-2_Technical_Report_Advancing_GUI_Agent_with_Multi-Turn_Reinforcement_Learning/","children":"[논문리뷰] UI-TARS-2 Technical Report: Advancing GUI Agent with Multi-Turn Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Haoyang Zou이 [arXiv]에 게시한 'UI-TARS-2 Technical Report: Advancing GUI Agent with Multi-Turn Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","GUI Agent",{"className":"page__taxonomy-item","children":["#","GUI Agent"]}],["$","span","Multi-Turn RL",{"className":"page__taxonomy-item","children":["#","Multi-Turn RL"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Data Flywheel",{"className":"page__taxonomy-item","children":["#","Data Flywheel"]}],["$","span","Agent Framework",{"className":"page__taxonomy-item","children":["#","Agent Framework"]}],["$","span","Hybrid Environments",{"className":"page__taxonomy-item","children":["#","Hybrid Environments"]}],["$","span","Parameter Interpolation",{"className":"page__taxonomy-item","children":["#","Parameter Interpolation"]}]]}]]}]]}],["$","article","2025-9-3-Towards_More_Diverse_and_Challenging_Pre-training_for_Point_Cloud_Learning_Self-Supervised_Cross_Reconstruction_with_Decoupled_Views",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-Towards_More_Diverse_and_Challenging_Pre-training_for_Point_Cloud_Learning_Self-Supervised_Cross_Reconstruction_with_Decoupled_Views/","children":"[논문리뷰] Towards More Diverse and Challenging Pre-training for Point Cloud Learning: Self-Supervised Cross Reconstruction with Decoupled Views"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Junchi Yan이 [arXiv]에 게시한 'Towards More Diverse and Challenging Pre-training for Point Cloud Learning: Self-Supervised Cross Reconstruction with Decoupled Views' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Point Cloud Learning",{"className":"page__taxonomy-item","children":["#","Point Cloud Learning"]}],["$","span","Self-Supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-Supervised Learning"]}],["$","span","Cross Reconstruction",{"className":"page__taxonomy-item","children":["#","Cross Reconstruction"]}],["$","span","Decoupled Views",{"className":"page__taxonomy-item","children":["#","Decoupled Views"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Positional Encoding",{"className":"page__taxonomy-item","children":["#","Positional Encoding"]}],["$","span","3D Vision",{"className":"page__taxonomy-item","children":["#","3D Vision"]}]]}]]}]]}],["$","article","2025-9-3-The_Landscape_of_Agentic_Reinforcement_Learning_for_LLMs_A_Survey",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-The_Landscape_of_Agentic_Reinforcement_Learning_for_LLMs_A_Survey/","children":"[논문리뷰] The Landscape of Agentic Reinforcement Learning for LLMs: A Survey"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hejia Geng이 [arXiv]에 게시한 'The Landscape of Agentic Reinforcement Learning for LLMs: A Survey' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Agentic Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Sequential Decision Making",{"className":"page__taxonomy-item","children":["#","Sequential Decision Making"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Dynamic Environments",{"className":"page__taxonomy-item","children":["#","Dynamic Environments"]}],["$","span","Autonomous AI",{"className":"page__taxonomy-item","children":["#","Autonomous AI"]}]]}]]}]]}],["$","article","2025-9-3-The_Gold_Medals_in_an_Empty_Room_Diagnosing_Metalinguistic_Reasoning_in_LLMs_with_Camlang",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-The_Gold_Medals_in_an_Empty_Room_Diagnosing_Metalinguistic_Reasoning_in_LLMs_with_Camlang/","children":"[논문리뷰] The Gold Medals in an Empty Room: Diagnosing Metalinguistic Reasoning in LLMs with Camlang"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Solomon Tsai이 [arXiv]에 게시한 'The Gold Medals in an Empty Room: Diagnosing Metalinguistic Reasoning in LLMs with Camlang' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Metalinguistic Reasoning",{"className":"page__taxonomy-item","children":["#","Metalinguistic Reasoning"]}],["$","span","Constructed Language",{"className":"page__taxonomy-item","children":["#","Constructed Language"]}],["$","span","Camlang",{"className":"page__taxonomy-item","children":["#","Camlang"]}],["$","span","Second Language Acquisition",{"className":"page__taxonomy-item","children":["#","Second Language Acquisition"]}],["$","span","Zero-shot Learning",{"className":"page__taxonomy-item","children":["#","Zero-shot Learning"]}],["$","span","Natural Language Understanding",{"className":"page__taxonomy-item","children":["#","Natural Language Understanding"]}],["$","span","Commonsense Reasoning",{"className":"page__taxonomy-item","children":["#","Commonsense Reasoning"]}]]}]]}]]}],["$","article","2025-9-3-SQL-of-Thought_Multi-agentic_Text-to-SQL_with_Guided_Error_Correction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-SQL-of-Thought_Multi-agentic_Text-to-SQL_with_Guided_Error_Correction/","children":"[논문리뷰] SQL-of-Thought: Multi-agentic Text-to-SQL with Guided Error Correction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"bindsch이 [arXiv]에 게시한 'SQL-of-Thought: Multi-agentic Text-to-SQL with Guided Error Correction' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-SQL",{"className":"page__taxonomy-item","children":["#","Text-to-SQL"]}],["$","span","Multi-agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-agent Systems"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Error Correction",{"className":"page__taxonomy-item","children":["#","Error Correction"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Query Planning",{"className":"page__taxonomy-item","children":["#","Query Planning"]}],["$","span","Database Interaction",{"className":"page__taxonomy-item","children":["#","Database Interaction"]}]]}]]}]]}],["$","article","2025-9-3-SimpleTIR_End-to-End_Reinforcement_Learning_for_Multi-Turn_Tool-Integrated_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-SimpleTIR_End-to-End_Reinforcement_Learning_for_Multi-Turn_Tool-Integrated_Reasoning/","children":"[논문리뷰] SimpleTIR: End-to-End Reinforcement Learning for Multi-Turn Tool-Integrated Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Qian Liu이 [arXiv]에 게시한 'SimpleTIR: End-to-End Reinforcement Learning for Multi-Turn Tool-Integrated Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Tool-Integrated Reasoning",{"className":"page__taxonomy-item","children":["#","Tool-Integrated Reasoning"]}],["$","span","Multi-turn Reasoning",{"className":"page__taxonomy-item","children":["#","Multi-turn Reasoning"]}],["$","span","Gradient Explosion",{"className":"page__taxonomy-item","children":["#","Gradient Explosion"]}],["$","span","Training Stability",{"className":"page__taxonomy-item","children":["#","Training Stability"]}],["$","span","Trajectory Filtering",{"className":"page__taxonomy-item","children":["#","Trajectory Filtering"]}],["$","span","Zero RL",{"className":"page__taxonomy-item","children":["#","Zero RL"]}]]}]]}]]}],["$","article","2025-9-3-Reasoning_Vectors_Transferring_Chain-of-Thought_Capabilities_via_Task_Arithmetic",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-Reasoning_Vectors_Transferring_Chain-of-Thought_Capabilities_via_Task_Arithmetic/","children":"[논문리뷰] Reasoning Vectors: Transferring Chain-of-Thought Capabilities via Task Arithmetic"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Bernard Ghanem이 [arXiv]에 게시한 'Reasoning Vectors: Transferring Chain-of-Thought Capabilities via Task Arithmetic' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reasoning Vectors",{"className":"page__taxonomy-item","children":["#","Reasoning Vectors"]}],["$","span","Task Arithmetic",{"className":"page__taxonomy-item","children":["#","Task Arithmetic"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Model Merging",{"className":"page__taxonomy-item","children":["#","Model Merging"]}],["$","span","Parameter Transfer",{"className":"page__taxonomy-item","children":["#","Parameter Transfer"]}]]}]]}]]}],["$","article","2025-9-3-POINTS-Reader_Distillation-Free_Adaptation_of_Vision-Language_Models_for_Document_Conversion",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-POINTS-Reader_Distillation-Free_Adaptation_of_Vision-Language_Models_for_Document_Conversion/","children":"[논문리뷰] POINTS-Reader: Distillation-Free Adaptation of Vision-Language Models for Document Conversion"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Haicheng Wang이 [arXiv]에 게시한 'POINTS-Reader: Distillation-Free Adaptation of Vision-Language Models for Document Conversion' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","문서 변환",{"className":"page__taxonomy-item","children":["#","문서 변환"]}],["$","span","시각-언어 모델",{"className":"page__taxonomy-item","children":["#","시각-언어 모델"]}],["$","span","자가 개선",{"className":"page__taxonomy-item","children":["#","자가 개선"]}],["$","span","합성 데이터",{"className":"page__taxonomy-item","children":["#","합성 데이터"]}],["$","span","증류 없는 학습",{"className":"page__taxonomy-item","children":["#","증류 없는 학습"]}],["$","span","OCR",{"className":"page__taxonomy-item","children":["#","OCR"]}],["$","span","멀티모달 AI",{"className":"page__taxonomy-item","children":["#","멀티모달 AI"]}],["$","span","데이터 필터링",{"className":"page__taxonomy-item","children":["#","데이터 필터링"]}]]}]]}]]}],["$","article","2025-9-3-OpenVision_2_A_Family_of_Generative_Pretrained_Visual_Encoders_for_Multimodal_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-OpenVision_2_A_Family_of_Generative_Pretrained_Visual_Encoders_for_Multimodal_Learning/","children":"[논문리뷰] OpenVision 2: A Family of Generative Pretrained Visual Encoders for Multimodal Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zirui Wang이 [arXiv]에 게시한 'OpenVision 2: A Family of Generative Pretrained Visual Encoders for Multimodal Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Vision Encoder",{"className":"page__taxonomy-item","children":["#","Vision Encoder"]}],["$","span","Generative Pretraining",{"className":"page__taxonomy-item","children":["#","Generative Pretraining"]}],["$","span","Captioning Loss",{"className":"page__taxonomy-item","children":["#","Captioning Loss"]}],["$","span","Training Efficiency",{"className":"page__taxonomy-item","children":["#","Training Efficiency"]}],["$","span","Image-Text Models",{"className":"page__taxonomy-item","children":["#","Image-Text Models"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}]]}]]}]]}],["$","article","2025-9-3-MobiAgent_A_Systematic_Framework_for_Customizable_Mobile_Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-MobiAgent_A_Systematic_Framework_for_Customizable_Mobile_Agents/","children":"[논문리뷰] MobiAgent: A Systematic Framework for Customizable Mobile Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wangbo Gong이 [arXiv]에 게시한 'MobiAgent: A Systematic Framework for Customizable Mobile Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Mobile Agents",{"className":"page__taxonomy-item","children":["#","Mobile Agents"]}],["$","span","GUI Agents",{"className":"page__taxonomy-item","children":["#","GUI Agents"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Agent Acceleration",{"className":"page__taxonomy-item","children":["#","Agent Acceleration"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Data Collection",{"className":"page__taxonomy-item","children":["#","Data Collection"]}]]}]]}]]}],["$","article","2025-9-3-Metis_Training_Large_Language_Models_with_Advanced_Low-Bit_Quantization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-Metis_Training_Large_Language_Models_with_Advanced_Low-Bit_Quantization/","children":"[논문리뷰] Metis: Training Large Language Models with Advanced Low-Bit Quantization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hengjie Cao이 [arXiv]에 게시한 'Metis: Training Large Language Models with Advanced Low-Bit Quantization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Low-Bit Quantization",{"className":"page__taxonomy-item","children":["#","Low-Bit Quantization"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Spectral Decomposition",{"className":"page__taxonomy-item","children":["#","Spectral Decomposition"]}],["$","span","Anisotropy",{"className":"page__taxonomy-item","children":["#","Anisotropy"]}],["$","span","Adaptive Learning Rate",{"className":"page__taxonomy-item","children":["#","Adaptive Learning Rate"]}],["$","span","Regularization",{"className":"page__taxonomy-item","children":["#","Regularization"]}],["$","span","FP8 Training",{"className":"page__taxonomy-item","children":["#","FP8 Training"]}],["$","span","FP4 Training",{"className":"page__taxonomy-item","children":["#","FP4 Training"]}]]}]]}]]}],["$","article","2025-9-3-MedDINOv3_How_to_adapt_vision_foundation_models_for_medical_image_segmentation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-MedDINOv3_How_to_adapt_vision_foundation_models_for_medical_image_segmentation/","children":"[논문리뷰] MedDINOv3: How to adapt vision foundation models for medical image segmentation?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiaofeng Yang이 [arXiv]에 게시한 'MedDINOv3: How to adapt vision foundation models for medical image segmentation?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Medical Image Segmentation",{"className":"page__taxonomy-item","children":["#","Medical Image Segmentation"]}],["$","span","Vision Foundation Models",{"className":"page__taxonomy-item","children":["#","Vision Foundation Models"]}],["$","span","Self-supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-supervised Learning"]}],["$","span","Vision Transformers (ViT)",{"className":"page__taxonomy-item","children":["#","Vision Transformers (ViT)"]}],["$","span","Domain Adaptation",{"className":"page__taxonomy-item","children":["#","Domain Adaptation"]}],["$","span","DINOv3",{"className":"page__taxonomy-item","children":["#","DINOv3"]}],["$","span","CT Imaging",{"className":"page__taxonomy-item","children":["#","CT Imaging"]}]]}]]}]]}],["$","article","2025-9-3-M3Ret_Unleashing_Zero-shot_Multimodal_Medical_Image_Retrieval_via_Self-Supervision",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-M3Ret_Unleashing_Zero-shot_Multimodal_Medical_Image_Retrieval_via_Self-Supervision/","children":"[논문리뷰] M3Ret: Unleashing Zero-shot Multimodal Medical Image Retrieval via Self-Supervision"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yan-Jie Zhou이 [arXiv]에 게시한 'M3Ret: Unleashing Zero-shot Multimodal Medical Image Retrieval via Self-Supervision' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Medical Image Retrieval",{"className":"page__taxonomy-item","children":["#","Medical Image Retrieval"]}],["$","span","Self-Supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-Supervised Learning"]}],["$","span","Multimodal",{"className":"page__taxonomy-item","children":["#","Multimodal"]}],["$","span","Zero-shot",{"className":"page__taxonomy-item","children":["#","Zero-shot"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","MAE",{"className":"page__taxonomy-item","children":["#","MAE"]}],["$","span","SimDINO",{"className":"page__taxonomy-item","children":["#","SimDINO"]}],["$","span","Vision Transformer",{"className":"page__taxonomy-item","children":["#","Vision Transformer"]}]]}]]}]]}],["$","article","2025-9-3-LLaVA-Critic-R1_Your_Critic_Model_is_Secretly_a_Strong_Policy_Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-LLaVA-Critic-R1_Your_Critic_Model_is_Secretly_a_Strong_Policy_Model/","children":"[논문리뷰] LLaVA-Critic-R1: Your Critic Model is Secretly a Strong Policy Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jianwei Yang이 [arXiv]에 게시한 'LLaVA-Critic-R1: Your Critic Model is Secretly a Strong Policy Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision-Language Models (VLMs)"]}],["$","span","Critic Models",{"className":"page__taxonomy-item","children":["#","Critic Models"]}],["$","span","Policy Models",{"className":"page__taxonomy-item","children":["#","Policy Models"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Self-Criticism",{"className":"page__taxonomy-item","children":["#","Self-Criticism"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","span","Preference Learning",{"className":"page__taxonomy-item","children":["#","Preference Learning"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}]]}]]}]]}],["$","article","2025-9-3-Kwai_Keye-VL_1.5_Technical_Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-Kwai_Keye-VL_1.5_Technical_Report/","children":"[논문리뷰] Kwai Keye-VL 1.5 Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"SXxtyz이 [arXiv]에 게시한 'Kwai Keye-VL 1.5 Technical Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Video Understanding",{"className":"page__taxonomy-item","children":["#","Video Understanding"]}],["$","span","Slow-Fast Encoding",{"className":"page__taxonomy-item","children":["#","Slow-Fast Encoding"]}],["$","span","Long Context",{"className":"page__taxonomy-item","children":["#","Long Context"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Human Alignment",{"className":"page__taxonomy-item","children":["#","Human Alignment"]}],["$","span","Native-Resolution Vision Encoder",{"className":"page__taxonomy-item","children":["#","Native-Resolution Vision Encoder"]}]]}]]}]]}],["$","article","2025-9-3-Jointly_Reinforcing_Diversity_and_Quality_in_Language_Model_Generations",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-Jointly_Reinforcing_Diversity_and_Quality_in_Language_Model_Generations/","children":"[논문리뷰] Jointly Reinforcing Diversity and Quality in Language Model Generations"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Tianlu이 [arXiv]에 게시한 'Jointly Reinforcing Diversity and Quality in Language Model Generations' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Language Models",{"className":"page__taxonomy-item","children":["#","Language Models"]}],["$","span","Diversity Optimization",{"className":"page__taxonomy-item","children":["#","Diversity Optimization"]}],["$","span","Quality Enhancement",{"className":"page__taxonomy-item","children":["#","Quality Enhancement"]}],["$","span","Semantic Clustering",{"className":"page__taxonomy-item","children":["#","Semantic Clustering"]}],["$","span","Post-training",{"className":"page__taxonomy-item","children":["#","Post-training"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}]]}]]}]]}],["$","article","2025-9-3-Improving_Large_Vision_and_Language_Models_by_Learning_from_a_Panel_of_Peers",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-Improving_Large_Vision_and_Language_Models_by_Learning_from_a_Panel_of_Peers/","children":"[논문리뷰] Improving Large Vision and Language Models by Learning from a Panel of Peers"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Simon Jenni이 [arXiv]에 게시한 'Improving Large Vision and Language Models by Learning from a Panel of Peers' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Vision and Language Models (LVLMs)",{"className":"page__taxonomy-item","children":["#","Large Vision and Language Models (LVLMs)"]}],["$","span","Self-Improvement",{"className":"page__taxonomy-item","children":["#","Self-Improvement"]}],["$","span","Peer Learning",{"className":"page__taxonomy-item","children":["#","Peer Learning"]}],["$","span","Preference Alignment",{"className":"page__taxonomy-item","children":["#","Preference Alignment"]}],["$","span","Reward Modeling",{"className":"page__taxonomy-item","children":["#","Reward Modeling"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Knowledge Transfer",{"className":"page__taxonomy-item","children":["#","Knowledge Transfer"]}]]}]]}]]}],["$","article","2025-9-3-Implicit_Actor_Critic_Coupling_via_a_Supervised_Learning_Framework_for_RLVR",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-Implicit_Actor_Critic_Coupling_via_a_Supervised_Learning_Framework_for_RLVR/","children":"[논문리뷰] Implicit Actor Critic Coupling via a Supervised Learning Framework for RLVR"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Lu Wang이 [arXiv]에 게시한 'Implicit Actor Critic Coupling via a Supervised Learning Framework for RLVR' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","RLVR",{"className":"page__taxonomy-item","children":["#","RLVR"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Actor-Critic",{"className":"page__taxonomy-item","children":["#","Actor-Critic"]}],["$","span","Supervised Learning",{"className":"page__taxonomy-item","children":["#","Supervised Learning"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Cross-Entropy Loss",{"className":"page__taxonomy-item","children":["#","Cross-Entropy Loss"]}]]}]]}]]}],["$","article","2025-9-3-GenCompositor_Generative_Video_Compositing_with_Diffusion_Transformer",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-GenCompositor_Generative_Video_Compositing_with_Diffusion_Transformer/","children":"[논문리뷰] GenCompositor: Generative Video Compositing with Diffusion Transformer"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Lingen Li이 [arXiv]에 게시한 'GenCompositor: Generative Video Compositing with Diffusion Transformer' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Compositing",{"className":"page__taxonomy-item","children":["#","Video Compositing"]}],["$","span","Diffusion Transformer",{"className":"page__taxonomy-item","children":["#","Diffusion Transformer"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Video Editing",{"className":"page__taxonomy-item","children":["#","Video Editing"]}],["$","span","Position Embedding",{"className":"page__taxonomy-item","children":["#","Position Embedding"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Masked Token Injection",{"className":"page__taxonomy-item","children":["#","Masked Token Injection"]}],["$","span","Video Harmonization",{"className":"page__taxonomy-item","children":["#","Video Harmonization"]}]]}]]}]]}],["$","article","2025-9-3-FlashAdventure_A_Benchmark_for_GUI_Agents_Solving_Full_Story_Arcs_in_Diverse_Adventure_Games",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-FlashAdventure_A_Benchmark_for_GUI_Agents_Solving_Full_Story_Arcs_in_Diverse_Adventure_Games/","children":"[논문리뷰] FlashAdventure: A Benchmark for GUI Agents Solving Full Story Arcs in Diverse Adventure Games"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Dongmin Park이 [arXiv]에 게시한 'FlashAdventure: A Benchmark for GUI Agents Solving Full Story Arcs in Diverse Adventure Games' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","GUI Agents",{"className":"page__taxonomy-item","children":["#","GUI Agents"]}],["$","span","Adventure Games",{"className":"page__taxonomy-item","children":["#","Adventure Games"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Full Story Arc",{"className":"page__taxonomy-item","children":["#","Full Story Arc"]}],["$","span","Observation-Behavior Gap",{"className":"page__taxonomy-item","children":["#","Observation-Behavior Gap"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Automated Evaluation",{"className":"page__taxonomy-item","children":["#","Automated Evaluation"]}]]}]]}]]}],["$","article","2025-9-3-FastFit_Accelerating_Multi-Reference_Virtual_Try-On_via_Cacheable_Diffusion_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-FastFit_Accelerating_Multi-Reference_Virtual_Try-On_via_Cacheable_Diffusion_Models/","children":"[논문리뷰] FastFit: Accelerating Multi-Reference Virtual Try-On via Cacheable Diffusion Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhen Wang이 [arXiv]에 게시한 'FastFit: Accelerating Multi-Reference Virtual Try-On via Cacheable Diffusion Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Virtual Try-On",{"className":"page__taxonomy-item","children":["#","Virtual Try-On"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Cacheable Architecture",{"className":"page__taxonomy-item","children":["#","Cacheable Architecture"]}],["$","span","Multi-Reference",{"className":"page__taxonomy-item","children":["#","Multi-Reference"]}],["$","span","Semi-Attention",{"className":"page__taxonomy-item","children":["#","Semi-Attention"]}],["$","span","Efficiency",{"className":"page__taxonomy-item","children":["#","Efficiency"]}],["$","span","Image Synthesis",{"className":"page__taxonomy-item","children":["#","Image Synthesis"]}]]}]]}]]}],["$","article","2025-9-3-Fantastic_Pretraining_Optimizers_and_Where_to_Find_Them",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-Fantastic_Pretraining_Optimizers_and_Where_to_Find_Them/","children":"[논문리뷰] Fantastic Pretraining Optimizers and Where to Find Them"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Percy Liang이 [arXiv]에 게시한 'Fantastic Pretraining Optimizers and Where to Find Them' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Deep Learning Optimizers",{"className":"page__taxonomy-item","children":["#","Deep Learning Optimizers"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Hyperparameter Tuning",{"className":"page__taxonomy-item","children":["#","Hyperparameter Tuning"]}],["$","span","Pretraining Speedup",{"className":"page__taxonomy-item","children":["#","Pretraining Speedup"]}],["$","span","Scaling Laws",{"className":"page__taxonomy-item","children":["#","Scaling Laws"]}],["$","span","AdamW",{"className":"page__taxonomy-item","children":["#","AdamW"]}],["$","span","Matrix-based Optimizers",{"className":"page__taxonomy-item","children":["#","Matrix-based Optimizers"]}],["$","span","Data-to-Model Ratio",{"className":"page__taxonomy-item","children":["#","Data-to-Model Ratio"]}]]}]]}]]}],["$","article","2025-9-3-ELV-Halluc_Benchmarking_Semantic_Aggregation_Hallucinations_in_Long_Video_Understanding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-ELV-Halluc_Benchmarking_Semantic_Aggregation_Hallucinations_in_Long_Video_Understanding/","children":"[논문리뷰] ELV-Halluc: Benchmarking Semantic Aggregation Hallucinations in Long Video Understanding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xuanyu Zheng이 [arXiv]에 게시한 'ELV-Halluc: Benchmarking Semantic Aggregation Hallucinations in Long Video Understanding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Long Video Understanding",{"className":"page__taxonomy-item","children":["#","Long Video Understanding"]}],["$","span","Hallucination",{"className":"page__taxonomy-item","children":["#","Hallucination"]}],["$","span","Semantic Aggregation",{"className":"page__taxonomy-item","children":["#","Semantic Aggregation"]}],["$","span","Video MLLM",{"className":"page__taxonomy-item","children":["#","Video MLLM"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","DPO",{"className":"page__taxonomy-item","children":["#","DPO"]}],["$","span","Positional Encoding",{"className":"page__taxonomy-item","children":["#","Positional Encoding"]}],["$","span","VideoQA",{"className":"page__taxonomy-item","children":["#","VideoQA"]}]]}]]}]]}],["$","article","2025-9-3-Discrete_Noise_Inversion_for_Next-scale_Autoregressive_Text-based_Image_Editing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-Discrete_Noise_Inversion_for_Next-scale_Autoregressive_Text-based_Image_Editing/","children":"[논문리뷰] Discrete Noise Inversion for Next-scale Autoregressive Text-based Image Editing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Amin Heyrani Nobar이 [arXiv]에 게시한 'Discrete Noise Inversion for Next-scale Autoregressive Text-based Image Editing' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Autoregressive Models",{"className":"page__taxonomy-item","children":["#","Autoregressive Models"]}],["$","span","Noise Inversion",{"className":"page__taxonomy-item","children":["#","Noise Inversion"]}],["$","span","Text-to-Image",{"className":"page__taxonomy-item","children":["#","Text-to-Image"]}],["$","span","Gumbel-max Trick",{"className":"page__taxonomy-item","children":["#","Gumbel-max Trick"]}],["$","span","Training-free",{"className":"page__taxonomy-item","children":["#","Training-free"]}],["$","span","Location-aware Argmax Inversion",{"className":"page__taxonomy-item","children":["#","Location-aware Argmax Inversion"]}]]}]]}]]}],["$","article","2025-9-3-DCPO_Dynamic_Clipping_Policy_Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-DCPO_Dynamic_Clipping_Policy_Optimization/","children":"[논문리뷰] DCPO: Dynamic Clipping Policy Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kai Lu이 [arXiv]에 게시한 'DCPO: Dynamic Clipping Policy Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Dynamic Clipping",{"className":"page__taxonomy-item","children":["#","Dynamic Clipping"]}],["$","span","Advantage Standardization",{"className":"page__taxonomy-item","children":["#","Advantage Standardization"]}],["$","span","RLVR",{"className":"page__taxonomy-item","children":["#","RLVR"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}]]}]]}]]}],["$","article","2025-9-3-C-DiffDet_Fusing_Global_Scene_Context_with_Generative_Denoising_for_High-Fidelity_Object_Detection",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-C-DiffDet_Fusing_Global_Scene_Context_with_Generative_Denoising_for_High-Fidelity_Object_Detection/","children":"[논문리뷰] C-DiffDet+: Fusing Global Scene Context with Generative Denoising for High-Fidelity Object Detection"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Vito Renó이 [arXiv]에 게시한 'C-DiffDet+: Fusing Global Scene Context with Generative Denoising for High-Fidelity Object Detection' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Object Detection",{"className":"page__taxonomy-item","children":["#","Object Detection"]}],["$","span","Diffusion Model",{"className":"page__taxonomy-item","children":["#","Diffusion Model"]}],["$","span","Global Scene Context",{"className":"page__taxonomy-item","children":["#","Global Scene Context"]}],["$","span","Context-Aware Fusion",{"className":"page__taxonomy-item","children":["#","Context-Aware Fusion"]}],["$","span","Fine-grained Detection",{"className":"page__taxonomy-item","children":["#","Fine-grained Detection"]}],["$","span","Automotive Damage Assessment",{"className":"page__taxonomy-item","children":["#","Automotive Damage Assessment"]}],["$","span","Generative Denoising",{"className":"page__taxonomy-item","children":["#","Generative Denoising"]}],["$","span","Cross-Attention",{"className":"page__taxonomy-item","children":["#","Cross-Attention"]}]]}]]}]]}],["$","article","2025-9-3-Benchmarking_Optimizers_for_Large_Language_Model_Pretraining",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-Benchmarking_Optimizers_for_Large_Language_Model_Pretraining/","children":"[논문리뷰] Benchmarking Optimizers for Large Language Model Pretraining"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"mjaggi이 [arXiv]에 게시한 'Benchmarking Optimizers for Large Language Model Pretraining' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Optimizers",{"className":"page__taxonomy-item","children":["#","LLM Optimizers"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Hyperparameter Tuning",{"className":"page__taxonomy-item","children":["#","Hyperparameter Tuning"]}],["$","span","AdamW",{"className":"page__taxonomy-item","children":["#","AdamW"]}],["$","span","AdEMAMix",{"className":"page__taxonomy-item","children":["#","AdEMAMix"]}],["$","span","MARS",{"className":"page__taxonomy-item","children":["#","MARS"]}],["$","span","Mixture of Experts (MoE)",{"className":"page__taxonomy-item","children":["#","Mixture of Experts (MoE)"]}],["$","span","Weight Decay",{"className":"page__taxonomy-item","children":["#","Weight Decay"]}]]}]]}]]}],["$","article","2025-9-3-Baichuan-M2_Scaling_Medical_Capability_with_Large_Verifier_System",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-Baichuan-M2_Scaling_Medical_Capability_with_Large_Verifier_System/","children":"[논문리뷰] Baichuan-M2: Scaling Medical Capability with Large Verifier System"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jayok6이 [arXiv]에 게시한 'Baichuan-M2: Scaling Medical Capability with Large Verifier System' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Medical AI",{"className":"page__taxonomy-item","children":["#","Medical AI"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Verifier System",{"className":"page__taxonomy-item","children":["#","Verifier System"]}],["$","span","Patient Simulator",{"className":"page__taxonomy-item","children":["#","Patient Simulator"]}],["$","span","Clinical Rubrics",{"className":"page__taxonomy-item","children":["#","Clinical Rubrics"]}],["$","span","Baichuan-M2",{"className":"page__taxonomy-item","children":["#","Baichuan-M2"]}],["$","span","HealthBench",{"className":"page__taxonomy-item","children":["#","HealthBench"]}]]}]]}]]}],["$","article","2025-9-3-Attributes_as_Textual_Genes_Leveraging_LLMs_as_Genetic_Algorithm_Simulators_for_Conditional_Synthetic_Data_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-Attributes_as_Textual_Genes_Leveraging_LLMs_as_Genetic_Algorithm_Simulators_for_Conditional_Synthetic_Data_Generation/","children":"[논문리뷰] Attributes as Textual Genes: Leveraging LLMs as Genetic Algorithm Simulators for Conditional Synthetic Data Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiaolei Huang이 [arXiv]에 게시한 'Attributes as Textual Genes: Leveraging LLMs as Genetic Algorithm Simulators for Conditional Synthetic Data Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Synthetic Data Generation",{"className":"page__taxonomy-item","children":["#","Synthetic Data Generation"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Genetic Algorithms",{"className":"page__taxonomy-item","children":["#","Genetic Algorithms"]}],["$","span","Textual Data Augmentation",{"className":"page__taxonomy-item","children":["#","Textual Data Augmentation"]}],["$","span","Active Learning",{"className":"page__taxonomy-item","children":["#","Active Learning"]}],["$","span","NLP",{"className":"page__taxonomy-item","children":["#","NLP"]}],["$","span","Data Diversity",{"className":"page__taxonomy-item","children":["#","Data Diversity"]}]]}]]}]]}],["$","article","2025-9-3-AMBEDKAR-A_Multi-level_Bias_Elimination_through_a_Decoding_Approach_with_Knowledge_Augmentation_for_Robust_Constitutional_Alignment_of_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-3-AMBEDKAR-A_Multi-level_Bias_Elimination_through_a_Decoding_Approach_with_Knowledge_Augmentation_for_Robust_Constitutional_Alignment_of_Language_Models/","children":"[논문리뷰] AMBEDKAR-A Multi-level Bias Elimination through a Decoding Approach with Knowledge Augmentation for Robust Constitutional Alignment of Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Rahul Karthikeyan이 [arXiv]에 게시한 'AMBEDKAR-A Multi-level Bias Elimination through a Decoding Approach with Knowledge Augmentation for Robust Constitutional Alignment of Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-03 13:36:21+0900","children":"2025년 9월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Bias Mitigation",{"className":"page__taxonomy-item","children":["#","Bias Mitigation"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Speculative Decoding",{"className":"page__taxonomy-item","children":["#","Speculative Decoding"]}],["$","span","Constitutional AI",{"className":"page__taxonomy-item","children":["#","Constitutional AI"]}],["$","span","Fairness",{"className":"page__taxonomy-item","children":["#","Fairness"]}],["$","span","Inference-Time Control",{"className":"page__taxonomy-item","children":["#","Inference-Time Control"]}],["$","span","Indian Sociocultural Context",{"className":"page__taxonomy-item","children":["#","Indian Sociocultural Context"]}]]}]]}]]}],["$","article","2025-9-2-UI-Level_Evaluation_of_ALLaM_34B_Measuring_an_Arabic-Centric_LLM_via_HUMAIN_Chat",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-2-UI-Level_Evaluation_of_ALLaM_34B_Measuring_an_Arabic-Centric_LLM_via_HUMAIN_Chat/","children":"[논문리뷰] UI-Level Evaluation of ALLaM 34B: Measuring an Arabic-Centric LLM via HUMAIN Chat"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Omartificial-Intelligence-Space이 [arXiv]에 게시한 'UI-Level Evaluation of ALLaM 34B: Measuring an Arabic-Centric LLM via HUMAIN Chat' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-02 13:01:41+0900","children":"2025년 9월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Arabic LLM",{"className":"page__taxonomy-item","children":["#","Arabic LLM"]}],["$","span","UI-level Evaluation",{"className":"page__taxonomy-item","children":["#","UI-level Evaluation"]}],["$","span","ALLaM 34B",{"className":"page__taxonomy-item","children":["#","ALLaM 34B"]}],["$","span","HUMAIN Chat",{"className":"page__taxonomy-item","children":["#","HUMAIN Chat"]}],["$","span","Dialectal Arabic",{"className":"page__taxonomy-item","children":["#","Dialectal Arabic"]}],["$","span","LLM as a Judge",{"className":"page__taxonomy-item","children":["#","LLM as a Judge"]}],["$","span","Safety Evaluation",{"className":"page__taxonomy-item","children":["#","Safety Evaluation"]}]]}]]}]]}],["$","article","2025-9-2-T2R-bench_A_Benchmark_for_Generating_Article-Level_Reports_from_Real_World_Industrial_Tables",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-2-T2R-bench_A_Benchmark_for_Generating_Article-Level_Reports_from_Real_World_Industrial_Tables/","children":"[논문리뷰] T2R-bench: A Benchmark for Generating Article-Level Reports from Real World Industrial Tables"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yu Zhao이 [arXiv]에 게시한 'T2R-bench: A Benchmark for Generating Article-Level Reports from Real World Industrial Tables' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-02 13:01:41+0900","children":"2025년 9월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Table-to-Report Generation",{"className":"page__taxonomy-item","children":["#","Table-to-Report Generation"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Benchmark Dataset",{"className":"page__taxonomy-item","children":["#","Benchmark Dataset"]}],["$","span","Industrial Applications",{"className":"page__taxonomy-item","children":["#","Industrial Applications"]}],["$","span","Table Reasoning",{"className":"page__taxonomy-item","children":["#","Table Reasoning"]}],["$","span","Evaluation Metrics",{"className":"page__taxonomy-item","children":["#","Evaluation Metrics"]}],["$","span","Real-world Data",{"className":"page__taxonomy-item","children":["#","Real-world Data"]}]]}]]}]]}],["$","article","2025-9-2-PVPO_Pre-Estimated_Value-Based_Policy_Optimization_for_Agentic_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-2-PVPO_Pre-Estimated_Value-Based_Policy_Optimization_for_Agentic_Reasoning/","children":"[논문리뷰] PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuewei Zhang이 [arXiv]에 게시한 'PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-02 13:01:41+0900","children":"2025년 9월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Critic-Free RL",{"className":"page__taxonomy-item","children":["#","Critic-Free RL"]}],["$","span","Agentic Reasoning",{"className":"page__taxonomy-item","children":["#","Agentic Reasoning"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Advantage Estimation",{"className":"page__taxonomy-item","children":["#","Advantage Estimation"]}],["$","span","Group Sampling",{"className":"page__taxonomy-item","children":["#","Group Sampling"]}],["$","span","Static Value Estimation",{"className":"page__taxonomy-item","children":["#","Static Value Estimation"]}]]}]]}]]}],["$","article","2025-9-2-No_Label_Left_Behind_A_Unified_Surface_Defect_Detection_Model_for_all_Supervision_Regimes",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-2-No_Label_Left_Behind_A_Unified_Surface_Defect_Detection_Model_for_all_Supervision_Regimes/","children":"[논문리뷰] No Label Left Behind: A Unified Surface Defect Detection Model for all Supervision Regimes"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Danijel Skočaj이 [arXiv]에 게시한 'No Label Left Behind: A Unified Surface Defect Detection Model for all Supervision Regimes' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-02 13:01:41+0900","children":"2025년 9월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Surface Defect Detection",{"className":"page__taxonomy-item","children":["#","Surface Defect Detection"]}],["$","span","Anomaly Detection",{"className":"page__taxonomy-item","children":["#","Anomaly Detection"]}],["$","span","Mixed Supervision",{"className":"page__taxonomy-item","children":["#","Mixed Supervision"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}],["$","span","Industrial Inspection",{"className":"page__taxonomy-item","children":["#","Industrial Inspection"]}],["$","span","Unified Model",{"className":"page__taxonomy-item","children":["#","Unified Model"]}]]}]]}]]}],["$","article","2025-9-2-How_Can_Input_Reformulation_Improve_Tool_Usage_Accuracy_in_a_Complex_Dynamic_Environment_A_Study_on_τ-bench",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-2-How_Can_Input_Reformulation_Improve_Tool_Usage_Accuracy_in_a_Complex_Dynamic_Environment_A_Study_on_τ-bench/","children":"[논문리뷰] How Can Input Reformulation Improve Tool Usage Accuracy in a Complex Dynamic Environment? A Study on τ-bench"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jayanth Srinivasa이 [arXiv]에 게시한 'How Can Input Reformulation Improve Tool Usage Accuracy in a Complex Dynamic Environment? A Study on τ-bench' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-02 13:01:41+0900","children":"2025년 9월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Function Calling",{"className":"page__taxonomy-item","children":["#","Function Calling"]}],["$","span","Input Reformulation",{"className":"page__taxonomy-item","children":["#","Input Reformulation"]}],["$","span","Dynamic Environments",{"className":"page__taxonomy-item","children":["#","Dynamic Environments"]}],["$","span","τ-bench",{"className":"page__taxonomy-item","children":["#","τ-bench"]}],["$","span","Context Engineering",{"className":"page__taxonomy-item","children":["#","Context Engineering"]}],["$","span","Multi-Agent Framework",{"className":"page__taxonomy-item","children":["#","Multi-Agent Framework"]}]]}]]}]]}],["$","article","2025-9-2-From_reactive_to_cognitive_brain-inspired_spatial_intelligence_for_embodied_agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-2-From_reactive_to_cognitive_brain-inspired_spatial_intelligence_for_embodied_agents/","children":"[논문리뷰] From reactive to cognitive: brain-inspired spatial intelligence for embodied agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Songming Liu이 [arXiv]에 게시한 'From reactive to cognitive: brain-inspired spatial intelligence for embodied agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-02 13:01:41+0900","children":"2025년 9월 2일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Spatial Cognition",{"className":"page__taxonomy-item","children":["#","Spatial Cognition"]}],["$","span","Embodied Agents",{"className":"page__taxonomy-item","children":["#","Embodied Agents"]}],["$","span","Brain-inspired AI",{"className":"page__taxonomy-item","children":["#","Brain-inspired AI"]}],["$","span","Cognitive Map",{"className":"page__taxonomy-item","children":["#","Cognitive Map"]}],["$","span","Spatial Memory",{"className":"page__taxonomy-item","children":["#","Spatial Memory"]}],["$","span","MLLMs",{"className":"page__taxonomy-item","children":["#","MLLMs"]}],["$","span","Navigation",{"className":"page__taxonomy-item","children":["#","Navigation"]}]]}]]}]]}],["$","article","2025-9-1-UItron_Foundational_GUI_Agent_with_Advanced_Perception_and_Planning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-1-UItron_Foundational_GUI_Agent_with_Advanced_Perception_and_Planning/","children":"[논문리뷰] UItron: Foundational GUI Agent with Advanced Perception and Planning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yufeng Zhong이 [arXiv]에 게시한 'UItron: Foundational GUI Agent with Advanced Perception and Planning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-01 13:14:34+0900","children":"2025년 9월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","GUI Agent",{"className":"page__taxonomy-item","children":["#","GUI Agent"]}],["$","span","Foundational Model",{"className":"page__taxonomy-item","children":["#","Foundational Model"]}],["$","span","Multimodal LLM",{"className":"page__taxonomy-item","children":["#","Multimodal LLM"]}],["$","span","Perception",{"className":"page__taxonomy-item","children":["#","Perception"]}],["$","span","Planning",{"className":"page__taxonomy-item","children":["#","Planning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Data Engineering",{"className":"page__taxonomy-item","children":["#","Data Engineering"]}],["$","span","Chinese App Scenarios",{"className":"page__taxonomy-item","children":["#","Chinese App Scenarios"]}]]}]]}]]}],["$","article","2025-9-1-TiKMiX_Take_Data_Influence_into_Dynamic_Mixture_for_Language_Model_Pre-training",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-1-TiKMiX_Take_Data_Influence_into_Dynamic_Mixture_for_Language_Model_Pre-training/","children":"[논문리뷰] TiKMiX: Take Data Influence into Dynamic Mixture for Language Model Pre-training"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiyao Deng이 [arXiv]에 게시한 'TiKMiX: Take Data Influence into Dynamic Mixture for Language Model Pre-training' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-01 13:14:34+0900","children":"2025년 9월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Language Model Pre-training",{"className":"page__taxonomy-item","children":["#","Language Model Pre-training"]}],["$","span","Dynamic Data Mixing",{"className":"page__taxonomy-item","children":["#","Dynamic Data Mixing"]}],["$","span","Data Influence",{"className":"page__taxonomy-item","children":["#","Data Influence"]}],["$","span","Group Influence",{"className":"page__taxonomy-item","children":["#","Group Influence"]}],["$","span","Optimization",{"className":"page__taxonomy-item","children":["#","Optimization"]}],["$","span","Regression Model",{"className":"page__taxonomy-item","children":["#","Regression Model"]}],["$","span","LLM Training",{"className":"page__taxonomy-item","children":["#","LLM Training"]}]]}]]}]]}],["$","article","2025-9-1-Think_in_Games_Learning_to_Reason_in_Games_via_Reinforcement_Learning_with_Large_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-1-Think_in_Games_Learning_to_Reason_in_Games_via_Reinforcement_Learning_with_Large_Language_Models/","children":"[논문리뷰] Think in Games: Learning to Reason in Games via Reinforcement Learning with Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yifan Lu이 [arXiv]에 게시한 'Think in Games: Learning to Reason in Games via Reinforcement Learning with Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-01 13:14:34+0900","children":"2025년 9월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Game AI",{"className":"page__taxonomy-item","children":["#","Game AI"]}],["$","span","Procedural Knowledge",{"className":"page__taxonomy-item","children":["#","Procedural Knowledge"]}],["$","span","Declarative Knowledge",{"className":"page__taxonomy-item","children":["#","Declarative Knowledge"]}],["$","span","Explainable AI",{"className":"page__taxonomy-item","children":["#","Explainable AI"]}],["$","span","Strategic Decision-Making",{"className":"page__taxonomy-item","children":["#","Strategic Decision-Making"]}]]}]]}]]}],["$","article","2025-9-1-TalkVid_A_Large-Scale_Diversified_Dataset_for_Audio-Driven_Talking_Head_Synthesis",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-1-TalkVid_A_Large-Scale_Diversified_Dataset_for_Audio-Driven_Talking_Head_Synthesis/","children":"[논문리뷰] TalkVid: A Large-Scale Diversified Dataset for Audio-Driven Talking Head Synthesis"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Pengcheng Chen이 [arXiv]에 게시한 'TalkVid: A Large-Scale Diversified Dataset for Audio-Driven Talking Head Synthesis' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-01 13:14:34+0900","children":"2025년 9월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Audio-Driven Talking Head Synthesis",{"className":"page__taxonomy-item","children":["#","Audio-Driven Talking Head Synthesis"]}],["$","span","Large-Scale Dataset",{"className":"page__taxonomy-item","children":["#","Large-Scale Dataset"]}],["$","span","Data Diversity",{"className":"page__taxonomy-item","children":["#","Data Diversity"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Evaluation Benchmark",{"className":"page__taxonomy-item","children":["#","Evaluation Benchmark"]}],["$","span","Generalization Gap",{"className":"page__taxonomy-item","children":["#","Generalization Gap"]}],["$","span","Algorithmic Fairness",{"className":"page__taxonomy-item","children":["#","Algorithmic Fairness"]}]]}]]}]]}],["$","article","2025-9-1-R-4B_Incentivizing_General-Purpose_Auto-Thinking_Capability_in_MLLMs_via_Bi-Mode_Annealing_and_Reinforce_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-1-R-4B_Incentivizing_General-Purpose_Auto-Thinking_Capability_in_MLLMs_via_Bi-Mode_Annealing_and_Reinforce_Learning/","children":"[논문리뷰] R-4B: Incentivizing General-Purpose Auto-Thinking Capability in MLLMs via Bi-Mode Annealing and Reinforce Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Han Hu이 [arXiv]에 게시한 'R-4B: Incentivizing General-Purpose Auto-Thinking Capability in MLLMs via Bi-Mode Annealing and Reinforce Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-01 13:14:34+0900","children":"2025년 9월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models (MLLMs)"]}],["$","span","Auto-Thinking",{"className":"page__taxonomy-item","children":["#","Auto-Thinking"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Bi-mode Annealing",{"className":"page__taxonomy-item","children":["#","Bi-mode Annealing"]}],["$","span","Bi-mode Policy Optimization (BPO)",{"className":"page__taxonomy-item","children":["#","Bi-mode Policy Optimization (BPO)"]}],["$","span","General-Purpose AI",{"className":"page__taxonomy-item","children":["#","General-Purpose AI"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Efficiency",{"className":"page__taxonomy-item","children":["#","Efficiency"]}]]}]]}]]}],["$","article","2025-9-1-Morae_Proactively_Pausing_UI_Agents_for_User_Choices",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-1-Morae_Proactively_Pausing_UI_Agents_for_User_Choices/","children":"[논문리뷰] Morae: Proactively Pausing UI Agents for User Choices"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Amy Pavel이 [arXiv]에 게시한 'Morae: Proactively Pausing UI Agents for User Choices' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-01 13:14:34+0900","children":"2025년 9월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","UI Agents",{"className":"page__taxonomy-item","children":["#","UI Agents"]}],["$","span","Accessibility",{"className":"page__taxonomy-item","children":["#","Accessibility"]}],["$","span","Human-Agent Interaction",{"className":"page__taxonomy-item","children":["#","Human-Agent Interaction"]}],["$","span","Mixed-Initiative AI",{"className":"page__taxonomy-item","children":["#","Mixed-Initiative AI"]}],["$","span","Large Multimodal Models",{"className":"page__taxonomy-item","children":["#","Large Multimodal Models"]}],["$","span","Proactive AI",{"className":"page__taxonomy-item","children":["#","Proactive AI"]}],["$","span","User Choice",{"className":"page__taxonomy-item","children":["#","User Choice"]}],["$","span","Blind and Low-Vision Users",{"className":"page__taxonomy-item","children":["#","Blind and Low-Vision Users"]}]]}]]}]]}],["$","article","2025-9-1-Mimicking_the_Physicists_EyeA_VLM-centric_Approach_for_Physics_Formula_Discovery",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-1-Mimicking_the_Physicists_EyeA_VLM-centric_Approach_for_Physics_Formula_Discovery/","children":"[논문리뷰] Mimicking the Physicist's Eye:A VLM-centric Approach for Physics Formula Discovery"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wenjie Zhou이 [arXiv]에 게시한 'Mimicking the Physicist's Eye:A VLM-centric Approach for Physics Formula Discovery' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-01 13:14:34+0900","children":"2025년 9월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Physics Formula Discovery",{"className":"page__taxonomy-item","children":["#","Physics Formula Discovery"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Symbolic Regression",{"className":"page__taxonomy-item","children":["#","Symbolic Regression"]}],["$","span","Causal Chain of Thought",{"className":"page__taxonomy-item","children":["#","Causal Chain of Thought"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}]]}]]}]]}],["$","article","2025-9-1-HERMES_Human-to-Robot_Embodied_Learning_from_Multi-Source_Motion_Data_for_Mobile_Dexterous_Manipulation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-1-HERMES_Human-to-Robot_Embodied_Learning_from_Multi-Source_Motion_Data_for_Mobile_Dexterous_Manipulation/","children":"[논문리뷰] HERMES: Human-to-Robot Embodied Learning from Multi-Source Motion Data for Mobile Dexterous Manipulation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Tianhai Liang이 [arXiv]에 게시한 'HERMES: Human-to-Robot Embodied Learning from Multi-Source Motion Data for Mobile Dexterous Manipulation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-01 13:14:34+0900","children":"2025년 9월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Dexterous Manipulation",{"className":"page__taxonomy-item","children":["#","Dexterous Manipulation"]}],["$","span","Mobile Manipulation",{"className":"page__taxonomy-item","children":["#","Mobile Manipulation"]}],["$","span","Human-to-Robot Learning",{"className":"page__taxonomy-item","children":["#","Human-to-Robot Learning"]}],["$","span","Sim2Real",{"className":"page__taxonomy-item","children":["#","Sim2Real"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Depth Image",{"className":"page__taxonomy-item","children":["#","Depth Image"]}],["$","span","Visual Localization",{"className":"page__taxonomy-item","children":["#","Visual Localization"]}],["$","span","Bimanual Control",{"className":"page__taxonomy-item","children":["#","Bimanual Control"]}]]}]]}]]}],["$","article","2025-9-1-EmbodiedOneVision_Interleaved_Vision-Text-Action_Pretraining_for_General_Robot_Control",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-1-EmbodiedOneVision_Interleaved_Vision-Text-Action_Pretraining_for_General_Robot_Control/","children":"[논문리뷰] EmbodiedOneVision: Interleaved Vision-Text-Action Pretraining for General Robot Control"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhaoqing Chen이 [arXiv]에 게시한 'EmbodiedOneVision: Interleaved Vision-Text-Action Pretraining for General Robot Control' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-01 13:14:34+0900","children":"2025년 9월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Robot Control",{"className":"page__taxonomy-item","children":["#","Robot Control"]}],["$","span","Vision-Language-Action Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action Models"]}],["$","span","Multimodal Pretraining",{"className":"page__taxonomy-item","children":["#","Multimodal Pretraining"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Real-world Robotics",{"className":"page__taxonomy-item","children":["#","Real-world Robotics"]}]]}]]}]]}],["$","article","2025-9-1-Efficient_Code_Embeddings_from_Code_Generation_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-1-Efficient_Code_Embeddings_from_Code_Generation_Models/","children":"[논문리뷰] Efficient Code Embeddings from Code Generation Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Han Xiao이 [arXiv]에 게시한 'Efficient Code Embeddings from Code Generation Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-01 13:14:34+0900","children":"2025년 9월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Code Embeddings",{"className":"page__taxonomy-item","children":["#","Code Embeddings"]}],["$","span","Code Generation Models",{"className":"page__taxonomy-item","children":["#","Code Generation Models"]}],["$","span","Autoregressive Backbones",{"className":"page__taxonomy-item","children":["#","Autoregressive Backbones"]}],["$","span","Last-Token Pooling",{"className":"page__taxonomy-item","children":["#","Last-Token Pooling"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","MTEB Benchmark",{"className":"page__taxonomy-item","children":["#","MTEB Benchmark"]}]]}]]}]]}],["$","article","2025-9-1-Droplet3D_Commonsense_Priors_from_Videos_Facilitate_3D_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-1-Droplet3D_Commonsense_Priors_from_Videos_Facilitate_3D_Generation/","children":"[논문리뷰] Droplet3D: Commonsense Priors from Videos Facilitate 3D Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Qi Jia이 [arXiv]에 게시한 'Droplet3D: Commonsense Priors from Videos Facilitate 3D Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-01 13:14:34+0900","children":"2025년 9월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Generation",{"className":"page__taxonomy-item","children":["#","3D Generation"]}],["$","span","Video Diffusion Models",{"className":"page__taxonomy-item","children":["#","Video Diffusion Models"]}],["$","span","Spatial Consistency",{"className":"page__taxonomy-item","children":["#","Spatial Consistency"]}],["$","span","Semantic Knowledge",{"className":"page__taxonomy-item","children":["#","Semantic Knowledge"]}],["$","span","Multi-view Synthesis",{"className":"page__taxonomy-item","children":["#","Multi-view Synthesis"]}],["$","span","Large-scale Dataset",{"className":"page__taxonomy-item","children":["#","Large-scale Dataset"]}],["$","span","Image-to-3D",{"className":"page__taxonomy-item","children":["#","Image-to-3D"]}],["$","span","Text-to-3D",{"className":"page__taxonomy-item","children":["#","Text-to-3D"]}]]}]]}]]}],["$","article","2025-9-1-CLIPSym_Delving_into_Symmetry_Detection_with_CLIP",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-1-CLIPSym_Delving_into_Symmetry_Detection_with_CLIP/","children":"[논문리뷰] CLIPSym: Delving into Symmetry Detection with CLIP"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Raymond A. Yeh이 [arXiv]에 게시한 'CLIPSym: Delving into Symmetry Detection with CLIP' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-01 13:14:34+0900","children":"2025년 9월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Symmetry Detection",{"className":"page__taxonomy-item","children":["#","Symmetry Detection"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","CLIP",{"className":"page__taxonomy-item","children":["#","CLIP"]}],["$","span","Equivariant Networks",{"className":"page__taxonomy-item","children":["#","Equivariant Networks"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","Geometric Deep Learning",{"className":"page__taxonomy-item","children":["#","Geometric Deep Learning"]}]]}]]}]]}],["$","article","2025-9-1-A_Survey_of_Scientific_Large_Language_Models_From_Data_Foundations_to_Agent_Frontiers",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-1-A_Survey_of_Scientific_Large_Language_Models_From_Data_Foundations_to_Agent_Frontiers/","children":"[논문리뷰] A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiamin Wu이 [arXiv]에 게시한 'A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-01 13:14:34+0900","children":"2025년 9월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Scientific LLMs",{"className":"page__taxonomy-item","children":["#","Scientific LLMs"]}],["$","span","AI for Science",{"className":"page__taxonomy-item","children":["#","AI for Science"]}],["$","span","Scientific Data",{"className":"page__taxonomy-item","children":["#","Scientific Data"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Multimodal Integration",{"className":"page__taxonomy-item","children":["#","Multimodal Integration"]}],["$","span","Knowledge Representation",{"className":"page__taxonomy-item","children":["#","Knowledge Representation"]}],["$","span","Autonomous Discovery",{"className":"page__taxonomy-item","children":["#","Autonomous Discovery"]}],["$","span","Data Ecosystems",{"className":"page__taxonomy-item","children":["#","Data Ecosystems"]}]]}]]}]]}],["$","article","2025-9-1-AHELM_A_Holistic_Evaluation_of_Audio-Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-1-AHELM_A_Holistic_Evaluation_of_Audio-Language_Models/","children":"[논문리뷰] AHELM: A Holistic Evaluation of Audio-Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Siwei Yang이 [arXiv]에 게시한 'AHELM: A Holistic Evaluation of Audio-Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-01 13:14:34+0900","children":"2025년 9월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Audio-Language Models",{"className":"page__taxonomy-item","children":["#","Audio-Language Models"]}],["$","span","Holistic Evaluation",{"className":"page__taxonomy-item","children":["#","Holistic Evaluation"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Multimodality",{"className":"page__taxonomy-item","children":["#","Multimodality"]}],["$","span","Fairness",{"className":"page__taxonomy-item","children":["#","Fairness"]}],["$","span","Robustness",{"className":"page__taxonomy-item","children":["#","Robustness"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Bias Detection",{"className":"page__taxonomy-item","children":["#","Bias Detection"]}]]}]]}]]}],["$","article","2025-9-1-A.S.E_A_Repository-Level_Benchmark_for_Evaluating_Security_in_AI-Generated_Code",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-9-1-A.S.E_A_Repository-Level_Benchmark_for_Evaluating_Security_in_AI-Generated_Code/","children":"[논문리뷰] A.S.E: A Repository-Level Benchmark for Evaluating Security in AI-Generated Code"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Libo Chen이 [arXiv]에 게시한 'A.S.E: A Repository-Level Benchmark for Evaluating Security in AI-Generated Code' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-09-01 13:14:34+0900","children":"2025년 9월 1일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI-Generated Code Security",{"className":"page__taxonomy-item","children":["#","AI-Generated Code Security"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Repository-Level Benchmark",{"className":"page__taxonomy-item","children":["#","Repository-Level Benchmark"]}],["$","span","Code Security",{"className":"page__taxonomy-item","children":["#","Code Security"]}],["$","span","Vulnerability Detection",{"className":"page__taxonomy-item","children":["#","Vulnerability Detection"]}],["$","span","Static Analysis",{"className":"page__taxonomy-item","children":["#","Static Analysis"]}],["$","span","Reproducibility",{"className":"page__taxonomy-item","children":["#","Reproducibility"]}],["$","span","Context-Awareness",{"className":"page__taxonomy-item","children":["#","Context-Awareness"]}]]}]]}]]}],["$","article","2025-8-29-USO_Unified_Style_and_Subject-Driven_Generation_via_Disentangled_and_Reward_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-USO_Unified_Style_and_Subject-Driven_Generation_via_Disentangled_and_Reward_Learning/","children":"[논문리뷰] USO: Unified Style and Subject-Driven Generation via Disentangled and Reward Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiahe Tian이 [arXiv]에 게시한 'USO: Unified Style and Subject-Driven Generation via Disentangled and Reward Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Style-Driven Generation",{"className":"page__taxonomy-item","children":["#","Style-Driven Generation"]}],["$","span","Subject-Driven Generation",{"className":"page__taxonomy-item","children":["#","Subject-Driven Generation"]}],["$","span","Disentangled Representation",{"className":"page__taxonomy-item","children":["#","Disentangled Representation"]}],["$","span","Reward Learning",{"className":"page__taxonomy-item","children":["#","Reward Learning"]}],["$","span","Cross-Task Learning",{"className":"page__taxonomy-item","children":["#","Cross-Task Learning"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Image Customization",{"className":"page__taxonomy-item","children":["#","Image Customization"]}],["$","span","Unified Framework",{"className":"page__taxonomy-item","children":["#","Unified Framework"]}]]}]]}]]}],["$","article","2025-8-29-Turning_the_Spell_Around_Lightweight_Alignment_Amplification_via_Rank-One_Safety_Injection",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-Turning_the_Spell_Around_Lightweight_Alignment_Amplification_via_Rank-One_Safety_Injection/","children":"[논문리뷰] Turning the Spell Around: Lightweight Alignment Amplification via Rank-One Safety Injection"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Bernard Ghanem이 [arXiv]에 게시한 'Turning the Spell Around: Lightweight Alignment Amplification via Rank-One Safety Injection' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Safety",{"className":"page__taxonomy-item","children":["#","LLM Safety"]}],["$","span","Alignment Amplification",{"className":"page__taxonomy-item","children":["#","Alignment Amplification"]}],["$","span","Rank-One Update",{"className":"page__taxonomy-item","children":["#","Rank-One Update"]}],["$","span","Mechanistic Interpretability",{"className":"page__taxonomy-item","children":["#","Mechanistic Interpretability"]}],["$","span","Weight Steering",{"className":"page__taxonomy-item","children":["#","Weight Steering"]}],["$","span","Jailbreak Robustness",{"className":"page__taxonomy-item","children":["#","Jailbreak Robustness"]}],["$","span","Fine-tuning-free",{"className":"page__taxonomy-item","children":["#","Fine-tuning-free"]}],["$","span","Safety Injection",{"className":"page__taxonomy-item","children":["#","Safety Injection"]}]]}]]}]]}],["$","article","2025-8-29-TCIA_A_Task-Centric_Instruction_Augmentation_Method_for_Instruction_Finetuning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-TCIA_A_Task-Centric_Instruction_Augmentation_Method_for_Instruction_Finetuning/","children":"[논문리뷰] TCIA: A Task-Centric Instruction Augmentation Method for Instruction Finetuning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Simin Ma이 [arXiv]에 게시한 'TCIA: A Task-Centric Instruction Augmentation Method for Instruction Finetuning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Instruction Augmentation",{"className":"page__taxonomy-item","children":["#","Instruction Augmentation"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Task-Centric",{"className":"page__taxonomy-item","children":["#","Task-Centric"]}],["$","span","Data Diversity",{"className":"page__taxonomy-item","children":["#","Data Diversity"]}],["$","span","Task Alignment",{"className":"page__taxonomy-item","children":["#","Task Alignment"]}],["$","span","Breadth-First Search",{"className":"page__taxonomy-item","children":["#","Breadth-First Search"]}],["$","span","Constraint Generation",{"className":"page__taxonomy-item","children":["#","Constraint Generation"]}]]}]]}]]}],["$","article","2025-8-29-rStar2-Agent_Agentic_Reasoning_Technical_Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-rStar2-Agent_Agentic_Reasoning_Technical_Report/","children":"[논문리뷰] rStar2-Agent: Agentic Reasoning Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Weijiang Xu이 [arXiv]에 게시한 'rStar2-Agent: Agentic Reasoning Technical Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Agentic Reinforcement Learning"]}],["$","span","Math Reasoning",{"className":"page__taxonomy-item","children":["#","Math Reasoning"]}],["$","span","Code Interpreter",{"className":"page__taxonomy-item","children":["#","Code Interpreter"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","GRPO-RoC",{"className":"page__taxonomy-item","children":["#","GRPO-RoC"]}],["$","span","LLM Training Efficiency",{"className":"page__taxonomy-item","children":["#","LLM Training Efficiency"]}],["$","span","Self-Reflection",{"className":"page__taxonomy-item","children":["#","Self-Reflection"]}]]}]]}]]}],["$","article","2025-8-29-ROSE_Remove_Objects_with_Side_Effects_in_Videos",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-ROSE_Remove_Objects_with_Side_Effects_in_Videos/","children":"[논문리뷰] ROSE: Remove Objects with Side Effects in Videos"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hantang Liu이 [arXiv]에 게시한 'ROSE: Remove Objects with Side Effects in Videos' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Object Removal",{"className":"page__taxonomy-item","children":["#","Video Object Removal"]}],["$","span","Side Effects",{"className":"page__taxonomy-item","children":["#","Side Effects"]}],["$","span","3D Rendering",{"className":"page__taxonomy-item","children":["#","3D Rendering"]}],["$","span","Diffusion Transformer",{"className":"page__taxonomy-item","children":["#","Diffusion Transformer"]}],["$","span","Video Inpainting",{"className":"page__taxonomy-item","children":["#","Video Inpainting"]}],["$","span","Synthetic Data",{"className":"page__taxonomy-item","children":["#","Synthetic Data"]}],["$","span","Difference Mask",{"className":"page__taxonomy-item","children":["#","Difference Mask"]}]]}]]}]]}],["$","article","2025-8-29-Provable_Benefits_of_In-Tool_Learning_for_Large_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-Provable_Benefits_of_In-Tool_Learning_for_Large_Language_Models/","children":"[논문리뷰] Provable Benefits of In-Tool Learning for Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Vivien Cabannes이 [arXiv]에 게시한 'Provable Benefits of In-Tool Learning for Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","In-Tool Learning",{"className":"page__taxonomy-item","children":["#","In-Tool Learning"]}],["$","span","In-Weight Learning",{"className":"page__taxonomy-item","children":["#","In-Weight Learning"]}],["$","span","Factual Recall",{"className":"page__taxonomy-item","children":["#","Factual Recall"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","Scaling Laws",{"className":"page__taxonomy-item","children":["#","Scaling Laws"]}],["$","span","Parameter Efficiency",{"className":"page__taxonomy-item","children":["#","Parameter Efficiency"]}],["$","span","Catastrophic Forgetting",{"className":"page__taxonomy-item","children":["#","Catastrophic Forgetting"]}]]}]]}]]}],["$","article","2025-8-29-Pref-GRPO_Pairwise_Preference_Reward-based_GRPO_for_Stable_Text-to-Image_Reinforcement_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-Pref-GRPO_Pairwise_Preference_Reward-based_GRPO_for_Stable_Text-to-Image_Reinforcement_Learning/","children":"[논문리뷰] Pref-GRPO: Pairwise Preference Reward-based GRPO for Stable Text-to-Image Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiazi Bu이 [arXiv]에 게시한 'Pref-GRPO: Pairwise Preference Reward-based GRPO for Stable Text-to-Image Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","GRPO",{"className":"page__taxonomy-item","children":["#","GRPO"]}],["$","span","Reward Hacking",{"className":"page__taxonomy-item","children":["#","Reward Hacking"]}],["$","span","Pairwise Preference",{"className":"page__taxonomy-item","children":["#","Pairwise Preference"]}],["$","span","Reward Model",{"className":"page__taxonomy-item","children":["#","Reward Model"]}],["$","span","Stable Optimization",{"className":"page__taxonomy-item","children":["#","Stable Optimization"]}],["$","span","UniGenBench",{"className":"page__taxonomy-item","children":["#","UniGenBench"]}]]}]]}]]}],["$","article","2025-8-29-Persuasion_Dynamics_in_LLMs_Investigating_Robustness_and_Adaptability_in_Knowledge_and_Safety_with_DuET-PD",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-Persuasion_Dynamics_in_LLMs_Investigating_Robustness_and_Adaptability_in_Knowledge_and_Safety_with_DuET-PD/","children":"[논문리뷰] Persuasion Dynamics in LLMs: Investigating Robustness and Adaptability in Knowledge and Safety with DuET-PD"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Roy Ka-Wei Lee이 [arXiv]에 게시한 'Persuasion Dynamics in LLMs: Investigating Robustness and Adaptability in Knowledge and Safety with DuET-PD' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Persuasion Dynamics",{"className":"page__taxonomy-item","children":["#","Persuasion Dynamics"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Robustness",{"className":"page__taxonomy-item","children":["#","Robustness"]}],["$","span","Gullibility",{"className":"page__taxonomy-item","children":["#","Gullibility"]}],["$","span","Receptiveness",{"className":"page__taxonomy-item","children":["#","Receptiveness"]}],["$","span","Direct Preference Optimization (DPO)",{"className":"page__taxonomy-item","children":["#","Direct Preference Optimization (DPO)"]}],["$","span","Safety Alignment",{"className":"page__taxonomy-item","children":["#","Safety Alignment"]}],["$","span","Multi-turn Dialogue",{"className":"page__taxonomy-item","children":["#","Multi-turn Dialogue"]}]]}]]}]]}],["$","article","2025-8-29-OnGoal_Tracking_and_Visualizing_Conversational_Goals_in_Multi-Turn_Dialogue_with_Large_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-OnGoal_Tracking_and_Visualizing_Conversational_Goals_in_Multi-Turn_Dialogue_with_Large_Language_Models/","children":"[논문리뷰] OnGoal: Tracking and Visualizing Conversational Goals in Multi-Turn Dialogue with Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Alex Endert이 [arXiv]에 게시한 'OnGoal: Tracking and Visualizing Conversational Goals in Multi-Turn Dialogue with Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Human-Computer Interaction (HCI)",{"className":"page__taxonomy-item","children":["#","Human-Computer Interaction (HCI)"]}],["$","span","Conversational AI",{"className":"page__taxonomy-item","children":["#","Conversational AI"]}],["$","span","Goal Tracking",{"className":"page__taxonomy-item","children":["#","Goal Tracking"]}],["$","span","Visualization",{"className":"page__taxonomy-item","children":["#","Visualization"]}],["$","span","Multi-Turn Dialogue",{"className":"page__taxonomy-item","children":["#","Multi-Turn Dialogue"]}],["$","span","User Interface Design",{"className":"page__taxonomy-item","children":["#","User Interface Design"]}],["$","span","Sensemaking",{"className":"page__taxonomy-item","children":["#","Sensemaking"]}]]}]]}]]}],["$","article","2025-8-29-OneReward_Unified_Mask-Guided_Image_Generation_via_Multi-Task_Human_Preference_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-OneReward_Unified_Mask-Guided_Image_Generation_via_Multi-Task_Human_Preference_Learning/","children":"[논문리뷰] OneReward: Unified Mask-Guided Image Generation via Multi-Task Human Preference Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yitong Wang이 [arXiv]에 게시한 'OneReward: Unified Mask-Guided Image Generation via Multi-Task Human Preference Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Mask-Guided Editing",{"className":"page__taxonomy-item","children":["#","Mask-Guided Editing"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Human Preference Learning",{"className":"page__taxonomy-item","children":["#","Human Preference Learning"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Multi-Task Learning",{"className":"page__taxonomy-item","children":["#","Multi-Task Learning"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}]]}]]}]]}],["$","article","2025-8-29-Multi-View_3D_Point_Tracking",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-Multi-View_3D_Point_Tracking/","children":"[논문리뷰] Multi-View 3D Point Tracking"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Irem Demir이 [arXiv]에 게시한 'Multi-View 3D Point Tracking' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Point Tracking",{"className":"page__taxonomy-item","children":["#","3D Point Tracking"]}],["$","span","Multi-View",{"className":"page__taxonomy-item","children":["#","Multi-View"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","kNN Correlation",{"className":"page__taxonomy-item","children":["#","kNN Correlation"]}],["$","span","Depth Estimation",{"className":"page__taxonomy-item","children":["#","Depth Estimation"]}],["$","span","Dynamic Scenes",{"className":"page__taxonomy-item","children":["#","Dynamic Scenes"]}],["$","span","Occlusion Handling",{"className":"page__taxonomy-item","children":["#","Occlusion Handling"]}],["$","span","Feature Fusion",{"className":"page__taxonomy-item","children":["#","Feature Fusion"]}]]}]]}]]}],["$","article","2025-8-29-Mixture_of_Contexts_for_Long_Video_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-Mixture_of_Contexts_for_Long_Video_Generation/","children":"[논문리뷰] Mixture of Contexts for Long Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Junfei Xiao이 [arXiv]에 게시한 'Mixture of Contexts for Long Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Long Video Generation",{"className":"page__taxonomy-item","children":["#","Long Video Generation"]}],["$","span","Diffusion Transformers (DiT)",{"className":"page__taxonomy-item","children":["#","Diffusion Transformers (DiT)"]}],["$","span","Sparse Attention",{"className":"page__taxonomy-item","children":["#","Sparse Attention"]}],["$","span","Context Routing",{"className":"page__taxonomy-item","children":["#","Context Routing"]}],["$","span","Memory Management",{"className":"page__taxonomy-item","children":["#","Memory Management"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Video Synthesis",{"className":"page__taxonomy-item","children":["#","Video Synthesis"]}]]}]]}]]}],["$","article","2025-8-29-MCP-Bench_Benchmarking_Tool-Using_LLM_Agents_with_Complex_Real-World_Tasks_via_MCP_Servers",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-MCP-Bench_Benchmarking_Tool-Using_LLM_Agents_with_Complex_Real-World_Tasks_via_MCP_Servers/","children":"[논문리뷰] MCP-Bench: Benchmarking Tool-Using LLM Agents with Complex Real-World Tasks via MCP Servers"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shashank Biju이 [arXiv]에 게시한 'MCP-Bench: Benchmarking Tool-Using LLM Agents with Complex Real-World Tasks via MCP Servers' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Model Context Protocol (MCP)",{"className":"page__taxonomy-item","children":["#","Model Context Protocol (MCP)"]}],["$","span","Cross-Domain Orchestration",{"className":"page__taxonomy-item","children":["#","Cross-Domain Orchestration"]}],["$","span","Fuzzy Instructions",{"className":"page__taxonomy-item","children":["#","Fuzzy Instructions"]}],["$","span","Multi-Step Tasks",{"className":"page__taxonomy-item","children":["#","Multi-Step Tasks"]}],["$","span","Real-World Scenarios",{"className":"page__taxonomy-item","children":["#","Real-World Scenarios"]}]]}]]}]]}],["$","article","2025-8-29-FakeParts_a_New_Family_of_AI-Generated_DeepFakes",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-FakeParts_a_New_Family_of_AI-Generated_DeepFakes/","children":"[논문리뷰] FakeParts: a New Family of AI-Generated DeepFakes"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xi Wang이 [arXiv]에 게시한 'FakeParts: a New Family of AI-Generated DeepFakes' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Deepfake Detection",{"className":"page__taxonomy-item","children":["#","Deepfake Detection"]}],["$","span","Partial Deepfakes",{"className":"page__taxonomy-item","children":["#","Partial Deepfakes"]}],["$","span","AI-Generated Video",{"className":"page__taxonomy-item","children":["#","AI-Generated Video"]}],["$","span","Benchmark Dataset",{"className":"page__taxonomy-item","children":["#","Benchmark Dataset"]}],["$","span","Video Forensics",{"className":"page__taxonomy-item","children":["#","Video Forensics"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Manipulation Detection",{"className":"page__taxonomy-item","children":["#","Manipulation Detection"]}],["$","span","Human Perception",{"className":"page__taxonomy-item","children":["#","Human Perception"]}]]}]]}]]}],["$","article","2025-8-29-DressDance_Dress_up_and_Dance_as_You_Like_It_-_Technical_Preview",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-DressDance_Dress_up_and_Dance_as_You_Like_It_-_Technical_Preview/","children":"[논문리뷰] Dress&Dance: Dress up and Dance as You Like It - Technical Preview"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yu-Xiong Wang이 [arXiv]에 게시한 'Dress&Dance: Dress up and Dance as You Like It - Technical Preview' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Virtual Try-On",{"className":"page__taxonomy-item","children":["#","Virtual Try-On"]}],["$","span","Video Diffusion",{"className":"page__taxonomy-item","children":["#","Video Diffusion"]}],["$","span","Multi-modal Conditioning",{"className":"page__taxonomy-item","children":["#","Multi-modal Conditioning"]}],["$","span","Garment Transfer",{"className":"page__taxonomy-item","children":["#","Garment Transfer"]}],["$","span","Pose Animation",{"className":"page__taxonomy-item","children":["#","Pose Animation"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Fashion Tech",{"className":"page__taxonomy-item","children":["#","Fashion Tech"]}],["$","span","CondNet",{"className":"page__taxonomy-item","children":["#","CondNet"]}]]}]]}]]}],["$","article","2025-8-29-Collaborative_Multi-Modal_Coding_for_High-Quality_3D_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-Collaborative_Multi-Modal_Coding_for_High-Quality_3D_Generation/","children":"[논문리뷰] Collaborative Multi-Modal Coding for High-Quality 3D Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ziwei Liu이 [arXiv]에 게시한 'Collaborative Multi-Modal Coding for High-Quality 3D Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Generation",{"className":"page__taxonomy-item","children":["#","3D Generation"]}],["$","span","Multi-modal Learning",{"className":"page__taxonomy-item","children":["#","Multi-modal Learning"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Triplane Representation",{"className":"page__taxonomy-item","children":["#","Triplane Representation"]}],["$","span","Collaborative Coding",{"className":"page__taxonomy-item","children":["#","Collaborative Coding"]}],["$","span","Image-to-3D",{"className":"page__taxonomy-item","children":["#","Image-to-3D"]}],["$","span","Latent Space",{"className":"page__taxonomy-item","children":["#","Latent Space"]}]]}]]}]]}],["$","article","2025-8-29-CogVLA_Cognition-Aligned_Vision-Language-Action_Model_via_Instruction-Driven_Routing_Sparsification",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-CogVLA_Cognition-Aligned_Vision-Language-Action_Model_via_Instruction-Driven_Routing_Sparsification/","children":"[논문리뷰] CogVLA: Cognition-Aligned Vision-Language-Action Model via Instruction-Driven Routing & Sparsification"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Liqiang Nie이 [arXiv]에 게시한 'CogVLA: Cognition-Aligned Vision-Language-Action Model via Instruction-Driven Routing & Sparsification' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action Model",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action Model"]}],["$","span","Sparsification",{"className":"page__taxonomy-item","children":["#","Sparsification"]}],["$","span","Instruction-Driven Routing",{"className":"page__taxonomy-item","children":["#","Instruction-Driven Routing"]}],["$","span","Cognition-Aligned AI",{"className":"page__taxonomy-item","children":["#","Cognition-Aligned AI"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}]]}]]}]]}],["$","article","2025-8-29-AWorld_Orchestrating_the_Training_Recipe_for_Agentic_AI",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-29-AWorld_Orchestrating_the_Training_Recipe_for_Agentic_AI/","children":"[논문리뷰] AWorld: Orchestrating the Training Recipe for Agentic AI"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Qintong Wu이 [arXiv]에 게시한 'AWorld: Orchestrating the Training Recipe for Agentic AI' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-29 13:14:44+0900","children":"2025년 8월 29일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Distributed Systems",{"className":"page__taxonomy-item","children":["#","Distributed Systems"]}],["$","span","Experience Generation",{"className":"page__taxonomy-item","children":["#","Experience Generation"]}],["$","span","LLM Fine-tuning",{"className":"page__taxonomy-item","children":["#","LLM Fine-tuning"]}],["$","span","GAIA Benchmark",{"className":"page__taxonomy-item","children":["#","GAIA Benchmark"]}],["$","span","Scalability",{"className":"page__taxonomy-item","children":["#","Scalability"]}],["$","span","AWORLD Framework",{"className":"page__taxonomy-item","children":["#","AWORLD Framework"]}]]}]]}]]}],["$","article","2025-8-28-Taming_the_Chaos_Coordinated_Autoscaling_for_Heterogeneous_and_Disaggregated_LLM_Inference",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-28-Taming_the_Chaos_Coordinated_Autoscaling_for_Heterogeneous_and_Disaggregated_LLM_Inference/","children":"[논문리뷰] Taming the Chaos: Coordinated Autoscaling for Heterogeneous and Disaggregated LLM Inference"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chunlei Han이 [arXiv]에 게시한 'Taming the Chaos: Coordinated Autoscaling for Heterogeneous and Disaggregated LLM Inference' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-28 13:10:39+0900","children":"2025년 8월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Inference",{"className":"page__taxonomy-item","children":["#","LLM Inference"]}],["$","span","Autoscaling",{"className":"page__taxonomy-item","children":["#","Autoscaling"]}],["$","span","Disaggregated Architecture",{"className":"page__taxonomy-item","children":["#","Disaggregated Architecture"]}],["$","span","Heterogeneous Hardware",{"className":"page__taxonomy-item","children":["#","Heterogeneous Hardware"]}],["$","span","Resource Management",{"className":"page__taxonomy-item","children":["#","Resource Management"]}],["$","span","Topology-aware Scheduling",{"className":"page__taxonomy-item","children":["#","Topology-aware Scheduling"]}],["$","span","GPU Utilization",{"className":"page__taxonomy-item","children":["#","GPU Utilization"]}]]}]]}]]}],["$","article","2025-8-28-StepWiser_Stepwise_Generative_Judges_for_Wiser_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-28-StepWiser_Stepwise_Generative_Judges_for_Wiser_Reasoning/","children":"[논문리뷰] StepWiser: Stepwise Generative Judges for Wiser Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Olga Golovneva이 [arXiv]에 게시한 'StepWiser: Stepwise Generative Judges for Wiser Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-28 13:10:39+0900","children":"2025년 8월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Reasoning",{"className":"page__taxonomy-item","children":["#","LLM Reasoning"]}],["$","span","Process Reward Models",{"className":"page__taxonomy-item","children":["#","Process Reward Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Generative Judges",{"className":"page__taxonomy-item","children":["#","Generative Judges"]}],["$","span","Stepwise Feedback",{"className":"page__taxonomy-item","children":["#","Stepwise Feedback"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Meta-Reasoning",{"className":"page__taxonomy-item","children":["#","Meta-Reasoning"]}]]}]]}]]}],["$","article","2025-8-28-Self-Rewarding_Vision-Language_Model_via_Reasoning_Decomposition",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-28-Self-Rewarding_Vision-Language_Model_via_Reasoning_Decomposition/","children":"[논문리뷰] Self-Rewarding Vision-Language Model via Reasoning Decomposition"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhenwen Liang이 [arXiv]에 게시한 'Self-Rewarding Vision-Language Model via Reasoning Decomposition' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-28 13:10:39+0900","children":"2025년 8월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Self-Rewarding",{"className":"page__taxonomy-item","children":["#","Self-Rewarding"]}],["$","span","Reasoning Decomposition",{"className":"page__taxonomy-item","children":["#","Reasoning Decomposition"]}],["$","span","Visual Perception",{"className":"page__taxonomy-item","children":["#","Visual Perception"]}],["$","span","Language Reasoning",{"className":"page__taxonomy-item","children":["#","Language Reasoning"]}],["$","span","Hallucinations",{"className":"page__taxonomy-item","children":["#","Hallucinations"]}],["$","span","Language Shortcuts",{"className":"page__taxonomy-item","children":["#","Language Shortcuts"]}]]}]]}]]}],["$","article","2025-8-28-Predicting_the_Order_of_Upcoming_Tokens_Improves_Language_Modeling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-28-Predicting_the_Order_of_Upcoming_Tokens_Improves_Language_Modeling/","children":"[논문리뷰] Predicting the Order of Upcoming Tokens Improves Language Modeling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Alham Fikri Aji이 [arXiv]에 게시한 'Predicting the Order of Upcoming Tokens Improves Language Modeling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-28 13:10:39+0900","children":"2025년 8월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Language Modeling",{"className":"page__taxonomy-item","children":["#","Language Modeling"]}],["$","span","Next-Token Prediction",{"className":"page__taxonomy-item","children":["#","Next-Token Prediction"]}],["$","span","Multi-Token Prediction",{"className":"page__taxonomy-item","children":["#","Multi-Token Prediction"]}],["$","span","Token Order Prediction",{"className":"page__taxonomy-item","children":["#","Token Order Prediction"]}],["$","span","Auxiliary Objective",{"className":"page__taxonomy-item","children":["#","Auxiliary Objective"]}],["$","span","Learning-to-Rank",{"className":"page__taxonomy-item","children":["#","Learning-to-Rank"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}]]}]]}]]}],["$","article","2025-8-28-MotionFlux_Efficient_Text-Guided_Motion_Generation_through_Rectified_Flow_Matching_and_Preference_Alignment",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-28-MotionFlux_Efficient_Text-Guided_Motion_Generation_through_Rectified_Flow_Matching_and_Preference_Alignment/","children":"[논문리뷰] MotionFlux: Efficient Text-Guided Motion Generation through Rectified Flow Matching and Preference Alignment"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"An-An Liu이 [arXiv]에 게시한 'MotionFlux: Efficient Text-Guided Motion Generation through Rectified Flow Matching and Preference Alignment' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-28 13:10:39+0900","children":"2025년 8월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-Guided Motion Generation",{"className":"page__taxonomy-item","children":["#","Text-Guided Motion Generation"]}],["$","span","Rectified Flow Matching",{"className":"page__taxonomy-item","children":["#","Rectified Flow Matching"]}],["$","span","Preference Alignment",{"className":"page__taxonomy-item","children":["#","Preference Alignment"]}],["$","span","Human Motion Synthesis",{"className":"page__taxonomy-item","children":["#","Human Motion Synthesis"]}],["$","span","Real-time AI",{"className":"page__taxonomy-item","children":["#","Real-time AI"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Self-supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-supervised Learning"]}]]}]]}]]}],["$","article","2025-8-28-Mind_the_Third_Eye_Benchmarking_Privacy_Awareness_in_MLLM-powered_Smartphone_Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-28-Mind_the_Third_Eye_Benchmarking_Privacy_Awareness_in_MLLM-powered_Smartphone_Agents/","children":"[논문리뷰] Mind the Third Eye! Benchmarking Privacy Awareness in MLLM-powered Smartphone Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yue Yao이 [arXiv]에 게시한 'Mind the Third Eye! Benchmarking Privacy Awareness in MLLM-powered Smartphone Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-28 13:10:39+0900","children":"2025년 8월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLMs (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs (MLLMs)"]}],["$","span","Smartphone Agents",{"className":"page__taxonomy-item","children":["#","Smartphone Agents"]}],["$","span","Privacy Awareness",{"className":"page__taxonomy-item","children":["#","Privacy Awareness"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Sensitive Data Detection",{"className":"page__taxonomy-item","children":["#","Sensitive Data Detection"]}],["$","span","Risk Assessment",{"className":"page__taxonomy-item","children":["#","Risk Assessment"]}],["$","span","UI Automation",{"className":"page__taxonomy-item","children":["#","UI Automation"]}]]}]]}]]}],["$","article","2025-8-28-MIDAS_Multimodal_Interactive_Digital-human_Synthesis_via_Real-time_Autoregressive_Video_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-28-MIDAS_Multimodal_Interactive_Digital-human_Synthesis_via_Real-time_Autoregressive_Video_Generation/","children":"[논문리뷰] MIDAS: Multimodal Interactive Digital-human Synthesis via Real-time Autoregressive Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yan Zhou이 [arXiv]에 게시한 'MIDAS: Multimodal Interactive Digital-human Synthesis via Real-time Autoregressive Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-28 13:10:39+0900","children":"2025년 8월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Generation",{"className":"page__taxonomy-item","children":["#","Multimodal Generation"]}],["$","span","Digital Human Synthesis",{"className":"page__taxonomy-item","children":["#","Digital Human Synthesis"]}],["$","span","Real-time Video Generation",{"className":"page__taxonomy-item","children":["#","Real-time Video Generation"]}],["$","span","Autoregressive LLM",{"className":"page__taxonomy-item","children":["#","Autoregressive LLM"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Deep Compression Autoencoder",{"className":"page__taxonomy-item","children":["#","Deep Compression Autoencoder"]}],["$","span","Exposure Bias Mitigation",{"className":"page__taxonomy-item","children":["#","Exposure Bias Mitigation"]}],["$","span","Streaming Inference",{"className":"page__taxonomy-item","children":["#","Streaming Inference"]}]]}]]}]]}],["$","article","2025-8-28-Gaze_into_the_Heart_A_Multi-View_Video_Dataset_for_rPPG_and_Health_Biomarkers_Estimation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-28-Gaze_into_the_Heart_A_Multi-View_Video_Dataset_for_rPPG_and_Health_Biomarkers_Estimation/","children":"[논문리뷰] Gaze into the Heart: A Multi-View Video Dataset for rPPG and Health Biomarkers Estimation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Anton Ivaschenko이 [arXiv]에 게시한 'Gaze into the Heart: A Multi-View Video Dataset for rPPG and Health Biomarkers Estimation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-28 13:10:39+0900","children":"2025년 8월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","rPPG",{"className":"page__taxonomy-item","children":["#","rPPG"]}],["$","span","Multi-View Video Dataset",{"className":"page__taxonomy-item","children":["#","Multi-View Video Dataset"]}],["$","span","Health Biomarkers",{"className":"page__taxonomy-item","children":["#","Health Biomarkers"]}],["$","span","Physiological Monitoring",{"className":"page__taxonomy-item","children":["#","Physiological Monitoring"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}],["$","span","Telemedicine",{"className":"page__taxonomy-item","children":["#","Telemedicine"]}],["$","span","Biosignals",{"className":"page__taxonomy-item","children":["#","Biosignals"]}]]}]]}]]}],["$","article","2025-8-28-Discrete_Diffusion_VLA_Bringing_Discrete_Diffusion_to_Action_Decoding_in_Vision-Language-Action_Policies",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-28-Discrete_Diffusion_VLA_Bringing_Discrete_Diffusion_to_Action_Decoding_in_Vision-Language-Action_Policies/","children":"[논문리뷰] Discrete Diffusion VLA: Bringing Discrete Diffusion to Action Decoding in Vision-Language-Action Policies"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Sitong Mao이 [arXiv]에 게시한 'Discrete Diffusion VLA: Bringing Discrete Diffusion to Action Decoding in Vision-Language-Action Policies' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-28 13:10:39+0900","children":"2025년 8월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action (VLA)",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action (VLA)"]}],["$","span","Discrete Diffusion",{"className":"page__taxonomy-item","children":["#","Discrete Diffusion"]}],["$","span","Action Decoding",{"className":"page__taxonomy-item","children":["#","Action Decoding"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Robot Control",{"className":"page__taxonomy-item","children":["#","Robot Control"]}],["$","span","Masked Modeling",{"className":"page__taxonomy-item","children":["#","Masked Modeling"]}],["$","span","Adaptive Decoding",{"className":"page__taxonomy-item","children":["#","Adaptive Decoding"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}]]}]]}]]}],["$","article","2025-8-28-Diffusion_Language_Models_Know_the_Answer_Before_Decoding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-28-Diffusion_Language_Models_Know_the_Answer_Before_Decoding/","children":"[논문리뷰] Diffusion Language Models Know the Answer Before Decoding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shilin Yan이 [arXiv]에 게시한 'Diffusion Language Models Know the Answer Before Decoding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-28 13:10:39+0900","children":"2025년 8월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Language Models",{"className":"page__taxonomy-item","children":["#","Diffusion Language Models"]}],["$","span","DLM Acceleration",{"className":"page__taxonomy-item","children":["#","DLM Acceleration"]}],["$","span","Early Answer Convergence",{"className":"page__taxonomy-item","children":["#","Early Answer Convergence"]}],["$","span","Early Commit Decoding",{"className":"page__taxonomy-item","children":["#","Early Commit Decoding"]}],["$","span","Confidence Gap",{"className":"page__taxonomy-item","children":["#","Confidence Gap"]}],["$","span","Inference Speedup",{"className":"page__taxonomy-item","children":["#","Inference Speedup"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}]]}]]}]]}],["$","article","2025-8-28-DeepScholar-Bench_A_Live_Benchmark_and_Automated_Evaluation_for_Generative_Research_Synthesis",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-28-DeepScholar-Bench_A_Live_Benchmark_and_Automated_Evaluation_for_Generative_Research_Synthesis/","children":"[논문리뷰] DeepScholar-Bench: A Live Benchmark and Automated Evaluation for Generative Research Synthesis"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ion Stoica이 [arXiv]에 게시한 'DeepScholar-Bench: A Live Benchmark and Automated Evaluation for Generative Research Synthesis' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-28 13:10:39+0900","children":"2025년 8월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Generative Research Synthesis",{"className":"page__taxonomy-item","children":["#","Generative Research Synthesis"]}],["$","span","Live Benchmark",{"className":"page__taxonomy-item","children":["#","Live Benchmark"]}],["$","span","Automated Evaluation",{"className":"page__taxonomy-item","children":["#","Automated Evaluation"]}],["$","span","LLM-as-a-judge",{"className":"page__taxonomy-item","children":["#","LLM-as-a-judge"]}],["$","span","Related Work Generation",{"className":"page__taxonomy-item","children":["#","Related Work Generation"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","Verifiability",{"className":"page__taxonomy-item","children":["#","Verifiability"]}]]}]]}]]}],["$","article","2025-8-28-CODA_Coordinating_the_Cerebrum_and_Cerebellum_for_a_Dual-Brain_Computer_Use_Agent_with_Decoupled_Reinforcement_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-28-CODA_Coordinating_the_Cerebrum_and_Cerebellum_for_a_Dual-Brain_Computer_Use_Agent_with_Decoupled_Reinforcement_Learning/","children":"[논문리뷰] CODA: Coordinating the Cerebrum and Cerebellum for a Dual-Brain Computer Use Agent with Decoupled Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jianze Liang이 [arXiv]에 게시한 'CODA: Coordinating the Cerebrum and Cerebellum for a Dual-Brain Computer Use Agent with Decoupled Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-28 13:10:39+0900","children":"2025년 8월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","GUI Agents",{"className":"page__taxonomy-item","children":["#","GUI Agents"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Planner-Executor Architecture",{"className":"page__taxonomy-item","children":["#","Planner-Executor Architecture"]}],["$","span","Decoupled Training",{"className":"page__taxonomy-item","children":["#","Decoupled Training"]}],["$","span","Large Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Large Vision-Language Models"]}],["$","span","Specialization",{"className":"page__taxonomy-item","children":["#","Specialization"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Computer Use Agent",{"className":"page__taxonomy-item","children":["#","Computer Use Agent"]}]]}]]}]]}],["$","article","2025-8-28-Beyond_Transcription_Mechanistic_Interpretability_in_ASR",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-28-Beyond_Transcription_Mechanistic_Interpretability_in_ASR/","children":"[논문리뷰] Beyond Transcription: Mechanistic Interpretability in ASR"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Aviv Shamsian이 [arXiv]에 게시한 'Beyond Transcription: Mechanistic Interpretability in ASR' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-28 13:10:39+0900","children":"2025년 8월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","ASR",{"className":"page__taxonomy-item","children":["#","ASR"]}],["$","span","Mechanistic Interpretability",{"className":"page__taxonomy-item","children":["#","Mechanistic Interpretability"]}],["$","span","Logit Lens",{"className":"page__taxonomy-item","children":["#","Logit Lens"]}],["$","span","Linear Probing",{"className":"page__taxonomy-item","children":["#","Linear Probing"]}],["$","span","Activation Patching",{"className":"page__taxonomy-item","children":["#","Activation Patching"]}],["$","span","Hallucinations",{"className":"page__taxonomy-item","children":["#","Hallucinations"]}],["$","span","Repetitions",{"className":"page__taxonomy-item","children":["#","Repetitions"]}],["$","span","Encoder-Decoder",{"className":"page__taxonomy-item","children":["#","Encoder-Decoder"]}]]}]]}]]}],["$","article","2025-8-28-AudioStory_Generating_Long-Form_Narrative_Audio_with_Large_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-28-AudioStory_Generating_Long-Form_Narrative_Audio_with_Large_Language_Models/","children":"[논문리뷰] AudioStory: Generating Long-Form Narrative Audio with Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yixiao Ge이 [arXiv]에 게시한 'AudioStory: Generating Long-Form Narrative Audio with Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-28 13:10:39+0900","children":"2025년 8월 28일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Audio",{"className":"page__taxonomy-item","children":["#","Text-to-Audio"]}],["$","span","Long-Form Audio Generation",{"className":"page__taxonomy-item","children":["#","Long-Form Audio Generation"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Narrative Reasoning",{"className":"page__taxonomy-item","children":["#","Narrative Reasoning"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Progressive Training",{"className":"page__taxonomy-item","children":["#","Progressive Training"]}]]}]]}]]}],["$","article","2025-8-27-Wan-S2V_Audio-Driven_Cinematic_Video_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-Wan-S2V_Audio-Driven_Cinematic_Video_Generation/","children":"[논문리뷰] Wan-S2V: Audio-Driven Cinematic Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chaonan Ji이 [arXiv]에 게시한 'Wan-S2V: Audio-Driven Cinematic Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Audio-Driven Video Generation",{"className":"page__taxonomy-item","children":["#","Audio-Driven Video Generation"]}],["$","span","Cinematic Video",{"className":"page__taxonomy-item","children":["#","Cinematic Video"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Long Video Consistency",{"className":"page__taxonomy-item","children":["#","Long Video Consistency"]}],["$","span","Human Animation",{"className":"page__taxonomy-item","children":["#","Human Animation"]}],["$","span","Multimodal Control",{"className":"page__taxonomy-item","children":["#","Multimodal Control"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}]]}]]}]]}],["$","article","2025-8-27-VoxHammer_Training-Free_Precise_and_Coherent_3D_Editing_in_Native_3D_Space",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-VoxHammer_Training-Free_Precise_and_Coherent_3D_Editing_in_Native_3D_Space/","children":"[논문리뷰] VoxHammer: Training-Free Precise and Coherent 3D Editing in Native 3D Space"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Rui Chen이 [arXiv]에 게시한 'VoxHammer: Training-Free Precise and Coherent 3D Editing in Native 3D Space' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Editing",{"className":"page__taxonomy-item","children":["#","3D Editing"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Latent Space",{"className":"page__taxonomy-item","children":["#","Latent Space"]}],["$","span","3D Inversion",{"className":"page__taxonomy-item","children":["#","3D Inversion"]}],["$","span","Contextual Feature Replacement",{"className":"page__taxonomy-item","children":["#","Contextual Feature Replacement"]}],["$","span","3D Consistency",{"className":"page__taxonomy-item","children":["#","3D Consistency"]}],["$","span","Edit3D-Bench",{"className":"page__taxonomy-item","children":["#","Edit3D-Bench"]}]]}]]}]]}],["$","article","2025-8-27-VibeVoice_Technical_Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-VibeVoice_Technical_Report/","children":"[논문리뷰] VibeVoice Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yaoyao Chang이 [arXiv]에 게시한 'VibeVoice Technical Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Speech Synthesis",{"className":"page__taxonomy-item","children":["#","Speech Synthesis"]}],["$","span","Long-form Audio",{"className":"page__taxonomy-item","children":["#","Long-form Audio"]}],["$","span","Multi-speaker",{"className":"page__taxonomy-item","children":["#","Multi-speaker"]}],["$","span","Next-token Diffusion",{"className":"page__taxonomy-item","children":["#","Next-token Diffusion"]}],["$","span","Speech Tokenizer",{"className":"page__taxonomy-item","children":["#","Speech Tokenizer"]}],["$","span","Large Language Model",{"className":"page__taxonomy-item","children":["#","Large Language Model"]}],["$","span","Variational Autoencoder",{"className":"page__taxonomy-item","children":["#","Variational Autoencoder"]}],["$","span","Audio Compression",{"className":"page__taxonomy-item","children":["#","Audio Compression"]}]]}]]}]]}],["$","article","2025-8-27-Unraveling_the_cognitive_patterns_of_Large_Language_Models_through_module_communities",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-Unraveling_the_cognitive_patterns_of_Large_Language_Models_through_module_communities/","children":"[논문리뷰] Unraveling the cognitive patterns of Large Language Models through module communities"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jianxi Gao이 [arXiv]에 게시한 'Unraveling the cognitive patterns of Large Language Models through module communities' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Network Community Structure",{"className":"page__taxonomy-item","children":["#","Network Community Structure"]}],["$","span","Cognitive Skills",{"className":"page__taxonomy-item","children":["#","Cognitive Skills"]}],["$","span","AI Interpretability",{"className":"page__taxonomy-item","children":["#","AI Interpretability"]}],["$","span","Module Communities",{"className":"page__taxonomy-item","children":["#","Module Communities"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Neural Plasticity",{"className":"page__taxonomy-item","children":["#","Neural Plasticity"]}]]}]]}]]}],["$","article","2025-8-27-UltraMemV2_Memory_Networks_Scaling_to_120B_Parameters_with_Superior_Long-Context_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-UltraMemV2_Memory_Networks_Scaling_to_120B_Parameters_with_Superior_Long-Context_Learning/","children":"[논문리뷰] UltraMemV2: Memory Networks Scaling to 120B Parameters with Superior Long-Context Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ran Guo이 [arXiv]에 게시한 'UltraMemV2: Memory Networks Scaling to 120B Parameters with Superior Long-Context Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Memory Networks",{"className":"page__taxonomy-item","children":["#","Memory Networks"]}],["$","span","Mixture of Experts (MoE)",{"className":"page__taxonomy-item","children":["#","Mixture of Experts (MoE)"]}],["$","span","Long-Context Learning",{"className":"page__taxonomy-item","children":["#","Long-Context Learning"]}],["$","span","Sparse Models",{"className":"page__taxonomy-item","children":["#","Sparse Models"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Efficient Inference",{"className":"page__taxonomy-item","children":["#","Efficient Inference"]}]]}]]}]]}],["$","article","2025-8-27-TreePO_Bridging_the_Gap_of_Policy_Optimization_and_Efficacy_and_Inference_Efficiency_with_Heuristic_Tree-based_Modeling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-TreePO_Bridging_the_Gap_of_Policy_Optimization_and_Efficacy_and_Inference_Efficiency_with_Heuristic_Tree-based_Modeling/","children":"[논문리뷰] TreePO: Bridging the Gap of Policy Optimization and Efficacy and Inference Efficiency with Heuristic Tree-based Modeling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhoufutu Wen이 [arXiv]에 게시한 'TreePO: Bridging the Gap of Policy Optimization and Efficacy and Inference Efficiency with Heuristic Tree-based Modeling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Inference Efficiency",{"className":"page__taxonomy-item","children":["#","Inference Efficiency"]}],["$","span","Tree Search",{"className":"page__taxonomy-item","children":["#","Tree Search"]}],["$","span","Segment-level Decoding",{"className":"page__taxonomy-item","children":["#","Segment-level Decoding"]}],["$","span","Advantage Estimation",{"className":"page__taxonomy-item","children":["#","Advantage Estimation"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}]]}]]}]]}],["$","article","2025-8-27-Training_Language_Model_Agents_to_Find_Vulnerabilities_with_CTF-Dojo",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-Training_Language_Model_Agents_to_Find_Vulnerabilities_with_CTF-Dojo/","children":"[논문리뷰] Training Language Model Agents to Find Vulnerabilities with CTF-Dojo"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zijian Wang이 [arXiv]에 게시한 'Training Language Model Agents to Find Vulnerabilities with CTF-Dojo' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Cybersecurity",{"className":"page__taxonomy-item","children":["#","Cybersecurity"]}],["$","span","CTF Challenges",{"className":"page__taxonomy-item","children":["#","CTF Challenges"]}],["$","span","Vulnerability Detection",{"className":"page__taxonomy-item","children":["#","Vulnerability Detection"]}],["$","span","Execution Environments",{"className":"page__taxonomy-item","children":["#","Execution Environments"]}],["$","span","Docker",{"className":"page__taxonomy-item","children":["#","Docker"]}],["$","span","Automated Training",{"className":"page__taxonomy-item","children":["#","Automated Training"]}],["$","span","Verifiable Feedback",{"className":"page__taxonomy-item","children":["#","Verifiable Feedback"]}]]}]]}]]}],["$","article","2025-8-27-ThinkDial_An_Open_Recipe_for_Controlling_Reasoning_Effort_in_Large_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-ThinkDial_An_Open_Recipe_for_Controlling_Reasoning_Effort_in_Large_Language_Models/","children":"[논문리뷰] ThinkDial: An Open Recipe for Controlling Reasoning Effort in Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiangjie Chen이 [arXiv]에 게시한 'ThinkDial: An Open Recipe for Controlling Reasoning Effort in Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Controllable Reasoning",{"className":"page__taxonomy-item","children":["#","Controllable Reasoning"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Reasoning Compression",{"className":"page__taxonomy-item","children":["#","Reasoning Compression"]}],["$","span","Budget-Aware Training",{"className":"page__taxonomy-item","children":["#","Budget-Aware Training"]}]]}]]}]]}],["$","article","2025-8-27-Spacer_Towards_Engineered_Scientific_Inspiration",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-Spacer_Towards_Engineered_Scientific_Inspiration/","children":"[논문리뷰] Spacer: Towards Engineered Scientific Inspiration"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"zerojun48이 [arXiv]에 게시한 'Spacer: Towards Engineered Scientific Inspiration' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Scientific Discovery",{"className":"page__taxonomy-item","children":["#","Scientific Discovery"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Decontextualization",{"className":"page__taxonomy-item","children":["#","Decontextualization"]}],["$","span","Keyword Graph",{"className":"page__taxonomy-item","children":["#","Keyword Graph"]}],["$","span","Multi-Agent System",{"className":"page__taxonomy-item","children":["#","Multi-Agent System"]}],["$","span","Scientific Ideation",{"className":"page__taxonomy-item","children":["#","Scientific Ideation"]}],["$","span","Research Automation",{"className":"page__taxonomy-item","children":["#","Research Automation"]}],["$","span","Inspiration Engine",{"className":"page__taxonomy-item","children":["#","Inspiration Engine"]}]]}]]}]]}],["$","article","2025-8-27-ReportBench_Evaluating_Deep_Research_Agents_via_Academic_Survey_Tasks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-ReportBench_Evaluating_Deep_Research_Agents_via_Academic_Survey_Tasks/","children":"[논문리뷰] ReportBench: Evaluating Deep Research Agents via Academic Survey Tasks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kai Jia이 [arXiv]에 게시한 'ReportBench: Evaluating Deep Research Agents via Academic Survey Tasks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Deep Research Agents",{"className":"page__taxonomy-item","children":["#","Deep Research Agents"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Academic Survey",{"className":"page__taxonomy-item","children":["#","Academic Survey"]}],["$","span","Factual Accuracy",{"className":"page__taxonomy-item","children":["#","Factual Accuracy"]}],["$","span","Citation Verification",{"className":"page__taxonomy-item","children":["#","Citation Verification"]}],["$","span","Report Generation",{"className":"page__taxonomy-item","children":["#","Report Generation"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Hallucination",{"className":"page__taxonomy-item","children":["#","Hallucination"]}]]}]]}]]}],["$","article","2025-8-27-QueryBandits_for_Hallucination_Mitigation_Exploiting_Semantic_Features_for_No-Regret_Rewriting",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-QueryBandits_for_Hallucination_Mitigation_Exploiting_Semantic_Features_for_No-Regret_Rewriting/","children":"[논문리뷰] QueryBandits for Hallucination Mitigation: Exploiting Semantic Features for No-Regret Rewriting"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Manuela Veloso이 [arXiv]에 게시한 'QueryBandits for Hallucination Mitigation: Exploiting Semantic Features for No-Regret Rewriting' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Hallucination Mitigation",{"className":"page__taxonomy-item","children":["#","Hallucination Mitigation"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Contextual Bandits",{"className":"page__taxonomy-item","children":["#","Contextual Bandits"]}],["$","span","Query Rewriting",{"className":"page__taxonomy-item","children":["#","Query Rewriting"]}],["$","span","Semantic Features",{"className":"page__taxonomy-item","children":["#","Semantic Features"]}],["$","span","No-Regret Learning",{"className":"page__taxonomy-item","children":["#","No-Regret Learning"]}]]}]]}]]}],["$","article","2025-8-27-Pixie_Fast_and_Generalizable_Supervised_Learning_of_3D_Physics_from_Pixels",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-Pixie_Fast_and_Generalizable_Supervised_Learning_of_3D_Physics_from_Pixels/","children":"[논문리뷰] Pixie: Fast and Generalizable Supervised Learning of 3D Physics from Pixels"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Dinesh Jayaraman이 [arXiv]에 게시한 'Pixie: Fast and Generalizable Supervised Learning of 3D Physics from Pixels' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Physics Prediction",{"className":"page__taxonomy-item","children":["#","3D Physics Prediction"]}],["$","span","Supervised Learning",{"className":"page__taxonomy-item","children":["#","Supervised Learning"]}],["$","span","CLIP Features",{"className":"page__taxonomy-item","children":["#","CLIP Features"]}],["$","span","Neural Radiance Fields",{"className":"page__taxonomy-item","children":["#","Neural Radiance Fields"]}],["$","span","Material Point Method",{"className":"page__taxonomy-item","children":["#","Material Point Method"]}],["$","span","PIXIEVERSE Dataset",{"className":"page__taxonomy-item","children":["#","PIXIEVERSE Dataset"]}],["$","span","Zero-Shot Generalization",{"className":"page__taxonomy-item","children":["#","Zero-Shot Generalization"]}]]}]]}]]}],["$","article","2025-8-27-Optimal_Sparsity_of_Mixture-of-Experts_Language_Models_for_Reasoning_Tasks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-Optimal_Sparsity_of_Mixture-of-Experts_Language_Models_for_Reasoning_Tasks/","children":"[논문리뷰] Optimal Sparsity of Mixture-of-Experts Language Models for Reasoning Tasks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Daisuke Nohara이 [arXiv]에 게시한 'Optimal Sparsity of Mixture-of-Experts Language Models for Reasoning Tasks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Mixture-of-Experts (MoE)",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts (MoE)"]}],["$","span","Sparsity",{"className":"page__taxonomy-item","children":["#","Sparsity"]}],["$","span","Scaling Laws",{"className":"page__taxonomy-item","children":["#","Scaling Laws"]}],["$","span","Reasoning Tasks",{"className":"page__taxonomy-item","children":["#","Reasoning Tasks"]}],["$","span","Memorization",{"className":"page__taxonomy-item","children":["#","Memorization"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Generalization Gap",{"className":"page__taxonomy-item","children":["#","Generalization Gap"]}],["$","span","Top-k Routing",{"className":"page__taxonomy-item","children":["#","Top-k Routing"]}]]}]]}]]}],["$","article","2025-8-27-OmniHuman-1.5_Instilling_an_Active_Mind_in_Avatars_via_Cognitive_Simulation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-OmniHuman-1.5_Instilling_an_Active_Mind_in_Avatars_via_Cognitive_Simulation/","children":"[논문리뷰] OmniHuman-1.5: Instilling an Active Mind in Avatars via Cognitive Simulation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiaqi Yang이 [arXiv]에 게시한 'OmniHuman-1.5: Instilling an Active Mind in Avatars via Cognitive Simulation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Avatar Generation",{"className":"page__taxonomy-item","children":["#","Video Avatar Generation"]}],["$","span","Cognitive Simulation",{"className":"page__taxonomy-item","children":["#","Cognitive Simulation"]}],["$","span","Multimodal Large Language Models (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models (MLLMs)"]}],["$","span","Diffusion Transformers (DiT)",{"className":"page__taxonomy-item","children":["#","Diffusion Transformers (DiT)"]}],["$","span","Multimodal Fusion",{"className":"page__taxonomy-item","children":["#","Multimodal Fusion"]}],["$","span","Human Motion Synthesis",{"className":"page__taxonomy-item","children":["#","Human Motion Synthesis"]}],["$","span","Contextual Animation",{"className":"page__taxonomy-item","children":["#","Contextual Animation"]}]]}]]}]]}],["$","article","2025-8-27-ObjFiller-3D_Consistent_Multi-view_3D_Inpainting_via_Video_Diffusion_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-ObjFiller-3D_Consistent_Multi-view_3D_Inpainting_via_Video_Diffusion_Models/","children":"[논문리뷰] ObjFiller-3D: Consistent Multi-view 3D Inpainting via Video Diffusion Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Beiqi Chen이 [arXiv]에 게시한 'ObjFiller-3D: Consistent Multi-view 3D Inpainting via Video Diffusion Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Inpainting",{"className":"page__taxonomy-item","children":["#","3D Inpainting"]}],["$","span","Multi-view Consistency",{"className":"page__taxonomy-item","children":["#","Multi-view Consistency"]}],["$","span","Video Diffusion Models",{"className":"page__taxonomy-item","children":["#","Video Diffusion Models"]}],["$","span","3D Object Completion",{"className":"page__taxonomy-item","children":["#","3D Object Completion"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","LoRA",{"className":"page__taxonomy-item","children":["#","LoRA"]}],["$","span","3D Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","3D Gaussian Splatting"]}]]}]]}]]}],["$","article","2025-8-27-MovieCORE_COgnitive_REasoning_in_Movies",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-MovieCORE_COgnitive_REasoning_in_Movies/","children":"[논문리뷰] MovieCORE: COgnitive REasoning in Movies"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hung-Ting Su이 [arXiv]에 게시한 'MovieCORE: COgnitive REasoning in Movies' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Question Answering (VQA)",{"className":"page__taxonomy-item","children":["#","Video Question Answering (VQA)"]}],["$","span","Cognitive Reasoning",{"className":"page__taxonomy-item","children":["#","Cognitive Reasoning"]}],["$","span","System-2 Thinking",{"className":"page__taxonomy-item","children":["#","System-2 Thinking"]}],["$","span","Multi-agent LLMs",{"className":"page__taxonomy-item","children":["#","Multi-agent LLMs"]}],["$","span","Dataset Creation",{"className":"page__taxonomy-item","children":["#","Dataset Creation"]}],["$","span","Movie Understanding",{"className":"page__taxonomy-item","children":["#","Movie Understanding"]}],["$","span","Cinematic Content",{"className":"page__taxonomy-item","children":["#","Cinematic Content"]}],["$","span","Agentic Enhancement",{"className":"page__taxonomy-item","children":["#","Agentic Enhancement"]}]]}]]}]]}],["$","article","2025-8-27-FastMeshEfficient_Artistic_Mesh_Generation_via_Component_Decoupling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-FastMeshEfficient_Artistic_Mesh_Generation_via_Component_Decoupling/","children":"[논문리뷰] FastMesh:Efficient Artistic Mesh Generation via Component Decoupling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xingang Pan이 [arXiv]에 게시한 'FastMesh:Efficient Artistic Mesh Generation via Component Decoupling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Mesh Generation",{"className":"page__taxonomy-item","children":["#","3D Mesh Generation"]}],["$","span","Component Decoupling",{"className":"page__taxonomy-item","children":["#","Component Decoupling"]}],["$","span","Autoregressive Models",{"className":"page__taxonomy-item","children":["#","Autoregressive Models"]}],["$","span","Bidirectional Transformer",{"className":"page__taxonomy-item","children":["#","Bidirectional Transformer"]}],["$","span","Fidelity Enhancement",{"className":"page__taxonomy-item","children":["#","Fidelity Enhancement"]}],["$","span","Prediction Filtering",{"className":"page__taxonomy-item","children":["#","Prediction Filtering"]}],["$","span","Token Efficiency",{"className":"page__taxonomy-item","children":["#","Token Efficiency"]}],["$","span","Artistic Meshes",{"className":"page__taxonomy-item","children":["#","Artistic Meshes"]}]]}]]}]]}],["$","article","2025-8-27-Demystifying_Scientific_Problem-Solving_in_LLMs_by_Probing_Knowledge_and_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-Demystifying_Scientific_Problem-Solving_in_LLMs_by_Probing_Knowledge_and_Reasoning/","children":"[논문리뷰] Demystifying Scientific Problem-Solving in LLMs by Probing Knowledge and Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Arman Cohan이 [arXiv]에 게시한 'Demystifying Scientific Problem-Solving in LLMs by Probing Knowledge and Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Scientific Reasoning",{"className":"page__taxonomy-item","children":["#","Scientific Reasoning"]}],["$","span","Knowledge Retrieval",{"className":"page__taxonomy-item","children":["#","Knowledge Retrieval"]}],["$","span","Reasoning Probing",{"className":"page__taxonomy-item","children":["#","Reasoning Probing"]}],["$","span","Benchmarks",{"className":"page__taxonomy-item","children":["#","Benchmarks"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}]]}]]}]]}],["$","article","2025-8-27-CMPhysBench_A_Benchmark_for_Evaluating_Large_Language_Models_in_Condensed_Matter_Physics",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-CMPhysBench_A_Benchmark_for_Evaluating_Large_Language_Models_in_Condensed_Matter_Physics/","children":"[논문리뷰] CMPhysBench: A Benchmark for Evaluating Large Language Models in Condensed Matter Physics"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Dongchen Huang이 [arXiv]에 게시한 'CMPhysBench: A Benchmark for Evaluating Large Language Models in Condensed Matter Physics' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Condensed Matter Physics",{"className":"page__taxonomy-item","children":["#","Condensed Matter Physics"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Scientific Reasoning",{"className":"page__taxonomy-item","children":["#","Scientific Reasoning"]}],["$","span","Evaluation Metric",{"className":"page__taxonomy-item","children":["#","Evaluation Metric"]}],["$","span","Expression Edit Distance",{"className":"page__taxonomy-item","children":["#","Expression Edit Distance"]}],["$","span","Problem Solving",{"className":"page__taxonomy-item","children":["#","Problem Solving"]}]]}]]}]]}],["$","article","2025-8-27-ClaimGen-CN_A_Large-scale_Chinese_Dataset_for_Legal_Claim_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-ClaimGen-CN_A_Large-scale_Chinese_Dataset_for_Legal_Claim_Generation/","children":"[논문리뷰] ClaimGen-CN: A Large-scale Chinese Dataset for Legal Claim Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kun Kuang이 [arXiv]에 게시한 'ClaimGen-CN: A Large-scale Chinese Dataset for Legal Claim Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Legal AI",{"className":"page__taxonomy-item","children":["#","Legal AI"]}],["$","span","Natural Language Processing",{"className":"page__taxonomy-item","children":["#","Natural Language Processing"]}],["$","span","Claim Generation",{"className":"page__taxonomy-item","children":["#","Claim Generation"]}],["$","span","Chinese Legal Dataset",{"className":"page__taxonomy-item","children":["#","Chinese Legal Dataset"]}],["$","span","Factuality",{"className":"page__taxonomy-item","children":["#","Factuality"]}],["$","span","Clarity",{"className":"page__taxonomy-item","children":["#","Clarity"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Zero-shot Evaluation",{"className":"page__taxonomy-item","children":["#","Zero-shot Evaluation"]}]]}]]}]]}],["$","article","2025-8-27-CineScale_Free_Lunch_in_High-Resolution_Cinematic_Visual_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-CineScale_Free_Lunch_in_High-Resolution_Cinematic_Visual_Generation/","children":"[논문리뷰] CineScale: Free Lunch in High-Resolution Cinematic Visual Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ziwei Liu이 [arXiv]에 게시한 'CineScale: Free Lunch in High-Resolution Cinematic Visual Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","High-Resolution Generation",{"className":"page__taxonomy-item","children":["#","High-Resolution Generation"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","UNet Architecture",{"className":"page__taxonomy-item","children":["#","UNet Architecture"]}],["$","span","DiT Architecture",{"className":"page__taxonomy-item","children":["#","DiT Architecture"]}],["$","span","Scale Fusion",{"className":"page__taxonomy-item","children":["#","Scale Fusion"]}],["$","span","LoRA Fine-tuning",{"className":"page__taxonomy-item","children":["#","LoRA Fine-tuning"]}]]}]]}]]}],["$","article","2025-8-27-Autoregressive_Universal_Video_Segmentation_Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-27-Autoregressive_Universal_Video_Segmentation_Model/","children":"[논문리뷰] Autoregressive Universal Video Segmentation Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Albert Gu이 [arXiv]에 게시한 'Autoregressive Universal Video Segmentation Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-27 13:22:18+0900","children":"2025년 8월 27일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Segmentation",{"className":"page__taxonomy-item","children":["#","Video Segmentation"]}],["$","span","Autoregressive Model",{"className":"page__taxonomy-item","children":["#","Autoregressive Model"]}],["$","span","Universal Model",{"className":"page__taxonomy-item","children":["#","Universal Model"]}],["$","span","State Space Models",{"className":"page__taxonomy-item","children":["#","State Space Models"]}],["$","span","Mamba",{"className":"page__taxonomy-item","children":["#","Mamba"]}],["$","span","Parallel Training",{"className":"page__taxonomy-item","children":["#","Parallel Training"]}],["$","span","Streaming Video",{"className":"page__taxonomy-item","children":["#","Streaming Video"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}]]}]]}]]}],["$","article","2025-8-26-Visual-CoG_Stage-Aware_Reinforcement_Learning_with_Chain_of_Guidance_for_Text-to-Image_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-Visual-CoG_Stage-Aware_Reinforcement_Learning_with_Chain_of_Guidance_for_Text-to-Image_Generation/","children":"[논문리뷰] Visual-CoG: Stage-Aware Reinforcement Learning with Chain of Guidance for Text-to-Image Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Haoxiang Shi이 [arXiv]에 게시한 'Visual-CoG: Stage-Aware Reinforcement Learning with Chain of Guidance for Text-to-Image Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-26 13:21:57+0900","children":"2025년 8월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Chain of Thought",{"className":"page__taxonomy-item","children":["#","Chain of Thought"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Stage-Aware Rewards",{"className":"page__taxonomy-item","children":["#","Stage-Aware Rewards"]}],["$","span","Semantic Reasoning",{"className":"page__taxonomy-item","children":["#","Semantic Reasoning"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}]]}]]}]]}],["$","article","2025-8-26-UQ_Assessing_Language_Models_on_Unsolved_Questions",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-UQ_Assessing_Language_Models_on_Unsolved_Questions/","children":"[논문리뷰] UQ: Assessing Language Models on Unsolved Questions"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wei Liu이 [arXiv]에 게시한 'UQ: Assessing Language Models on Unsolved Questions' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-26 13:21:57+0900","children":"2025년 8월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Unsolved Questions",{"className":"page__taxonomy-item","children":["#","Unsolved Questions"]}],["$","span","AI Benchmark",{"className":"page__taxonomy-item","children":["#","AI Benchmark"]}],["$","span","Oracle-Free Validation",{"className":"page__taxonomy-item","children":["#","Oracle-Free Validation"]}],["$","span","Generator-Validator Gap",{"className":"page__taxonomy-item","children":["#","Generator-Validator Gap"]}],["$","span","Community Evaluation",{"className":"page__taxonomy-item","children":["#","Community Evaluation"]}],["$","span","Stack Exchange",{"className":"page__taxonomy-item","children":["#","Stack Exchange"]}]]}]]}]]}],["$","article","2025-8-26-TaDiCodec_Text-aware_Diffusion_Speech_Tokenizer_for_Speech_Language_Modeling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-TaDiCodec_Text-aware_Diffusion_Speech_Tokenizer_for_Speech_Language_Modeling/","children":"[논문리뷰] TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiaqi Li이 [arXiv]에 게시한 'TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-26 13:21:57+0900","children":"2025년 8월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Speech Tokenizer",{"className":"page__taxonomy-item","children":["#","Speech Tokenizer"]}],["$","span","Diffusion Model",{"className":"page__taxonomy-item","children":["#","Diffusion Model"]}],["$","span","Text-to-Speech",{"className":"page__taxonomy-item","children":["#","Text-to-Speech"]}],["$","span","Speech Language Modeling",{"className":"page__taxonomy-item","children":["#","Speech Language Modeling"]}],["$","span","Low Bitrate Codec",{"className":"page__taxonomy-item","children":["#","Low Bitrate Codec"]}],["$","span","End-to-End Training",{"className":"page__taxonomy-item","children":["#","End-to-End Training"]}],["$","span","Binary Spherical Quantization",{"className":"page__taxonomy-item","children":["#","Binary Spherical Quantization"]}]]}]]}]]}],["$","article","2025-8-26-T2I-ReasonBench_Benchmarking_Reasoning-Informed_Text-to-Image_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-T2I-ReasonBench_Benchmarking_Reasoning-Informed_Text-to-Image_Generation/","children":"[논문리뷰] T2I-ReasonBench: Benchmarking Reasoning-Informed Text-to-Image Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xihui Liu이 [arXiv]에 게시한 'T2I-ReasonBench: Benchmarking Reasoning-Informed Text-to-Image Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-26 13:21:57+0900","children":"2025년 8월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Reasoning Benchmark",{"className":"page__taxonomy-item","children":["#","Reasoning Benchmark"]}],["$","span","Idiom Interpretation",{"className":"page__taxonomy-item","children":["#","Idiom Interpretation"]}],["$","span","Textual Image Design",{"className":"page__taxonomy-item","children":["#","Textual Image Design"]}],["$","span","Entity Reasoning",{"className":"page__taxonomy-item","children":["#","Entity Reasoning"]}],["$","span","Scientific Reasoning",{"className":"page__taxonomy-item","children":["#","Scientific Reasoning"]}],["$","span","Multimodal LLM Evaluation",{"className":"page__taxonomy-item","children":["#","Multimodal LLM Evaluation"]}]]}]]}]]}],["$","article","2025-8-26-ST-Raptor_LLM-Powered_Semi-Structured_Table_Question_Answering",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-ST-Raptor_LLM-Powered_Semi-Structured_Table_Question_Answering/","children":"[논문리뷰] ST-Raptor: LLM-Powered Semi-Structured Table Question Answering"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wei Zhou이 [arXiv]에 게시한 'ST-Raptor: LLM-Powered Semi-Structured Table Question Answering' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-26 13:21:57+0900","children":"2025년 8월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Semi-structured Tables",{"className":"page__taxonomy-item","children":["#","Semi-structured Tables"]}],["$","span","Question Answering",{"className":"page__taxonomy-item","children":["#","Question Answering"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Hierarchical Orthogonal Tree",{"className":"page__taxonomy-item","children":["#","Hierarchical Orthogonal Tree"]}],["$","span","Table Layout Understanding",{"className":"page__taxonomy-item","children":["#","Table Layout Understanding"]}],["$","span","Pipeline Generation",{"className":"page__taxonomy-item","children":["#","Pipeline Generation"]}],["$","span","Verification Mechanism",{"className":"page__taxonomy-item","children":["#","Verification Mechanism"]}]]}]]}]]}],["$","article","2025-8-26-SpotEdit_Evaluating_Visually-Guided_Image_Editing_Methods",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-SpotEdit_Evaluating_Visually-Guided_Image_Editing_Methods/","children":"[논문리뷰] SpotEdit: Evaluating Visually-Guided Image Editing Methods"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ersin Yumer이 [arXiv]에 게시한 'SpotEdit: Evaluating Visually-Guided Image Editing Methods' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-26 13:21:57+0900","children":"2025년 8월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Visually-Guided Image Editing",{"className":"page__taxonomy-item","children":["#","Visually-Guided Image Editing"]}],["$","span","Multimodal Models",{"className":"page__taxonomy-item","children":["#","Multimodal Models"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Hallucination",{"className":"page__taxonomy-item","children":["#","Hallucination"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Autoregressive Models",{"className":"page__taxonomy-item","children":["#","Autoregressive Models"]}],["$","span","Evaluation Metrics",{"className":"page__taxonomy-item","children":["#","Evaluation Metrics"]}]]}]]}]]}],["$","article","2025-8-26-PosterGen_Aesthetic-Aware_Paper-to-Poster_Generation_via_Multi-Agent_LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-PosterGen_Aesthetic-Aware_Paper-to-Poster_Generation_via_Multi-Agent_LLMs/","children":"[논문리뷰] PosterGen: Aesthetic-Aware Paper-to-Poster Generation via Multi-Agent LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chenyu You이 [arXiv]에 게시한 'PosterGen: Aesthetic-Aware Paper-to-Poster Generation via Multi-Agent LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-26 13:21:57+0900","children":"2025년 8월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-Agent LLMs",{"className":"page__taxonomy-item","children":["#","Multi-Agent LLMs"]}],["$","span","Academic Poster Generation",{"className":"page__taxonomy-item","children":["#","Academic Poster Generation"]}],["$","span","Aesthetic Design",{"className":"page__taxonomy-item","children":["#","Aesthetic Design"]}],["$","span","Layout Optimization",{"className":"page__taxonomy-item","children":["#","Layout Optimization"]}],["$","span","Typography",{"className":"page__taxonomy-item","children":["#","Typography"]}],["$","span","Color Palette",{"className":"page__taxonomy-item","children":["#","Color Palette"]}],["$","span","VLM-as-Judge",{"className":"page__taxonomy-item","children":["#","VLM-as-Judge"]}],["$","span","Content Fidelity",{"className":"page__taxonomy-item","children":["#","Content Fidelity"]}]]}]]}]]}],["$","article","2025-8-26-Neither_Valid_nor_Reliable_Investigating_the_Use_of_LLMs_as_Judges",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-Neither_Valid_nor_Reliable_Investigating_the_Use_of_LLMs_as_Judges/","children":"[논문리뷰] Neither Valid nor Reliable? Investigating the Use of LLMs as Judges"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Golnoosh Farnadi이 [arXiv]에 게시한 'Neither Valid nor Reliable? Investigating the Use of LLMs as Judges' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-26 13:21:57+0900","children":"2025년 8월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLMs as Judges",{"className":"page__taxonomy-item","children":["#","LLMs as Judges"]}],["$","span","NLG Evaluation",{"className":"page__taxonomy-item","children":["#","NLG Evaluation"]}],["$","span","Measurement Theory",{"className":"page__taxonomy-item","children":["#","Measurement Theory"]}],["$","span","Validity",{"className":"page__taxonomy-item","children":["#","Validity"]}],["$","span","Reliability",{"className":"page__taxonomy-item","children":["#","Reliability"]}],["$","span","Evaluation Bias",{"className":"page__taxonomy-item","children":["#","Evaluation Bias"]}],["$","span","Scalability",{"className":"page__taxonomy-item","children":["#","Scalability"]}],["$","span","Responsible AI",{"className":"page__taxonomy-item","children":["#","Responsible AI"]}]]}]]}]]}],["$","article","2025-8-26-MV-RAG_Retrieval_Augmented_Multiview_Diffusion",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-MV-RAG_Retrieval_Augmented_Multiview_Diffusion/","children":"[논문리뷰] MV-RAG: Retrieval Augmented Multiview Diffusion"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"sagiebenaim이 [arXiv]에 게시한 'MV-RAG: Retrieval Augmented Multiview Diffusion' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-26 13:21:57+0900","children":"2025년 8월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Retrieval Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval Augmented Generation"]}],["$","span","Multiview Diffusion",{"className":"page__taxonomy-item","children":["#","Multiview Diffusion"]}],["$","span","Text-to-3D Generation",{"className":"page__taxonomy-item","children":["#","Text-to-3D Generation"]}],["$","span","Out-of-Domain",{"className":"page__taxonomy-item","children":["#","Out-of-Domain"]}],["$","span","Image Retrieval",{"className":"page__taxonomy-item","children":["#","Image Retrieval"]}],["$","span","3D Consistency",{"className":"page__taxonomy-item","children":["#","3D Consistency"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Hybrid Training",{"className":"page__taxonomy-item","children":["#","Hybrid Training"]}]]}]]}]]}],["$","article","2025-8-26-MeshSplat_Generalizable_Sparse-View_Surface_Reconstruction_via_Gaussian_Splatting",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-MeshSplat_Generalizable_Sparse-View_Surface_Reconstruction_via_Gaussian_Splatting/","children":"[논문리뷰] MeshSplat: Generalizable Sparse-View Surface Reconstruction via Gaussian Splatting"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yanzhe Liang이 [arXiv]에 게시한 'MeshSplat: Generalizable Sparse-View Surface Reconstruction via Gaussian Splatting' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-26 13:21:57+0900","children":"2025년 8월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Sparse-View",{"className":"page__taxonomy-item","children":["#","Sparse-View"]}],["$","span","Surface Reconstruction",{"className":"page__taxonomy-item","children":["#","Surface Reconstruction"]}],["$","span","Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","Gaussian Splatting"]}],["$","span","2DGS",{"className":"page__taxonomy-item","children":["#","2DGS"]}],["$","span","Novel View Synthesis",{"className":"page__taxonomy-item","children":["#","Novel View Synthesis"]}],["$","span","Generalizable",{"className":"page__taxonomy-item","children":["#","Generalizable"]}],["$","span","Mesh Extraction",{"className":"page__taxonomy-item","children":["#","Mesh Extraction"]}],["$","span","3D Vision",{"className":"page__taxonomy-item","children":["#","3D Vision"]}]]}]]}]]}],["$","article","2025-8-26-MEENA_PersianMMMU_Multimodal-Multilingual_Educational_Exams_for_N-level_Assessment",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-MEENA_PersianMMMU_Multimodal-Multilingual_Educational_Exams_for_N-level_Assessment/","children":"[논문리뷰] MEENA (PersianMMMU): Multimodal-Multilingual Educational Exams for N-level Assessment"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Doratossadat Dastgheib이 [arXiv]에 게시한 'MEENA (PersianMMMU): Multimodal-Multilingual Educational Exams for N-level Assessment' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-26 13:21:57+0900","children":"2025년 8월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Language Models",{"className":"page__taxonomy-item","children":["#","Multimodal Language Models"]}],["$","span","Multilingual Benchmarking",{"className":"page__taxonomy-item","children":["#","Multilingual Benchmarking"]}],["$","span","Persian Language",{"className":"page__taxonomy-item","children":["#","Persian Language"]}],["$","span","Educational Assessment",{"className":"page__taxonomy-item","children":["#","Educational Assessment"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Cultural Nuance",{"className":"page__taxonomy-item","children":["#","Cultural Nuance"]}],["$","span","Reasoning Tasks",{"className":"page__taxonomy-item","children":["#","Reasoning Tasks"]}]]}]]}]]}],["$","article","2025-8-26-Limitations_of_Normalization_in_Attention_Mechanism",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-Limitations_of_Normalization_in_Attention_Mechanism/","children":"[논문리뷰] Limitations of Normalization in Attention Mechanism"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Radu State이 [arXiv]에 게시한 'Limitations of Normalization in Attention Mechanism' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-26 13:21:57+0900","children":"2025년 8월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Attention Mechanism",{"className":"page__taxonomy-item","children":["#","Attention Mechanism"]}],["$","span","Normalization",{"className":"page__taxonomy-item","children":["#","Normalization"]}],["$","span","Softmax",{"className":"page__taxonomy-item","children":["#","Softmax"]}],["$","span","Transformer Models",{"className":"page__taxonomy-item","children":["#","Transformer Models"]}],["$","span","Gradient Sensitivity",{"className":"page__taxonomy-item","children":["#","Gradient Sensitivity"]}],["$","span","Token Separability",{"className":"page__taxonomy-item","children":["#","Token Separability"]}],["$","span","Context Length",{"className":"page__taxonomy-item","children":["#","Context Length"]}],["$","span","GPT-2",{"className":"page__taxonomy-item","children":["#","GPT-2"]}]]}]]}]]}],["$","article","2025-8-26-InternVL3.5_Advancing_Open-Source_Multimodal_Models_in_Versatility_Reasoning_and_Efficiency",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-InternVL3.5_Advancing_Open-Source_Multimodal_Models_in_Versatility_Reasoning_and_Efficiency/","children":"[논문리뷰] InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"jinglinglin이 [arXiv]에 게시한 'InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-26 13:21:57+0900","children":"2025년 8월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Inference Efficiency",{"className":"page__taxonomy-item","children":["#","Inference Efficiency"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Open-Source",{"className":"page__taxonomy-item","children":["#","Open-Source"]}],["$","span","Versatility",{"className":"page__taxonomy-item","children":["#","Versatility"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}]]}]]}]]}],["$","article","2025-8-26-German4All_-_A_Dataset_and_Model_for_Readability-Controlled_Paraphrasing_in_German",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-German4All_-_A_Dataset_and_Model_for_Readability-Controlled_Paraphrasing_in_German/","children":"[논문리뷰] German4All - A Dataset and Model for Readability-Controlled Paraphrasing in German"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Cristian-George Craciun이 [arXiv]에 게시한 'German4All - A Dataset and Model for Readability-Controlled Paraphrasing in German' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-26 13:21:57+0900","children":"2025년 8월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text Simplification",{"className":"page__taxonomy-item","children":["#","Text Simplification"]}],["$","span","Paraphrasing",{"className":"page__taxonomy-item","children":["#","Paraphrasing"]}],["$","span","Readability Control",{"className":"page__taxonomy-item","children":["#","Readability Control"]}],["$","span","German NLP",{"className":"page__taxonomy-item","children":["#","German NLP"]}],["$","span","Dataset Generation",{"className":"page__taxonomy-item","children":["#","Dataset Generation"]}],["$","span","LLM Distillation",{"className":"page__taxonomy-item","children":["#","LLM Distillation"]}],["$","span","Multi-level Text Generation",{"className":"page__taxonomy-item","children":["#","Multi-level Text Generation"]}],["$","span","Accessibility",{"className":"page__taxonomy-item","children":["#","Accessibility"]}]]}]]}]]}],["$","article","2025-8-26-Explain_Before_You_Answer_A_Survey_on_Compositional_Visual_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-Explain_Before_You_Answer_A_Survey_on_Compositional_Visual_Reasoning/","children":"[논문리뷰] Explain Before You Answer: A Survey on Compositional Visual Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xin Zheng이 [arXiv]에 게시한 'Explain Before You Answer: A Survey on Compositional Visual Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-26 13:21:57+0900","children":"2025년 8월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Compositional Visual Reasoning",{"className":"page__taxonomy-item","children":["#","Compositional Visual Reasoning"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Tool Learning",{"className":"page__taxonomy-item","children":["#","Tool Learning"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Survey",{"className":"page__taxonomy-item","children":["#","Survey"]}]]}]]}]]}],["$","article","2025-8-26-Breaking_the_Exploration_Bottleneck_Rubric-Scaffolded_Reinforcement_Learning_for_General_LLM_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-Breaking_the_Exploration_Bottleneck_Rubric-Scaffolded_Reinforcement_Learning_for_General_LLM_Reasoning/","children":"[논문리뷰] Breaking the Exploration Bottleneck: Rubric-Scaffolded Reinforcement Learning for General LLM Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiale Zhao이 [arXiv]에 게시한 'Breaking the Exploration Bottleneck: Rubric-Scaffolded Reinforcement Learning for General LLM Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-26 13:21:57+0900","children":"2025년 8월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Exploration Bottleneck",{"className":"page__taxonomy-item","children":["#","Exploration Bottleneck"]}],["$","span","Instructional Scaffolding",{"className":"page__taxonomy-item","children":["#","Instructional Scaffolding"]}],["$","span","Rubric-based Rewards",{"className":"page__taxonomy-item","children":["#","Rubric-based Rewards"]}],["$","span","General Reasoning",{"className":"page__taxonomy-item","children":["#","General Reasoning"]}],["$","span","RL with Verifiable Rewards",{"className":"page__taxonomy-item","children":["#","RL with Verifiable Rewards"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}]]}]]}]]}],["$","article","2025-8-26-Beyond_Memorization_Extending_Reasoning_Depth_with_Recurrence_Memory_and_Test-Time_Compute_Scaling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-26-Beyond_Memorization_Extending_Reasoning_Depth_with_Recurrence_Memory_and_Test-Time_Compute_Scaling/","children":"[논문리뷰] Beyond Memorization: Extending Reasoning Depth with Recurrence, Memory and Test-Time Compute Scaling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Daniil Orel이 [arXiv]에 게시한 'Beyond Memorization: Extending Reasoning Depth with Recurrence, Memory and Test-Time Compute Scaling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-26 13:21:57+0900","children":"2025년 8월 26일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reasoning Depth",{"className":"page__taxonomy-item","children":["#","Reasoning Depth"]}],["$","span","Cellular Automata",{"className":"page__taxonomy-item","children":["#","Cellular Automata"]}],["$","span","Transformer Architectures",{"className":"page__taxonomy-item","children":["#","Transformer Architectures"]}],["$","span","Recurrence",{"className":"page__taxonomy-item","children":["#","Recurrence"]}],["$","span","Adaptive Computation Time",{"className":"page__taxonomy-item","children":["#","Adaptive Computation Time"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}]]}]]}]]}],["$","article","2025-8-25-TPLA_Tensor_Parallel_Latent_Attention_for_Efficient_Disaggregated_Prefill_Decode_Inference",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-25-TPLA_Tensor_Parallel_Latent_Attention_for_Efficient_Disaggregated_Prefill_Decode_Inference/","children":"[논문리뷰] TPLA: Tensor Parallel Latent Attention for Efficient Disaggregated Prefill & Decode Inference"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Di Yin이 [arXiv]에 게시한 'TPLA: Tensor Parallel Latent Attention for Efficient Disaggregated Prefill & Decode Inference' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-25 13:13:07+0900","children":"2025년 8월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Inference",{"className":"page__taxonomy-item","children":["#","LLM Inference"]}],["$","span","Tensor Parallelism",{"className":"page__taxonomy-item","children":["#","Tensor Parallelism"]}],["$","span","KV Cache Optimization",{"className":"page__taxonomy-item","children":["#","KV Cache Optimization"]}],["$","span","Latent Attention",{"className":"page__taxonomy-item","children":["#","Latent Attention"]}],["$","span","Memory Efficiency",{"className":"page__taxonomy-item","children":["#","Memory Efficiency"]}],["$","span","Decoding Speedup",{"className":"page__taxonomy-item","children":["#","Decoding Speedup"]}],["$","span","Prefill/Decode Separation",{"className":"page__taxonomy-item","children":["#","Prefill/Decode Separation"]}],["$","span","Reparameterization",{"className":"page__taxonomy-item","children":["#","Reparameterization"]}]]}]]}]]}],["$","article","2025-8-25-Selective_Contrastive_Learning_for_Weakly_Supervised_Affordance_Grounding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-25-Selective_Contrastive_Learning_for_Weakly_Supervised_Affordance_Grounding/","children":"[논문리뷰] Selective Contrastive Learning for Weakly Supervised Affordance Grounding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jae-Pil Heo이 [arXiv]에 게시한 'Selective Contrastive Learning for Weakly Supervised Affordance Grounding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-25 13:13:07+0900","children":"2025년 8월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Weakly Supervised Learning",{"className":"page__taxonomy-item","children":["#","Weakly Supervised Learning"]}],["$","span","Affordance Grounding",{"className":"page__taxonomy-item","children":["#","Affordance Grounding"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","CLIP",{"className":"page__taxonomy-item","children":["#","CLIP"]}],["$","span","Part Discovery",{"className":"page__taxonomy-item","children":["#","Part Discovery"]}],["$","span","Object Localization",{"className":"page__taxonomy-item","children":["#","Object Localization"]}],["$","span","DINO",{"className":"page__taxonomy-item","children":["#","DINO"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}]]}]]}]]}],["$","article","2025-8-25-Learnable_SMPLify_A_Neural_Solution_for_Optimization-Free_Human_Pose_Inverse_Kinematics",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-25-Learnable_SMPLify_A_Neural_Solution_for_Optimization-Free_Human_Pose_Inverse_Kinematics/","children":"[논문리뷰] Learnable SMPLify: A Neural Solution for Optimization-Free Human Pose Inverse Kinematics"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiao Sun이 [arXiv]에 게시한 'Learnable SMPLify: A Neural Solution for Optimization-Free Human Pose Inverse Kinematics' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-25 13:13:07+0900","children":"2025년 8월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Inverse Kinematics",{"className":"page__taxonomy-item","children":["#","Inverse Kinematics"]}],["$","span","Human Pose Estimation",{"className":"page__taxonomy-item","children":["#","Human Pose Estimation"]}],["$","span","SMPL Model",{"className":"page__taxonomy-item","children":["#","SMPL Model"]}],["$","span","Neural Networks",{"className":"page__taxonomy-item","children":["#","Neural Networks"]}],["$","span","Optimization-Free",{"className":"page__taxonomy-item","children":["#","Optimization-Free"]}],["$","span","Residual Learning",{"className":"page__taxonomy-item","children":["#","Residual Learning"]}],["$","span","Data-Driven",{"className":"page__taxonomy-item","children":["#","Data-Driven"]}]]}]]}]]}],["$","article","2025-8-25-Jailbreaking_Commercial_Black-Box_LLMs_with_Explicitly_Harmful_Prompts",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-25-Jailbreaking_Commercial_Black-Box_LLMs_with_Explicitly_Harmful_Prompts/","children":"[논문리뷰] Jailbreaking Commercial Black-Box LLMs with Explicitly Harmful Prompts"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Liming Fang이 [arXiv]에 게시한 'Jailbreaking Commercial Black-Box LLMs with Explicitly Harmful Prompts' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-25 13:13:07+0900","children":"2025년 8월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Jailbreaking",{"className":"page__taxonomy-item","children":["#","LLM Jailbreaking"]}],["$","span","Red Teaming",{"className":"page__taxonomy-item","children":["#","Red Teaming"]}],["$","span","Malicious Content Detection",{"className":"page__taxonomy-item","children":["#","Malicious Content Detection"]}],["$","span","Developer Messages",{"className":"page__taxonomy-item","children":["#","Developer Messages"]}],["$","span","D-Attack",{"className":"page__taxonomy-item","children":["#","D-Attack"]}],["$","span","DH-CoT",{"className":"page__taxonomy-item","children":["#","DH-CoT"]}],["$","span","Adversarial Attacks",{"className":"page__taxonomy-item","children":["#","Adversarial Attacks"]}],["$","span","Dataset Cleaning",{"className":"page__taxonomy-item","children":["#","Dataset Cleaning"]}]]}]]}]]}],["$","article","2025-8-25-InMind_Evaluating_LLMs_in_Capturing_and_Applying_Individual_Human_Reasoning_Styles",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-25-InMind_Evaluating_LLMs_in_Capturing_and_Applying_Individual_Human_Reasoning_Styles/","children":"[논문리뷰] InMind: Evaluating LLMs in Capturing and Applying Individual Human Reasoning Styles"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Diping Song이 [arXiv]에 게시한 'InMind: Evaluating LLMs in Capturing and Applying Individual Human Reasoning Styles' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-25 13:13:07+0900","children":"2025년 8월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Human Reasoning Styles",{"className":"page__taxonomy-item","children":["#","Human Reasoning Styles"]}],["$","span","Social Deduction Games",{"className":"page__taxonomy-item","children":["#","Social Deduction Games"]}],["$","span","Theory of Mind",{"className":"page__taxonomy-item","children":["#","Theory of Mind"]}],["$","span","Adaptive Reasoning",{"className":"page__taxonomy-item","children":["#","Adaptive Reasoning"]}],["$","span","Avalon Game",{"className":"page__taxonomy-item","children":["#","Avalon Game"]}],["$","span","Cognitive Grounding",{"className":"page__taxonomy-item","children":["#","Cognitive Grounding"]}]]}]]}]]}],["$","article","2025-8-25-End-to-End_Agentic_RAG_System_Training_for_Traceable_Diagnostic_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-25-End-to-End_Agentic_RAG_System_Training_for_Traceable_Diagnostic_Reasoning/","children":"[논문리뷰] End-to-End Agentic RAG System Training for Traceable Diagnostic Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Pengcheng Qiu이 [arXiv]에 게시한 'End-to-End Agentic RAG System Training for Traceable Diagnostic Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-25 13:13:07+0900","children":"2025년 8월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic RAG",{"className":"page__taxonomy-item","children":["#","Agentic RAG"]}],["$","span","Medical Diagnosis",{"className":"page__taxonomy-item","children":["#","Medical Diagnosis"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Traceable AI",{"className":"page__taxonomy-item","children":["#","Traceable AI"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Clinical Decision Support",{"className":"page__taxonomy-item","children":["#","Clinical Decision Support"]}],["$","span","Out-of-Distribution Generalization",{"className":"page__taxonomy-item","children":["#","Out-of-Distribution Generalization"]}],["$","span","Reward Design",{"className":"page__taxonomy-item","children":["#","Reward Design"]}]]}]]}]]}],["$","article","2025-8-25-EgoTwin_Dreaming_Body_and_View_in_First_Person",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-25-EgoTwin_Dreaming_Body_and_View_in_First_Person/","children":"[논문리뷰] EgoTwin: Dreaming Body and View in First Person"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wentao Wang이 [arXiv]에 게시한 'EgoTwin: Dreaming Body and View in First Person' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-25 13:13:07+0900","children":"2025년 8월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Egocentric Video Generation",{"className":"page__taxonomy-item","children":["#","Egocentric Video Generation"]}],["$","span","Human Motion Synthesis",{"className":"page__taxonomy-item","children":["#","Human Motion Synthesis"]}],["$","span","Diffusion Transformers",{"className":"page__taxonomy-item","children":["#","Diffusion Transformers"]}],["$","span","Multimodal Generation",{"className":"page__taxonomy-item","children":["#","Multimodal Generation"]}],["$","span","Viewpoint Alignment",{"className":"page__taxonomy-item","children":["#","Viewpoint Alignment"]}],["$","span","Causal Interplay",{"className":"page__taxonomy-item","children":["#","Causal Interplay"]}],["$","span","First-Person Vision",{"className":"page__taxonomy-item","children":["#","First-Person Vision"]}]]}]]}]]}],["$","article","2025-8-25-Do_What_Teaching_Vision-Language-Action_Models_to_Reject_the_Impossible",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-25-Do_What_Teaching_Vision-Language-Action_Models_to_Reject_the_Impossible/","children":"[논문리뷰] Do What? Teaching Vision-Language-Action Models to Reject the Impossible"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Roei Herzig이 [arXiv]에 게시한 'Do What? Teaching Vision-Language-Action Models to Reject the Impossible' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-25 13:13:07+0900","children":"2025년 8월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action Models"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","False Premise Detection",{"className":"page__taxonomy-item","children":["#","False Premise Detection"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}],["$","span","Human-Robot Interaction",{"className":"page__taxonomy-item","children":["#","Human-Robot Interaction"]}],["$","span","Clarification",{"className":"page__taxonomy-item","children":["#","Clarification"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}]]}]]}]]}],["$","article","2025-8-25-CRISP_Persistent_Concept_Unlearning_via_Sparse_Autoencoders",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-25-CRISP_Persistent_Concept_Unlearning_via_Sparse_Autoencoders/","children":"[논문리뷰] CRISP: Persistent Concept Unlearning via Sparse Autoencoders"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yonatan Belinkov이 [arXiv]에 게시한 'CRISP: Persistent Concept Unlearning via Sparse Autoencoders' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-25 13:13:07+0900","children":"2025년 8월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Concept Unlearning",{"className":"page__taxonomy-item","children":["#","Concept Unlearning"]}],["$","span","Sparse Autoencoders (SAEs)",{"className":"page__taxonomy-item","children":["#","Sparse Autoencoders (SAEs)"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Parameter-Efficient Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Parameter-Efficient Fine-Tuning"]}],["$","span","Model Interpretability",{"className":"page__taxonomy-item","children":["#","Model Interpretability"]}],["$","span","Safety-Critical AI",{"className":"page__taxonomy-item","children":["#","Safety-Critical AI"]}],["$","span","Feature Suppression",{"className":"page__taxonomy-item","children":["#","Feature Suppression"]}],["$","span","WMDP Benchmark",{"className":"page__taxonomy-item","children":["#","WMDP Benchmark"]}]]}]]}]]}],["$","article","2025-8-25-CARFT_Boosting_LLM_Reasoning_via_Contrastive_Learning_with_Annotated_Chain-of-Thought-based_Reinforced_Fine-Tuning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-25-CARFT_Boosting_LLM_Reasoning_via_Contrastive_Learning_with_Annotated_Chain-of-Thought-based_Reinforced_Fine-Tuning/","children":"[논문리뷰] CARFT: Boosting LLM Reasoning via Contrastive Learning with Annotated Chain-of-Thought-based Reinforced Fine-Tuning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yulun Zhang이 [arXiv]에 게시한 'CARFT: Boosting LLM Reasoning via Contrastive Learning with Annotated Chain-of-Thought-based Reinforced Fine-Tuning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-25 13:13:07+0900","children":"2025년 8월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Reasoning",{"className":"page__taxonomy-item","children":["#","LLM Reasoning"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Chain-of-Thought (CoT)",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought (CoT)"]}],["$","span","Annotated Data",{"className":"page__taxonomy-item","children":["#","Annotated Data"]}],["$","span","Model Stability",{"className":"page__taxonomy-item","children":["#","Model Stability"]}]]}]]}]]}],["$","article","2025-8-25-Beyond_Pass1_Self-Play_with_Variational_Problem_Synthesis_Sustains_RLVR",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-25-Beyond_Pass1_Self-Play_with_Variational_Problem_Synthesis_Sustains_RLVR/","children":"[논문리뷰] Beyond Pass@1: Self-Play with Variational Problem Synthesis Sustains RLVR"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ying Nian Wu이 [arXiv]에 게시한 'Beyond Pass@1: Self-Play with Variational Problem Synthesis Sustains RLVR' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-25 13:13:07+0900","children":"2025년 8월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Self-Play",{"className":"page__taxonomy-item","children":["#","Self-Play"]}],["$","span","Variational Problem Synthesis",{"className":"page__taxonomy-item","children":["#","Variational Problem Synthesis"]}],["$","span","Policy Entropy",{"className":"page__taxonomy-item","children":["#","Policy Entropy"]}],["$","span","Pass@k",{"className":"page__taxonomy-item","children":["#","Pass@k"]}],["$","span","Reasoning Benchmarks",{"className":"page__taxonomy-item","children":["#","Reasoning Benchmarks"]}]]}]]}]]}],["$","article","2025-8-25-AgentScope_1.0_A_Developer-Centric_Framework_for_Building_Agentic_Applications",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-25-AgentScope_1.0_A_Developer-Centric_Framework_for_Building_Agentic_Applications/","children":"[논문리뷰] AgentScope 1.0: A Developer-Centric Framework for Building Agentic Applications"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Liuyi Yao이 [arXiv]에 게시한 'AgentScope 1.0: A Developer-Centric Framework for Building Agentic Applications' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-25 13:13:07+0900","children":"2025년 8월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Agentic Applications",{"className":"page__taxonomy-item","children":["#","Agentic Applications"]}],["$","span","ReAct Paradigm",{"className":"page__taxonomy-item","children":["#","ReAct Paradigm"]}],["$","span","Framework",{"className":"page__taxonomy-item","children":["#","Framework"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Developer Experience",{"className":"page__taxonomy-item","children":["#","Developer Experience"]}],["$","span","Evaluation",{"className":"page__taxonomy-item","children":["#","Evaluation"]}]]}]]}]]}],["$","article","2025-8-25-AetherCode_Evaluating_LLMs_Ability_to_Win_In_Premier_Programming_Competitions",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-25-AetherCode_Evaluating_LLMs_Ability_to_Win_In_Premier_Programming_Competitions/","children":"[논문리뷰] AetherCode: Evaluating LLMs' Ability to Win In Premier Programming Competitions"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yidi Du이 [arXiv]에 게시한 'AetherCode: Evaluating LLMs' Ability to Win In Premier Programming Competitions' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-25 13:13:07+0900","children":"2025년 8월 25일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Competitive Programming",{"className":"page__taxonomy-item","children":["#","Competitive Programming"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Code Reasoning",{"className":"page__taxonomy-item","children":["#","Code Reasoning"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Test Case Generation",{"className":"page__taxonomy-item","children":["#","Test Case Generation"]}],["$","span","Programming Competitions",{"className":"page__taxonomy-item","children":["#","Programming Competitions"]}],["$","span","Algorithmic Problems",{"className":"page__taxonomy-item","children":["#","Algorithmic Problems"]}]]}]]}]]}],["$","article","2025-8-22-When_and_What_Diffusion-Grounded_VideoLLM_with_Entity_Aware_Segmentation_for_Long_Video_Understanding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-22-When_and_What_Diffusion-Grounded_VideoLLM_with_Entity_Aware_Segmentation_for_Long_Video_Understanding/","children":"[논문리뷰] When and What: Diffusion-Grounded VideoLLM with Entity Aware Segmentation for Long Video Understanding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Rui Guo이 [arXiv]에 게시한 'When and What: Diffusion-Grounded VideoLLM with Entity Aware Segmentation for Long Video Understanding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-22 13:10:52+0900","children":"2025년 8월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video-LLM",{"className":"page__taxonomy-item","children":["#","Video-LLM"]}],["$","span","Diffusion Model",{"className":"page__taxonomy-item","children":["#","Diffusion Model"]}],["$","span","Temporal Grounding",{"className":"page__taxonomy-item","children":["#","Temporal Grounding"]}],["$","span","Object Segmentation",{"className":"page__taxonomy-item","children":["#","Object Segmentation"]}],["$","span","Long Video Understanding",{"className":"page__taxonomy-item","children":["#","Long Video Understanding"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Video Question Answering",{"className":"page__taxonomy-item","children":["#","Video Question Answering"]}]]}]]}]]}],["$","article","2025-8-22-Waver_Wave_Your_Way_to_Lifelike_Video_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-22-Waver_Wave_Your_Way_to_Lifelike_Video_Generation/","children":"[논문리뷰] Waver: Wave Your Way to Lifelike Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yifu Zhang이 [arXiv]에 게시한 'Waver: Wave Your Way to Lifelike Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-22 13:10:52+0900","children":"2025년 8월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Foundation Model",{"className":"page__taxonomy-item","children":["#","Foundation Model"]}],["$","span","Diffusion Model",{"className":"page__taxonomy-item","children":["#","Diffusion Model"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Text-to-Video",{"className":"page__taxonomy-item","children":["#","Text-to-Video"]}],["$","span","Image-to-Video",{"className":"page__taxonomy-item","children":["#","Image-to-Video"]}],["$","span","Super-Resolution",{"className":"page__taxonomy-item","children":["#","Super-Resolution"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}]]}]]}]]}],["$","article","2025-8-22-Snap-Snap_Taking_Two_Images_to_Reconstruct_3D_Human_Gaussians_in_Milliseconds",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-22-Snap-Snap_Taking_Two_Images_to_Reconstruct_3D_Human_Gaussians_in_Milliseconds/","children":"[논문리뷰] Snap-Snap: Taking Two Images to Reconstruct 3D Human Gaussians in Milliseconds"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chuiyun Wu이 [arXiv]에 게시한 'Snap-Snap: Taking Two Images to Reconstruct 3D Human Gaussians in Milliseconds' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-22 13:10:52+0900","children":"2025년 8월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Human Reconstruction",{"className":"page__taxonomy-item","children":["#","3D Human Reconstruction"]}],["$","span","Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","Gaussian Splatting"]}],["$","span","Sparse View",{"className":"page__taxonomy-item","children":["#","Sparse View"]}],["$","span","Two-Image Input",{"className":"page__taxonomy-item","children":["#","Two-Image Input"]}],["$","span","Real-time Inference",{"className":"page__taxonomy-item","children":["#","Real-time Inference"]}],["$","span","Point Cloud Prediction",{"className":"page__taxonomy-item","children":["#","Point Cloud Prediction"]}],["$","span","Feed-forward Network",{"className":"page__taxonomy-item","children":["#","Feed-forward Network"]}]]}]]}]]}],["$","article","2025-8-22-SceneGen_Single-Image_3D_Scene_Generation_in_One_Feedforward_Pass",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-22-SceneGen_Single-Image_3D_Scene_Generation_in_One_Feedforward_Pass/","children":"[논문리뷰] SceneGen: Single-Image 3D Scene Generation in One Feedforward Pass"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ya Zhang이 [arXiv]에 게시한 'SceneGen: Single-Image 3D Scene Generation in One Feedforward Pass' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-22 13:10:52+0900","children":"2025년 8월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Scene Generation",{"className":"page__taxonomy-item","children":["#","3D Scene Generation"]}],["$","span","Single-Image Input",{"className":"page__taxonomy-item","children":["#","Single-Image Input"]}],["$","span","Feedforward Networks",{"className":"page__taxonomy-item","children":["#","Feedforward Networks"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Geometric Modeling",{"className":"page__taxonomy-item","children":["#","Geometric Modeling"]}],["$","span","Texture Synthesis",{"className":"page__taxonomy-item","children":["#","Texture Synthesis"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Feature Aggregation",{"className":"page__taxonomy-item","children":["#","Feature Aggregation"]}]]}]]}]]}],["$","article","2025-8-22-Mobile-Agent-v3_Foundamental_Agents_for_GUI_Automation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-22-Mobile-Agent-v3_Foundamental_Agents_for_GUI_Automation/","children":"[논문리뷰] Mobile-Agent-v3: Foundamental Agents for GUI Automation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Haowei Liu이 [arXiv]에 게시한 'Mobile-Agent-v3: Foundamental Agents for GUI Automation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-22 13:10:52+0900","children":"2025년 8월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","GUI Automation",{"className":"page__taxonomy-item","children":["#","GUI Automation"]}],["$","span","Multimodal Agents",{"className":"page__taxonomy-item","children":["#","Multimodal Agents"]}],["$","span","Foundational Models",{"className":"page__taxonomy-item","children":["#","Foundational Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Cross-Platform",{"className":"page__taxonomy-item","children":["#","Cross-Platform"]}],["$","span","Self-Supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-Supervised Learning"]}]]}]]}]]}],["$","article","2025-8-22-LiveMCP-101_Stress_Testing_and_Diagnosing_MCP-enabled_Agents_on_Challenging_Queries",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-22-LiveMCP-101_Stress_Testing_and_Diagnosing_MCP-enabled_Agents_on_Challenging_Queries/","children":"[논문리뷰] LiveMCP-101: Stress Testing and Diagnosing MCP-enabled Agents on Challenging Queries"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"huuuyeah이 [arXiv]에 게시한 'LiveMCP-101: Stress Testing and Diagnosing MCP-enabled Agents on Challenging Queries' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-22 13:10:52+0900","children":"2025년 8월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Agents",{"className":"page__taxonomy-item","children":["#","AI Agents"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Model Context Protocol (MCP)",{"className":"page__taxonomy-item","children":["#","Model Context Protocol (MCP)"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Real-world Tasks",{"className":"page__taxonomy-item","children":["#","Real-world Tasks"]}],["$","span","Evaluation",{"className":"page__taxonomy-item","children":["#","Evaluation"]}],["$","span","Error Analysis",{"className":"page__taxonomy-item","children":["#","Error Analysis"]}]]}]]}]]}],["$","article","2025-8-22-INTIMA_A_Benchmark_for_Human-AI_Companionship_Behavior",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-22-INTIMA_A_Benchmark_for_Human-AI_Companionship_Behavior/","children":"[논문리뷰] INTIMA: A Benchmark for Human-AI Companionship Behavior"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yacine Jernite이 [arXiv]에 게시한 'INTIMA: A Benchmark for Human-AI Companionship Behavior' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-22 13:10:52+0900","children":"2025년 8월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Companionship",{"className":"page__taxonomy-item","children":["#","AI Companionship"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Language Models (LLMs)"]}],["$","span","Human-AI Interaction",{"className":"page__taxonomy-item","children":["#","Human-AI Interaction"]}],["$","span","Emotional AI",{"className":"page__taxonomy-item","children":["#","Emotional AI"]}],["$","span","Boundary Setting",{"className":"page__taxonomy-item","children":["#","Boundary Setting"]}],["$","span","Psychological Frameworks",{"className":"page__taxonomy-item","children":["#","Psychological Frameworks"]}],["$","span","Evaluation Metrics",{"className":"page__taxonomy-item","children":["#","Evaluation Metrics"]}]]}]]}]]}],["$","article","2025-8-22-Intern-S1_A_Scientific_Multimodal_Foundation_Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-22-Intern-S1_A_Scientific_Multimodal_Foundation_Model/","children":"[논문리뷰] Intern-S1: A Scientific Multimodal Foundation Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"xuhuang87이 [arXiv]에 게시한 'Intern-S1: A Scientific Multimodal Foundation Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-22 13:10:52+0900","children":"2025년 8월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Foundation Model",{"className":"page__taxonomy-item","children":["#","Multimodal Foundation Model"]}],["$","span","Scientific AI",{"className":"page__taxonomy-item","children":["#","Scientific AI"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Mixture-of-Experts (MoE)",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts (MoE)"]}],["$","span","Dynamic Tokenizer",{"className":"page__taxonomy-item","children":["#","Dynamic Tokenizer"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Low-Resource Learning",{"className":"page__taxonomy-item","children":["#","Low-Resource Learning"]}]]}]]}]]}],["$","article","2025-8-22-Fin-PRM_A_Domain-Specialized_Process_Reward_Model_for_Financial_Reasoning_in_Large_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-22-Fin-PRM_A_Domain-Specialized_Process_Reward_Model_for_Financial_Reasoning_in_Large_Language_Models/","children":"[논문리뷰] Fin-PRM: A Domain-Specialized Process Reward Model for Financial Reasoning in Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Lifan Guo이 [arXiv]에 게시한 'Fin-PRM: A Domain-Specialized Process Reward Model for Financial Reasoning in Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-22 13:10:52+0900","children":"2025년 8월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Process Reward Models",{"className":"page__taxonomy-item","children":["#","Process Reward Models"]}],["$","span","Financial Reasoning",{"className":"page__taxonomy-item","children":["#","Financial Reasoning"]}],["$","span","Domain Specialization",{"className":"page__taxonomy-item","children":["#","Domain Specialization"]}],["$","span","RLHF",{"className":"page__taxonomy-item","children":["#","RLHF"]}],["$","span","Best-of-N Selection",{"className":"page__taxonomy-item","children":["#","Best-of-N Selection"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}]]}]]}]]}],["$","article","2025-8-22-Does_the_cafe_entrance_look_accessible_Where_is_the_door_Towards_Geospatial_AI_Agents_for_Visual_Inquiries",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-22-Does_the_cafe_entrance_look_accessible_Where_is_the_door_Towards_Geospatial_AI_Agents_for_Visual_Inquiries/","children":"[논문리뷰] 'Does the cafe entrance look accessible? Where is the door?' Towards Geospatial AI Agents for Visual Inquiries"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xia Su이 [arXiv]에 게시한 'Does the cafe entrance look accessible? Where is the door? Towards Geospatial AI Agents for Visual Inquiries' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-22 13:10:52+0900","children":"2025년 8월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Geospatial AI",{"className":"page__taxonomy-item","children":["#","Geospatial AI"]}],["$","span","Multimodal AI Agents",{"className":"page__taxonomy-item","children":["#","Multimodal AI Agents"]}],["$","span","Visual Question Answering",{"className":"page__taxonomy-item","children":["#","Visual Question Answering"]}],["$","span","Accessibility",{"className":"page__taxonomy-item","children":["#","Accessibility"]}],["$","span","Street View Imagery",{"className":"page__taxonomy-item","children":["#","Street View Imagery"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}],["$","span","Human-Computer Interaction",{"className":"page__taxonomy-item","children":["#","Human-Computer Interaction"]}]]}]]}]]}],["$","article","2025-8-22-Deep_Think_with_Confidence",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-22-Deep_Think_with_Confidence/","children":"[논문리뷰] Deep Think with Confidence"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xuewei Wang이 [arXiv]에 게시한 'Deep Think with Confidence' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-22 13:10:52+0900","children":"2025년 8월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Reasoning",{"className":"page__taxonomy-item","children":["#","LLM Reasoning"]}],["$","span","Confidence Filtering",{"className":"page__taxonomy-item","children":["#","Confidence Filtering"]}],["$","span","Self-Consistency",{"className":"page__taxonomy-item","children":["#","Self-Consistency"]}],["$","span","Test-Time Optimization",{"className":"page__taxonomy-item","children":["#","Test-Time Optimization"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}],["$","span","Adaptive Sampling",{"className":"page__taxonomy-item","children":["#","Adaptive Sampling"]}],["$","span","Early Stopping",{"className":"page__taxonomy-item","children":["#","Early Stopping"]}],["$","span","Majority Voting",{"className":"page__taxonomy-item","children":["#","Majority Voting"]}]]}]]}]]}],["$","article","2025-8-22-A_Survey_on_Large_Language_Model_Benchmarks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-22-A_Survey_on_Large_Language_Model_Benchmarks/","children":"[논문리뷰] A Survey on Large Language Model Benchmarks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Siyi Li이 [arXiv]에 게시한 'A Survey on Large Language Model Benchmarks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-22 13:10:52+0900","children":"2025년 8월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Benchmarks",{"className":"page__taxonomy-item","children":["#","LLM Benchmarks"]}],["$","span","Evaluation",{"className":"page__taxonomy-item","children":["#","Evaluation"]}],["$","span","Systematic Review",{"className":"page__taxonomy-item","children":["#","Systematic Review"]}],["$","span","General Capabilities",{"className":"page__taxonomy-item","children":["#","General Capabilities"]}],["$","span","Domain-Specific Benchmarks",{"className":"page__taxonomy-item","children":["#","Domain-Specific Benchmarks"]}],["$","span","Target-Specific Benchmarks",{"className":"page__taxonomy-item","children":["#","Target-Specific Benchmarks"]}],["$","span","Data Contamination",{"className":"page__taxonomy-item","children":["#","Data Contamination"]}],["$","span","AI Ethics",{"className":"page__taxonomy-item","children":["#","AI Ethics"]}]]}]]}]]}],["$","article","2025-8-22-ATLAS_Decoupling_Skeletal_and_Shape_Parameters_for_Expressive_Parametric_Human_Modeling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-22-ATLAS_Decoupling_Skeletal_and_Shape_Parameters_for_Expressive_Parametric_Human_Modeling/","children":"[논문리뷰] ATLAS: Decoupling Skeletal and Shape Parameters for Expressive Parametric Human Modeling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shunsuke Saito이 [arXiv]에 게시한 'ATLAS: Decoupling Skeletal and Shape Parameters for Expressive Parametric Human Modeling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-22 13:10:52+0900","children":"2025년 8월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Parametric Human Model",{"className":"page__taxonomy-item","children":["#","Parametric Human Model"]}],["$","span","3D Human Modeling",{"className":"page__taxonomy-item","children":["#","3D Human Modeling"]}],["$","span","Shape-Skeleton Decoupling",{"className":"page__taxonomy-item","children":["#","Shape-Skeleton Decoupling"]}],["$","span","Pose Correctives",{"className":"page__taxonomy-item","children":["#","Pose Correctives"]}],["$","span","Single Image Mesh Fitting",{"className":"page__taxonomy-item","children":["#","Single Image Mesh Fitting"]}],["$","span","Expressive Modeling",{"className":"page__taxonomy-item","children":["#","Expressive Modeling"]}],["$","span","Goliath Dataset",{"className":"page__taxonomy-item","children":["#","Goliath Dataset"]}]]}]]}]]}],["$","article","2025-8-22-aiXiv_A_Next-Generation_Open_Access_Ecosystem_for_Scientific_Discovery_Generated_by_AI_Scientists",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-22-aiXiv_A_Next-Generation_Open_Access_Ecosystem_for_Scientific_Discovery_Generated_by_AI_Scientists/","children":"[논문리뷰] aiXiv: A Next-Generation Open Access Ecosystem for Scientific Discovery Generated by AI Scientists"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Heng Zhang이 [arXiv]에 게시한 'aiXiv: A Next-Generation Open Access Ecosystem for Scientific Discovery Generated by AI Scientists' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-22 13:10:52+0900","children":"2025년 8월 22일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Agents",{"className":"page__taxonomy-item","children":["#","AI Agents"]}],["$","span","Open Access",{"className":"page__taxonomy-item","children":["#","Open Access"]}],["$","span","Scientific Discovery",{"className":"page__taxonomy-item","children":["#","Scientific Discovery"]}],["$","span","Peer Review",{"className":"page__taxonomy-item","children":["#","Peer Review"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Multi-agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-agent Systems"]}],["$","span","Prompt Injection",{"className":"page__taxonomy-item","children":["#","Prompt Injection"]}],["$","span","Iterative Refinement",{"className":"page__taxonomy-item","children":["#","Iterative Refinement"]}]]}]]}]]}],["$","article","2025-8-21-ViExam_Are_Vision_Language_Models_Better_than_Humans_on_Vietnamese_Multimodal_Exam_Questions",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-ViExam_Are_Vision_Language_Models_Better_than_Humans_on_Vietnamese_Multimodal_Exam_Questions/","children":"[논문리뷰] ViExam: Are Vision Language Models Better than Humans on Vietnamese Multimodal Exam Questions?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Daeyoung Kim이 [arXiv]에 게시한 'ViExam: Are Vision Language Models Better than Humans on Vietnamese Multimodal Exam Questions?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-21 13:15:28+0900","children":"2025년 8월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision Language Models",{"className":"page__taxonomy-item","children":["#","Vision Language Models"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Vietnamese Language",{"className":"page__taxonomy-item","children":["#","Vietnamese Language"]}],["$","span","Educational Assessment",{"className":"page__taxonomy-item","children":["#","Educational Assessment"]}],["$","span","Low-Resource Languages",{"className":"page__taxonomy-item","children":["#","Low-Resource Languages"]}],["$","span","Cross-Lingual Reasoning",{"className":"page__taxonomy-item","children":["#","Cross-Lingual Reasoning"]}],["$","span","ViExam",{"className":"page__taxonomy-item","children":["#","ViExam"]}],["$","span","Human-in-the-Loop",{"className":"page__taxonomy-item","children":["#","Human-in-the-Loop"]}]]}]]}]]}],["$","article","2025-8-21-Tinker_Diffusions_Gift_to_3D--Multi-View_Consistent_Editing_From_Sparse_Inputs_without_Per-Scene_Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-Tinker_Diffusions_Gift_to_3D--Multi-View_Consistent_Editing_From_Sparse_Inputs_without_Per-Scene_Optimization/","children":"[논문리뷰] Tinker: Diffusion's Gift to 3D--Multi-View Consistent Editing From Sparse Inputs without Per-Scene Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hao Chen이 [arXiv]에 게시한 'Tinker: Diffusion's Gift to 3D--Multi-View Consistent Editing From Sparse Inputs without Per-Scene Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-21 13:15:28+0900","children":"2025년 8월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Editing",{"className":"page__taxonomy-item","children":["#","3D Editing"]}],["$","span","Multi-View Consistency",{"className":"page__taxonomy-item","children":["#","Multi-View Consistency"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Sparse Input",{"className":"page__taxonomy-item","children":["#","Sparse Input"]}],["$","span","Zero-Shot Learning",{"className":"page__taxonomy-item","children":["#","Zero-Shot Learning"]}],["$","span","Scene Completion",{"className":"page__taxonomy-item","children":["#","Scene Completion"]}],["$","span","Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","Gaussian Splatting"]}]]}]]}]]}],["$","article","2025-8-21-RynnEC_Bringing_MLLMs_into_Embodied_World",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-RynnEC_Bringing_MLLMs_into_Embodied_World/","children":"[논문리뷰] RynnEC: Bringing MLLMs into Embodied World"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"jiangpinliu이 [arXiv]에 게시한 'RynnEC: Bringing MLLMs into Embodied World' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-21 13:15:28+0900","children":"2025년 8월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-modal Large Language Models",{"className":"page__taxonomy-item","children":["#","Multi-modal Large Language Models"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Embodied Cognition",{"className":"page__taxonomy-item","children":["#","Embodied Cognition"]}],["$","span","Video Understanding",{"className":"page__taxonomy-item","children":["#","Video Understanding"]}],["$","span","Instance Segmentation",{"className":"page__taxonomy-item","children":["#","Instance Segmentation"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}]]}]]}]]}],["$","article","2025-8-21-Refining_Contrastive_Learning_and_Homography_Relations_for_Multi-Modal_Recommendation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-Refining_Contrastive_Learning_and_Homography_Relations_for_Multi-Modal_Recommendation/","children":"[논문리뷰] Refining Contrastive Learning and Homography Relations for Multi-Modal Recommendation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shiqing Wu이 [arXiv]에 게시한 'Refining Contrastive Learning and Homography Relations for Multi-Modal Recommendation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-21 13:15:28+0900","children":"2025년 8월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-modal Recommendation",{"className":"page__taxonomy-item","children":["#","Multi-modal Recommendation"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Graph Neural Network",{"className":"page__taxonomy-item","children":["#","Graph Neural Network"]}],["$","span","Homography Relations",{"className":"page__taxonomy-item","children":["#","Homography Relations"]}],["$","span","Meta-network",{"className":"page__taxonomy-item","children":["#","Meta-network"]}],["$","span","Orthogonal Constraint",{"className":"page__taxonomy-item","children":["#","Orthogonal Constraint"]}],["$","span","Data Sparsity",{"className":"page__taxonomy-item","children":["#","Data Sparsity"]}]]}]]}]]}],["$","article","2025-8-21-Quantization_Meets_dLLMs_A_Systematic_Study_of_Post-training_Quantization_for_Diffusion_LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-Quantization_Meets_dLLMs_A_Systematic_Study_of_Post-training_Quantization_for_Diffusion_LLMs/","children":"[논문리뷰] Quantization Meets dLLMs: A Systematic Study of Post-training Quantization for Diffusion LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Haobo Xu이 [arXiv]에 게시한 'Quantization Meets dLLMs: A Systematic Study of Post-training Quantization for Diffusion LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-21 13:15:28+0900","children":"2025년 8월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion LLMs",{"className":"page__taxonomy-item","children":["#","Diffusion LLMs"]}],["$","span","Post-training Quantization (PTQ)",{"className":"page__taxonomy-item","children":["#","Post-training Quantization (PTQ)"]}],["$","span","Model Compression",{"className":"page__taxonomy-item","children":["#","Model Compression"]}],["$","span","Activation Outliers",{"className":"page__taxonomy-item","children":["#","Activation Outliers"]}],["$","span","Quantization Methods",{"className":"page__taxonomy-item","children":["#","Quantization Methods"]}],["$","span","Efficient Deployment",{"className":"page__taxonomy-item","children":["#","Efficient Deployment"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}]]}]]}]]}],["$","article","2025-8-21-On-Policy_RL_Meets_Off-Policy_Experts_Harmonizing_Supervised_Fine-Tuning_and_Reinforcement_Learning_via_Dynamic_Weighting",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-On-Policy_RL_Meets_Off-Policy_Experts_Harmonizing_Supervised_Fine-Tuning_and_Reinforcement_Learning_via_Dynamic_Weighting/","children":"[논문리뷰] On-Policy RL Meets Off-Policy Experts: Harmonizing Supervised Fine-Tuning and Reinforcement Learning via Dynamic Weighting"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Guoyin Wang이 [arXiv]에 게시한 'On-Policy RL Meets Off-Policy Experts: Harmonizing Supervised Fine-Tuning and Reinforcement Learning via Dynamic Weighting' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-21 13:15:28+0900","children":"2025년 8월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Supervised Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning"]}],["$","span","On-Policy RL",{"className":"page__taxonomy-item","children":["#","On-Policy RL"]}],["$","span","Off-Policy Experts",{"className":"page__taxonomy-item","children":["#","Off-Policy Experts"]}],["$","span","Dynamic Weighting",{"className":"page__taxonomy-item","children":["#","Dynamic Weighting"]}],["$","span","LLM Alignment",{"className":"page__taxonomy-item","children":["#","LLM Alignment"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}]]}]]}]]}],["$","article","2025-8-21-NVIDIA_Nemotron_Nano_2_An_Accurate_and_Efficient_Hybrid_Mamba-Transformer_Reasoning_Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-NVIDIA_Nemotron_Nano_2_An_Accurate_and_Efficient_Hybrid_Mamba-Transformer_Reasoning_Model/","children":"[논문리뷰] NVIDIA Nemotron Nano 2: An Accurate and Efficient Hybrid Mamba-Transformer Reasoning Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"abercovich이 [arXiv]에 게시한 'NVIDIA Nemotron Nano 2: An Accurate and Efficient Hybrid Mamba-Transformer Reasoning Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-21 13:15:28+0900","children":"2025년 8월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Hybrid Architecture",{"className":"page__taxonomy-item","children":["#","Hybrid Architecture"]}],["$","span","Mamba-Transformer",{"className":"page__taxonomy-item","children":["#","Mamba-Transformer"]}],["$","span","Reasoning LLM",{"className":"page__taxonomy-item","children":["#","Reasoning LLM"]}],["$","span","Model Compression",{"className":"page__taxonomy-item","children":["#","Model Compression"]}],["$","span","Knowledge Distillation",{"className":"page__taxonomy-item","children":["#","Knowledge Distillation"]}],["$","span","Long Context",{"className":"page__taxonomy-item","children":["#","Long Context"]}],["$","span","High Throughput",{"className":"page__taxonomy-item","children":["#","High Throughput"]}],["$","span","FP8 Training",{"className":"page__taxonomy-item","children":["#","FP8 Training"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}]]}]]}]]}],["$","article","2025-8-21-mSCoRe_a_Multilingual_and_Scalable_Benchmark_for_Skill-based_Commonsense_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-mSCoRe_a_Multilingual_and_Scalable_Benchmark_for_Skill-based_Commonsense_Reasoning/","children":"[논문리뷰] mSCoRe: a Multilingual and Scalable Benchmark for Skill-based Commonsense Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"anoperson이 [arXiv]에 게시한 'mSCoRe: a Multilingual and Scalable Benchmark for Skill-based Commonsense Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-21 13:15:28+0900","children":"2025년 8월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multilingual Benchmark",{"className":"page__taxonomy-item","children":["#","Multilingual Benchmark"]}],["$","span","Commonsense Reasoning",{"className":"page__taxonomy-item","children":["#","Commonsense Reasoning"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Reasoning Taxonomy",{"className":"page__taxonomy-item","children":["#","Reasoning Taxonomy"]}],["$","span","Benchmark Scaling",{"className":"page__taxonomy-item","children":["#","Benchmark Scaling"]}],["$","span","Data Synthesis",{"className":"page__taxonomy-item","children":["#","Data Synthesis"]}],["$","span","Cultural Nuances",{"className":"page__taxonomy-item","children":["#","Cultural Nuances"]}]]}]]}]]}],["$","article","2025-8-21-MeshCoder_LLM-Powered_Structured_Mesh_Code_Generation_from_Point_Clouds",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-MeshCoder_LLM-Powered_Structured_Mesh_Code_Generation_from_Point_Clouds/","children":"[논문리뷰] MeshCoder: LLM-Powered Structured Mesh Code Generation from Point Clouds"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiangmiao이 [arXiv]에 게시한 'MeshCoder: LLM-Powered Structured Mesh Code Generation from Point Clouds' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-21 13:15:28+0900","children":"2025년 8월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Point Clouds",{"className":"page__taxonomy-item","children":["#","Point Clouds"]}],["$","span","3D Reconstruction",{"className":"page__taxonomy-item","children":["#","3D Reconstruction"]}],["$","span","Structured Mesh",{"className":"page__taxonomy-item","children":["#","Structured Mesh"]}],["$","span","Blender Python",{"className":"page__taxonomy-item","children":["#","Blender Python"]}],["$","span","Shape Editing",{"className":"page__taxonomy-item","children":["#","Shape Editing"]}],["$","span","Part-based Representation",{"className":"page__taxonomy-item","children":["#","Part-based Representation"]}],["$","span","Large Language Model",{"className":"page__taxonomy-item","children":["#","Large Language Model"]}]]}]]}]]}],["$","article","2025-8-21-MCP-Universe_Benchmarking_Large_Language_Models_with_Real-World_Model_Context_Protocol_Servers",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-MCP-Universe_Benchmarking_Large_Language_Models_with_Real-World_Model_Context_Protocol_Servers/","children":"[논문리뷰] MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Prathyusha Jwalapuram이 [arXiv]에 게시한 'MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-21 13:15:28+0900","children":"2025년 8월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Model Context Protocol",{"className":"page__taxonomy-item","children":["#","Model Context Protocol"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Real-World Applications",{"className":"page__taxonomy-item","children":["#","Real-World Applications"]}],["$","span","Agent Evaluation",{"className":"page__taxonomy-item","children":["#","Agent Evaluation"]}],["$","span","Long Context",{"className":"page__taxonomy-item","children":["#","Long Context"]}],["$","span","Unknown Tools",{"className":"page__taxonomy-item","children":["#","Unknown Tools"]}]]}]]}]]}],["$","article","2025-8-21-Local_Scale_Equivariance_with_Latent_Deep_Equilibrium_Canonicalizer",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-Local_Scale_Equivariance_with_Latent_Deep_Equilibrium_Canonicalizer/","children":"[논문리뷰] Local Scale Equivariance with Latent Deep Equilibrium Canonicalizer"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jeremiah Jiang이 [arXiv]에 게시한 'Local Scale Equivariance with Latent Deep Equilibrium Canonicalizer' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-21 13:15:28+0900","children":"2025년 8월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Scale Equivariance",{"className":"page__taxonomy-item","children":["#","Scale Equivariance"]}],["$","span","Deep Equilibrium Models",{"className":"page__taxonomy-item","children":["#","Deep Equilibrium Models"]}],["$","span","Canonicalization",{"className":"page__taxonomy-item","children":["#","Canonicalization"]}],["$","span","Computer Vision",{"className":"page__taxonomy-item","children":["#","Computer Vision"]}],["$","span","Image Classification",{"className":"page__taxonomy-item","children":["#","Image Classification"]}],["$","span","Semantic Segmentation",{"className":"page__taxonomy-item","children":["#","Semantic Segmentation"]}],["$","span","Latent Representation",{"className":"page__taxonomy-item","children":["#","Latent Representation"]}],["$","span","Monotone Scaling",{"className":"page__taxonomy-item","children":["#","Monotone Scaling"]}]]}]]}]]}],["$","article","2025-8-21-Leuvenshtein_Efficient_FHE-based_Edit_Distance_Computation_with_Single_Bootstrap_per_Cell",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-Leuvenshtein_Efficient_FHE-based_Edit_Distance_Computation_with_Single_Bootstrap_per_Cell/","children":"[논문리뷰] Leuvenshtein: Efficient FHE-based Edit Distance Computation with Single Bootstrap per Cell"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ingrid Verbauwhede이 [arXiv]에 게시한 'Leuvenshtein: Efficient FHE-based Edit Distance Computation with Single Bootstrap per Cell' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-21 13:15:28+0900","children":"2025년 8월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Fully Homomorphic Encryption (FHE)",{"className":"page__taxonomy-item","children":["#","Fully Homomorphic Encryption (FHE)"]}],["$","span","TFHE",{"className":"page__taxonomy-item","children":["#","TFHE"]}],["$","span","Levenshtein Distance",{"className":"page__taxonomy-item","children":["#","Levenshtein Distance"]}],["$","span","Programmable Bootstrapping (PBS)",{"className":"page__taxonomy-item","children":["#","Programmable Bootstrapping (PBS)"]}],["$","span","Privacy-Preserving Computation",{"className":"page__taxonomy-item","children":["#","Privacy-Preserving Computation"]}],["$","span","String Similarity",{"className":"page__taxonomy-item","children":["#","String Similarity"]}]]}]]}]]}],["$","article","2025-8-21-FutureX_An_Advanced_Live_Benchmark_for_LLM_Agents_in_Future_Prediction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-FutureX_An_Advanced_Live_Benchmark_for_LLM_Agents_in_Future_Prediction/","children":"[논문리뷰] FutureX: An Advanced Live Benchmark for LLM Agents in Future Prediction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"tianlecai이 [arXiv]에 게시한 'FutureX: An Advanced Live Benchmark for LLM Agents in Future Prediction' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-21 13:15:28+0900","children":"2025년 8월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Future Prediction",{"className":"page__taxonomy-item","children":["#","Future Prediction"]}],["$","span","Live Benchmark",{"className":"page__taxonomy-item","children":["#","Live Benchmark"]}],["$","span","Dynamic Evaluation",{"className":"page__taxonomy-item","children":["#","Dynamic Evaluation"]}],["$","span","Data Contamination",{"className":"page__taxonomy-item","children":["#","Data Contamination"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Web Search",{"className":"page__taxonomy-item","children":["#","Web Search"]}],["$","span","Financial Forecasting",{"className":"page__taxonomy-item","children":["#","Financial Forecasting"]}],["$","span","Misinformation",{"className":"page__taxonomy-item","children":["#","Misinformation"]}]]}]]}]]}],["$","article","2025-8-21-From_Scores_to_Skills_A_Cognitive_Diagnosis_Framework_for_Evaluating_Financial_Large_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-From_Scores_to_Skills_A_Cognitive_Diagnosis_Framework_for_Evaluating_Financial_Large_Language_Models/","children":"[논문리뷰] From Scores to Skills: A Cognitive Diagnosis Framework for Evaluating Financial Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ziyan Kuang이 [arXiv]에 게시한 'From Scores to Skills: A Cognitive Diagnosis Framework for Evaluating Financial Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-21 13:15:28+0900","children":"2025년 8월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Financial LLMs",{"className":"page__taxonomy-item","children":["#","Financial LLMs"]}],["$","span","Cognitive Diagnosis Model",{"className":"page__taxonomy-item","children":["#","Cognitive Diagnosis Model"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Knowledge Assessment",{"className":"page__taxonomy-item","children":["#","Knowledge Assessment"]}],["$","span","Matrix Factorization",{"className":"page__taxonomy-item","children":["#","Matrix Factorization"]}],["$","span","CPA-QKA",{"className":"page__taxonomy-item","children":["#","CPA-QKA"]}],["$","span","Interpretability",{"className":"page__taxonomy-item","children":["#","Interpretability"]}]]}]]}]]}],["$","article","2025-8-21-From_AI_for_Science_to_Agentic_Science_A_Survey_on_Autonomous_Scientific_Discovery",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-From_AI_for_Science_to_Agentic_Science_A_Survey_on_Autonomous_Scientific_Discovery/","children":"[논문리뷰] From AI for Science to Agentic Science: A Survey on Autonomous Scientific Discovery"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"zijieqiu이 [arXiv]에 게시한 'From AI for Science to Agentic Science: A Survey on Autonomous Scientific Discovery' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-21 13:15:28+0900","children":"2025년 8월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Autonomous Scientific Discovery",{"className":"page__taxonomy-item","children":["#","Autonomous Scientific Discovery"]}],["$","span","AI for Science",{"className":"page__taxonomy-item","children":["#","AI for Science"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Multi-agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-agent Systems"]}],["$","span","Scientific Workflow Automation",{"className":"page__taxonomy-item","children":["#","Scientific Workflow Automation"]}],["$","span","Natural Sciences",{"className":"page__taxonomy-item","children":["#","Natural Sciences"]}]]}]]}]]}],["$","article","2025-8-21-DuPO_Enabling_Reliable_LLM_Self-Verification_via_Dual_Preference_Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-21-DuPO_Enabling_Reliable_LLM_Self-Verification_via_Dual_Preference_Optimization/","children":"[논문리뷰] DuPO: Enabling Reliable LLM Self-Verification via Dual Preference Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yu Lu이 [arXiv]에 게시한 'DuPO: Enabling Reliable LLM Self-Verification via Dual Preference Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-21 13:15:28+0900","children":"2025년 8월 21일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Optimization",{"className":"page__taxonomy-item","children":["#","LLM Optimization"]}],["$","span","Self-Verification",{"className":"page__taxonomy-item","children":["#","Self-Verification"]}],["$","span","Dual Learning",{"className":"page__taxonomy-item","children":["#","Dual Learning"]}],["$","span","Preference Optimization",{"className":"page__taxonomy-item","children":["#","Preference Optimization"]}],["$","span","Self-Supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-Supervised Learning"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Multilingual Translation",{"className":"page__taxonomy-item","children":["#","Multilingual Translation"]}],["$","span","RLHF",{"className":"page__taxonomy-item","children":["#","RLHF"]}]]}]]}]]}],["$","article","2025-8-20-ZARA_Zero-shot_Motion_Time-Series_Analysis_via_Knowledge_and_Retrieval_Driven_LLM_Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-ZARA_Zero-shot_Motion_Time-Series_Analysis_via_Knowledge_and_Retrieval_Driven_LLM_Agents/","children":"[논문리뷰] ZARA: Zero-shot Motion Time-Series Analysis via Knowledge and Retrieval Driven LLM Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Flora D. Salim이 [arXiv]에 게시한 'ZARA: Zero-shot Motion Time-Series Analysis via Knowledge and Retrieval Driven LLM Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Zero-shot HAR",{"className":"page__taxonomy-item","children":["#","Zero-shot HAR"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Time-Series Analysis",{"className":"page__taxonomy-item","children":["#","Time-Series Analysis"]}],["$","span","Knowledge Base",{"className":"page__taxonomy-item","children":["#","Knowledge Base"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","Multi-sensor Fusion",{"className":"page__taxonomy-item","children":["#","Multi-sensor Fusion"]}],["$","span","Interpretability",{"className":"page__taxonomy-item","children":["#","Interpretability"]}]]}]]}]]}],["$","article","2025-8-20-Training-Free_Text-Guided_Color_Editing_with_Multi-Modal_Diffusion_Transformer",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-Training-Free_Text-Guided_Color_Editing_with_Multi-Modal_Diffusion_Transformer/","children":"[논문리뷰] Training-Free Text-Guided Color Editing with Multi-Modal Diffusion Transformer"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Deyu Zhou이 [arXiv]에 게시한 'Training-Free Text-Guided Color Editing with Multi-Modal Diffusion Transformer' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-Guided Editing",{"className":"page__taxonomy-item","children":["#","Text-Guided Editing"]}],["$","span","Color Editing",{"className":"page__taxonomy-item","children":["#","Color Editing"]}],["$","span","Diffusion Transformers",{"className":"page__taxonomy-item","children":["#","Diffusion Transformers"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}],["$","span","Multi-Modal AI",{"className":"page__taxonomy-item","children":["#","Multi-Modal AI"]}],["$","span","Attention Control",{"className":"page__taxonomy-item","children":["#","Attention Control"]}],["$","span","Image Manipulation",{"className":"page__taxonomy-item","children":["#","Image Manipulation"]}]]}]]}]]}],["$","article","2025-8-20-TempFlow-GRPO_When_Timing_Matters_for_GRPO_in_Flow_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-TempFlow-GRPO_When_Timing_Matters_for_GRPO_in_Flow_Models/","children":"[논문리뷰] TempFlow-GRPO: When Timing Matters for GRPO in Flow Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jian Yang이 [arXiv]에 게시한 'TempFlow-GRPO: When Timing Matters for GRPO in Flow Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Human Preference Alignment",{"className":"page__taxonomy-item","children":["#","Human Preference Alignment"]}],["$","span","GRPO",{"className":"page__taxonomy-item","children":["#","GRPO"]}],["$","span","Temporal Credit Assignment",{"className":"page__taxonomy-item","children":["#","Temporal Credit Assignment"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Text-to-Image",{"className":"page__taxonomy-item","children":["#","Text-to-Image"]}]]}]]}]]}],["$","article","2025-8-20-Semantic_IDs_for_Joint_Generative_Search_and_Recommendation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-Semantic_IDs_for_Joint_Generative_Search_and_Recommendation/","children":"[논문리뷰] Semantic IDs for Joint Generative Search and Recommendation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Enrico Palumbo이 [arXiv]에 게시한 'Semantic IDs for Joint Generative Search and Recommendation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Search and Recommendation",{"className":"page__taxonomy-item","children":["#","Search and Recommendation"]}],["$","span","Semantic IDs",{"className":"page__taxonomy-item","children":["#","Semantic IDs"]}],["$","span","Bi-Encoder",{"className":"page__taxonomy-item","children":["#","Bi-Encoder"]}],["$","span","Quantization",{"className":"page__taxonomy-item","children":["#","Quantization"]}],["$","span","Multi-Task Learning",{"className":"page__taxonomy-item","children":["#","Multi-Task Learning"]}],["$","span","Retrieval Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval Augmented Generation"]}]]}]]}]]}],["$","article","2025-8-20-Radiance_Fields_in_XR_A_Survey_on_How_Radiance_Fields_are_Envisioned_and_Addressed_for_XR_Research",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-Radiance_Fields_in_XR_A_Survey_on_How_Radiance_Fields_are_Envisioned_and_Addressed_for_XR_Research/","children":"[논문리뷰] Radiance Fields in XR: A Survey on How Radiance Fields are Envisioned and Addressed for XR Research"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Susanne Schmidt이 [arXiv]에 게시한 'Radiance Fields in XR: A Survey on How Radiance Fields are Envisioned and Addressed for XR Research' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Radiance Fields",{"className":"page__taxonomy-item","children":["#","Radiance Fields"]}],["$","span","XR",{"className":"page__taxonomy-item","children":["#","XR"]}],["$","span","NeRF",{"className":"page__taxonomy-item","children":["#","NeRF"]}],["$","span","3D Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","3D Gaussian Splatting"]}],["$","span","View Synthesis",{"className":"page__taxonomy-item","children":["#","View Synthesis"]}],["$","span","Systematic Review",{"className":"page__taxonomy-item","children":["#","Systematic Review"]}],["$","span","Immersive Technology",{"className":"page__taxonomy-item","children":["#","Immersive Technology"]}]]}]]}]]}],["$","article","2025-8-20-Prompt_Orchestration_Markup_Language",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-Prompt_Orchestration_Markup_Language/","children":"[논문리뷰] Prompt Orchestration Markup Language"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuqing Yang이 [arXiv]에 게시한 'Prompt Orchestration Markup Language' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Markup Language",{"className":"page__taxonomy-item","children":["#","Markup Language"]}],["$","span","Structured Prompting",{"className":"page__taxonomy-item","children":["#","Structured Prompting"]}],["$","span","IDE Support",{"className":"page__taxonomy-item","children":["#","IDE Support"]}],["$","span","Multimodal Data",{"className":"page__taxonomy-item","children":["#","Multimodal Data"]}],["$","span","Styling System",{"className":"page__taxonomy-item","children":["#","Styling System"]}],["$","span","Development Toolkit",{"className":"page__taxonomy-item","children":["#","Development Toolkit"]}]]}]]}]]}],["$","article","2025-8-20-OmniTry_Virtual_Try-On_Anything_without_Masks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-OmniTry_Virtual_Try-On_Anything_without_Masks/","children":"[논문리뷰] OmniTry: Virtual Try-On Anything without Masks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiaoduan Feng이 [arXiv]에 게시한 'OmniTry: Virtual Try-On Anything without Masks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Virtual Try-On",{"className":"page__taxonomy-item","children":["#","Virtual Try-On"]}],["$","span","Diffusion Model",{"className":"page__taxonomy-item","children":["#","Diffusion Model"]}],["$","span","Mask-Free",{"className":"page__taxonomy-item","children":["#","Mask-Free"]}],["$","span","Image Inpainting",{"className":"page__taxonomy-item","children":["#","Image Inpainting"]}],["$","span","ID Consistency",{"className":"page__taxonomy-item","children":["#","ID Consistency"]}],["$","span","Wearable Objects",{"className":"page__taxonomy-item","children":["#","Wearable Objects"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}]]}]]}]]}],["$","article","2025-8-20-MultiRef_Controllable_Image_Generation_with_Multiple_Visual_References",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-MultiRef_Controllable_Image_Generation_with_Multiple_Visual_References/","children":"[논문리뷰] MultiRef: Controllable Image Generation with Multiple Visual References"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shiyun Lang이 [arXiv]에 게시한 'MultiRef: Controllable Image Generation with Multiple Visual References' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Controllable Image Generation",{"className":"page__taxonomy-item","children":["#","Controllable Image Generation"]}],["$","span","Multi-modal Generation",{"className":"page__taxonomy-item","children":["#","Multi-modal Generation"]}],["$","span","Visual References",{"className":"page__taxonomy-item","children":["#","Visual References"]}],["$","span","Image-to-Image",{"className":"page__taxonomy-item","children":["#","Image-to-Image"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}],["$","span","MLLM-as-a-Judge",{"className":"page__taxonomy-item","children":["#","MLLM-as-a-Judge"]}]]}]]}]]}],["$","article","2025-8-20-Motion2Motion_Cross-topology_Motion_Transfer_with_Sparse_Correspondence",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-Motion2Motion_Cross-topology_Motion_Transfer_with_Sparse_Correspondence/","children":"[논문리뷰] Motion2Motion: Cross-topology Motion Transfer with Sparse Correspondence"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xin Chen이 [arXiv]에 게시한 'Motion2Motion: Cross-topology Motion Transfer with Sparse Correspondence' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Motion Transfer",{"className":"page__taxonomy-item","children":["#","Motion Transfer"]}],["$","span","Cross-topology",{"className":"page__taxonomy-item","children":["#","Cross-topology"]}],["$","span","Sparse Correspondence",{"className":"page__taxonomy-item","children":["#","Sparse Correspondence"]}],["$","span","Motion Matching",{"className":"page__taxonomy-item","children":["#","Motion Matching"]}],["$","span","Animation",{"className":"page__taxonomy-item","children":["#","Animation"]}],["$","span","Training-free",{"className":"page__taxonomy-item","children":["#","Training-free"]}],["$","span","Few-shot Learning",{"className":"page__taxonomy-item","children":["#","Few-shot Learning"]}]]}]]}]]}],["$","article","2025-8-20-MMAU-Pro_A_Challenging_and_Comprehensive_Benchmark_for_Holistic_Evaluation_of_Audio_General_Intelligence",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-MMAU-Pro_A_Challenging_and_Comprehensive_Benchmark_for_Holistic_Evaluation_of_Audio_General_Intelligence/","children":"[논문리뷰] MMAU-Pro: A Challenging and Comprehensive Benchmark for Holistic Evaluation of Audio General Intelligence"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Fernando López이 [arXiv]에 게시한 'MMAU-Pro: A Challenging and Comprehensive Benchmark for Holistic Evaluation of Audio General Intelligence' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Audio Intelligence",{"className":"page__taxonomy-item","children":["#","Audio Intelligence"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Audio-Language Models",{"className":"page__taxonomy-item","children":["#","Audio-Language Models"]}],["$","span","Holistic Evaluation",{"className":"page__taxonomy-item","children":["#","Holistic Evaluation"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Long-Form Audio",{"className":"page__taxonomy-item","children":["#","Long-Form Audio"]}],["$","span","Multicultural Music",{"className":"page__taxonomy-item","children":["#","Multicultural Music"]}]]}]]}]]}],["$","article","2025-8-20-MM-BrowseComp_A_Comprehensive_Benchmark_for_Multimodal_Browsing_Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-MM-BrowseComp_A_Comprehensive_Benchmark_for_Multimodal_Browsing_Agents/","children":"[논문리뷰] MM-BrowseComp: A Comprehensive Benchmark for Multimodal Browsing Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jun Dong이 [arXiv]에 게시한 'MM-BrowseComp: A Comprehensive Benchmark for Multimodal Browsing Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Browsing",{"className":"page__taxonomy-item","children":["#","Multimodal Browsing"]}],["$","span","AI Agents",{"className":"page__taxonomy-item","children":["#","AI Agents"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Deep Search",{"className":"page__taxonomy-item","children":["#","Deep Search"]}]]}]]}]]}],["$","article","2025-8-20-Mind_the_Generation_Process_Fine-Grained_Confidence_Estimation_During_LLM_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-Mind_the_Generation_Process_Fine-Grained_Confidence_Estimation_During_LLM_Generation/","children":"[논문리뷰] Mind the Generation Process: Fine-Grained Confidence Estimation During LLM Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xinyi Wang이 [arXiv]에 게시한 'Mind the Generation Process: Fine-Grained Confidence Estimation During LLM Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Confidence Estimation",{"className":"page__taxonomy-item","children":["#","Confidence Estimation"]}],["$","span","Fine-Grained",{"className":"page__taxonomy-item","children":["#","Fine-Grained"]}],["$","span","Generation Process",{"className":"page__taxonomy-item","children":["#","Generation Process"]}],["$","span","Calibration",{"className":"page__taxonomy-item","children":["#","Calibration"]}],["$","span","Monte Carlo Sampling",{"className":"page__taxonomy-item","children":["#","Monte Carlo Sampling"]}],["$","span","Backward Confidence Integration",{"className":"page__taxonomy-item","children":["#","Backward Confidence Integration"]}]]}]]}]]}],["$","article","2025-8-20-MedSAMix_A_Training-Free_Model_Merging_Approach_for_Medical_Image_Segmentation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-MedSAMix_A_Training-Free_Model_Merging_Approach_for_Medical_Image_Segmentation/","children":"[논문리뷰] MedSAMix: A Training-Free Model Merging Approach for Medical Image Segmentation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jonas Geiping이 [arXiv]에 게시한 'MedSAMix: A Training-Free Model Merging Approach for Medical Image Segmentation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Medical Image Segmentation",{"className":"page__taxonomy-item","children":["#","Medical Image Segmentation"]}],["$","span","Model Merging",{"className":"page__taxonomy-item","children":["#","Model Merging"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}],["$","span","SAM",{"className":"page__taxonomy-item","children":["#","SAM"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Zero-Order Optimization",{"className":"page__taxonomy-item","children":["#","Zero-Order Optimization"]}],["$","span","Bayesian Optimization",{"className":"page__taxonomy-item","children":["#","Bayesian Optimization"]}]]}]]}]]}],["$","article","2025-8-20-LongSplat_Robust_Unposed_3D_Gaussian_Splatting_for_Casual_Long_Videos",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-LongSplat_Robust_Unposed_3D_Gaussian_Splatting_for_Casual_Long_Videos/","children":"[논문리뷰] LongSplat: Robust Unposed 3D Gaussian Splatting for Casual Long Videos"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yen-Yu Lin이 [arXiv]에 게시한 'LongSplat: Robust Unposed 3D Gaussian Splatting for Casual Long Videos' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Novel View Synthesis",{"className":"page__taxonomy-item","children":["#","Novel View Synthesis"]}],["$","span","3D Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","3D Gaussian Splatting"]}],["$","span","Unposed Reconstruction",{"className":"page__taxonomy-item","children":["#","Unposed Reconstruction"]}],["$","span","Camera Pose Estimation",{"className":"page__taxonomy-item","children":["#","Camera Pose Estimation"]}],["$","span","Incremental Optimization",{"className":"page__taxonomy-item","children":["#","Incremental Optimization"]}],["$","span","Octree",{"className":"page__taxonomy-item","children":["#","Octree"]}],["$","span","Long Videos",{"className":"page__taxonomy-item","children":["#","Long Videos"]}]]}]]}]]}],["$","article","2025-8-20-Leveraging_Large_Language_Models_for_Predictive_Analysis_of_Human_Misery",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-Leveraging_Large_Language_Models_for_Predictive_Analysis_of_Human_Misery/","children":"[논문리뷰] Leveraging Large Language Models for Predictive Analysis of Human Misery"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Abhilash Nandy이 [arXiv]에 게시한 'Leveraging Large Language Models for Predictive Analysis of Human Misery' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Affective Computing",{"className":"page__taxonomy-item","children":["#","Affective Computing"]}],["$","span","Misery Score Prediction",{"className":"page__taxonomy-item","children":["#","Misery Score Prediction"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","Few-shot Learning",{"className":"page__taxonomy-item","children":["#","Few-shot Learning"]}],["$","span","Gamified Evaluation",{"className":"page__taxonomy-item","children":["#","Gamified Evaluation"]}],["$","span","Feedback-driven Adaptation",{"className":"page__taxonomy-item","children":["#","Feedback-driven Adaptation"]}]]}]]}]]}],["$","article","2025-8-20-Evaluating_Podcast_Recommendations_with_Profile-Aware_LLM-as-a-Judge",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-Evaluating_Podcast_Recommendations_with_Profile-Aware_LLM-as-a-Judge/","children":"[논문리뷰] Evaluating Podcast Recommendations with Profile-Aware LLM-as-a-Judge"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Alice Wang이 [arXiv]에 게시한 'Evaluating Podcast Recommendations with Profile-Aware LLM-as-a-Judge' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Podcast Recommendation",{"className":"page__taxonomy-item","children":["#","Podcast Recommendation"]}],["$","span","LLM-as-a-Judge",{"className":"page__taxonomy-item","children":["#","LLM-as-a-Judge"]}],["$","span","Offline Evaluation",{"className":"page__taxonomy-item","children":["#","Offline Evaluation"]}],["$","span","User Profiling",{"className":"page__taxonomy-item","children":["#","User Profiling"]}],["$","span","Recommender Systems",{"className":"page__taxonomy-item","children":["#","Recommender Systems"]}],["$","span","Natural Language Processing",{"className":"page__taxonomy-item","children":["#","Natural Language Processing"]}]]}]]}]]}],["$","article","2025-8-20-Embodied-R1_Reinforced_Embodied_Reasoning_for_General_Robotic_Manipulation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-Embodied-R1_Reinforced_Embodied_Reasoning_for_General_Robotic_Manipulation/","children":"[논문리뷰] Embodied-R1: Reinforced Embodied Reasoning for General Robotic Manipulation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Fei Ni이 [arXiv]에 게시한 'Embodied-R1: Reinforced Embodied Reasoning for General Robotic Manipulation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Robotic Manipulation",{"className":"page__taxonomy-item","children":["#","Robotic Manipulation"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Vision-Language Model",{"className":"page__taxonomy-item","children":["#","Vision-Language Model"]}],["$","span","Pointing",{"className":"page__taxonomy-item","children":["#","Pointing"]}],["$","span","Zero-shot Generalization",{"className":"page__taxonomy-item","children":["#","Zero-shot Generalization"]}]]}]]}]]}],["$","article","2025-8-20-Describe_What_You_See_with_Multimodal_Large_Language_Models_to_Enhance_Video_Recommendations",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-Describe_What_You_See_with_Multimodal_Large_Language_Models_to_Enhance_Video_Recommendations/","children":"[논문리뷰] Describe What You See with Multimodal Large Language Models to Enhance Video Recommendations"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Mounia Lalmas이 [arXiv]에 게시한 'Describe What You See with Multimodal Large Language Models to Enhance Video Recommendations' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models"]}],["$","span","Video Recommendation",{"className":"page__taxonomy-item","children":["#","Video Recommendation"]}],["$","span","Zero-Shot Learning",{"className":"page__taxonomy-item","children":["#","Zero-Shot Learning"]}],["$","span","Content-Based Filtering",{"className":"page__taxonomy-item","children":["#","Content-Based Filtering"]}],["$","span","Natural Language Processing",{"className":"page__taxonomy-item","children":["#","Natural Language Processing"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}]]}]]}]]}],["$","article","2025-8-20-CorrSteer_Steering_Improves_Task_Performance_and_Safety_in_LLMs_through_Correlation-based_Sparse_Autoencoder_Feature_Selection",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-CorrSteer_Steering_Improves_Task_Performance_and_Safety_in_LLMs_through_Correlation-based_Sparse_Autoencoder_Feature_Selection/","children":"[논문리뷰] CorrSteer: Steering Improves Task Performance and Safety in LLMs through Correlation-based Sparse Autoencoder Feature Selection"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Adriano Koshiyama이 [arXiv]에 게시한 'CorrSteer: Steering Improves Task Performance and Safety in LLMs through Correlation-based Sparse Autoencoder Feature Selection' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Sparse Autoencoders",{"className":"page__taxonomy-item","children":["#","Sparse Autoencoders"]}],["$","span","LLM Steering",{"className":"page__taxonomy-item","children":["#","LLM Steering"]}],["$","span","Feature Selection",{"className":"page__taxonomy-item","children":["#","Feature Selection"]}],["$","span","Correlation Analysis",{"className":"page__taxonomy-item","children":["#","Correlation Analysis"]}],["$","span","AI Safety",{"className":"page__taxonomy-item","children":["#","AI Safety"]}],["$","span","Bias Mitigation",{"className":"page__taxonomy-item","children":["#","Bias Mitigation"]}],["$","span","Mechanistic Interpretability",{"className":"page__taxonomy-item","children":["#","Mechanistic Interpretability"]}]]}]]}]]}],["$","article","2025-8-20-Copyright_Protection_for_Large_Language_Models_A_Survey_of_Methods_Challenges_and_Trends",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-Copyright_Protection_for_Large_Language_Models_A_Survey_of_Methods_Challenges_and_Trends/","children":"[논문리뷰] Copyright Protection for Large Language Models: A Survey of Methods, Challenges, and Trends"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xixiang Zhao이 [arXiv]에 게시한 'Copyright Protection for Large Language Models: A Survey of Methods, Challenges, and Trends' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Copyright Protection",{"className":"page__taxonomy-item","children":["#","LLM Copyright Protection"]}],["$","span","Model Fingerprinting",{"className":"page__taxonomy-item","children":["#","Model Fingerprinting"]}],["$","span","Text Watermarking",{"className":"page__taxonomy-item","children":["#","Text Watermarking"]}],["$","span","Invasive Fingerprinting",{"className":"page__taxonomy-item","children":["#","Invasive Fingerprinting"]}],["$","span","Intrinsic Fingerprinting",{"className":"page__taxonomy-item","children":["#","Intrinsic Fingerprinting"]}],["$","span","Intellectual Property",{"className":"page__taxonomy-item","children":["#","Intellectual Property"]}],["$","span","Digital Rights Management",{"className":"page__taxonomy-item","children":["#","Digital Rights Management"]}],["$","span","Backdoor Watermarking",{"className":"page__taxonomy-item","children":["#","Backdoor Watermarking"]}]]}]]}]]}],["$","article","2025-8-20-Chain-of-Agents_End-to-End_Agent_Foundation_Models_via_Multi-Agent_Distillation_and_Agentic_RL",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-Chain-of-Agents_End-to-End_Agent_Foundation_Models_via_Multi-Agent_Distillation_and_Agentic_RL/","children":"[논문리뷰] Chain-of-Agents: End-to-End Agent Foundation Models via Multi-Agent Distillation and Agentic RL"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Liam-Liu이 [arXiv]에 게시한 'Chain-of-Agents: End-to-End Agent Foundation Models via Multi-Agent Distillation and Agentic RL' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Chain-of-Agents",{"className":"page__taxonomy-item","children":["#","Chain-of-Agents"]}],["$","span","Agent Foundation Models",{"className":"page__taxonomy-item","children":["#","Agent Foundation Models"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Tool-Integrated Reasoning",{"className":"page__taxonomy-item","children":["#","Tool-Integrated Reasoning"]}],["$","span","Multi-agent Distillation",{"className":"page__taxonomy-item","children":["#","Multi-agent Distillation"]}],["$","span","Agentic Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Agentic Reinforcement Learning"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","End-to-End Learning",{"className":"page__taxonomy-item","children":["#","End-to-End Learning"]}]]}]]}]]}],["$","article","2025-8-20-CAMAR_Continuous_Actions_Multi-Agent_Routing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-CAMAR_Continuous_Actions_Multi-Agent_Routing/","children":"[논문리뷰] CAMAR: Continuous Actions Multi-Agent Routing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Alexey Skrynnik이 [arXiv]에 게시한 'CAMAR: Continuous Actions Multi-Agent Routing' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-Agent Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Multi-Agent Reinforcement Learning"]}],["$","span","Continuous Control",{"className":"page__taxonomy-item","children":["#","Continuous Control"]}],["$","span","Pathfinding",{"className":"page__taxonomy-item","children":["#","Pathfinding"]}],["$","span","MARL Benchmark",{"className":"page__taxonomy-item","children":["#","MARL Benchmark"]}],["$","span","GPU Acceleration",{"className":"page__taxonomy-item","children":["#","GPU Acceleration"]}],["$","span","Robotics Simulation",{"className":"page__taxonomy-item","children":["#","Robotics Simulation"]}],["$","span","Scalability",{"className":"page__taxonomy-item","children":["#","Scalability"]}],["$","span","Heterogeneous Agents",{"className":"page__taxonomy-item","children":["#","Heterogeneous Agents"]}]]}]]}]]}],["$","article","2025-8-20-Beyond_Human_Judgment_A_Bayesian_Evaluation_of_LLMs_Moral_Values_Understanding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-Beyond_Human_Judgment_A_Bayesian_Evaluation_of_LLMs_Moral_Values_Understanding/","children":"[논문리뷰] Beyond Human Judgment: A Bayesian Evaluation of LLMs' Moral Values Understanding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Alina Landowska이 [arXiv]에 게시한 'Beyond Human Judgment: A Bayesian Evaluation of LLMs' Moral Values Understanding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Moral Reasoning",{"className":"page__taxonomy-item","children":["#","Moral Reasoning"]}],["$","span","Bayesian Evaluation",{"className":"page__taxonomy-item","children":["#","Bayesian Evaluation"]}],["$","span","Uncertainty Quantification",{"className":"page__taxonomy-item","children":["#","Uncertainty Quantification"]}],["$","span","Natural Language Processing",{"className":"page__taxonomy-item","children":["#","Natural Language Processing"]}],["$","span","Soft Labels",{"className":"page__taxonomy-item","children":["#","Soft Labels"]}]]}]]}]]}],["$","article","2025-8-20-A_Stitch_in_Time_Saves_Nine_Proactive_Self-Refinement_for_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-A_Stitch_in_Time_Saves_Nine_Proactive_Self-Refinement_for_Language_Models/","children":"[논문리뷰] A Stitch in Time Saves Nine: Proactive Self-Refinement for Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zishang Jiang이 [arXiv]에 게시한 'A Stitch in Time Saves Nine: Proactive Self-Refinement for Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Self-Refinement",{"className":"page__taxonomy-item","children":["#","Self-Refinement"]}],["$","span","Language Models",{"className":"page__taxonomy-item","children":["#","Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Proactive AI",{"className":"page__taxonomy-item","children":["#","Proactive AI"]}],["$","span","Generation Process",{"className":"page__taxonomy-item","children":["#","Generation Process"]}],["$","span","Markov Decision Process",{"className":"page__taxonomy-item","children":["#","Markov Decision Process"]}],["$","span","Adaptive Learning",{"className":"page__taxonomy-item","children":["#","Adaptive Learning"]}],["$","span","LLM Efficiency",{"className":"page__taxonomy-item","children":["#","LLM Efficiency"]}]]}]]}]]}],["$","article","2025-8-20-Advances_in_Speech_Separation_Techniques_Challenges_and_Future_Trends",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-20-Advances_in_Speech_Separation_Techniques_Challenges_and_Future_Trends/","children":"[논문리뷰] Advances in Speech Separation: Techniques, Challenges, and Future Trends"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhuo Chen이 [arXiv]에 게시한 'Advances in Speech Separation: Techniques, Challenges, and Future Trends' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-20 13:26:54+0900","children":"2025년 8월 20일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Speech Separation",{"className":"page__taxonomy-item","children":["#","Speech Separation"]}],["$","span","Deep Neural Networks",{"className":"page__taxonomy-item","children":["#","Deep Neural Networks"]}],["$","span","Cocktail Party Problem",{"className":"page__taxonomy-item","children":["#","Cocktail Party Problem"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Unsupervised Learning",{"className":"page__taxonomy-item","children":["#","Unsupervised Learning"]}],["$","span","Supervised Learning",{"className":"page__taxonomy-item","children":["#","Supervised Learning"]}],["$","span","Evaluation Metrics",{"className":"page__taxonomy-item","children":["#","Evaluation Metrics"]}],["$","span","Datasets",{"className":"page__taxonomy-item","children":["#","Datasets"]}]]}]]}]]}],["$","article","2025-8-19-When_Punctuation_Matters_A_Large-Scale_Comparison_of_Prompt_Robustness_Methods_for_LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-When_Punctuation_Matters_A_Large-Scale_Comparison_of_Prompt_Robustness_Methods_for_LLMs/","children":"[논문리뷰] When Punctuation Matters: A Large-Scale Comparison of Prompt Robustness Methods for LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Elena Tutubalina이 [arXiv]에 게시한 'When Punctuation Matters: A Large-Scale Comparison of Prompt Robustness Methods for LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-19 13:15:01+0900","children":"2025년 8월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Robustness",{"className":"page__taxonomy-item","children":["#","LLM Robustness"]}],["$","span","Prompt Sensitivity",{"className":"page__taxonomy-item","children":["#","Prompt Sensitivity"]}],["$","span","In-Context Learning",{"className":"page__taxonomy-item","children":["#","In-Context Learning"]}],["$","span","Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Fine-Tuning"]}],["$","span","Batch Calibration",{"className":"page__taxonomy-item","children":["#","Batch Calibration"]}],["$","span","Template Ensembles",{"className":"page__taxonomy-item","children":["#","Template Ensembles"]}],["$","span","Distribution Shift",{"className":"page__taxonomy-item","children":["#","Distribution Shift"]}]]}]]}]]}],["$","article","2025-8-19-Speed_Always_Wins_A_Survey_on_Efficient_Architectures_for_Large_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-Speed_Always_Wins_A_Survey_on_Efficient_Architectures_for_Large_Language_Models/","children":"[논문리뷰] Speed Always Wins: A Survey on Efficient Architectures for Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jusen Du이 [arXiv]에 게시한 'Speed Always Wins: A Survey on Efficient Architectures for Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-19 13:15:01+0900","children":"2025년 8월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Efficient Architectures",{"className":"page__taxonomy-item","children":["#","Efficient Architectures"]}],["$","span","Transformer Optimization",{"className":"page__taxonomy-item","children":["#","Transformer Optimization"]}],["$","span","Linear Attention",{"className":"page__taxonomy-item","children":["#","Linear Attention"]}],["$","span","State Space Models",{"className":"page__taxonomy-item","children":["#","State Space Models"]}],["$","span","Mixture-of-Experts",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts"]}],["$","span","Sparse Attention",{"className":"page__taxonomy-item","children":["#","Sparse Attention"]}],["$","span","Diffusion LLMs",{"className":"page__taxonomy-item","children":["#","Diffusion LLMs"]}]]}]]}]]}],["$","article","2025-8-19-S2-Guidance_Stochastic_Self_Guidance_for_Training-Free_Enhancement_of_Diffusion_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-S2-Guidance_Stochastic_Self_Guidance_for_Training-Free_Enhancement_of_Diffusion_Models/","children":"[논문리뷰] S^2-Guidance: Stochastic Self Guidance for Training-Free Enhancement of Diffusion Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Meiqi Wu이 [arXiv]에 게시한 'S^2-Guidance: Stochastic Self Guidance for Training-Free Enhancement of Diffusion Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-19 13:15:01+0900","children":"2025년 8월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Classifier-free Guidance",{"className":"page__taxonomy-item","children":["#","Classifier-free Guidance"]}],["$","span","Self-Guidance",{"className":"page__taxonomy-item","children":["#","Self-Guidance"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}],["$","span","Stochastic Block-Dropping",{"className":"page__taxonomy-item","children":["#","Stochastic Block-Dropping"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Text-to-Image",{"className":"page__taxonomy-item","children":["#","Text-to-Image"]}]]}]]}]]}],["$","article","2025-8-19-Representing_Speech_Through_Autoregressive_Prediction_of_Cochlear_Tokens",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-Representing_Speech_Through_Autoregressive_Prediction_of_Cochlear_Tokens/","children":"[논문리뷰] Representing Speech Through Autoregressive Prediction of Cochlear Tokens"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Daniel L. K. Yamins이 [arXiv]에 게시한 'Representing Speech Through Autoregressive Prediction of Cochlear Tokens' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-19 13:15:01+0900","children":"2025년 8월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Speech Representation Learning",{"className":"page__taxonomy-item","children":["#","Speech Representation Learning"]}],["$","span","Autoregressive Models",{"className":"page__taxonomy-item","children":["#","Autoregressive Models"]}],["$","span","Cochlear Tokens",{"className":"page__taxonomy-item","children":["#","Cochlear Tokens"]}],["$","span","Biologically Inspired AI",{"className":"page__taxonomy-item","children":["#","Biologically Inspired AI"]}],["$","span","Self-Supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-Supervised Learning"]}],["$","span","Audio Processing",{"className":"page__taxonomy-item","children":["#","Audio Processing"]}],["$","span","Transformer Networks",{"className":"page__taxonomy-item","children":["#","Transformer Networks"]}]]}]]}]]}],["$","article","2025-8-19-Reinforcement_Learning_with_Rubric_Anchors",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-Reinforcement_Learning_with_Rubric_Anchors/","children":"[논문리뷰] Reinforcement Learning with Rubric Anchors"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Haokai Xu이 [arXiv]에 게시한 'Reinforcement Learning with Rubric Anchors' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-19 13:15:01+0900","children":"2025년 8월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Rubric-based Reward",{"className":"page__taxonomy-item","children":["#","Rubric-based Reward"]}],["$","span","RLVR Extension",{"className":"page__taxonomy-item","children":["#","RLVR Extension"]}],["$","span","Human-centric AI",{"className":"page__taxonomy-item","children":["#","Human-centric AI"]}],["$","span","Controllable Generation",{"className":"page__taxonomy-item","children":["#","Controllable Generation"]}],["$","span","Reward Hacking Mitigation",{"className":"page__taxonomy-item","children":["#","Reward Hacking Mitigation"]}]]}]]}]]}],["$","article","2025-8-19-Precise_Action-to-Video_Generation_Through_Visual_Action_Prompts",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-Precise_Action-to-Video_Generation_Through_Visual_Action_Prompts/","children":"[논문리뷰] Precise Action-to-Video Generation Through Visual Action Prompts"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Minghan Qin이 [arXiv]에 게시한 'Precise Action-to-Video Generation Through Visual Action Prompts' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-19 13:15:01+0900","children":"2025년 8월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Action-to-Video Generation",{"className":"page__taxonomy-item","children":["#","Action-to-Video Generation"]}],["$","span","Visual Action Prompts",{"className":"page__taxonomy-item","children":["#","Visual Action Prompts"]}],["$","span","Skeleton Representation",{"className":"page__taxonomy-item","children":["#","Skeleton Representation"]}],["$","span","Human-Object Interaction",{"className":"page__taxonomy-item","children":["#","Human-Object Interaction"]}],["$","span","Robotic Manipulation",{"className":"page__taxonomy-item","children":["#","Robotic Manipulation"]}],["$","span","Cross-Domain Transfer",{"className":"page__taxonomy-item","children":["#","Cross-Domain Transfer"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}]]}]]}]]}],["$","article","2025-8-19-Ovis2.5_Technical_Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-Ovis2.5_Technical_Report/","children":"[논문리뷰] Ovis2.5 Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yang Li이 [arXiv]에 게시한 'Ovis2.5 Technical Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-19 13:15:01+0900","children":"2025년 8월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Native Resolution Vision",{"className":"page__taxonomy-item","children":["#","Native Resolution Vision"]}],["$","span","Deep Reasoning",{"className":"page__taxonomy-item","children":["#","Deep Reasoning"]}],["$","span","Chart Analysis",{"className":"page__taxonomy-item","children":["#","Chart Analysis"]}],["$","span","OCR",{"className":"page__taxonomy-item","children":["#","OCR"]}],["$","span","Visual Grounding",{"className":"page__taxonomy-item","children":["#","Visual Grounding"]}],["$","span","Training Efficiency",{"className":"page__taxonomy-item","children":["#","Training Efficiency"]}],["$","span","Preference Optimization",{"className":"page__taxonomy-item","children":["#","Preference Optimization"]}]]}]]}]]}],["$","article","2025-8-19-Next_Visual_Granularity_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-Next_Visual_Granularity_Generation/","children":"[논문리뷰] Next Visual Granularity Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kang Liao이 [arXiv]에 게시한 'Next Visual Granularity Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-19 13:15:01+0900","children":"2025년 8월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Granularity Control",{"className":"page__taxonomy-item","children":["#","Granularity Control"]}],["$","span","Structured Representation",{"className":"page__taxonomy-item","children":["#","Structured Representation"]}],["$","span","Hierarchical Generation",{"className":"page__taxonomy-item","children":["#","Hierarchical Generation"]}],["$","span","Coarse-to-fine",{"className":"page__taxonomy-item","children":["#","Coarse-to-fine"]}],["$","span","Visual Tokenization",{"className":"page__taxonomy-item","children":["#","Visual Tokenization"]}],["$","span","Latent Space",{"className":"page__taxonomy-item","children":["#","Latent Space"]}]]}]]}]]}],["$","article","2025-8-19-Matrix-Game_2.0_An_Open-Source_Real-Time_and_Streaming_Interactive_World_Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-Matrix-Game_2.0_An_Open-Source_Real-Time_and_Streaming_Interactive_World_Model/","children":"[논문리뷰] Matrix-Game 2.0: An Open-Source, Real-Time, and Streaming Interactive World Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yifan Zhang이 [arXiv]에 게시한 'Matrix-Game 2.0: An Open-Source, Real-Time, and Streaming Interactive World Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-19 13:15:01+0900","children":"2025년 8월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","World Model",{"className":"page__taxonomy-item","children":["#","World Model"]}],["$","span","Interactive Video Generation",{"className":"page__taxonomy-item","children":["#","Interactive Video Generation"]}],["$","span","Real-Time AI",{"className":"page__taxonomy-item","children":["#","Real-Time AI"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Auto-Regressive Generation",{"className":"page__taxonomy-item","children":["#","Auto-Regressive Generation"]}],["$","span","Data Pipeline",{"className":"page__taxonomy-item","children":["#","Data Pipeline"]}],["$","span","Self-Forcing",{"className":"page__taxonomy-item","children":["#","Self-Forcing"]}],["$","span","KV Caching",{"className":"page__taxonomy-item","children":["#","KV Caching"]}]]}]]}]]}],["$","article","2025-8-19-Lumen_Consistent_Video_Relighting_and_Harmonious_Background_Replacement_with_Video_Generative_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-Lumen_Consistent_Video_Relighting_and_Harmonious_Background_Replacement_with_Video_Generative_Models/","children":"[논문리뷰] Lumen: Consistent Video Relighting and Harmonious Background Replacement with Video Generative Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zixiang Gao이 [arXiv]에 게시한 'Lumen: Consistent Video Relighting and Harmonious Background Replacement with Video Generative Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-19 13:15:01+0900","children":"2025년 8월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Relighting",{"className":"page__taxonomy-item","children":["#","Video Relighting"]}],["$","span","Background Replacement",{"className":"page__taxonomy-item","children":["#","Background Replacement"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Temporal Consistency",{"className":"page__taxonomy-item","children":["#","Temporal Consistency"]}],["$","span","Dataset Generation",{"className":"page__taxonomy-item","children":["#","Dataset Generation"]}],["$","span","Video Editing",{"className":"page__taxonomy-item","children":["#","Video Editing"]}]]}]]}]]}],["$","article","2025-8-19-Inverse-LLaVA_Eliminating_Alignment_Pre-training_Through_Text-to-Vision_Mapping",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-Inverse-LLaVA_Eliminating_Alignment_Pre-training_Through_Text-to-Vision_Mapping/","children":"[논문리뷰] Inverse-LLaVA: Eliminating Alignment Pre-training Through Text-to-Vision Mapping"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Tyler Derr이 [arXiv]에 게시한 'Inverse-LLaVA: Eliminating Alignment Pre-training Through Text-to-Vision Mapping' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-19 13:15:01+0900","children":"2025년 8월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Alignment Pre-training",{"className":"page__taxonomy-item","children":["#","Alignment Pre-training"]}],["$","span","Text-to-Vision Mapping",{"className":"page__taxonomy-item","children":["#","Text-to-Vision Mapping"]}],["$","span","Continuous Representations",{"className":"page__taxonomy-item","children":["#","Continuous Representations"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}]]}]]}]]}],["$","article","2025-8-19-HeroBench_A_Benchmark_for_Long-Horizon_Planning_and_Structured_Reasoning_in_Virtual_Worlds",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-HeroBench_A_Benchmark_for_Long-Horizon_Planning_and_Structured_Reasoning_in_Virtual_Worlds/","children":"[논문리뷰] HeroBench: A Benchmark for Long-Horizon Planning and Structured Reasoning in Virtual Worlds"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Artyom Sorokin이 [arXiv]에 게시한 'HeroBench: A Benchmark for Long-Horizon Planning and Structured Reasoning in Virtual Worlds' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-19 13:15:01+0900","children":"2025년 8월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Long-Horizon Planning",{"className":"page__taxonomy-item","children":["#","Long-Horizon Planning"]}],["$","span","Structured Reasoning",{"className":"page__taxonomy-item","children":["#","Structured Reasoning"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Virtual Worlds",{"className":"page__taxonomy-item","children":["#","Virtual Worlds"]}],["$","span","RPG",{"className":"page__taxonomy-item","children":["#","RPG"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Agent Systems",{"className":"page__taxonomy-item","children":["#","Agent Systems"]}],["$","span","Combat Simulation",{"className":"page__taxonomy-item","children":["#","Combat Simulation"]}]]}]]}]]}],["$","article","2025-8-19-Has_GPT-5_Achieved_Spatial_Intelligence_An_Empirical_Study",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-Has_GPT-5_Achieved_Spatial_Intelligence_An_Empirical_Study/","children":"[논문리뷰] Has GPT-5 Achieved Spatial Intelligence? An Empirical Study"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ruisi Wang이 [arXiv]에 게시한 'Has GPT-5 Achieved Spatial Intelligence? An Empirical Study' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-19 13:15:01+0900","children":"2025년 8월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Spatial Intelligence",{"className":"page__taxonomy-item","children":["#","Spatial Intelligence"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Benchmark Evaluation",{"className":"page__taxonomy-item","children":["#","Benchmark Evaluation"]}],["$","span","GPT-5",{"className":"page__taxonomy-item","children":["#","GPT-5"]}],["$","span","Cognitive AI",{"className":"page__taxonomy-item","children":["#","Cognitive AI"]}],["$","span","AGI",{"className":"page__taxonomy-item","children":["#","AGI"]}]]}]]}]]}],["$","article","2025-8-19-G-CUT3R_Guided_3D_Reconstruction_with_Camera_and_Depth_Prior_Integration",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-G-CUT3R_Guided_3D_Reconstruction_with_Camera_and_Depth_Prior_Integration/","children":"[논문리뷰] G-CUT3R: Guided 3D Reconstruction with Camera and Depth Prior Integration"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Evgeny Burnaev이 [arXiv]에 게시한 'G-CUT3R: Guided 3D Reconstruction with Camera and Depth Prior Integration' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-19 13:15:01+0900","children":"2025년 8월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Reconstruction",{"className":"page__taxonomy-item","children":["#","3D Reconstruction"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}],["$","span","Multi-Modal Fusion",{"className":"page__taxonomy-item","children":["#","Multi-Modal Fusion"]}],["$","span","Camera Pose Estimation",{"className":"page__taxonomy-item","children":["#","Camera Pose Estimation"]}],["$","span","Depth Estimation",{"className":"page__taxonomy-item","children":["#","Depth Estimation"]}],["$","span","Transformer Networks",{"className":"page__taxonomy-item","children":["#","Transformer Networks"]}],["$","span","Prior Information",{"className":"page__taxonomy-item","children":["#","Prior Information"]}]]}]]}]]}],["$","article","2025-8-19-ComoRAG_A_Cognitive-Inspired_Memory-Organized_RAG_for_Stateful_Long_Narrative_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-ComoRAG_A_Cognitive-Inspired_Memory-Organized_RAG_for_Stateful_Long_Narrative_Reasoning/","children":"[논문리뷰] ComoRAG: A Cognitive-Inspired Memory-Organized RAG for Stateful Long Narrative Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yufeng Wang이 [arXiv]에 게시한 'ComoRAG: A Cognitive-Inspired Memory-Organized RAG for Stateful Long Narrative Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-19 13:15:01+0900","children":"2025년 8월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Cognitive-Inspired RAG",{"className":"page__taxonomy-item","children":["#","Cognitive-Inspired RAG"]}],["$","span","Stateful Reasoning",{"className":"page__taxonomy-item","children":["#","Stateful Reasoning"]}],["$","span","Long Narrative Comprehension",{"className":"page__taxonomy-item","children":["#","Long Narrative Comprehension"]}],["$","span","Dynamic Memory",{"className":"page__taxonomy-item","children":["#","Dynamic Memory"]}],["$","span","Metacognitive Regulation",{"className":"page__taxonomy-item","children":["#","Metacognitive Regulation"]}],["$","span","Multi-step Retrieval",{"className":"page__taxonomy-item","children":["#","Multi-step Retrieval"]}],["$","span","Hierarchical Knowledge Source",{"className":"page__taxonomy-item","children":["#","Hierarchical Knowledge Source"]}]]}]]}]]}],["$","article","2025-8-19-Beyond_Solving_Math_Quiz_Evaluating_the_Ability_of_Large_Reasoning_Models_to_Ask_for_Information",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-Beyond_Solving_Math_Quiz_Evaluating_the_Ability_of_Large_Reasoning_Models_to_Ask_for_Information/","children":"[논문리뷰] Beyond Solving Math Quiz: Evaluating the Ability of Large Reasoning Models to Ask for Information"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xi Yang이 [arXiv]에 게시한 'Beyond Solving Math Quiz: Evaluating the Ability of Large Reasoning Models to Ask for Information' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-19 13:15:01+0900","children":"2025년 8월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Reasoning Models (LRMs)",{"className":"page__taxonomy-item","children":["#","Large Reasoning Models (LRMs)"]}],["$","span","Information Seeking",{"className":"page__taxonomy-item","children":["#","Information Seeking"]}],["$","span","Incomplete Problems",{"className":"page__taxonomy-item","children":["#","Incomplete Problems"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Supervised Fine-tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning (SFT)"]}],["$","span","Overthinking",{"className":"page__taxonomy-item","children":["#","Overthinking"]}],["$","span","Hallucination",{"className":"page__taxonomy-item","children":["#","Hallucination"]}],["$","span","CRITIC-math",{"className":"page__taxonomy-item","children":["#","CRITIC-math"]}]]}]]}]]}],["$","article","2025-8-19-4DNeX_Feed-Forward_4D_Generative_Modeling_Made_Easy",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-19-4DNeX_Feed-Forward_4D_Generative_Modeling_Made_Easy/","children":"[논문리뷰] 4DNeX: Feed-Forward 4D Generative Modeling Made Easy"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zeng Tao이 [arXiv]에 게시한 '4DNeX: Feed-Forward 4D Generative Modeling Made Easy' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-19 13:15:01+0900","children":"2025년 8월 19일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","4D Generation",{"className":"page__taxonomy-item","children":["#","4D Generation"]}],["$","span","Dynamic 3D",{"className":"page__taxonomy-item","children":["#","Dynamic 3D"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Single Image Input",{"className":"page__taxonomy-item","children":["#","Single Image Input"]}],["$","span","Video Synthesis",{"className":"page__taxonomy-item","children":["#","Video Synthesis"]}],["$","span","Point Clouds",{"className":"page__taxonomy-item","children":["#","Point Clouds"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}]]}]]}]]}],["$","article","2025-8-18-X-Node_Self-Explanation_is_All_We_Need",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-18-X-Node_Self-Explanation_is_All_We_Need/","children":"[논문리뷰] X-Node: Self-Explanation is All We Need"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Islem Rekik이 [arXiv]에 게시한 'X-Node: Self-Explanation is All We Need' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-18 13:14:38+0900","children":"2025년 8월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Graph Neural Networks",{"className":"page__taxonomy-item","children":["#","Graph Neural Networks"]}],["$","span","Explainable AI",{"className":"page__taxonomy-item","children":["#","Explainable AI"]}],["$","span","Self-Explanation",{"className":"page__taxonomy-item","children":["#","Self-Explanation"]}],["$","span","Node Classification",{"className":"page__taxonomy-item","children":["#","Node Classification"]}],["$","span","Medical Imaging",{"className":"page__taxonomy-item","children":["#","Medical Imaging"]}],["$","span","Natural Language Processing",{"className":"page__taxonomy-item","children":["#","Natural Language Processing"]}],["$","span","Interpretability",{"className":"page__taxonomy-item","children":["#","Interpretability"]}]]}]]}]]}],["$","article","2025-8-18-Thyme_Think_Beyond_Images",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-18-Thyme_Think_Beyond_Images/","children":"[논문리뷰] Thyme: Think Beyond Images"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Wei Chen이 [arXiv]에 게시한 'Thyme: Think Beyond Images' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-18 13:14:38+0900","children":"2025년 8월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","Image Processing",{"className":"page__taxonomy-item","children":["#","Image Processing"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Supervised Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning"]}],["$","span","Visual Reasoning",{"className":"page__taxonomy-item","children":["#","Visual Reasoning"]}],["$","span","Sandbox",{"className":"page__taxonomy-item","children":["#","Sandbox"]}]]}]]}]]}],["$","article","2025-8-18-TexVerse_A_Universe_of_3D_Objects_with_High-Resolution_Textures",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-18-TexVerse_A_Universe_of_3D_Objects_with_High-Resolution_Textures/","children":"[논문리뷰] TexVerse: A Universe of 3D Objects with High-Resolution Textures"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Nan Cao이 [arXiv]에 게시한 'TexVerse: A Universe of 3D Objects with High-Resolution Textures' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-18 13:14:38+0900","children":"2025년 8월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Dataset",{"className":"page__taxonomy-item","children":["#","3D Dataset"]}],["$","span","High-Resolution Textures",{"className":"page__taxonomy-item","children":["#","High-Resolution Textures"]}],["$","span","Physically Based Rendering (PBR)",{"className":"page__taxonomy-item","children":["#","Physically Based Rendering (PBR)"]}],["$","span","3D Animation",{"className":"page__taxonomy-item","children":["#","3D Animation"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","GPT-5 Annotations",{"className":"page__taxonomy-item","children":["#","GPT-5 Annotations"]}],["$","span","Sketchfab",{"className":"page__taxonomy-item","children":["#","Sketchfab"]}]]}]]}]]}],["$","article","2025-8-18-StyleMM_Stylized_3D_Morphable_Face_Model_via_Text-Driven_Aligned_Image_Translation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-18-StyleMM_Stylized_3D_Morphable_Face_Model_via_Text-Driven_Aligned_Image_Translation/","children":"[논문리뷰] StyleMM: Stylized 3D Morphable Face Model via Text-Driven Aligned Image Translation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Junyong Noh이 [arXiv]에 게시한 'StyleMM: Stylized 3D Morphable Face Model via Text-Driven Aligned Image Translation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-18 13:14:38+0900","children":"2025년 8월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Morphable Model",{"className":"page__taxonomy-item","children":["#","3D Morphable Model"]}],["$","span","Face Stylization",{"className":"page__taxonomy-item","children":["#","Face Stylization"]}],["$","span","Text-to-Image Translation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Translation"]}],["$","span","Diffusion Model",{"className":"page__taxonomy-item","children":["#","Diffusion Model"]}],["$","span","Attribute Preservation",{"className":"page__taxonomy-item","children":["#","Attribute Preservation"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Computer Graphics",{"className":"page__taxonomy-item","children":["#","Computer Graphics"]}]]}]]}]]}],["$","article","2025-8-18-SSRL_Self-Search_Reinforcement_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-18-SSRL_Self-Search_Reinforcement_Learning/","children":"[논문리뷰] SSRL: Self-Search Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yanxu Chen이 [arXiv]에 게시한 'SSRL: Self-Search Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-18 13:14:38+0900","children":"2025년 8월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Self-Search",{"className":"page__taxonomy-item","children":["#","Self-Search"]}],["$","span","Sim-to-Real Transfer",{"className":"page__taxonomy-item","children":["#","Sim-to-Real Transfer"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Knowledge Retrieval",{"className":"page__taxonomy-item","children":["#","Knowledge Retrieval"]}],["$","span","Reward Modeling",{"className":"page__taxonomy-item","children":["#","Reward Modeling"]}]]}]]}]]}],["$","article","2025-8-18-SPARSE_Data_Rich_Results_Few-Shot_Semi-Supervised_Learning_via_Class-Conditioned_Image_Translation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-18-SPARSE_Data_Rich_Results_Few-Shot_Semi-Supervised_Learning_via_Class-Conditioned_Image_Translation/","children":"[논문리뷰] SPARSE Data, Rich Results: Few-Shot Semi-Supervised Learning via Class-Conditioned Image Translation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Paolo Soda이 [arXiv]에 게시한 'SPARSE Data, Rich Results: Few-Shot Semi-Supervised Learning via Class-Conditioned Image Translation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-18 13:14:38+0900","children":"2025년 8월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Semi-supervised Learning",{"className":"page__taxonomy-item","children":["#","Semi-supervised Learning"]}],["$","span","Few-shot Learning",{"className":"page__taxonomy-item","children":["#","Few-shot Learning"]}],["$","span","Medical Imaging",{"className":"page__taxonomy-item","children":["#","Medical Imaging"]}],["$","span","GAN-based Methods",{"className":"page__taxonomy-item","children":["#","GAN-based Methods"]}],["$","span","Image-to-image Translation",{"className":"page__taxonomy-item","children":["#","Image-to-image Translation"]}],["$","span","Pseudo-labeling",{"className":"page__taxonomy-item","children":["#","Pseudo-labeling"]}],["$","span","Ensemble Learning",{"className":"page__taxonomy-item","children":["#","Ensemble Learning"]}]]}]]}]]}],["$","article","2025-8-18-PaperRegister_Boosting_Flexible-grained_Paper_Search_via_Hierarchical_Register_Indexing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-18-PaperRegister_Boosting_Flexible-grained_Paper_Search_via_Hierarchical_Register_Indexing/","children":"[논문리뷰] PaperRegister: Boosting Flexible-grained Paper Search via Hierarchical Register Indexing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xianpei Han이 [arXiv]에 게시한 'PaperRegister: Boosting Flexible-grained Paper Search via Hierarchical Register Indexing' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-18 13:14:38+0900","children":"2025년 8월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","논문 검색",{"className":"page__taxonomy-item","children":["#","논문 검색"]}],["$","span","계층적 인덱싱",{"className":"page__taxonomy-item","children":["#","계층적 인덱싱"]}],["$","span","유연한 검색",{"className":"page__taxonomy-item","children":["#","유연한 검색"]}],["$","span","대규모 언어 모델",{"className":"page__taxonomy-item","children":["#","대규모 언어 모델"]}],["$","span","정보 추출",{"className":"page__taxonomy-item","children":["#","정보 추출"]}],["$","span","뷰 인식",{"className":"page__taxonomy-item","children":["#","뷰 인식"]}],["$","span","강화 학습",{"className":"page__taxonomy-item","children":["#","강화 학습"]}]]}]]}]]}],["$","article","2025-8-18-MAESTRO_Masked_AutoEncoders_for_Multimodal_Multitemporal_and_Multispectral_Earth_Observation_Data",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-18-MAESTRO_Masked_AutoEncoders_for_Multimodal_Multitemporal_and_Multispectral_Earth_Observation_Data/","children":"[논문리뷰] MAESTRO: Masked AutoEncoders for Multimodal, Multitemporal, and Multispectral Earth Observation Data"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Nicolas Gonthier이 [arXiv]에 게시한 'MAESTRO: Masked AutoEncoders for Multimodal, Multitemporal, and Multispectral Earth Observation Data' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-18 13:14:38+0900","children":"2025년 8월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Self-supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-supervised Learning"]}],["$","span","Masked Autoencoder",{"className":"page__taxonomy-item","children":["#","Masked Autoencoder"]}],["$","span","Earth Observation",{"className":"page__taxonomy-item","children":["#","Earth Observation"]}],["$","span","Multimodal",{"className":"page__taxonomy-item","children":["#","Multimodal"]}],["$","span","Multitemporal",{"className":"page__taxonomy-item","children":["#","Multitemporal"]}],["$","span","Multispectral",{"className":"page__taxonomy-item","children":["#","Multispectral"]}],["$","span","Fusion Strategies",{"className":"page__taxonomy-item","children":["#","Fusion Strategies"]}],["$","span","Target Normalization",{"className":"page__taxonomy-item","children":["#","Target Normalization"]}]]}]]}]]}],["$","article","2025-8-18-FantasyTalking2_Timestep-Layer_Adaptive_Preference_Optimization_for_Audio-Driven_Portrait_Animation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-18-FantasyTalking2_Timestep-Layer_Adaptive_Preference_Optimization_for_Audio-Driven_Portrait_Animation/","children":"[논문리뷰] FantasyTalking2: Timestep-Layer Adaptive Preference Optimization for Audio-Driven Portrait Animation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Mu Xu이 [arXiv]에 게시한 'FantasyTalking2: Timestep-Layer Adaptive Preference Optimization for Audio-Driven Portrait Animation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-18 13:14:38+0900","children":"2025년 8월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Audio-Driven Animation",{"className":"page__taxonomy-item","children":["#","Audio-Driven Animation"]}],["$","span","Preference Optimization",{"className":"page__taxonomy-item","children":["#","Preference Optimization"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Reward Modeling",{"className":"page__taxonomy-item","children":["#","Reward Modeling"]}],["$","span","Human Feedback",{"className":"page__taxonomy-item","children":["#","Human Feedback"]}],["$","span","Multi-Objective Optimization",{"className":"page__taxonomy-item","children":["#","Multi-Objective Optimization"]}],["$","span","Timestep-Layer Adaptive",{"className":"page__taxonomy-item","children":["#","Timestep-Layer Adaptive"]}]]}]]}]]}],["$","article","2025-8-18-DINOv3",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-18-DINOv3/","children":"[논문리뷰] DINOv3"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Maxime Oquab이 [arXiv]에 게시한 'DINOv3' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-18 13:14:38+0900","children":"2025년 8월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Self-supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-supervised Learning"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Vision Transformer",{"className":"page__taxonomy-item","children":["#","Vision Transformer"]}],["$","span","Dense Feature Maps",{"className":"page__taxonomy-item","children":["#","Dense Feature Maps"]}],["$","span","Gram Anchoring",{"className":"page__taxonomy-item","children":["#","Gram Anchoring"]}],["$","span","Model Distillation",{"className":"page__taxonomy-item","children":["#","Model Distillation"]}],["$","span","Geospatial AI",{"className":"page__taxonomy-item","children":["#","Geospatial AI"]}]]}]]}]]}],["$","article","2025-8-18-Controlling_Multimodal_LLMs_via_Reward-guided_Decoding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-18-Controlling_Multimodal_LLMs_via_Reward-guided_Decoding/","children":"[논문리뷰] Controlling Multimodal LLMs via Reward-guided Decoding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Michal Drozdzal이 [arXiv]에 게시한 'Controlling Multimodal LLMs via Reward-guided Decoding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-18 13:14:38+0900","children":"2025년 8월 18일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Reward Models",{"className":"page__taxonomy-item","children":["#","Reward Models"]}],["$","span","Guided Decoding",{"className":"page__taxonomy-item","children":["#","Guided Decoding"]}],["$","span","Visual Grounding",{"className":"page__taxonomy-item","children":["#","Visual Grounding"]}],["$","span","Hallucination Mitigation",{"className":"page__taxonomy-item","children":["#","Hallucination Mitigation"]}],["$","span","Object Precision",{"className":"page__taxonomy-item","children":["#","Object Precision"]}],["$","span","Object Recall",{"className":"page__taxonomy-item","children":["#","Object Recall"]}],["$","span","Inference-time Control",{"className":"page__taxonomy-item","children":["#","Inference-time Control"]}]]}]]}]]}],["$","article","2025-8-15-We-Math_2.0_A_Versatile_MathBook_System_for_Incentivizing_Visual_Mathematical_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-15-We-Math_2.0_A_Versatile_MathBook_System_for_Incentivizing_Visual_Mathematical_Reasoning/","children":"[논문리뷰] We-Math 2.0: A Versatile MathBook System for Incentivizing Visual Mathematical Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiaowan Wang이 [arXiv]에 게시한 'We-Math 2.0: A Versatile MathBook System for Incentivizing Visual Mathematical Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-15 13:09:31+0900","children":"2025년 8월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Visual Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Visual Mathematical Reasoning"]}],["$","span","MLLMs",{"className":"page__taxonomy-item","children":["#","MLLMs"]}],["$","span","Knowledge System",{"className":"page__taxonomy-item","children":["#","Knowledge System"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Dataset Construction",{"className":"page__taxonomy-item","children":["#","Dataset Construction"]}],["$","span","Mathematical Benchmark",{"className":"page__taxonomy-item","children":["#","Mathematical Benchmark"]}]]}]]}]]}],["$","article","2025-8-15-UI-Venus_Technical_Report_Building_High-performance_UI_Agents_with_RFT",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-15-UI-Venus_Technical_Report_Building_High-performance_UI_Agents_with_RFT/","children":"[논문리뷰] UI-Venus Technical Report: Building High-performance UI Agents with RFT"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shuheng Shen이 [arXiv]에 게시한 'UI-Venus Technical Report: Building High-performance UI Agents with RFT' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-15 13:09:31+0900","children":"2025년 8월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","UI Agent",{"className":"page__taxonomy-item","children":["#","UI Agent"]}],["$","span","MLLM",{"className":"page__taxonomy-item","children":["#","MLLM"]}],["$","span","RFT",{"className":"page__taxonomy-item","children":["#","RFT"]}],["$","span","UI Grounding",{"className":"page__taxonomy-item","children":["#","UI Grounding"]}],["$","span","UI Navigation",{"className":"page__taxonomy-item","children":["#","UI Navigation"]}],["$","span","GRPO",{"className":"page__taxonomy-item","children":["#","GRPO"]}],["$","span","Data Cleaning",{"className":"page__taxonomy-item","children":["#","Data Cleaning"]}],["$","span","Self-Evolving Trajectory",{"className":"page__taxonomy-item","children":["#","Self-Evolving Trajectory"]}]]}]]}]]}],["$","article","2025-8-15-ToonComposer_Streamlining_Cartoon_Production_with_Generative_Post-Keyframing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-15-ToonComposer_Streamlining_Cartoon_Production_with_Generative_Post-Keyframing/","children":"[논문리뷰] ToonComposer: Streamlining Cartoon Production with Generative Post-Keyframing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiaoyu Li이 [arXiv]에 게시한 'ToonComposer: Streamlining Cartoon Production with Generative Post-Keyframing' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-15 13:09:31+0900","children":"2025년 8월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Cartoon Generation",{"className":"page__taxonomy-item","children":["#","Cartoon Generation"]}],["$","span","Video Diffusion Models",{"className":"page__taxonomy-item","children":["#","Video Diffusion Models"]}],["$","span","DiT",{"className":"page__taxonomy-item","children":["#","DiT"]}],["$","span","Post-Keyframing",{"className":"page__taxonomy-item","children":["#","Post-Keyframing"]}],["$","span","Low-Rank Adaptation",{"className":"page__taxonomy-item","children":["#","Low-Rank Adaptation"]}],["$","span","Sparse Control",{"className":"page__taxonomy-item","children":["#","Sparse Control"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Animation",{"className":"page__taxonomy-item","children":["#","Animation"]}]]}]]}]]}],["$","article","2025-8-15-STream3R_Scalable_Sequential_3D_Reconstruction_with_Causal_Transformer",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-15-STream3R_Scalable_Sequential_3D_Reconstruction_with_Causal_Transformer/","children":"[논문리뷰] STream3R: Scalable Sequential 3D Reconstruction with Causal Transformer"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Honghua Chen이 [arXiv]에 게시한 'STream3R: Scalable Sequential 3D Reconstruction with Causal Transformer' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-15 13:09:31+0900","children":"2025년 8월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Reconstruction",{"className":"page__taxonomy-item","children":["#","3D Reconstruction"]}],["$","span","Causal Transformer",{"className":"page__taxonomy-item","children":["#","Causal Transformer"]}],["$","span","Sequential Modeling",{"className":"page__taxonomy-item","children":["#","Sequential Modeling"]}],["$","span","Streaming Data",{"className":"page__taxonomy-item","children":["#","Streaming Data"]}],["$","span","Pointmap Prediction",{"className":"page__taxonomy-item","children":["#","Pointmap Prediction"]}],["$","span","Online Perception",{"className":"page__taxonomy-item","children":["#","Online Perception"]}],["$","span","KVCache",{"className":"page__taxonomy-item","children":["#","KVCache"]}]]}]]}]]}],["$","article","2025-8-15-Processing_and_acquisition_traces_in_visual_encoders_What_does_CLIP_know_about_your_camera",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-15-Processing_and_acquisition_traces_in_visual_encoders_What_does_CLIP_know_about_your_camera/","children":"[논문리뷰] Processing and acquisition traces in visual encoders: What does CLIP know about your camera?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Giorgos Tolias이 [arXiv]에 게시한 'Processing and acquisition traces in visual encoders: What does CLIP know about your camera?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-15 13:09:31+0900","children":"2025년 8월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Visual Encoders",{"className":"page__taxonomy-item","children":["#","Visual Encoders"]}],["$","span","Metadata",{"className":"page__taxonomy-item","children":["#","Metadata"]}],["$","span","Image Processing",{"className":"page__taxonomy-item","children":["#","Image Processing"]}],["$","span","Image Acquisition",{"className":"page__taxonomy-item","children":["#","Image Acquisition"]}],["$","span","Robustness",{"className":"page__taxonomy-item","children":["#","Robustness"]}],["$","span","CLIP",{"className":"page__taxonomy-item","children":["#","CLIP"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Distribution Shift",{"className":"page__taxonomy-item","children":["#","Distribution Shift"]}]]}]]}]]}],["$","article","2025-8-15-PRELUDE_A_Benchmark_Designed_to_Require_Global_Comprehension_and_Reasoning_over_Long_Contexts",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-15-PRELUDE_A_Benchmark_Designed_to_Require_Global_Comprehension_and_Reasoning_over_Long_Contexts/","children":"[논문리뷰] PRELUDE: A Benchmark Designed to Require Global Comprehension and Reasoning over Long Contexts"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Rui Lu이 [arXiv]에 게시한 'PRELUDE: A Benchmark Designed to Require Global Comprehension and Reasoning over Long Contexts' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-15 13:09:31+0900","children":"2025년 8월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Long-Context Understanding",{"className":"page__taxonomy-item","children":["#","Long-Context Understanding"]}],["$","span","Reasoning Benchmark",{"className":"page__taxonomy-item","children":["#","Reasoning Benchmark"]}],["$","span","LLMs Evaluation",{"className":"page__taxonomy-item","children":["#","LLMs Evaluation"]}],["$","span","Natural Language Processing",{"className":"page__taxonomy-item","children":["#","Natural Language Processing"]}],["$","span","Global Comprehension",{"className":"page__taxonomy-item","children":["#","Global Comprehension"]}],["$","span","Fluid Intelligence",{"className":"page__taxonomy-item","children":["#","Fluid Intelligence"]}],["$","span","Prequel Entailment",{"className":"page__taxonomy-item","children":["#","Prequel Entailment"]}],["$","span","RAG",{"className":"page__taxonomy-item","children":["#","RAG"]}]]}]]}]]}],["$","article","2025-8-15-Passk_Training_for_Adaptively_Balancing_Exploration_and_Exploitation_of_Large_Reasoning_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-15-Passk_Training_for_Adaptively_Balancing_Exploration_and_Exploitation_of_Large_Reasoning_Models/","children":"[논문리뷰] Pass@k Training for Adaptively Balancing Exploration and Exploitation of Large Reasoning Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Qinghao Ye이 [arXiv]에 게시한 'Pass@k Training for Adaptively Balancing Exploration and Exploitation of Large Reasoning Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-15 13:09:31+0900","children":"2025년 8월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Exploration-Exploitation",{"className":"page__taxonomy-item","children":["#","Exploration-Exploitation"]}],["$","span","Reward Design",{"className":"page__taxonomy-item","children":["#","Reward Design"]}],["$","span","Reasoning Tasks",{"className":"page__taxonomy-item","children":["#","Reasoning Tasks"]}],["$","span","Pass@k",{"className":"page__taxonomy-item","children":["#","Pass@k"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}]]}]]}]]}],["$","article","2025-8-15-NextStep-1_Toward_Autoregressive_Image_Generation_with_Continuous_Tokens_at_Scale",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-15-NextStep-1_Toward_Autoregressive_Image_Generation_with_Continuous_Tokens_at_Scale/","children":"[논문리뷰] NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Quan Sun이 [arXiv]에 게시한 'NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-15 13:09:31+0900","children":"2025년 8월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Autoregressive Models",{"className":"page__taxonomy-item","children":["#","Autoregressive Models"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Continuous Latent Tokens",{"className":"page__taxonomy-item","children":["#","Continuous Latent Tokens"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}]]}]]}]]}],["$","article","2025-8-15-HumanSense_From_Multimodal_Perception_to_Empathetic_Context-Aware_Responses_through_Reasoning_MLLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-15-HumanSense_From_Multimodal_Perception_to_Empathetic_Context-Aware_Responses_through_Reasoning_MLLMs/","children":"[논문리뷰] HumanSense: From Multimodal Perception to Empathetic Context-Aware Responses through Reasoning MLLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yi Yuan이 [arXiv]에 게시한 'HumanSense: From Multimodal Perception to Empathetic Context-Aware Responses through Reasoning MLLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-15 13:09:31+0900","children":"2025년 8월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Human-Centered AI",{"className":"page__taxonomy-item","children":["#","Human-Centered AI"]}],["$","span","Empathy",{"className":"page__taxonomy-item","children":["#","Empathy"]}],["$","span","Context-Awareness",{"className":"page__taxonomy-item","children":["#","Context-Awareness"]}],["$","span","MLLM Benchmark",{"className":"page__taxonomy-item","children":["#","MLLM Benchmark"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}]]}]]}]]}],["$","article","2025-8-15-From_Black_Box_to_Transparency_Enhancing_Automated_Interpreting_Assessment_with_Explainable_AI_in_College_Classrooms",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-15-From_Black_Box_to_Transparency_Enhancing_Automated_Interpreting_Assessment_with_Explainable_AI_in_College_Classrooms/","children":"[논문리뷰] From Black Box to Transparency: Enhancing Automated Interpreting Assessment with Explainable AI in College Classrooms"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ziyin Zhang이 [arXiv]에 게시한 'From Black Box to Transparency: Enhancing Automated Interpreting Assessment with Explainable AI in College Classrooms' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-15 13:09:31+0900","children":"2025년 8월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Automated Interpreting Assessment",{"className":"page__taxonomy-item","children":["#","Automated Interpreting Assessment"]}],["$","span","Explainable AI",{"className":"page__taxonomy-item","children":["#","Explainable AI"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}],["$","span","Variational Autoencoder",{"className":"page__taxonomy-item","children":["#","Variational Autoencoder"]}],["$","span","SHAP",{"className":"page__taxonomy-item","children":["#","SHAP"]}],["$","span","Interpreting Quality",{"className":"page__taxonomy-item","children":["#","Interpreting Quality"]}],["$","span","Natural Language Processing",{"className":"page__taxonomy-item","children":["#","Natural Language Processing"]}]]}]]}]]}],["$","article","2025-8-15-A_Survey_on_Diffusion_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-15-A_Survey_on_Diffusion_Language_Models/","children":"[논문리뷰] A Survey on Diffusion Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhiqiang Shen이 [arXiv]에 게시한 'A Survey on Diffusion Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-15 13:09:31+0900","children":"2025년 8월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Language Models",{"className":"page__taxonomy-item","children":["#","Diffusion Language Models"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Parallel Decoding",{"className":"page__taxonomy-item","children":["#","Parallel Decoding"]}],["$","span","Text Generation",{"className":"page__taxonomy-item","children":["#","Text Generation"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Model Compression",{"className":"page__taxonomy-item","children":["#","Model Compression"]}],["$","span","Reinforcement Learning from Human Feedback",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning from Human Feedback"]}],["$","span","Inference Optimization",{"className":"page__taxonomy-item","children":["#","Inference Optimization"]}]]}]]}]]}],["$","article","2025-8-15-2025-8-15-Explainability_and_Privacy_in_NLP",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-15-2025-8-15-Explainability_and_Privacy_in_NLP/","children":"[논문리뷰] When Explainability Meets Privacy: An Investigation at the Intersection of Post-hoc Explainability and Differential Privacy in the Context of Natural Language Processing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Gjergji Kasneci이 [arXiv]에 게시한 'When Explainability Meets Privacy: An Investigation at the Intersection of Post-hoc Explainability and Differential Privacy in the Context of Natural Language Processing' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-15 13:09:31+0900","children":"2025년 8월 15일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Natural Language Processing (NLP)",{"className":"page__taxonomy-item","children":["#","Natural Language Processing (NLP)"]}],["$","span","Explainable AI (XAI)",{"className":"page__taxonomy-item","children":["#","Explainable AI (XAI)"]}],["$","span","Post-hoc Explainability",{"className":"page__taxonomy-item","children":["#","Post-hoc Explainability"]}],["$","span","Differential Privacy (DP)",{"className":"page__taxonomy-item","children":["#","Differential Privacy (DP)"]}],["$","span","Privacy-Utility Trade-off",{"className":"page__taxonomy-item","children":["#","Privacy-Utility Trade-off"]}],["$","span","Model Faithfulness",{"className":"page__taxonomy-item","children":["#","Model Faithfulness"]}],["$","span","Text Privatization",{"className":"page__taxonomy-item","children":["#","Text Privatization"]}]]}]]}]]}],["$","article","2025-8-14-VisCodex_Unified_Multimodal_Code_Generation_via_Merging_Vision_and_Coding_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-VisCodex_Unified_Multimodal_Code_Generation_via_Merging_Vision_and_Coding_Models/","children":"[논문리뷰] VisCodex: Unified Multimodal Code Generation via Merging Vision and Coding Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Dongdong Zhang이 [arXiv]에 게시한 'VisCodex: Unified Multimodal Code Generation via Merging Vision and Coding Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-14 13:19:02+0900","children":"2025년 8월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLM",{"className":"page__taxonomy-item","children":["#","Multimodal LLM"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","Model Merging",{"className":"page__taxonomy-item","children":["#","Model Merging"]}],["$","span","Task Vectors",{"className":"page__taxonomy-item","children":["#","Task Vectors"]}],["$","span","Vision-Language Model",{"className":"page__taxonomy-item","children":["#","Vision-Language Model"]}],["$","span","Coding LLM",{"className":"page__taxonomy-item","children":["#","Coding LLM"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}]]}]]}]]}],["$","article","2025-8-14-Story2Board_A_Training-Free_Approach_for_Expressive_Storyboard_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-Story2Board_A_Training-Free_Approach_for_Expressive_Storyboard_Generation/","children":"[논문리뷰] Story2Board: A Training-Free Approach for Expressive Storyboard Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Dani Lischinski이 [arXiv]에 게시한 'Story2Board: A Training-Free Approach for Expressive Storyboard Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-14 13:19:02+0900","children":"2025년 8월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Storyboard Generation",{"className":"page__taxonomy-item","children":["#","Storyboard Generation"]}],["$","span","Text-to-Image",{"className":"page__taxonomy-item","children":["#","Text-to-Image"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}],["$","span","Character Consistency",{"className":"page__taxonomy-item","children":["#","Character Consistency"]}],["$","span","Scene Diversity",{"className":"page__taxonomy-item","children":["#","Scene Diversity"]}],["$","span","Visual Storytelling",{"className":"page__taxonomy-item","children":["#","Visual Storytelling"]}]]}]]}]]}],["$","article","2025-8-14-Stand-In_A_Lightweight_and_Plug-and-Play_Identity_Control_for_Video_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-Stand-In_A_Lightweight_and_Plug-and-Play_Identity_Control_for_Video_Generation/","children":"[논문리뷰] Stand-In: A Lightweight and Plug-and-Play Identity Control for Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chen Li이 [arXiv]에 게시한 'Stand-In: A Lightweight and Plug-and-Play Identity Control for Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-14 13:19:02+0900","children":"2025년 8월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Identity Preservation",{"className":"page__taxonomy-item","children":["#","Identity Preservation"]}],["$","span","Plug-and-Play",{"className":"page__taxonomy-item","children":["#","Plug-and-Play"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Self-Attention",{"className":"page__taxonomy-item","children":["#","Self-Attention"]}],["$","span","Lightweight AI",{"className":"page__taxonomy-item","children":["#","Lightweight AI"]}],["$","span","Conditional Image Branch",{"className":"page__taxonomy-item","children":["#","Conditional Image Branch"]}]]}]]}]]}],["$","article","2025-8-14-Seeing_Listening_Remembering_and_Reasoning_A_Multimodal_Agent_with_Long-Term_Memory",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-Seeing_Listening_Remembering_and_Reasoning_A_Multimodal_Agent_with_Long-Term_Memory/","children":"[논문리뷰] Seeing, Listening, Remembering, and Reasoning: A Multimodal Agent with Long-Term Memory"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuan Lin이 [arXiv]에 게시한 'Seeing, Listening, Remembering, and Reasoning: A Multimodal Agent with Long-Term Memory' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-14 13:19:02+0900","children":"2025년 8월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Agent",{"className":"page__taxonomy-item","children":["#","Multimodal Agent"]}],["$","span","Long-Term Memory",{"className":"page__taxonomy-item","children":["#","Long-Term Memory"]}],["$","span","Episodic Memory",{"className":"page__taxonomy-item","children":["#","Episodic Memory"]}],["$","span","Semantic Memory",{"className":"page__taxonomy-item","children":["#","Semantic Memory"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Video Question Answering",{"className":"page__taxonomy-item","children":["#","Video Question Answering"]}],["$","span","Entity-Centric Memory",{"className":"page__taxonomy-item","children":["#","Entity-Centric Memory"]}]]}]]}]]}],["$","article","2025-8-14-Noise_Hypernetworks_Amortizing_Test-Time_Compute_in_Diffusion_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-Noise_Hypernetworks_Amortizing_Test-Time_Compute_in_Diffusion_Models/","children":"[논문리뷰] Noise Hypernetworks: Amortizing Test-Time Compute in Diffusion Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zeynep Akata이 [arXiv]에 게시한 'Noise Hypernetworks: Amortizing Test-Time Compute in Diffusion Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-14 13:19:02+0900","children":"2025년 8월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Hypernetworks",{"className":"page__taxonomy-item","children":["#","Hypernetworks"]}],["$","span","Test-Time Optimization",{"className":"page__taxonomy-item","children":["#","Test-Time Optimization"]}],["$","span","Reward-Guided Generation",{"className":"page__taxonomy-item","children":["#","Reward-Guided Generation"]}],["$","span","Latent Space Optimization",{"className":"page__taxonomy-item","children":["#","Latent Space Optimization"]}],["$","span","LoRA",{"className":"page__taxonomy-item","children":["#","LoRA"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}]]}]]}]]}],["$","article","2025-8-14-Mol-R1_Towards_Explicit_Long-CoT_Reasoning_in_Molecule_Discovery",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-Mol-R1_Towards_Explicit_Long-CoT_Reasoning_in_Molecule_Discovery/","children":"[논문리뷰] Mol-R1: Towards Explicit Long-CoT Reasoning in Molecule Discovery"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Di Zhang이 [arXiv]에 게시한 'Mol-R1: Towards Explicit Long-CoT Reasoning in Molecule Discovery' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-14 13:19:02+0900","children":"2025년 8월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Molecule Discovery",{"className":"page__taxonomy-item","children":["#","Molecule Discovery"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Molecular Generation",{"className":"page__taxonomy-item","children":["#","Molecular Generation"]}],["$","span","Explainable AI",{"className":"page__taxonomy-item","children":["#","Explainable AI"]}]]}]]}]]}],["$","article","2025-8-14-MathReal_We_Keep_It_Real_A_Real_Scene_Benchmark_for_Evaluating_Math_Reasoning_in_Multimodal_Large_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-MathReal_We_Keep_It_Real_A_Real_Scene_Benchmark_for_Evaluating_Math_Reasoning_in_Multimodal_Large_Language_Models/","children":"[논문리뷰] MathReal: We Keep It Real! A Real Scene Benchmark for Evaluating Math Reasoning in Multimodal Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhihan Zhou이 [arXiv]에 게시한 'MathReal: We Keep It Real! A Real Scene Benchmark for Evaluating Math Reasoning in Multimodal Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-14 13:19:02+0900","children":"2025년 8월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models (MLLMs)"]}],["$","span","Math Reasoning",{"className":"page__taxonomy-item","children":["#","Math Reasoning"]}],["$","span","Real-World Benchmark",{"className":"page__taxonomy-item","children":["#","Real-World Benchmark"]}],["$","span","Visual Perception",{"className":"page__taxonomy-item","children":["#","Visual Perception"]}],["$","span","Robustness",{"className":"page__taxonomy-item","children":["#","Robustness"]}],["$","span","K-12 Education",{"className":"page__taxonomy-item","children":["#","K-12 Education"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}]]}]]}]]}],["$","article","2025-8-14-Learning_to_Align_Aligning_to_Learn_A_Unified_Approach_for_Self-Optimized_Alignment",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-Learning_to_Align_Aligning_to_Learn_A_Unified_Approach_for_Self-Optimized_Alignment/","children":"[논문리뷰] Learning to Align, Aligning to Learn: A Unified Approach for Self-Optimized Alignment"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Lei Fan이 [arXiv]에 게시한 'Learning to Align, Aligning to Learn: A Unified Approach for Self-Optimized Alignment' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-14 13:19:02+0900","children":"2025년 8월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Alignment",{"className":"page__taxonomy-item","children":["#","LLM Alignment"]}],["$","span","Reinforcement Learning from Human Feedback",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning from Human Feedback"]}],["$","span","Preference Learning",{"className":"page__taxonomy-item","children":["#","Preference Learning"]}],["$","span","Group Relative Alignment Optimization",{"className":"page__taxonomy-item","children":["#","Group Relative Alignment Optimization"]}],["$","span","Self-Optimization",{"className":"page__taxonomy-item","children":["#","Self-Optimization"]}],["$","span","Mixture-of-Experts",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts"]}],["$","span","Imitation Learning",{"className":"page__taxonomy-item","children":["#","Imitation Learning"]}]]}]]}]]}],["$","article","2025-8-14-IAG_Input-aware_Backdoor_Attack_on_VLMs_for_Visual_Grounding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-IAG_Input-aware_Backdoor_Attack_on_VLMs_for_Visual_Grounding/","children":"[논문리뷰] IAG: Input-aware Backdoor Attack on VLMs for Visual Grounding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Di Zhang이 [arXiv]에 게시한 'IAG: Input-aware Backdoor Attack on VLMs for Visual Grounding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-14 13:19:02+0900","children":"2025년 8월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Backdoor Attack",{"className":"page__taxonomy-item","children":["#","Backdoor Attack"]}],["$","span","Vision-Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision-Language Models (VLMs)"]}],["$","span","Visual Grounding",{"className":"page__taxonomy-item","children":["#","Visual Grounding"]}],["$","span","Input-aware Trigger",{"className":"page__taxonomy-item","children":["#","Input-aware Trigger"]}],["$","span","Adversarial Attack",{"className":"page__taxonomy-item","children":["#","Adversarial Attack"]}],["$","span","Security",{"className":"page__taxonomy-item","children":["#","Security"]}],["$","span","U-Net",{"className":"page__taxonomy-item","children":["#","U-Net"]}],["$","span","Open-vocabulary",{"className":"page__taxonomy-item","children":["#","Open-vocabulary"]}]]}]]}]]}],["$","article","2025-8-14-GSFixer_Improving_3D_Gaussian_Splatting_with_Reference-Guided_Video_Diffusion_Priors",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-GSFixer_Improving_3D_Gaussian_Splatting_with_Reference-Guided_Video_Diffusion_Priors/","children":"[논문리뷰] GSFixer: Improving 3D Gaussian Splatting with Reference-Guided Video Diffusion Priors"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Qingnan Fan이 [arXiv]에 게시한 'GSFixer: Improving 3D Gaussian Splatting with Reference-Guided Video Diffusion Priors' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-14 13:19:02+0900","children":"2025년 8월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","3D Gaussian Splatting"]}],["$","span","Novel View Synthesis",{"className":"page__taxonomy-item","children":["#","Novel View Synthesis"]}],["$","span","Diffusion Model",{"className":"page__taxonomy-item","children":["#","Diffusion Model"]}],["$","span","Artifact Restoration",{"className":"page__taxonomy-item","children":["#","Artifact Restoration"]}],["$","span","Sparse-view 3D Reconstruction",{"className":"page__taxonomy-item","children":["#","Sparse-view 3D Reconstruction"]}],["$","span","Reference-Guided",{"className":"page__taxonomy-item","children":["#","Reference-Guided"]}]]}]]}]]}],["$","article","2025-8-14-Echo-4o_Harnessing_the_Power_of_GPT-4o_Synthetic_Images_for_Improved_Image_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-Echo-4o_Harnessing_the_Power_of_GPT-4o_Synthetic_Images_for_Improved_Image_Generation/","children":"[논문리뷰] Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhenghao Hu이 [arXiv]에 게시한 'Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-14 13:19:02+0900","children":"2025년 8월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Synthetic Data",{"className":"page__taxonomy-item","children":["#","Synthetic Data"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","GPT-4o",{"className":"page__taxonomy-item","children":["#","GPT-4o"]}],["$","span","Multimodal Models",{"className":"page__taxonomy-item","children":["#","Multimodal Models"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}],["$","span","Surreal Image Generation",{"className":"page__taxonomy-item","children":["#","Surreal Image Generation"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}]]}]]}]]}],["$","article","2025-8-14-Diffusion_LLMs_Can_Do_Faster-Than-AR_Inference_via_Discrete_Diffusion_Forcing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-Diffusion_LLMs_Can_Do_Faster-Than-AR_Inference_via_Discrete_Diffusion_Forcing/","children":"[논문리뷰] Diffusion LLMs Can Do Faster-Than-AR Inference via Discrete Diffusion Forcing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hao Zhang이 [arXiv]에 게시한 'Diffusion LLMs Can Do Faster-Than-AR Inference via Discrete Diffusion Forcing' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-14 13:19:02+0900","children":"2025년 8월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion LLMs",{"className":"page__taxonomy-item","children":["#","Diffusion LLMs"]}],["$","span","Faster Inference",{"className":"page__taxonomy-item","children":["#","Faster Inference"]}],["$","span","Discrete Diffusion Forcing (D2F)",{"className":"page__taxonomy-item","children":["#","Discrete Diffusion Forcing (D2F)"]}],["$","span","Autoregressive Generation",{"className":"page__taxonomy-item","children":["#","Autoregressive Generation"]}],["$","span","KV Cache Optimization",{"className":"page__taxonomy-item","children":["#","KV Cache Optimization"]}],["$","span","Parallel Decoding",{"className":"page__taxonomy-item","children":["#","Parallel Decoding"]}],["$","span","Text Generation",{"className":"page__taxonomy-item","children":["#","Text Generation"]}],["$","span","Model Distillation",{"className":"page__taxonomy-item","children":["#","Model Distillation"]}]]}]]}]]}],["$","article","2025-8-14-Cooper_Co-Optimizing_Policy_and_Reward_Models_in_Reinforcement_Learning_for_Large_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-Cooper_Co-Optimizing_Policy_and_Reward_Models_in_Reinforcement_Learning_for_Large_Language_Models/","children":"[논문리뷰] Cooper: Co-Optimizing Policy and Reward Models in Reinforcement Learning for Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Guiyang Hou이 [arXiv]에 게시한 'Cooper: Co-Optimizing Policy and Reward Models in Reinforcement Learning for Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-14 13:19:02+0900","children":"2025년 8월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reward Model",{"className":"page__taxonomy-item","children":["#","Reward Model"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Reward Hacking",{"className":"page__taxonomy-item","children":["#","Reward Hacking"]}],["$","span","Hybrid Annotation",{"className":"page__taxonomy-item","children":["#","Hybrid Annotation"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}],["$","span","Verifiable Rewards",{"className":"page__taxonomy-item","children":["#","Verifiable Rewards"]}]]}]]}]]}],["$","article","2025-8-14-Can_LLM-Generated_Textual_Explanations_Enhance_Model_Classification_Performance_An_Empirical_Study",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-Can_LLM-Generated_Textual_Explanations_Enhance_Model_Classification_Performance_An_Empirical_Study/","children":"[논문리뷰] Can LLM-Generated Textual Explanations Enhance Model Classification Performance? An Empirical Study"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Gjergji Kasneci이 [arXiv]에 게시한 'Can LLM-Generated Textual Explanations Enhance Model Classification Performance? An Empirical Study' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-14 13:19:02+0900","children":"2025년 8월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Explainable NLP",{"className":"page__taxonomy-item","children":["#","Explainable NLP"]}],["$","span","Natural Language Explanations",{"className":"page__taxonomy-item","children":["#","Natural Language Explanations"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Pre-trained Language Models",{"className":"page__taxonomy-item","children":["#","Pre-trained Language Models"]}],["$","span","Natural Language Inference",{"className":"page__taxonomy-item","children":["#","Natural Language Inference"]}],["$","span","Model Performance Enhancement",{"className":"page__taxonomy-item","children":["#","Model Performance Enhancement"]}],["$","span","Text Generation",{"className":"page__taxonomy-item","children":["#","Text Generation"]}]]}]]}]]}],["$","article","2025-8-14-AWorld_Dynamic_Multi-Agent_System_with_Stable_Maneuvering_for_Robust_GAIA_Problem_Solving",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-AWorld_Dynamic_Multi-Agent_System_with_Stable_Maneuvering_for_Robust_GAIA_Problem_Solving/","children":"[논문리뷰] AWorld: Dynamic Multi-Agent System with Stable Maneuvering for Robust GAIA Problem Solving"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jinjie Gu이 [arXiv]에 게시한 'AWorld: Dynamic Multi-Agent System with Stable Maneuvering for Robust GAIA Problem Solving' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-14 13:19:02+0900","children":"2025년 8월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-Agent System",{"className":"page__taxonomy-item","children":["#","Multi-Agent System"]}],["$","span","Agent Stability",{"className":"page__taxonomy-item","children":["#","Agent Stability"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","GAIA Benchmark",{"className":"page__taxonomy-item","children":["#","GAIA Benchmark"]}],["$","span","Robustness",{"className":"page__taxonomy-item","children":["#","Robustness"]}],["$","span","Dynamic Supervision",{"className":"page__taxonomy-item","children":["#","Dynamic Supervision"]}],["$","span","Maneuvering",{"className":"page__taxonomy-item","children":["#","Maneuvering"]}]]}]]}]]}],["$","article","2025-8-14-AMFT_Aligning_LLM_Reasoners_by_Meta-Learning_the_Optimal_Imitation-Exploration_Balance",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-14-AMFT_Aligning_LLM_Reasoners_by_Meta-Learning_the_Optimal_Imitation-Exploration_Balance/","children":"[논문리뷰] AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yong Li이 [arXiv]에 게시한 'AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-14 13:19:02+0900","children":"2025년 8월 14일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Meta-learning",{"className":"page__taxonomy-item","children":["#","Meta-learning"]}],["$","span","Adaptive Control",{"className":"page__taxonomy-item","children":["#","Adaptive Control"]}],["$","span","Imitation Learning",{"className":"page__taxonomy-item","children":["#","Imitation Learning"]}],["$","span","Exploration",{"className":"page__taxonomy-item","children":["#","Exploration"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}]]}]]}]]}],["$","article","2025-8-13-WGAST_Weakly-Supervised_Generative_Network_for_Daily_10_m_Land_Surface_Temperature_Estimation_via_Spatio-Temporal_Fusion",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-WGAST_Weakly-Supervised_Generative_Network_for_Daily_10_m_Land_Surface_Temperature_Estimation_via_Spatio-Temporal_Fusion/","children":"[논문리뷰] WGAST: Weakly-Supervised Generative Network for Daily 10 m Land Surface Temperature Estimation via Spatio-Temporal Fusion"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Rachid Nedjai이 [arXiv]에 게시한 'WGAST: Weakly-Supervised Generative Network for Daily 10 m Land Surface Temperature Estimation via Spatio-Temporal Fusion' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Spatio-Temporal Fusion",{"className":"page__taxonomy-item","children":["#","Spatio-Temporal Fusion"]}],["$","span","Land Surface Temperature",{"className":"page__taxonomy-item","children":["#","Land Surface Temperature"]}],["$","span","Generative Adversarial Network",{"className":"page__taxonomy-item","children":["#","Generative Adversarial Network"]}],["$","span","Weakly-Supervised Learning",{"className":"page__taxonomy-item","children":["#","Weakly-Supervised Learning"]}],["$","span","Remote Sensing",{"className":"page__taxonomy-item","children":["#","Remote Sensing"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}]]}]]}]]}],["$","article","2025-8-13-VertexRegen_Mesh_Generation_with_Continuous_Level_of_Detail",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-VertexRegen_Mesh_Generation_with_Continuous_Level_of_Detail/","children":"[논문리뷰] VertexRegen: Mesh Generation with Continuous Level of Detail"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jakob Engel이 [arXiv]에 게시한 'VertexRegen: Mesh Generation with Continuous Level of Detail' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Mesh Generation",{"className":"page__taxonomy-item","children":["#","Mesh Generation"]}],["$","span","Level of Detail (LOD)",{"className":"page__taxonomy-item","children":["#","Level of Detail (LOD)"]}],["$","span","Progressive Meshes",{"className":"page__taxonomy-item","children":["#","Progressive Meshes"]}],["$","span","Vertex Split",{"className":"page__taxonomy-item","children":["#","Vertex Split"]}],["$","span","Autoregressive Models",{"className":"page__taxonomy-item","children":["#","Autoregressive Models"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","3D Graphics",{"className":"page__taxonomy-item","children":["#","3D Graphics"]}]]}]]}]]}],["$","article","2025-8-13-UNCAGE_Contrastive_Attention_Guidance_for_Masked_Generative_Transformers_in_Text-to-Image_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-UNCAGE_Contrastive_Attention_Guidance_for_Masked_Generative_Transformers_in_Text-to-Image_Generation/","children":"[논문리뷰] UNCAGE: Contrastive Attention Guidance for Masked Generative Transformers in Text-to-Image Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kevin Galim이 [arXiv]에 게시한 'UNCAGE: Contrastive Attention Guidance for Masked Generative Transformers in Text-to-Image Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Masked Generative Transformers",{"className":"page__taxonomy-item","children":["#","Masked Generative Transformers"]}],["$","span","Compositional Generation",{"className":"page__taxonomy-item","children":["#","Compositional Generation"]}],["$","span","Attention Guidance",{"className":"page__taxonomy-item","children":["#","Attention Guidance"]}],["$","span","Unmasking Strategy",{"className":"page__taxonomy-item","children":["#","Unmasking Strategy"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}],["$","span","Attribute Binding",{"className":"page__taxonomy-item","children":["#","Attribute Binding"]}]]}]]}]]}],["$","article","2025-8-13-Train_Long_Think_Short_Curriculum_Learning_for_Efficient_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-Train_Long_Think_Short_Curriculum_Learning_for_Efficient_Reasoning/","children":"[논문리뷰] Train Long, Think Short: Curriculum Learning for Efficient Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Marzyeh Ghassemi이 [arXiv]에 게시한 'Train Long, Think Short: Curriculum Learning for Efficient Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reasoning Efficiency",{"className":"page__taxonomy-item","children":["#","Reasoning Efficiency"]}],["$","span","Token Budget Control",{"className":"page__taxonomy-item","children":["#","Token Budget Control"]}],["$","span","Group Relative Policy Optimization",{"className":"page__taxonomy-item","children":["#","Group Relative Policy Optimization"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}]]}]]}]]}],["$","article","2025-8-13-Towards_Affordance-Aware_Robotic_Dexterous_Grasping_with_Human-like_Priors",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-Towards_Affordance-Aware_Robotic_Dexterous_Grasping_with_Human-like_Priors/","children":"[논문리뷰] Towards Affordance-Aware Robotic Dexterous Grasping with Human-like Priors"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Haoran Xu이 [arXiv]에 게시한 'Towards Affordance-Aware Robotic Dexterous Grasping with Human-like Priors' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Robotic Dexterous Grasping",{"className":"page__taxonomy-item","children":["#","Robotic Dexterous Grasping"]}],["$","span","Affordance-Aware",{"className":"page__taxonomy-item","children":["#","Affordance-Aware"]}],["$","span","Human-like Priors",{"className":"page__taxonomy-item","children":["#","Human-like Priors"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Two-Stage Training",{"className":"page__taxonomy-item","children":["#","Two-Stage Training"]}],["$","span","Manipulation",{"className":"page__taxonomy-item","children":["#","Manipulation"]}]]}]]}]]}],["$","article","2025-8-13-TopXGen_Topic-Diverse_Parallel_Data_Generation_for_Low-Resource_Machine_Translation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-TopXGen_Topic-Diverse_Parallel_Data_Generation_for_Low-Resource_Machine_Translation/","children":"[논문리뷰] TopXGen: Topic-Diverse Parallel Data Generation for Low-Resource Machine Translation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Rachel Bawden이 [arXiv]에 게시한 'TopXGen: Topic-Diverse Parallel Data Generation for Low-Resource Machine Translation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Low-Resource MT",{"className":"page__taxonomy-item","children":["#","Low-Resource MT"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Back-Translation",{"className":"page__taxonomy-item","children":["#","Back-Translation"]}],["$","span","In-Context Learning (ICL)",{"className":"page__taxonomy-item","children":["#","In-Context Learning (ICL)"]}],["$","span","Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Fine-Tuning"]}],["$","span","Topic-Guided Generation",{"className":"page__taxonomy-item","children":["#","Topic-Guided Generation"]}],["$","span","Parallel Data Synthesis",{"className":"page__taxonomy-item","children":["#","Parallel Data Synthesis"]}]]}]]}]]}],["$","article","2025-8-13-Time_Is_a_Feature_Exploiting_Temporal_Dynamics_in_Diffusion_Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-Time_Is_a_Feature_Exploiting_Temporal_Dynamics_in_Diffusion_Language_Models/","children":"[논문리뷰] Time Is a Feature: Exploiting Temporal Dynamics in Diffusion Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chenchen Jing이 [arXiv]에 게시한 'Time Is a Feature: Exploiting Temporal Dynamics in Diffusion Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Language Models",{"className":"page__taxonomy-item","children":["#","Diffusion Language Models"]}],["$","span","Temporal Oscillation",{"className":"page__taxonomy-item","children":["#","Temporal Oscillation"]}],["$","span","Self-Consistency Voting",{"className":"page__taxonomy-item","children":["#","Self-Consistency Voting"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Temporal Semantic Entropy",{"className":"page__taxonomy-item","children":["#","Temporal Semantic Entropy"]}],["$","span","Text Generation",{"className":"page__taxonomy-item","children":["#","Text Generation"]}]]}]]}]]}],["$","article","2025-8-13-Test-Time_Reinforcement_Learning_for_GUI_Grounding_via_Region_Consistency",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-Test-Time_Reinforcement_Learning_for_GUI_Grounding_via_Region_Consistency/","children":"[논문리뷰] Test-Time Reinforcement Learning for GUI Grounding via Region Consistency"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhengxi Lu이 [arXiv]에 게시한 'Test-Time Reinforcement Learning for GUI Grounding via Region Consistency' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","GUI Grounding",{"className":"page__taxonomy-item","children":["#","GUI Grounding"]}],["$","span","Test-Time Scaling",{"className":"page__taxonomy-item","children":["#","Test-Time Scaling"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Region Consistency",{"className":"page__taxonomy-item","children":["#","Region Consistency"]}],["$","span","Spatial Voting",{"className":"page__taxonomy-item","children":["#","Spatial Voting"]}],["$","span","Self-Supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-Supervised Learning"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}]]}]]}]]}],["$","article","2025-8-13-OpenCUA_Open_Foundations_for_Computer-Use_Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-OpenCUA_Open_Foundations_for_Computer-Use_Agents/","children":"[논문리뷰] OpenCUA: Open Foundations for Computer-Use Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Tianbao Xie이 [arXiv]에 게시한 'OpenCUA: Open Foundations for Computer-Use Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Computer-Use Agents",{"className":"page__taxonomy-item","children":["#","Computer-Use Agents"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Chain-of-Thought Reasoning",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought Reasoning"]}],["$","span","Large-scale Dataset",{"className":"page__taxonomy-item","children":["#","Large-scale Dataset"]}],["$","span","Open-source Framework",{"className":"page__taxonomy-item","children":["#","Open-source Framework"]}],["$","span","Desktop Automation",{"className":"page__taxonomy-item","children":["#","Desktop Automation"]}],["$","span","Agent Evaluation",{"className":"page__taxonomy-item","children":["#","Agent Evaluation"]}]]}]]}]]}],["$","article","2025-8-13-NVSpeech_An_Integrated_and_Scalable_Pipeline_for_Human-Like_Speech_Modeling_with_Paralinguistic_Vocalizations",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-NVSpeech_An_Integrated_and_Scalable_Pipeline_for_Human-Like_Speech_Modeling_with_Paralinguistic_Vocalizations/","children":"[논문리뷰] NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Haoyue Zhan이 [arXiv]에 게시한 'NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Paralinguistic Vocalizations",{"className":"page__taxonomy-item","children":["#","Paralinguistic Vocalizations"]}],["$","span","Speech Recognition",{"className":"page__taxonomy-item","children":["#","Speech Recognition"]}],["$","span","Text-to-Speech",{"className":"page__taxonomy-item","children":["#","Text-to-Speech"]}],["$","span","Speech Synthesis",{"className":"page__taxonomy-item","children":["#","Speech Synthesis"]}],["$","span","Data Annotation",{"className":"page__taxonomy-item","children":["#","Data Annotation"]}],["$","span","Mandarin Speech",{"className":"page__taxonomy-item","children":["#","Mandarin Speech"]}],["$","span","Expressive Speech",{"className":"page__taxonomy-item","children":["#","Expressive Speech"]}]]}]]}]]}],["$","article","2025-8-13-Matrix-3D_Omnidirectional_Explorable_3D_World_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-Matrix-3D_Omnidirectional_Explorable_3D_World_Generation/","children":"[논문리뷰] Matrix-3D: Omnidirectional Explorable 3D World Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuqi Li이 [arXiv]에 게시한 'Matrix-3D: Omnidirectional Explorable 3D World Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D World Generation",{"className":"page__taxonomy-item","children":["#","3D World Generation"]}],["$","span","Panoramic Video Generation",{"className":"page__taxonomy-item","children":["#","Panoramic Video Generation"]}],["$","span","3D Reconstruction",{"className":"page__taxonomy-item","children":["#","3D Reconstruction"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","Gaussian Splatting"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}],["$","span","Camera Control",{"className":"page__taxonomy-item","children":["#","Camera Control"]}]]}]]}]]}],["$","article","2025-8-13-HierSearch_A_Hierarchical_Enterprise_Deep_Search_Framework_Integrating_Local_and_Web_Searches",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-HierSearch_A_Hierarchical_Enterprise_Deep_Search_Framework_Integrating_Local_and_Web_Searches/","children":"[논문리뷰] HierSearch: A Hierarchical Enterprise Deep Search Framework Integrating Local and Web Searches"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Qiang Ju이 [arXiv]에 게시한 'HierSearch: A Hierarchical Enterprise Deep Search Framework Integrating Local and Web Searches' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Hierarchical Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Hierarchical Reinforcement Learning"]}],["$","span","Deep Search",{"className":"page__taxonomy-item","children":["#","Deep Search"]}],["$","span","Multi-source RAG",{"className":"page__taxonomy-item","children":["#","Multi-source RAG"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Knowledge Integration",{"className":"page__taxonomy-item","children":["#","Knowledge Integration"]}],["$","span","Enterprise Search",{"className":"page__taxonomy-item","children":["#","Enterprise Search"]}],["$","span","Large Reasoning Models",{"className":"page__taxonomy-item","children":["#","Large Reasoning Models"]}]]}]]}]]}],["$","article","2025-8-13-GeRe_Towards_Efficient_Anti-Forgetting_in_Continual_Learning_of_LLM_via_General_Samples_Replay",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-GeRe_Towards_Efficient_Anti-Forgetting_in_Continual_Learning_of_LLM_via_General_Samples_Replay/","children":"[논문리뷰] GeRe: Towards Efficient Anti-Forgetting in Continual Learning of LLM via General Samples Replay"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yang Fan이 [arXiv]에 게시한 'GeRe: Towards Efficient Anti-Forgetting in Continual Learning of LLM via General Samples Replay' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Continual Learning",{"className":"page__taxonomy-item","children":["#","Continual Learning"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Catastrophic Forgetting",{"className":"page__taxonomy-item","children":["#","Catastrophic Forgetting"]}],["$","span","Replay",{"className":"page__taxonomy-item","children":["#","Replay"]}],["$","span","Knowledge Distillation",{"className":"page__taxonomy-item","children":["#","Knowledge Distillation"]}],["$","span","Activation States",{"className":"page__taxonomy-item","children":["#","Activation States"]}],["$","span","Anti-forgetting",{"className":"page__taxonomy-item","children":["#","Anti-forgetting"]}],["$","span","Threshold-based Margin Loss",{"className":"page__taxonomy-item","children":["#","Threshold-based Margin Loss"]}]]}]]}]]}],["$","article","2025-8-13-Feedback-Driven_Tool-Use_Improvements_in_Large_Language_Models_via_Automated_Build_Environments",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-Feedback-Driven_Tool-Use_Improvements_in_Large_Language_Models_via_Automated_Build_Environments/","children":"[논문리뷰] Feedback-Driven Tool-Use Improvements in Large Language Models via Automated Build Environments"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xuesong Yao이 [arXiv]에 게시한 'Feedback-Driven Tool-Use Improvements in Large Language Models via Automated Build Environments' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Automated Environment Generation",{"className":"page__taxonomy-item","children":["#","Automated Environment Generation"]}],["$","span","Feedback-Driven Training",{"className":"page__taxonomy-item","children":["#","Feedback-Driven Training"]}],["$","span","Reward Mechanism",{"className":"page__taxonomy-item","children":["#","Reward Mechanism"]}],["$","span","Contextual Understanding",{"className":"page__taxonomy-item","children":["#","Contextual Understanding"]}]]}]]}]]}],["$","article","2025-8-13-Democratizing_Diplomacy_A_Harness_for_Evaluating_Any_Large_Language_Model_on_Full-Press_Diplomacy",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-Democratizing_Diplomacy_A_Harness_for_Evaluating_Any_Large_Language_Model_on_Full-Press_Diplomacy/","children":"[논문리뷰] Democratizing Diplomacy: A Harness for Evaluating Any Large Language Model on Full-Press Diplomacy"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Elizabeth Karpinski이 [arXiv]에 게시한 'Democratizing Diplomacy: A Harness for Evaluating Any Large Language Model on Full-Press Diplomacy' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Diplomacy Game",{"className":"page__taxonomy-item","children":["#","Diplomacy Game"]}],["$","span","Multi-agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-agent Systems"]}],["$","span","Strategic Reasoning",{"className":"page__taxonomy-item","children":["#","Strategic Reasoning"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","Behavioral Analysis",{"className":"page__taxonomy-item","children":["#","Behavioral Analysis"]}],["$","span","Game AI",{"className":"page__taxonomy-item","children":["#","Game AI"]}]]}]]}]]}],["$","article","2025-8-13-DeCRED_Decoder-Centric_Regularization_for_Encoder-Decoder_Based_Speech_Recognition",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-DeCRED_Decoder-Centric_Regularization_for_Encoder-Decoder_Based_Speech_Recognition/","children":"[논문리뷰] DeCRED: Decoder-Centric Regularization for Encoder-Decoder Based Speech Recognition"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Lukáš Burget이 [arXiv]에 게시한 'DeCRED: Decoder-Centric Regularization for Encoder-Decoder Based Speech Recognition' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Speech Recognition",{"className":"page__taxonomy-item","children":["#","Speech Recognition"]}],["$","span","Encoder-Decoder",{"className":"page__taxonomy-item","children":["#","Encoder-Decoder"]}],["$","span","Regularization",{"className":"page__taxonomy-item","children":["#","Regularization"]}],["$","span","Decoder-Centric",{"className":"page__taxonomy-item","children":["#","Decoder-Centric"]}],["$","span","Intermediate Supervision",{"className":"page__taxonomy-item","children":["#","Intermediate Supervision"]}],["$","span","Out-of-Domain Generalization",{"className":"page__taxonomy-item","children":["#","Out-of-Domain Generalization"]}],["$","span","Internal Language Model",{"className":"page__taxonomy-item","children":["#","Internal Language Model"]}]]}]]}]]}],["$","article","2025-8-13-Cut2Next_Generating_Next_Shot_via_In-Context_Tuning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-Cut2Next_Generating_Next_Shot_via_In-Context_Tuning/","children":"[논문리뷰] Cut2Next: Generating Next Shot via In-Context Tuning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yu Qiao이 [arXiv]에 게시한 'Cut2Next: Generating Next Shot via In-Context Tuning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Next Shot Generation",{"className":"page__taxonomy-item","children":["#","Next Shot Generation"]}],["$","span","In-Context Tuning",{"className":"page__taxonomy-item","children":["#","In-Context Tuning"]}],["$","span","Diffusion Transformer",{"className":"page__taxonomy-item","children":["#","Diffusion Transformer"]}],["$","span","Cinematic Continuity",{"className":"page__taxonomy-item","children":["#","Cinematic Continuity"]}],["$","span","Hierarchical Prompting",{"className":"page__taxonomy-item","children":["#","Hierarchical Prompting"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Shot Editing",{"className":"page__taxonomy-item","children":["#","Shot Editing"]}]]}]]}]]}],["$","article","2025-8-13-CharacterShot_Controllable_and_Consistent_4D_Character_Animation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-CharacterShot_Controllable_and_Consistent_4D_Character_Animation/","children":"[논문리뷰] CharacterShot: Controllable and Consistent 4D Character Animation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Fei Shen이 [arXiv]에 게시한 'CharacterShot: Controllable and Consistent 4D Character Animation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","4D Character Animation",{"className":"page__taxonomy-item","children":["#","4D Character Animation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","Gaussian Splatting"]}],["$","span","Pose Control",{"className":"page__taxonomy-item","children":["#","Pose Control"]}],["$","span","Multi-view Synthesis",{"className":"page__taxonomy-item","children":["#","Multi-view Synthesis"]}],["$","span","Temporal Consistency",{"className":"page__taxonomy-item","children":["#","Temporal Consistency"]}],["$","span","Character Dataset",{"className":"page__taxonomy-item","children":["#","Character Dataset"]}]]}]]}]]}],["$","article","2025-8-13-Bridging_Theory_and_Practice_in_Quantum_Game_Theory_Optimized_Implementation_of_the_Battle_of_the_Sexes_with_Error_Mitigation_on_NISQ_Hardware",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-Bridging_Theory_and_Practice_in_Quantum_Game_Theory_Optimized_Implementation_of_the_Battle_of_the_Sexes_with_Error_Mitigation_on_NISQ_Hardware/","children":"[논문리뷰] Bridging Theory and Practice in Quantum Game Theory: Optimized Implementation of the Battle of the Sexes with Error Mitigation on NISQ Hardware"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jhon Alejandro Andrade이 [arXiv]에 게시한 'Bridging Theory and Practice in Quantum Game Theory: Optimized Implementation of the Battle of the Sexes with Error Mitigation on NISQ Hardware' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Quantum Game Theory",{"className":"page__taxonomy-item","children":["#","Quantum Game Theory"]}],["$","span","NISQ Hardware",{"className":"page__taxonomy-item","children":["#","NISQ Hardware"]}],["$","span","Error Mitigation",{"className":"page__taxonomy-item","children":["#","Error Mitigation"]}],["$","span","Battle of the Sexes",{"className":"page__taxonomy-item","children":["#","Battle of the Sexes"]}],["$","span","Qiskit",{"className":"page__taxonomy-item","children":["#","Qiskit"]}],["$","span","Quantum Computing",{"className":"page__taxonomy-item","children":["#","Quantum Computing"]}],["$","span","Strategic Coordination",{"className":"page__taxonomy-item","children":["#","Strategic Coordination"]}],["$","span","Payoff Maximization",{"className":"page__taxonomy-item","children":["#","Payoff Maximization"]}]]}]]}]]}],["$","article","2025-8-13-BiasGym_Fantastic_Biases_and_How_to_Find_and_Remove_Them",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-BiasGym_Fantastic_Biases_and_How_to_Find_and_Remove_Them/","children":"[논문리뷰] BiasGym: Fantastic Biases and How to Find (and Remove) Them"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Arnav Arora이 [arXiv]에 게시한 'BiasGym: Fantastic Biases and How to Find (and Remove) Them' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Bias Mitigation",{"className":"page__taxonomy-item","children":["#","Bias Mitigation"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Mechanistic Interpretability",{"className":"page__taxonomy-item","children":["#","Mechanistic Interpretability"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Attention Steering",{"className":"page__taxonomy-item","children":["#","Attention Steering"]}],["$","span","Stereotype Analysis",{"className":"page__taxonomy-item","children":["#","Stereotype Analysis"]}],["$","span","Safety Alignment",{"className":"page__taxonomy-item","children":["#","Safety Alignment"]}]]}]]}]]}],["$","article","2025-8-13-Beyond_Ten_Turns_Unlocking_Long-Horizon_Agentic_Search_with_Large-Scale_Asynchronous_RL",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-Beyond_Ten_Turns_Unlocking_Long-Horizon_Agentic_Search_with_Large-Scale_Asynchronous_RL/","children":"[논문리뷰] Beyond Ten Turns: Unlocking Long-Horizon Agentic Search with Large-Scale Asynchronous RL"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chuyi He이 [arXiv]에 게시한 'Beyond Ten Turns: Unlocking Long-Horizon Agentic Search with Large-Scale Asynchronous RL' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Agentic Search",{"className":"page__taxonomy-item","children":["#","Agentic Search"]}],["$","span","Asynchronous RL",{"className":"page__taxonomy-item","children":["#","Asynchronous RL"]}],["$","span","Long-Horizon Planning",{"className":"page__taxonomy-item","children":["#","Long-Horizon Planning"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Data Synthesis",{"className":"page__taxonomy-item","children":["#","Data Synthesis"]}]]}]]}]]}],["$","article","2025-8-13-AutoCodeBench_Large_Language_Models_are_Automatic_Code_Benchmark_Generators",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-AutoCodeBench_Large_Language_Models_are_Automatic_Code_Benchmark_Generators/","children":"[논문리뷰] AutoCodeBench: Large Language Models are Automatic Code Benchmark Generators"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Tao Zhang이 [arXiv]에 게시한 'AutoCodeBench: Large Language Models are Automatic Code Benchmark Generators' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","코드 생성",{"className":"page__taxonomy-item","children":["#","코드 생성"]}],["$","span","대규모 언어 모델",{"className":"page__taxonomy-item","children":["#","대규모 언어 모델"]}],["$","span","코드 벤치마크",{"className":"page__taxonomy-item","children":["#","코드 벤치마크"]}],["$","span","다국어 프로그래밍",{"className":"page__taxonomy-item","children":["#","다국어 프로그래밍"]}],["$","span","자동화된 데이터 생성",{"className":"page__taxonomy-item","children":["#","자동화된 데이터 생성"]}],["$","span","샌드박스 평가",{"className":"page__taxonomy-item","children":["#","샌드박스 평가"]}],["$","span","멀티모달 AI",{"className":"page__taxonomy-item","children":["#","멀티모달 AI"]}]]}]]}]]}],["$","article","2025-8-13-Aryabhata_An_exam-focused_language_model_for_JEE_Math",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-Aryabhata_An_exam-focused_language_model_for_JEE_Math/","children":"[논문리뷰] Aryabhata: An exam-focused language model for JEE Math"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Sandeep Varma이 [arXiv]에 게시한 'Aryabhata: An exam-focused language model for JEE Math' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Language Model",{"className":"page__taxonomy-item","children":["#","Language Model"]}],["$","span","Math Reasoning",{"className":"page__taxonomy-item","children":["#","Math Reasoning"]}],["$","span","JEE",{"className":"page__taxonomy-item","children":["#","JEE"]}],["$","span","Supervised Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Model Merging",{"className":"page__taxonomy-item","children":["#","Model Merging"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}]]}]]}]]}],["$","article","2025-8-13-Adversarial_Video_Promotion_Against_Text-to-Video_Retrieval",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-13-Adversarial_Video_Promotion_Against_Text-to-Video_Retrieval/","children":"[논문리뷰] Adversarial Video Promotion Against Text-to-Video Retrieval"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shuai Liu이 [arXiv]에 게시한 'Adversarial Video Promotion Against Text-to-Video Retrieval' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-13 13:29:23+0900","children":"2025년 8월 13일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Adversarial Attack",{"className":"page__taxonomy-item","children":["#","Adversarial Attack"]}],["$","span","Video Promotion",{"className":"page__taxonomy-item","children":["#","Video Promotion"]}],["$","span","Text-to-Video Retrieval",{"className":"page__taxonomy-item","children":["#","Text-to-Video Retrieval"]}],["$","span","Modality Refinement",{"className":"page__taxonomy-item","children":["#","Modality Refinement"]}],["$","span","Black-box Attack",{"className":"page__taxonomy-item","children":["#","Black-box Attack"]}],["$","span","Video Manipulation",{"className":"page__taxonomy-item","children":["#","Video Manipulation"]}],["$","span","Transferability",{"className":"page__taxonomy-item","children":["#","Transferability"]}]]}]]}]]}],["$","article","2025-8-12-WideSearch_Benchmarking_Agentic_Broad_Info-Seeking",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-WideSearch_Benchmarking_Agentic_Broad_Info-Seeking/","children":"[논문리뷰] WideSearch: Benchmarking Agentic Broad Info-Seeking"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yan Gao이 [arXiv]에 게시한 'WideSearch: Benchmarking Agentic Broad Info-Seeking' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Agentic Search",{"className":"page__taxonomy-item","children":["#","Agentic Search"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Information Seeking",{"className":"page__taxonomy-item","children":["#","Information Seeking"]}],["$","span","Structured Output",{"className":"page__taxonomy-item","children":["#","Structured Output"]}],["$","span","Evaluation Metrics",{"className":"page__taxonomy-item","children":["#","Evaluation Metrics"]}],["$","span","Multi-agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-agent Systems"]}]]}]]}]]}],["$","article","2025-8-12-When_Good_Sounds_Go_Adversarial_Jailbreaking_Audio-Language_Models_with_Benign_Inputs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-When_Good_Sounds_Go_Adversarial_Jailbreaking_Audio-Language_Models_with_Benign_Inputs/","children":"[논문리뷰] When Good Sounds Go Adversarial: Jailbreaking Audio-Language Models with Benign Inputs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Dasol Choi이 [arXiv]에 게시한 'When Good Sounds Go Adversarial: Jailbreaking Audio-Language Models with Benign Inputs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Audio-Language Models",{"className":"page__taxonomy-item","children":["#","Audio-Language Models"]}],["$","span","Jailbreak Attack",{"className":"page__taxonomy-item","children":["#","Jailbreak Attack"]}],["$","span","Adversarial Audio",{"className":"page__taxonomy-item","children":["#","Adversarial Audio"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Projected Gradient Descent",{"className":"page__taxonomy-item","children":["#","Projected Gradient Descent"]}],["$","span","Native Payload Discovery",{"className":"page__taxonomy-item","children":["#","Native Payload Discovery"]}],["$","span","Multimodal AI Safety",{"className":"page__taxonomy-item","children":["#","Multimodal AI Safety"]}]]}]]}]]}],["$","article","2025-8-12-VisR-Bench_An_Empirical_Study_on_Visual_Retrieval-Augmented_Generation_for_Multilingual_Long_Document_Understanding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-VisR-Bench_An_Empirical_Study_on_Visual_Retrieval-Augmented_Generation_for_Multilingual_Long_Document_Understanding/","children":"[논문리뷰] VisR-Bench: An Empirical Study on Visual Retrieval-Augmented Generation for Multilingual Long Document Understanding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Tong Yu이 [arXiv]에 게시한 'VisR-Bench: An Empirical Study on Visual Retrieval-Augmented Generation for Multilingual Long Document Understanding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Retrieval",{"className":"page__taxonomy-item","children":["#","Multimodal Retrieval"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","Long Document Understanding",{"className":"page__taxonomy-item","children":["#","Long Document Understanding"]}],["$","span","Multilingual NLP",{"className":"page__taxonomy-item","children":["#","Multilingual NLP"]}],["$","span","Visual QA",{"className":"page__taxonomy-item","children":["#","Visual QA"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","MLLMs",{"className":"page__taxonomy-item","children":["#","MLLMs"]}],["$","span","Table Understanding",{"className":"page__taxonomy-item","children":["#","Table Understanding"]}]]}]]}]]}],["$","article","2025-8-12-UserBench_An_Interactive_Gym_Environment_for_User-Centric_Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-UserBench_An_Interactive_Gym_Environment_for_User-Centric_Agents/","children":"[논문리뷰] UserBench: An Interactive Gym Environment for User-Centric Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jianguo Zhang이 [arXiv]에 게시한 'UserBench: An Interactive Gym Environment for User-Centric Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","User-Centric AI",{"className":"page__taxonomy-item","children":["#","User-Centric AI"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Interactive Agents",{"className":"page__taxonomy-item","children":["#","Interactive Agents"]}],["$","span","Gym Environment",{"className":"page__taxonomy-item","children":["#","Gym Environment"]}],["$","span","Preference Elicitation",{"className":"page__taxonomy-item","children":["#","Preference Elicitation"]}],["$","span","Multi-turn Dialogue",{"className":"page__taxonomy-item","children":["#","Multi-turn Dialogue"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}]]}]]}]]}],["$","article","2025-8-12-Temporal_Self-Rewarding_Language_Models_Decoupling_Chosen-Rejected_via_Past-Future",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-Temporal_Self-Rewarding_Language_Models_Decoupling_Chosen-Rejected_via_Past-Future/","children":"[논문리뷰] Temporal Self-Rewarding Language Models: Decoupling Chosen-Rejected via Past-Future"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Qiufeng Wang이 [arXiv]에 게시한 'Temporal Self-Rewarding Language Models: Decoupling Chosen-Rejected via Past-Future' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Self-Rewarding LLMs",{"className":"page__taxonomy-item","children":["#","Self-Rewarding LLMs"]}],["$","span","Direct Preference Optimization (DPO)",{"className":"page__taxonomy-item","children":["#","Direct Preference Optimization (DPO)"]}],["$","span","Preference Learning",{"className":"page__taxonomy-item","children":["#","Preference Learning"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Gradient Collapse",{"className":"page__taxonomy-item","children":["#","Gradient Collapse"]}],["$","span","LLM Alignment",{"className":"page__taxonomy-item","children":["#","LLM Alignment"]}],["$","span","Iterative Optimization",{"className":"page__taxonomy-item","children":["#","Iterative Optimization"]}]]}]]}]]}],["$","article","2025-8-12-Speech-to-LaTeX_New_Models_and_Datasets_for_Converting_Spoken_Equations_and_Sentences",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-Speech-to-LaTeX_New_Models_and_Datasets_for_Converting_Spoken_Equations_and_Sentences/","children":"[논문리뷰] Speech-to-LaTeX: New Models and Datasets for Converting Spoken Equations and Sentences"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Matvey Skripkin이 [arXiv]에 게시한 'Speech-to-LaTeX: New Models and Datasets for Converting Spoken Equations and Sentences' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Speech-to-LaTeX",{"className":"page__taxonomy-item","children":["#","Speech-to-LaTeX"]}],["$","span","ASR",{"className":"page__taxonomy-item","children":["#","ASR"]}],["$","span","Language Models",{"className":"page__taxonomy-item","children":["#","Language Models"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Dataset Creation",{"className":"page__taxonomy-item","children":["#","Dataset Creation"]}],["$","span","Mathematical Expression Recognition",{"className":"page__taxonomy-item","children":["#","Mathematical Expression Recognition"]}],["$","span","LaTeX Generation",{"className":"page__taxonomy-item","children":["#","LaTeX Generation"]}]]}]]}]]}],["$","article","2025-8-12-Shortcut_Learning_in_Generalist_Robot_Policies_The_Role_of_Dataset_Diversity_and_Fragmentation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-Shortcut_Learning_in_Generalist_Robot_Policies_The_Role_of_Dataset_Diversity_and_Fragmentation/","children":"[논문리뷰] Shortcut Learning in Generalist Robot Policies: The Role of Dataset Diversity and Fragmentation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hengtao Shen이 [arXiv]에 게시한 'Shortcut Learning in Generalist Robot Policies: The Role of Dataset Diversity and Fragmentation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Robot Learning",{"className":"page__taxonomy-item","children":["#","Robot Learning"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Shortcut Learning",{"className":"page__taxonomy-item","children":["#","Shortcut Learning"]}],["$","span","Dataset Diversity",{"className":"page__taxonomy-item","children":["#","Dataset Diversity"]}],["$","span","Dataset Fragmentation",{"className":"page__taxonomy-item","children":["#","Dataset Fragmentation"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}],["$","span","Imitation Learning",{"className":"page__taxonomy-item","children":["#","Imitation Learning"]}]]}]]}]]}],["$","article","2025-8-12-Reinforcement_Learning_in_Vision_A_Survey",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-Reinforcement_Learning_in_Vision_A_Survey/","children":"[논문리뷰] Reinforcement Learning in Vision: A Survey"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Qingwei Meng이 [arXiv]에 게시한 'Reinforcement Learning in Vision: A Survey' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Computer Vision (CV)",{"className":"page__taxonomy-item","children":["#","Computer Vision (CV)"]}],["$","span","Multimodal Large Language Models (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models (MLLMs)"]}],["$","span","Visual Generation",{"className":"page__taxonomy-item","children":["#","Visual Generation"]}],["$","span","Vision-Language-Action (VLA) Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action (VLA) Models"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Reward Modeling",{"className":"page__taxonomy-item","children":["#","Reward Modeling"]}]]}]]}]]}],["$","article","2025-8-12-ReasonRank_Empowering_Passage_Ranking_with_Strong_Reasoning_Ability",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-ReasonRank_Empowering_Passage_Ranking_with_Strong_Reasoning_Ability/","children":"[논문리뷰] ReasonRank: Empowering Passage Ranking with Strong Reasoning Ability"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuchen Li이 [arXiv]에 게시한 'ReasonRank: Empowering Passage Ranking with Strong Reasoning Ability' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Passage Ranking",{"className":"page__taxonomy-item","children":["#","Passage Ranking"]}],["$","span","Reasoning Models",{"className":"page__taxonomy-item","children":["#","Reasoning Models"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Data Synthesis",{"className":"page__taxonomy-item","children":["#","Data Synthesis"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Listwise Reranking",{"className":"page__taxonomy-item","children":["#","Listwise Reranking"]}],["$","span","Information Retrieval",{"className":"page__taxonomy-item","children":["#","Information Retrieval"]}]]}]]}]]}],["$","article","2025-8-12-Part_I_Tricks_or_Traps_A_Deep_Dive_into_RL_for_LLM_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-Part_I_Tricks_or_Traps_A_Deep_Dive_into_RL_for_LLM_Reasoning/","children":"[논문리뷰] Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiaheng Liu이 [arXiv]에 게시한 'Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","LLM Reasoning",{"className":"page__taxonomy-item","children":["#","LLM Reasoning"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Normalization",{"className":"page__taxonomy-item","children":["#","Normalization"]}],["$","span","Clipping",{"className":"page__taxonomy-item","children":["#","Clipping"]}],["$","span","Loss Aggregation",{"className":"page__taxonomy-item","children":["#","Loss Aggregation"]}],["$","span","Overlong Filtering",{"className":"page__taxonomy-item","children":["#","Overlong Filtering"]}]]}]]}]]}],["$","article","2025-8-12-OmniEAR_Benchmarking_Agent_Reasoning_in_Embodied_Tasks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-OmniEAR_Benchmarking_Agent_Reasoning_in_Embodied_Tasks/","children":"[논문리뷰] OmniEAR: Benchmarking Agent Reasoning in Embodied Tasks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hongxing Li이 [arXiv]에 게시한 'OmniEAR: Benchmarking Agent Reasoning in Embodied Tasks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Agent Reasoning",{"className":"page__taxonomy-item","children":["#","Agent Reasoning"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Physical Interaction",{"className":"page__taxonomy-item","children":["#","Physical Interaction"]}],["$","span","Constraint Reasoning",{"className":"page__taxonomy-item","children":["#","Constraint Reasoning"]}]]}]]}]]}],["$","article","2025-8-12-Omni-Effects_Unified_and_Spatially-Controllable_Visual_Effects_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-Omni-Effects_Unified_and_Spatially-Controllable_Visual_Effects_Generation/","children":"[논문리뷰] Omni-Effects: Unified and Spatially-Controllable Visual Effects Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiaokun Feng이 [arXiv]에 게시한 'Omni-Effects: Unified and Spatially-Controllable Visual Effects Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Visual Effects",{"className":"page__taxonomy-item","children":["#","Visual Effects"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","LoRA",{"className":"page__taxonomy-item","children":["#","LoRA"]}],["$","span","Mixture of Experts",{"className":"page__taxonomy-item","children":["#","Mixture of Experts"]}],["$","span","Spatial Control",{"className":"page__taxonomy-item","children":["#","Spatial Control"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Multi-VFX",{"className":"page__taxonomy-item","children":["#","Multi-VFX"]}]]}]]}]]}],["$","article","2025-8-12-MolmoAct_Action_Reasoning_Models_that_can_Reason_in_Space",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-MolmoAct_Action_Reasoning_Models_that_can_Reason_in_Space/","children":"[논문리뷰] MolmoAct: Action Reasoning Models that can Reason in Space"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shuo Liu이 [arXiv]에 게시한 'MolmoAct: Action Reasoning Models that can Reason in Space' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Action Reasoning",{"className":"page__taxonomy-item","children":["#","Action Reasoning"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Spatial Planning",{"className":"page__taxonomy-item","children":["#","Spatial Planning"]}],["$","span","Depth Perception",{"className":"page__taxonomy-item","children":["#","Depth Perception"]}],["$","span","Trajectory Generation",{"className":"page__taxonomy-item","children":["#","Trajectory Generation"]}],["$","span","Explainable AI",{"className":"page__taxonomy-item","children":["#","Explainable AI"]}]]}]]}]]}],["$","article","2025-8-12-MoBE_Mixture-of-Basis-Experts_for_Compressing_MoE-based_LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-MoBE_Mixture-of-Basis-Experts_for_Compressing_MoE-based_LLMs/","children":"[논문리뷰] MoBE: Mixture-of-Basis-Experts for Compressing MoE-based LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jianguo Li이 [arXiv]에 게시한 'MoBE: Mixture-of-Basis-Experts for Compressing MoE-based LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Mixture-of-Experts (MoE)",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts (MoE)"]}],["$","span","LLM Compression",{"className":"page__taxonomy-item","children":["#","LLM Compression"]}],["$","span","Matrix Decomposition",{"className":"page__taxonomy-item","children":["#","Matrix Decomposition"]}],["$","span","Parameter Efficiency",{"className":"page__taxonomy-item","children":["#","Parameter Efficiency"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}],["$","span","Memory Optimization",{"className":"page__taxonomy-item","children":["#","Memory Optimization"]}]]}]]}]]}],["$","article","2025-8-12-Less_Is_More_Training-Free_Sparse_Attention_with_Global_Locality_for_Efficient_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-Less_Is_More_Training-Free_Sparse_Attention_with_Global_Locality_for_Efficient_Reasoning/","children":"[논문리뷰] Less Is More: Training-Free Sparse Attention with Global Locality for Efficient Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Baihong Yuan이 [arXiv]에 게시한 'Less Is More: Training-Free Sparse Attention with Global Locality for Efficient Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Sparse Attention",{"className":"page__taxonomy-item","children":["#","Sparse Attention"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Reasoning Tasks",{"className":"page__taxonomy-item","children":["#","Reasoning Tasks"]}],["$","span","Efficiency",{"className":"page__taxonomy-item","children":["#","Efficiency"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}],["$","span","Global Locality",{"className":"page__taxonomy-item","children":["#","Global Locality"]}],["$","span","KV Cache Optimization",{"className":"page__taxonomy-item","children":["#","KV Cache Optimization"]}]]}]]}]]}],["$","article","2025-8-12-Klear-Reasoner_Advancing_Reasoning_Capability_via_Gradient-Preserving_Clipping_Policy_Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-Klear-Reasoner_Advancing_Reasoning_Capability_via_Gradient-Preserving_Clipping_Policy_Optimization/","children":"[논문리뷰] Klear-Reasoner: Advancing Reasoning Capability via Gradient-Preserving Clipping Policy Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Guanting Dong이 [arXiv]에 게시한 'Klear-Reasoner: Advancing Reasoning Capability via Gradient-Preserving Clipping Policy Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reasoning LLMs",{"className":"page__taxonomy-item","children":["#","Reasoning LLMs"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","PPO",{"className":"page__taxonomy-item","children":["#","PPO"]}],["$","span","Gradient Clipping",{"className":"page__taxonomy-item","children":["#","Gradient Clipping"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Math Reasoning",{"className":"page__taxonomy-item","children":["#","Math Reasoning"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}]]}]]}]]}],["$","article","2025-8-12-Grove_MoE_Towards_Efficient_and_Superior_MoE_LLMs_with_Adjugate_Experts",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-Grove_MoE_Towards_Efficient_and_Superior_MoE_LLMs_with_Adjugate_Experts/","children":"[논문리뷰] Grove MoE: Towards Efficient and Superior MoE LLMs with Adjugate Experts"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Tieyuan Chen이 [arXiv]에 게시한 'Grove MoE: Towards Efficient and Superior MoE LLMs with Adjugate Experts' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Mixture of Experts",{"className":"page__taxonomy-item","children":["#","Mixture of Experts"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","MoE Architecture",{"className":"page__taxonomy-item","children":["#","MoE Architecture"]}],["$","span","Dynamic Activation",{"className":"page__taxonomy-item","children":["#","Dynamic Activation"]}],["$","span","Adjugate Experts",{"className":"page__taxonomy-item","children":["#","Adjugate Experts"]}],["$","span","Upcycling Strategy",{"className":"page__taxonomy-item","children":["#","Upcycling Strategy"]}],["$","span","Load Balancing",{"className":"page__taxonomy-item","children":["#","Load Balancing"]}]]}]]}]]}],["$","article","2025-8-12-GLiClass_Generalist_Lightweight_Model_for_Sequence_Classification_Tasks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-GLiClass_Generalist_Lightweight_Model_for_Sequence_Classification_Tasks/","children":"[논문리뷰] GLiClass: Generalist Lightweight Model for Sequence Classification Tasks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Alexander Yavorskyi이 [arXiv]에 게시한 'GLiClass: Generalist Lightweight Model for Sequence Classification Tasks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Sequence Classification",{"className":"page__taxonomy-item","children":["#","Sequence Classification"]}],["$","span","Zero-shot Learning",{"className":"page__taxonomy-item","children":["#","Zero-shot Learning"]}],["$","span","Few-shot Learning",{"className":"page__taxonomy-item","children":["#","Few-shot Learning"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Multi-label Classification",{"className":"page__taxonomy-item","children":["#","Multi-label Classification"]}],["$","span","PPO",{"className":"page__taxonomy-item","children":["#","PPO"]}],["$","span","GLiNER",{"className":"page__taxonomy-item","children":["#","GLiNER"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}]]}]]}]]}],["$","article","2025-8-12-Follow-Your-Shape_Shape-Aware_Image_Editing_via_Trajectory-Guided_Region_Control",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-Follow-Your-Shape_Shape-Aware_Image_Editing_via_Trajectory-Guided_Region_Control/","children":"[논문리뷰] Follow-Your-Shape: Shape-Aware Image Editing via Trajectory-Guided Region Control"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hongyu Liu이 [arXiv]에 게시한 'Follow-Your-Shape: Shape-Aware Image Editing via Trajectory-Guided Region Control' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Shape Transformation",{"className":"page__taxonomy-item","children":["#","Shape Transformation"]}],["$","span","Rectified Flow",{"className":"page__taxonomy-item","children":["#","Rectified Flow"]}],["$","span","Trajectory Divergence Map",{"className":"page__taxonomy-item","children":["#","Trajectory Divergence Map"]}],["$","span","Region Control",{"className":"page__taxonomy-item","children":["#","Region Control"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}]]}]]}]]}],["$","article","2025-8-12-Fact2Fiction_Targeted_Poisoning_Attack_to_Agentic_Fact-checking_System",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-Fact2Fiction_Targeted_Poisoning_Attack_to_Agentic_Fact-checking_System/","children":"[논문리뷰] Fact2Fiction: Targeted Poisoning Attack to Agentic Fact-checking System"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Reynold Cheng이 [arXiv]에 게시한 'Fact2Fiction: Targeted Poisoning Attack to Agentic Fact-checking System' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Adversarial Attack",{"className":"page__taxonomy-item","children":["#","Adversarial Attack"]}],["$","span","Poisoning Attack",{"className":"page__taxonomy-item","children":["#","Poisoning Attack"]}],["$","span","Fact-checking",{"className":"page__taxonomy-item","children":["#","Fact-checking"]}],["$","span","LLM Agent",{"className":"page__taxonomy-item","children":["#","LLM Agent"]}],["$","span","Retrieval Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval Augmented Generation"]}],["$","span","Misinformation",{"className":"page__taxonomy-item","children":["#","Misinformation"]}],["$","span","System Security",{"className":"page__taxonomy-item","children":["#","System Security"]}]]}]]}]]}],["$","article","2025-8-12-Deep_Ignorance_Filtering_Pretraining_Data_Builds_Tamper-Resistant_Safeguards_into_Open-Weight_LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-Deep_Ignorance_Filtering_Pretraining_Data_Builds_Tamper-Resistant_Safeguards_into_Open-Weight_LLMs/","children":"[논문리뷰] Deep Ignorance: Filtering Pretraining Data Builds Tamper-Resistant Safeguards into Open-Weight LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Robert Kirk이 [arXiv]에 게시한 'Deep Ignorance: Filtering Pretraining Data Builds Tamper-Resistant Safeguards into Open-Weight LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","데이터 필터링",{"className":"page__taxonomy-item","children":["#","데이터 필터링"]}],["$","span","사전 학습",{"className":"page__taxonomy-item","children":["#","사전 학습"]}],["$","span","변조 저항성",{"className":"page__taxonomy-item","children":["#","변조 저항성"]}],["$","span","바이오위협",{"className":"page__taxonomy-item","children":["#","바이오위협"]}],["$","span","AI 안전",{"className":"page__taxonomy-item","children":["#","AI 안전"]}],["$","span","서킷 브레이킹",{"className":"page__taxonomy-item","children":["#","서킷 브레이킹"]}],["$","span","머신 언러닝",{"className":"page__taxonomy-item","children":["#","머신 언러닝"]}]]}]]}]]}],["$","article","2025-8-12-Compressing_Chain-of-Thought_in_LLMs_via_Step_Entropy",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-Compressing_Chain-of-Thought_in_LLMs_via_Step_Entropy/","children":"[논문리뷰] Compressing Chain-of-Thought in LLMs via Step Entropy"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhijian Xu이 [arXiv]에 게시한 'Compressing Chain-of-Thought in LLMs via Step Entropy' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","CoT Compression",{"className":"page__taxonomy-item","children":["#","CoT Compression"]}],["$","span","Step Entropy",{"className":"page__taxonomy-item","children":["#","Step Entropy"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","SFT",{"className":"page__taxonomy-item","children":["#","SFT"]}],["$","span","GRPO",{"className":"page__taxonomy-item","children":["#","GRPO"]}]]}]]}]]}],["$","article","2025-8-12-BrowseComp-Plus_A_More_Fair_and_Transparent_Evaluation_Benchmark_of_Deep-Research_Agent",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-BrowseComp-Plus_A_More_Fair_and_Transparent_Evaluation_Benchmark_of_Deep-Research_Agent/","children":"[논문리뷰] BrowseComp-Plus: A More Fair and Transparent Evaluation Benchmark of Deep-Research Agent"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kai Zou이 [arXiv]에 게시한 'BrowseComp-Plus: A More Fair and Transparent Evaluation Benchmark of Deep-Research Agent' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Deep-Research Agents",{"className":"page__taxonomy-item","children":["#","Deep-Research Agents"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Retrieval",{"className":"page__taxonomy-item","children":["#","Retrieval"]}],["$","span","Curated Corpus",{"className":"page__taxonomy-item","children":["#","Curated Corpus"]}],["$","span","Evaluation",{"className":"page__taxonomy-item","children":["#","Evaluation"]}],["$","span","Fairness",{"className":"page__taxonomy-item","children":["#","Fairness"]}],["$","span","Transparency",{"className":"page__taxonomy-item","children":["#","Transparency"]}],["$","span","Reproducibility",{"className":"page__taxonomy-item","children":["#","Reproducibility"]}]]}]]}]]}],["$","article","2025-8-12-Bifrost-1_Bridging_Multimodal_LLMs_and_Diffusion_Models_with_Patch-level_CLIP_Latents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-Bifrost-1_Bridging_Multimodal_LLMs_and_Diffusion_Models_with_Patch-level_CLIP_Latents/","children":"[논문리뷰] Bifrost-1: Bridging Multimodal LLMs and Diffusion Models with Patch-level CLIP Latents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Mohit Bansal이 [arXiv]에 게시한 'Bifrost-1: Bridging Multimodal LLMs and Diffusion Models with Patch-level CLIP Latents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal LLM",{"className":"page__taxonomy-item","children":["#","Multimodal LLM"]}],["$","span","Diffusion Model",{"className":"page__taxonomy-item","children":["#","Diffusion Model"]}],["$","span","CLIP Latent",{"className":"page__taxonomy-item","children":["#","CLIP Latent"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Multimodal Understanding",{"className":"page__taxonomy-item","children":["#","Multimodal Understanding"]}],["$","span","ControlNet",{"className":"page__taxonomy-item","children":["#","ControlNet"]}],["$","span","Training Efficiency",{"className":"page__taxonomy-item","children":["#","Training Efficiency"]}]]}]]}]]}],["$","article","2025-8-12-A_Comprehensive_Survey_of_Self-Evolving_AI_Agents_A_New_Paradigm_Bridging_Foundation_Models_and_Lifelong_Agentic_Systems",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-12-A_Comprehensive_Survey_of_Self-Evolving_AI_Agents_A_New_Paradigm_Bridging_Foundation_Models_and_Lifelong_Agentic_Systems/","children":"[논문리뷰] A Comprehensive Survey of Self-Evolving AI Agents: A New Paradigm Bridging Foundation Models and Lifelong Agentic Systems"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xinhao Yi이 [arXiv]에 게시한 'A Comprehensive Survey of Self-Evolving AI Agents: A New Paradigm Bridging Foundation Models and Lifelong Agentic Systems' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-12 13:29:09+0900","children":"2025년 8월 12일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Self-Evolving AI Agents",{"className":"page__taxonomy-item","children":["#","Self-Evolving AI Agents"]}],["$","span","Lifelong Learning",{"className":"page__taxonomy-item","children":["#","Lifelong Learning"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Agent Optimization",{"className":"page__taxonomy-item","children":["#","Agent Optimization"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","Tool Use",{"className":"page__taxonomy-item","children":["#","Tool Use"]}],["$","span","AI Safety",{"className":"page__taxonomy-item","children":["#","AI Safety"]}],["$","span","Survey",{"className":"page__taxonomy-item","children":["#","Survey"]}]]}]]}]]}],["$","article","2025-8-11-Voost_A_Unified_and_Scalable_Diffusion_Transformer_for_Bidirectional_Virtual_Try-On_and_Try-Off",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-11-Voost_A_Unified_and_Scalable_Diffusion_Transformer_for_Bidirectional_Virtual_Try-On_and_Try-Off/","children":"[논문리뷰] Voost: A Unified and Scalable Diffusion Transformer for Bidirectional Virtual Try-On and Try-Off"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"jgkwak이 [arXiv]에 게시한 'Voost: A Unified and Scalable Diffusion Transformer for Bidirectional Virtual Try-On and Try-Off' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-11 13:13:28+0900","children":"2025년 8월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Virtual Try-On",{"className":"page__taxonomy-item","children":["#","Virtual Try-On"]}],["$","span","Virtual Try-Off",{"className":"page__taxonomy-item","children":["#","Virtual Try-Off"]}],["$","span","Diffusion Transformer",{"className":"page__taxonomy-item","children":["#","Diffusion Transformer"]}],["$","span","Bidirectional Learning",{"className":"page__taxonomy-item","children":["#","Bidirectional Learning"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Fashion Synthesis",{"className":"page__taxonomy-item","children":["#","Fashion Synthesis"]}],["$","span","Attention Mechanism",{"className":"page__taxonomy-item","children":["#","Attention Mechanism"]}],["$","span","Self-Correction",{"className":"page__taxonomy-item","children":["#","Self-Correction"]}]]}]]}]]}],["$","article","2025-8-11-UI-AGILE_Advancing_GUI_Agents_with_Effective_Reinforcement_Learning_and_Precise_Inference-Time_Grounding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-11-UI-AGILE_Advancing_GUI_Agents_with_Effective_Reinforcement_Learning_and_Precise_Inference-Time_Grounding/","children":"[논문리뷰] UI-AGILE: Advancing GUI Agents with Effective Reinforcement Learning and Precise Inference-Time Grounding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Bingqi Chen이 [arXiv]에 게시한 'UI-AGILE: Advancing GUI Agents with Effective Reinforcement Learning and Precise Inference-Time Grounding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-11 13:13:28+0900","children":"2025년 8월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","GUI Agents",{"className":"page__taxonomy-item","children":["#","GUI Agents"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Grounding",{"className":"page__taxonomy-item","children":["#","Grounding"]}],["$","span","MLLMs",{"className":"page__taxonomy-item","children":["#","MLLMs"]}],["$","span","Reward Function",{"className":"page__taxonomy-item","children":["#","Reward Function"]}],["$","span","Resampling",{"className":"page__taxonomy-item","children":["#","Resampling"]}],["$","span","Visual Noise Reduction",{"className":"page__taxonomy-item","children":["#","Visual Noise Reduction"]}]]}]]}]]}],["$","article","2025-8-11-Pruning_the_Unsurprising_Efficient_Code_Reasoning_via_First-Token_Surprisal",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-11-Pruning_the_Unsurprising_Efficient_Code_Reasoning_via_First-Token_Surprisal/","children":"[논문리뷰] Pruning the Unsurprising: Efficient Code Reasoning via First-Token Surprisal"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chengcheng Wan이 [arXiv]에 게시한 'Pruning the Unsurprising: Efficient Code Reasoning via First-Token Surprisal' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-11 13:13:28+0900","children":"2025년 8월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Code Reasoning",{"className":"page__taxonomy-item","children":["#","Code Reasoning"]}],["$","span","CoT Compression",{"className":"page__taxonomy-item","children":["#","CoT Compression"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Efficiency",{"className":"page__taxonomy-item","children":["#","Efficiency"]}],["$","span","Surprisal",{"className":"page__taxonomy-item","children":["#","Surprisal"]}],["$","span","Pruning",{"className":"page__taxonomy-item","children":["#","Pruning"]}],["$","span","Fine-tuning",{"className":"page__taxonomy-item","children":["#","Fine-tuning"]}],["$","span","Large Reasoning Models",{"className":"page__taxonomy-item","children":["#","Large Reasoning Models"]}]]}]]}]]}],["$","article","2025-8-11-MeshLLM_Empowering_Large_Language_Models_to_Progressively_Understand_and_Generate_3D_Mesh",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-11-MeshLLM_Empowering_Large_Language_Models_to_Progressively_Understand_and_Generate_3D_Mesh/","children":"[논문리뷰] MeshLLM: Empowering Large Language Models to Progressively Understand and Generate 3D Mesh"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yi Yang이 [arXiv]에 게시한 'MeshLLM: Empowering Large Language Models to Progressively Understand and Generate 3D Mesh' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-11 13:13:28+0900","children":"2025년 8월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Mesh Generation",{"className":"page__taxonomy-item","children":["#","3D Mesh Generation"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Mesh Understanding",{"className":"page__taxonomy-item","children":["#","Mesh Understanding"]}],["$","span","Text-to-3D",{"className":"page__taxonomy-item","children":["#","Text-to-3D"]}],["$","span","Primitive-Mesh Decomposition",{"className":"page__taxonomy-item","children":["#","Primitive-Mesh Decomposition"]}],["$","span","Progressive Training",{"className":"page__taxonomy-item","children":["#","Progressive Training"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}]]}]]}]]}],["$","article","2025-8-11-Memp_Exploring_Agent_Procedural_Memory",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-11-Memp_Exploring_Agent_Procedural_Memory/","children":"[논문리뷰] Memp: Exploring Agent Procedural Memory"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shuofei Qiao이 [arXiv]에 게시한 'Memp: Exploring Agent Procedural Memory' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-11 13:13:28+0900","children":"2025년 8월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Procedural Memory",{"className":"page__taxonomy-item","children":["#","Procedural Memory"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Memory Management",{"className":"page__taxonomy-item","children":["#","Memory Management"]}],["$","span","Task Automation",{"className":"page__taxonomy-item","children":["#","Task Automation"]}],["$","span","Lifelong Learning",{"className":"page__taxonomy-item","children":["#","Lifelong Learning"]}],["$","span","Experience Replay",{"className":"page__taxonomy-item","children":["#","Experience Replay"]}],["$","span","Agent Learning",{"className":"page__taxonomy-item","children":["#","Agent Learning"]}]]}]]}]]}],["$","article","2025-8-11-MELLA_Bridging_Linguistic_Capability_and_Cultural_Groundedness_for_Low-Resource_Language_MLLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-11-MELLA_Bridging_Linguistic_Capability_and_Cultural_Groundedness_for_Low-Resource_Language_MLLMs/","children":"[논문리뷰] MELLA: Bridging Linguistic Capability and Cultural Groundedness for Low-Resource Language MLLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Guohang Yan이 [arXiv]에 게시한 'MELLA: Bridging Linguistic Capability and Cultural Groundedness for Low-Resource Language MLLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-11 13:13:28+0900","children":"2025년 8월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Large Language Models",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models"]}],["$","span","Low-Resource Languages",{"className":"page__taxonomy-item","children":["#","Low-Resource Languages"]}],["$","span","Cultural Groundedness",{"className":"page__taxonomy-item","children":["#","Cultural Groundedness"]}],["$","span","Linguistic Capability",{"className":"page__taxonomy-item","children":["#","Linguistic Capability"]}],["$","span","Dataset Creation",{"className":"page__taxonomy-item","children":["#","Dataset Creation"]}],["$","span","Multilingual AI",{"className":"page__taxonomy-item","children":["#","Multilingual AI"]}]]}]]}]]}],["$","article","2025-8-11-LightSwitch_Multi-view_Relighting_with_Material-guided_Diffusion",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-11-LightSwitch_Multi-view_Relighting_with_Material-guided_Diffusion/","children":"[논문리뷰] LightSwitch: Multi-view Relighting with Material-guided Diffusion"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shubham Tulsiani이 [arXiv]에 게시한 'LightSwitch: Multi-view Relighting with Material-guided Diffusion' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-11 13:13:28+0900","children":"2025년 8월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-view Relighting",{"className":"page__taxonomy-item","children":["#","Multi-view Relighting"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Material-guided",{"className":"page__taxonomy-item","children":["#","Material-guided"]}],["$","span","Inverse Rendering",{"className":"page__taxonomy-item","children":["#","Inverse Rendering"]}],["$","span","3D Scene Reconstruction",{"className":"page__taxonomy-item","children":["#","3D Scene Reconstruction"]}],["$","span","Image Synthesis",{"className":"page__taxonomy-item","children":["#","Image Synthesis"]}],["$","span","Consistent Relighting",{"className":"page__taxonomy-item","children":["#","Consistent Relighting"]}]]}]]}]]}],["$","article","2025-8-11-InfiGUI-G1_Advancing_GUI_Grounding_with_Adaptive_Exploration_Policy_Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-11-InfiGUI-G1_Advancing_GUI_Grounding_with_Adaptive_Exploration_Policy_Optimization/","children":"[논문리뷰] InfiGUI-G1: Advancing GUI Grounding with Adaptive Exploration Policy Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Pengxiang Li이 [arXiv]에 게시한 'InfiGUI-G1: Advancing GUI Grounding with Adaptive Exploration Policy Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-11 13:13:28+0900","children":"2025년 8월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","GUI Grounding",{"className":"page__taxonomy-item","children":["#","GUI Grounding"]}],["$","span","MLLMs",{"className":"page__taxonomy-item","children":["#","MLLMs"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Policy Optimization",{"className":"page__taxonomy-item","children":["#","Policy Optimization"]}],["$","span","Exploration Strategy",{"className":"page__taxonomy-item","children":["#","Exploration Strategy"]}],["$","span","Semantic Alignment",{"className":"page__taxonomy-item","children":["#","Semantic Alignment"]}],["$","span","Adaptive Exploration Reward",{"className":"page__taxonomy-item","children":["#","Adaptive Exploration Reward"]}],["$","span","Human-Computer Interaction",{"className":"page__taxonomy-item","children":["#","Human-Computer Interaction"]}]]}]]}]]}],["$","article","2025-8-11-GLM-4.5_Agentic_Reasoning_and_Coding_ARC_Foundation_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-11-GLM-4.5_Agentic_Reasoning_and_Coding_ARC_Foundation_Models/","children":"[논문리뷰] GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"GLM-4. 5 Team이 [arXiv]에 게시한 'GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-11 13:13:28+0900","children":"2025년 8월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Model",{"className":"page__taxonomy-item","children":["#","Large Language Model"]}],["$","span","Mixture-of-Experts",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Foundation Model",{"className":"page__taxonomy-item","children":["#","Foundation Model"]}]]}]]}]]}],["$","article","2025-8-11-GENIE_Gaussian_Encoding_for_Neural_Radiance_Fields_Interactive_Editing",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-11-GENIE_Gaussian_Encoding_for_Neural_Radiance_Fields_Interactive_Editing/","children":"[논문리뷰] GENIE: Gaussian Encoding for Neural Radiance Fields Interactive Editing"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Przemysław Spurek이 [arXiv]에 게시한 'GENIE: Gaussian Encoding for Neural Radiance Fields Interactive Editing' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-11 13:13:28+0900","children":"2025년 8월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Neural Radiance Fields (NeRF)",{"className":"page__taxonomy-item","children":["#","Neural Radiance Fields (NeRF)"]}],["$","span","Gaussian Splatting (GS)",{"className":"page__taxonomy-item","children":["#","Gaussian Splatting (GS)"]}],["$","span","Interactive Editing",{"className":"page__taxonomy-item","children":["#","Interactive Editing"]}],["$","span","3D Scene Representation",{"className":"page__taxonomy-item","children":["#","3D Scene Representation"]}],["$","span","Physics Simulation",{"className":"page__taxonomy-item","children":["#","Physics Simulation"]}],["$","span","Hybrid Model",{"className":"page__taxonomy-item","children":["#","Hybrid Model"]}],["$","span","Real-time Rendering",{"className":"page__taxonomy-item","children":["#","Real-time Rendering"]}],["$","span","Ray Tracing",{"className":"page__taxonomy-item","children":["#","Ray Tracing"]}]]}]]}]]}],["$","article","2025-8-11-Adapting_Vision-Language_Models_Without_Labels_A_Comprehensive_Survey",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-11-Adapting_Vision-Language_Models_Without_Labels_A_Comprehensive_Survey/","children":"[논문리뷰] Adapting Vision-Language Models Without Labels: A Comprehensive Survey"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Eleni Chatzi이 [arXiv]에 게시한 'Adapting Vision-Language Models Without Labels: A Comprehensive Survey' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-11 13:13:28+0900","children":"2025년 8월 11일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision-Language Models (VLMs)"]}],["$","span","Unsupervised Adaptation",{"className":"page__taxonomy-item","children":["#","Unsupervised Adaptation"]}],["$","span","Test-Time Adaptation (TTA)",{"className":"page__taxonomy-item","children":["#","Test-Time Adaptation (TTA)"]}],["$","span","Domain Transfer",{"className":"page__taxonomy-item","children":["#","Domain Transfer"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Label-Free Learning",{"className":"page__taxonomy-item","children":["#","Label-Free Learning"]}],["$","span","Zero-Shot Learning",{"className":"page__taxonomy-item","children":["#","Zero-Shot Learning"]}]]}]]}]]}],["$","article","2025-8-8-Visual_Document_Understanding_and_Question_Answering_A_Multi-Agent_Collaboration_Framework_with_Test-Time_Scaling",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-Visual_Document_Understanding_and_Question_Answering_A_Multi-Agent_Collaboration_Framework_with_Test-Time_Scaling/","children":"[논문리뷰] Visual Document Understanding and Question Answering: A Multi-Agent Collaboration Framework with Test-Time Scaling"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ruolin Shen이 [arXiv]에 게시한 'Visual Document Understanding and Question Answering: A Multi-Agent Collaboration Framework with Test-Time Scaling' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Visual Document Understanding",{"className":"page__taxonomy-item","children":["#","Visual Document Understanding"]}],["$","span","Visual Question Answering",{"className":"page__taxonomy-item","children":["#","Visual Question Answering"]}],["$","span","Multi-Agent System",{"className":"page__taxonomy-item","children":["#","Multi-Agent System"]}],["$","span","Test-Time Scaling",{"className":"page__taxonomy-item","children":["#","Test-Time Scaling"]}],["$","span","Self-Correction",{"className":"page__taxonomy-item","children":["#","Self-Correction"]}],["$","span","Mixed Reward Modeling",{"className":"page__taxonomy-item","children":["#","Mixed Reward Modeling"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}]]}]]}]]}],["$","article","2025-8-8-StrandDesigner_Towards_Practical_Strand_Generation_with_Sketch_Guidance",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-StrandDesigner_Towards_Practical_Strand_Generation_with_Sketch_Guidance/","children":"[논문리뷰] StrandDesigner: Towards Practical Strand Generation with Sketch Guidance"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiaobin Hu이 [arXiv]에 게시한 'StrandDesigner: Towards Practical Strand Generation with Sketch Guidance' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Strand Generation",{"className":"page__taxonomy-item","children":["#","Strand Generation"]}],["$","span","Sketch Guidance",{"className":"page__taxonomy-item","children":["#","Sketch Guidance"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Multi-scale Learning",{"className":"page__taxonomy-item","children":["#","Multi-scale Learning"]}],["$","span","Adaptive Conditioning",{"className":"page__taxonomy-item","children":["#","Adaptive Conditioning"]}],["$","span","3D Hair Modeling",{"className":"page__taxonomy-item","children":["#","3D Hair Modeling"]}],["$","span","Computer Graphics",{"className":"page__taxonomy-item","children":["#","Computer Graphics"]}]]}]]}]]}],["$","article","2025-8-8-Steering_One-Step_Diffusion_Model_with_Fidelity-Rich_Decoder_for_Fast_Image_Compression",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-Steering_One-Step_Diffusion_Model_with_Fidelity-Rich_Decoder_for_Fast_Image_Compression/","children":"[논문리뷰] Steering One-Step Diffusion Model with Fidelity-Rich Decoder for Fast Image Compression"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yifei Ji이 [arXiv]에 게시한 'Steering One-Step Diffusion Model with Fidelity-Rich Decoder for Fast Image Compression' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Compression",{"className":"page__taxonomy-item","children":["#","Image Compression"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","One-Step Decoding",{"className":"page__taxonomy-item","children":["#","One-Step Decoding"]}],["$","span","Fidelity Guidance",{"className":"page__taxonomy-item","children":["#","Fidelity Guidance"]}],["$","span","Rate Annealing",{"className":"page__taxonomy-item","children":["#","Rate Annealing"]}],["$","span","VAE",{"className":"page__taxonomy-item","children":["#","VAE"]}],["$","span","Perceptual Quality",{"className":"page__taxonomy-item","children":["#","Perceptual Quality"]}]]}]]}]]}],["$","article","2025-8-8-RPCANet_Deep_Interpretable_Robust_PCA_for_Sparse_Object_Segmentation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-RPCANet_Deep_Interpretable_Robust_PCA_for_Sparse_Object_Segmentation/","children":"[논문리뷰] RPCANet++: Deep Interpretable Robust PCA for Sparse Object Segmentation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jian Yang이 [arXiv]에 게시한 'RPCANet++: Deep Interpretable Robust PCA for Sparse Object Segmentation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Robust PCA",{"className":"page__taxonomy-item","children":["#","Robust PCA"]}],["$","span","Deep Unfolding",{"className":"page__taxonomy-item","children":["#","Deep Unfolding"]}],["$","span","Sparse Segmentation",{"className":"page__taxonomy-item","children":["#","Sparse Segmentation"]}],["$","span","Interpretability",{"className":"page__taxonomy-item","children":["#","Interpretability"]}],["$","span","Image Decomposition",{"className":"page__taxonomy-item","children":["#","Image Decomposition"]}],["$","span","Computer Vision",{"className":"page__taxonomy-item","children":["#","Computer Vision"]}]]}]]}]]}],["$","article","2025-8-8-REINA_Regularized_Entropy_Information-Based_Loss_for_Efficient_Simultaneous_Speech_Translation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-REINA_Regularized_Entropy_Information-Based_Loss_for_Efficient_Simultaneous_Speech_Translation/","children":"[논문리뷰] REINA: Regularized Entropy Information-Based Loss for Efficient Simultaneous Speech Translation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiao Yu이 [arXiv]에 게시한 'REINA: Regularized Entropy Information-Based Loss for Efficient Simultaneous Speech Translation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Simultaneous Speech Translation",{"className":"page__taxonomy-item","children":["#","Simultaneous Speech Translation"]}],["$","span","Adaptive Policy",{"className":"page__taxonomy-item","children":["#","Adaptive Policy"]}],["$","span","Entropy-based Loss",{"className":"page__taxonomy-item","children":["#","Entropy-based Loss"]}],["$","span","Mutual Information",{"className":"page__taxonomy-item","children":["#","Mutual Information"]}],["$","span","Latency-Quality Trade-off",{"className":"page__taxonomy-item","children":["#","Latency-Quality Trade-off"]}],["$","span","Speech-to-Text Translation",{"className":"page__taxonomy-item","children":["#","Speech-to-Text Translation"]}],["$","span","REINA",{"className":"page__taxonomy-item","children":["#","REINA"]}]]}]]}]]}],["$","article","2025-8-8-R-Zero_Self-Evolving_Reasoning_LLM_from_Zero_Data",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-R-Zero_Self-Evolving_Reasoning_LLM_from_Zero_Data/","children":"[논문리뷰] R-Zero: Self-Evolving Reasoning LLM from Zero Data"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zongxia Li이 [arXiv]에 게시한 'R-Zero: Self-Evolving Reasoning LLM from Zero Data' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Self-Evolving LLM",{"className":"page__taxonomy-item","children":["#","Self-Evolving LLM"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Self-Play",{"className":"page__taxonomy-item","children":["#","Self-Play"]}],["$","span","Zero-Data Training",{"className":"page__taxonomy-item","children":["#","Zero-Data Training"]}]]}]]}]]}],["$","article","2025-8-8-PRvL_Quantifying_the_Capabilities_and_Risks_of_Large_Language_Models_for_PII_Redaction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-PRvL_Quantifying_the_Capabilities_and_Risks_of_Large_Language_Models_for_PII_Redaction/","children":"[논문리뷰] PRvL: Quantifying the Capabilities and Risks of Large Language Models for PII Redaction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Prajit Das이 [arXiv]에 게시한 'PRvL: Quantifying the Capabilities and Risks of Large Language Models for PII Redaction' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","PII Redaction",{"className":"page__taxonomy-item","children":["#","PII Redaction"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","Privacy Preservation",{"className":"page__taxonomy-item","children":["#","Privacy Preservation"]}],["$","span","Model Evaluation",{"className":"page__taxonomy-item","children":["#","Model Evaluation"]}],["$","span","Cross-Domain Generalization",{"className":"page__taxonomy-item","children":["#","Cross-Domain Generalization"]}],["$","span","Open-Source LLMs",{"className":"page__taxonomy-item","children":["#","Open-Source LLMs"]}]]}]]}]]}],["$","article","2025-8-8-On_the_Generalization_of_SFT_A_Reinforcement_Learning_Perspective_with_Reward_Rectification",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-On_the_Generalization_of_SFT_A_Reinforcement_Learning_Perspective_with_Reward_Rectification/","children":"[논문리뷰] On the Generalization of SFT: A Reinforcement Learning Perspective with Reward Rectification"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xinyu Ye이 [arXiv]에 게시한 'On the Generalization of SFT: A Reinforcement Learning Perspective with Reward Rectification' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Supervised Fine-Tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning (SFT)"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Reward Rectification",{"className":"page__taxonomy-item","children":["#","Reward Rectification"]}],["$","span","Dynamic Fine-Tuning (DFT)",{"className":"page__taxonomy-item","children":["#","Dynamic Fine-Tuning (DFT)"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","Policy Gradient",{"className":"page__taxonomy-item","children":["#","Policy Gradient"]}],["$","span","Mathematical Reasoning",{"className":"page__taxonomy-item","children":["#","Mathematical Reasoning"]}]]}]]}]]}],["$","article","2025-8-8-MOSEv2_A_More_Challenging_Dataset_for_Video_Object_Segmentation_in_Complex_Scenes",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-MOSEv2_A_More_Challenging_Dataset_for_Video_Object_Segmentation_in_Complex_Scenes/","children":"[논문리뷰] MOSEv2: A More Challenging Dataset for Video Object Segmentation in Complex Scenes"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xudong Jiang이 [arXiv]에 게시한 'MOSEv2: A More Challenging Dataset for Video Object Segmentation in Complex Scenes' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Object Segmentation",{"className":"page__taxonomy-item","children":["#","Video Object Segmentation"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}],["$","span","Complex Scenes",{"className":"page__taxonomy-item","children":["#","Complex Scenes"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Object Tracking",{"className":"page__taxonomy-item","children":["#","Object Tracking"]}],["$","span","Computer Vision",{"className":"page__taxonomy-item","children":["#","Computer Vision"]}],["$","span","Dataset Challenges",{"className":"page__taxonomy-item","children":["#","Dataset Challenges"]}]]}]]}]]}],["$","article","2025-8-8-Marco-Voice_Technical_Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-Marco-Voice_Technical_Report/","children":"[논문리뷰] Marco-Voice Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Qingjuan Li이 [arXiv]에 게시한 'Marco-Voice Technical Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Speech Synthesis",{"className":"page__taxonomy-item","children":["#","Speech Synthesis"]}],["$","span","Voice Cloning",{"className":"page__taxonomy-item","children":["#","Voice Cloning"]}],["$","span","Emotion Control",{"className":"page__taxonomy-item","children":["#","Emotion Control"]}],["$","span","Text-to-Speech",{"className":"page__taxonomy-item","children":["#","Text-to-Speech"]}],["$","span","Disentanglement",{"className":"page__taxonomy-item","children":["#","Disentanglement"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Emotional Speech Dataset",{"className":"page__taxonomy-item","children":["#","Emotional Speech Dataset"]}]]}]]}]]}],["$","article","2025-8-8-I_Think_Therefore_I_Am_Under-Qualified_A_Benchmark_for_Evaluating_Linguistic_Shibboleth_Detection_in_LLM_Hiring_Evaluations",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-I_Think_Therefore_I_Am_Under-Qualified_A_Benchmark_for_Evaluating_Linguistic_Shibboleth_Detection_in_LLM_Hiring_Evaluations/","children":"[논문리뷰] I Think, Therefore I Am Under-Qualified? A Benchmark for Evaluating Linguistic Shibboleth Detection in LLM Hiring Evaluations"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chirag Shah이 [arXiv]에 게시한 'I Think, Therefore I Am Under-Qualified? A Benchmark for Evaluating Linguistic Shibboleth Detection in LLM Hiring Evaluations' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Bias",{"className":"page__taxonomy-item","children":["#","LLM Bias"]}],["$","span","Hiring Evaluation",{"className":"page__taxonomy-item","children":["#","Hiring Evaluation"]}],["$","span","Linguistic Shibboleth",{"className":"page__taxonomy-item","children":["#","Linguistic Shibboleth"]}],["$","span","Hedging Language",{"className":"page__taxonomy-item","children":["#","Hedging Language"]}],["$","span","Fairness",{"className":"page__taxonomy-item","children":["#","Fairness"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Sociolinguistics",{"className":"page__taxonomy-item","children":["#","Sociolinguistics"]}]]}]]}]]}],["$","article","2025-8-8-InfiAlign_A_Scalable_and_Sample-Efficient_Framework_for_Aligning_LLMs_to_Enhance_Reasoning_Capabilities",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-InfiAlign_A_Scalable_and_Sample-Efficient_Framework_for_Aligning_LLMs_to_Enhance_Reasoning_Capabilities/","children":"[논문리뷰] InfiAlign: A Scalable and Sample-Efficient Framework for Aligning LLMs to Enhance Reasoning Capabilities"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhijie Sang이 [arXiv]에 게시한 'InfiAlign: A Scalable and Sample-Efficient Framework for Aligning LLMs to Enhance Reasoning Capabilities' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Alignment",{"className":"page__taxonomy-item","children":["#","LLM Alignment"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}],["$","span","Supervised Fine-tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning (SFT)"]}],["$","span","Direct Preference Optimization (DPO)",{"className":"page__taxonomy-item","children":["#","Direct Preference Optimization (DPO)"]}],["$","span","Sample Efficiency",{"className":"page__taxonomy-item","children":["#","Sample Efficiency"]}],["$","span","Scalability",{"className":"page__taxonomy-item","children":["#","Scalability"]}],["$","span","Multi-dimensional Filtering",{"className":"page__taxonomy-item","children":["#","Multi-dimensional Filtering"]}]]}]]}]]}],["$","article","2025-8-8-I2CR_Intra-_and_Inter-modal_Collaborative_Reflections_for_Multimodal_Entity_Linking",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-I2CR_Intra-_and_Inter-modal_Collaborative_Reflections_for_Multimodal_Entity_Linking/","children":"[논문리뷰] I2CR: Intra- and Inter-modal Collaborative Reflections for Multimodal Entity Linking"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chao Wang이 [arXiv]에 게시한 'I2CR: Intra- and Inter-modal Collaborative Reflections for Multimodal Entity Linking' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Entity Linking",{"className":"page__taxonomy-item","children":["#","Multimodal Entity Linking"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Collaborative Reflection",{"className":"page__taxonomy-item","children":["#","Collaborative Reflection"]}],["$","span","Iterative Reasoning",{"className":"page__taxonomy-item","children":["#","Iterative Reasoning"]}],["$","span","Visual Information",{"className":"page__taxonomy-item","children":["#","Visual Information"]}],["$","span","Text-centric",{"className":"page__taxonomy-item","children":["#","Text-centric"]}]]}]]}]]}],["$","article","2025-8-8-Hop_Skip_and_Overthink_Diagnosing_Why_Reasoning_Models_Fumble_during_Multi-Hop_Analysis",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-Hop_Skip_and_Overthink_Diagnosing_Why_Reasoning_Models_Fumble_during_Multi-Hop_Analysis/","children":"[논문리뷰] Hop, Skip, and Overthink: Diagnosing Why Reasoning Models Fumble during Multi-Hop Analysis"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Reshmi Ghosh이 [arXiv]에 게시한 'Hop, Skip, and Overthink: Diagnosing Why Reasoning Models Fumble during Multi-Hop Analysis' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-hop Question Answering",{"className":"page__taxonomy-item","children":["#","Multi-hop Question Answering"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reasoning Errors",{"className":"page__taxonomy-item","children":["#","Reasoning Errors"]}],["$","span","Error Taxonomy",{"className":"page__taxonomy-item","children":["#","Error Taxonomy"]}],["$","span","Human Evaluation",{"className":"page__taxonomy-item","children":["#","Human Evaluation"]}],["$","span","Automated Evaluation",{"className":"page__taxonomy-item","children":["#","Automated Evaluation"]}],["$","span","Overthinking",{"className":"page__taxonomy-item","children":["#","Overthinking"]}]]}]]}]]}],["$","article","2025-8-8-Hi3DEval_Advancing_3D_Generation_Evaluation_with_Hierarchical_Validity",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-Hi3DEval_Advancing_3D_Generation_Evaluation_with_Hierarchical_Validity/","children":"[논문리뷰] Hi3DEval: Advancing 3D Generation Evaluation with Hierarchical Validity"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhibing Li이 [arXiv]에 게시한 'Hi3DEval: Advancing 3D Generation Evaluation with Hierarchical Validity' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Generation Evaluation",{"className":"page__taxonomy-item","children":["#","3D Generation Evaluation"]}],["$","span","Hierarchical Evaluation",{"className":"page__taxonomy-item","children":["#","Hierarchical Evaluation"]}],["$","span","Material Properties",{"className":"page__taxonomy-item","children":["#","Material Properties"]}],["$","span","Multi-Agent Annotation",{"className":"page__taxonomy-item","children":["#","Multi-Agent Annotation"]}],["$","span","Hybrid Scoring System",{"className":"page__taxonomy-item","children":["#","Hybrid Scoring System"]}],["$","span","Video-based Evaluation",{"className":"page__taxonomy-item","children":["#","Video-based Evaluation"]}],["$","span","Part-level Analysis",{"className":"page__taxonomy-item","children":["#","Part-level Analysis"]}]]}]]}]]}],["$","article","2025-8-8-Genie_Envisioner_A_Unified_World_Foundation_Platform_for_Robotic_Manipulation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-Genie_Envisioner_A_Unified_World_Foundation_Platform_for_Robotic_Manipulation/","children":"[논문리뷰] Genie Envisioner: A Unified World Foundation Platform for Robotic Manipulation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shengcong Chen이 [arXiv]에 게시한 'Genie Envisioner: A Unified World Foundation Platform for Robotic Manipulation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Robotic Manipulation",{"className":"page__taxonomy-item","children":["#","Robotic Manipulation"]}],["$","span","World Model",{"className":"page__taxonomy-item","children":["#","World Model"]}],["$","span","Video Generation",{"className":"page__taxonomy-item","children":["#","Video Generation"]}],["$","span","Diffusion Model",{"className":"page__taxonomy-item","children":["#","Diffusion Model"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Foundation Model",{"className":"page__taxonomy-item","children":["#","Foundation Model"]}],["$","span","Robotics Simulation",{"className":"page__taxonomy-item","children":["#","Robotics Simulation"]}],["$","span","Policy Learning",{"className":"page__taxonomy-item","children":["#","Policy Learning"]}]]}]]}]]}],["$","article","2025-8-8-Evaluating_Synthesizing_and_Enhancing_for_Customer_Support_Conversation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-Evaluating_Synthesizing_and_Enhancing_for_Customer_Support_Conversation/","children":"[논문리뷰] Evaluating, Synthesizing, and Enhancing for Customer Support Conversation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Feng Chen이 [arXiv]에 게시한 'Evaluating, Synthesizing, and Enhancing for Customer Support Conversation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Customer Support",{"className":"page__taxonomy-item","children":["#","Customer Support"]}],["$","span","Dialogue Generation",{"className":"page__taxonomy-item","children":["#","Dialogue Generation"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Role-Playing",{"className":"page__taxonomy-item","children":["#","Role-Playing"]}],["$","span","COPC Framework",{"className":"page__taxonomy-item","children":["#","COPC Framework"]}],["$","span","Synthetic Data",{"className":"page__taxonomy-item","children":["#","Synthetic Data"]}],["$","span","Strategy Prediction",{"className":"page__taxonomy-item","children":["#","Strategy Prediction"]}],["$","span","Empathetic AI",{"className":"page__taxonomy-item","children":["#","Empathetic AI"]}]]}]]}]]}],["$","article","2025-8-8-Dont_Overthink_It_A_Survey_of_Efficient_R1-style_Large_Reasoning_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-Dont_Overthink_It_A_Survey_of_Efficient_R1-style_Large_Reasoning_Models/","children":"[논문리뷰] Don't Overthink It: A Survey of Efficient R1-style Large Reasoning Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Fangzhou Yao이 [arXiv]에 게시한 'Don't Overthink It: A Survey of Efficient R1-style Large Reasoning Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Reasoning Models",{"className":"page__taxonomy-item","children":["#","Large Reasoning Models"]}],["$","span","Efficient Reasoning",{"className":"page__taxonomy-item","children":["#","Efficient Reasoning"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Model Optimization",{"className":"page__taxonomy-item","children":["#","Model Optimization"]}],["$","span","Model Collaboration",{"className":"page__taxonomy-item","children":["#","Model Collaboration"]}],["$","span","Overthinking Problem",{"className":"page__taxonomy-item","children":["#","Overthinking Problem"]}],["$","span","LLM Efficiency",{"className":"page__taxonomy-item","children":["#","LLM Efficiency"]}]]}]]}]]}],["$","article","2025-8-8-DeepPHY_Benchmarking_Agentic_VLMs_on_Physical_Reasoning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-DeepPHY_Benchmarking_Agentic_VLMs_on_Physical_Reasoning/","children":"[논문리뷰] DeepPHY: Benchmarking Agentic VLMs on Physical Reasoning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ziming Wang이 [arXiv]에 게시한 'DeepPHY: Benchmarking Agentic VLMs on Physical Reasoning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision Language Models (VLMs)"]}],["$","span","Agentic AI",{"className":"page__taxonomy-item","children":["#","Agentic AI"]}],["$","span","Physical Reasoning",{"className":"page__taxonomy-item","children":["#","Physical Reasoning"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Simulation Environments",{"className":"page__taxonomy-item","children":["#","Simulation Environments"]}],["$","span","Action Planning",{"className":"page__taxonomy-item","children":["#","Action Planning"]}],["$","span","Interactive AI",{"className":"page__taxonomy-item","children":["#","Interactive AI"]}]]}]]}]]}],["$","article","2025-8-8-CoAct-1_Computer-using_Agents_with_Coding_as_Actions",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-CoAct-1_Computer-using_Agents_with_Coding_as_Actions/","children":"[논문리뷰] CoAct-1: Computer-using Agents with Coding as Actions"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Taiwei Shi이 [arXiv]에 게시한 'CoAct-1: Computer-using Agents with Coding as Actions' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Agent",{"className":"page__taxonomy-item","children":["#","AI Agent"]}],["$","span","Multi-agent System",{"className":"page__taxonomy-item","children":["#","Multi-agent System"]}],["$","span","GUI Automation",{"className":"page__taxonomy-item","children":["#","GUI Automation"]}],["$","span","Programmatic Control",{"className":"page__taxonomy-item","children":["#","Programmatic Control"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","OSWorld Benchmark",{"className":"page__taxonomy-item","children":["#","OSWorld Benchmark"]}],["$","span","Hybrid AI",{"className":"page__taxonomy-item","children":["#","Hybrid AI"]}]]}]]}]]}],["$","article","2025-8-8-Can_Large_Multimodal_Models_Actively_Recognize_Faulty_Inputs_A_Systematic_Evaluation_Framework_of_Their_Input_Scrutiny_Ability",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-Can_Large_Multimodal_Models_Actively_Recognize_Faulty_Inputs_A_Systematic_Evaluation_Framework_of_Their_Input_Scrutiny_Ability/","children":"[논문리뷰] Can Large Multimodal Models Actively Recognize Faulty Inputs? A Systematic Evaluation Framework of Their Input Scrutiny Ability"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuan Wu이 [arXiv]에 게시한 'Can Large Multimodal Models Actively Recognize Faulty Inputs? A Systematic Evaluation Framework of Their Input Scrutiny Ability' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Multimodal Models",{"className":"page__taxonomy-item","children":["#","Large Multimodal Models"]}],["$","span","Input Scrutiny",{"className":"page__taxonomy-item","children":["#","Input Scrutiny"]}],["$","span","Error Detection",{"className":"page__taxonomy-item","children":["#","Error Detection"]}],["$","span","Faulty Inputs",{"className":"page__taxonomy-item","children":["#","Faulty Inputs"]}],["$","span","Evaluation Framework",{"className":"page__taxonomy-item","children":["#","Evaluation Framework"]}],["$","span","Modality Preference",{"className":"page__taxonomy-item","children":["#","Modality Preference"]}],["$","span","Cross-Modal Inconsistency",{"className":"page__taxonomy-item","children":["#","Cross-Modal Inconsistency"]}]]}]]}]]}],["$","article","2025-8-8-Are_We_on_the_Right_Way_for_Assessing_Document_Retrieval-Augmented_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-Are_We_on_the_Right_Way_for_Assessing_Document_Retrieval-Augmented_Generation/","children":"[논문리뷰] Are We on the Right Way for Assessing Document Retrieval-Augmented Generation?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Junjie Yang이 [arXiv]에 게시한 'Are We on the Right Way for Assessing Document Retrieval-Augmented Generation?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","Multimodal LLMs",{"className":"page__taxonomy-item","children":["#","Multimodal LLMs"]}],["$","span","Benchmark Evaluation",{"className":"page__taxonomy-item","children":["#","Benchmark Evaluation"]}],["$","span","Document Understanding",{"className":"page__taxonomy-item","children":["#","Document Understanding"]}],["$","span","Multi-hop Reasoning",{"className":"page__taxonomy-item","children":["#","Multi-hop Reasoning"]}],["$","span","Information Retrieval",{"className":"page__taxonomy-item","children":["#","Information Retrieval"]}],["$","span","Evaluation Dataset",{"className":"page__taxonomy-item","children":["#","Evaluation Dataset"]}]]}]]}]]}],["$","article","2025-8-8-Are_Todays_LLMs_Ready_to_Explain_Well-Being_Concepts",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-8-Are_Todays_LLMs_Ready_to_Explain_Well-Being_Concepts/","children":"[논문리뷰] Are Today's LLMs Ready to Explain Well-Being Concepts?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Huan Liu이 [arXiv]에 게시한 'Are Today's LLMs Ready to Explain Well-Being Concepts?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-08 13:32:22+0900","children":"2025년 8월 8일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Well-being Concepts",{"className":"page__taxonomy-item","children":["#","Well-being Concepts"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Principle-Guided Evaluation",{"className":"page__taxonomy-item","children":["#","Principle-Guided Evaluation"]}],["$","span","LLM-as-a-Judge",{"className":"page__taxonomy-item","children":["#","LLM-as-a-Judge"]}],["$","span","Supervised Fine-Tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning (SFT)"]}],["$","span","Direct Preference Optimization (DPO)",{"className":"page__taxonomy-item","children":["#","Direct Preference Optimization (DPO)"]}],["$","span","Explanation Generation",{"className":"page__taxonomy-item","children":["#","Explanation Generation"]}]]}]]}]]}],["$","article","2025-8-7-Web-CogReasoner_Towards_Knowledge-Induced_Cognitive_Reasoning_for_Web_Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-Web-CogReasoner_Towards_Knowledge-Induced_Cognitive_Reasoning_for_Web_Agents/","children":"[논문리뷰] Web-CogReasoner: Towards Knowledge-Induced Cognitive Reasoning for Web Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xinyu Yang이 [arXiv]에 게시한 'Web-CogReasoner: Towards Knowledge-Induced Cognitive Reasoning for Web Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Web Agent",{"className":"page__taxonomy-item","children":["#","Web Agent"]}],["$","span","Cognitive Reasoning",{"className":"page__taxonomy-item","children":["#","Cognitive Reasoning"]}],["$","span","Knowledge-Induced",{"className":"page__taxonomy-item","children":["#","Knowledge-Induced"]}],["$","span","Large Multimodal Models (LMMs)",{"className":"page__taxonomy-item","children":["#","Large Multimodal Models (LMMs)"]}],["$","span","Bloom's Taxonomy",{"className":"page__taxonomy-item","children":["#","Bloom's Taxonomy"]}],["$","span","Chain-of-Thought (CoT)",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought (CoT)"]}],["$","span","Web-CogDataset",{"className":"page__taxonomy-item","children":["#","Web-CogDataset"]}],["$","span","Web-CogBench",{"className":"page__taxonomy-item","children":["#","Web-CogBench"]}]]}]]}]]}],["$","article","2025-8-7-Training_Long-Context_Multi-Turn_Software_Engineering_Agents_with_Reinforcement_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-Training_Long-Context_Multi-Turn_Software_Engineering_Agents_with_Reinforcement_Learning/","children":"[논문리뷰] Training Long-Context, Multi-Turn Software Engineering Agents with Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Maksim Nekrashevich이 [arXiv]에 게시한 'Training Long-Context, Multi-Turn Software Engineering Agents with Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Software Engineering",{"className":"page__taxonomy-item","children":["#","Software Engineering"]}],["$","span","Multi-Turn Interaction",{"className":"page__taxonomy-item","children":["#","Multi-Turn Interaction"]}],["$","span","Long Context",{"className":"page__taxonomy-item","children":["#","Long Context"]}],["$","span","DAPO",{"className":"page__taxonomy-item","children":["#","DAPO"]}],["$","span","Autonomous Agents",{"className":"page__taxonomy-item","children":["#","Autonomous Agents"]}],["$","span","SWE-BENCH",{"className":"page__taxonomy-item","children":["#","SWE-BENCH"]}]]}]]}]]}],["$","article","2025-8-7-The_Cow_of_Rembrandt_-_Analyzing_Artistic_Prompt_Interpretation_in_Text-to-Image_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-The_Cow_of_Rembrandt_-_Analyzing_Artistic_Prompt_Interpretation_in_Text-to-Image_Models/","children":"[논문리뷰] The Cow of Rembrandt - Analyzing Artistic Prompt Interpretation in Text-to-Image Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Elisabetta Rocchetti이 [arXiv]에 게시한 'The Cow of Rembrandt - Analyzing Artistic Prompt Interpretation in Text-to-Image Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Cross-Attention Analysis",{"className":"page__taxonomy-item","children":["#","Cross-Attention Analysis"]}],["$","span","Content-Style Disentanglement",{"className":"page__taxonomy-item","children":["#","Content-Style Disentanglement"]}],["$","span","Artistic Style Transfer",{"className":"page__taxonomy-item","children":["#","Artistic Style Transfer"]}],["$","span","Explainable AI",{"className":"page__taxonomy-item","children":["#","Explainable AI"]}],["$","span","SDXL",{"className":"page__taxonomy-item","children":["#","SDXL"]}]]}]]}]]}],["$","article","2025-8-7-Sotopia-RL_Reward_Design_for_Social_Intelligence",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-Sotopia-RL_Reward_Design_for_Social_Intelligence/","children":"[논문리뷰] Sotopia-RL: Reward Design for Social Intelligence"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Keyang Xuan이 [arXiv]에 게시한 'Sotopia-RL: Reward Design for Social Intelligence' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Social Intelligence",{"className":"page__taxonomy-item","children":["#","Social Intelligence"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Reward Design",{"className":"page__taxonomy-item","children":["#","Reward Design"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Utterance-level Rewards",{"className":"page__taxonomy-item","children":["#","Utterance-level Rewards"]}],["$","span","Multi-dimensional Rewards",{"className":"page__taxonomy-item","children":["#","Multi-dimensional Rewards"]}],["$","span","Partial Observability",{"className":"page__taxonomy-item","children":["#","Partial Observability"]}],["$","span","SOTOPIA",{"className":"page__taxonomy-item","children":["#","SOTOPIA"]}]]}]]}]]}],["$","article","2025-8-7-SonicMaster_Towards_Controllable_All-in-One_Music_Restoration_and_Mastering",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-SonicMaster_Towards_Controllable_All-in-One_Music_Restoration_and_Mastering/","children":"[논문리뷰] SonicMaster: Towards Controllable All-in-One Music Restoration and Mastering"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ambuj Mehrish이 [arXiv]에 게시한 'SonicMaster: Towards Controllable All-in-One Music Restoration and Mastering' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Music Restoration",{"className":"page__taxonomy-item","children":["#","Music Restoration"]}],["$","span","Audio Mastering",{"className":"page__taxonomy-item","children":["#","Audio Mastering"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}],["$","span","Text-to-Audio",{"className":"page__taxonomy-item","children":["#","Text-to-Audio"]}],["$","span","Audio Quality Enhancement",{"className":"page__taxonomy-item","children":["#","Audio Quality Enhancement"]}],["$","span","Multi-task Learning",{"className":"page__taxonomy-item","children":["#","Multi-task Learning"]}],["$","span","Dataset Creation",{"className":"page__taxonomy-item","children":["#","Dataset Creation"]}]]}]]}]]}],["$","article","2025-8-7-Sel3DCraft_Interactive_Visual_Prompts_for_User-Friendly_Text-to-3D_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-Sel3DCraft_Interactive_Visual_Prompts_for_User-Friendly_Text-to-3D_Generation/","children":"[논문리뷰] Sel3DCraft: Interactive Visual Prompts for User-Friendly Text-to-3D Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hao Huang이 [arXiv]에 게시한 'Sel3DCraft: Interactive Visual Prompts for User-Friendly Text-to-3D Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Text-to-3D Generation",{"className":"page__taxonomy-item","children":["#","Text-to-3D Generation"]}],["$","span","Prompt Engineering",{"className":"page__taxonomy-item","children":["#","Prompt Engineering"]}],["$","span","Visual Analytics",{"className":"page__taxonomy-item","children":["#","Visual Analytics"]}],["$","span","Human-Computer Interaction",{"className":"page__taxonomy-item","children":["#","Human-Computer Interaction"]}],["$","span","Multi-modal Large Language Models",{"className":"page__taxonomy-item","children":["#","Multi-modal Large Language Models"]}],["$","span","3D Model Evaluation",{"className":"page__taxonomy-item","children":["#","3D Model Evaluation"]}]]}]]}]]}],["$","article","2025-8-7-SEAgent_Self-Evolving_Computer_Use_Agent_with_Autonomous_Learning_from_Experience",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-SEAgent_Self-Evolving_Computer_Use_Agent_with_Autonomous_Learning_from_Experience/","children":"[논문리뷰] SEAgent: Self-Evolving Computer Use Agent with Autonomous Learning from Experience"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Xiaoyi Dong이 [arXiv]에 게시한 'SEAgent: Self-Evolving Computer Use Agent with Autonomous Learning from Experience' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Computer Use Agent",{"className":"page__taxonomy-item","children":["#","Computer Use Agent"]}],["$","span","Self-Evolving",{"className":"page__taxonomy-item","children":["#","Self-Evolving"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Experiential Learning",{"className":"page__taxonomy-item","children":["#","Experiential Learning"]}],["$","span","Specialist-to-Generalist",{"className":"page__taxonomy-item","children":["#","Specialist-to-Generalist"]}]]}]]}]]}],["$","article","2025-8-7-Sculptor_Empowering_LLMs_with_Cognitive_Agency_via_Active_Context_Management",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-Sculptor_Empowering_LLMs_with_Cognitive_Agency_via_Active_Context_Management/","children":"[논문리뷰] Sculptor: Empowering LLMs with Cognitive Agency via Active Context Management"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yunxin Liu이 [arXiv]에 게시한 'Sculptor: Empowering LLMs with Cognitive Agency via Active Context Management' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Active Context Management",{"className":"page__taxonomy-item","children":["#","Active Context Management"]}],["$","span","Proactive Interference",{"className":"page__taxonomy-item","children":["#","Proactive Interference"]}],["$","span","Tool Augmentation",{"className":"page__taxonomy-item","children":["#","Tool Augmentation"]}],["$","span","Working Memory",{"className":"page__taxonomy-item","children":["#","Working Memory"]}],["$","span","Context Curation",{"className":"page__taxonomy-item","children":["#","Context Curation"]}],["$","span","Long Context",{"className":"page__taxonomy-item","children":["#","Long Context"]}]]}]]}]]}],["$","article","2025-8-7-RL-PLUS_Countering_Capability_Boundary_Collapse_of_LLMs_in_Reinforcement_Learning_with_Hybrid-policy_Optimization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-RL-PLUS_Countering_Capability_Boundary_Collapse_of_LLMs_in_Reinforcement_Learning_with_Hybrid-policy_Optimization/","children":"[논문리뷰] RL-PLUS: Countering Capability Boundary Collapse of LLMs in Reinforcement Learning with Hybrid-policy Optimization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kechi Zhang이 [arXiv]에 게시한 'RL-PLUS: Countering Capability Boundary Collapse of LLMs in Reinforcement Learning with Hybrid-policy Optimization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Capability Collapse",{"className":"page__taxonomy-item","children":["#","Capability Collapse"]}],["$","span","Hybrid Policy Optimization",{"className":"page__taxonomy-item","children":["#","Hybrid Policy Optimization"]}],["$","span","Multiple Importance Sampling",{"className":"page__taxonomy-item","children":["#","Multiple Importance Sampling"]}],["$","span","Exploration",{"className":"page__taxonomy-item","children":["#","Exploration"]}],["$","span","Math Reasoning",{"className":"page__taxonomy-item","children":["#","Math Reasoning"]}],["$","span","Out-of-Distribution",{"className":"page__taxonomy-item","children":["#","Out-of-Distribution"]}]]}]]}]]}],["$","article","2025-8-7-Reasoning_Language_Models_for_Root_Cause_Analysis_in_5G_Wireless_Networks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-Reasoning_Language_Models_for_Root_Cause_Analysis_in_5G_Wireless_Networks/","children":"[논문리뷰] Reasoning Language Models for Root Cause Analysis in 5G Wireless Networks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Haozhe Zhang이 [arXiv]에 게시한 'Reasoning Language Models for Root Cause Analysis in 5G Wireless Networks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Root Cause Analysis",{"className":"page__taxonomy-item","children":["#","Root Cause Analysis"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","5G Wireless Networks",{"className":"page__taxonomy-item","children":["#","5G Wireless Networks"]}],["$","span","Supervised Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-Tuning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","TeleLogs Dataset",{"className":"page__taxonomy-item","children":["#","TeleLogs Dataset"]}]]}]]}]]}],["$","article","2025-8-7-Position_The_Current_AI_Conference_Model_is_Unsustainable_Diagnosing_the_Crisis_of_Centralized_AI_Conference",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-Position_The_Current_AI_Conference_Model_is_Unsustainable_Diagnosing_the_Crisis_of_Centralized_AI_Conference/","children":"[논문리뷰] Position: The Current AI Conference Model is Unsustainable! Diagnosing the Crisis of Centralized AI Conference"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiaying Wu이 [arXiv]에 게시한 'Position: The Current AI Conference Model is Unsustainable! Diagnosing the Crisis of Centralized AI Conference' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Conferences",{"className":"page__taxonomy-item","children":["#","AI Conferences"]}],["$","span","Sustainability",{"className":"page__taxonomy-item","children":["#","Sustainability"]}],["$","span","Peer Review",{"className":"page__taxonomy-item","children":["#","Peer Review"]}],["$","span","Community Building",{"className":"page__taxonomy-item","children":["#","Community Building"]}],["$","span","Environmental Impact",{"className":"page__taxonomy-item","children":["#","Environmental Impact"]}],["$","span","Mental Health",{"className":"page__taxonomy-item","children":["#","Mental Health"]}],["$","span","Centralized Model",{"className":"page__taxonomy-item","children":["#","Centralized Model"]}],["$","span","Decentralized Model",{"className":"page__taxonomy-item","children":["#","Decentralized Model"]}]]}]]}]]}],["$","article","2025-8-7-OpenMed_NER_Open-Source_Domain-Adapted_State-of-the-Art_Transformers_for_Biomedical_NER_Across_12_Public_Datasets",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-OpenMed_NER_Open-Source_Domain-Adapted_State-of-the-Art_Transformers_for_Biomedical_NER_Across_12_Public_Datasets/","children":"[논문리뷰] OpenMed NER: Open-Source, Domain-Adapted State-of-the-Art Transformers for Biomedical NER Across 12 Public Datasets"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"MaziyarPanahi이 [arXiv]에 게시한 'OpenMed NER: Open-Source, Domain-Adapted State-of-the-Art Transformers for Biomedical NER Across 12 Public Datasets' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Biomedical NER",{"className":"page__taxonomy-item","children":["#","Biomedical NER"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Domain Adaptation",{"className":"page__taxonomy-item","children":["#","Domain Adaptation"]}],["$","span","LoRA",{"className":"page__taxonomy-item","children":["#","LoRA"]}],["$","span","Open-Source",{"className":"page__taxonomy-item","children":["#","Open-Source"]}],["$","span","Named Entity Recognition",{"className":"page__taxonomy-item","children":["#","Named Entity Recognition"]}],["$","span","Healthcare AI",{"className":"page__taxonomy-item","children":["#","Healthcare AI"]}]]}]]}]]}],["$","article","2025-8-7-MiDashengLM_Efficient_Audio_Understanding_with_General_Audio_Captions",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-MiDashengLM_Efficient_Audio_Understanding_with_General_Audio_Captions/","children":"[논문리뷰] MiDashengLM: Efficient Audio Understanding with General Audio Captions"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yadong Niu이 [arXiv]에 게시한 'MiDashengLM: Efficient Audio Understanding with General Audio Captions' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Audio-Language Model",{"className":"page__taxonomy-item","children":["#","Audio-Language Model"]}],["$","span","General Audio Captions",{"className":"page__taxonomy-item","children":["#","General Audio Captions"]}],["$","span","Audio Understanding",{"className":"page__taxonomy-item","children":["#","Audio Understanding"]}],["$","span","Speech Recognition",{"className":"page__taxonomy-item","children":["#","Speech Recognition"]}],["$","span","Efficient Inference",{"className":"page__taxonomy-item","children":["#","Efficient Inference"]}],["$","span","Public Datasets",{"className":"page__taxonomy-item","children":["#","Public Datasets"]}],["$","span","Multimodality",{"className":"page__taxonomy-item","children":["#","Multimodality"]}],["$","span","Data Curation",{"className":"page__taxonomy-item","children":["#","Data Curation"]}]]}]]}]]}],["$","article","2025-8-7-Light-IF_Endowing_LLMs_with_Generalizable_Reasoning_via_Preview_and_Self-Checking_for_Complex_Instruction_Following",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-Light-IF_Endowing_LLMs_with_Generalizable_Reasoning_via_Preview_and_Self-Checking_for_Complex_Instruction_Following/","children":"[논문리뷰] Light-IF: Endowing LLMs with Generalizable Reasoning via Preview and Self-Checking for Complex Instruction Following"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Liang Xu이 [arXiv]에 게시한 'Light-IF: Endowing LLMs with Generalizable Reasoning via Preview and Self-Checking for Complex Instruction Following' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Supervised Fine-tuning",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning"]}],["$","span","Entropy Regularization",{"className":"page__taxonomy-item","children":["#","Entropy Regularization"]}],["$","span","Self-Checking",{"className":"page__taxonomy-item","children":["#","Self-Checking"]}],["$","span","Previewing",{"className":"page__taxonomy-item","children":["#","Previewing"]}]]}]]}]]}],["$","article","2025-8-7-LeanK_Learnable_K_Cache_Channel_Pruning_for_Efficient_Decoding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-LeanK_Learnable_K_Cache_Channel_Pruning_for_Efficient_Decoding/","children":"[논문리뷰] LeanK: Learnable K Cache Channel Pruning for Efficient Decoding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yuqing Yang이 [arXiv]에 게시한 'LeanK: Learnable K Cache Channel Pruning for Efficient Decoding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM",{"className":"page__taxonomy-item","children":["#","LLM"]}],["$","span","KV Cache Optimization",{"className":"page__taxonomy-item","children":["#","KV Cache Optimization"]}],["$","span","Model Pruning",{"className":"page__taxonomy-item","children":["#","Model Pruning"]}],["$","span","Efficient Decoding",{"className":"page__taxonomy-item","children":["#","Efficient Decoding"]}],["$","span","Memory Optimization",{"className":"page__taxonomy-item","children":["#","Memory Optimization"]}],["$","span","Static Sparsity",{"className":"page__taxonomy-item","children":["#","Static Sparsity"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}]]}]]}]]}],["$","article","2025-8-7-LaTCoder_Converting_Webpage_Design_to_Code_with_Layout-as-Thought",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-LaTCoder_Converting_Webpage_Design_to_Code_with_Layout-as-Thought/","children":"[논문리뷰] LaTCoder: Converting Webpage Design to Code with Layout-as-Thought"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Tianpeng Lv이 [arXiv]에 게시한 'LaTCoder: Converting Webpage Design to Code with Layout-as-Thought' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Design-to-Code",{"className":"page__taxonomy-item","children":["#","Design-to-Code"]}],["$","span","Webpage Generation",{"className":"page__taxonomy-item","children":["#","Webpage Generation"]}],["$","span","Multimodal Large Language Models (MLLMs)",{"className":"page__taxonomy-item","children":["#","Multimodal Large Language Models (MLLMs)"]}],["$","span","Layout Preservation",{"className":"page__taxonomy-item","children":["#","Layout Preservation"]}],["$","span","Chain-of-Thought (CoT)",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought (CoT)"]}],["$","span","UI Automation",{"className":"page__taxonomy-item","children":["#","UI Automation"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}]]}]]}]]}],["$","article","2025-8-7-Is_Chain-of-Thought_Reasoning_of_LLMs_a_Mirage_A_Data_Distribution_Lens",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-Is_Chain-of-Thought_Reasoning_of_LLMs_a_Mirage_A_Data_Distribution_Lens/","children":"[논문리뷰] Is Chain-of-Thought Reasoning of LLMs a Mirage? A Data Distribution Lens"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhen Tan이 [arXiv]에 게시한 'Is Chain-of-Thought Reasoning of LLMs a Mirage? A Data Distribution Lens' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","OOD Generalization",{"className":"page__taxonomy-item","children":["#","OOD Generalization"]}],["$","span","Data Distribution Shift",{"className":"page__taxonomy-item","children":["#","Data Distribution Shift"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Pattern Matching",{"className":"page__taxonomy-item","children":["#","Pattern Matching"]}],["$","span","DataAlchemy",{"className":"page__taxonomy-item","children":["#","DataAlchemy"]}]]}]]}]]}],["$","article","2025-8-7-IFDECORATOR_Wrapping_Instruction_Following_Reinforcement_Learning_with_Verifiable_Rewards",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-IFDECORATOR_Wrapping_Instruction_Following_Reinforcement_Learning_with_Verifiable_Rewards/","children":"[논문리뷰] IFDECORATOR: Wrapping Instruction Following Reinforcement Learning with Verifiable Rewards"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ling-I Wu이 [arXiv]에 게시한 'IFDECORATOR: Wrapping Instruction Following Reinforcement Learning with Verifiable Rewards' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Reward Hacking",{"className":"page__taxonomy-item","children":["#","Reward Hacking"]}],["$","span","LLMs",{"className":"page__taxonomy-item","children":["#","LLMs"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Data Flywheel",{"className":"page__taxonomy-item","children":["#","Data Flywheel"]}],["$","span","Verifiable Rewards",{"className":"page__taxonomy-item","children":["#","Verifiable Rewards"]}]]}]]}]]}],["$","article","2025-8-7-IAUNet_Instance-Aware_U-Net",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-IAUNet_Instance-Aware_U-Net/","children":"[논문리뷰] IAUNet: Instance-Aware U-Net"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Dmytro Fishman이 [arXiv]에 게시한 'IAUNet: Instance-Aware U-Net' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Instance Segmentation",{"className":"page__taxonomy-item","children":["#","Instance Segmentation"]}],["$","span","U-Net",{"className":"page__taxonomy-item","children":["#","U-Net"]}],["$","span","Query-based Model",{"className":"page__taxonomy-item","children":["#","Query-based Model"]}],["$","span","Transformer Decoder",{"className":"page__taxonomy-item","children":["#","Transformer Decoder"]}],["$","span","Biomedical Imaging",{"className":"page__taxonomy-item","children":["#","Biomedical Imaging"]}],["$","span","Cell Segmentation",{"className":"page__taxonomy-item","children":["#","Cell Segmentation"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}]]}]]}]]}],["$","article","2025-8-7-HPSv3_Towards_Wide-Spectrum_Human_Preference_Score",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-HPSv3_Towards_Wide-Spectrum_Human_Preference_Score/","children":"[논문리뷰] HPSv3: Towards Wide-Spectrum Human Preference Score"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hongsheng Li이 [arXiv]에 게시한 'HPSv3: Towards Wide-Spectrum Human Preference Score' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Human Preference Score",{"className":"page__taxonomy-item","children":["#","Human Preference Score"]}],["$","span","Text-to-Image Generation",{"className":"page__taxonomy-item","children":["#","Text-to-Image Generation"]}],["$","span","Image Evaluation",{"className":"page__taxonomy-item","children":["#","Image Evaluation"]}],["$","span","Vision-Language Models (VLMs)",{"className":"page__taxonomy-item","children":["#","Vision-Language Models (VLMs)"]}],["$","span","Uncertainty-Aware Ranking Loss",{"className":"page__taxonomy-item","children":["#","Uncertainty-Aware Ranking Loss"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}],["$","span","Iterative Refinement",{"className":"page__taxonomy-item","children":["#","Iterative Refinement"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}]]}]]}]]}],["$","article","2025-8-7-Gaussian_Variation_Field_Diffusion_for_High-fidelity_Video-to-4D_Synthesis",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-Gaussian_Variation_Field_Diffusion_for_High-fidelity_Video-to-4D_Synthesis/","children":"[논문리뷰] Gaussian Variation Field Diffusion for High-fidelity Video-to-4D Synthesis"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Feng Zhao이 [arXiv]에 게시한 'Gaussian Variation Field Diffusion for High-fidelity Video-to-4D Synthesis' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","4D Generation",{"className":"page__taxonomy-item","children":["#","4D Generation"]}],["$","span","Video-to-3D Synthesis",{"className":"page__taxonomy-item","children":["#","Video-to-3D Synthesis"]}],["$","span","Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","Gaussian Splatting"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Latent Space Modeling",{"className":"page__taxonomy-item","children":["#","Latent Space Modeling"]}],["$","span","Variational Autoencoder",{"className":"page__taxonomy-item","children":["#","Variational Autoencoder"]}],["$","span","Temporal Coherence",{"className":"page__taxonomy-item","children":["#","Temporal Coherence"]}]]}]]}]]}],["$","article","2025-8-7-EVOC2RUST_A_Skeleton-guided_Framework_for_Project-Level_C-to-Rust_Translation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-EVOC2RUST_A_Skeleton-guided_Framework_for_Project-Level_C-to-Rust_Translation/","children":"[논문리뷰] EVOC2RUST: A Skeleton-guided Framework for Project-Level C-to-Rust Translation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Dong Chen이 [arXiv]에 게시한 'EVOC2RUST: A Skeleton-guided Framework for Project-Level C-to-Rust Translation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","C-to-Rust Conversion",{"className":"page__taxonomy-item","children":["#","C-to-Rust Conversion"]}],["$","span","Project-Level Translation",{"className":"page__taxonomy-item","children":["#","Project-Level Translation"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Code Synthesis",{"className":"page__taxonomy-item","children":["#","Code Synthesis"]}],["$","span","Memory Safety",{"className":"page__taxonomy-item","children":["#","Memory Safety"]}],["$","span","Software Migration",{"className":"page__taxonomy-item","children":["#","Software Migration"]}],["$","span","Hybrid Translation",{"className":"page__taxonomy-item","children":["#","Hybrid Translation"]}]]}]]}]]}],["$","article","2025-8-7-Enhancing_Vision-Language_Model_Training_with_Reinforcement_Learning_in_Synthetic_Worlds_for_Real-World_Success",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-Enhancing_Vision-Language_Model_Training_with_Reinforcement_Learning_in_Synthetic_Worlds_for_Real-World_Success/","children":"[논문리뷰] Enhancing Vision-Language Model Training with Reinforcement Learning in Synthetic Worlds for Real-World Success"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Ruslan Rakhimov이 [arXiv]에 게시한 'Enhancing Vision-Language Model Training with Reinforcement Learning in Synthetic Worlds for Real-World Success' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Synthetic Worlds",{"className":"page__taxonomy-item","children":["#","Synthetic Worlds"]}],["$","span","Transfer Learning",{"className":"page__taxonomy-item","children":["#","Transfer Learning"]}],["$","span","PPO",{"className":"page__taxonomy-item","children":["#","PPO"]}],["$","span","Actor-Critic",{"className":"page__taxonomy-item","children":["#","Actor-Critic"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}]]}]]}]]}],["$","article","2025-8-7-Efficient_Agents_Building_Effective_Agents_While_Reducing_Cost",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-Efficient_Agents_Building_Effective_Agents_While_Reducing_Cost/","children":"[논문리뷰] Efficient Agents: Building Effective Agents While Reducing Cost"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yue Hou이 [arXiv]에 게시한 'Efficient Agents: Building Effective Agents While Reducing Cost' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Cost Efficiency",{"className":"page__taxonomy-item","children":["#","Cost Efficiency"]}],["$","span","Performance-Cost Trade-off",{"className":"page__taxonomy-item","children":["#","Performance-Cost Trade-off"]}],["$","span","Agent Frameworks",{"className":"page__taxonomy-item","children":["#","Agent Frameworks"]}],["$","span","GAIA Benchmark",{"className":"page__taxonomy-item","children":["#","GAIA Benchmark"]}],["$","span","Optimization",{"className":"page__taxonomy-item","children":["#","Optimization"]}],["$","span","Resource Management",{"className":"page__taxonomy-item","children":["#","Resource Management"]}]]}]]}]]}],["$","article","2025-8-7-DreamVVT_Mastering_Realistic_Video_Virtual_Try-On_in_the_Wild_via_a_Stage-Wise_Diffusion_Transformer_Framework",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-DreamVVT_Mastering_Realistic_Video_Virtual_Try-On_in_the_Wild_via_a_Stage-Wise_Diffusion_Transformer_Framework/","children":"[논문리뷰] DreamVVT: Mastering Realistic Video Virtual Try-On in the Wild via a Stage-Wise Diffusion Transformer Framework"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chao Liang이 [arXiv]에 게시한 'DreamVVT: Mastering Realistic Video Virtual Try-On in the Wild via a Stage-Wise Diffusion Transformer Framework' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Video Virtual Try-On",{"className":"page__taxonomy-item","children":["#","Video Virtual Try-On"]}],["$","span","Diffusion Transformers",{"className":"page__taxonomy-item","children":["#","Diffusion Transformers"]}],["$","span","Stage-Wise Framework",{"className":"page__taxonomy-item","children":["#","Stage-Wise Framework"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","LoRA",{"className":"page__taxonomy-item","children":["#","LoRA"]}],["$","span","Temporal Consistency",{"className":"page__taxonomy-item","children":["#","Temporal Consistency"]}],["$","span","Garment Preservation",{"className":"page__taxonomy-item","children":["#","Garment Preservation"]}]]}]]}]]}],["$","article","2025-8-7-CoTox_Chain-of-Thought-Based_Molecular_Toxicity_Reasoning_and_Prediction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-CoTox_Chain-of-Thought-Based_Molecular_Toxicity_Reasoning_and_Prediction/","children":"[논문리뷰] CoTox: Chain-of-Thought-Based Molecular Toxicity Reasoning and Prediction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Donghyeon Lee이 [arXiv]에 게시한 'CoTox: Chain-of-Thought-Based Molecular Toxicity Reasoning and Prediction' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Toxicity Prediction",{"className":"page__taxonomy-item","children":["#","Toxicity Prediction"]}],["$","span","Large Language Model",{"className":"page__taxonomy-item","children":["#","Large Language Model"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Drug Development",{"className":"page__taxonomy-item","children":["#","Drug Development"]}],["$","span","Cheminformatics",{"className":"page__taxonomy-item","children":["#","Cheminformatics"]}],["$","span","Interpretable AI",{"className":"page__taxonomy-item","children":["#","Interpretable AI"]}],["$","span","IUPAC Nomenclature",{"className":"page__taxonomy-item","children":["#","IUPAC Nomenclature"]}]]}]]}]]}],["$","article","2025-8-7-C3D-AD_Toward_Continual_3D_Anomaly_Detection_via_Kernel_Attention_with_Learnable_Advisor",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-C3D-AD_Toward_Continual_3D_Anomaly_Detection_via_Kernel_Attention_with_Learnable_Advisor/","children":"[논문리뷰] C3D-AD: Toward Continual 3D Anomaly Detection via Kernel Attention with Learnable Advisor"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jinbao Wang이 [arXiv]에 게시한 'C3D-AD: Toward Continual 3D Anomaly Detection via Kernel Attention with Learnable Advisor' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Anomaly Detection",{"className":"page__taxonomy-item","children":["#","3D Anomaly Detection"]}],["$","span","Continual Learning",{"className":"page__taxonomy-item","children":["#","Continual Learning"]}],["$","span","Kernel Attention",{"className":"page__taxonomy-item","children":["#","Kernel Attention"]}],["$","span","Learnable Advisor",{"className":"page__taxonomy-item","children":["#","Learnable Advisor"]}],["$","span","Parameter Perturbation",{"className":"page__taxonomy-item","children":["#","Parameter Perturbation"]}],["$","span","Point Cloud",{"className":"page__taxonomy-item","children":["#","Point Cloud"]}],["$","span","Industrial AI",{"className":"page__taxonomy-item","children":["#","Industrial AI"]}]]}]]}]]}],["$","article","2025-8-7-A_Coarse-to-Fine_Approach_to_Multi-Modality_3D_Occupancy_Grounding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-A_Coarse-to-Fine_Approach_to_Multi-Modality_3D_Occupancy_Grounding/","children":"[논문리뷰] A Coarse-to-Fine Approach to Multi-Modality 3D Occupancy Grounding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jianke Zhu이 [arXiv]에 게시한 'A Coarse-to-Fine Approach to Multi-Modality 3D Occupancy Grounding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Occupancy Grounding",{"className":"page__taxonomy-item","children":["#","3D Occupancy Grounding"]}],["$","span","Multi-modal Learning",{"className":"page__taxonomy-item","children":["#","Multi-modal Learning"]}],["$","span","Natural Language Understanding",{"className":"page__taxonomy-item","children":["#","Natural Language Understanding"]}],["$","span","Autonomous Driving",{"className":"page__taxonomy-item","children":["#","Autonomous Driving"]}],["$","span","Voxel-based Prediction",{"className":"page__taxonomy-item","children":["#","Voxel-based Prediction"]}],["$","span","Benchmark Dataset",{"className":"page__taxonomy-item","children":["#","Benchmark Dataset"]}],["$","span","Coarse-to-Fine",{"className":"page__taxonomy-item","children":["#","Coarse-to-Fine"]}]]}]]}]]}],["$","article","2025-8-7-Agent_Lightning_Train_ANY_AI_Agents_with_Reinforcement_Learning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-7-Agent_Lightning_Train_ANY_AI_Agents_with_Reinforcement_Learning/","children":"[논문리뷰] Agent Lightning: Train ANY AI Agents with Reinforcement Learning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zilong Wang이 [arXiv]에 게시한 'Agent Lightning: Train ANY AI Agents with Reinforcement Learning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-07 13:38:21+0900","children":"2025년 8월 7일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","AI Agents",{"className":"page__taxonomy-item","children":["#","AI Agents"]}],["$","span","Framework",{"className":"page__taxonomy-item","children":["#","Framework"]}],["$","span","Markov Decision Process",{"className":"page__taxonomy-item","children":["#","Markov Decision Process"]}],["$","span","Hierarchical RL",{"className":"page__taxonomy-item","children":["#","Hierarchical RL"]}],["$","span","Training-Agent Disaggregation",{"className":"page__taxonomy-item","children":["#","Training-Agent Disaggregation"]}],["$","span","Observability",{"className":"page__taxonomy-item","children":["#","Observability"]}]]}]]}]]}],["$","article","2025-8-6-TRACEALIGN_--_Tracing_the_Drift_Attributing_Alignment_Failures_to_Training-Time_Belief_Sources_in_LLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-6-TRACEALIGN_--_Tracing_the_Drift_Attributing_Alignment_Failures_to_Training-Time_Belief_Sources_in_LLMs/","children":"[논문리뷰] TRACEALIGN -- Tracing the Drift: Attributing Alignment Failures to Training-Time Belief Sources in LLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Aman Chadha이 [arXiv]에 게시한 'TRACEALIGN -- Tracing the Drift: Attributing Alignment Failures to Training-Time Belief Sources in LLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-06 13:46:36+0900","children":"2025년 8월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Alignment",{"className":"page__taxonomy-item","children":["#","LLM Alignment"]}],["$","span","Alignment Drift",{"className":"page__taxonomy-item","children":["#","Alignment Drift"]}],["$","span","Training Data Provenance",{"className":"page__taxonomy-item","children":["#","Training Data Provenance"]}],["$","span","Belief Conflict Index (BCI)",{"className":"page__taxonomy-item","children":["#","Belief Conflict Index (BCI)"]}],["$","span","Suffix Array",{"className":"page__taxonomy-item","children":["#","Suffix Array"]}],["$","span","Safety Interventions",{"className":"page__taxonomy-item","children":["#","Safety Interventions"]}],["$","span","Reinforcement Learning from Human Feedback",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning from Human Feedback"]}],["$","span","Explainable AI",{"className":"page__taxonomy-item","children":["#","Explainable AI"]}]]}]]}]]}],["$","article","2025-8-6-Tool-integrated_Reinforcement_Learning_for_Repo_Deep_Search",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-6-Tool-integrated_Reinforcement_Learning_for_Repo_Deep_Search/","children":"[논문리뷰] Tool-integrated Reinforcement Learning for Repo Deep Search"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yanzhen Zou이 [arXiv]에 게시한 'Tool-integrated Reinforcement Learning for Repo Deep Search' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-06 13:46:36+0900","children":"2025년 8월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Issue Localization",{"className":"page__taxonomy-item","children":["#","Issue Localization"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Reinforcement Learning (RL)",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning (RL)"]}],["$","span","Supervised Fine-tuning (SFT)",{"className":"page__taxonomy-item","children":["#","Supervised Fine-tuning (SFT)"]}],["$","span","Tool-integrated Agents",{"className":"page__taxonomy-item","children":["#","Tool-integrated Agents"]}],["$","span","Software Engineering",{"className":"page__taxonomy-item","children":["#","Software Engineering"]}],["$","span","Code Search",{"className":"page__taxonomy-item","children":["#","Code Search"]}]]}]]}]]}],["$","article","2025-8-6-Skywork_UniPic_Unified_Autoregressive_Modeling_for_Visual_Understanding_and_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-6-Skywork_UniPic_Unified_Autoregressive_Modeling_for_Visual_Understanding_and_Generation/","children":"[논문리뷰] Skywork UniPic: Unified Autoregressive Modeling for Visual Understanding and Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Tianyidan Xie이 [arXiv]에 게시한 'Skywork UniPic: Unified Autoregressive Modeling for Visual Understanding and Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-06 13:46:36+0900","children":"2025년 8월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Autoregressive Models",{"className":"page__taxonomy-item","children":["#","Autoregressive Models"]}],["$","span","Multimodal AI",{"className":"page__taxonomy-item","children":["#","Multimodal AI"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Visual Understanding",{"className":"page__taxonomy-item","children":["#","Visual Understanding"]}],["$","span","Unified Architecture",{"className":"page__taxonomy-item","children":["#","Unified Architecture"]}],["$","span","Parameter Efficiency",{"className":"page__taxonomy-item","children":["#","Parameter Efficiency"]}]]}]]}]]}],["$","article","2025-8-6-Seed_Diffusion_A_Large-Scale_Diffusion_Language_Model_with_High-Speed_Inference",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-6-Seed_Diffusion_A_Large-Scale_Diffusion_Language_Model_with_High-Speed_Inference/","children":"[논문리뷰] Seed Diffusion: A Large-Scale Diffusion Language Model with High-Speed Inference"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Fan Xia이 [arXiv]에 게시한 'Seed Diffusion: A Large-Scale Diffusion Language Model with High-Speed Inference' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-06 13:46:36+0900","children":"2025년 8월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Language Models",{"className":"page__taxonomy-item","children":["#","Language Models"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","Non-Autoregressive Inference",{"className":"page__taxonomy-item","children":["#","Non-Autoregressive Inference"]}],["$","span","High-Speed Inference",{"className":"page__taxonomy-item","children":["#","High-Speed Inference"]}],["$","span","Discrete Diffusion",{"className":"page__taxonomy-item","children":["#","Discrete Diffusion"]}],["$","span","LLM Inference",{"className":"page__taxonomy-item","children":["#","LLM Inference"]}]]}]]}]]}],["$","article","2025-8-6-Multi-human_Interactive_Talking_Dataset",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-6-Multi-human_Interactive_Talking_Dataset/","children":"[논문리뷰] Multi-human Interactive Talking Dataset"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Mike Zheng Shou이 [arXiv]에 게시한 'Multi-human Interactive Talking Dataset' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-06 13:46:36+0900","children":"2025년 8월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-human Video Generation",{"className":"page__taxonomy-item","children":["#","Multi-human Video Generation"]}],["$","span","Interactive Talking",{"className":"page__taxonomy-item","children":["#","Interactive Talking"]}],["$","span","Dataset",{"className":"page__taxonomy-item","children":["#","Dataset"]}],["$","span","Audio-driven Animation",{"className":"page__taxonomy-item","children":["#","Audio-driven Animation"]}],["$","span","Pose Control",{"className":"page__taxonomy-item","children":["#","Pose Control"]}],["$","span","Speech Interaction",{"className":"page__taxonomy-item","children":["#","Speech Interaction"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}]]}]]}]]}],["$","article","2025-8-6-LongVie_Multimodal-Guided_Controllable_Ultra-Long_Video_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-6-LongVie_Multimodal-Guided_Controllable_Ultra-Long_Video_Generation/","children":"[논문리뷰] LongVie: Multimodal-Guided Controllable Ultra-Long Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chenyang Si이 [arXiv]에 게시한 'LongVie: Multimodal-Guided Controllable Ultra-Long Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-06 13:46:36+0900","children":"2025년 8월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Ultra-long Video Generation",{"className":"page__taxonomy-item","children":["#","Ultra-long Video Generation"]}],["$","span","Multimodal Guidance",{"className":"page__taxonomy-item","children":["#","Multimodal Guidance"]}],["$","span","Controllable Video Generation",{"className":"page__taxonomy-item","children":["#","Controllable Video Generation"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Temporal Consistency",{"className":"page__taxonomy-item","children":["#","Temporal Consistency"]}],["$","span","Visual Quality",{"className":"page__taxonomy-item","children":["#","Visual Quality"]}],["$","span","Autoregressive Generation",{"className":"page__taxonomy-item","children":["#","Autoregressive Generation"]}],["$","span","Degradation-aware Training",{"className":"page__taxonomy-item","children":["#","Degradation-aware Training"]}]]}]]}]]}],["$","article","2025-8-6-LiveMCPBench_Can_Agents_Navigate_an_Ocean_of_MCP_Tools",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-6-LiveMCPBench_Can_Agents_Navigate_an_Ocean_of_MCP_Tools/","children":"[논문리뷰] LiveMCPBench: Can Agents Navigate an Ocean of MCP Tools?"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yaojie Lu이 [arXiv]에 게시한 'LiveMCPBench: Can Agents Navigate an Ocean of MCP Tools?' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-06 13:46:36+0900","children":"2025년 8월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Agent",{"className":"page__taxonomy-item","children":["#","LLM Agent"]}],["$","span","Tool-use",{"className":"page__taxonomy-item","children":["#","Tool-use"]}],["$","span","MCP",{"className":"page__taxonomy-item","children":["#","MCP"]}],["$","span","Benchmark",{"className":"page__taxonomy-item","children":["#","Benchmark"]}],["$","span","Large-scale",{"className":"page__taxonomy-item","children":["#","Large-scale"]}],["$","span","Real-world tasks",{"className":"page__taxonomy-item","children":["#","Real-world tasks"]}],["$","span","Automated Evaluation",{"className":"page__taxonomy-item","children":["#","Automated Evaluation"]}],["$","span","Meta-tool-learning",{"className":"page__taxonomy-item","children":["#","Meta-tool-learning"]}]]}]]}]]}],["$","article","2025-8-6-LAMIC_Layout-Aware_Multi-Image_Composition_via_Scalability_of_Multimodal_Diffusion_Transformer",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-6-LAMIC_Layout-Aware_Multi-Image_Composition_via_Scalability_of_Multimodal_Diffusion_Transformer/","children":"[논문리뷰] LAMIC: Layout-Aware Multi-Image Composition via Scalability of Multimodal Diffusion Transformer"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Shunyu Yao이 [arXiv]에 게시한 'LAMIC: Layout-Aware Multi-Image Composition via Scalability of Multimodal Diffusion Transformer' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-06 13:46:36+0900","children":"2025년 8월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-Image Composition",{"className":"page__taxonomy-item","children":["#","Multi-Image Composition"]}],["$","span","Layout Control",{"className":"page__taxonomy-item","children":["#","Layout Control"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Transformer",{"className":"page__taxonomy-item","children":["#","Transformer"]}],["$","span","Attention Mechanisms",{"className":"page__taxonomy-item","children":["#","Attention Mechanisms"]}],["$","span","Training-Free",{"className":"page__taxonomy-item","children":["#","Training-Free"]}],["$","span","Zero-Shot Generalization",{"className":"page__taxonomy-item","children":["#","Zero-Shot Generalization"]}]]}]]}]]}],["$","article","2025-8-6-Goedel-Prover-V2_Scaling_Formal_Theorem_Proving_with_Scaffolded_Data_Synthesis_and_Self-Correction",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-6-Goedel-Prover-V2_Scaling_Formal_Theorem_Proving_with_Scaffolded_Data_Synthesis_and_Self-Correction/","children":"[논문리뷰] Goedel-Prover-V2: Scaling Formal Theorem Proving with Scaffolded Data Synthesis and Self-Correction"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jui-Hui Chung이 [arXiv]에 게시한 'Goedel-Prover-V2: Scaling Formal Theorem Proving with Scaffolded Data Synthesis and Self-Correction' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-06 13:46:36+0900","children":"2025년 8월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Automated Theorem Proving",{"className":"page__taxonomy-item","children":["#","Automated Theorem Proving"]}],["$","span","Formal Verification",{"className":"page__taxonomy-item","children":["#","Formal Verification"]}],["$","span","Language Models",{"className":"page__taxonomy-item","children":["#","Language Models"]}],["$","span","Self-Correction",{"className":"page__taxonomy-item","children":["#","Self-Correction"]}],["$","span","Data Synthesis",{"className":"page__taxonomy-item","children":["#","Data Synthesis"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Model Averaging",{"className":"page__taxonomy-item","children":["#","Model Averaging"]}],["$","span","Lean",{"className":"page__taxonomy-item","children":["#","Lean"]}]]}]]}]]}],["$","article","2025-8-6-CRINN_Contrastive_Reinforcement_Learning_for_Approximate_Nearest_Neighbor_Search",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-6-CRINN_Contrastive_Reinforcement_Learning_for_Approximate_Nearest_Neighbor_Search/","children":"[논문리뷰] CRINN: Contrastive Reinforcement Learning for Approximate Nearest Neighbor Search"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiwei Li이 [arXiv]에 게시한 'CRINN: Contrastive Reinforcement Learning for Approximate Nearest Neighbor Search' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-06 13:46:36+0900","children":"2025년 8월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Approximate Nearest Neighbor Search",{"className":"page__taxonomy-item","children":["#","Approximate Nearest Neighbor Search"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Code Optimization",{"className":"page__taxonomy-item","children":["#","Code Optimization"]}],["$","span","HNSW",{"className":"page__taxonomy-item","children":["#","HNSW"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}],["$","span","Contrastive Learning",{"className":"page__taxonomy-item","children":["#","Contrastive Learning"]}]]}]]}]]}],["$","article","2025-8-6-CompassVerifier_A_Unified_and_Robust_Verifier_for_LLMs_Evaluation_and_Outcome_Reward",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-6-CompassVerifier_A_Unified_and_Robust_Verifier_for_LLMs_Evaluation_and_Outcome_Reward/","children":"[논문리뷰] CompassVerifier: A Unified and Robust Verifier for LLMs Evaluation and Outcome Reward"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Songyang Gao이 [arXiv]에 게시한 'CompassVerifier: A Unified and Robust Verifier for LLMs Evaluation and Outcome Reward' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-06 13:46:36+0900","children":"2025년 8월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Answer Verification",{"className":"page__taxonomy-item","children":["#","Answer Verification"]}],["$","span","Reward Model",{"className":"page__taxonomy-item","children":["#","Reward Model"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Formula Verification",{"className":"page__taxonomy-item","children":["#","Formula Verification"]}],["$","span","Hallucination Detection",{"className":"page__taxonomy-item","children":["#","Hallucination Detection"]}]]}]]}]]}],["$","article","2025-8-6-ChartCap_Mitigating_Hallucination_of_Dense_Chart_Captioning",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-6-ChartCap_Mitigating_Hallucination_of_Dense_Chart_Captioning/","children":"[논문리뷰] ChartCap: Mitigating Hallucination of Dense Chart Captioning"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Gunhee Kim이 [arXiv]에 게시한 'ChartCap: Mitigating Hallucination of Dense Chart Captioning' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-06 13:46:36+0900","children":"2025년 8월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Chart Captioning",{"className":"page__taxonomy-item","children":["#","Chart Captioning"]}],["$","span","Hallucination Mitigation",{"className":"page__taxonomy-item","children":["#","Hallucination Mitigation"]}],["$","span","Dataset Generation",{"className":"page__taxonomy-item","children":["#","Dataset Generation"]}],["$","span","Visual Language Models",{"className":"page__taxonomy-item","children":["#","Visual Language Models"]}],["$","span","Cycle Consistency",{"className":"page__taxonomy-item","children":["#","Cycle Consistency"]}],["$","span","Reference-Free Metric",{"className":"page__taxonomy-item","children":["#","Reference-Free Metric"]}],["$","span","Data Visualization",{"className":"page__taxonomy-item","children":["#","Data Visualization"]}]]}]]}]]}],["$","article","2025-8-6-AlignGuard-LoRA_Alignment-Preserving_Fine-Tuning_via_Fisher-Guided_Decomposition_and_Riemannian-Geodesic_Collision_Regularization",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-6-AlignGuard-LoRA_Alignment-Preserving_Fine-Tuning_via_Fisher-Guided_Decomposition_and_Riemannian-Geodesic_Collision_Regularization/","children":"[논문리뷰] AlignGuard-LoRA: Alignment-Preserving Fine-Tuning via Fisher-Guided Decomposition and Riemannian-Geodesic Collision Regularization"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Aman Chadha이 [arXiv]에 게시한 'AlignGuard-LoRA: Alignment-Preserving Fine-Tuning via Fisher-Guided Decomposition and Riemannian-Geodesic Collision Regularization' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-06 13:46:36+0900","children":"2025년 8월 6일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Alignment Preservation",{"className":"page__taxonomy-item","children":["#","Alignment Preservation"]}],["$","span","Fine-Tuning",{"className":"page__taxonomy-item","children":["#","Fine-Tuning"]}],["$","span","LoRA",{"className":"page__taxonomy-item","children":["#","LoRA"]}],["$","span","Fisher Information Matrix",{"className":"page__taxonomy-item","children":["#","Fisher Information Matrix"]}],["$","span","Catastrophic Forgetting",{"className":"page__taxonomy-item","children":["#","Catastrophic Forgetting"]}],["$","span","LLM Safety",{"className":"page__taxonomy-item","children":["#","LLM Safety"]}],["$","span","Riemannian Geometry",{"className":"page__taxonomy-item","children":["#","Riemannian Geometry"]}],["$","span","Parameter-Efficient Learning",{"className":"page__taxonomy-item","children":["#","Parameter-Efficient Learning"]}]]}]]}]]}],["$","article","2025-8-5-VeOmni__Scaling_Any_Modality_Model_Training_with_Model-Centric __Distributed_Recipe_Zoo",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-5-VeOmni__Scaling_Any_Modality_Model_Training_with_Model-Centric __Distributed_Recipe_Zoo/","children":"[논문리뷰] VeOmni: Scaling Any Modality Model Training with Model-Centric Distributed Recipe Zoo"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Bin Jia이 [arXiv]에 게시한 'VeOmni: Scaling Any Modality Model Training with Model-Centric Distributed Recipe Zoo' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-05 11:40:52+0900","children":"2025년 8월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Omni-modal LLMs",{"className":"page__taxonomy-item","children":["#","Omni-modal LLMs"]}],["$","span","Distributed Training",{"className":"page__taxonomy-item","children":["#","Distributed Training"]}],["$","span","Model-centric",{"className":"page__taxonomy-item","children":["#","Model-centric"]}],["$","span","Parallelism",{"className":"page__taxonomy-item","children":["#","Parallelism"]}],["$","span","FSDP",{"className":"page__taxonomy-item","children":["#","FSDP"]}],["$","span","Sequence Parallelism",{"className":"page__taxonomy-item","children":["#","Sequence Parallelism"]}],["$","span","Expert Parallelism",{"className":"page__taxonomy-item","children":["#","Expert Parallelism"]}],["$","span","Mixture-of-Experts",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts"]}]]}]]}]]}],["$","article","2025-8-5-SitEmb-v1.5__Improved_Context-Aware_Dense_Retrieval_for_Semantic __Association_and_Long_Story_Comprehension",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-5-SitEmb-v1.5__Improved_Context-Aware_Dense_Retrieval_for_Semantic __Association_and_Long_Story_Comprehension/","children":"[논문리뷰] SitEmb-v1.5: Improved Context-Aware Dense Retrieval for Semantic Association and Long Story Comprehension"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Liyan Xu이 [arXiv]에 게시한 'SitEmb-v1.5: Improved Context-Aware Dense Retrieval for Semantic Association and Long Story Comprehension' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-05 11:40:52+0900","children":"2025년 8월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Dense Retrieval",{"className":"page__taxonomy-item","children":["#","Dense Retrieval"]}],["$","span","Context-Aware Embedding",{"className":"page__taxonomy-item","children":["#","Context-Aware Embedding"]}],["$","span","RAG",{"className":"page__taxonomy-item","children":["#","RAG"]}],["$","span","Long Document Comprehension",{"className":"page__taxonomy-item","children":["#","Long Document Comprehension"]}],["$","span","Residual Learning",{"className":"page__taxonomy-item","children":["#","Residual Learning"]}],["$","span","Semantic Association",{"className":"page__taxonomy-item","children":["#","Semantic Association"]}],["$","span","Text Embedding",{"className":"page__taxonomy-item","children":["#","Text Embedding"]}]]}]]}]]}],["$","article","2025-8-5-RoboMemory__A_Brain-inspired_Multi-memory_Agentic_Framework_for_Lifelong __Learning_in_Physical_Embodied_Systems",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-5-RoboMemory__A_Brain-inspired_Multi-memory_Agentic_Framework_for_Lifelong __Learning_in_Physical_Embodied_Systems/","children":"[논문리뷰] RoboMemory: A Brain-inspired Multi-memory Agentic Framework for Lifelong Learning in Physical Embodied Systems"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Junkun Hong이 [arXiv]에 게시한 'RoboMemory: A Brain-inspired Multi-memory Agentic Framework for Lifelong Learning in Physical Embodied Systems' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-05 11:40:52+0900","children":"2025년 8월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Brain-inspired AI",{"className":"page__taxonomy-item","children":["#","Brain-inspired AI"]}],["$","span","Lifelong Learning",{"className":"page__taxonomy-item","children":["#","Lifelong Learning"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Multi-memory Systems",{"className":"page__taxonomy-item","children":["#","Multi-memory Systems"]}],["$","span","Knowledge Graph",{"className":"page__taxonomy-item","children":["#","Knowledge Graph"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Closed-Loop Planning",{"className":"page__taxonomy-item","children":["#","Closed-Loop Planning"]}]]}]]}]]}],["$","article","2025-8-5-Qwen-Image_Technical_Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-5-Qwen-Image_Technical_Report/","children":"[논문리뷰] Qwen-Image Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kaiyuan Gao이 [arXiv]에 게시한 'Qwen-Image Technical Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-05 11:40:52+0900","children":"2025년 8월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image Generation",{"className":"page__taxonomy-item","children":["#","Image Generation"]}],["$","span","Text-to-Image",{"className":"page__taxonomy-item","children":["#","Text-to-Image"]}],["$","span","Image Editing",{"className":"page__taxonomy-item","children":["#","Image Editing"]}],["$","span","Text Rendering",{"className":"page__taxonomy-item","children":["#","Text Rendering"]}],["$","span","Multimodal Diffusion Transformer",{"className":"page__taxonomy-item","children":["#","Multimodal Diffusion Transformer"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Foundation Model",{"className":"page__taxonomy-item","children":["#","Foundation Model"]}]]}]]}]]}],["$","article","2025-8-5-Personalized_Safety_Alignment_for_Text-to-Image_Diffusion_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-5-Personalized_Safety_Alignment_for_Text-to-Image_Diffusion_Models/","children":"[논문리뷰] Personalized Safety Alignment for Text-to-Image Diffusion Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kaidong Yu이 [arXiv]에 게시한 'Personalized Safety Alignment for Text-to-Image Diffusion Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-05 11:40:52+0900","children":"2025년 8월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Personalized Safety Alignment",{"className":"page__taxonomy-item","children":["#","Personalized Safety Alignment"]}],["$","span","Text-to-Image Diffusion Models",{"className":"page__taxonomy-item","children":["#","Text-to-Image Diffusion Models"]}],["$","span","DPO",{"className":"page__taxonomy-item","children":["#","DPO"]}],["$","span","User Preferences",{"className":"page__taxonomy-item","children":["#","User Preferences"]}],["$","span","Content Moderation",{"className":"page__taxonomy-item","children":["#","Content Moderation"]}],["$","span","Generative AI",{"className":"page__taxonomy-item","children":["#","Generative AI"]}],["$","span","Cross-Attention",{"className":"page__taxonomy-item","children":["#","Cross-Attention"]}],["$","span","Safety Alignment",{"className":"page__taxonomy-item","children":["#","Safety Alignment"]}]]}]]}]]}],["$","article","2025-8-5-Llama-3.1-FoundationAI-SecurityLLM-8B-Instruct_Technical_Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-5-Llama-3.1-FoundationAI-SecurityLLM-8B-Instruct_Technical_Report/","children":"[논문리뷰] Llama-3.1-FoundationAI-SecurityLLM-8B-Instruct Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Anu Vellore이 [arXiv]에 게시한 'Llama-3.1-FoundationAI-SecurityLLM-8B-Instruct Technical Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-05 11:40:52+0900","children":"2025년 8월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Model",{"className":"page__taxonomy-item","children":["#","Large Language Model"]}],["$","span","Cybersecurity",{"className":"page__taxonomy-item","children":["#","Cybersecurity"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}],["$","span","Direct Preference Optimization",{"className":"page__taxonomy-item","children":["#","Direct Preference Optimization"]}],["$","span","Cyber Threat Intelligence",{"className":"page__taxonomy-item","children":["#","Cyber Threat Intelligence"]}],["$","span","Foundation Model",{"className":"page__taxonomy-item","children":["#","Foundation Model"]}],["$","span","Chatbot",{"className":"page__taxonomy-item","children":["#","Chatbot"]}]]}]]}]]}],["$","article","2025-8-5-InstructVLA__Vision-Language-Action_Instruction_Tuning_from __Understanding_to_Manipulation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-5-InstructVLA__Vision-Language-Action_Instruction_Tuning_from __Understanding_to_Manipulation/","children":"[논문리뷰] InstructVLA: Vision-Language-Action Instruction Tuning from Understanding to Manipulation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yang Tian이 [arXiv]에 게시한 'InstructVLA: Vision-Language-Action Instruction Tuning from Understanding to Manipulation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-05 11:40:52+0900","children":"2025년 8월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action (VLA)",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action (VLA)"]}],["$","span","Instruction Tuning",{"className":"page__taxonomy-item","children":["#","Instruction Tuning"]}],["$","span","Multimodal Reasoning",{"className":"page__taxonomy-item","children":["#","Multimodal Reasoning"]}],["$","span","Robotic Manipulation",{"className":"page__taxonomy-item","children":["#","Robotic Manipulation"]}],["$","span","Catastrophic Forgetting",{"className":"page__taxonomy-item","children":["#","Catastrophic Forgetting"]}],["$","span","Mixture-of-Experts (MoE)",{"className":"page__taxonomy-item","children":["#","Mixture-of-Experts (MoE)"]}],["$","span","Flow Matching",{"className":"page__taxonomy-item","children":["#","Flow Matching"]}]]}]]}]]}],["$","article","2025-8-5-Exploitation_Is_All_You_Need..._for_Exploration",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-5-Exploitation_Is_All_You_Need..._for_Exploration/","children":"[논문리뷰] Exploitation Is All You Need... for Exploration"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jesse Roberts이 [arXiv]에 게시한 'Exploitation Is All You Need... for Exploration' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-05 11:40:52+0900","children":"2025년 8월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Exploration-Exploitation",{"className":"page__taxonomy-item","children":["#","Exploration-Exploitation"]}],["$","span","Meta-RL",{"className":"page__taxonomy-item","children":["#","Meta-RL"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Emergent Behavior",{"className":"page__taxonomy-item","children":["#","Emergent Behavior"]}],["$","span","Multi-Armed Bandits",{"className":"page__taxonomy-item","children":["#","Multi-Armed Bandits"]}],["$","span","Gridworlds",{"className":"page__taxonomy-item","children":["#","Gridworlds"]}],["$","span","Pseudo-Thompson Sampling",{"className":"page__taxonomy-item","children":["#","Pseudo-Thompson Sampling"]}]]}]]}]]}],["$","article","2025-8-5-Cyber-Zero__Training_Cybersecurity_Agents_without_Runtime",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-5-Cyber-Zero__Training_Cybersecurity_Agents_without_Runtime/","children":"[논문리뷰] Cyber-Zero: Training Cybersecurity Agents without Runtime"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zijian Wang이 [arXiv]에 게시한 'Cyber-Zero: Training Cybersecurity Agents without Runtime' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-05 11:40:52+0900","children":"2025년 8월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Cybersecurity Agents",{"className":"page__taxonomy-item","children":["#","Cybersecurity Agents"]}],["$","span","LLM Training",{"className":"page__taxonomy-item","children":["#","LLM Training"]}],["$","span","Trajectory Synthesis",{"className":"page__taxonomy-item","children":["#","Trajectory Synthesis"]}],["$","span","Runtime-Free Training",{"className":"page__taxonomy-item","children":["#","Runtime-Free Training"]}],["$","span","CTF Challenges",{"className":"page__taxonomy-item","children":["#","CTF Challenges"]}],["$","span","LLM Simulation",{"className":"page__taxonomy-item","children":["#","LLM Simulation"]}]]}]]}]]}],["$","article","2025-8-5-CellForge__Agentic_Design_of_Virtual_Cell_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-5-CellForge__Agentic_Design_of_Virtual_Cell_Models/","children":"[논문리뷰] CellForge: Agentic Design of Virtual Cell Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Daniel Shao이 [arXiv]에 게시한 'CellForge: Agentic Design of Virtual Cell Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-05 11:40:52+0900","children":"2025년 8월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","AI Scientist",{"className":"page__taxonomy-item","children":["#","AI Scientist"]}],["$","span","Multi-Agent System",{"className":"page__taxonomy-item","children":["#","Multi-Agent System"]}],["$","span","Virtual Cell Modeling",{"className":"page__taxonomy-item","children":["#","Virtual Cell Modeling"]}],["$","span","Single-Cell Perturbation Prediction",{"className":"page__taxonomy-item","children":["#","Single-Cell Perturbation Prediction"]}],["$","span","Deep Learning",{"className":"page__taxonomy-item","children":["#","Deep Learning"]}],["$","span","Automated Model Design",{"className":"page__taxonomy-item","children":["#","Automated Model Design"]}],["$","span","Code Generation",{"className":"page__taxonomy-item","children":["#","Code Generation"]}],["$","span","Retrieval-Augmented Generation",{"className":"page__taxonomy-item","children":["#","Retrieval-Augmented Generation"]}]]}]]}]]}],["$","article","2025-8-5-Beyond_the_Trade-off__Self-Supervised_Reinforcement_Learning_for __Reasoning_Models'_Instruction_Following",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-5-Beyond_the_Trade-off__Self-Supervised_Reinforcement_Learning_for __Reasoning_Models'_Instruction_Following/","children":"[논문리뷰] Beyond the Trade-off: Self-Supervised Reinforcement Learning for Reasoning Models' Instruction Following"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiaqing Liang이 [arXiv]에 게시한 'Beyond the Trade-off: Self-Supervised Reinforcement Learning for Reasoning Models' Instruction Following' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-05 11:40:52+0900","children":"2025년 8월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Self-Supervised RL",{"className":"page__taxonomy-item","children":["#","Self-Supervised RL"]}],["$","span","Instruction Following",{"className":"page__taxonomy-item","children":["#","Instruction Following"]}],["$","span","Reasoning Models",{"className":"page__taxonomy-item","children":["#","Reasoning Models"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Reward Modeling",{"className":"page__taxonomy-item","children":["#","Reward Modeling"]}],["$","span","Curriculum Learning",{"className":"page__taxonomy-item","children":["#","Curriculum Learning"]}]]}]]}]]}],["$","article","2025-8-5-A_Glimpse_to_Compress__Dynamic_Visual_Token_Pruning_for_Large __Vision-Language_Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-5-A_Glimpse_to_Compress__Dynamic_Visual_Token_Pruning_for_Large __Vision-Language_Models/","children":"[논문리뷰] A Glimpse to Compress: Dynamic Visual Token Pruning for Large Vision-Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zuxuan Wu이 [arXiv]에 게시한 'A Glimpse to Compress: Dynamic Visual Token Pruning for Large Vision-Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-05 11:40:52+0900","children":"2025년 8월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Vision-Language Models (LVLMs)",{"className":"page__taxonomy-item","children":["#","Large Vision-Language Models (LVLMs)"]}],["$","span","Visual Token Pruning",{"className":"page__taxonomy-item","children":["#","Visual Token Pruning"]}],["$","span","Dynamic Compression",{"className":"page__taxonomy-item","children":["#","Dynamic Compression"]}],["$","span","GlimpsePrune",{"className":"page__taxonomy-item","children":["#","GlimpsePrune"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}],["$","span","VQA",{"className":"page__taxonomy-item","children":["#","VQA"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}]]}]]}]]}],["$","article","2025-8-5-AgentTTS__Large_Language_Model_Agent_for_Test-time_Compute-optimal __Scaling_Strategy_in_Complex_Tasks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-5-AgentTTS__Large_Language_Model_Agent_for_Test-time_Compute-optimal __Scaling_Strategy_in_Complex_Tasks/","children":"[논문리뷰] AgentTTS: Large Language Model Agent for Test-time Compute-optimal Scaling Strategy in Complex Tasks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhiwei Zhang이 [arXiv]에 게시한 'AgentTTS: Large Language Model Agent for Test-time Compute-optimal Scaling Strategy in Complex Tasks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-05 11:40:52+0900","children":"2025년 8월 5일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Test-time Scaling",{"className":"page__taxonomy-item","children":["#","Test-time Scaling"]}],["$","span","Compute Optimization",{"className":"page__taxonomy-item","children":["#","Compute Optimization"]}],["$","span","Multi-stage Tasks",{"className":"page__taxonomy-item","children":["#","Multi-stage Tasks"]}],["$","span","Resource Allocation",{"className":"page__taxonomy-item","children":["#","Resource Allocation"]}],["$","span","Search Efficiency",{"className":"page__taxonomy-item","children":["#","Search Efficiency"]}]]}]]}]]}],["$","article","2025-8-4-SWE-Exp__Experience-Driven_Software_Issue_Resolution",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-4-SWE-Exp__Experience-Driven_Software_Issue_Resolution/","children":"[논문리뷰] SWE-Exp: Experience-Driven Software Issue Resolution"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Heng Lian이 [arXiv]에 게시한 'SWE-Exp: Experience-Driven Software Issue Resolution' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-04 12:17:01+0900","children":"2025년 8월 4일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Software Issue Resolution",{"className":"page__taxonomy-item","children":["#","Software Issue Resolution"]}],["$","span","LLM Agents",{"className":"page__taxonomy-item","children":["#","LLM Agents"]}],["$","span","Experience-Driven Learning",{"className":"page__taxonomy-item","children":["#","Experience-Driven Learning"]}],["$","span","Automated Program Repair",{"className":"page__taxonomy-item","children":["#","Automated Program Repair"]}],["$","span","Multi-Agent Systems",{"className":"page__taxonomy-item","children":["#","Multi-Agent Systems"]}],["$","span","Knowledge Management",{"className":"page__taxonomy-item","children":["#","Knowledge Management"]}],["$","span","Continuous Learning",{"className":"page__taxonomy-item","children":["#","Continuous Learning"]}]]}]]}]]}],["$","article","2025-8-4-SWE-Debate__Competitive_Multi-Agent_Debate_for_Software_Issue_Resolution",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-4-SWE-Debate__Competitive_Multi-Agent_Debate_for_Software_Issue_Resolution/","children":"[논문리뷰] SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Heng Lian이 [arXiv]에 게시한 'SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-04 12:17:01+0900","children":"2025년 8월 4일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-Agent System",{"className":"page__taxonomy-item","children":["#","Multi-Agent System"]}],["$","span","Software Engineering",{"className":"page__taxonomy-item","children":["#","Software Engineering"]}],["$","span","Fault Localization",{"className":"page__taxonomy-item","children":["#","Fault Localization"]}],["$","span","Issue Resolution",{"className":"page__taxonomy-item","children":["#","Issue Resolution"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Competitive Debate",{"className":"page__taxonomy-item","children":["#","Competitive Debate"]}],["$","span","Graph Traversal",{"className":"page__taxonomy-item","children":["#","Graph Traversal"]}]]}]]}]]}],["$","article","2025-8-4-SpA2V__Harnessing_Spatial_Auditory_Cues_for_Audio-driven_Spatially-aware __Video_Generation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-4-SpA2V__Harnessing_Spatial_Auditory_Cues_for_Audio-driven_Spatially-aware __Video_Generation/","children":"[논문리뷰] SpA2V: Harnessing Spatial Auditory Cues for Audio-driven Spatially-aware Video Generation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Long Chen이 [arXiv]에 게시한 'SpA2V: Harnessing Spatial Auditory Cues for Audio-driven Spatially-aware Video Generation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-04 12:17:01+0900","children":"2025년 8월 4일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Audio-driven Video Generation",{"className":"page__taxonomy-item","children":["#","Audio-driven Video Generation"]}],["$","span","Spatial Auditory Cues",{"className":"page__taxonomy-item","children":["#","Spatial Auditory Cues"]}],["$","span","Video Scene Layout",{"className":"page__taxonomy-item","children":["#","Video Scene Layout"]}],["$","span","MLLM",{"className":"page__taxonomy-item","children":["#","MLLM"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Training-free",{"className":"page__taxonomy-item","children":["#","Training-free"]}]]}]]}]]}],["$","article","2025-8-4-PixNerd__Pixel_Neural_Field_Diffusion",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-4-PixNerd__Pixel_Neural_Field_Diffusion/","children":"[논문리뷰] PixNerd: Pixel Neural Field Diffusion"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Limin Wang이 [arXiv]에 게시한 'PixNerd: Pixel Neural Field Diffusion' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-04 12:17:01+0900","children":"2025년 8월 4일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Neural Fields",{"className":"page__taxonomy-item","children":["#","Neural Fields"]}],["$","span","Pixel Space",{"className":"page__taxonomy-item","children":["#","Pixel Space"]}],["$","span","Generative Models",{"className":"page__taxonomy-item","children":["#","Generative Models"]}],["$","span","Image Synthesis",{"className":"page__taxonomy-item","children":["#","Image Synthesis"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","End-to-End Learning",{"className":"page__taxonomy-item","children":["#","End-to-End Learning"]}]]}]]}]]}],["$","article","2025-8-4-Multimodal_Referring_Segmentation__A_Survey",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-4-Multimodal_Referring_Segmentation__A_Survey/","children":"[논문리뷰] Multimodal Referring Segmentation: A Survey"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zuxuan Wu이 [arXiv]에 게시한 'Multimodal Referring Segmentation: A Survey' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-04 12:17:01+0900","children":"2025년 8월 4일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multimodal Learning",{"className":"page__taxonomy-item","children":["#","Multimodal Learning"]}],["$","span","Referring Segmentation",{"className":"page__taxonomy-item","children":["#","Referring Segmentation"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Image Segmentation",{"className":"page__taxonomy-item","children":["#","Image Segmentation"]}],["$","span","Video Segmentation",{"className":"page__taxonomy-item","children":["#","Video Segmentation"]}],["$","span","3D Vision",{"className":"page__taxonomy-item","children":["#","3D Vision"]}],["$","span","Survey",{"className":"page__taxonomy-item","children":["#","Survey"]}]]}]]}]]}],["$","article","2025-8-4-Learning_an_Efficient_Multi-Turn_Dialogue_Evaluator_from_Multiple_Judges",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-4-Learning_an_Efficient_Multi-Turn_Dialogue_Evaluator_from_Multiple_Judges/","children":"[논문리뷰] Learning an Efficient Multi-Turn Dialogue Evaluator from Multiple Judges"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Chengfei Lv이 [arXiv]에 게시한 'Learning an Efficient Multi-Turn Dialogue Evaluator from Multiple Judges' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-04 12:17:01+0900","children":"2025년 8월 4일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Multi-Turn Dialogue Evaluation",{"className":"page__taxonomy-item","children":["#","Multi-Turn Dialogue Evaluation"]}],["$","span","LLM-as-a-Judge",{"className":"page__taxonomy-item","children":["#","LLM-as-a-Judge"]}],["$","span","Multi-Judge Aggregation",{"className":"page__taxonomy-item","children":["#","Multi-Judge Aggregation"]}],["$","span","Preference Learning",{"className":"page__taxonomy-item","children":["#","Preference Learning"]}],["$","span","Dialogue Quality Assessment",{"className":"page__taxonomy-item","children":["#","Dialogue Quality Assessment"]}],["$","span","Maximum Likelihood Estimation",{"className":"page__taxonomy-item","children":["#","Maximum Likelihood Estimation"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}]]}]]}]]}],["$","article","2025-8-4-Investigating_Hallucination_in_Conversations_for_Low_Resource_Languages",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-4-Investigating_Hallucination_in_Conversations_for_Low_Resource_Languages/","children":"[논문리뷰] Investigating Hallucination in Conversations for Low Resource Languages"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Fatemeh Jamshidi이 [arXiv]에 게시한 'Investigating Hallucination in Conversations for Low Resource Languages' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-04 12:17:01+0900","children":"2025년 8월 4일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","LLM Hallucination",{"className":"page__taxonomy-item","children":["#","LLM Hallucination"]}],["$","span","Low-resource Languages",{"className":"page__taxonomy-item","children":["#","Low-resource Languages"]}],["$","span","Conversational AI",{"className":"page__taxonomy-item","children":["#","Conversational AI"]}],["$","span","ROUGE Score",{"className":"page__taxonomy-item","children":["#","ROUGE Score"]}],["$","span","Cross-lingual Evaluation",{"className":"page__taxonomy-item","children":["#","Cross-lingual Evaluation"]}],["$","span","Factual Consistency",{"className":"page__taxonomy-item","children":["#","Factual Consistency"]}]]}]]}]]}],["$","article","2025-8-4-IGL-Nav__Incremental_3D_Gaussian_Localization_for_Image-goal_Navigation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-4-IGL-Nav__Incremental_3D_Gaussian_Localization_for_Image-goal_Navigation/","children":"[논문리뷰] IGL-Nav: Incremental 3D Gaussian Localization for Image-goal Navigation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jianjiang Feng이 [arXiv]에 게시한 'IGL-Nav: Incremental 3D Gaussian Localization for Image-goal Navigation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-04 12:17:01+0900","children":"2025년 8월 4일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Image-goal Navigation",{"className":"page__taxonomy-item","children":["#","Image-goal Navigation"]}],["$","span","3D Gaussian Splatting (3DGS)",{"className":"page__taxonomy-item","children":["#","3D Gaussian Splatting (3DGS)"]}],["$","span","Incremental Scene Representation",{"className":"page__taxonomy-item","children":["#","Incremental Scene Representation"]}],["$","span","Coarse-to-fine Localization",{"className":"page__taxonomy-item","children":["#","Coarse-to-fine Localization"]}],["$","span","Embodied AI",{"className":"page__taxonomy-item","children":["#","Embodied AI"]}],["$","span","Robotics",{"className":"page__taxonomy-item","children":["#","Robotics"]}],["$","span","Differentiable Rendering",{"className":"page__taxonomy-item","children":["#","Differentiable Rendering"]}]]}]]}]]}],["$","article","2025-8-4-Beyond_Fixed__Variable-Length_Denoising_for_Diffusion_Large_Language __Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-4-Beyond_Fixed__Variable-Length_Denoising_for_Diffusion_Large_Language __Models/","children":"[논문리뷰] Beyond Fixed: Variable-Length Denoising for Diffusion Large Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiaqi Wang이 [arXiv]에 게시한 'Beyond Fixed: Variable-Length Denoising for Diffusion Large Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-04 12:17:01+0900","children":"2025년 8월 4일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Diffusion Large Language Models",{"className":"page__taxonomy-item","children":["#","Diffusion Large Language Models"]}],["$","span","Variable-Length Generation",{"className":"page__taxonomy-item","children":["#","Variable-Length Generation"]}],["$","span","Dynamic Length Adaptation",{"className":"page__taxonomy-item","children":["#","Dynamic Length Adaptation"]}],["$","span","Denoising Strategy",{"className":"page__taxonomy-item","children":["#","Denoising Strategy"]}],["$","span","Inference Optimization",{"className":"page__taxonomy-item","children":["#","Inference Optimization"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}]]}]]}]]}],["$","article","2025-8-4-3D-R1__Enhancing_Reasoning_in_3D_VLMs_for_Unified_Scene_Understanding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-4-3D-R1__Enhancing_Reasoning_in_3D_VLMs_for_Unified_Scene_Understanding/","children":"[논문리뷰] 3D-R1: Enhancing Reasoning in 3D VLMs for Unified Scene Understanding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Hao Tang이 [arXiv]에 게시한 '3D-R1: Enhancing Reasoning in 3D VLMs for Unified Scene Understanding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-04 12:17:01+0900","children":"2025년 8월 4일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Vision-Language Models",{"className":"page__taxonomy-item","children":["#","3D Vision-Language Models"]}],["$","span","Reasoning",{"className":"page__taxonomy-item","children":["#","Reasoning"]}],["$","span","Scene Understanding",{"className":"page__taxonomy-item","children":["#","Scene Understanding"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Dynamic View Selection",{"className":"page__taxonomy-item","children":["#","Dynamic View Selection"]}],["$","span","Multi-task Learning",{"className":"page__taxonomy-item","children":["#","Multi-task Learning"]}]]}]]}]]}],["$","article","2025-8-3-villa-X__Enhancing_Latent_Action_Modeling_in_Vision-Language-Action __Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-villa-X__Enhancing_Latent_Action_Modeling_in_Vision-Language-Action__Models/","children":"[논문리뷰] villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kaixin Wang이 [arXiv]에 게시한 'villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-03 07:35:17+0900","children":"2025년 8월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language-Action Models",{"className":"page__taxonomy-item","children":["#","Vision-Language-Action Models"]}],["$","span","Latent Actions",{"className":"page__taxonomy-item","children":["#","Latent Actions"]}],["$","span","Robot Manipulation",{"className":"page__taxonomy-item","children":["#","Robot Manipulation"]}],["$","span","Pre-training",{"className":"page__taxonomy-item","children":["#","Pre-training"]}],["$","span","Diffusion Models",{"className":"page__taxonomy-item","children":["#","Diffusion Models"]}],["$","span","Proprioceptive Feedback",{"className":"page__taxonomy-item","children":["#","Proprioceptive Feedback"]}],["$","span","Foundation Models",{"className":"page__taxonomy-item","children":["#","Foundation Models"]}]]}]]}]]}],["$","article","2025-8-3-TARS__MinMax_Token-Adaptive_Preference_Strategy_for_Hallucination __Reduction_in_MLLMs",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-TARS__MinMax_Token-Adaptive_Preference_Strategy_for_Hallucination__Reduction_in_MLLMs/","children":"[논문리뷰] TARS: MinMax Token-Adaptive Preference Strategy for Hallucination Reduction in MLLMs"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jiasheng Tang이 [arXiv]에 게시한 'TARS: MinMax Token-Adaptive Preference Strategy for Hallucination Reduction in MLLMs' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-03 07:35:17+0900","children":"2025년 8월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","MLLMs",{"className":"page__taxonomy-item","children":["#","MLLMs"]}],["$","span","Hallucination Reduction",{"className":"page__taxonomy-item","children":["#","Hallucination Reduction"]}],["$","span","Preference Optimization",{"className":"page__taxonomy-item","children":["#","Preference Optimization"]}],["$","span","Min-Max Optimization",{"className":"page__taxonomy-item","children":["#","Min-Max Optimization"]}],["$","span","Token-Adaptive Strategy",{"className":"page__taxonomy-item","children":["#","Token-Adaptive Strategy"]}],["$","span","Spectral Regularization",{"className":"page__taxonomy-item","children":["#","Spectral Regularization"]}],["$","span","Visual Grounding",{"className":"page__taxonomy-item","children":["#","Visual Grounding"]}]]}]]}]]}],["$","article","2025-8-3-Seed-Prover__Deep_and_Broad_Reasoning_for_Automated_Theorem_Proving",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-Seed-Prover__Deep_and_Broad_Reasoning_for_Automated_Theorem_Proving/","children":"[논문리뷰] Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Zhicheng Jiang이 [arXiv]에 게시한 'Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-03 07:35:17+0900","children":"2025년 8월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Automated Theorem Proving",{"className":"page__taxonomy-item","children":["#","Automated Theorem Proving"]}],["$","span","Large Language Models",{"className":"page__taxonomy-item","children":["#","Large Language Models"]}],["$","span","Formal Verification",{"className":"page__taxonomy-item","children":["#","Formal Verification"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Lean",{"className":"page__taxonomy-item","children":["#","Lean"]}],["$","span","Geometry Reasoning",{"className":"page__taxonomy-item","children":["#","Geometry Reasoning"]}],["$","span","Chain-of-Thought",{"className":"page__taxonomy-item","children":["#","Chain-of-Thought"]}],["$","span","Lemma-Style Proving",{"className":"page__taxonomy-item","children":["#","Lemma-Style Proving"]}]]}]]}]]}],["$","article","2025-8-3-Scalable_Multi-Task_Reinforcement_Learning_for_Generalizable_Spatial __Intelligence_in_Visuomotor_Agents",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-Scalable_Multi-Task_Reinforcement_Learning_for_Generalizable_Spatial__Intelligence_in_Visuomotor_Agents/","children":"[논문리뷰] Scalable Multi-Task Reinforcement Learning for Generalizable Spatial Intelligence in Visuomotor Agents"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Anji Liu이 [arXiv]에 게시한 'Scalable Multi-Task Reinforcement Learning for Generalizable Spatial Intelligence in Visuomotor Agents' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-03 07:35:17+0900","children":"2025년 8월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Reinforcement Learning",{"className":"page__taxonomy-item","children":["#","Reinforcement Learning"]}],["$","span","Multi-Task Learning",{"className":"page__taxonomy-item","children":["#","Multi-Task Learning"]}],["$","span","Visuomotor Agents",{"className":"page__taxonomy-item","children":["#","Visuomotor Agents"]}],["$","span","Spatial Reasoning",{"className":"page__taxonomy-item","children":["#","Spatial Reasoning"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Minecraft",{"className":"page__taxonomy-item","children":["#","Minecraft"]}],["$","span","Cross-View Goal Specification",{"className":"page__taxonomy-item","children":["#","Cross-View Goal Specification"]}],["$","span","Automated Task Synthesis",{"className":"page__taxonomy-item","children":["#","Automated Task Synthesis"]}]]}]]}]]}],["$","article","2025-8-3-RecGPT_Technical_Report",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-RecGPT_Technical_Report/","children":"[논문리뷰] RecGPT Technical Report"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jian Wu이 [arXiv]에 게시한 'RecGPT Technical Report' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-03 07:35:17+0900","children":"2025년 8월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Recommender Systems",{"className":"page__taxonomy-item","children":["#","Recommender Systems"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","User Intent Modeling",{"className":"page__taxonomy-item","children":["#","User Intent Modeling"]}],["$","span","Multi-Stage Training",{"className":"page__taxonomy-item","children":["#","Multi-Stage Training"]}],["$","span","Human-in-the-Loop",{"className":"page__taxonomy-item","children":["#","Human-in-the-Loop"]}],["$","span","E-commerce",{"className":"page__taxonomy-item","children":["#","E-commerce"]}],["$","span","Filter Bubble Mitigation",{"className":"page__taxonomy-item","children":["#","Filter Bubble Mitigation"]}],["$","span","Matthew Effect",{"className":"page__taxonomy-item","children":["#","Matthew Effect"]}]]}]]}]]}],["$","article","2025-8-3-Phi-Ground_Tech_Report__Advancing_Perception_in_GUI_Grounding",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-Phi-Ground_Tech_Report__Advancing_Perception_in_GUI_Grounding/","children":"[논문리뷰] Phi-Ground Tech Report: Advancing Perception in GUI Grounding"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Kai Qiu이 [arXiv]에 게시한 'Phi-Ground Tech Report: Advancing Perception in GUI Grounding' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-03 07:35:17+0900","children":"2025년 8월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","GUI grounding",{"className":"page__taxonomy-item","children":["#","GUI grounding"]}],["$","span","AI agent",{"className":"page__taxonomy-item","children":["#","AI agent"]}],["$","span","Large Multi-modal Model",{"className":"page__taxonomy-item","children":["#","Large Multi-modal Model"]}],["$","span","Perception",{"className":"page__taxonomy-item","children":["#","Perception"]}],["$","span","Data Augmentation",{"className":"page__taxonomy-item","children":["#","Data Augmentation"]}],["$","span","Direct Preference Optimization",{"className":"page__taxonomy-item","children":["#","Direct Preference Optimization"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}]]}]]}]]}],["$","article","2025-8-3-Persona_Vectors__Monitoring_and_Controlling_Character_Traits_in_Language __Models",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-Persona_Vectors__Monitoring_and_Controlling_Character_Traits_in_Language__Models/","children":"[논문리뷰] Persona Vectors: Monitoring and Controlling Character Traits in Language Models"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Jack Lindsey이 [arXiv]에 게시한 'Persona Vectors: Monitoring and Controlling Character Traits in Language Models' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-03 07:35:17+0900","children":"2025년 8월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Large Language Models (LLMs)",{"className":"page__taxonomy-item","children":["#","Large Language Models (LLMs)"]}],["$","span","Persona Control",{"className":"page__taxonomy-item","children":["#","Persona Control"]}],["$","span","Activation Steering",{"className":"page__taxonomy-item","children":["#","Activation Steering"]}],["$","span","Finetuning",{"className":"page__taxonomy-item","children":["#","Finetuning"]}],["$","span","Behavioral Shift Detection",{"className":"page__taxonomy-item","children":["#","Behavioral Shift Detection"]}],["$","span","Interpretability",{"className":"page__taxonomy-item","children":["#","Interpretability"]}],["$","span","Data Filtering",{"className":"page__taxonomy-item","children":["#","Data Filtering"]}]]}]]}]]}],["$","article","2025-8-3-On_the_Expressiveness_of_Softmax_Attention__A_Recurrent_Neural_Network __Perspective",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-On_the_Expressiveness_of_Softmax_Attention__A_Recurrent_Neural_Network__Perspective/","children":"[논문리뷰] On the Expressiveness of Softmax Attention: A Recurrent Neural Network Perspective"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Eric C. Larson이 [arXiv]에 게시한 'On the Expressiveness of Softmax Attention: A Recurrent Neural Network Perspective' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-03 07:35:17+0900","children":"2025년 8월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Softmax Attention",{"className":"page__taxonomy-item","children":["#","Softmax Attention"]}],["$","span","Linear Attention",{"className":"page__taxonomy-item","children":["#","Linear Attention"]}],["$","span","Recurrent Neural Networks (RNNs)",{"className":"page__taxonomy-item","children":["#","Recurrent Neural Networks (RNNs)"]}],["$","span","Taylor Series Expansion",{"className":"page__taxonomy-item","children":["#","Taylor Series Expansion"]}],["$","span","Attention Mechanisms",{"className":"page__taxonomy-item","children":["#","Attention Mechanisms"]}],["$","span","Expressiveness",{"className":"page__taxonomy-item","children":["#","Expressiveness"]}],["$","span","Transformer Architectures",{"className":"page__taxonomy-item","children":["#","Transformer Architectures"]}]]}]]}]]}],["$","article","2025-8-3-NeRF_Is_a_Valuable_Assistant_for_3D_Gaussian_Splatting",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-NeRF_Is_a_Valuable_Assistant_for_3D_Gaussian_Splatting/","children":"[논문리뷰] NeRF Is a Valuable Assistant for 3D Gaussian Splatting"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"ZeSheng Wang이 [arXiv]에 게시한 'NeRF Is a Valuable Assistant for 3D Gaussian Splatting' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-03 07:35:17+0900","children":"2025년 8월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","NeRF",{"className":"page__taxonomy-item","children":["#","NeRF"]}],["$","span","3D Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","3D Gaussian Splatting"]}],["$","span","Hybrid Model",{"className":"page__taxonomy-item","children":["#","Hybrid Model"]}],["$","span","Joint Optimization",{"className":"page__taxonomy-item","children":["#","Joint Optimization"]}],["$","span","Scene Representation",{"className":"page__taxonomy-item","children":["#","Scene Representation"]}],["$","span","Neural Rendering",{"className":"page__taxonomy-item","children":["#","Neural Rendering"]}],["$","span","Residual Learning",{"className":"page__taxonomy-item","children":["#","Residual Learning"]}],["$","span","Sparse View",{"className":"page__taxonomy-item","children":["#","Sparse View"]}]]}]]}]]}],["$","article","2025-8-3-iLRM__An_Iterative_Large_3D_Reconstruction_Model",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-iLRM__An_Iterative_Large_3D_Reconstruction_Model/","children":"[논문리뷰] iLRM: An Iterative Large 3D Reconstruction Model"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Abdelrahman Mohamed이 [arXiv]에 게시한 'iLRM: An Iterative Large 3D Reconstruction Model' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-03 07:35:17+0900","children":"2025년 8월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","3D Reconstruction",{"className":"page__taxonomy-item","children":["#","3D Reconstruction"]}],["$","span","Gaussian Splatting",{"className":"page__taxonomy-item","children":["#","Gaussian Splatting"]}],["$","span","Iterative Refinement",{"className":"page__taxonomy-item","children":["#","Iterative Refinement"]}],["$","span","Transformer Architecture",{"className":"page__taxonomy-item","children":["#","Transformer Architecture"]}],["$","span","Multi-view Learning",{"className":"page__taxonomy-item","children":["#","Multi-view Learning"]}],["$","span","Scalability",{"className":"page__taxonomy-item","children":["#","Scalability"]}],["$","span","Feed-forward Models",{"className":"page__taxonomy-item","children":["#","Feed-forward Models"]}]]}]]}]]}],["$","article","2025-8-3-Flow_Equivariant_Recurrent_Neural_Networks",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-Flow_Equivariant_Recurrent_Neural_Networks/","children":"[논문리뷰] Flow Equivariant Recurrent Neural Networks"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"T. Anderson Keller이 [arXiv]에 게시한 'Flow Equivariant Recurrent Neural Networks' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-03 07:35:17+0900","children":"2025년 8월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Flow Equivariance",{"className":"page__taxonomy-item","children":["#","Flow Equivariance"]}],["$","span","Recurrent Neural Networks",{"className":"page__taxonomy-item","children":["#","Recurrent Neural Networks"]}],["$","span","Sequence Models",{"className":"page__taxonomy-item","children":["#","Sequence Models"]}],["$","span","Group Equivariance",{"className":"page__taxonomy-item","children":["#","Group Equivariance"]}],["$","span","Lie Subgroups",{"className":"page__taxonomy-item","children":["#","Lie Subgroups"]}],["$","span","Generalization",{"className":"page__taxonomy-item","children":["#","Generalization"]}],["$","span","Time-Parameterized Symmetries",{"className":"page__taxonomy-item","children":["#","Time-Parameterized Symmetries"]}]]}]]}]]}],["$","article","2025-8-3-Enhanced_Arabic_Text_Retrieval_with_Attentive_Relevance_Scoring",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-Enhanced_Arabic_Text_Retrieval_with_Attentive_Relevance_Scoring/","children":"[논문리뷰] Enhanced Arabic Text Retrieval with Attentive Relevance Scoring"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Abdenour Hadid이 [arXiv]에 게시한 'Enhanced Arabic Text Retrieval with Attentive Relevance Scoring' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-03 07:35:17+0900","children":"2025년 8월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Arabic NLP",{"className":"page__taxonomy-item","children":["#","Arabic NLP"]}],["$","span","Dense Passage Retrieval",{"className":"page__taxonomy-item","children":["#","Dense Passage Retrieval"]}],["$","span","Attentive Relevance Scoring",{"className":"page__taxonomy-item","children":["#","Attentive Relevance Scoring"]}],["$","span","Information Retrieval",{"className":"page__taxonomy-item","children":["#","Information Retrieval"]}],["$","span","Question Answering",{"className":"page__taxonomy-item","children":["#","Question Answering"]}],["$","span","Transformer Models",{"className":"page__taxonomy-item","children":["#","Transformer Models"]}],["$","span","Semantic Matching",{"className":"page__taxonomy-item","children":["#","Semantic Matching"]}]]}]]}]]}],["$","article","2025-8-3-Efficient_Machine_Unlearning_via_Influence_Approximation",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-Efficient_Machine_Unlearning_via_Influence_Approximation/","children":"[논문리뷰] Efficient Machine Unlearning via Influence Approximation"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Enhong Chen이 [arXiv]에 게시한 'Efficient Machine Unlearning via Influence Approximation' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-03 07:35:17+0900","children":"2025년 8월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Machine Unlearning",{"className":"page__taxonomy-item","children":["#","Machine Unlearning"]}],["$","span","Influence Function",{"className":"page__taxonomy-item","children":["#","Influence Function"]}],["$","span","Incremental Learning",{"className":"page__taxonomy-item","children":["#","Incremental Learning"]}],["$","span","Privacy Protection",{"className":"page__taxonomy-item","children":["#","Privacy Protection"]}],["$","span","Gradient Optimization",{"className":"page__taxonomy-item","children":["#","Gradient Optimization"]}],["$","span","Model Editing",{"className":"page__taxonomy-item","children":["#","Model Editing"]}],["$","span","Computational Efficiency",{"className":"page__taxonomy-item","children":["#","Computational Efficiency"]}]]}]]}]]}],["$","article","2025-8-3-C3__A_Bilingual_Benchmark_for_Spoken_Dialogue_Models_Exploring __Challenges_in_Complex_Conversations",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-C3__A_Bilingual_Benchmark_for_Spoken_Dialogue_Models_Exploring__Challenges_in_Complex_Conversations/","children":"[논문리뷰] C3: A Bilingual Benchmark for Spoken Dialogue Models Exploring Challenges in Complex Conversations"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yiwen Guo이 [arXiv]에 게시한 'C3: A Bilingual Benchmark for Spoken Dialogue Models Exploring Challenges in Complex Conversations' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-03 07:35:17+0900","children":"2025년 8월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Spoken Dialogue Models",{"className":"page__taxonomy-item","children":["#","Spoken Dialogue Models"]}],["$","span","Bilingual Benchmark",{"className":"page__taxonomy-item","children":["#","Bilingual Benchmark"]}],["$","span","Complex Conversations",{"className":"page__taxonomy-item","children":["#","Complex Conversations"]}],["$","span","Ambiguity Resolution",{"className":"page__taxonomy-item","children":["#","Ambiguity Resolution"]}],["$","span","Context Understanding",{"className":"page__taxonomy-item","children":["#","Context Understanding"]}],["$","span","LLM Evaluation",{"className":"page__taxonomy-item","children":["#","LLM Evaluation"]}],["$","span","Human-Computer Interaction",{"className":"page__taxonomy-item","children":["#","Human-Computer Interaction"]}]]}]]}]]}],["$","article","2025-8-3-Beyond_Linear_Bottlenecks__Spline-Based_Knowledge_Distillation_for __Culturally_Diverse_Art_Style_Classification",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-Beyond_Linear_Bottlenecks__Spline-Based_Knowledge_Distillation_for__Culturally_Diverse_Art_Style_Classification/","children":"[논문리뷰] Beyond Linear Bottlenecks: Spline-Based Knowledge Distillation for Culturally Diverse Art Style Classification"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Abdelmalik Taleb-Ahmed이 [arXiv]에 게시한 'Beyond Linear Bottlenecks: Spline-Based Knowledge Distillation for Culturally Diverse Art Style Classification' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-03 07:35:17+0900","children":"2025년 8월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Kolmogorov-Arnold Networks",{"className":"page__taxonomy-item","children":["#","Kolmogorov-Arnold Networks"]}],["$","span","Knowledge Distillation",{"className":"page__taxonomy-item","children":["#","Knowledge Distillation"]}],["$","span","Art Style Classification",{"className":"page__taxonomy-item","children":["#","Art Style Classification"]}],["$","span","Self-Supervised Learning",{"className":"page__taxonomy-item","children":["#","Self-Supervised Learning"]}],["$","span","Spline-Based Activation",{"className":"page__taxonomy-item","children":["#","Spline-Based Activation"]}],["$","span","Dual-Teacher",{"className":"page__taxonomy-item","children":["#","Dual-Teacher"]}],["$","span","Gram Matrix",{"className":"page__taxonomy-item","children":["#","Gram Matrix"]}]]}]]}]]}],["$","article","2025-8-3-AgroBench__Vision-Language_Model_Benchmark_in_Agriculture",{"className":"archive__item","children":[["$","h2",null,{"className":"archive__item-title","children":["$","$L3",null,{"href":"/ai/review/2025-8-3-AgroBench__Vision-Language_Model_Benchmark_in_Agriculture/","children":"[논문리뷰] AgroBench: Vision-Language Model Benchmark in Agriculture"}]}],["$","div",null,{"className":"archive__item-excerpt","children":"Yoshitaka Ushiku이 [arXiv]에 게시한 'AgroBench: Vision-Language Model Benchmark in Agriculture' 논문에 대한 자세한 리뷰입니다."}],["$","div",null,{"className":"archive__item-meta","children":[["$","time",null,{"dateTime":"2025-08-03 07:35:17+0900","children":"2025년 8월 3일"}],["$","div",null,{"className":"page__taxonomy mt-2","children":[["$","span","Review",{"className":"page__taxonomy-item","children":["#","Review"]}],["$","span","Vision-Language Models",{"className":"page__taxonomy-item","children":["#","Vision-Language Models"]}],["$","span","Agriculture",{"className":"page__taxonomy-item","children":["#","Agriculture"]}],["$","span","Benchmarking",{"className":"page__taxonomy-item","children":["#","Benchmarking"]}],["$","span","Disease Identification",{"className":"page__taxonomy-item","children":["#","Disease Identification"]}],["$","span","Pest Management",{"className":"page__taxonomy-item","children":["#","Pest Management"]}],["$","span","Crop Management",{"className":"page__taxonomy-item","children":["#","Crop Management"]}],["$","span","Agronomy",{"className":"page__taxonomy-item","children":["#","Agronomy"]}]]}]]}]]}]]}]]}],["$","aside",null,{"className":"lg:w-80","children":["$","div",null,{"className":"sidebar sticky","children":["$","nav",null,{"className":"space-y-4","children":[["$","div","Backend",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"Backend"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Django",{"children":["$","a",null,{"href":"/backend/django/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Django"," (",6,")"]}]}],["$","li","Logging",{"children":["$","a",null,{"href":"/backend/logging/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Logging"," (",1,")"]}]}]]}]]}],["$","div","Python",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"Python"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","PEP",{"children":["$","a",null,{"href":"/python/pep/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["PEP"," (",650,")"]}]}]]}]]}],["$","div","AI/ML",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"AI/ML"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","LLM",{"children":["$","a",null,{"href":"/ai/llm/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["LLM"," (",1,")"]}]}],["$","li","Review",{"children":["$","a",null,{"href":"/ai/review/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Review"," (",1214,")"]}]}]]}]]}],["$","div","DevOps",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"DevOps"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Nginx",{"children":["$","a",null,{"href":"/devops/nginx/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Nginx"," (",1,")"]}]}],["$","li","Docker",{"children":["$","a",null,{"href":"/devops/docker/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Docker"," (",1,")"]}]}],["$","li","SafeLine",{"children":["$","a",null,{"href":"/devops/safeline/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["SafeLine"," (",1,")"]}]}],["$","li","Jenkins",{"children":["$","a",null,{"href":"/devops/jenkins/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Jenkins"," (",3,")"]}]}],["$","li","GitHub Actions",{"children":["$","a",null,{"href":"/devops/github-actions/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["GitHub Actions"," (",1,")"]}]}],["$","li","AWS",{"children":["$","a",null,{"href":"/devops/aws/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["AWS"," (",1,")"]}]}]]}]]}],["$","div","etc",{"children":[["$","h4",null,{"className":"font-medium text-gray-900 mb-2","children":"etc"}],["$","ul",null,{"className":"space-y-1 ml-4","children":[["$","li","Me",{"children":["$","a",null,{"href":"/etc/me/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Me"," (",3,")"]}]}],["$","li","Chrome Extension",{"children":["$","a",null,{"href":"/etc/chrome-extension/","className":"text-sm text-gray-600 hover:text-primary-600 block py-1","children":["Chrome Extension"," (",1,")"]}]}]]}]]}]]}]}]}]]}]}],["$","div",null,{"id":"footer","className":"page__footer","children":["$","footer",null,{"className":"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8","children":["$","div",null,{"className":"text-center text-gray-500 text-sm","children":["$","p",null,{"children":"© 2025 secrett2633. All rights reserved."}]}]}]}]]],null],null]},["$","$L4",null,{"parallelRouterKey":"children","segmentPath":["children","categories","children","$5","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L6",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},["$","$L4",null,{"parallelRouterKey":"children","segmentPath":["children","categories","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L6",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},[["$","html",null,{"lang":"ko","className":"no-js","children":[["$","head",null,{"children":[["$","meta",null,{"name":"msapplication-TileColor","content":"#ffc40d"}],["$","meta",null,{"name":"theme-color","content":"#ffffff"}],["$","script",null,{"async":true,"src":"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY"}],["$","script",null,{"dangerouslySetInnerHTML":{"__html":"\n              window.dataLayer = window.dataLayer || [];\n              function gtag(){dataLayer.push(arguments);}\n              gtag('js', new Date());\n              gtag('config', 'G-NE2W3CFPNY');\n            "}}]]}],["$","body",null,{"className":"__className_f367f3 layout--default","children":["$","div",null,{"className":"min-h-screen bg-gray-50","children":[["$","$L2",null,{}],["$","main",null,{"className":"initial-content","children":["$","$L4",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L6",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","div",null,{"className":"min-h-screen flex items-center justify-center bg-gray-50","children":["$","div",null,{"className":"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center","children":[["$","h1",null,{"className":"text-6xl font-bold text-primary-600 mb-4","children":"404"}],["$","h2",null,{"className":"text-2xl font-semibold text-gray-900 mb-4","children":"페이지를 찾을 수 없습니다"}],["$","p",null,{"className":"text-gray-600 mb-8","children":"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다."}],["$","$L3",null,{"href":"/","className":"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors","children":"홈으로 돌아가기"}]]}]}],"notFoundStyles":[],"styles":null}]}],["$","div",null,{"id":"footer","className":"page__footer","children":["$","footer",null,{"className":"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8","children":["$","div",null,{"className":"text-center text-gray-500 text-sm","children":["$","p",null,{"children":"© 2025 secrett2633. All rights reserved."}]}]}]}]]}]}]]}],null],[["$","div",null,{"className":"flex items-center justify-center min-h-screen","children":["$","div",null,{"className":"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600"}]}],[],[]]],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/e975486d410ad4e9.css","precedence":"next","crossOrigin":"$undefined"}]],[null,"$L7"]]]]]
7:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"secrett2633's blog"}],["$","meta","3",{"name":"description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","meta","4",{"name":"author","content":"secrett2633"}],["$","meta","5",{"name":"keywords","content":"Django, Python, DevOps, AI, ML, 블로그, 기술"}],["$","meta","6",{"name":"creator","content":"secrett2633"}],["$","meta","7",{"name":"publisher","content":"secrett2633"}],["$","meta","8",{"name":"robots","content":"index, follow"}],["$","meta","9",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","10",{"rel":"canonical","href":"https://secrett2633.github.io/"}],["$","meta","11",{"name":"format-detection","content":"telephone=no, address=no, email=no"}],["$","meta","12",{"property":"og:title","content":"secrett2633's blog"}],["$","meta","13",{"property":"og:description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","meta","14",{"property":"og:url","content":"https://secrett2633.github.io/"}],["$","meta","15",{"property":"og:site_name","content":"secrett2633's blog"}],["$","meta","16",{"property":"og:locale","content":"ko_KR"}],["$","meta","17",{"property":"og:type","content":"website"}],["$","meta","18",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","19",{"name":"twitter:title","content":"secrett2633's blog"}],["$","meta","20",{"name":"twitter:description","content":"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"}],["$","link","21",{"rel":"icon","href":"/icon.ico?6d9f34d4948640b8","type":"image/x-icon","sizes":"16x16"}]]
1:null
